Abstract
We propose a novel probabilistic method employing
Bayesian Model Averaging and self-cycle regularization for spatio-temporal correspondence learning in videos within a self-supervised learning framework. Most existing meth-ods for self-supervised correspondence learning suffer from noisy labels that come with the data for free, and the pres-ence of occlusion exacerbates the problem. We tackle this issue within a probabilistic framework that handles model uncertainty inherent in the path selection problem built on a complete graph. We propose a self-cycle regularization to consider a cycle-consistency property on individual edges in order to prevent converging on noisy matching or trivial solutions. We also utilize a mixture of sequential Bayesian filters to estimate posterior distribution for targets. In ad-dition, we present a domain contrastive loss to learn dis-criminative representation among videos. Our algorithm is evaluated on various datasets for video label propagation tasks including DAVIS2017, VIP and JHMDB, and shows outstanding performances compared to the state-of-the-art self-supervised learning based video correspondence algo-rithms. Moreover, our method converges significantly faster than previous methods. 1.

Introduction
With recent advances in deep neural networks and contrastive learning, there have been rapid and substan-tial progress in self-supervised visual representation learn-ing [3, 10, 11, 13, 15, 16, 33, 35]. This approach explores implicit supervisory patterns capture in massive unlabeled images or videos. Recently, it has succeeded to learn much richer representations compared to the strong supervised learning approaches. Yet, it has not lead to advances in learning temporal correspondences from video.
Learning representations for visual correspondence across space and time is a one of fundamental problems in computer vision, and closely related to many vision tasks, such as video object tracking [1, 40, 46], video ob-Figure 1. Procedure of proposed model-averaged filtering with multiple paths. Our model conducts a (a) complete graph from given a video clip, and (b) finds palindrome sequences starting from the first frame (red circles). (c) Self-cycle edges (dashed arrows) are selected in a stochastic manner. (d) All chain models are averaged to obtain the final posterior. ject segmentation [2, 32, 43], and optical flow estimation [9, 21]. The collection of large-scale visual correspondence dataset, however, is dreadfully labor-intensive, and the qual-ity of labels depends on human annotators. Recently, self-supervised visual correspondence learning becomes one so-lution to handle this problem by leveraging a large amount of raw videos for training [22,23,29–31,44,47,49,53]. This self-supervised visual correspondence problem is formu-lated by a query-target matching problem in videos, which finds an affinity between the query frame and the target frame to match corresponding points.
Most of recent advanced methods, however, rely on noisy labels captured from colors [29, 30, 44], cycle-consistency constraint [22, 31, 47, 49, 53], positive/negative sample mining [23], or frame-level similarity [50] during training. Directions of these approaches are promising, but they often rely on sophisticated manners or ambiguous su-pervisions that may lead to falling in local optima and over-fitting to the noisy labels. To alleviate this problem, a prob-abilistic method [22] is proposed to find paths through the graph by performing a random walk between query and tar-get nodes. The problem, however, is that it may suffer from occlusions since the graph in [22] is modeled by the first-order Markov chain where the edge is linked between two consecutive frames. The very recent approach [23] tackles
those issues by collecting well-defined samples by solving optimal transport problem and measuring their uncertain-ties. Although this method tries to handle uncertainties by collecting positive samples, it still suffers from ambiguity of labels since positive and negative samples are selected by their similarity scores only.
Another limitation of most self-supervised correspon-dence learning methods [22, 23, 29, 30, 49, 53, 53] in videos is that they focus only on contrastive learning within a given video. Intra-inter consistency loss in [47] is proposed to en-courage both positive feature invariance and negative video embedding separation, but it uses an indirect reconstruction loss rather than a contrastive loss, and its performance is far from the state-of-the-art one. Meanwhile, [50] focuses on contrastive learning at video frame-level representations.
This method, however, only discriminates the coarse frame-level representations within and across the videos without considering fine patch-level representations.
We propose a new self-cycle regularization method that implies a cycle-consistency constraint for each edge in the graph, which help preventing an overfitting by incorrect matching at the early stage on training. This simple self-cycle edge preserves a cycle-consistency constraint within individual edges as well as a whole path. However, since it is intractable to handle all possible paths having self-cycle edges, we use stochastic sampling to reduce complexity and address lack of model diversity.
In addition, we propose a novel Bayesian framework that learns visual representations for dense correspondences using a complete space-time graph from an input video.
The complete space-time graph is constructed from a video clip where nodes correspond to grid patches in frames, and edges connect two nodes between all different frames. We then extract a path set including all possible paths start-ing from the first frame and returning back to the first frame again. This is called the palindrome sequence as in [22]. Since we cannot identify where occlusions exist during training, we leverage the Bayesian Model Averaging (BMA) [18] to handle uncertainty inherent in the model se-lection process. By averaging all possible competing paths by BMA, we can alleviate overfitting and uncertainty prob-lems in the model. In Figure 1, we illustrate a simplified procedure of our model-average filtering on multiple paths extracted on a complete graph.
Furthermore, we present a domain contrastive loss that discriminates learned representations of different videos in the embedding space. Most methods typically focus on learning similar representation for positive matches and dis-tant one for negative matches within a video. In order to learn more comprehensive representations for multiple do-mains which correspond to videos, we aggregate all features within a video and then apply the domain-wise contrastive loss to distinguish them. This can be viewed as coarse-to-fine contrastive learning for videos.
Our contributions are summarized as follows:
• We propose self-cycle edges that implicitly deal with cycle-consistency in a single edge and mitigate a prob-lem of falling into local optima in earlier training stage.
• A mixture of sequential Bayesian filters is used to formulate space-time correspondences on multiple paths considering multi-hops in a complete graph con-structed from a video. It can handle model uncertainty by considering all paths in the graph simultaneously.
• Our batch-wise domain contrastive loss discriminates negative pairs not only in the same video but also be-tween different videos. It leads to learn fine-grained visual representations for dense correspondences.
• Our method not only outperforms the state-of-the-art algorithms but also converges much faster on various video benchmarks. 2.