Abstract
Pseudo-labels are conﬁdent predictions made on unla-beled target data by a classiﬁer trained on labeled source data. They are widely used for adapting a model to unlabeled data, e.g., in a semi-supervised learning setting.
Our key insight is that pseudo-labels are naturally imbal-anced due to intrinsic data similarity, even when a model is trained on balanced source data and evaluated on balanced target data. If we address this previously unknown imbal-anced classiﬁcation problem arising from pseudo-labels in-stead of ground-truth training labels, we could remove model biases towards false majorities created by pseudo-labels.
We propose a novel and effective debiased learning method with pseudo-labels, based on counterfactual rea-soning and adaptive margins: The former removes the clas-siﬁer response bias, whereas the latter adjusts the margin of each class according to the imbalance of pseudo-labels.
Validated by extensive experimentation, our simple debiased learning delivers signiﬁcant accuracy gains over the state-of-the-art on ImageNet-1K: 26% for semi-supervised learning with 0.2% annotations and 9% for zero-shot learning. Our code is available at: https://github.com/frank-xwang/debiased-pseudo-labeling. 1.

Introduction
Real-world observations, as well as non-curated datasets, are naturally long-tail distributed [18, 56]. Imbalanced clas-siﬁcation [10, 24, 59] tackles such data biases to prevent models from being dominated by head-class instances. De-veloping visual recognition systems capable of counteracting biases also has signiﬁcant social impacts [34].
While existing methods focus on debiasing from imbal-anced ground-truth labels collected by human annotators, we discover that pseudo-labels produced by machine learning models are naturally imbalanced, creating another source for widespread biased learning!
Pseudo-labels are highly conﬁdent predictions made by an existing (teacher) model on unlabeled data, which then become part of the training data for supervising the (student) model adaptation to unlabeled data (Fig. 1a). When the stu-(a) Framework of pseudo-labeling (b) FixMatch on CIFAR10 SSL (c) CLIP on ImageNet ZSL
Figure 1. We study the pseudo-labeling-based Semi-Supervised
Learning (SSL) and transductive Zero-Shot Learning (ZSL), where both tasks require transferring semantic information learned from labeled source data to unlabeled target data via pseudo-labeling.
Surprisingly, we ﬁnd that pseudo-labels of target data produced by typical SSL and ZSL methods (i.e., FixMatch [53] and CLIP [45]) are highly biased, even when both source and target data are class-balanced or even sampled from the same domain. dent model is the teacher model itself, the learning process is also known as self-training [4, 5, 29, 53, 65]. Pseudo-labeling is widely used in semi-supervised learning (SSL) [32, 53], domain adaptation [25, 37], and transfer learning [1].
We examine pseudo-label distributions in two common tasks. 1) In zero-shot transfer learning (ZSL) where the source and target domains are different, a pretrained CLIP model [45] produces highly imbalanced predictions on the curated and balanced ImageNet-1K dataset, although the training set of CLIP is approximately balanced (Fig. 1c).
More than 3500 instances are predicted as class 0, 3 times the actual number of samples in class 0. 2) In semi-supervised learning where the source and target domains are the same,
FixMatch [53] trained on labeled CIFAR10 images generates highly biased pseudo-labels on unlabeled images, although both the labeled and unlabeled sets are balanced (Fig. 1b).
That is, pseudo-labels created by machines are naturally imbalanced, just like ground-truth labels created by humans.
If we address this previously unknown imbalanced classiﬁ-cation problem arising from pseudo-labels instead of ground-truth training labels, we could improve model learning based
on pseudo-labels and remove the model bias towards false majorities created by pseudo-labels.
We propose a novel and effective debiased learning method with pseudo-labels, without any knowledge about the distribution of actual classiﬁcation margins that are readily available to debiased learning with ground-truth la-bels [22, 33, 57]. It consists of an adaptive debiasing module and an adaptive marginal loss. The former dynamically re-moves the classiﬁer response bias through counterfactual reasoning, whereas the latter dynamically adjusts the margin of each class according to the imbalance of pseudo-labels.
Validated by our extensive experiments, our simple de-biased learning not only improves the state-of-the-art on
ImageNet-1K by 26% for SSL with 0.2% annotations and 9% for ZSL, but is also a universal add-on to various pseudo-labeling methods with more robustness to domain shift. The imbalanced pseudo-labeling issue is even more severe when the unlabeled raw data is naturally imbalanced, and the model tends to mislabel tail-class samples as head-class. By applying debiased learning, we improve SSL performance under long-tailed settings by a large margin.
Our work makes four major contributions. 1) We sys-tematically investigate and discover that pseudo-labels are naturally imbalanced and create biased learning. 2) We pro-pose a simple debiased learning method with pseudo-labeled instances, requiring no knowledge of their actual classiﬁca-tion margins. 3) We improve the ZSL/SSL state-of-the-art by a large margin and demonstrate that our debiasing is a universal add-on to various pseudo-labeling models. 4) We establish a new effective ZSL/SSL pipeline for applying vision-and-language pre-trained models such as CLIP. 2.