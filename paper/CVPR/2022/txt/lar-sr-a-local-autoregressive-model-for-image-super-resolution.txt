Abstract
Previous super-resolution (SR) approaches often formu-late SR as a regression problem and pixel wise restora-tion, which leads to a blurry and unreal SR output. Re-cent works combine adversarial loss with pixel-wise loss to train a GAN-based model or introduce normalizing flows into SR problems to generate more realistic images. As an-other powerful generative approach, autoregressive (AR) model has not been noticed in low level tasks due to its limitation. Based on the fact that given the structural in-formation, the textural details in the natural images are lo-cally related without long term dependency, in this paper we propose a novel autoregressive model-based SR approach, namely LAR-SR, which can efficiently generate realistic SR images using a novel local autoregressive (LAR) module.
The proposed LAR module can sample all the patches of textural components in parallel, which greatly reduces the time consumption. In addition to high time efficiency, it is also able to leverage contextual information of pixels and can be optimized with a consistent loss. Experimental re-sults on the widely-used datasets show that the proposed
LAR-SR approach achieves superior performance on the vi-sual quality and quantitative metrics compared with other generative models such as GAN, Flow, and is competitive with the mixture generative model. 1.

Introduction
Recent years have witnessed great progress in deep learning based method for image super-resolution (SR)
[5, 14, 33]. Most of the existing methods formulate image
SR as a pixel-wise regression problem, which is optimized with a pixel-wise loss such as L1 or MSE. As image super-resolution is inherently an ill-posed problem, when trained with many-to-one mapping between the high resolution im-ages and the low resolution images, the regression-based models, with the per-pixel loss design, tend to adopt the av-*Equal contribution(co-first authors).
†Corresponding author.
Figure 1. The purpose of regression-based methods (a) is to min-imize the pixel-wise loss, i.e., MSE-loss or L1-loss between the ground truth and the output, which results in blur images lacking of details. Our algorithm is based on the autoregresssive method (b), which considers the relation between adjacent pixels. Accord-ing to the HR datasets, the first pixel has a probability of 3/4 of 0 and a probability of 1/4 of 1. Once we sample the first pixel as 0, the second pixel has a posterior probability of 2/3 of 0 and a posterior probability of 1/3 of 1 et al. erage of all possible HR images, thus suffering from blurry and unreal SR images. See Figure 1(a) for an illustration.
To generate more realistic images, Generative Adversar-ial Network (GAN) [7]-based models and Flow [4]-based models have recently been introduced into image super-resolution. Both types of these methods generate all the pixels in parallel where the correlation between pixels is implicitly embedded in the latent space. During the training procedure, the discriminator or the invertable network maps the normal distribution to the joint distribution of the pix-els. Thus GAN-based and Flow-based models can generate high-fidelity details compared with traditional regression-based models. However, GAN-based models pose the chal-lenge of joint optimization, while Flow-based models are limited by the specific invertable network.
As another powerful generative model, autoregressive model has recently been explored in image synthesis tasks
[6], which expressively learn relationships among its input.
Because Taming transformer [6] is designed for general im-age synthesis where global understanding of the input is acquired by modeling long-range relationship through se-quential sampling, one great challenge of such expressive modeling is its computationally infeasibility for long se-quences, especially for high-resolution images. Although patch-wise processing in a sliding-window manner has been adopted for speeding, its computation cost is still based on the size of the images and unacceptable especially for the super-resolution beyond High Definition (HD) resolution.
Focusing on the super-resolution task, with the LR in-put, we can obtain a coarse SR result by a simple regres-sion model, which has already included the main content and semantic structure. And thus we only need the expres-sive model to generate the additional texture details or high frequency components of images, which can be modelled locally (experiments also verify this hypothesis). There-fore, in this paper we propose to take advantage of both regression and autoregressive models. With a coarse SR achieved by a regression model, we can efficiently and ef-fectively generate texture details by a local autoregressive model with a learned texture codebook by our proposed
LAR-SR model.
Specifically, for textural details generation, we partition the image into non-overlapping patches, and pixels in all the patches are sampled in parallel by the local autoregressive module as shown in Figure 2. Thus the time consumption is significantly reduced because of the parallelism. What’s more, inspired by [20] that the AR-based model benefits from the quantization compression for the data space, a novel texture codebook based on Vector Quantized Varia-tional AutoEncoder (VQVAE) [20] is adopted to learn and discretize the textural detail. Since this texture codebook is only for generating texture details, it is much easier to learn. Leveraging the texture codebook learned from the
VQVAE and coarse-SR from the regression model, the pro-posed LAR-SR method can generate texture details effi-ciently in a patch-wise and parallel mode.
Our main contributions can be summarized as follows:
• We propose a novel local autoregressive super-resolution framework by taking advantage of both re-gression and autoregressive models, which can gener-ate SR images with high-fidelity details but also high computation efficiency. To the best of our knowledge, it is the first AR-based framework designed for the super-resolution task.
• A novel local autoregressive (LAR) module is pro-posed to efficiently generate texture details in patch-wise and parallel mode, through a learned texture codebook from VQVAE and a coarse-SR from a re-gression model.
• We construct extensive experiments for two super res-olution tasks: general super resolution and face super
Figure 2. Example of our local autoregressive method, with a patch size of 4×4. All the pixels are labeled by their locations in each patch. The same labeled pixels are sampled in parallel.
Thus the sampling time complexity only depends on the size of the patch. resolution. Objective quality metrics and visual results on three popular datasets (DIV2k [1], celebA [15] and
FFHQ [10]) show that LAR-SR can yield state-of-the-art results compared with baseline approaches. 2.