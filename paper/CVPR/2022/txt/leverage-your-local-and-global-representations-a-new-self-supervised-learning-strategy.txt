Abstract
Self-supervised learning (SSL) methods aim to learn view-invariant representations by maximizing the similar-ity between the features extracted from different crops of the same image regardless of cropping size and content. In essence, this strategy ignores the fact that two crops may truly contain different image information, e.g., background and small objects, and thus tends to restrain the diversity of the learned representations. In this work, we address this issue by introducing a new self-supervised learning strat-egy, LoGo, that explicitly reasons about Local and Global crops. To achieve view invariance, LoGo encourages sim-ilarity between global crops from the same image, as well as between a global and a local crop. However, to correctly encode the fact that the content of smaller crops may differ entirely, LoGo promotes two local crops to have dissimi-lar representations, while being close to global crops. Our
LoGo strategy can easily be applied to existing SSL meth-ods. Our extensive experiments on a variety of datasets and using different self-supervised learning frameworks vali-date its superiority over existing approaches. Noticeably, we achieve better results than supervised models on trans-fer learning when using only 1/10 of the data.1 1.

Introduction
Building on the great success of supervised learning in visual tasks such as image classification [20,25,26] and ob-ject detection [15,19], significant efforts have recently been dedicated to learning high-level representations without hu-man annotations. Inspired by the pre-training stage in natu-ral language processing, e.g. GPT [32] and BERT [13], such a self-supervised learning (SSL) approach aims to learn representations that extract useful information for a down-stream task in an unsupervised manner, thus providing an 1Our code and pretrained models can be https://github.com/ztt1024/LoGo-SSL. Correspondence (wei.ke@mail.xjtu.edu.cn). at found to Ke Wei effective initialization to start from when some annotated data for the downstream tasks become available. Recently,
SSL has been proven to be as effective as supervised pre-training, or even more effective in some cases [6, 10].
The basic principle behind existing SSL approaches can be traced back to [17, 29] and consists of learning a repre-sentation that is shared across different views of the same input, yet carries discriminative information.
In vision tasks, this is typically achieved by maximizing the similar-ity between two augmented views of the same image while penalizing trivial solutions using various techniques. For example, contrastive learning [9, 18] incorporates negative pairs, where one view comes from a different image, to prevent the network from constantly generating the same output; non-contrastive methods [11, 16] only rely on posi-tive pairs by modifying the back-propagation mechanism to prevent collapse; clustering-based methods [2, 6] perform online clustering to keep the consistency between exem-plar representations (the centroids of clusters) and different views of the same image.
Intuitively, one should expect the representations of ran-dom crops with smaller sizes to have a larger variance than that of larger crops because, as shown in Figure 1, they may truly encode entirely different content. Nevertheless, exist-ing methods encourage all the random crops of the same image to have similar representations. This complicates the learning process and tends to lead the network to discard-ing valuable image information to achieve such invariance.
This was, for example, observed in [7], where the multi-crop strategy of [6] was shown to yield a performance drop when applied to other SSL methods, such as BYOL [16],
SimSiam [11], and MoCo [18]
In this paper, we address this limitation by introducing a new multi-crop SSL strategy, LoGo, which exploits the re-lationships between local and global image patches in dif-ferent, well-adapted ways, and can easily be integrated into existing SSL frameworks. Specifically, we exploit two dif-ferent kinds of crops: Large ones that encompass a global view of the input image, thus being well-suited to learn a view-invariant representation; and small ones with a higher
(a) (b)
Figure 1. (a) Overview of our self-supervised learning strategy. To learn a view-invariant representation that nonetheless encodes semantic information about local objects, we seek to maximize the similarity between global crops while allowing the local crops to remain distant from each other, thus accounting for the fact that local crops may represent entirely different objects. (b) Monitoring of the KNN top-1 accuracy on ImageNet-100 with a ResNet-34 backbone evidences the benefits of our approach in different SSL strategies. variance that focus on local image regions, thus allowing the model to encode information such as background, tex-ture, and objects. As illustrated in Figure 1, we then design a loss function that (i) pulls the global representations of the same image close to each other, while also encouraging each local representation of that image to be close to the global ones; (ii) favors the different local representations to remain distant to account for the differences between the local patches. Altogether, this provides the model with the flexibility to keep apart the local representations that encode different regions while nonetheless encouraging the repre-sentations of all crops from the same image to cluster in the latent space.
Furthermore, to account for the fact that traditional dis-tance metrics may be unreliable in a high dimensional space [1], we introduce a new approach to evaluate the sim-ilarity between the representations of two patches. Specif-ically, based on the assumption that the similarity of two local crops from the same image is greater than that of two local crops from different images with high probability, we train an MLP to discriminate between pairs of local crops from the same or from different images, and exploit its pre-diction as a similarity score.
Our contributions can be summarized as follows:
• We exploit both global and local views in SSL to en-code rich semantic information. To this end, we en-courage similarity across global crops to achieve view invariance, but allow the local crops to be dissimilar to maintain the diversity of local object representations.
• We introduce a learnable similarity measure to over-come the limitations of standard metrics in high di-mensional feature space.
• Our approach generalizes to different SSL frame-works, including constrastive (e.g., MoCo [18]) and non-contrastive (e.g., SimSiam [11]) ones.
• Our approach allows the network to be trained on smaller datasets, which benefits downstream tasks where the training-testing domain gap is large.
We demonstrate the benefits of our approach over the state-of-the-art SSL techniques on several datasets. Importantly, our strategy enables the self-supervised models to surpass their supervised counterparts on dense prediction tasks with only 1/10 of the training data. 2.