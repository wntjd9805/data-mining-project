Abstract
In this paper, we study teacher-student learning from the perspective of data initialization and propose a novel algo-rithm called Active Teacher1 for semi-supervised object de-tection (SSOD). Active Teacher extends the teacher-student framework to an iterative version, where the label set is partially initialized and gradually augmented by evaluat-ing three key factors of unlabeled examples, including dif-ficulty, information and diversity. With this design, Active
Teacher can maximize the effect of limited label informa-tion while improving the quality of pseudo-labels. To vali-date our approach, we conduct extensive experiments on the
MS-COCO benchmark and compare Active Teacher with a set of recently proposed SSOD methods. The experimental results not only validate the superior performance gain of
Active Teacher over the compared methods, but also show that it enables the baseline network, i.e., Faster-RCNN, to achieve 100% supervised performance with much less la-bel expenditure, i.e. 40% labeled examples on MS-COCO.
More importantly, we believe that the experimental analy-ses in this paper can provide useful empirical knowledge for data annotation in practical applications. 1.

Introduction
Recent years have witnessed the rapid development of object detection supported by a flurry of benchmark datasets [9, 11, 22, 32] and methods [13–15, 23, 26, 28, 29].
Despite great success, the expensive instance-level annota-tion has long plagued the advancement and application of existing detection models. To this end, how to save labeling expenditure has become a research focus in object detec-tion [4, 5, 17, 17, 24, 25, 33, 35, 36, 38, 40, 41].
*Equal Contribution. † Corresponding Author. 1Source code are available at: https://github.com/HunterJ-Lin/ActiveTeacher
Figure 1. The performance comparison between Active Teacher and the state-of-the-art (SOTA) method [24] with different propor-tions of labeled data in MS-COCO. Active Teacher exceeds 100% fully supervised performance with only 40% label information.
Specifically,
Inspired by recent success in image classification [2, 3, 19, 34, 39], some practitioners resort to teacher-student learning for semi-supervised object detection (SSOD) [24, this methodology uses a teacher 35, 37]. network with weakly augmented labeled data to generate high-quality pseudo-labels for the student network with strong data augmentation [8, 10, 44]. This self-training process helps the model explore large amounts of unla-beled data based on a very limited number of annota-tions. Following this methodology, Sohn et al. [35] pro-posed the first teacher-student framework called STAC for
SSOD. This simple framework outperforms the existing semi-supervised methods [4, 33, 36, 38] by a large margin, showing the great potential of teacher-student learning in object detection.
Some very recent SSOD works [24, 37, 50] are pro-posed to improve this methodology. For instances, Liu et al. [24] apply exponential moving average (EMA) [39] to train a gradually progressing teacher to alleviate the class-imbalance and over-fitting issues. Zhou et al. [50] propose an instant pseudo labeling strategy to reduce the impact of the confirmation bias and improve the quality of pseudo la-beling. In [37], Tang et al. adopt a detection-specific data ensemble to produce more reliable pseudo-labels. Conclu-sively, these methods mainly focus on the framework opti-mization or the negative impact of noisy pseudo-labels, of which contributions are orthogonal to ours.
In this paper, we study this semi-supervised methodol-ogy from the perspective of data initialization. More specif-ically, we investigate how to select the optimal labeled ex-amples for teacher-student learning in SSOD. To explain, although a plenty of pseudo-labels are generated for self-training, ground-truth label information still plays a key role in the infant training phase, which determines the qual-ity of pseudo-labels and the performance lower-bound of the teacher networks [24, 35, 50]. Meanwhile, in some teacher-student methods [24,31], the pseudo-labels are only used to optimize the predictions of object categories and foreground-background proposals, while the optimization of bounding boxes regression still relies on the ground-truth annotations. In this case, we observe that ground-truth la-bel information plays an important role in SSOD, which, however, is still left unexplored.
To this end, we propose a new teacher-student method, coined as Active Teacher, for semi-supervised object de-tection. As shown in Fig. 2, Active Teacher extends the conventional teacher-student framework to an iterative one, where the label set is partially initialized and gradually aug-mented via a novel active sampling strategy. With this mod-ification, Active Teacher can maximize the effect of limited label information by active sampling, which can also im-prove the quality of pseudo-labels. We further investigate the selection of labeled examples from the aspects of diffi-culty, information and diversity, and the values of these met-rics are automatically combined without hyper-parameter tunning. Through these metrics, we can explore what kind of data are optimal for SSOD.
To validate the proposed method, we conduct exten-sive experiments on the benchmark dataset, namely MS
COCO [22]2. The experimental results not only con-firm the significant performance gains of Active Teacher against a set of state-of-the-art SSOD methods, e.g., +6.3% and +23.3% compared with Unbiased Teacher [24] and
STAC [35] on 5% MS-COCO, respectively. It also shows that Active Teacher enables the baseline detection network, i.e., Faster-RCNN [29], to achieve 100% supervised perfor-mance with much less labeling expenditure, e.g., with 40% labeled examples on MS-COCO, as shown in Fig. 1. More importantly, we also provide the in-depth analyses for active sampling, which can give useful hints for data annotation in practical applications of object detection. 2More experimental results can be found in our Github project.
In summary, our contribution is two-fold:
• We present the first attempt of studying data initializa-tion in teacher-student based semi-supervised object detection (SSOD), and conduct extensive experiments for different sampling strategies. These quantitative and qualitative analyses can provide useful references for data annotation in practical applications.
• We propose a new teacher-student framework for
SSOD called Active Teacher, which not only out-performs a set of SSOD methods on the benchmark dataset, but also enables the baseline detection network achieve 100% fully supervised performance with much less label expenditure. 2.