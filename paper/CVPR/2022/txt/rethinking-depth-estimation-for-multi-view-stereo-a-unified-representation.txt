Abstract
Depth estimation is solved as a regression or classiﬁca-tion problem in existing learning-based multi-view stereo methods. Although these two representations have recently demonstrated their excellent performance, they still have apparent shortcomings, e.g., regression methods tend to overﬁt due to the indirect learning cost volume, and clas-siﬁcation methods cannot directly infer the exact depth due to its discrete prediction. In this paper, we propose a novel representation, termed Uniﬁcation, to unify the advantages of regression and classiﬁcation. It can directly constrain the cost volume like classiﬁcation methods, but also realize the sub-pixel depth prediction like regression methods. To exca-vate the potential of uniﬁcation, we design a new loss func-tion named Uniﬁed Focal Loss, which is more uniform and reasonable to combat the challenge of sample imbalance.
Combining these two unburdened modules, we present a coarse-to-ﬁne framework, that we call UniMVSNet. The results of ranking ﬁrst on both DTU and Tanks and Temples benchmarks verify that our model not only performs the best but also has the best generalization ability. 1.

Introduction
Multi-view stereo (MVS) is a vital branch to extract ge-ometry from photographs, which takes stereo correspon-dence from multiple images as the main cue to reconstruct dense 3D representations. Although traditional methods
[2, 7, 25, 26] have achieved excellent performance after oc-cupying researchers for decades, more and more learning-based approaches [4, 5, 9, 34–36] are proposed to promote the effectiveness of MVS due to their more powerful repre-sentation capability in low-texture regions, reﬂections, etc.
Concretely, they infer the depth for each view from the 3D cost volume, which is constructed from the warped feature according to a set of predeﬁned depth hypotheses. Com-pared with hand-crafted similarity metrics in traditional methods, the 3D cost volume can capture more discrimina-tive features to achieve more robust matching. Without loss of integrity, existing learning-based methods can be divided into two categories: Regression and Classiﬁcation.
Regression is the most primitive and straightforward im-plementation of the learning-based MVS method.
It’s a group of approaches [5,9,20,34,35,39] to regress the depth from the 3D cost volume through Soft-argmin, which softly weighting each depth hypothesis. More speciﬁcally, the model expects to regress greater weight for the depth hy-pothesis with a small cost. Theoretically, it can achieve the sub-pixel estimation of depth by weighted summation of discrete depth hypotheses. Nevertheless, the model needs to learn a complex combination of weights under indirect constraints performed on the weighted depth but not on the weight combination, which is non-trivial and tends to over-ﬁt. You can imagine that there are many weight combina-tions for a set of depth hypotheses that can be weighted and summed to the same depth, and this ambiguity also implic-itly increases the difﬁculty of the model convergence.
Classiﬁcation is proposed in R-MVSNet [36] to infer the optimal depth hypothesis. Different from the weight es-timation in regression, classiﬁcation methods [10, 33, 36] predict the probability of each depth hypothesis from the 3D cost volume and take the depth hypothesis with the maximum probability as the ﬁnal estimation. Obviously, these methods cannot infer the exact depth directly from the model like regression methods. However, classiﬁca-tion methods directly constrain the cost volume through the cross-entropy loss executed on the regularized probability volume, which is the essence of ensuring the robustness of
MVS. Moreover, the estimated probability distribution can directly reﬂect the conﬁdence, which is difﬁcult to derive from the weight combination intuitively.
In this paper, we seek to unify the advantages of regres-sion and classiﬁcation, that is, we hope that the model can accurately predict the depth while maintaining robustness.
There is a fact that the depth hypothesis close to the ground-truth has more potential knowledge, while that of other re-maining hypotheses is limited or even harmful due to the wrong induction of multimodal [42]. Motivated by this, we present that estimating the weights for all depth hypothe-ses is redundant, and the model only needs to do regres-sion on the optimal depth hypothesis that the representa-tive depth interval (referring to the upper area until the next
Figure 1. Comparison with different representations at a certain pixel. The purple curve represents different weights, probabilities, and unity of each depth hypothesis obtained by regression, classiﬁcation and uniﬁcation respectively. While the regression representation requires the exact weight of each hypothesis to regress the depth, the classiﬁcation representation only cares about which hypothesis has the maximum probability and uniﬁcation only needs to know the proximity with the maximum unity. CE denotes cross-entropy, and U F L refers to Uniﬁed Focal Loss (Sec. 3.3). larger depth hypothesis) contains the ground truth depth. To achieve this, we propose a uniﬁed representation for depth, termed Uniﬁcation. As shown in Fig. 1, unlike regression, the loss is executed on the regularized probability volume directly, and different from classiﬁcation, our method esti-mates the Unity (What we call), whose label is composed by at most one non-zero continuous target (0 ∼ 1), to simulta-neously represent the location of optimal depth hypothesis and its offset to the ground-truth depth. We take proximity (deﬁned as the complement of the offset between ground-truth and optimal depth hypothesis) to characterize the non-zero target in unity label, which is more efﬁcient than purely using offset. The detailed comparisons are in Supp. Mat.
Moreover, we note that this uniﬁed representation faces an undeniable sample imbalance in both category and hard-ness. While Focal Loss (FL) [19] is the common solution proposed in the detection ﬁeld, which is tailored to the tra-ditional discrete label, the more general form (GFL) is pro-posed in [17, 40] to deal with the continuous label. Even though GFL has demonstrated its performance, we hold the belief that it has an obvious limitation in distinguishing hard and easy samples due to ignoring the magnitude of ground-truth. To this end, we put forward a more reasonable and uniﬁed form, called Uniﬁed Focal Loss (UFL), after thor-In this ough analysis to better address these challenges. way, the traditional FL can be regarded as a special case of UFL, while GFL is its imperfect expression.
To demonstrate the superiority of our proposed modules, we present a coarse-to-ﬁne framework termed UniMVSNet (or UniﬁedMVSNet), named for its uniﬁcation of depth representation and focal loss, which replaces the traditional representation of recent works [5,9,34] with Uniﬁcation and adopts UFL for optimization. Extensive experiments show that our model surpasses all previous MVS methods and achieves state-of-the-art performance on both DTU [1] and
Tanks and Temples [14] benchmarks. 2.