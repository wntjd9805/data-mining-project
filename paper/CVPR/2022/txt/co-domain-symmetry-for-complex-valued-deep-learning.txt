Abstract
We study complex-valued scaling as a type of symmetry natural and unique to complex-valued measurements and representations. Deep Complex Networks (DCN) extend real-valued algebra to the complex domain without addressing complex-valued scaling. SurReal extends manifold learning to the complex plane, achieving scaling invariance with manifold distances that discard phase information.
Treating complex-valued scaling as a co-domain trans-formation, we design novel equivariant/invariant layer func-tions and architectures that exploit co-domain symmetry. We also propose novel complex-valued representations of RGB images, where complex-valued scaling indicates hue shift or correlated changes across color channels.
Benchmarked on MSTAR, CIFAR10, CIFAR100, and
SVHN, our co-domain symmetric (CDS) classifiers deliver higher accuracy, better generalization, more robustness to co-domain transformations, and lower model bias and vari-ance than DCN and SurReal with far fewer parameters. 1.

Introduction
Symmetry is one of the most powerful tools in the deep learning repertoire. Naturally occurring symmetries lead to structured variation in natural data. Modeling these symme-tries thus greatly simplifies learning [1], e.g., Convolutional
Neural Networks (CNNs) [2] capture the translational sym-metry of image data, and PointNet [3] captures the permu-tation symmetry of 3D point clouds. These symmetries are formalized as invariance or equivariance to a group of trans-formations [4]. However, this line of research has primarily focused on transformations defined on the domain of an im-age (such as scaling and rotations [5–7]), while co-domain transformations (Fig. 1) such as color shift and complex-valued range scaling remain under-explored. Additionally, this research has primarily focused on real-valued data.
We explore complex-valued data which arise naturally in 1) remote sensing such as synthetic aperture radar (SAR) imaging, medical imaging such as magnetic resonance imag-ing (MRI), and radio frequency communications; 2) spectral representations of real-valued data such as Fourier Trans-Figure 1. We study principled deep learning designs that exploit co-domain symmetry in the range of an image. An image is a function from pixel coordinates in the domain RD to pixel values in the co-domain CK (e.g., (D, K) = (2, 3) for RGB images). Spatial transformations such as scaling and rotations act on the domain, mapping points in RD to other points, while leaving the underlying function values intact. Co-domain transformations such as color distortion or complex-valued scaling, on the other hand, act on the function values only. Rows 2-3 in Column 4 are complex-valued scaled SAR images with magnitudes and phases visualized in the color intensity and hue respectively. form [8, 9]; and 3) physics and engineering applications [10].
In deep learning, complex-valued models have shown several benefits over their real-valued counterparts: larger represen-tational capacity [11], more robust embedding [12] and asso-ciative memory [13], more efficient multi-task learning [14], and higher quality MRI image reconstruction [15]. We ap-proach complex-valued deep learning from a symmetry per-spective: Which symmetries are inherent in complex-valued data, and how do we exploit them in modeling?
One type of symmetry inherent to complex-valued data is complex-valued scaling ambiguity [18]. For example, con-sider a complex-valued MRI or SAR signal z. Due to the nature of signal acquisition, z could be subject to global mag-nitude scaling and phase offset represented by a complex-valued scalar s, thus becoming s z.
A complex-valued classifier takes input z and ideally
·
Complex
Algebra
✗
C-scale
Invariance
✗
✓
✗
✓
✗
✓
✓
Real
DCN
Surreal
Ours (a) Summary of properties (b) Classwise bias and variance (c) Color transformation robustness (d) Model prediction for single ex-ample under C-scaling
Figure 2. Our method combines the strengths of DCN and SurReal, demonstrating better generalization and increased robustness to
C-scaling and color transformations. All examples are from CIFAR 10 with our LAB encoding. (a) Unlike DCN or SurReal, our model handles two aspects essential to complex-valued data: C-scale in-variance and complex algebra. Our key insight is to design novel layer functions that are equivariant and invariant to complex scaling in the rich family of functions with complex algebra. (b) Violin plots of classwise bias/variance computed following the method of [16]. The whiskers represent maximum/median/minimum values respectively. While SurReal has the highest bias and variance, our model achieves the lowest, indicating better generalization. (c)
Accuracy under color jitter (as used in [17]) and complex-scaling with different rotation ranges. Our method maintains high accu-racy across complex-rotations and color jitter, whereas DCN and
Real-valued CNN fail. SurReal [18] is robust, but has low overall accuracy. Our method combines high accuracy with robustness. (d) Model confidence of the correct class for a single example.
Higher confidence means larger radius. DCN predictions are highly variable, while our model is robust to complex-scaling. should focus on discriminating among instances from dif-ferent classes, not on the instance-wise variation s z caused by complex-valued scaling. Formally, function f is called z) = f (z) and called complex-scale invariant if f (s
· f (z). For brevity, z) = s complex-scale equivariant if f (s
· we abbreviate complex-valued scaling as C-scaling.
·
·
We distinguish two types of image transformations, view-ing an image as a function defined over spatial locations.
C-scaling of a complex-valued image is a transformation in the co-domain of the image function, as opposed to a spatial transformation in the domain of the image (Fig. 1). Formally,
I : RD
CK denotes a complex-valued image of K chan-nels in the D-dimensional space, where R (C) denotes the set of real (complex) numbers. Some common (D, K)’s are (2,1) for grayscale images, (2,3) for RGB, and (3, 6+) for diffusion tensor images.
→ 1. Domain transformation T : RD
RD transforms the
→ spatial coordinates of an image, resulting in a spatially
RD denotes the pixel warped image I(T (p)), where p location. Translation, rotation, and scaling are examples of domain transformations.
∈ 2. Co-domain transformation T ′ : CK
CK maps the pixel value to another value, resulting in a color adjusted
RD. C-scaling and color distortions image T ′(I(p)), p are examples of co-domain transformations.
→
∈
C-scaling thus presents not only a practical setting but also a case study for general co-domain transformations.
Existing methods approach complex-valued deep learn-ing in two different ways. 1) Deep Complex Networks (DCN) [19] extends real-valued algebra to the complex do-main without addressing C-scaling; their models are highly sensitive to C-scaling (Figs. 2c and 8a). A pre-processing trick to remove such scaling ambiguity is to simply normal-ize all the pixel values by setting their average phase to 0 and magnitude to 1, but this process introduces artifacts when the phase distribution varies greatly with the content of the im-age (Fig. 8c). 2) SurReal [18] extends manifold-valued deep learning to complex-valued data, achieving C-scaling invari-ance using manifold distances. However, these manifold distances discard rich phase information, and the restrictive
SurReal framework is unable to express complex algebraic operations on complex-valued data. As a result, it underper-forms on large datasets (Tab. 1 and Fig. 2c).
We propose a principled method by designing novel layer functions that preserve co-domain symmetry. Our work makes the following contributions. 1) We develop coun-terparts of common layer functions used in computer vi-sion pipelines that are equivariant and invariant to C-scaling.
Our method circumvents the limitations of SurReal [18] and achieves high accuracy with larger models and datasets. 2) We introduce novel complex-valued encodings of color, demonstrating the utility of using complex-valued repre-sentations for real-valued data. C-scaling invariance under our LAB encoding automatically leads to color distortion robustness without the need for color jitter augmentation. 3) Benchmarked on MSTAR, CIFAR 10, CIFAR 100, and
SVHN, our method outperforms DCN and SurReal with higher accuracy, better generalization, and more robustness using far fewer parameters. 2.