Abstract 6D object pose estimation networks are limited in their capability to scale to large numbers of object instances due to the close-set assumption and their reliance on high-fidelity object CAD models. In this work, we study a new open set problem; the few-shot 6D object poses estimation: estimating the 6D pose of an unknown object by a few sup-port views without extra training. To tackle the problem, we point out the importance of fully exploring the appear-ance and geometric relationship between the given support views and query scene patches and propose a dense pro-totypes matching framework by extracting and matching dense RGBD prototypes with transformers. Moreover, we show that the priors from diverse appearances and shapes are crucial to the generalization capability under the prob-lem setting and thus propose a large-scale RGBD photore-alistic dataset (ShapeNet6D) for network pre-training. A simple and effective online texture blending approach is also introduced to eliminate the domain gap from the syn-thesis dataset, which enriches appearance diversity at a low cost. Finally, we discuss possible solutions to this problem and establish benchmarks on popular datasets to facilitate future research. [project page]
Figure 1. The few-shot 6D pose estimation problem. Given a few RGBD views of a novel objects with pose labels. The few-shot pose estimation network aims to estimate 6D pose of that object in a novel query scene without extra training. No precise CAD models are required as well. 1.

Introduction 6D object pose estimation aims to predict a rigid trans-formation from the object coordinate system to the cam-era coordinate system, which benefits various applica-tions, including robotic manipulation, augmented reality, autonomous driving, etc. The explosive development of deep learning has brought significant improvement to this problem. With recent works [15, 16] reaching nearly 99% recall accuracy on existing benchmarks [18, 22, 58], one may get the impression that the 6D object pose problem has been solved, which is not the case. We argue that the current problem has been simplified with strict restrictions.
They are under the close-set assumption that the training and testing data are drawn from the same object space, which, however, does not adhere to the real dynamic worlds.
Moreover, extravagant high-fidelity CAD models and large-scale datasets are required for training to obtain good per-formance on new objects under the current instance-level pose estimation setting.
The recently proposed category-level pose estimation task [55] loosens the restriction with generalizability to novel objects within the same categories. However, it is still limited in the close-set assumption of predefined categories.
Instead, in this work, we study a new open-set problem, the few-shot 6D object pose estimation: estimating 6D pose of unknown objects by only a few views of the objects without extra training. As shown in Figure 1, in our setting, only a few labeled RGBD images of novel objects are provided, and no high-fidelity CAD models are required. The goal of the problem is to bridge the capability gap between machine learning algorithms and flexible human visual systems that can locate and estimate the pose of a novel object given only several views of it. Besides, it has a wide range of
real-world applications in robotic vision systems, i.e., fast registration of novel objects for robotic manipulation and home robots.
Under the observation that human beings utilize both ap-pearance and geometric information to match and locate a new object, we propose a dense RGBD prototypes match-ing framework to tackle the problem. Specifically, trans-formers are utilized to fully explore the semantic and geo-metric relationship between the query scene patch and the support views of novel objects. Moreover, we point out that large-scale datasets’ diverse shape and appearance priors are essential to empower networks to generalize on novel objects. Therefore, we introduce a large-scale photorealistic dataset (ShapeNet6D) with diverse shapes and appearances for prior learning. To our knowledge, ours (800K images of 12K objects) is the largest and most diverse dataset for 6D pose algorithms. To bridge the domain gap between ren-dered RGB images and real-world scenes, we introduce a simple and effective online texture blending augmentation, which further enriches the appearance diversity and facili-tates network performance at a low cost.
To summarize, the contributions of this work are:
• We introduce a challenging open-set problem, the few-shot 6D object pose estimation, and establish a bench-mark to study it.
• We formulate the problem by dense RGBD proto-types matching and introduce FS6D-DPM, which fully leverage appearance and geometric information to tackle the problem.
• Datasets: We introduce ShapeNet6D, a large-scale photorealistic dataset with diverse shapes and appear-ances for prior learning of few-shot 6D pose estima-tion algorithms. We also introduce an online texture blending augmentation to obtain scenes of texture-rich objects without domain gaps at a low cost. 2.