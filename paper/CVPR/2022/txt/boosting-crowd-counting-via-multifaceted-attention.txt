Abstract
This paper focuses on the challenging crowd counting task. As large-scale variations often exist within crowd images, neither fixed-size convolution kernel of CNN nor fixed-size attention of recent vision transformers can well handle this kind of variations. To address this problem, we propose a Multifaceted Attention Network (MAN) to improve transformer models in local spatial relation en-coding. MAN incorporates global attention from vanilla transformer, learnable local attention, and instance atten-tion into a counting model. Firstly, the local Learn-able Region Attention (LRA) is proposed to assign atten-tion exclusive for each feature location dynamically. Sec-ondly, we design the Local Attention Regularization to supervise the training of LRA by minimizing the devia-tion among the attention for different feature locations.
Finally, we provide an Instance Attention mechanism to focus on the most important instances dynamically dur-ing training. Extensive experiments on four challeng-ing crowd counting datasets namely ShanghaiTech, UCF-QNRF, JHU++, and NWPU have validated the proposed https://github.com/LoraLinH/Boosting-method.
Crowd-Counting-via-Multifaceted-Attention.
Code: 1.

Introduction
Crowd counting plays an essential role in congestion es-timation, video surveillance, and crowd management. Es-pecially after the outbreak of coronavirus disease (COVID-19), real-time crowd detection and counting attract more and more attention.
In recent years, typical counting methods [20, 21, 41, 50] utilize the Convolution Neural Network (CNN) as backbone and regress density map to predict the total crowd count.
However, due to the wide viewing angle of cameras and
*Corresponding author. the 2D perspective projection, large-scale variations often exist in crowd images. Traditional CNNs with fixed-size convolution kernel are difficult to deal with these variations and the counting performance is severely limited. To alle-viate this issue, multi-scale mechanism is designed, such as multi-scale blobs [48], pyramid networks [22], and multi-column networks. These methods introduce an intuitive local-structure inductive bias [43], suggesting that the re-spective field should be adaptive to the size of objects.
Lately, the blossom of Transformer models, which adopt the global self-attention mechanism, has significantly im-proved the performances of various natural language pro-cessing tasks. Nonetheless, it is not until ViT [10] in-troduces patch-dividing as a local-structure inductive bias that transformer models can compete with and even surpass
CNN models in vision tasks. The development of vision transformer suggests that both global self-attention mecha-nism and local inductive bias are important for vision tasks.
The study about transformer based crowd counting is just in its preliminary stage [19, 49] and undergoes major chal-lenges in introducing the local inductive bias to transformer models in crowded scenes. These models usually use fixed-size attention as ViT, which is limited in encoding the 2D local structure as pointed out by [10] and clearly inadequate to handle large-scale variations of crowd images. To solve this problem, in this paper, we improve both the structure and training scheme of vision transformers for crowd count-ing from the following three perspectives.
Firstly, in response to such limitations in local region en-coding, we propose the learnable region attention (LRA) to emphasize the local context. Different from previous vision transformers that adopt fixed patch division schemes, LRA can flexibly determine which local region it should pay at-tention to for each feature location. As a result, the local attention module provides an efficient way of extracting the most relevant local information against the scale changes.
Moreover, it further disengages from the dependence on the position embedding module of ViT, which has been proven
Figure 1. The framework of Multifaceted Attention Network. A crowd image is first fed into CNN. Then the flatten output feature map is transmitted into the transformer encoder with the Learnable Region Attention. Finally, a regression decoder predicts the density map.
Local Attention Regularization and Instance Attention Loss (in lilac boxes) are optimized during the training process. inefficient in encoding local space relations [10].
Secondly, we propose an efficient Local Attention Reg-ularization (LAR) method to regularize the training of the
LRA module. Inspired by the recent finding of human be-haviors [5] that people often allocate similar attention re-sources to objects with similar real sizes regardless of their sizes in 2D images, we require the allocated attention w.r.t. each feature location to be similar. Based on this under-standing, we design LAR to optimize the distribution of lo-cal attention by penalizing the deviation among them. LAR enforces the span of visual attention to be small on crowd area, and vice versa, for balanced and efficient allocations of attention.
Finally, we make an attempt to apply the attention mech-anism to the instance (i.e., the point annotations) level in images and propose the Instance Attention module. As the point annotations as provided in popular crowd benchmarks are spare and can only occupy a very small portion of the en-tire human heads, there are unavoidable annotation errors.
To alleviate this issue, we use Instance Attention to focus on the most important instances dynamically during training.
In summary, we propose a counting model with mul-tifaceted attention, termed as Multifaceted Attention Net-work (MAN), to address large-scale variations in crowd im-ages. The contributions are further summarized as follows:
• We propose the local Learnable Region Attention to allocate an attention region exclusive for each feature location dynamically.
• We design a local region attention regularization method to supervise the training of LRA.
• We introduce an effective instance attention mecha-nism to select the most important instances dynami-cally during training.
• We perform extensive experiments on popular datasets including ShanghaiTech, UCF-QNRF, JHU++, and
NWPU, and show that the proposed method makes a solid advance in counting performance. 2.