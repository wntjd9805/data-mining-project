Abstract
Current few-shot action recognition methods reach im-pressive performance by learning discriminative features for each video via episodic training and designing various temporal alignment strategies. Nevertheless, they are lim-ited in that (a) learning individual features without consid-ering the entire task may lose the most relevant informa-tion in the current episode, and (b) these alignment strate-gies may fail in misaligned instances. To overcome the two limitations, we propose a novel Hybrid Relation guided
Set Matching (HyRSM) approach that incorporates two key components: hybrid relation module and set matching met-ric. The purpose of the hybrid relation module is to learn task-specific embeddings by fully exploiting associated re-lations within and cross videos in an episode. Built upon the task-specific features, we reformulate distance measure be-tween query and support videos as a set matching problem and further design a bidirectional Mean Hausdorff Metric to improve the resilience to misaligned instances. By this means, the proposed HyRSM can be highly informative and flexible to predict query categories under the few-shot set-tings. We evaluate HyRSM on six challenging benchmarks, and the experimental results show its superiority over the state-of-the-art methods by a convincing margin. Project page: https://hyrsm-cvpr2022.github.io/. 1.

Introduction
Action recognition has been witnessing remarkable progress with the evolution of large-scale datasets [5, 9, 18] and video models [14, 32, 52]. However, this success heav-ily relies on a large amount of manually labeled examples, which are labor-intensive and time-consuming to collect. It actually limits further applications of this task. Few-shot action recognition is promising in reducing manual annota-âˆ— Corresponding authors.
Figure 1. (a) The proposed hybrid relation module. We enhance video representations by extracting relevant discriminative pat-terns cross videos in an episode, which can adaptively learn task-specific embeddings. (b) Example of make coffee, the current tem-poral alignment metrics tend to be strict, resulting in an incorrect match on misaligned videos. In contrast, the proposed set match-ing metric is more flexible in finding the best correspondences. tions and thus has attracted much attention recently [58,63].
It aims at learning to classify unseen action classes with ex-tremely few annotated examples.
To address the few-shot action recognition problem, cur-rent attempts [4, 40, 59, 63] mainly adopt a metric-based meta-learning framework [45] for its simplicity and effec-tiveness. It first learns a deep embedding space and then designs an explicit or implicit alignment metric to cal-culate the distances between the query (test) videos and support (reference) videos for classification in an episodic task. For instance, Ordered Temporal Alignment Module (OTAM) [4] extracts features for each video independently and tries to find potential query-support frame pairs only along the ordered temporal alignment path in this feature space. Despite remarkable performance has been reached,
these methods still suffer from two drawbacks. First, dis-criminative interactive clues cross videos in an episode are ignored when each video is considered independently dur-ing representation learning. As a result, these methods ac-tually assume the learned representations are equally ef-fective on different episodic tasks and maintain a fixed set of video features for all test-time tasks, i.e., task-agnostic, which hence might overlook the most discriminative dimen-sions for the current task. Existing work also shows that the task-agnostic methods tend to suffer inferior general-ization in other fields, such as image recognition [29, 56],
NLP [35, 38], and information retrieval [33]. Second, ac-tions are usually complicated and involve many subactions with different orders and offsets, which may cause the fail-ure of existing temporal alignment metrics. For example, as shown in Figure 1(b), to make coffee, you can pour wa-ter before pour coffee powder, or in a reverse order, hence it is hard for recent temporal alignment strategies to find the right correspondences. Thus a more flexible metric is required to cope with the misalignment.
Inspired by the above observations, we thus propose a novel Hybrid Relation guided Set Matching (HyRSM) al-gorithm that consists of a hybrid relation module and a set matching metric.
In the hybrid relation module, we ar-gue that the considerable relevant relations within and cross videos are beneficial to generate a set of customized fea-tures that are discriminative for a given task. To this end, we first apply an intra-relation function to strengthen structural patterns within a video via modeling long-range temporal dependencies. Then an inter-relation function operates on different videos to extract rich semantic information to rein-force the features which are more relevant to query predic-tions, as shown in Figure 1(a). By this means, we can learn task-specific embeddings for the few-shot task. On top of the hybrid relation module, we design a novel bidirectional
Mean Hausdorff Metric to calculate the distances between query and support videos from the set matching perspec-tive. Concretely, we treat each video as a set of frames and alleviate the strictly ordered constraints to acquire bet-ter query-support correspondences, as shown in Figure 1(b).
In this way, by combining the two components, the pro-posed HyRSM can sufficiently integrate semantically re-lational representations within the entire task and provide flexible video matching in an end-to-end manner. We eval-uate the proposed HyRSM on six challenging benchmarks and achieve remarkable improvements again current state-of-the-art methods.
Summarily, we make the following three contributions: 1) We propose a novel hybrid relation module to capture the intra- and inter-relations inside the episodic task, yielding task-specific representations for different tasks. 2) We fur-ther reformulate the query-support video pair distance met-ric as a set matching problem and develop a bidirectional
Mean Hausdorff Metric, which can be robust to complex ac-tions. 3) We conduct extensive experiments on six challeng-ing datasets to verify that the proposed HyRSM achieves superior performance over the state-of-the-art methods. 2.