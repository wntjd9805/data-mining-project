Abstract
We introduce the dynamic grasp synthesis task: given an object with a known 6D pose and a grasp reference, our goal is to generate motions that move the object to a target 6D pose. This is challenging, because it requires reasoning about the complex articulation of the human hand and the intricate physical interaction with the object. We propose a novel method that frames this problem in the reinforcement learning framework and leverages a physics simulation, both to learn and to evaluate such dynamic interactions.
A hierarchical approach decomposes the task into low-level grasping and high-level motion synthesis. It can be used to generate novel hand sequences that approach, grasp, and move an object to a desired location, while retaining human-likeness. We show that our approach leads to stable grasps and generates a wide range of motions. Further-more, even imperfect labels can be corrected by our method to generate dynamic interaction sequences. Video and code are available at: https://eth-ait.github.io/d-grasp/. 1.

Introduction
A key problem in computer vision is to understand how humans interact with their surroundings. Because hands are our primary means of manipulation with the physical world, there has been an intense interest in hand-object pose estimation [5, 13–15, 19, 38, 39] and the synthesis of static grasps for a given object [19, 21, 24, 38]. However, human grasping is not limited to a single time instance, but involves a continuous interaction with objects in order to move them.
It requires maintaining a stable grasp throughout the inter-action, introducing intricate dynamics to the task. This in-volves reasoning about the complex physical interactions between the dexterous hand and the manipulated object, including collisions, friction, and dynamics. A generative model that can synthesize realistic and physically plausi-ble object manipulation sequences would have many down-stream applications in AR/VR, robotics and HCI.
†Corresponding author
We propose the new task of dynamic grasp synthesis.
Given an object with a known 6D pose and a static grasp reference, our goal is to generate a grasping motion and to move the object to a target 6D pose in a natural and physically-plausible way. This new setting adds several challenges. First, the object geometry and the spatial con-ﬁguration of the object and the hand need to be considered in continuous interaction. Second, contacts between the hand and object are crucial in maintaining stability of the grasps, where even a small error in hand pose may lead to an object slipping. Moreover, contact is typically unobserv-able in images [10] and measuring the stability of a grasp is very challenging in a static setting. Finally, synthesizing se-quences of hand motion requires the generation of smooth and plausible trajectories. While prior work investigates the control of dexterous hands by learning from full demonstra-tion trajectories [11, 32], we address the generation of hand motion from only a single-frame grasp reference. This is a more challenging setting, because the generation of human-like hand-object interaction trajectories without dense su-pervision is not straightforward.
Taking a step towards this goal, we propose D-Grasp, which generates physically plausible grasping motions with only a single grasp reference as input (Fig. 1). Concretely, we formulate the dynamic grasp synthesis task as a re-inforcement learning (RL) problem and propose a policy learning approach that leverages a physics simulation. Our
RL-based approach considers the underlying physical phe-nomena and compensates data scarcity via exploration in the physics simulation. This ensures physical plausibility, e.g., there is no hand-object interpenetration and the ﬁngers exert enough force on the object to hold it without slipping.
Speciﬁcally, we introduce a hierarchical framework that consists of a low-level grasping policy and a high-level mo-tion synthesis module. The grasping policy’s purpose is to establish and maintain a stable grasp, whereas the mo-tion synthesis module generates a motion to move the ob-ject to a user-speciﬁed target position. To guide the low-level grasping policy, we require a single grasp label corre-sponding to a static hand pose, which can be obtained either from a hand-grasping dataset [5,13], a state-of-the-art grasp synthesis method [19] or via an image-based pose estima-tor [12]. Crucially, we propose a reward function that is parameterized by the grasp label to incentivize the ﬁngers to reach contact points on the object, leading to human-like grasps. Our high-level motion synthesis module generates motions that move the hand and object to the ﬁnal target pose. Importantly, the low-level policy continually controls the grasp to not drop the object.
In our experiments, we ﬁrst demonstrate that samples from motion capture, static grasp synthesis or image-based pose estimates often do not lead to stable grasps when eval-uated in a physics simulation (Fig. 4). We then present how our method can learn to produce physically plausible and stable grasps when guided by such labels. Next, we set out to generate motions with the object in-hand to reach a wide range of target poses. We provide an extensive ablation, re-vealing the importance of the hierarchical approach and the reward formulation for dynamic grasp synthesis.
Our contributions can be summarized as follows: i) We introduce the new task of dynamic grasp synthesis. ii)
We propose D-Grasp, an RL-based method to synthesize physically-plausible and natural hand-object interactions. iii) We show that our method can generate grasp motions with static grasp references, which can originate from mo-tion capture, static grasp synthesis or image-based pose es-timation . We will release our code for research purposes. 2.