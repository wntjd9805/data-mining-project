Abstract
Rain removal aims to remove rain streaks from im-ages/videos and reduce the disruptive effects caused by rain. It not only enhances image/video visibility but also allows many computer vision algorithms to function prop-erly. This paper makes the first attempt to conduct a com-prehensive study on the robustness of deep learning-based rain removal methods against adversarial attacks. Our study shows that, when the image/video is highly degraded, rain removal methods are more vulnerable to the adversar-ial attacks as small distortions/perturbations become less noticeable or detectable. In this paper, we first present a comprehensive empirical evaluation of various methods at different levels of attacks and with various losses/targets to generate the perturbations from the perspective of hu-man perception and machine analysis tasks. A system-atic evaluation of key modules in existing methods is per-formed in terms of their robustness against adversarial at-tacks. From the insights of our analysis, we construct a more robust deraining method by integrating these effec-tive modules. Finally, we examine various types of adver-sarial attacks that are specific to deraining problems and their effects on both human and machine vision tasks, in-cluding 1) rain region attacks, adding perturbations only in the rain regions to make the perturbations in the at-tacked rain images less visible; 2) object-sensitive attacks, adding perturbations only in regions near the given objects.
Code is available at https://github.com/yuyi-sd/Robust_Rain_Removal. 1.

Introduction
Rain removal methods aim to remove the disruptive ef-fects caused by rain streaks to restore a clean version of the image. It not only largely improves the visibility of the rainy image but can also improve the performance of many
*Corresponding author.
Figure 1. Left is from corresponding patch of clean input/output, and right is from adversarial input/output with perturbation bound
ϵ = 4/255. The semantic segmentation overlap of output is shown in the last column. The testing image is from RainCityscape [13]. subsequent (downstream) computer vision applications.
Early approaches are mainly model-driven and address the deraining problem based on the statistical properties of rain streaks and background scenes, e.g. image decom-position [17], sparse coding [27], and Gaussian mixture model [26]. These methods can well handle light rain.
However, they fall short in cases of handle heavy rain and often blur the background scenes. Recently, deep-learning based deraining methods [9, 41] have become the main-stream. These methods have the capacity to model more complicated mappings from rain images to clean images and offer a better performance in terms of less remaining rain streaks and better preserved background scene. They also enhanced the performance of practical applications such as video surveillance.
While many deep learning-based deraining methods have been introduced, it isn’t a thorough study on the ro-bustness of these methods against adversarial attacks.
It is also a real concern of deraining methods that some un-noticeable perturbations can alter the predicted results of deep networks [12, 31]. As the rainy images can be usu-ally highly degraded by intensive rain streaks, perturbations can be easily and noticeably hidden in such images. These adversarially generated outputs can also compromise the re-liability and stability of the subsequent applications such as video surveillance and autonomous driving, that adopt rain removal methods as a pre-processing module.
In this paper, we make the first attempt to investigate, improve, and evaluate the robustness of deep learning-based rain removal methods against adversarial attacks. Our main contributions are summarized below.
• A thorough analysis of existing deraining methods at different levels of robustness against adversarial at-tacks and with various losses/targets to generate the perturbations, from both the perspectives of human and machine vision tasks.
• A systematic evaluation of the modules in existing methods at both the model side (recurrence, attention, receptive field, and side information) and loss side (ad-versarial loss) in terms of their impact on robustness.
• A more robust deraining method constructed by inte-grating the effective modules which are identified from our analysis.
• Investigation of various adversarial attack types and scenarios specific to rain removal degradation in terms of both human and machine vision tasks. 2.