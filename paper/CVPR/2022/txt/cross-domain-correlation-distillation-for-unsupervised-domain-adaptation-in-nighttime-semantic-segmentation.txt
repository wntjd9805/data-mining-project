Abstract
The performance of nighttime semantic segmentation is restricted by the poor illumination and a lack of pixel-wise annotation, which severely limit its application in au-tonomous driving. Existing works, e.g., using the twilight as the intermediate target domain to perform the adapta-tion from daytime to nighttime, may fail to cope with the inherent difference between datasets caused by the camera equipment and the urban style. Faced with these two types of domain shifts, i.e., the illumination and the inherent dif-ference of the datasets, we propose a novel domain adap-tation framework via cross-domain correlation distillation, called CCDistill. The invariance of illumination or inher-ent difference between two images is fully explored so as to make up for the lack of labels for nighttime images. Specifi-cally, we extract the content and style knowledge contained in features, calculate the degree of inherent or illumination difference between two images. The domain adaptation is achieved using the invariance of the same kind of difference.
Extensive experiments on Dark Zurich and ACDC demon-strate that CCDistill achieves the state-of-the-art perfor-mance for nighttime semantic segmentation. Notably, our method is a one-stage domain adaptation network which can avoid affecting the inference time. Our implementa-tion is available at https://github.com/ghuan99/
CCDistill. 1.

Introduction
Semantic segmentation as one of the fundamental top-ics in computer vision, has been widely used in many crit-ical downstream tasks [4, 12]. While a large variety of approaches have been proposed [2, 30], they are predomi-nantly designed to train on daytime images with favorable illumination. However, outdoor applications require satis-factory performance in more challenging scenes, such as
*Corresponding author
Figure 1. Every two embeddings connected by the dotted line come from two domains, and they only have one difference in illu-minance (i.e., each column) or dataset (i.e., each row). The cross-domain correlation reflects the similarity of the two domains, and can also be considered as a concrete representation of the domain shift. Here we only illustrate the cross-domain style distillation.
Our main idea is to make the different cross-domain correlations under the same domain shift consistent. nighttime. In this work, we focus on semantic segmentation at nighttime, which is primarily limited by the low exposure of the captured images and the lack of ground truth.
To handle this problem, many domain adaptation meth-ods have been proposed to adapt the daytime-trained model to nighttime without requiring ground-truth labels in the nighttime domain.
In [34–36, 38, 48], they apply an im-age transfer network to stylize daytime or nighttime images and generate synthetic datasets. However, the style trans-fer network cannot fully utilize the semantic embedding of the segmentation task and also increases the inference time.
Some works [7, 35, 36] utilize the twilight as the intermedi-ate target domain. These methods require additional train-ing data and the training process is complex. Most impor-tantly, all these methods ignore inherent difference between datasets, treating daytime images from different datasets as the same style. Prior work [13] points out that appearance discrepancy has a significant impact on the effect of adap-tation. Ignoring the inherent difference can adversely affect
domain adaptation.
Considering the illumination and inherent difference be-tween labeled daytime images and unlabeled nighttime im-ages, we intend to construct an end-to-end multi-source multi-target domain adaptation framework for nighttime se-mantic segmentation (shown in Fig. 1). The Dark Zurich
[35] containing unlabeled daytime (Td) and nighttime (Tn) image pairs and Cityscapes [6] containing labeled daytime images (Sd) are adopted as our datasets. It can be seen from
Fig. 1, that Td and Tn are taken at different times in the close scene, thus there is the huge difference of illumination but highly overlapped semantic information. Although Sd and
Td are both daytime images, there are obvious differences in the urban style and color tone. We treat the difference in illumination and dataset as the domain shift.
There is a wide literature on knowledge distillation works [9, 20, 24, 39, 44, 51] that have explored the cross-modal learning. One of strategies in these methods is to ex-ploit the semantic consistency of images across domains as prior knowledge [39,44]. However, most of them [9,22,39] focus on one teacher and one student. As illustrated in
Fig. 1, we observe that if we can get the Sn with content of Sd and illumination style of Tn, the degree of difference in content between Sd and Td should be consistent with that between Sn and Tn. Similarly, the degree of difference in il-lumination or content between Sd and Sn is consistent with that between Td and Tn. Therefore, we can leverage the in-variance of domain shifts as prior knowledge to implement knowledge distillation in multi-source multi-target domain.
With this insight, we propose a cross-domain correlation distillation approach, which is implemented on the content and style knowledge contained in the feature. The degree of cross-domain difference is obtained by the similarity of two content or style embeddings with only one domain shift, and it can also be regarded as a concrete representation of the domain shift. The cross-domain content correlation is utilized to realize the knowledge distillation from the la-beled daytime to the unlabeled nighttime domain, so as to improve the performance of the nighttime semantic seg-mentation. The premise for the effectiveness of the cross-domain content distillation is that the generated and real nighttime images tend to be as consistent as possible in style. Therefore, we first employ a simple image transla-tion method [13] to align holistic distribution on LAB color space to initially reduce the style discrepancy between day and night. And the cross-domain style distillation can fur-ther achieve the style transfer at the semantic-level.
Different from reducing the illumination shift adopted by previous works, it is possible to obtain accurate features of nighttime images by exploiting the consistency of domain shift. We evaluate the performance of CCDistill on Dark
Zurich [35], ACDC [37] datasets. Our main contributions are summarized as follows:
• For nighttime semantic segmentation, we propose an end-to-end unsupervised domain adaptation framework,
CCDistill, which requires neither extra data nor style transfer network, thus it does not affect the inference time of the semantic segmentation network.
• We propose the cross-domain correlation distillation al-gorithm, which utilizes the invariance of domain shifts to perform knowledge distillation on content and style em-beddings separately. It enables knowledge distillation to be free from the adverse effect caused by the complex do-main shifts.
• Extensive experiments on the Dark Zurich and ACDC datasets verify that our network achieves a new state-of-the-art performance of nighttime semantic segmentation. 2.