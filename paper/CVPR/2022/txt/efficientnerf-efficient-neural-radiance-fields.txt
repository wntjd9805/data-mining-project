Abstract
Neural Radiance Fields (NeRF) has been wildly applied to various tasks for its high-quality representation of 3D scenes. It takes long per-scene training time and per-image
In this paper, we present EfﬁcientNeRF as testing time. an efﬁcient NeRF-based method to represent 3D scene and synthesize novel-view images. Although several ways exist to accelerate the training or testing process, it is still dif-ﬁcult to much reduce time for both phases simultaneously.
We analyze the density and weight distribution of the sam-pled points then propose valid and pivotal sampling at the coarse and ﬁne stage, respectively, to signiﬁcantly improve
In addition, we design a novel data sampling efﬁciency. structure to cache the whole scene during testing to accel-erate the rendering speed. Overall, our method can reduce over 88% of training time, reach rendering speed of over 200 FPS, while still achieving competitive accuracy. Ex-periments prove that our method promotes the practical-ity of NeRF in the real world and enables many applica-tions. The code is available in https://github.com/dvlab-research/EfﬁcientNeRF. 1.

Introduction
Novel View Synthesis (NVS) aims to generate images at new views, given multiple camera-calibrated images. It is an effective line for realizing Visual or Augmented Real-ity. With Neural Radiance Fields (NeRF) [17] proposed,
NVS tasks [20, 24], like large-scale or dynamic synthe-sis [21, 22, 25], were successfully dealt with in high quality.
NeRF adopts implicit functions to directly map 3D-point spatial information, in terms of locations and directions, to the attributes of color and densities. To synthesize high-resolution images, NeRF needs to densely sample points over the whole scene, which consumes far more computa-tion than traditional solutions [14, 16, 29]. For instance, for a scene containing 100 images with resolution 800 × 800,
NeRF training time usually takes 1-2 days [17], and the per-image testing time is around 30 seconds. These two inefﬁ-ciencies impede the fast practical applications of NeRF.
Figure 1. Training and testing efﬁciency on realistic synthetic dataset [17] on a single GPU. Our EfﬁcientNeRF much improves efﬁciency in both training and testing phases.
Recently, methods [2, 4, 12, 18, 32, 35] were proposed to accelerate either the training process or the testing phase.
On the one hand, during testing, NSVF [12] and DON-eRF [18] decrease the number of samples by their gener-ated sparse voxels or predicted depth. FastNeRF [4] and
PlenOctree [35] discretely cache the target scene and syn-thesize novel-view images by fast query. Although these methods successfully reduce the per-image inference time, their training time is equivalent or even longer, as illustrated in Fig. 1.
On the other hand, during training, methods of [2,32,36] combine NeRF with image features extracted from ResNet
[7] or MVSNet [34] to construct a generalized model, thus achieving fast training. Nevertheless, as the image prior comes from limited neighboring views, the synthesis accu-racy tends to be lower than NeRF [2, 32]. Besides, obtain-ing features from multi-view images takes more time during testing. There is no work yet to signiﬁcantly shorten both training and testing time simultaneously.
In this paper, we present the Efﬁcient Neural Radiance
Fields (EfﬁcientNeRF) as the ﬁrst attempt to accelerate both per-scene training and per-image testing. Apart from ob-taining competitive accuracy, the training time can be re-duced by more than 88%, and the rendering speed is accel-erated to over 200 FPS, as illustrated in Fig. 1.
The pipeline of original NeRF [17] consists of the coarse and ﬁne stages. During training, the coarse stage obtains the density distribution over the whole scene. It uniformly and densely samples points and calculates corresponding densi-ties by a coarse MLP. However, as will be shown in Table 1, for common scenes with uniformly sampling, there are only around 10% - 20% of valid samples (in Eq. (5)) – 5%
- 10% are pivotal samples (in Eq. (12)).
Also, since each point’s density is shared by all rays, it is possible to memorize the global density by Voxels.
Although NSVF [12] also marks this fact, its solution is to gradually delete invalid voxels, which may cause ad-verse effects when removal is wrong. Differently, we pro-pose Valid Sampling, which maintains dense voxels and up-dates density in an online way with momentum. The coarse
MLP only infers valid samples whose queried densities are greater than zeros, thus saving most of the time at the coarse stage.
For the ﬁne stage, the original NeRF samples more points following previous coarse density distribution. We
ﬁnd that many rays even do not contain any valid and pivotal points because of the empty background. We instead pro-pose Pivotal Sampling for the ﬁne stage that focuses on the nearby area of pivotal samples to efﬁciently sample points.
Our strategy substantially decreases the number of sampled points while achieving comparable accuracy.
During testing, inspired by [35] and [4] that replace MLP modules by caching the whole scene in voxels, we design a novel tree-based data structure, i.e. NerfTree, to more efﬁ-ciently represent 3D scenes. Our NerfTree only has 2 layers.
The ﬁrst layer represents the coarse dense voxels extracted from the coarse MLP, and the second layer stores the ﬁne sparse voxels obtained from the ﬁne MLP. The combination of our dense and sparse voxels leads to fast inference speed.
Our main contributions are the following. 1. We propose EfﬁcientNeRF, the ﬁrst work to signiﬁ-cantly accelerate both training and testing of NeRF-based methods while maintaining reasonable accuracy. 2. We propose Valid Sampling, which constructs dy-namic Voxels to accelerate the sampling process at the coarse stage. Also, we propose Pivotal Sampling to ac-celerate the ﬁne stage. They in total reduce over 88% of computation and training time. 3. We design a simple and yet efﬁcient data structure, called NerfTree, for NeRF-based methods. It quickly caches and queries 3D scenes, thus improving the ren-dering speed by 4, 000+ times. 2.