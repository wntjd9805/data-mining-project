Abstract
The rise of deep neural networks has led to several break-throughs for semantic segmentation. In spite of this, a model trained on source domain often fails to work properly in new challenging domains, that is directly concerned with the gen-eralization capability of the model. In this paper, we present a novel memory-guided domain generalization method for semantic segmentation based on meta-learning framework.
Especially, our method abstracts the conceptual knowledge of semantic classes into categorical memory which is con-stant beyond the domains. Upon the meta-learning concept, we repeatedly train memory-guided networks and simulate virtual test to 1) learn how to memorize a domain-agnostic and distinct information of classes and 2) offer an externally settled memory as a class-guidance to reduce the ambiguity of representation in the test data of arbitrary unseen domain.
To this end, we also propose memory divergence and feature cohesion losses, which encourage to learn memory reading and update processes for category-aware domain general-ization. Extensive experiments for semantic segmentation demonstrate the superior generalization capability of our method over state-of-the-art works on various benchmarks.1 1.

Introduction
Semantic segmentation, assigning a semantic class label to each pixel, is a classical research topic for visual under-standing in computer vision. The recent tremendous progress in semantic segmentation has been dominated by deep neu-ral networks trained on large amounts of densly annotated datasets. Despite its success, models trained with a given dataset (source) do not generalize well in a new domain (target) that the models have not seen during training. Over-coming the domain shift issue caused by the different data distributions of two domains is crucial to deal with unex-*Corresponding authors.
This research was supported by the National Research Founda-tion of Korea (NRF) grant funded by the Korea government (MSIP) (NRF2021R1A2C2006703), the Yonsei University Research Fund of 2021 (2021-22-0001), and the Mid-Career Researcher Program through the NRF of Korea (NRF-2021R1A2C2011624). 1https://github.com/Genie-Kim/PintheMemory
Figure 1. The illustration of our memory-guided meta-learning algorithm for domain generalization. Our method learns how to memorize domain-agnostic categorical knowledge that can provide an external guide to the test data in unseen target domain. pected and unseen data, especially for replacing human tasks such as medical diagnosing or autonomous driving.
In order to mitigate severe performance degradation from the domain shift [4, 20], unsupervised domain adaptation (UDA) approaches [16, 41, 56] have been proposed to bridge the domain gap using unlabelled images of the target domain.
These methods have introduced inventive learning strategies to learn domain invariant features [21, 28, 65, 66, 73, 76] or align source and target domain to unified space [22, 24, 51, 69, 70]. Though they have shown impressive results against domain shift, collecting data from the target domain is of-ten impractical. Moreover, the scalability of the model is restricted as UDA requires network re-training or fine-tuning for the new target domain, thereby exposing limitations in terms of being able to generalize to ‘any’ unseen domains.
To overcome those limitations, domain generalization (DG) methods have been developed to learn robust models against variants of data distribution across arbitrary unseen domains [7, 29, 35, 37, 58, 77]. It is much harder than UDA in that no target domain data is available during training. Some
methods heuristically define domain-biased information as style (e.g., texture, color) to explicitly augment it [27, 63], or erase style through instance normalization [46] and channel covariance whitening [13]. Despite their efforts, existing methods still show limited performance for use in real-world applications. But, it is natural that human visual system adapts stably even when facing scenes that they have never seen before. Where does this difference in generalization ability between humans and machines come from?
We argue that there is an important missing piece in this puzzle. The conceptual knowledge of humans [5], also known as semantic memory, is abstracted from actual expe-riences in the reusable form and is generalized to support a variety of cognitive activities such as event reconstruc-tion [30, 31] and object recognition [53]. Inspired by this, we consider that human’s knowledge concept can be effec-tively utilized in domain generalization by remembering the shared information of each class. For example, the style of the car may vary depending on the domain, but the basic features to configure the car (e.g. wheel, door, bumper, head-light) remain unchanged. Namely, the guidance of such prior knowledge about concurrent features can help to improve the generalization capability of machines.
In this work, we propose a novel memory-guided meta-learning framework to capture and memorize co-occurrent categorical knowledge between objects of the same class across domains. The objective of this framework is to as-sign shared information of each class into external memory slots and reuse the categorical concept for robust semantic segmentation in arbitrary unseen domains. To this end, we split source domain data into meta-training and meta-testing sets to explicitly mimic domain shift in the inference, allow-ing the network to store and invoke memory corresponding to domain-agnostic prototypes of class patterns, as shown in Fig. 1. That is, our method enables category-aware gen-eralization for semantic segmentation, unlike previous DG approaches [13, 46, 63] that only concentrate on globally inferring domain-agnostic representations. Moreover, we in-troduce a memory divergence loss and a feature cohesion loss which boost discriminative power of memory and make more domain-invariant representations from the encoder, respectively. Consequently, our method achieves superior performance gain over existing DG approaches on multi-ple unseen real-world benchmarks. Without re-training or fine-tuning, our results are even on par with the multi-source
UDA methods [22, 68–70], where the training images are given from both source and target domains.
In summary, our key contributions are as follows: (i) We present a novel approach to domain generalization for seman-tic segmentation with memory module to exploit domain-agnostic categorical knowledge of classes. (ii) We introduce the memory-guided meta-learning algorithm that improves the representation power of the memory-guided feature by exposing the model to mismatched data distribution. (iii) We propose two complementary losses, including memory diver-gence loss and feature cohesion loss, that promote power for an embedded feature to find the apposite class memory. (iv)
Extensive experiments prove the significance of category-aware generalization on both single- or multi-source settings. 2.