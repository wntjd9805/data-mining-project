Abstract
This paper aims to leverage symbolic knowledge to im-prove the performance and interpretability of the Visual Re-lationship Detection (VRD) models. Existing VRD meth-ods based on deep learning suffer from the problems of poor performance on insufficient labeled examples and lack of interpretability. To overcome the aforementioned weak-nesses, we integrate symbolic knowledge into deep learn-ing models and propose a bi-level probabilistic graphical reasoning framework called BPGR. Specifically, in the high-level structure, we take the objects and relationships de-tected by the VRD model as hidden variables (reasoning results); In the low-level structure of BPGR, we use Markov
Logic Networks (MLNs) to project First-Order Logic (FOL) as observed variables (symbolic knowledge) to correct er-ror reasoning results. We adopt a variational EM algorithm for optimization. Experiments results show that our BPGR improves the performance of the VRD models. In particu-lar, BPGR can also provide easy-to-understand insights for reasoning results to show interpretability. 1.

Introduction
The goal of Visual Relationship Detection(VRD) is to detect objects as well as their relationships with each other, representing as (subject, predicate, object) triplet. As shown Fig. 1 (a), a triplet is (person, hold, horse). As a foundation visual recognition task, VRD can benefit a wide range of high level image understanding tasks, such as scene graph generation [38, 43], image captioning [15, 17], and visual question answering [3, 4], etc. Consequently,
VRD has emerged as an important research topic in the past few years. Most recent methods based on deep learn-‡Corresponding author.
Figure 1. An example for visual relationship detection and statis-tic of datasets. (a) Different colored blocks with a line connecting subject and object mean different relationships. It is detected three triples (person, has, hat), (person, wear, shirt), and (person, hold, horse) in the image. (b)VRD and VG200 are long-tail dis-tribution. The horizontal axis represents the number of relation-ships, and the vertical axis represents the number of instances of the relationship. ing have been proposed, including LS-VRU [46] and GPS-Net [21], UVTransE [13], etc. However, these methods mainly rely on language prior (semantic information) of en-tities to help relationship detection, which suffers several limitations. First, these approaches need a lot of labeled ex-amples to get decent performance, which goes against the characteristics of the dataset in Fig. 1 (b). Second, they are black boxes, lacking interpretability which is very impor-tant for many applications. An expected solution is neural-symbolic systems, which combines the excellent perceptual ability of neural networks and the cognitive ability of sym-bolic systems [41].
Recently some studies attempted to explore combining symbolic knowledge with the VRD models to enforce the performance of detection. LENSR [37] uses Conjunctive
Normal Form (CNF) [8] or decision-Deterministic Decom-posable Negation Normal Form (d-DNNF) [9] formulae to construct a graph for each propositional logic and adopts
graph neural network to encode them to models. DASL [33] encodes logic rules into the structure of the deep learning model for training. While these methods generally enrich the flexibility compared to the pure deep learning methods, they still have unnoticeable deficiencies. First, it is only capturing local information in LENSR, i.e., they construct an independent graph for each propositional logic and only encode interaction information between nodes in a proposi-tional logic. Second, it is an implicit reasoning process in
DASL. i.e., DASL encodes First-Order Logic as the neural network structure, and then the neural network will com-plete the next work.
To offset the above deficiencies, we adopt Markov Logic
Networks (MLNs) [31] to represent First-Order Logic (FOL) and combine logic with the deep model in a prob-abilistic graphical model. MLN can build a global depen-dency graph for all FOLs and attain a joint probability dis-tribution for all ground atoms. Furthermore, MLNs can be used as a general framework for joining logical AI and sta-tistical AI, and can capture uncertainty. The probabilistic graphical model solves the model by way of probabilistic inference, reflecting an explicit reasoning process.
Therefore, we propose a bi-level probabilistic graphical reasoning framework (BPGR) to encode symbolic knowl-edge into the VRD model. BPGR includes two parts: the vi-sual reasoning module and the symbolic reasoning module.
The visual reasoning module extracts features of objects in images and reasons objects and relationships. The symbolic reasoning module uses symbolic knowledge to guide the reasoning of the visual reasoning module towards a good direction, which acts as an error correction. Specifically, the symbolic reasoning module is a double layer proba-bilistic graph and contains two types of nodes: one is the reasoning result of the VRD model (the visual reasoning module) in the high-level structure, and the other is ground atoms of logic rules in the low-level structure. When the probabilistic graphical model is constructed, the model can be trained efficiently end-to-end in the variational expecta-tion–maximization (EM) framework. In particular, BPGR achieves superior performance on visual relationship detec-tion dataset [23] and the scene graph dataset [38] and is also shown interpretable for reasoning results. An overall frame-work of our method is given in Fig. 2.
Our contributions can be summarized in threefold:
• We propose bi-level probabilistic graphical reason-ing (BPGR) framework which is a novel VRD model based on neural-symbolic systems to improve the de-tection performance and provide interpretability of re-sults. Our BPGR uses symbolic knowledge to guide the model towards improved performance and rectifies error reasoning results.
• We present a joint framework for modeling symbolic knowledge and VRD models. Our framework can capture global symbolic knowledge in logic rules and maintain an explicit reasoning process than existing neural-symbolic methods because it applies Markov
Logic Network (MLN) as knowledge representation and integrates by way of probabilistic inference.
• Experimental results show that BPGR performs better on two datasets of visual relationship detection, com-pared to state-of-the-art methods. We provide visual-ized results to show efficacy and interpretability. 2.