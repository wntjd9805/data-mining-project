Abstract
Point cloud scene flow estimation is of practical impor-tance for dynamic scene navigation in autonomous driving.
Since scene flow labels are hard to obtain, current meth-ods train their models on synthetic data and transfer them to real scenes. However, large disparities between existing synthetic datasets and real scenes lead to poor model trans-fer. We make two major contributions to address that. First, we develop a point cloud collector and scene flow annotator for GTA-V engine to automatically obtain diverse realistic training samples without human intervention. With that, we develop a large-scale synthetic scene flow dataset GTA-SF.
Second, we propose a mean-teacher-based domain adapta-tion framework that leverages self-generated pseudo-labels of the target domain. It also explicitly incorporates shape deformation regularization and surface correspondence re-finement to address distortions and misalignments in do-main transfer. Through extensive experiments, we show that our GTA-SF dataset leads to a consistent boost in model generalization to three real datasets (i.e., Waymo, Lyft and
KITTI) as compared to the most widely used FT3D dataset.
Moreover, our framework achieves superior adaptation per-formance on six source-target dataset pairs, remarkably closing the average domain gap by 60%. Data and codes are available at https://github.com/leolyj/DCA-SRSFE 1.

Introduction
Scene flow estimation aims to predict the 3D motion field from two consecutive input frames. As a generaliza-tion of 2D optical flow, scene flow represents 3D motion of objects and can be used to predict their movement in the future, which is meaningful in robotic navigation and au-tonomous driving. In the early years, scene flow was esti-mated from stereo or RGB-D images [13, 44, 45, 49]. With the recent advances in 3D sensing and data driven tech-nologies, learning scene flow directly from point clouds has
*Corresponding Author: Yinjie Lei (yinjie@scu.edu.cn) (a) Differences between FT3D [27] (left) and Waymo [17, 40] (right) (b) Inaccurate predictions (i.e., results of adding estimated scene flow to 1st frame) caused by training on FT3D [27] and testing on Waymo [17,40]
Figure 1. Challenges for Synthetic-to-Real Scene Flow Estimation (SRSFE). (a) Existing synthetic dataset FT3D [27] (left) stacks and moves ShapeNet [38] objects for data generation, resulting in unnatural scenes distinct from real data (right), e.g., Waymo
[17, 40]. (b) Due to domain shift, SRSFE fails to maintain local structure and accurate movement, leading to shape deformation and correspondence deviation. The lack of appropriate synthetic datasets and performance drop in SRSFE motivate our work. gained significant research attention [2, 7, 8, 17, 24, 32].
Obtaining training data for scene flow estimation re-quires 3D motion vector annotation of each point in the scene, which is extremely challenging. One pragmatic so-lution is to employ synthetic data for training, whose an-notations can be directly generated. However, training on synthetic data and testing on real data for scene flow estimation, i.e., Synthetic-to-Real Scene Flow Estimation (SRSFE), faces two major challenges. First, SRSFE re-search on point clouds is still in its infancy, and currently there is a lack of synthetic data that adequately captures the real-world dynamics for this task. The only public synthetic data for SRSFE on point clouds, i.e., FlyingThings3D [27] (FT3D), is generated by randomly moving 3D objects sam-pled from ShapeNet [38]. This simplistic process leads to unnatural scene flows in the data, see Fig. 1(a). Second,
SRSFE must overcome the inevitable domain gap caused by the synthetic-to-real setting. In recent years, extensive stud-ies have been conducted on Unsupervised Domain Adapta-tion (UDA), which adapts a model to unseen unlabeled data to mitigate the domain gap problem. However, most of the existing UDA methods [3,4,6,9,10,41,42] are designed for 2D tasks to address the domain gap caused by the variance of image texture, color and illumination. Much less atten-tion has been paid to UDA for point clouds [34, 53–56].
This is especially true for SRSFE, for which no systematic study is available to date. Compared to other static point cloud tasks, SRSFE has a peculiar requirement of learning correlations between dynamic points. Hence, existing UDA methods are not readily transferable to this task.
In this paper, we address the above two problems. First, we propose a synthetic point cloud scene flow dataset GTA-V Scene Flow (GTA-SF), to address the lack of dataset.
Our data leverages GTA-V engine [5] to simulate LiDAR scanning and autonomously annotate scene flow by align-ing the identical entities rendered by the engine. Compared to FT3D, GTA-SF has more realistic scenes and point cloud representation. Secondly, to bridge the synthetic-to-real do-main gap, we propose a UDA framework specifically de-signed for the SRSFE task. Observing that ‘shape deforma-tion’ and ‘correspondence deviation’ are the key contribu-tors to performance degradation in SRSFE - Fig. 1(b), our technique learns deformation and correspondence under a mean-teacher strategy. We constrain the teacher predictions with rigid shapes and induce a deformation-aware student model to learn desirable scene flow. To address correspon-dence deviation, we leverage object surface relationships to let the model learn better correspondence on real data.
Our extensive experiments show that our dataset GTA-SF shows remarkable generalization to real-world data, and the proposed framework is highly effective in reducing the domain gap for the point cloud SRSFE problem. In brief, our contributions can be summarized as follows
• We present the first (to the best of our knowledge) sys-tematic study on bridging the domain gap in synthetic to real-world scene flow estimation for point clouds.
• We develop a point cloud sequence collector and scene flow annotator for GTA-V engine, and create a large-scale dataset GTA-SF for the SRSFE task.
• We propose a mean-teacher domain adaptation frame-work for point cloud SRSFE that explicitly addresses shape deformations and correspondence deviation.
• With extensive experiments, we demonstrate our GTA-SF is closer to real as it enables better performance on real dataset, and our technique consistently surpass common UDA methods across multiple datasets. 2.