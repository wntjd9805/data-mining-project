Abstract
Many recent semi-supervised learning (SSL) studies build teacher-student architecture and train the student net-work by the generated supervisory signal from the teacher.
Data augmentation strategy plays a significant role in the
SSL framework since it is hard to create a weak-strong aug-mented input pair without losing label information. Espe-cially when extending SSL to semi-supervised object de-tection (SSOD), many strong augmentation methodologies related to image geometry and interpolation-regularization are hard to utilize since they possibly hurt the location information of the bounding box in the object detection task. To address this, we introduce a simple yet effective data augmentation method, Mix/UnMix (MUM) , which un-mixes feature tiles for the mixed image tiles for the SSOD framework. Our proposed method makes mixed input im-age tiles and reconstructs them in the feature space. Thus,
MUM can enjoy the interpolation-regularization effect from non-interpolated pseudo-labels and successfully generate a meaningful weak-strong pair. Furthermore, MUM can be easily equipped on top of various SSOD methods. Exten-sive experiments on MS-COCO and PASCAL VOC datasets demonstrate the superiority of MUM by consistently im-proving the mAP performance over the baseline in all the tested SSOD benchmark protocols. The code is released at https://github.com/JongMokKim/mix-unmix. 1.

Introduction
Deep neural networks have made a lot of progress on diverse computer vision tasks thanks to the availability of large-scale datasets. To achieve better and generalizable performance, a large amount of labeled data is indispens-able, which however requires a vast amount of workforce and time for annotation [3, 12, 31]. Unlike image classifica-This work was supported by the NRF grant (2021R1A2C3006659) and IITP grant (NO.2021-0-01343, Artificial Intelligence Graduate School
Program) funded by the Korea government (MSIT).
Figure 1. Typical teacher-student (pseudo-labeling) framework for SSL. To fully exploit the unlabeled data, building an intelligent teacher and employing an adequate data augmentation strategy for weak-strong pairs are very important in this framework. tion, which needs only a class label per image, object de-tection requires a pair of a class label and location informa-tion for multiple objects per single image. Therefore, it is more challenging to acquire enough amount of labeled data in object detection. To address the above problem, many re-cent works have focused on leveraging abundant unlabeled data when training the network with a small amount of la-beled data, called semi-supervised learning (SSL) and semi-supervised object detection (SSOD).
In recent days, many SSL works rely on the teacher-student framework where a teacher network, typically a temporal ensemble model of the student, generates super-visory signals and trains the student network with them as shown in Fig. 1 [23, 35]. Data augmentation plays a signif-icant role in this framework and most of the recent works apply strongly augmented inputs for the student model while weak augmentations are given to the teacher [33, 38].
Interpolation-regularization (IR), whose core idea is that the output of the interpolated input should be similar to the in-terpolated output of the original inputs, was originally de-veloped as a data augmentation technique for supervised learning [46] and has been successfully applied to teacher-Figure 2. Overview of Mix/UnMix (MUM) training system. The teacher network generates a pseudo label to give a supervisory signal to the student, while weakly and strong & mixed augmented inputs are injected to the teacher and the student, respectively. In order to utilize the supervisory signal from the original shaped image, we unmix the mixed feature tiles and feed the unmixed features to the detection head in the student network. In each training step, the teacher network is slowly updated via EMA of the student’s weights. For visual simplicity, we assume the batch size, NT , and NG are all identical to 4. For more details about the hyperparameters, NT and NG, see Sec.3. student framework for SSL [6, 38]. It is a clever way to generate augmented input-output pairs without losing much contextual information and has also been extended to se-mantic segmentation by generating interpolated labels in a pixel-wise manner [14, 20].
However, it is challenging to make an interpolated label in the object detection task because it involves in multi-task learning, which consists of localization and classifi-cation. To tackle this problem, in this paper, we propose
Mix/UnMix (MUM) method, which exploits IR in a much more efficient and more straightforward way for object de-tection (Fig. 2). MUM generates mixed images1 by mix-ing image tiles in a batch and uses them as inputs to the student network. Then the feature maps extracted from the backbone are unmixed back to their original image geome-try. The tiles maintain their positions in the original images through the mixing process so that it is possible for the fea-ture maps to get back to their initial position through an unmixing phase. Therefore, the student network can learn from the mixed image without the interpolated (mixed) la-bel. For the teacher network, input images are weakly aug-mented to generate highly confident pseudo labels as in other existing methods. As a result, the student can learn the robust features from the mixed and naturally occluded input image with the guide of a confident pseudo-label from 1Mixed images can be considered as a type of interpolated images since they can be generated by patchwise interpolation with binary interpolation coefficients. the teacher network.
We benchmark Unbiased-Teacher [27] as a reliable baseline, which proposed a pseudo-labeling method for
SSOD. Following the standard experimental setting of re-cent SSOD research, we adopted Faster-RCNN [30] as a de-fault architecture. To verify the superiority of our algorithm, we test MUM on PASCAL VOC [13] and MS-COCO [26] dataset following the experimental protocols used in [27].
MUM achieves performance improvement against the base-line in every experimental protocol and could obtain the state-of-the-art performance in the SSOD benchmark exper-iment. Furthermore, thanks to the simplicity of MUM, the increase in the computational cost and complexity is neg-ligible in the train phase, and it can be readily plugged in other SSOD frameworks as a data augmentation method.
We also explore the versatility of MUM over different ar-chitectures through additional experiments with the Swin
Transformer backbone. In addition, we tested performance of MUM for the supervised ImageNet classification task
[10]. Our main contributions can be summarized as follows:
• We show the problem in applying the IR method to the pseudo-label-based semi-supervised object detection and propose a novel and simple data augmentation method,
MUM, which benefits from IR.
• We experimentally prove our proposed method’s supe-riority over a reliable baseline method through experi-ments and could obtain state-of-the-art performance on
MS-COCO and PASCAL VOC dataset. Furthermore, we
demonstrate the generalizability of our proposed method by still getting improved performance on a different back-bone, Swin Transformer.
• Through thorough analysis of the feature maps, class ac-tivation maps and experimental results, we show the pro-posed MUM’s compatibility with the SSOD problem. 2.