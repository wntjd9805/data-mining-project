Abstract
Semi-supervised learning (SSL) has been studied for a long time to solve vision tasks in data-efficient application scenarios. SSL aims to learn a good classification model us-ing a few labeled data together with large-scale unlabeled data. Recent advances achieve the goal by combining mul-tiple SSL techniques, e.g., self-training and consistency reg-ularization. From unlabeled samples, they usually adopt a confidence filter (CF) to select reliable ones with high pre-diction confidence. In this work, we study whether the mod-erately confident samples are useless and how to select the useful ones to improve model optimization. To answer these problems, we propose a novel Taylor expansion inspired filtration (TEIF) framework, which admits the samples of moderate confidence with similar feature or gradient to the respective one averaged over the labeled and highly confi-dent unlabeled data. It can produce a stable and new infor-mation induced network update, leading to better general-ization. Two novel filters are derived from this framework and can be naturally explained in two perspectives. One is gradient synchronization filter (GSF), which strengthens the optimization dynamic of fully-supervised learning; it se-lects the samples whose gradients are similar to class-wise majority gradients. The other is prototype proximity filter (PPF), which involves more prototypical samples in train-ing to learn better semantic representations; it selects the samples near class-wise prototypes. They can be integrated into SSL methods with CF. We use the state-of-the-art Fix-Match as the baseline. Experiments on popular SSL bench-marks show that we achieve the new state of the art. 1.

Introduction
Deep learning has achieved great success in computer vision tasks, with image classification [9] as one of the prominent examples. The success can be mainly attributed to large-scale labeled data. However, annotating enormous
*Corresponding author. training data for all tasks of interest is practically infeasible.
To reduce the labeling cost, the topic of semi-supervised learning (SSL) has been proposed and there are already a large number of research works in SSL [40]. The goal of
SSL is to achieve good model generalization using limited labeled data and many unlabeled data that are assumed to follow the same distribution. In this work, we investigate the classical topic, aiming to push the limit of SSL.
Recent SSL methods rely on deep models [47] to learn feature representations that can facilitate the subsequent classification. A common strategy is self-training [12, 17, 31], where the pseudo labels are iteratively generated and then used as supervision to guide the model training on un-labeled samples. Another popular paradigm is consistency regularization [29, 33], which constrains the model to pro-duce consistent predictions for two different duplicates of the same unlabeled sample. The difference between the two duplicates can be made by random data augmentation [33] or perturbation of network parameters [29]. After, a lot of extensions have been proposed [2, 16, 21, 24, 38, 49]. The two techniques are effective but not optimal on their own, as suggested in [26]. The current best practice in SSL is tech-nique combination, e.g., combining self-training and con-sistency regularization [4, 5, 18, 37, 44, 48, 48]. The cluster and smoothness assumptions are enforced simultaneously.
The former [7] assumes that the decision boundaries are lo-cated in low-density regions and the latter [40] assumes that the adjacent samples have similar labels. Such a combi-nation can progressively improve the model performance, as verified in the theoretical work [42]. Note that the two techniques would be uninformative if the model predicts a uniform distribution over classes for unlabeled samples.
To address it, existing methods adopt confidence filtering
[10, 18, 37], which abandons the samples whose prediction confidences (ranged in [0, 1]) are lower than a predefined high threshold (e.g., 0.95 [37]).
It is reasonable that the least confident samples are extremely unreliable. But are all the moderately confident samples useless, e.g., ranged in (0, 75, 0.95)? Is there any way to pick out the useful ones to enhance the optimization power applied to the model?
In this work, we solve the questions by introducing a novel framework of Taylor expansion inspired filtration (TEIF). The Tayor formula of the cross-entropy loss func-tion w.r.t. the feature of one sample with true or pseudo la-bel mainly includes terms of the multiplication of gradient and feature of finite orders. To make the change of loss con-sistent in the neighborhood of the feature, this framework selects the samples of moderate confidence, whose feature or gradient is similar to the respective one averaged over the labeled and highly confident unlabeled data, which are the most reliable. Hence, the final network update is still close to the one determined by the most reliable samples and further incorporates the new information contained in the selected samples of moderate confidence, such that the model optimization could be steady and improved.
From this framework, two novel filters are derived to select the helpful samples from the moderately confident unlabeled data. The selected samples together with the highly confident ones are then used to train the classifica-tion model. The first filter based on gradients assumes that one moderately confident sample is useful if it follows the optimization dynamic of fully-supervised learning [1, 50].
The previous research [1] has verified that deep neuron net-works learn simple patterns first that are better fitted by easy examples. The fact implies that pattern learning could be improved if such an optimization dynamic is strength-ened. On the other hand, the recent approach [14] relies on the sample feature gradients to characterize the optimiza-tion dynamic, i.e., constraining the local and global align-ments to be consistent. By nature of the gradient-based fil-ter, we can thus approximate the optimization dynamic by class-wise majority gradients, which are computed on fea-tures of the labeled and highly confident unlabeled samples, i.e., easy examples. From those moderately confident sam-ples, we select the ones that have similar feature gradients to the corresponding majority gradient. We thus term this method as gradient synchronization filter (GSF). The sec-ond filter based on features assumes that one moderately confident sample is useful if it has a certain level of pro-totypicality [36]. Specifically, the class-wise prototypical representations, which best characterize specific semantic classes (as suggested in [36]), are computed by taking an av-erage over sample features of each class. The samples near prototypes are selected from those moderately confident un-labeled data. We thus term this method as prototype prox-imity filter (PPF). Our methods can be naturally integrated into SSL frameworks with confidence filter. To challenge the current state of the art, we choose FixMatch [37] as the baseline. Experiments on commonly used SSL benchmarks show that our methods outperform FixMatch. The em-pirical study also answers the previously raised questions: some moderately confident samples are useful and there are ways to pick them out. Our main contributions are summa-rized below. (1) We introduce new and significant questions for SSL and provide preliminary answers for them, i.e., whether all the moderately confident samples are useless and how to select the useful ones from them. (2) To solve the questions, we propose a novel Taylor expansion inspired filtration (TEIF) framework, which relies on the Taylor ex-pansion of the loss function to inspire the key measurement index of sample filtration, i.e., gradient and feature of finite orders. The principle wherein is to make the network update stable and improved after adding the selected moderately confident samples. (3) Two novel filters are derived from this framework and make sense from different perspectives of optimization dynamic and prototype proximity, leading to gradient synchronization filter (GSF) and prototype prox-imity filter (PPF) respectively. The moderately confident samples selected by GSF or PPF are then involved in model training, which helps learn decision boundaries closer to the ground-truth ones. 2.