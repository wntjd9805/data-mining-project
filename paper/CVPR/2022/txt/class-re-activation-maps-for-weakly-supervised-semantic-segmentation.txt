Abstract
Extracting class activation maps (CAM) is arguably the most standard step of generating pseudo masks for weakly-supervised semantic segmentation (WSSS). Yet, we find that the crux of the unsatisfactory pseudo masks is the binary cross-entropy loss (BCE) widely used in CAM. Specifically, due to the sum-over-class pooling nature of BCE, each pixel in CAM may be responsive to multiple classes co-occurring in the same receptive field. As a result, given a class, its hot CAM pixels may wrongly invade the area belonging to other classes, or the non-hot ones may be actually a part of the class. To this end, we introduce an embarrass-ingly simple yet surprisingly effective method: Reactivat-ing the converged CAM with BCE by using softmax cross-entropy loss (SCE), dubbed ReCAM. Given an image, we use CAM to extract the feature pixels of each single class, and use them with the class label to learn another fully-connected layer (after the backbone) with SCE. Once con-verged, we extract ReCAM in the same way as in CAM.
Thanks to the contrastive nature of SCE, the pixel response is disentangled into different classes and hence less mask ambiguity is expected. The evaluation on both PASCAL
VOC and MS COCO shows that ReCAM not only gener-ates high-quality masks, but also supports plug-and-play in any CAM variant with little overhead. Our code is public at https://github.com/zhaozhengChen/ReCAM. 1.

Introduction
Weakly-supervised semantic segmentation (WSSS) aims to lower the high cost in annotating “strong” pixel-level masks by using “weak” labels instead, such as scrib-bles [29, 36], bounding boxes [7, 35], and image-level class labels [1, 19, 27, 28, 42, 46]. The last one is the most eco-nomic yet challenging budget and thus is our focus in this paper. A common pipeline has three steps: 1) training a
Figure 1. We train two models respectively using binary cross en-tropy (BCE) and softmax cross entropy (SCE) losses. Our train and val sets contain only single-label images of MS COCO [30].
“80-class” model uses the complete label set. “5-hoofed” model is trained on only the samples of 5 hoofed animals each causing false positive flaws to another, e.g., between cow and horse. multi-label classification model with the image-level class labels; 2) extracting the class activation map (CAM) [51] of each class to generate a 0-1 mask, with potential refine-ment such as erosion and expansion [1, 23]; and 3) tak-ing all-class masks as pseudo labels to learn the segmenta-tion model in a standard fully-supervised fashion [5, 6, 41].
There are different factors affecting the performance of the final segmentation model, but the classification model in the first step is definitely the root. We often observe two com-mon flaws. In the CAM of an object class A, there are 1) false positive pixels that are activated for class A but have the actual label of class B, where B is usually a confus-ing class to A rather than background—a special class in semantic segmentation; and 2) false negative pixels that be-long to class A but are wrongly labeled as background.
Findings. We point out that these flaws are particu-larly obvious when the model is trained with the binary cross-entropy (BCE) loss with sigmoid activation function. ex ex+1 where x denotes
Specifically, the sigmoid function is the prediction logit of any individual class. The output is
fed into the BCE function to compute a loss. This loss represents the penalty strength for misclassification corre-sponding to x. The BCE loss is thus not class mutually exclusive—the misclassification of one class does not pe-nalize the activation on others. This is indispensable for training multi-label classifiers. However, when extracting
CAM via these classifiers, we see the drawbacks: non-exclusive activation across different classes (resulting in false positive pixels in CAM); and the activation on total classes is limited (resulting in false negative pixels) since partial activation is shared.
Motivation. We conduct a few toy experiments to empiri-cally show the poor quality of CAM when using BCE. We pick single-label training images in MS COCO 2014 [30] (about 20% in the train set) to train 5-class and 80-class classifiers, respectively, where for 5-class, we pick 5 hoofed animal classes (e.g., horse and cow) that suffer from the confused activation. We train every model using two losses, respectively: BCE loss and softmax cross-entropy (SCE) loss—the most common one for classification. We use the single-label images in val set to evaluate models’ clas-sification performance, as shown in Figure 1 (a), and use the single-label images in both train and val sets to in-spect models’ ability of activating correct regions on the objects—the quality of CAM, as compared in Figure 1 (b).
Intrigued, 1) for 80-class models, BCE and SCE yield equal-quality classifiers but clearly different CAMs, and 2) the CAMs of SCE models are of higher mIoU, and this superiority is almost maintained for validation images. A small yet key observation is that for 5 hoofed animal classes,
BCE shows weaker to classify them. We point out this is because the sigmoid activation function of BCE does not enforce class-exclusive learning, confusing the model
Its between similar classes. However, SCE is different. ex+Σyey , where y denotes the softmax activation function prediction of any negative class, explicitly enforces class-exclusion by using exponential terms in the denomina-tor. SCE encourages to improve the logit of ground truth and penalizes others simultaneously. This makes two ef-fects on CAM: 1) reducing false positive pixels which con-fuse the model among different classes; and 2) encour-aging the model to explore class-specific features that re-duce false negative pixels. We show the empirical evidence in Figure 1 (b) where the mIoU improvements by SCE over BCE are especially significant for 5-hoofed. Please note that the functions of BCE and SCE are different. To give more concrete comparison between them, we elaborate the comparison between their produced gradients in Sec-tion 4.2, theoretically and empirically.
Our Solution. Our intuition is to use SCE loss function to train a model for CAM. However, directly replacing BCE with SCE does not make sense for multi-label classification tasks where the probabilities of different classes are not in-ex dependent [34, 47]. Instead, we use SCE as an additional loss to Reactivate the model and generate ReCAM. Specif-ically, when the model converges with BCE, for every in-dividual class labeled in the image, we extract the CAM in the format of normalized soft mask, i.e., without hard thresholding [40, 51]. We apply all masks on the feature (i.e., the feature map block output by the backbone), re-spectively, each “highlighting” the feature pixels contribut-ing to the classification of a specific class. In this way, we branch the multi-label feature to a set of single-label fea-tures. We can thus use these features (and labels) to train a multi-class classifier with SCE, e.g., by plugging another fully-connected layer after the backbone. The SCE loss penalizes any misclassification caused by either poor fea-tures or poor masks. Then, backpropagating its gradients improves both. Once converged, we extract ReCAM in the same way of CAM.
Empirical Evaluations. To evaluate the ReCAM, we con-duct extensive WSSS experiments on two popular bench-marks of semantic segmentation, PASCAL VOC 2012 [9] and MS COCO 2014 [30]. A standard pipeline of WSSS is to use CAM [51] as seeds and then deploy refinement methods such as AdvCAM [23] or IRN [1] to expand the seeds to pseudo masks—the labels used to train the seg-mentation model. We design the following comparisons to show the generality and superiority of ReCAM. 1) ReCAM as seeds, too. We extract ReCAM and use refinement meth-ods afterwards, showing that the superiority over CAM is maintained after strong refinement steps. 2) ReCAM as an-other refinement method. We compare ReCAM with exist-ing refinement methods, regarding the quality of generated masks as well as the computational overhead added to base-line CAM [51]. In the stage of learning semantic segmen-tation models, we use the ResNet-based DeepLabV2 [5],
DeepLabV3+ [6] and the transformer-based UperNet [41].
Our Contributions in this paper are thus two-fold. 1) A simple yet effective method ReCAM for generating pseudo masks for WSSS. 2) Extensive evaluations of ReCAM on two popular WSSS benchmarks, with or without incorpo-rating advanced refinement methods [1, 23]. 2.