Abstract
State-of-the-art stereo matching networks trained only on synthetic data often fail to generalize to more challeng-ing real data domains. In this paper, we attempt to unfold an important factor that hinders the networks from general-izing across domains: through the lens of shortcut learning.
We demonstrate that the learning of feature representations in stereo matching networks is heavily influenced by syn-thetic data artefacts (shortcut attributes). To mitigate this issue, we propose an Information-Theoretic Shortcut Avoid-ance (ITSA) approach to automatically restrict shortcut-related information from being encoded into the feature rep-resentations. As a result, our proposed method learns ro-bust and shortcut-invariant features by minimizing the sen-sitivity of latent features to input variations. To avoid the prohibitive computational cost of direct input sensitivity op-timization, we propose an effective yet feasible algorithm to achieve robustness. We show that using this method, state-of-the-art stereo matching networks that are trained purely on synthetic data can effectively generalize to challenging and previously unseen real data scenarios. Importantly, the proposed method enhances the robustness of the synthetic trained networks to the point that they outperform their fine-tuned counterparts (on real data) for challenging out-of-domain stereo datasets. 1.

Introduction
Stereo matching is a fundamental task in computer vi-sion and is widely used for depth sensing in various ap-plications such as augmented reality (AR), robotics and
In recent years, end-to-end trained autonomous driving.
Convolutional Neural Networks (CNNs) have achieved im-pressive results for this task as quantified by the perfor-mance on several publicly available stereo-matching bench-marks [6, 16, 18, 45, 52].
Generally, end-to-end stereo-matching networks require a large amount of labelled data for training. To overcome (a) KITTI-15 (b) DrivingStereo (c) Oxford (d) Middlebury
Figure 1. Comparison of disparity maps estimated by PSMNet [6] when it is trained under different settings and across multiple do-mains. Each column shows the results for a realistic domain namely: KITTI 2015 [26], DrivingStereo [47], Oxford Robot-car [24] and Middlebury [35]. Rows from top to bottom show a sample image (I) , the prediction for the Scene Flow pre-trained model (II), KITTI-15 fine-tuned model (III), and the proposed
ITSA optimized method (IV). Comparing these figures shows that
PSMNet trained solely on synthetic data performs poorly on real data and fine tuning only improves the result for KITTI dataset (still fails to generalize for other scenarios). The proposed method performs well across the board (best viewed in color). this challenge, many state-of-the-art networks are initially trained on labelled synthetic data, commonly generated us-ing game engines. However, models trained using synthetic data do not generalize well to unseen realistic domains. For example, the PSMNet [6] pre-trained on the Scene Flow dataset [25] performs poorly when tested on unseen realis-tic domains as illustrated in Fig. 1. Therefore, in practice, the networks trained with synthetic data are fine-tuned us-ing labelled data from the relevant target domain. However, collecting even a relatively small amount of dense ground truth data in the real-world can be challenging for tasks like stereo-matching [22, 41]. Furthermore, to be practi-cally useful in many applications, a stereo-matching model should be able to generalize effortlessly to different do-mains like day and night times, varying weather conditions, etc. Collecting data for fine-tuning that cover all possible situations is both difficult and expensive.
It is therefore highly desirable to remove the fine-tuning requirement.
It is known that neural networks, including stereo match-ing networks, can learn superficial shortcut features (or spurious correlations with the target labels), which prevent them from generalizing across different domains [2,12]. We found that stereo matching networks trained on synthetic data are susceptible to exploiting shortcuts in synthetic data such as (1) consistent local statistics (RGB color features) between the left and right stereo images and (2) over-reliance on local chromaticity features (e.g. color, illu-mination, texture) of the reference stereo viewpoint. De-tailed analysis and discussion are included in Sec. 4.2. De-pendency on these shortcut cues, instead of the desirable semantic and structural representations, means that these networks would fail drastically when the spurious corre-lations between shortcuts and labels do not exist in a new (unseen) domain [33]. While several shortcut-removal ap-proaches have been previously proposed [4, 17, 38], most of these methods are manually designed (e.g. carefully se-lected data augmentations [4, 17]) and rely on the assump-tion that the shortcuts could be identified in advance. How-ever, shortcuts can be non-intuitive, task-specific, and diffi-cult to identify [9, 27].
Our goal is to train a stereo matching network on syn-thetic data that can generalize to realistic scenes without the need for fine-tuning. To achieve this, we propose an information-theoretic approach to automatically restrict the shortcut-related information from being encoded from the input into the feature representations. The approach is based on the well known information bottleneck (IB) principle that proposes to optimize the following objective [1, 40]: argmax
θ
I (Y, Z; θ) − βI (X, Z; θ) (1) where Z is the encoding of input X, Y is the target, I is mutual information and β ∈ [0, 1] is the hyperparam-eter that controls the size of the information bottleneck.
While optimizing the IB objective leads to compressed fea-ture representations, our empirical experiments showed that these compressed features are neither robust nor shortcut-invariant (details are provided in Sec. 3.3.1). Consequently, the IB optimized networks may still incorporate shortcuts and remain fragile when tested in unseen domains. The re-cently introduced robust IB criterion [31] encourages the learning of both robust and compressive features by replac-ing the mutual information in IB with statistical Fisher in-formation. Robust IB is presented in the context of learning features that are robust to adversarial attacks and to the best of our knowledge it has not been used for domain general-ization.
In our approach, we combine the task loss (e.g. smooth
L1 loss) with Fisher information to learn a generalizable stereo matching model. Although such an objective can work in theory, straightforward optimization of the Fisher information by gradient descent requires computation of the second-order derivatives and is therefore computation-ally expensive for tasks with high dimensional inputs such as stereo matching and semantic segmentation. To over-come this shortcoming, we propose ITSA which consists of a novel loss term and perturbation technique to approximate the optimization of the Fisher information loss. The pro-posed ITSA is computationally efficient, and as we show by extensive experiments, it can promote the learning of shortcut-invariant features. Unlike the existing domain-invariant stereo matching networks [37, 53], the proposed
ITSA does not involve significant network alteration and is model-agnostic. Therefore, as shown in the experiments section, it can be easily integrated with different stereo matching networks.
The empirical results show that stereo-matching net-works trained on synthetic data, with the proposed ITSA, can generalise to realistic data without fine-tuning. Ad-ditional experiments on challenging out-of-domain stereo datasets (e.g. different adverse weathers and night scenes) show that our method also improves the overall robustness of the stereo matching networks and importantly even out-performs the networks fine-tuned on realistic domains when tested on these challenging datasets. The main contributions of this paper include:
• We show that learning feature representations that are less sensitive to input variations can significantly en-hance the synthetic to realistic domain generalization, and robustness in stereo matching networks.
• We introduce a novel loss function that enables us to minimize the Fisher information, without computing the second-order derivatives.
• We also show that the application of the proposed framework is not limited to stereo matching task, and can be used in training models for non-geometry based vision problems such as semantic segmentation.
The rest of the paper is organized as follows. Sec. 2 de-scribes the related work in the field of learning-based stereo matching networks, domain generalization and shortcut learning. Sec. 3 presents the proposed method for automatic shortcut avoidance and domain generalization. Experimen-tal results and discussions are presented in Sec. 4, and Sec. 6 concludes the paper. 2.