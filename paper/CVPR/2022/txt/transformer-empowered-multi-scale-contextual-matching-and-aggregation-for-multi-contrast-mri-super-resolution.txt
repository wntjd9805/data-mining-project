Abstract
Magnetic resonance imaging (MRI) can present multi-contrast images of the same anatomical structures, enabling multi-contrast super-resolution (SR) techniques. Com-pared with SR reconstruction using a single-contrast, multi-contrast SR reconstruction is promising to yield SR images with higher quality by leveraging diverse yet complemen-tary information embedded in different imaging modali-ties. However, existing methods still have two shortcom-ings: (1) they neglect that the multi-contrast features at dif-ferent scales contain different anatomical details and hence lack effective mechanisms to match and fuse these features for better reconstruction; and (2) they are still deficient in capturing long-range dependencies, which are essential for the regions with complicated anatomical structures. We propose a novel network to comprehensively address these problems by developing a set of innovative Transformer-empowered multi-scale contextual matching and aggrega-tion techniques; we call it McMRSR. Firstly, we tame trans-formers to model long-range dependencies in both refer-ence and target images. Then, a new multi-scale contex-tual matching method is proposed to capture corresponding contexts from reference features at different scales. Further-more, we introduce a multi-scale aggregation mechanism to gradually and interactively aggregate multi-scale matched features for reconstructing the target SR MR image. Ex-tensive experiments demonstrate that our network outper-forms state-of-the-art approaches and has great potential to be applied in clinical practice. Codes are available at https://github.com/XAIMI-Lab/McMRSR.
*Corresponding author. (a) Crop area (b) Bicubic (c) MCSR [20] (d) MINet [8] (e) McMRSR (Ours) (f) HR
Figure 1. Compared with state-of-the-art multi-constrast MRI
SR reconstruction methods: MCSR and MINet; the reconstructed
MRI image by our McMRSR network contains sharper edges, more visual details, and fewer blurring artifacts. 1.

Introduction
Magnetic resonance imaging (MRI) is an essential med-ical imaging technique in clinical application that provides clear information on tissue structure and function without causing ionizing radiation. However, due to the essential drawbacks of imaging systems [27, 36] and crepitations in some parts of the body, e.g., the abdomen, it is challenging to acquire high-resolution (HR) MR images in clinics [9].
In addition, prolonged acquisition procedure may cause dis-comforts to patients, introduce motion artifacts, and hence affect image quality [15]. Super-resolution (SR) reconstruc-tion is a promising way to improve the quality of MR im-ages without upgrading hardware facilities [11].
MRI can present multi-contrast images with the same
anatomical structures at different settings, e.g., T1-weighted images (T1) and T2-weighted images (T2), as well as pro-ton density weighted images (PD) and fat-suppressed pro-ton density weighted images (FS-PD), which can provide complementary information to each other [3, 8]. In clinical applications, as the repetition time and echo time of T1 are shorter than those of T2 and the scanning process of PD is usually shorter than that of FS-PD, T1 can be used to guide
LR T2 for SR reconstruction and PD can help to reconstruct
FS-PD [38]. In this regard, it is promising to leverage an HR reference image with shorter acquisition time to reconstruct the modality with longer scanning time from an LR image.
While some effort has been dedicated to multi-contrast
MRI SR reconstruction [8, 20, 31, 43, 46, 47], we still face challenges in two key steps: (1) how to effectively extract the features in the reference and target images, and (2) how to transfer the features of the reference image to the features of the target image. In recent studies, Zeng et al. [43] em-ployed CNN to simultaneously perform single- and multi-contrast SR reconstruction. Lyu et al. [20] applied a GAN-based progressive network to multi-contrast SR reconstruc-tion. Feng et al. [8] used multi-stage integration network to perform multi-contrast MRI SR reconstruction. However, these methods are still incapable of sufficiently and com-prehensively address the challenges in the two steps.
There are two main shortcomings. First, most existing methods harness deep convolutional layers for feature ex-traction. However, the convolution kernel usually has a limited receptive field and hence cannot adequately cap-ture long-range/non-local features, which are important for
MRI SR reconstruction as, for some regions with compli-cated anatomical structures, faithful reconstruction depends on not only local relationships but also long-range depen-dencies. Second, many of existing methods [8, 20] directly upsample the low-scale image into a high-scale image, and then perform the extraction and fusion of multi-contrast fea-tures. However, these methods neglect that multi-contrast features at different scales contain different anatomical de-tails and hence can provide broad yet diverse guidance for target MRI SR reconstruction.
In order to address these two shortcomings, in this pa-per, we propose a novel and effective network for multi-contrast MRI SR by taming transformers to extract long-range dependencies to facilitate more comprehensive con-textual matching and exploiting multi-contrast multi-scale features to guide the reconstruction at different scales with anatomical information extracted from different modalities; we call the network as McMRSR network. Our contribu-tions can be summarized as follows. 1. We propose a novel network equipped with contextual transformer-empowered multi-scale matching for multi-contrast MRI SR , where Swin
Transformer groups are exploited to extract deep features at different scales and from different contrasts to capture more long-range dependencies. 2. We propose multi-scale contextual matching and ag-gregation schemes to transfer visual contexts from ref-erence images to target LR MR images at different scales, allowing the target LR images make full use of the guidance information to achieve SR images full of fine details. 3. Our McMRSR outperforms state-of-the-art approaches on three benchmark datasets: clinical pelvic, clini-cal brain, and fastMRI, demonstrating its effectiveness and great potential to be used in clinical practice. 2.