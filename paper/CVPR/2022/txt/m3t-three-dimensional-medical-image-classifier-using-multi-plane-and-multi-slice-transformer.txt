Abstract
In this study, we propose a three-dimensional Medical image classifier using Multi-plane and Multi-slice Trans-former (M3T) network to classify Alzheimer’s disease (AD) in 3D MRI images. The proposed network synergically com-bines 3D CNN, 2D CNN, and Transformer for accurate AD classification. The 3D CNN is used to perform natively 3D representation learning, while 2D CNN is used to utilize the pre-trained weights on large 2D databases and 2D repre-sentation learning. It is possible to efficiently extract the lo-cality information for AD-related abnormalities in the local brain using CNN networks with inductive bias. The trans-former network is also used to obtain attention relationships among multi-plane (axial, coronal, and sagittal) and multi-slice images after CNN. It is also possible to learn the ab-normalities distributed over the wider region in the brain
In this ex-using the transformer without inductive bias. periment, we used a training dataset from the Alzheimer’s
Disease Neuroimaging Initiative (ADNI) which contains a total of 4,786 3D T1-weighted MRI images. For the valida-tion data, we used dataset from three different institutions:
The Australian Imaging, Biomarker and Lifestyle Flagship
Study of Ageing (AIBL), The Open Access Series of Imag-ing Studies (OASIS), and some set of ADNI data indepen-dent from the training dataset. Our proposed M3T is com-pared to conventional 3D classification networks based on an area under the curve (AUC) and classification accuracy for AD classification. This study represents that the pro-posed network M3T achieved the highest performance in multi-institutional validation database, and demonstrates the feasibility of the method to efficiently combine CNN and
Transformer for 3D medical images. 1.

Introduction
Convolutional Neural Networks (CNN) have been es-tablished with a dominant performance in the computer vision field [35]. They have showed high feasibilities in
*Corresponding author.
Figure 1. The overall framework of three-dimensional Medical image classifier using Multi-plane and Multi-slice Transformer network (M3T) various computer vision tasks such as image classification
[26, 28, 35, 65], object detection [38, 53, 54], and seman-tic segmentation [8, 40, 55]. In addition, these CNN-based architectures have been widely applied to the medical im-age analysis field [39] in the various modalities such as X-ray [27], CT [24], MRI [20, 30], and Ultrasound [12], and in various dimension signals from 2D to 3D medical im-ages [4, 74]. Especially, to analyze 3D medical images, var-ious approaches have been established based on 2D and 3D
CNN networks [4, 47, 56, 74]. The 2D-based methods have advantages from a pre-trained model using large-scale 2D natural images, while the 2D representation learning has a disadvantage for analysis of 3D image contexts [47, 56, 74].
On the other hand, The 3D-based methods can learn na-tively 3D representations [13, 44, 57]. However, there are few publicly available 3D databases for pretraining [61,62].
Furthermore, the 3D model has lacks of ability to build deep layers because it requires large parameters and computa-tion costs [64, 72]. There are trade-offs between 2D and 3D representation learning on 3D medical images: these re-searches select either 2D or 3D CNN models [74].
Meanwhile, transformer networks have been widely used not only in natural language processing [16, 69] but also in computer vision processing [5, 18, 32]. These net-works have a wider receptive field, which can cover a large area of images and grow linearly with the depth of the net-work, while the convolution-based networks have a limited receptive field. More recently, Vision Transformer (ViT)
[18] which consists of a pure-transformer-based architec-ture could achieve reasonable performance on image clas-sification. Furthermore, ViT achieves comparable results to conventional CNN-based methods using very large-scale databases, indicating that the transformer model is compet-itive with the other state-of-the-art techniques. However, when the models are trained with smaller dataset, the CNN-based method tends to show higher accuracy. This indi-cates that the pure-transformer-based architectures struggle to learn meaningful representations when trained on small datasets due to the low abilities of inductive biases pos-sessed in CNN architectures [18, 32]. Especially for 3D medical images, the number of datasets is relatively lower than those of other domains because of hardly accessibili-ties by ethical issues [61, 62], large computational costs by high dimensionalities [64], expensive annotation, and se-vere class-imbalance problems [72]. Therefore, the pure-transformer-based method has not been yet widely used in analyzing 3D medical images.
In fact, there are some trade-offs between CNN and
Transformer: CNN’s strong inductive biases and localities to achieve high performance even with minimal data, yet these biases may limit the CNN when there are high dimen-sional data to cover with the low receptive field [32, 79].
On the other hand, a transformer with minimal inductive biases, which can prove to limit in small datasets, but the bias enables the architecture to cover a large area with a high receptive field [14, 18, 71]. More recently, the hy-brid network combining CNN and transformer has been re-searched to take advantage of both methods and achieved more competitive performance compared to conventional methods [14, 71, 79]. However, these hybrid networks only combine 2D CNN and transformer for 2D images, while our method combines 2D, 3D CNN and transformer for 3D medical images.
Alzheimer’s Disease (AD) is progressive neurological illness that causes memory loss and makes it difficult to communicate and perform daily tasks like walking and speaking [43]. The progression of AD often involves struc-tural changes such as cerebral cortex atrophy, ventricle area enlargement and hippocampus volume shrinkage [1, 25].
Fig. 2 shows the brain image of normal control and AD patients. Therefore, 3D MRI images has been widely used
Figure 2. Comparison of a normal control brain (left) and struc-tural changes by degeneration from severe Alzheimer’s disease (right) to analyze AD-related abnormalities [63]. However, it can be challenging for doctors to analyze large and complex
MRI images and to extract important information manually.
Moreover, due to various inter- or intra-operator variability issues, manual analysis of brain 3D MRI is time-consuming and vulnerable to misdiagnosis [15].
The atrophy of cerebral cortex of AD patients occurs in the cortex distributed throughout the brain. So, transformer architecture with a wide receptive field is suitable to detect this cortex change. On the other hand, enlargement of ven-tricle area and hippocampus shrinkage occur in local area of brain. A CNN network with inductive bias is suitable for these local hippocampal changes. Accordingly, we used a hybrid network combining CNN and transformer networks in this study. Furthermore, transformer network can analyze various range relationship from adjacent to far away images because it has permutation -invariant property [18].
In this study, we propose a three-dimensional Medical image classifier using Multi-plane and Multi-slice Trans-former (M3T) network to analyze AD in 3D MRI images.
Our goal is to classify Alzheimer’s disease (AD) with nor-mal control (NC) in the 3D MRI images. The overall archi-tecture of the proposed M3T model is shown in Fig. 1. The main contributions of this study are as follows.
First, our proposed M3T successfully combines CNN and transformer architectures for 3-dimensional image clas-sification. CNN architecture with inductive bias enables our network to efficiently analyze local features related to abnormalities of AD. The transformer with a large recep-tive field efficiently combines multi-plane (coronal, sagittal, and axial) and multi-slice tokens from CNN and captures a long-range relationship in 3D MRI images. M3T achieves higher performance compared with pure CNN and trans-former methods.
Second, we efficiently combined 2D and 3D CNN ar-chitectures for 3D MRI images using hybrid networks and multi-plane, -slice feature extraction. Using 3D CNN, 3D representation features can be obtained to analyze 3D AD-In addition, cross-slice and cross-related abnormalities. plane 2D features used in the 2D CNN process can be ex-tracted from the 3D images. Using 2D CNN, we use the large-database pre-trained network, which ensures stable training with a small number of medical images. For these reasons, our M3T obtain higher performance compared to the approaches that do not combined 2D or 3D CNN net-works.
Third, we visualize the activated area in 3D MRI im-ages the transformer interpretability methods [7]. These re-sults provide explanation and interpretation of AD-related abnormalities in 3D MRI images. Furthermore, the acti-vated area shows where the network focused on AD-related features. From these visualization results, the regions an-alyzed by our proposed largely coincide with the regions mainly shrunk by Alzheimer’s disease. 2.