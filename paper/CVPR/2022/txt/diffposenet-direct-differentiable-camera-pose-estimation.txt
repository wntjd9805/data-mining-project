Abstract
Current deep neural network approaches for camera pose estimation rely on scene structure for 3D motion esti-mation, but this decreases the robustness and thereby makes cross-dataset generalization difficult. In contrast, classical approaches to structure from motion estimate 3D motion utilizing optical flow and then compute depth. Their ac-curacy, however, depends strongly on the quality of the op-tical flow. To avoid this issue, direct methods have been proposed, which separate 3D motion from depth estima-tion, but compute 3D motion using only image gradients
In this paper, we introduce in the form of normal flow. a network NFlowNet, for normal flow estimation which is used to enforce robust and direct constraints. In particular, normal flow is used to estimate relative camera pose based on the cheirality (depth positivity) constraint. We achieve this by formulating the optimization problem as a differen-tiable cheirality layer, which allows for end-to-end learning of camera pose. We perform extensive qualitative and quan-titative evaluation of the proposed DiffPoseNet’s sensitivity to noise and its generalization across datasets. We compare our approach to existing state-of-the-art methods on KITTI,
TartanAir, and TUM-RGBD datasets. 1.

Introduction
The ability to localize is imperative for applications in mobile robotics, and solutions based on vision are often the preferred choice because of size, weight, power con-straints and the availability of robust localization meth-ods. Many mathematical frameworks and deep learning ap-proaches have been developed for the problem of visual lo-calization [12, 38] under the umbrella of Visual Odometry (VO) or Simultaneous Localization and Mapping (SLAM).
However, their performance is subpar for commonly en-countered challenging conditions in-the-wild that involve changing lighting, scenes with textureless regions, and dy-namic objects.
Classical approaches [5, 8, 9, 24] for localization rely ei-ther on sparse feature correspondences between images or on the computation of dense motion fields (optical flow).
One of the difficulties in optical flow estimation is bias due to noise [15, 16]. For example, if in a patch there are more gradients in one direction than another, their estimated op-tical flow will be biased towards the dominant direction.
Even though over the past decade many learning-based ap-proaches have proposed to improve optical flow estimation, this behavior still persists in optical flow approaches. This is demonstrated in Fig. 1, which shows the errors produced by the normal flow algorithm presented in this paper in com-parison to three optical flow algorithms from the literature.
As can be seen, all flow algorithms have large errors in re-gions of non-uniform gradient distributions.
To this end, the pioneers of the field remarked on the ob-servation that the projection of optical flow on the image gradient direction is resilient to the bias and can be com-puted robustly. This projection is called the normal flow.
Over the past few decades, a number of methods have been proposed that use the spatial gradient directly for 3D mo-tion recovery. These methods are commonly called direct methods. In principle, such methods are robust and compu-tationally cheaper than flow-based feature based approaches as they use the image brightness directly. However, despite the advantages of the normal flow formulation, the compu-tational methods to estimate normal flow have not been ro-bust enough to allow deployment in the wild. Thus, optical flow has been the go-to representation for ego-motion esti-mation, supported in recent years by the high accuracy and speed of deep learning algorithms [22, 26, 35]. To improve the robustness of camera pose estimation (ego-motion), we propose the first normal flow network NFlowNet.
Further, to estimate pose independent of scene structure from normal flow, direct approaches utilize minimal con-straints. When optical flow or correspondence are available, pose is estimated using the depth-independent epipolar con-straint. However different from these 2D measurements, normal flow is 1D and thus depth cannot be eliminated from the equations relating it to scene geometry and 3D motion.
Not making assumptions about the scene structure, the only
Figure 1. Top Row: Endpoint error map of NFlowNet compared to three different optical flow approaches (SelFlow [30], LiteFlowNet [21], and PWC-Net [43]). Bottom Row: enlarged endpoint error map of the region highlighted in red in the top row. The optical flow is due to the camera undergoing translation parallel to the wall. It has large errors in regions of non-uniform gradient directions. Notably, on the bricks of rectangular shape, there are many more (vertical) gradients due to the horizontal edges than (horizontal) gradients due to vertical edges, and this causes erroneous flow estimation. Similarly, on the edges of the niches, where there is only one gradient direction, there is error. All the images in this paper are best viewed in color on a computer screen at a zoom of 200%. constraint that can be imposed on the scene, is the depth positivity [34] or cheirality constraint [49]. Cheirality states that the scene has to be in front of the camera for it to be im-aged, and thus the depth has to be positive. This constraint when enforced on normal flow can be utilized to estimate camera pose without making assumptions on scene depth or shape. Since the cheirality condition is an inequality con-straint and hence is not differentiable, until recently it was not possible to employ it in a deep learning pipeline. To this end, we utilize the differentiable programming paradigm [2] implemented with the implicit differentiation [18] frame-work to reformulate the cheirality optimization into a dif-ferentiable layer and hence train our pose network in an end-to-end fashion.
In this work, we design a novel normal flow network
NFlowNet and couple it with a differentiable cheirality layer for robust pose estimation. Our contributions (in the order for ease of understanding) can be summarized as follows:
• We introduce a network NFlowNet to estimate normal flow. This estimated robust normal flow, beyond this paper, is useful for applications requiring computation-ally efficient solutions for navigation tasks in computer vision and robotics.
• We formulate the estimation of pose from normal flow using the cheirality (or depth positivity) constraint as a differentiable optimization layer.
• Extensive qualitative and quantitative experimental re-sults highlighting the robustness and cross-dataset gen-eralizability of our approach without any fine-tuning and/or re-training. 2.