Abstract
Hierarchical frameworks consisting of both coarse and
ﬁne localization are often used as the standard pipeline for large-scale visual localization. Despite their promis-ing performance in simple environments, they still suffer from low efﬁciency and accuracy in large-scale scenes, es-pecially under challenging conditions.
In this paper, we propose an efﬁcient and accurate large-scale localization framework based on the recognition of buildings, which are not only discriminative for coarse localization but also ro-bust for ﬁne localization. Speciﬁcally, we assign each build-ing instance a global ID and perform pixel-wise recogni-tion of these global instances in the localization process.
For coarse localization, we employ an efﬁcient reference search strategy to ﬁnd candidates progressively from the local map observing recognized instances instead of the whole database. For ﬁne localization, predicted labels are further used for instance-wise feature detection and match-ing, allowing our model to focus on fewer but more ro-bust keypoints for establishing correspondences. The ex-periments in long-term large-scale localization datasets in-cluding Aachen and RobotCar-Seasons demonstrate that our method outperforms previous approaches consistently in terms of both efﬁciency and accuracy. 1.

Introduction
Visual localization is a key technique of various appli-cations, e.g., autonomous driving and robotics. Visual lo-calization algorithms can be roughly categorized as image-based [21, 64], scene coordinate-based [4–7], and structure-based [37, 40, 47, 56].
Image-based methods only yield approximate poses [2, 15, 34, 43] and scene coordinate-based models don’t perform well in large-scale scenes [23].
Structure-based systems consisting of coarse (ﬁnding refer-ence images in the database via image retrieval [2, 15, 58]) and ﬁne localization (establishing correspondences between the query and reference images by keypoint matching [10, 27, 35]), are preferred in real applications.
In the pipeline of structure-based systems, both coarse
Figure 1. Overview of our framework. For each query image, we ﬁrst perform pixel-wise global instance recognition, results of which are then used to ﬁnd references from areas observing recog-nized instances instead of the whole database. Pixel-wise recog-nition masks are also used for instance-wise feature detection and matching to provide robust correspondences for ﬁne localization.
Finally, 2D-2D matches between the query and reference images are converted to 2D-3D matches for pose estimation. and ﬁne localization are formulated as ﬁnding the clos-est candidates from a given set for the query data point, e.g., image to image matches in coarse localization and point to point matches in ﬁne localization. Previous meth-ods [10, 35, 37] employ exhaustive comparisons for all query data with the rest in the database. This, however, is computationally slow and suffers from low accuracy be-cause of spurious wrong candidates, especially under chal-lenging conditions, e.g., changes of illumination, season, and weather. Some works [23, 47, 63] make use of se-mantics to improve both coarse and ﬁne localization sep-arately. For coarse localization, they ﬁlter unstable ob-jects like trees [46, 63] or transfer images from night to day [1]. For ﬁne localization, additional segmentation net-works are incorporated to reject semantically inconsistent matches [18, 22, 23, 45, 47, 56]. Despite their promising im-provements, modeling coarse and ﬁne localization as two independent tasks, they ignore the fact that coarse local-ization should provide reference images with enough valid
areas for establishing correspondences in ﬁne localization rather than the most similar images in the database. More-over, most of which make explicit use of semantic la-bels [23, 47, 56] are not robust to segmentation failures.
In this paper, we aim to design an efﬁcient and accurate large-scale localization system by modeling coarse and ﬁne localization as a coherent process. To this end, we lever-age buildings to bridge the gap between the two processes.
Compared with other objects (e.g., trees and cars), which are sensitive to appearance changes, buildings are able to provide robust correspondences for ﬁne localization. Be-sides, buildings are also discriminative to represent a loca-tion for coarse localization. We make use of the robustness and discriminative ability of buildings in a coherent man-ner and propose a recognition-based localization system.
Speciﬁcally, we ﬁrst assign each building instance a global
ID. Next, for each image, we perform pixel-wise recogni-tion of global building instances, results of which are then utilized to ﬁnd reference images from areas observing rec-ognized instances rather than the whole map. Finally, pixel-wise recognition masks are further used for local feature de-tection and matching, allowing our model to extract fewer but more robust keypoints and execute instance-wise match-ing in a reduced space to increase the number of inliers.
Beneﬁting from the uniqueness of buildings and their ro-bustness to appearance changes, in comparison to general objects, our model can recognize more building instances even under challenging conditions. To minimize the inﬂu-ence of potential recognition errors, we employ a progres-sive search strategy to efﬁciently ﬁnd references for coarse localization and a robust instance-wise detection and match-ing approach for ﬁne localization. We also divide the pose estimation process into two steps so that our model is able to explore more potential locations at low cost in the ﬁrst step and perform a slower reﬁnement to produce more ac-curate poses in the second step. Fig. 1 shows an overview of our framework. Contributions are summarized as follows:
• We propose a novel localization framework based on global building instance recognition, which models coarse and ﬁne localization as a coherent process.
• We employ a progressive recognition-based reference search strategy to efﬁciently ﬁnd candidates from local areas instead of the whole database.
• We leverage a robust instance-wise detection and matching technique to obtain better accuracy with fewer keypoints even under challenging conditions.
Results on long-term large-scale Aachen and RobotCar-Seasons datasets [30, 41, 42] demonstrate that our model outperforms previous approaches in terms of both efﬁciency and accuracy. We organize the rest of this paper as follows.
In Sec. 2, we introduce related works on visual localization.
In Sec. 3, our framework is described in detail. We con-duct extensive experiments in Sec. 4. The limitations and conclusions are discussed in Sec. 5 and 6, respectively. 2.