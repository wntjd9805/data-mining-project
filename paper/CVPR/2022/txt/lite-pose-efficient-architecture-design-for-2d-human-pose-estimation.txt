Abstract
Pose estimation plays a critical role in human-centered vision applications. However, it is difficult to deploy state-of-the-art HRNet-based pose estimation models on resource-constrained edge devices due to the high computational cost (more than 150 GMACs per frame).
In this paper, we study efficient architecture design for real-time multi-person pose estimation on edge. We reveal that HRNet’s high-resolution branches are redundant for models at the low-computation region via our gradual shrinking exper-iments. Removing them improves both efficiency and per-formance. Inspired by this finding, we design LitePose, an efficient single-branch architecture for pose estimation, and introduce two simple approaches to enhance the capacity of LitePose, including fusion deconv head and large kernel conv. On mobile platforms, LitePose reduces the latency by up to 5.0× without sacrificing performance, compared with prior state-of-the-art efficient pose estimation models, push-ing the frontier of real-time multi-person pose estimation on edge. Our code and pre-trained models are released at https://github.com/mit-han-lab/litepose. 1.

Introduction
Human pose estimation aims to predict each person’s key-point positions from an image. It is a critical technique for many vision applications that require understanding human behavior. Typical human pose estimation models can be cat-egorized into two paradigms: top-down and bottom-up. The top-down paradigm [7, 10, 15, 23, 38, 44, 47, 51] first detects people via an extra person detector and then performs single-person pose estimation for each detected person. In contrast, the bottom-up paradigm [5, 8, 11, 21, 22, 24, 37, 38, 40, 41] first predicts identity-free keypoints and then groups them into persons. As the bottom-up paradigm does not involve an extra person detector and does not require repeatedly run-ning the pose estimation model for each person in the image,
∗ work done while interning at MIT HAN Lab
Figure 1. LitePose provides up to 2.9× latency reduction com-pared to EfficientHRNet [36] on Qualcomm Snapdragon 855 while achieving higher mAP on COCO. Compared with Lightweight
OpenPose [39], LitePose obtains 14% higher mAP on COCO with lower latency. it is more suitable for real-time multi-person pose estimation on edge.
However, existing bottom-up pose estimation models [5, 8, 11, 21, 22, 24, 37, 38, 40, 41] mainly focus on the high-computation region. For instance, HigherHRNet [8] achieves its best performance on the CrowdPose dataset [26] with more than 150GMACs, which is prohibitive for edge de-vices. It is of great importance to design models with low computational cost while maintaining good performances.
In this paper, we study efficient architecture design for bottom-up human pose estimation. Previous study [8, 11] in the high-computation region suggests that maintaining the high-resolution representation plays a critical role in achieving good performances for bottom-up pose estimation.
However, it is unclear whether this still holds for models in the low-computation region. To answer this question, we build a “bridge” between the representative multi-branch architecture, HigherHRNet [8], and the single-branch archi-tecture by gradual shrinking (Figure 2). We surprisingly find that the performance improves as we shrink the depth of high-resolution branches for models in the low-computation region (Figure 3).
Inspired by this finding, we design a single-branch architecture, LitePose, for efficient bottom-up pose estimation. In LitePose, we use a modified Mo-bileNetV21 [43] backbone with two important improvement to efficiently handle the scale variation problem in the single-branch design: fusion deconv head and large kernel conv.
The fusion deconv head removes the redundant refinement in high-resolution branches and therefore allows scale-aware multi-resolution fusion in a single-branch way (Figure 6).
Meanwhile, different from image classification, we find large kernel convs provide a much more prominent improvement in bottom-up pose estimation (Figure 7). Finally, we apply
Neural Architecture Search (NAS) to optimize the model architecture and choose appropriate input resolution.
[26] and
COCO [28] demonstrate the effectiveness of LitePose. On
CrowdPose [26], LitePose achieves 2.8× MACs reduction and up to 5.0× latency reduction with better performance.
On COCO [28], LitePose obtains 2.9× latency reduction compared with EfficientHRNet [36] while providing better performances. experiments on CrowdPose
Extensive
We summarize our contributions as follows: 1. We design gradual shrinking experiments, revealing that the high-resolution branches are redundant for mod-els in the low-computation region. 2. We propose LitePose, an efficient architecture for bottom-up pose estimation. We also introduce two tech-niques to enhance the capacity of LitePose, including fusion deconv head and large kernel conv. 3. Extensive experiments on two benchmark datasets, Mi-crosoft COCO [28] and CrowdPose [26] demonstrate the effectiveness of our method: LitePose achieves up to 2.8× MACs reduction and up to 5.0× latency re-duction compared with state-of-the-art HRNet-based models. 2.