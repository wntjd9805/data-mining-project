Abstract
Sketching enables many exciting applications, notably, image retrieval. The fear-to-sketch problem (i.e., “I can’t sketch”) has however proven to be fatal for its widespread adoption. This paper tackles this “fear” head on, and for the ﬁrst time, proposes an auxiliary module for existing re-trieval models that predominantly lets the users sketch with-out having to worry. We ﬁrst conducted a pilot study that revealed the secret lies in the existence of noisy strokes, but not so much of the “I can’t sketch”. We consequently design a stroke subset selector that detects noisy strokes, leaving only those which make a positive contribution towards suc-cessful retrieval. Our Reinforcement Learning based for-mulation quantiﬁes the importance of each stroke present in a given subset, based on the extent to which that stroke contributes to retrieval. When combined with pre-trained retrieval models as a pre-processing module, we achieve a signiﬁcant gain of 8%-10% over standard baselines and in turn report new state-of-the-art performance. Last but not least, we demonstrate the selector once trained, can also be used in a plug-and-play manner to empower various sketch applications in ways that were not previously possible. 1.

Introduction
Thanks to the convenience of interactive touchscreen de-vices, sketch-based image retrieval (SBIR) [11, 12, 14, 38] has emerged as a practical means of image research that is complementary to the conventional text-based retrieval
[25]. Although initially developed for a category-level set-ting [42, 36, 59], of late SBIR has undertaken a ﬁne-grained shift to better reﬂect the inherent ﬁne-grained characteristics (pose, appearance detail, etc) of sketches [46, 56, 7].
Despite great strides made [3, 33, 10], the fear-to-sketch has proven to be fatal for its omnipresence – a “I can’t sketch” reply is often the end of it. This “fear” is predom-inant for ﬁne-grained SBIR (FG-SBIR), where the system dictates users to produce even more faithful and diligent
*Interned with SketchX
Figure 1: (a) While the average ranking percentile increases as the sketching proceeds from starting towards completion, unwanted sudden drops have been noticed for many individ-ual sketches due to noisy/irrelevant strokes drawn. (b) The same thing is visualised with number of samples in the third axis to get an overall statistics on QMUL-Shoe-V2 dataset. sketches than that required for category-level retrieval [11].
In this paper, we tackle this “fear” head-on and pro-pose for the ﬁrst time a pre-processing module for FG-SBIR that essentially let the users sketch without the worry of “I can’t”. We ﬁrst experimentally show that, in most cases it is not about how bad a sketch is – most can sketch (even a rough outline) – the devil lies in the fact that users typically draw irrelevant (noisy) strokes that are detrimental to the overall retrieval performance (see Section 3). This observa-tion has largely inspired us to alleviate the “can’t sketch” problem by eliminating the noisy strokes through selecting an optimal subset that can lead to effective retrieval.
This problem might sound trivial enough – e.g., how about considering all possible stroke subsets as training samples to gain model invariance against noisy strokes? Al-beit theoretically possible, the highly complex nature of this process (i.e., O(2N )) quickly renders this naive solution infeasible, especially when the number of strokes in free-hand sketches can range from an average of N = 9 to a max of N = 15 in ﬁne-grained SBIR datasets (QMUL-ShoeV2/ChairV2 [56, 46]). Most importantly, augmenting the training data by random stroke dropping would lead to a noisy gradient during training. This is because out of all possible subsets, many of these augmented sketch subsets
are too coarse/incomplete to convey any meaningful infor-mation to represent the paired photo. Therefore, instead of naively learning the invariance, we advocate for ﬁnding meaningful subsets that can sustain efﬁcient retrieval.
Our solution generally rests with detecting noisy strokes and leaving only those that positively contribute to success-ful retrieval. We achieve that by proposing a mechanism to quantify the importance of each stroke present in a given stroke-set, based on the extent to which that stroke is wor-thy for retrieval (i.e, makes a positive contribution). We work on vector sketches[4] in order to utilise stroke-level information, and propose a sketch stroke subset selector that learns to determine a binary action for every stroke – whether to include that particular stroke to the query stroke subset, or not. The stroke subset selector is designed via a hierarchical Recurrent Neural Network (RNN) that mod-els the compositional relationship among the strokes. Once the stroke subset is obtained, it is ﬁrst rasterized then passed through a pre-trained FG-SBIR model [56] to obtain a rank-ing of target photos against the ground-truth photo. The main objective is to select a particular subset that will rank the paired ground-truth photo towards the top of the ranking list. We use Reinforcement Learning (RL) based training due to the non-differentiability of rasterization operation.
As explicit stroke-level ground-truth for the optimal subset is absent, we seek to train our stroke-subset selector with the help of pre-trained FG-SBIR for reward computation.
In particular, we use the actor-critic version of proximal policy optimisation (PPO) to train the stroke subset selector.
Apart from the main objective of noisy stroke elimina-tion, the proposed method also enables a few secondary sketch applications (Section 5) in a plug-and-play manner.
First, we show that a pre-trained stroke selector can be used as a stroke importance quantiﬁer to guide users to produce a sketch “just” enough for successful retrieval. Second, we demonstrate that it can signiﬁcantly speed up existing works on interactive “on-the-ﬂy” retrieval [7] removing the need for incomplete rasterized sketch to be unnecessarily passed for inference multiple times. Third, besides beneﬁt-ing FG-SBIR, our subset selector module can also act as a faithful sketch data augmenter over random stroke dropping without much computational overhead. That is, instead of costly operation like sketch deformation [58] or unfaithful approximation like edge/contour-map as soft ground-truths
[9], users can effortlessly generate n most representative subsets to augment training for many downstream tasks.
In summary our contributions are, (a) We tackle the fear-to-sketch problem for sketch-based image retrieval for the
ﬁrst time, (b) We formulate the “can’t sketch” problem as stroke subset selection problem following detailed experi-mental analysis, (c) We propose a RL-based framework for stroke subset selection that learns through interacting with a pre-trained retrieval model. (d) We demonstrate our pre-trained subset selector can empower other sketch applica-tions in a plug-and-plug manner. 2.