Abstract
Object encoding and identification are vital for robotic tasks such as autonomous exploration, semantic scene un-derstanding, and re-localization. Previous approaches have attempted to either track objects or generate descriptors for object identification. However, such systems are lim-ited to a “fixed” partial object representation from a single viewpoint. In a robot exploration setup, there is a require-ment for a temporally “evolving” global object represen-tation built as the robot observes the object from multiple viewpoints. Furthermore, given the vast distribution of un-known novel objects in the real world, the object identifi-cation process must be class-agnostic. In this context, we propose a novel temporal 3D object encoding approach, dubbed AirObject, to obtain global keypoint graph-based embeddings of objects. Specifically, the global 3D object embeddings are generated using a temporal convolutional network across structural information of multiple frames obtained from a graph attention-based encoding method.
We demonstrate that AirObject achieves the state-of-the-art performance for video object identification and is robust to severe occlusion, perceptual aliasing, viewpoint shift, de-formation, and scale transform, outperforming the state-of-the-art single-frame and sequential descriptors. To the best of our knowledge, AirObject is one of the first tempo-ral object encoding methods. Source code is available at https://github.com/Nik-V9/AirObject. 1.

Introduction
Object encoding and identification are crucial for robotic tasks such as autonomous exploration, semantic scene un-derstanding, and loop closure in simultaneous localization and mapping (SLAM). For example, object-based seman-tic SLAM and identification of revisited objects require ro-bust and efficient object encodings [41, 45, 46]. Prior ap-proaches proposed in the literature have attempted to track object detections [47], use keypoint features [10], and gen-erate graph-based embeddings for object matching [50].
However, such systems are limited to a “fixed” object rep-Figure 1. Temporally evolving topological graph representations of objects within a video sequence. We propose a method, AirOb-ject, to match these temporally evolving representations and al-leviate problems caused by perceptually-aliased occluded single frame representations. resentation from a single viewpoint and are not robust to severe occlusion, viewpoint shift, perceptual aliasing, or scale transform. These single frame representations tend to lead to false correspondences amongst perceptually-aliased objects, especially when severely occluded. Hence, a ro-bust object encoding method that aggregates the temporally
“evolving” object structures is necessary since we often ob-serve more information when the camera or object moves, as shown in Figure 1.
In this work, we propose a novel temporal encoding ap-proach, dubbed AirObject, that encapsulates the evolving
It is topological graph-based representations of objects. very simple and only contains three modules. Specifically, we use extracted deep learned keypoint features [9] across multiple frames to form sequences of object-wise topolog-ical graph neural networks (GNNs), which on embedding generate temporal 3D object descriptors. We next employ a graph attention-based sparse encoding method on these topological GNNs to generate content graph features and location graph features representing the structural informa-tion of the object. Then, these graph features are aggregated across multiple frames using a single-layer temporal convo-lutional network to generate a temporal 3D object descrip-tor. These generated object descriptors, which accumulate knowledge across multiple evolving representations of the objects, are robust to severe occlusion, viewpoint changes, deformation, perceptual aliasing, and the scale transform.
In summary, we make the following contributions:
• To learn the geometric relationship of the keypoints, we construct topological object graphs for each frame using Delaunay triangulation.
• We introduce a simple yet effective temporal object encoding method to aggregate and embed multiple in-stances into an object descriptor.
• Extensive experiments show that AirObject consis-tently provides the state-of-the-art performance for video object identification on four large-scale datasets. 2.