Abstract
Datasets that capture the connection between vision, language, and affection are limited, causing a lack of un-derstanding of the emotional aspect of human intelligence.
As a step in this direction, the ArtEmis dataset was recently introduced as a large-scale dataset of emotional reactions to images along with language explanations of these cho-sen emotions. We observed a significant emotional bias to-wards instance-rich emotions, making trained neural speak-ers less accurate in describing under-represented emotions.
We show that collecting new data, in the same way, is not effective in mitigating this emotional bias. To remedy this problem, we propose a contrastive data collection approach to balance ArtEmis with a new complementary dataset such that a pair of similar images have contrasting emotions (one positive and one negative). We collected 260,533 in-stances using the proposed method, we combine them with
ArtEmis, creating a second iteration of the dataset. The new combined dataset, dubbed ArtEmis v2.0, has a bal-anced distribution of emotions with explanations revealing more fine details in the associated painting. Our experi-ments show that neural speakers trained on the new dataset improve CIDEr and METEOR evaluation metrics by 20% and 7%, respectively, compared to the biased dataset. Fi-nally, we also show that the performance per emotion of neural speakers is improved across all the emotion cate-gories, significantly on under-represented emotions. The collected dataset and code are available at https:// artemisdataset-v2.org. 1.

Introduction
Emotional experiences stimulated by sensory informa-tion lie at the heart of human nature. They provide a win-dow into rich yet less understood aspects of human intelli-gence. Emotions play a central role in determining humans’ internal state, and subsequently, their behavior. Thus, study-ing emotional experiences and their expression is essential in understanding human behavior. Emotions are heavily in-fluenced by external stimuli, especially vision and language.
So, it is essential to have affective datasets that capture dif-ferent modalities to study the relationship between sensory information and emotions. These datasets enable machines to comprehend emotions better and eventually increase so-cial acceptance of AI applications, especially applications which interact with humans.
Several affective datasets connecting emotions to sen-sory information have been proposed. Most notably, GoE-motions dataset [16] captured the underlying emotions be-hind Reddit comments. Its size was large enough to train deep learning models bringing machines a step closer to un-derstanding emotions. However, a major drawback of GoE-motions and similar datasets [10, 12, 13, 14] is that they attribute emotional experiences to a single stimulus.
Multi-modal datasets such as MS-COCO captions [24], and VQA [2] revolutionized the AI field and allowed ma-chines to go beyond simple text/image problems towards complex visual-language understanding tasks such as visual question answering and image captioning . These semi-nal datasets brought machines a significant step closer to human-level intelligence. Achlioptas et al. [1] recognized that affective modeling needed similar multi-modal datasets to better understand emotions and how they are constructed.
They introduced ArtEmis dataset that connects emotions, visual art, and language by collecting affective language ex-planations on visual artworks from the WikiArt dataset[29].
Dataset Bias Plous [30] suggests that biases and preju-dices are integral to humans’ evolution. He views biases as a method to optimize brain functions without the need for costly human attention. He claims that biases are created and modified by the human environment and experiences.
That is why biases are extremely difficult to eliminate, but it is only possible to minimize their impact. Naturally, hu-mans label datasets, inevitably introducing their biases in the collected data. These biases can sometimes be mild, but they can also be very problematic, especially in eth-ical judgment and applications that interact with humans
[17, 21, 31, 36]. Gino et al. [17] showed that people eth-ically condemn certain behaviors based on a bad outcome, even though the outcome is determined randomly.
Humans are usually capable of recognizing biases when they cause more harm than good. However, machine learn-ing models do not have a similar ability to detect and rea-son about biases. Therefore, if models learn from a biased dataset, they will make biased decisions. Consequently, re-ducing biases from datasets is crucial in increasing accep-tance and trust in machine learning models. It is equally important to detect biases in datasets, especially in affective datasets, used to train models that emulate human affect or interact directly with them.
Goyal et al. [18] identified a bias in VQA dataset [2] making models trained on the dataset not rely properly on the visual modality and depend only on the language modal-ity. This bias was introduced during the data collection pro-cess, and later this was observed in unexpected results from deep learning models trained on this dataset. The biased
VQA1.0 had a fundamental issue with the distribution of answers to a given question, adversely affecting the trained models. Detecting and explaining this anomaly was not triv-ial because the distribution of VQA1.0 was biased. Conse-quently, the test set was biased, and despite the evaluation, metrics were high, giving the illusion of properly trained models; these models are not suitable for practical scenar-ios since the test set is not representative of the real world.
Motivated by this, we observed that ArtEmis had a dis-crepancy in the results of trained neural speakers where a naive nearest neighbor model performed abnormally well.
The main cause of this is an unbalanced distribution of emo-tions and generic captions. The unbalanced distribution is caused by a tendency of humans to feel positive about paint-ings. ArtEmis had 62% of its captions labeled by a positive emotion compared to 26% as negative, and the rest is some-thing else. On the other hand, generic captions do not men-tion specific details about the described painting leading to less diversity among paintings with a similar style. For ex-ample, the two paintings in Fig. 1 in the bottom right corner have a similar style. In ArtEmis, the old caption describes the colors giving an overall contentment feeling and thus can match any caption from the neighborhood. On the other hand, the new caption recognizes the green patches as mold and thus elicits feelings of disgust. This detailed caption is very specific to this painting and can not be used for any neighboring painting. This diversity and attention to detail is something that ArtEmis lacks, and we attempt to solve this issue by collecting a complementary dataset using the interface we developed in Fig 2. We collect the complemen-tary data in a contrastive fashion carefully designed to alle-viate the bias in ArtEmis. Combining our complementary dataset with ArtEmis, we get a more balanced distribution of emotional labels where positive and negative emotions account for 47% and 45% of the dataset. We also show through experiments with neural speakers the superiority of this contrastive data collection method compared to expand-ing the size of ArtEmis using regular collection.
Contributions.
• We show that the data collection process of the
ArtEmis dataset results in an unbalanced distribution of emotions and generic captions, adversely affecting the quality of trained neural speakers. We also col-lect a complementary dataset using a Contrastive Data
Collection method, which alleviates the problems in
ArtEmis
• We show that the captions in the combined dataset are more representative of Semantic Space Theory fine-grained emotions as studied in GoEMotions [16].
(b) Positive emotion explanation interface. (a) Most similar paintings selection (24, only 4 shown ) (c) Negative emotion explanation interface.
Figure 2. The contrastive data collection interface. The left interface shows a painting and 24 of similar paintings from which the user selects the closest painting that elicits opposite emotions to the original one. A No Image Available option can also be chosen. Depending on the sentiment of the original painting the user will either see the positive or negative emotion captioning interface (right interface).
• We trained multiple neural speakers to reflect the ad-vantages of using contrastive data collection to com-plement ArtEmis. We show that speakers trained on our combined dataset significantly outperform speak-ers trained on ArtEmis in several aspects. 2.