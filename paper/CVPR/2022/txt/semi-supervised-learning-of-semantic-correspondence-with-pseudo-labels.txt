Abstract
Establishing dense correspondences across semantically similar images remains a challenging task due to the signif-icant intra-class variations and background clutters. Tra-ditionally, a supervised learning was used for training the models, which required tremendous manually-labeled data, while some methods suggested a self-supervised or weakly-supervised learning to mitigate the reliance on the labeled data, but with limited performance.
In this paper, we present a simple, but effective so-lution for semantic correspondence that learns the net-works in a semi-supervised manner by supplementing few ground-truth correspondences via utilization of a large amount of conﬁdent correspondences as pseudo-labels,
Speciﬁcally, our framework gener-called SemiMatch. ates the pseudo-labels using the model’s prediction itself between source and weakly-augmented target, and uses pseudo-labels to learn the model again between source and strongly-augmented target, which improves the robust-ness of the model. We also present a novel conﬁdence measure for pseudo-labels and data augmentation tailored for semantic correspondence. In experiments, SemiMatch achieves state-of-the-art performance on various bench-marks. 1.

Introduction
Establishing dense correspondences across semantically similar images, depicting different instances of the same ob-ject or scene category, can facilitate many Computer Vision applications such as semantic segmentation [42,52,61], ob-ject detection [34], or image editing [25, 33]. Unlike classi-cal dense correspondence problems such stereo matching or optical ﬂow [21, 58], semantic correspondence poses addi-tional challenges from large intra-class appearance and ge-*Equal contribution
†Corresponding author (a) Supervised loss (b) Self-supervised loss (c) Unsupervised loss (Ours) (d) Semi-supervised loss (Ours)
Figure 1. Comparison of semantic correspondence methods in terms of different formulation of supervision. Conventional methods leverage either (a) supervised loss using sparse ground-truth keypoint matches [16,43,45] or (b) self-supervised loss using synthetic ﬂow ﬁeld with random geometric parameters [40,48,63].
Unlike them, we present (c) unsupervised loss using pseudo-labels from a matching probability and (d) semi-supervised loss using both sparse ground-truth keypoints and conﬁdent pseudo-labels. ometric variations [10, 16, 23].
Although formulated in various ways, most recent ap-proaches [9,36,40,41,43,45,48,49,51,54,63,64] addressed these challenges by carefully designing deep neural net-works, such as CNNs [36, 40, 43, 45, 48, 49, 51, 54, 63, 64] or
Transformers [9, 59], based models. The most straightfor-ward way to formulate a mapping function is to use ground-truth correspondences between the image pairs. Recent ap-proaches [9, 70], including conventional approaches, have been formulated in a supervised fashion (Fig. 1a). However, ground-truth keypoint pairs on the most standard bench-marks [15,44] can be the inherent bottleneck [10,16,43,45] because they are annotated subjectively and sparsely.
To alleviate the reliance on the ground-truth data, some methods [40, 48, 63, 64] presented a self-supervised learn-ing framework (Fig. 1b), using synthetic geometric warps of an image to generate a synthetic image pair. Although it turns out that it is an appealing alternative, using synthetic image pairs cannot account for extreme intra-class appear-ance variations in semantic correspondence [48,55]. On the other hand, some other methods [20, 23, 25, 45] presented a weakly-supervised learning framework that casts this task as a feature reconstruction between the images, but the loss function often fails to explain the correspondences across severely different instances among the same class.
On the other hand, most recent approaches in image clas-siﬁcation task [3, 4, 19, 27, 57] have been popularly formu-lated in a semi-supervised learning framework, which en-ables learning the model on a large amount of unlabeled data with a few labeled data, and showed outstanding per-formance. Most recent trends of semi-supervised learn-ing [3, 4, 19, 27, 57] integrate consistency regularization [2] and pseudo-labeling [29]. For instance, FixMatch [57] ﬁrst generates a pseudo-label using the model’s prediction on weakly-augmented unlabeled data and then encourages the prediction from strongly-augmented unlabeled data to fol-low the pseudo-label with conﬁdence thresholding. This learning framework has become a promising solution to mitigate the reliance on large labeled data [18, 38, 57], but directly applying these techniques to semantic correspon-dence is challenging in that learning the matching networks requires pixel-level pseudo-labels.
In this paper, we present a novel semi-supervised learn-ing framework, called SemiMatch, that generates pixel-level pseudo-labels using the model’s prediction itself be-tween source and weakly-augmented target and then en-courages the model to predict the pseudo-label again be-tween source and strongly-augmented target, as illustrated in Fig. 2. To account for the observation that all of the pseudo-labels may not help to boost performance, we in-troduce a novel conﬁdence measure for pseudo-labels by considering object-centric foreground, forward-backward consistency, and uncertainty of probability itself. Tailored for semantic correspondence, we also present a matching-specialized augmentation that exploits a keypoint-aware cutout, helping the network to learn distinctive feature rep-resentations around the keypoints.
We evaluate our method on several benchmarks [15, 44].
Experimental results on various benchmarks show that us-ing our novel loss function with sparsely-supervised loss function consistently improves the performance compared to the latest methods for semantic correspondence. We also provide an extensive ablation study to validate and analyze components in our learning framework. 2.