Abstract
As a prerequisite of many text-related tasks such as text erasing and text style transfer, text segmentation arouses more and more attention recently. Current researches mainly focus on only English characters and digits, while few work studies Chinese characters due to the lack of pub-lic large-scale and high-quality Chinese datasets, which limits the practical application scenarios of text segmenta-tion. Different from English which has a limited alphabet of letters, Chinese has much more basic characters with com-plex structures, making the problem more difficult to deal with. To better analyze this problem, we propose the Bi-lingual Text Segmentation (BTS) dataset, a benchmark that covers various common Chinese scenes including 14, 250 diverse and fine-annotated text images. BTS mainly focuses on Chinese characters, and also contains English words and digits. We also introduce Prior Guided Text Segmen-tation Network (PGTSNet) , the first baseline to handle bi-lingual and complex-structured text segmentation. A plug-in text region highlighting module and a text perceptual dis-criminator are proposed in PGTSNet to supervise the model with text prior, and guide for more stable and finer text seg-mentation. A variation loss is also employed for suppress-ing background noise under complex scene. Extensive ex-periments are conducted not only to demonstrate the neces-sity and superiority of the proposed dataset BTS, but also to show the effectiveness of the proposed PGTSNet compared with a variety of state-of-the-art text segmentation methods. 1.

Introduction
Text segmentation is a fundamental and important task in computer vision. Different from other segmentation tasks such as semantic segmentation and instance segmentation, it is required to parse text instead of objects from complex scenes. With the text mask, it can be applied to various downstream tasks including scene text removal for cover generation and material recreation, font style transfer for
*Corresponding author.
Figure 1. The top block: example images and annotations from the proposed BTS dataset. From left to right are images, character-level bounding boxes, word-level bounding boxes, and pixel-level segmentation masks. The left bottom block: qualitative results.
From top to down are original image, result using the SOTA method (TexRNet [66]) trained on only English dataset (TextSeg
[66]), result using TexRNet trained on TextSeg and our bi-lingual dataset BTS, and result using our proposed method PGTSNet trained on TextSeg and BTS. The right bottom block: quanti-tative results on the testing set of the bi-lingual dataset. The circle represents the SOTA method TextRNet; the square represents dif-ferent variations of our proposed PGTSNet. The points below the dash line are results using only English dataset TextSeg, and using
TextSeg with a synthetic bi-lingual dataset, respectively; the points above the dash line are results using TextSeg with our bi-lingual dataset BTS. The results demonstrate that the fine-annotated bi-lingual dataset is necessary, which improves the performance of the existing SOTA method with a large margin, and boosts the overall performance in the area of bi-lingual text segmentation to a new level.
AI design, interactive text image editing, etc.
Text segmentation presents two distinct characteristics.
First, as the strokes and structure of text are looser and inco-herent (unlike object segmentation), it is more challenging to capture fine-grained features of every stroke in a word.
For example, some strokes like the lowercase L or the dot on
with unsatisfying labeling quality [6, 7]. In a smaller scale,
TextSeg [66] is proposed to fills the blank of segmentation in the area of artistic design and text effects. However, all these datasets contain only common English characters and numbers, and few work studies Chinese characters without any Chinese large-scale and high-quality datasets released, which limits the practical application scenarios of text seg-mentation.
To fill the above-mentioned research gaps of limited character types and extend the text segmentation to sup-port more scenes and languages, we propose Bi-lingual Text
Segmentation (BTS), a new text segmentation dataset. The diversity of BTS can be described at three levels: (1) scene-it covers common life scenes including level diversity: street signs, shop signs, plaques, attractions, book covers, banners, and couplets; (2) image-level diversity: appear-ances and geometric variances caused by camera-captured settings and background distractions such as perspective, illumination, resolution, partly blocking, blur and so on, in total including 14, 250 fine-annotated text images; (3) character-level diversity: variances of character categories, up to 3, 985 classes including Chinese characters, English letters, digits, common punctuation with varied fonts and sizes. Image examples and their segmentation annotations in BTS dataset are shown in Fig. 1 and Fig. 2. From Fig. 1 we can see that the fine-annotated bi-lingual dataset can beat the synthetic bi-lingual dataset, improve the performance of the existing SOTA method with a large margin, and boost the overall performance in the area of bi-lingual text seg-mentation to a new level.
Most of the text segmentation methods inherit semantic or instance segmentation and perform mask level supervi-sion, while unaware of the global structure information of the characters. Therefore we turn to the recognition model for prior guidance to help the model regain the global struc-ture of a character. We propose a novel approach, named as the Prior Guided Text Segmentation Network (PGTSNet) to better deal with bi-lingual text segmentation with text prior guidance. In this study, the main contributions can be sum-marized in four folds:
• We propose BTS, the first large-scale bi-lingual text segmentation dataset that goes beyond English words and digits including also Chinese characters. BTS pro-vides annotations of text region, transcripts and the text masks, and therefore can be used not only for text seg-mentation but also for text detection, recognition, and end-to-end text spotting. We prove the superiority of the proposed dataset BTS by comparing and analyzing the methods trained on BTS and a synthetic dataset.
• To better handle text distribution in different scenes, we propose a simple yet effective module to highlight the text region and serve as the prior to boost the text segmentation performance.
Figure 2. Samples and their segmentation annotations of several mainstream scenes from the proposed BTS dataset, including the street sign, the banner, the couplet, the cover of book, the plaque, the shop sign, and the attraction. the top of the lowercase I, or when the character shares sim-ilar features with common background such as the check-ered floor or black dot, are easy to be ignored in pixel level segmentation. The situation can be further worse with the
Chinese characters. Different from sequentially arranged
English words, a Chinese character is formed with stroke combinations in spatial dimension, which thus leaves dis-continuous segmentation hollow within the characters. Sec-ond, different from the semantic and instance segmentation which usually contain multiple categories, text segmenta-tion is usually treated as a binary classification problem. It treats all different characters the same foreground category, and ignores the semantic variance contained in the charac-ters. Xu et al. [66] has proved the significance of using the character prior in enhancing the English text segmenta-tion. However, English has a small-sized alphabet of letters, while Chinese has much more basic characters (e.g., over 3, 000 commonly used ones) with complex structure forma-tions, making the problem more difficult to deal with. How to utilize the priors of text to make better segmentation is worth exploring.
To obtain high-quality segmentation for down-stream tasks, sufficient well-annotated training data is necessary.
However, modern text segmentation datasets as well as methods are still left behind. First introduced as a public challenge [27], text segmentation developed slowly in the past few years with few research works and datasets pro-posed [6, 7, 13]. Among whom, large-scale datasets are
• We introduce a plug-in text recognition module as a prior to supervise for more stable and better text seg-mentation, whose advantage has been verified espe-cially in the segmentation of large-sized text.
• We adopt the total variation loss in the text segmenta-tion task, which exhibits the advantages in suppressing the ambient noises, and is able to supervise the PGT-SNet to produce more smooth masks. 2.