Abstract
The promise of active learning (AL) is to reduce labelling costs by selecting the most valuable examples to annotate from a pool of unlabelled data. Identifying these examples is especially challenging with high-dimensional data (e.g. images, videos) and in low-data regimes. In this paper, we propose a novel method for batch AL called ALFA-Mix. We identify unlabelled instances with sufﬁciently-distinct fea-tures by seeking inconsistencies in predictions resulting from interventions on their representations. We construct interpo-lations between representations of labelled and unlabelled instances then examine the predicted labels. We show that inconsistencies in these predictions help discovering features that the model is unable to recognise in the unlabelled in-stances. We derive an efﬁcient implementation based on a closed-form solution to the optimal interpolation causing changes in predictions. Our method outperforms all recent
AL approaches in 30 different settings on 12 benchmarks of images, videos, and non-visual data. The improvements are especially signiﬁcant in low-data regimes and on self-trained vision transformers, where ALFA-Mix outperforms the state-of-the-art in 59% and 43% of the experiments respectively1. 1.

Introduction
The success of machine learning applications depends on the quality and volume of the annotated datasets. High quality data annotations can be slow and expensive. Ac-tive learning (AL) aims to actively select the most valuable samples to be labelled in the training process iteratively, to boost the predictive performance. A popular setting called batch AL [34] ﬁxes a budget on the size of the batch of instances to be sent to an oracle for labelling. The process is repeated over multiple rounds, allowing the model to be updated iteratively. The core challenge is therefore to iden-tify the most valuable instances to be included in this batch at each round, depending on the current model. 1The available aminparvaneh/alpha_mix_active_learning code is at https : / / github . com /
Figure 1. We propose to form linear combinations (i.e. interpola-tions or mixing) of the features of an unlabelled instance (middle image) and of labelled ones (top and bottom images). The in-terpolated features are passed through the current classiﬁer. We show that inconsistencies in the predicted labels indicate that the unlabelled instance may have novel features to learn from.
Various AL strategies have been proposed differing in predicting (1) how informative a particular unlabelled in-stance will be (i.e. uncertainty estimation [12, 15, 31, 38]) or (2) how varied a set of instances will be (i.e. diversity estima-tion [33, 39]), or both [2, 17, 19]. Recent deep learning based
AL techniques include, for example, the use of an auxiliary network to estimate the loss of unlabelled instances [40], the use of generative models like VAEs to capture distribu-tional differences [20,35], and the use of graph convolutional networks to relate unlabelled and labelled instances [5].
Despite much progress made, current AL methods still struggle when applied to deep neural networks, with high-dimensional data, and in a low-data regime. We hypoth-esised that the representations learned within deep neural networks may be leveraged to reason about the model’s un-certainty while alleviating the challenges associated with high-dimensional data. Some existing methods only con-sider the model’s output, but we believe that this cannot convey a complete picture of the model’s current state. As-sessing the uncertainty in the model is particularly important in a low-data regime since the number of available training
(a) ALFA-Mix (ours) (b) CDAL (ECCV 2020) [2] (c) BADGE (ICLR 2020) [3] (d) GCNAL (CVPR 2021) [5] (e) CoreSet (ICLR 2018) [33] (f) BALD (ICML 2017) [15]
Figure 2. Visualization of sample selection behaviours of various AL methods in the latent space (see the Appendix for additional methods). The larger dots represent the selected samples to label; smaller dots represent unlabelled ones. Our approach ﬁnds a candidate set (demonstrated by stars in 2a) of unlabelled instances with inconsistencies in their label prediction when interpolated with labelled representations. It selects a diverse set of samples lying close to the all four borders for the labelling (with three zoom-in windows). The demonstration problem is that of identifying 4 classes from MNIST (illustrated above by 4 colours) using a MLP. An initial training set of 200 randomly selected points and their labels was provided, with each method given a budget of 200 additional labels. The features are projected to two-dimensions for visualization. examples is small. This motivation has led to methods like
BADGE [3] which uses gradients through the classiﬁer layer of the network. Besides its relatively poor performance in lo-data regimes [3], the drawback is a high computational cost due to the high dimensionality of the gradient embeddings, making the method impractical for deep models with latent representations of high dimensions, large datasets, and large numbers of classes.
In this paper, we present a novel and efﬁcient AL method, named Active Learning by FeAture Mixing (ALFA-Mix), based on the manipulation of latent representations of the data. We identify informative unlabelled instances by eval-uating the variability of the labels predicted for perturbed versions of these instances. These perturbed versions are instantiated in feature space as convex combinations of unla-belled and labelled instances (see Figure 1). This approach effectively explores the neighbourhood surrounding an un-labelled instance by interpolating its features with those of previously-labelled ones. Convex combinations of features have been already used in other contexts such as data aug-mentation, using random interpolations [36, 37, 41, 42] or actual solutions to an optimisation problem [1, 29].
We provide a theoretical support for the method. In par-ticular, under a norm-constraint on the interpolation ratio, we show that the interpolation is equivalent to considering (1) the difference between the features of the unlabelled instance and the labelled ones and (2) the gradient of the model w.r.t the features at the unlabelled point. Discovering new features considering (1) and (2) leads us to ﬁnding an optimal interpolated point deterministically, at a minimal computing cost. Rather than using all the labelled data for these interpolations, we choose a subset we call anchors to capture the common features for each class. Subsequently, we construct a candidate set by choosing the instances from the unlabelled set that when mixed with these anchors lead to a change in the model’s prediction for those instances. Then, to ensure selected instances are diverse, we perform a simple clustering in the candidate set and choose their centroids as the points to be queried.
The contributions of this paper are as follows.
• Instead of interrogating an unlabelled instance directly, we interpolate its representation features from the labelled instances to uncover its hidden traits. To the best of our knowledge, it is the ﬁrst of its kind in AL. Unlike existing methods that reply solely on the predicted output, we har-ness useful information from the feature representations as an indication of which features are novel for the model.
• We show that optimal interpolation/mixing for each in-stance that underscores the novel features with which the model could change prediction, has a closed-form solution making our approach efﬁcient and scalable.
• We show that our approach outperforms its counterparts
over 9 image, 2 OpenML, and one video datasets in var-ious settings of architecture, network initialisation, and budget choice. Our approach consistently achieves higher accuracy than existing methods, with particularly signiﬁ-cant gains in a low-data regime.
• We provide the ﬁrst investigation into using AL in vision transformers: we demonstrate the effectiveness of ALFA-Mix on a self-trained vision transformer [6], performing better than random selection in all tests, and 43% better than the state-of-the-art. In addition, our approach per-forms signiﬁcantly better that its counterparts for video classiﬁcation using transformers [14]. 2.