Abstract
The key challenge for few-shot semantic segmentation (FSS) is how to tailor a desirable interaction among sup-port and query features and/or their prototypes, under the episodic training scenario. Most existing FSS methods im-plement such support/query interactions by solely leverag-ing plain operations – e.g., cosine similarity and feature concatenation – for segmenting the query objects. How-ever, these interaction approaches usually cannot well cap-ture the intrinsic object details in the query images that are widely encountered in FSS, e.g., if the query object to be segmented has holes and slots, inaccurate segmentation al-most always happens. To this end, we propose a dynamic prototype convolution network (DPCN) to fully capture the aforementioned intrinsic details for accurate FSS. Specifi-cally, in DPCN, a dynamic convolution module (DCM) is firstly proposed to generate dynamic kernels from support foreground, then information interaction is achieved by con-volution operations over query features using these kernels.
Moreover, we equip DPCN with a support activation mod-ule (SAM) and a feature filtering module (FFM) to generate pseudo mask and filter out background information for the query images, respectively. SAM and FFM together can mine enriched context information from the query features.
Our DPCN is also flexible and efficient under the k-shot FSS setting. Extensive experiments on PASCAL-5i and COCO-20i show that DPCN yields superior performances under both 1-shot and 5-shot settings. 1.

Introduction
Semantic segmentation has achieved tremendous success due to the advancement of deep convolutional neural net-works [9, 10, 22]. Nevertheless, most leading image se-mantic segmentation models rely on large amounts of train-ing images with pixel-wise annotations, which require huge human efforts. Semi- and weakly-supervised segmentation methods [15, 24, 28] are proposed to alleviate such expen-*Equal contribution.
†Corresponding author.
Figure 1. Comparison between (a) existing prototype-based methods and (b) proposed DPCN. (a) Existing methods usually adopt mask average pooling or clustering on support foreground to get multiple foreground/background prototypes. Then the in-formation interaction between support and query can be plain op-erations, e.g., cosine similarity, element-wise sum, and channel-wise concatenation. However, this paradigm fails to segment the intrinsic details of plants, because this insufficient interaction can-not well address the appearance and shape variations (e.g., holes and slots in the plants) in FSS. (b) Our DPCN can well segment plants and capture the intrinsic subtle details. This benefits from dynamic convolution on query features with dynamic kernels gen-erated from the support foreground features. sive annotation cost. However, both semi- and weakly-supervised methods have to face a significant performance drop when only a few annotated samples for a novel object are available. In such a case, few-shot semantic segmenta-tion (FSS) [20] is introduced to allow for dense pixel-wise prediction on novel object categories given only a few an-notated samples.
Typically, most FSS methods adopt an episode-based meta-learning strategy [30], and each episode is composed of the support set and the query set, which share the same object class. The support set contains a few support im-ages with pixel-wise annotation. FSS models are expected to learn to predict the segmentation mask for images in the query set with the guidance of the support set. Learning is based on episodes available with annotations during train-ing. At test time, the model is expected to segment a query
image with respect to a class of interest, again provided with corresponding support set, only this time the class of inter-est in the query and support set is novel and not previously seen. the most
Currently, leading FSS methods are the prototype-based ones [12, 25]. As in Fig. 1(a), prototype-based paradigm typically generates multiple foreground and/or background prototypes by utilizing mask average pooling and/or clustering over support features. These pro-totypes are supposed to contain representative information of the target object in the support images, thus their interac-tions with query features by cosine similarity, element-wise summation, and feature concatenation can produce neces-sary predictions for the objects in the query image. How-ever, the predictions achieved by solely relying on such lim-ited prototypes and plain operations are inevitably losing some intrinsic object details in the query image. For in-stance, as in Fig. 1(a), since the objects plants have holes and slots which are intrinsic details, the segmented ob-jects cannot well cover these details, i.e., a defective over-segmentation is achieved in this case.
In addition, in the presence of large object variations (e.g., appearance and scale) in FSS, it is usually difficult to comprehensively en-code the adequate patterns of the target objects by solely considering the support information as in most previous prototype-based methods.
To address the above challenges, we propose a dynamic prototype convolution network (DPCN) to fully capture the intrinsic object details for accurate FSS. DPCN belongs to prototype-based methods yet with several elegant exten-sions and merits. Specifically, we first propose a dynamic convolution module (DCM) to achieve more adequate inter-action between support and query features, thus leading to more accurate prediction for the query objects. As in Fig. 1(b), we leverage three dynamic kernels, i.e., a square ker-nel and two asymmetric kernels, generated from the support foreground features. Then three convolution operations are employed in parallel onto the query features using these dy-namic kernels. This interaction strategy is simple yet impor-tant to comprehensively tackle large object variations (e.g., appearance and scales) and can capture the intrinsic object details. Intuitively, the square kernel is capable of capturing the main information of an object (e.g., main body of the plant in Fig. 1(b)); By contrast, asymmetric kernels (i.e., kernel with size d × 1 or 1 × d aim to capture the subtle object details, e.g., leaves in Fig. 1(b). As such, DPCN equipped with DCM can better handle the intrinsic object details using an extremely simple way.
Moreover, to comprehensively encode the adequate pat-terns of the target objects, we propose a support activa-tion module (SAM) and a feature filtering module (FFM) to mine as much object-related context information from query image as possible. Specifically, SAM generates sup-port activation maps and initial pseudo query mask using high-level support and query features. Then the support prototypes and pseudo query foreground features are fused to generate a refined pseudo mask for the query image in
FFM. Compared with the original pseudo query mask, the refined one contains more object foreground context while filtering some noise information. Therefore, rich object-related context information from both support and query images are aggregated to the final feature, leading to bet-ter segmentation performance. Our main contributions are as follows:
• We propose a dynamic prototype convolution network (DPCN) to capture the intrinsic object details for accurate
FSS. To the best of knowledge, we are the first one to do this in the FSS domain.
• We propose a novel dynamic convolution module (DCM) to achieve adequate support-query interactions.
DCM can serve as a plug-and-play component to improve existing prototype learning methods.
• We propose a support activation module (SAM) and a feature filtering module (FFM) to mine complementary information of target objects from query images. 2.