Abstract
A mass of experiments shows that the pose of the in-put 3D models exerts a tremendous influence on automatic 3D shape analysis. In this paper, we propose Upright-Net, a deep-learning-based approach for estimating the upright orientation of 3D point clouds. Based on a well-known pos-tulate of design states that ”form ever follows function”, we treat the natural base of an object as a common functional structure, which supports the object in a most commonly seen pose following a set of specific rules, e.g. physical laws, functionality-related geometric properties, semantic cues, and so on. Thus we apply a data-driven deep learn-ing method to automatically encode those rules and formu-late the upright orientation estimation problem as a classi-fication model, i.e. extract the points on a 3D model that forms the natural base. And then the upright orientation is computed as the normal of the natural base. Our proposed new approach has three advantages. First, it formulates the continuous orientation estimation task as a discrete classi-fication task while preserving the continuity of the solution space. Second, it automatically learns the comprehensive criteria defining a natural base of general 3D models even with asymmetric geometry. Third, the learned orientation-aware features can serve well in downstream tasks. Results show that our network outperforms previous approaches on orientation estimation and also achieves remarkable gener-alization capability and transfer capability. 1.

Introduction
The upright orientation of an object is associated with its most commonly seen pose in daily life. Such pose usu-ally serves multiple objectives such as functionality, stabil-ity, semantic meaning, facility, and so on. Posing object in their upright orientation is the human preference since it makes the objects easily recognizable [12].
⋆ Co-first authors, (cid:66) Co-corresponding authors
In computer graphics and computer vision, registering objects in upright orientation is usually the first step for 3D model analysis [26,27], which benefits applications like shape matching [1], shape retrieval [19], robotic manip-ulation on object placement problems [13], generation of thumbnails for 3D shape repositories [11], and so on. With the thriving of deep learning, neural networks operating on point clouds have shown superior performance on these tasks. However, their performance is usually evaluated on a dataset aligned in a canonical frame. A key challenge in learning unaligned point cloud data is to learn features that are invariant or equivariant with respect to geometric trans-formations [26]. However, either T-Net in PointNet [15] or ITN [26] is not significantly contributive to performance due to their weak supervision on pose transformation. Thus, orientation estimation is used as an auxiliary task for com-puter graphics tasks, such as shape classification and key-point prediction [14], to achieve strongly supervised pose transformation.
However, it is an open challenge to recover the upright orientation for general 3D models because of two reasons.
Firstly, determining the upright orientation of a 3D object requires a comprehensive consideration of physical laws, geometric properties, semantic preference, functionality, design knowledge, and so on. Thus it is hard to define a universal rule to upright general 3D shapes effectively [12].
For example, paper [5] tried to infer the upright orientation of a 3D model based on a series of hand-crafted geometrical features, however, it failed on some models due to the bias or conflict among features. Secondly, estimating the upright orientation is intuitively a continuous rotation problem, for which, however, the convergence of solutions is fragile due to the diverse variation between different shape categories.
Although the divide-and-conquer scheme [12], which first classifies the object and then estimates the orientation via a regression model, achieves an acceptable result, it is not an ideal solution to train separate regression models for differ-ent categories.
In this paper, we convert the continuous orientation prob-lem into a discrete classification problem based on our ob-servation that objects with mostly commonly seen upright poses are usually supported by their natural bases, where the surface or points contact the supporting plane. Our key idea is to extract points on a 3D model that forms the natural base and then compute its upright orientation as the normal of the fitted plane over the base points, that point to the object.
We propose a data-driven deep learning method to auto-matically extracts a comprehensive feature description that provides sufficient discrimination power for general upright orientation detection. Our method has three advantages.
First, formulating the continuous orientation problem as a discrete classification problem improves the generalization ability of the solution. Second, different from hand-crafted features, our deep-learning-based approach automatically encodes comprehensive criteria that define the natural base.
Third, by learning orientation-aware features, we can com-press the feature space and boost the performance in down-stream tasks. Our experiment results indicate that Upright-Net outperforms previous approaches on orientation estima-tion, and demonstrate remarkable generalization ability and transfer capability. 2.