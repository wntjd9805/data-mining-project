Abstract
In the biological visual pathway especially the retina, neurons are tiled along spatial dimensions with the electri-cal coupling as their local association, while in a convolu-tion layer, kernels are placed along the channel dimension singly. We propose convolution of convolution, associat-ing kernels in a layer and letting them collaborate spatially.
With this method, a layer can provide feature maps with ex-tra transformations and learn its kernels together instead of isolatedly.
It is only used during training, bringing in negligible extra costs; then it can be re-parameterized to common convolution before testing, boosting performance gratuitously in tasks like classiﬁcation, detection and seg-mentation. Our method works even better when larger re-ceptive ﬁelds are demanded. The code is available on site: https://github.com/Genera1Z/ConvolutionOfConvolution. 1.

Introduction
In the most recent decades, deep learning methods have been greatly promoting the performance of algorithms on various computation vision (CV) tasks. Particularly, the convolution operation in convolution neural networks (CNNs) is of great importance because of its powerful ca-pability in feature extraction.
For gains in performance or efﬁciency, various ways have been tried to improve the convolution operation. The very early efforts are light convolution, by lowering connec-tivities in the channel [1,10,30] or space [19,31,33], or both
[34]. The following trials are increasing the freedom of ker-nel shape or value [5, 17, 42]. The most recent are dynamic weights generated by the inputs [18, 27, 40]. Some draw attention or multi-scale into convolution [4, 9, 12, 22, 39], which are more like blocks.
In modeling the retina and subsequent visual pathway, as shown in Fig. 1 [11,36], these methods are no different from the standard convolution: different populations of neurons
∗Corresponding author.
Figure 1. Current convolutions succeed in modeling many key features of the retina, except the electrical synapses. The electrical synapses among close neurons of different types have not been realized yet. We address this by employing the spatial association (vertical red arrows on the left) on kernels within a layer. are modeled as different convolution layers; connections be-tween populations, i.e., chemical synapses, are modeled as weights connecting different layers; different neuron types within a population are modeled by different kernels within a layer, while neurons of the same type are modeled by one same kernel shared over spatial dimensions; the electrical synapses among close neurons (red arrows on Fig. 1 right), however, is not well handled.
The electrical sysnapses provide the electrical coupling effect that neural signals are transduced instantly in local ar-eas. And such an effect also plays an important role in coor-dinating neighboring neurons to perform visual perception all together [11,36], which we believe should not be ignored in CNNs’ implementation.
The electrical synapses among close neurons of the same type, in current methods, are implicated in the spatial over-lap of those neighboring convolution sliding windows (hor-izontal red arrows on Fig. 1 left) of one single kernel within a layer; the electrical sysnapses among close neurons of dif-ferent types have not been realized yet.
Inspired by this, we propose the method “convolution of convolution” (CoC), where spatial associations among ker-nels (vertical red arrows on Fig. 1 left) within a layer are
It can seam-employed to let them collaborate spatially. lessly replace current kinds of convolution layers. It only brings in negligible extra costs during training, then can be re-parameterized to the original convolution version once
ﬁnished, which gives various networks re-built of CoC gra-tuitous performance gains during testing.
Our contributions are: (1) Proposing method CoC, opening up a new way of thinking for other works to follow up; (2) Realizing an association to let kernels collaborate spatially for better feature extraction; (3) Conducting detailed ablation studies on how hyper-parameters affect CoC’s performance; (4) Evaluating CoC on various backbones and vision tasks to demonstrate its superiority. 2.