Abstract
We propose a principled and practical method for out-of-distribution (OoD) detection with deep hybrid models (DHMs), which model the joint density p(x, y) of features and labels with a single forward pass. By factorizing the joint density p(x, y) into three sources of uncertainty, we show that our approach has the ability to identify samples semantically different from the training data. To ensure computational scalability, we add a weight normalization step during training, which enables us to plug in state-of-the-art (SoTA) deep neural network (DNN) architectures for approximately modeling and inferring expressive probabil-ity distributions. Our method provides an efficient, general, and flexible framework for predictive uncertainty estima-tion with promising results and theoretical support. To our knowledge, this is the first work to reach 100% in OoD de-tection tasks on both vision and language datasets, espe-cially on notably difficult dataset pairs such as CIFAR-10 vs. SVHN and CIFAR-100 vs. CIFAR-10. This work is a step towards enabling DNNs in real-world deployment for safety-critical applications. 1.

Introduction
One significant obstacle to deploying DNN models in real-world applications is that deep learning systems often break down in novel situations. Specifically, DNNs tend to yield unreliable predictive uncertainty estimates and make high-confident yet incorrect predictions when exposed to inputs drawn from unfamiliar distributions. Therefore, ac-curate quantification of predictive uncertainty of DNNs is critical in high-stake applications such as medical diag-nosis [16, 87], self-driving vehicles [20, 45], and financial decision-making [65], where silent mistakes can lead to catastrophic consequences.
Suppose that the training data come from the distribu-tion p(y, x), where y denotes labels and x denotes features.
The majority of the literature uses DNNs to model the con-ditional distribution p(y|x), which has achieved impressive performance when the test data are restricted to p(y, x)
Figure 1. The histograms of log p(x) for both in-distributional (CIFAR-10) and OoD datasets (CIFAR-100 and SVHN).
[12, 24, 99, 100]. However, when faced with OoD test sam-ples x* drawn from a different distribution, p(y|x*) often yields incorrect predictions with low uncertainties, result-ing in silent failures. The main reason for this phenomenon is that p(y|x*) does not fit a probability distribution over the whole (x, y) space. This motivates the need for a fam-ily of models endowed with a meaningful notion of proba-bility over (x, y): deep hybrid models (DHMs), which aim to learn the joint distribution p(y, x) = p(y|x)p(x). Since p(y, x) is a probability distribution which integrates to one over its support, p(y, x*) is automatically decreased after maximizing the probability of the in-distributional (ID) data during training. As a result, even though p(y|x*) might yield an incorrect label, p(y|x*)p(x*) should be a small value suggesting a high predictive uncertainty and an alarm-ing signal for potentially wrong predictions.
This paper aims to construct a family of DHMs that are computationally efficient and practically effective for de-tecting OoD samples. However, we face two main chal-lenges. The first challenge is the model’s expressibility and computational scalability. Constructing a DHM usually re-quires modeling p(y|x) and p(x) with two DNNs sharing a subset of their parameters [8, 44, 47, 50, 53, 69, 76, 77, 85].
Training a high-fidelity DHM on high dimensional data is difficult typically because p(x) often underfits, and proba-bilistic inference for flexible p(x) is usually computation-Figure 2. This figure (adapted and redrawn from [29]) illustrates the basic structure of our proposed DHMs. The data manifold M embedded in Rn is mapped, under an approximately volume-preserving mapping ϕ, to the low dimensional embedding space Rm(m < n), where an NF learns to capture its probability density and a discriminator learns to distinguish semantically different objects. ally expensive. Recently, normalizing flows (NFs) [15, 79] have been adopted to model p(x) [42, 72] due to their great promise for modeling complex distributions. A standard
Euclidean NF is a transform ϕ : Rn → Rn that maps the data points x to their latent embeddings h equipped with a tractable base density p(h), where the density p(x) can be computed in closed-form: p(x) = p(h)|det Jϕ|.
However, this result requires the NF ϕ to be invertible and dimension-preserving, imposing significant structural constraints on ϕ and limiting the model’s expressibility
[4, 13, 14, 21, 23, 32, 41, 46, 84]. To overcome the limita-tions on the dimensionality, a few attempts have been made to generalize NFs from Euclidean spaces to Riemannian manifolds where |det Jϕ| becomes a pseudo determinant (cid:113)
ϕ Jϕ| [11, 29, 43, 68]. However, to make computing the pseudo determinant tractable (yet still very expensive), additional restrictions are usually placed on ϕ, significantly limiting the model’s expressiveness and performance.
|det J T
The second challenge is that NFs tend to learn low-level features of their inputs, such as simple graphical structures for image data, rather than high-level semantic information
[48]. This is due to the fact that the features learned by NFs are primarily aimed at reconstructing the inputs rather than distinguishing semantically different objects, such as a cat and a dog. Although the semantic structures of ID and OoD data are generally different, they may share common low-level features. As a result, NFs, in general, fail to detect
OoD samples.
In this paper, we introduce a simple and effective method to deal with both challenges. First, to relax the dimension-preserving requirement of ϕ while also circumventing the expensive step of computing the pseudo determinant, we replace the invertible mapping ϕ with a bi-Lipschitz con-tinuous DNN ϕ : Rn → Rm by applying spectral nor-malization [70] to its weights. A bi-Lipschitz continuous function is distance-preserving and bijective (restricted to its image) but has no restrictions on the dimensionality of its output layer. This property enables us to use SoTA DNN architectures to obtain geometry-preserving and low dimen-sional representations of the inputs x, namely h = ϕ(x). We show that a bi-Lipschitz continuous function ϕ also approx-imately preserves the measure, intuitively the local volumes of the data manifold, implying that p(x) ≈ p(h). Second, to capture the density of h, we add a Euclidean NF f : h (cid:55)→ z on top of it, where z ∼ N (0, I). In order for ϕ to learn high-level semantic features of its inputs x, we also add a fully connected layer as a discriminator c : h (cid:55)→ y. The structure of our proposed DHMs is illustrated in Figure 2.
While the lack of restrictions on ϕ increases a DHM’s expressivity, a DHM is computationally efficient because it only requires one feed-forward pass to obtain both p(y|x) and p(x) without the expensive step of calculating the pseudo determinant. By learning a joint embedding h for both the density estimator f and the discriminator c, a DHM improves the discriminative expressiveness of the features.
Therefore, the density estimator f is built on high-level fea-tures and thus able to distinguish objects that are semanti-cally different from the training data. To our knowledge, this is the first work to reach 100% in OoD detection tasks on both vision and language datasets. This work is a step to-wards enabling DNNs in real-world deployment for safety-critical applications since any result lower than 100% still provides no safety guarantee.
Contributions: 1: in Section 2, we introduce a novel un-certainty factorization: factorizing p(y, x) into three sources of uncertainty.
It provides theoretical support for DHMs to do OoD/anomaly detection. 2: we propose one type of
DHMs that is both computationally efficient and practically effective for OoD detection. 2. Uncertainty Factorization
Notation and Problem Setup We assume that the train-ing data D = {xi, yi}N i=1 are generated from a joint dis-tribution p(y, x). The features {xi}N i=1 are i.i.d. samples of a random variable x ∈ Rn that takes values on a low-dimensional manifold M (equipped with a metric ∥.∥M) diffeomorphic to Rm with typically m < n (the well-known manifold hypothesis). Our goal is to train a DHM p(y, x; θ) = p(y|x; θ)p(x; θ) parameterized by θ to generate reliable predictive uncertainty estimates that can be used to detect OoD samples x*.
2.1. Different Types of Uncertainty
In machine learning modeling, there are two types of uncertainty that are crucial to distinguish: aleatoric uncer-tainty and epistemic uncertainty [83]. Aleatoric uncertainty, or data uncertainty, arises due to the inherent randomness of the data generating mechanism, which is not reducible by observing more data points. On the other hand, epistemic uncertainty describes the uncertainty due to the lack of data and knowledge. It can be sufficiently reduced theoretically as the size of training data grows to infinity. A model’s epistemic uncertainty mainly comes from two sources [60]: parametric uncertainty, or model uncertainty, which mea-sures the uncertainty in estimating the model parameters under the current model specification, and distributional uncertainty that arises due to the discrepancy between the training and test distributions. A well-calibrated model should assign higher distributional uncertainty to OoD sam-ples than to ID samples. 2.2. Uncertainty Factorization
What Is a Good Uncertainty Factorization? In the literature of uncertainty factorization, the main goal is to factorize the model into two or three types of uncertainty so that we can directly access the uncertainty information once we learn the model. First, we want the uncertainty factor-ization to be general and natural so that it can be used in a wide variety of models. Second, a good uncertainty factor-ization should be semantically accurate, which means that the results should be aligned with the definitions described in Section 2.1.
The existing literature [19, 59, 67] focuses on factorizing the posterior predictive distribution p(y|x, θ, D). The main shortcoming of this approach is that the proposed factoriza-tions are often complicated and not general, only suitable for specific models. Furthermore, many factorizations fail to correctly capture the semantics of different sources of uncertainty described in Section 2.1. A more detailed liter-ature review is presented in Appendix A.
Our Proposed Uncertainty Factorization Instead of factorizing the posterior predictive distribution p(y|x, θ, D), we propose to factorize the posterior joint distribution p(y, x, θ|D) into three sources of uncertainty. We assume that x is independent of θ. This assumption is generally valid for the following reason: θ is trained from the data D; thus, θ is dependent on D. However, in our problem set-tings, x can be OoD, which means that the distribution of x is independent of (can be different from) the distribution of the data D. Therefore, x is independent of θ. With this as-sumption, the posterior joint distribution can be factorized as follows: p(y, x, θ|D) = p(y|x, θ) (cid:124) (cid:123)(cid:122) (cid:125) data p(x|D) (cid:124) (cid:123)(cid:122) (cid:125) distributional p(θ|D) (cid:124) (cid:123)(cid:122) (cid:125) model (1) p(y|x, θ) is the aleatoric uncertainty which measures the in-trinsic randomness of y at a particular point x; p(x|D) rep-resents the distributional uncertainty, reflecting how likely it is to see a new point x in light of the training data D; p(θ|D) is the parametric uncertainty which can be reduced to a Dirac delta function (point estimate) given infinite data points.
This uncertainty factorization is quite neat and seman-tically accurate. More importantly, it is also quite general since it does not introduce auxiliary variables and there-fore can be used in a wide variety of models. This uncer-tainty factorization can be used in both Bayesian and non-Bayesian models since the parametric uncertainty is sepa-rated (Equation (1)). To be specific, for Bayesian models, when making predictions on a new data point x*, we inte-grate out θ and obtain: p(y, x*|D) = p(x*|D) (cid:90) p(y|x*, θ)p(θ|D)dθ (2)
For non-Bayesian models, if we use the maximum likeli-hood method, we have: p(y, x*|D) = p(x*|D) (cid:124) (cid:123)(cid:122) (cid:125) data p(y|x*, ˆθMLE) (cid:123)(cid:122) (cid:125) (cid:124) distributional (3)
It is crucial to distinguish different types of predictive uncertainty in real-world problems so that different ac-tions can be taken depending on the source of uncertainty.
Our uncertainty factorization enables us to model differ-ent sources of uncertainty separately. For example, from
Equations (2) and (3), the parametric uncertainty can only be estimated in Bayesian models; however, the distribu-tional uncertainty and the aleatoric uncertainty can be mod-eled independently regardless of whether the model is under the Bayesian setting. Thus, this uncertainty factorization is practical when one needs to differentiate between different sources of uncertainty with a single model. 2.3. Connecting Uncertainty Factorization to OoD
Detection
Our proposed uncertainty factorization (Equation (1)) sheds light on what type of models are capable of de-tecting OoD samples. Without combining additional tech-niques, the widely used conditional models p(y|x, θ) alone are not good at OoD detection because they only capture the data uncertainty. However, a well-trained DHM p(y, x, θ) should be able to detect OoD samples since it contains the distributional uncertainty in nature. Furthermore, since a
DHM fits a probability distribution over the whole (x, y) space, it also learns the interactions between x and y. Labels y provide the interested ID semantics of the features x and tell the model what is ID and what is OoD. Consequently, modeling p(x, θ) alone with NFs generally fails to detect
dVϕ(h) = volJϕdx (6)
Equation (5) is a general version of the ”change-of-variables” formula, and it illustrates the relationship be-tween p(x) and p(h). To evaluate the density p(h), we need to compute the volume term volJϕ, which is not scalable to high-dimensional data. Equation (6) elucidates the ge-ometric intuition of volJϕ: it represents the ratio between two differentials (infinitesimal volumes) before and after the mapping ϕ.
In light of this observation, one way to bypass the computation of volJϕ is to make ϕ a measure-preserving (volume-preserving) mapping where volJϕ ≡ 1, which is the goal of this section. However, in practice, this requirement might be too stringent. Therefore we con-sider a more general version of measure-preserving map-pings (Definition 3.4) to keep ϕ’s expressivity. 3.1. Bi-Lipschitz Mappings Approximately Preseve the Measure (Volume)
Definition 3.2 (Bi-Lipschitz mappings). Consider two metric spaces (X, ∥.∥X ) and (H, ∥.∥H ). A function ϕ :
X → H is called bi-Lipschitz continuous if there exists a constant L ≥ 1, s.t. 1
L ∗∥x1 −x2∥X ≤ ∥ϕ(x1)−ϕ(x2)∥H ≤
L ∗ ∥x1 − x2∥X , ∀x1, x2 ∈ X.
The smallest L that satisfies the inequality is called the bi-Lipschitz constant of ϕ, and we say that ϕ is L-bi-Lipschitz continuous. If ϕ only satisfies half of the inequal-ity ∥ϕ(x1) − ϕ(x2)∥H ≤ L ∗ ∥x1 − x2∥X , we say that ϕ is
L-Lipschitz continuous. Note that invertible functions are not necessary to be bi-Lipschitz continuous, whereas bi-Lipschitz continuous functions are always bijective.
Proposition 3.3 If a function ϕ is L-bi-Lipschitz contin-uous, then ϕ is differentiable almost everywhere (Theorem 3.1.6 of [26]), and the singular values of its Jacobian lie in the interval (L−1, L).
Definition 3.4 (L-measure-preserving). Consider two measure spaces (X, A , volX ) and (H, H , volH ). A function ϕ : X → H is called L-measure-preserving (volume-preserving) if there exists a constant L ≥ 1, s.t.
L ∗ volX (B) ≤ volH (ϕ(B)) ≤ L ∗ volX (B), ∀B ∈ A . 1
Theorem 3.5 (Bi-Lipschitz mappings are approximately measure-preserving). Specifically, if a mapping ϕ : Rn →
Rm is L1/m-bi-Lipschitz continuous, then it is L-measure-preserving.
The proof is in Appendix A. Suppose that ϕ is L-measure-preserving and Bx ∈ A is an infinitesimal open cover of a point x ∈ X.
The volume ratio volH (ϕ(Bx))/volX (Bx) = dVϕ(h)/dx = volJϕ lies in the interval (L−1, L) where L ≥ 1 and thus approximately equal to 1 when L is close to 1. Therefore, from Equa-tion (5), we have p(x) = p(h)volJϕ ≈ p(h), which gives us a chance to circumvent the expensive step of computing volJϕ. The bounds are tight when L = 1 and ϕ becomes a strictly measure-preserving mapping.
Figure 3. An example to show that labels contain ID semantic information.
OoD samples [48] since the model does not learn what it means to be ID.
We briefly illustrate the above idea with a toy example.
In Figure 3, given a training dataset of six pictures and two test pictures, without information about the labels, we have no idea of what it means to be OoD. If the labels are ”1”,
”2”, and ”3”, the test data are ID. On the other hand, if the labels are ”red” and ”blue”, the test pictures should be considered OoD. With different labels, the ID semantics can change. As a result, the notion of OoD also changes. There-fore, labels contain semantic information that is useful for
OoD detection, especially for hard OoD samples. 3. L-Measure-Preserving Mappings
In this section, our goal is to construct an approximately measure-preserving (volume-preserving) mapping ϕ such that we have p(x) ≈ p(h) where h = ϕ(x). To begin with, we provide some mathematical background.
Definition 3.1 (Volume of a Matrix A) Consider a matrix
A ∈ Rm×n with nonzero singular values σ1, σ2,...,σr, the volume of A, volA := Πr i=1σi. volA is a generalization of |det(A)|, which intuitively measures the volume of the parallelepiped generated by the rows (columns) of A. Any r-dimensional unit cube em-bedded in Rn is mapped, through A, into a parallelepiped of volume volA. If A is of full row (column) rank, then volA = (cid:112)|det(G)| where G = AT A is the Gram matrix of A [5].
Normalizing Flow on Riemannian Manifolds Let x ∈
Rn be a random variable that takes values on an m-manifold
M with m < n (the manifold hypothesis). Consider an NF
ϕ : Rn → Rm that is bijective and differentiable almost ev-erywhere (allowing for piecewise differentiable functions).
Denote the Gram matrix of ϕ as G(x) = Jϕ(x)T Jϕ(x) where Jϕ(x) is the Jacobian of ϕ; then we have volJϕ = (cid:112)|det G(x)|. For any measurable set B ⊂ Rn, one can cal-culate the probability of its image under ϕ [6,11,29,43,68]:
P (h ∈ ϕ(B)) = (cid:90)
B p(x)dx = (cid:90)
ϕ(B) p(h)dVϕ(h) (4) where p(h) = p(x)/volJϕ (5)
3.2. Constructing Measure-Preserving Mappings via Spectral Normalization
Modern DNNs, such as ResNets, BERT, and Transform-ers, are often constructed with residual blocks. Spectral nor-malization (SN) [70] provides a simple yet efficient method to ensure the L-measure-preserving property on such DNN architectures. We state the theorem formally below:
Proposition 3.6 (Lipschitz-bounded residual blocks lead to bi-Lipschitz continuous DNNs [3,58]). Consider a resid-ual DNN ϕ = ϕd ◦ ... ◦ ϕ2 ◦ ϕ1 where ϕl(x) = x + gl(x) for l = 1, . . . , d.
If all gl(x) are β-Lipschitz continuous where 0 < β < 1, then ϕ is L-bi-Lipschitz continuous where
L = max{(1 − β)−d, (1 + β)d}.
The proof is in Appendix A. We consider gl(x) =
σ(Wlx + bl), where σ is the activation function such as
ReLU. We notice that the Lipschitz constant of the affine transformation Wlx + bl is the spectral norm of its weight matrix Wl, denoted as ∥Wl∥2 (the largest singular value of
Wl) [70,75], and the spectral norm of the activation function
σ is less than 1. Therefore, to ensure gl to be β-Lipschitz continuous where 0 < β < 1, it is sufficient to restrict
∥Wl∥2 to be less than 1. To this end, we apply SN to the weight matrices {Wl}d l=1. Following [4], at each training step, we first estimate the spectral norm ˆηl ≈ ∥Wl∥2 with the power iteration method [31, 70] and then normalize the weights via: (cid:40)
˜Wl = c ∗ Wl/ ˆηl
Wl if c < ˆηl otherwise (7) c > 0 is a scaling coefficient called the SN upper bound since it is the upper bound for the scaled spectral norm (∥ ˜Wl∥2 ≤ c), and therefore the upper bound for the Lip-schitz constant of gl(x) (β < c).
Tighter Bi-Lipschitz Bounds It is crucial to note that even if L1 and L2 are individually the best bi-Lipschitz con-stants of ϕ1 and ϕ2, respectively, L1L2 will not necessarily be the smallest bi-Lipschitz constant of ϕ2 ◦ ϕ1. It is pos-sible to obtain a much tighter bi-Lipschitz bound by con-sidering the entire DNN as a whole rather than each layer in isolation. Under mild assumptions, we can provide some analysis on the bi-Lipschitz bound of a residual DNN.
Corollary 3.7 (A tighter bi-Lipschitz bound for residual
DNNs). Consider a DNN ϕ composed of d residual blocks, each of which is β-Lipschitz continuous where 0 < β < 1.
The expected value of the bi-Lipschitz constant of the DNN is 0.5d(1 + β + 1 1+β )d.
The proof (informal) is in Appendix A. Let us look at an example. If our model is a DNN composed of 10 residual blocks and each block is 0.1-Lipschitz continuous. From the manifold hypothesis, suppose that the data lie on a three-dimensional manifold. Then, after the model is trained on the dataset, we would expect it to become a 1.14-measure-preserving mapping.
It is crucial to note that an overly strong measure-preserving property (L is too close to 1) might harm OoD detection in practice. This is due to the fact that the bi-Lipschitz condition, by definition, leads the model to pre-serve a naive metric ∥.∥X (such as the Euclidean distance) in the original data space X rather than a semantically meaningful distance in the data manifold M. Due to highly non-convexity, OoD data in space X can be even closer to the center of the ID data than the ID data themselves.
Consequently, an overly strong measure-preserving condi-tion makes detecting OoD samples even harder. For exam-ple, a strictly measure-preserving mapping would become a naive rotation or identity function (for residual networks), in which case detecting OoD samples is impossible. There-fore, we hope that our model is measure-preserving only to the extent that it is safe to drop the volume term volJϕ, and we can still do OoD detection. For example, if the probabil-ities of the ID data are ten times larger than the probabilities of the OoD data, it is safe to drop the volume term even if the measure-preserving constant is as large as 2. In practice, the SN upper bound c is a critical hyperparameter to control the strictness of the measure-preserving property. 4. Method Summary for DHMs
Architecture Given a DNN ϕ, logits(x) = c ◦ ϕ(x; θ) where c is a fully connected layer, a DHM makes two changes to the model: applying SN on the weights of ϕ and adding an NF f : ϕ(x; θ) (cid:55)→ z, where z ∼ N (0, I).
Objective In DHMs, the maximum likelihood objective is naturally separated into log p(y, x; θ) = log p(y|x; θ) + log p(x; θ). In practice, though, a weighted maximum likeli-hood objective log p(y, x; θ) = log p(y|x; θ) + λ log p(x; θ) is commonly used where λ is a scaling constant, as predic-tion accuracy is usually of more interest.
Training and Prediction We summarize the methods in
Algorithm 1 and Algorithm 2.
Algorithm 1 DHM Training 1: Input: batches B = {xi, yi}M i=1 2: Initialize parameters θ 3: for step = 1 to max step do 4: 5: 6: end for
SGD update θ
Apply SN to θ
Algorithm 2 DHM Prediction 1: Input: test example x* 2: Compute p(y|x*) = max softmax ◦ c ◦ ϕ(x*; θ) 3: Compute p(x*) ≈ p(z)|det Jf (ϕ(x*; θ))| 4: Compute Uncertainty = p(y|x*)p(x*) or p(x*) 5: Compute Label = arg max c ◦ ϕ(x*; θ) 6: Return Label, Uncertainty
Why Do DHMs Work? 1: a DHM aims to learn a joint density p(x, y) which contains the distributional uncertainty in nature (Equation (1)); 2: by learning a joint embedding for both p(y|x) and p(x), a DHM encodes high-level seman-tic information of the data (partly coming from labels y); 3: by applying SN, we construct an approximately measure-preserving mapping ϕ (p(x) ≈ p(h) where h = ϕ(x)).
This technique enables us to use SoTA DNNs to learn low-dimensional representations of the inputs x without comput-ing the expensive volume term (pseudo determinant), which solves the problem of expressibility and computational scal-ability. 5.