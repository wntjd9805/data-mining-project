Abstract
Cross domain object detection is a realistic and challenging task in the wild. It suffers from performance degradation due to large shift of data distributions and lack of instance-level annotations in the target domain. Existing approaches mainly focus on either of these two difficulties, even though they are closely coupled in cross domain object detection.
To solve this problem, we propose a novel Target-perceived
Dual-branch Distillation (TDD) framework. By integrating detection branches of both source and target domains in a unified teacher-student learning scheme, it can reduce domain shift and generate reliable supervision effectively.
In particular, we first introduce a distinct Target Proposal
Perceiver between two domains. It can adaptively enhance source detector to perceive objects in a target image, by leveraging target proposal contexts from iterative cross-attention. Afterwards, we design a concise Dual Branch
Self Distillation strategy for model training, which can progressively integrate complementary object knowledge from different domains via self-distillation in two branches.
Finally, we conduct extensive experiments on a number of widely-used scenarios in cross domain object detection.
The results show that our TDD significantly outperforms the state-of-the-art methods on all the benchmarks. The codes and models will be released afterwards. 1.

Introduction
Object detection has achieved remarkable success with the help of advanced deep neural networks [2, 12–14, 26, 28–31,36]. However, it still faces challenges in realistic ap-plications such as autonomous driving and mobile robots, where data variance is often large due to various conditions of weather, illumination, object appearance, etc. Hence,
∗ Equal contribution. † Corresponding author.
Figure 1. Two typical examples of detection results on the adverse weather conditions adaptation experiments with different methods.
Semi-supervised method UBT [27] lacks awareness of objects in the fog. Adversarial based GPA [49] attempts to exploit the objects in the fog but gives some wrong predictions, such as the motorcy-cle in the first row and the person in the second row. Our methods can predict the boxes and categories more accurately. cross-domain object detection has attracted lots of attention in recent years. In general, there are two difficulties in this problem. First, object detection is more vulnerable to do-main shift. The main reason is that, object detection focuses on instance-level prediction, which is more sensitive to ob-ject variance in various image styles and contents. Second, object annotations are more expensive and labor-intensive to get, causing the scarcity of discriminative object supervi-sion in a new domain. Both of them inevitably deteriorate the detection performance in target domain.
Recently, several approaches have been proposed for cross-domain object detection [5, 24, 32, 34, 49]. Unfortu-nately, most of them focus on either domain shift or label deficiency, which limits their power in cross domain ob-ject detection. For example, domain adaption approaches
[5, 34, 49] propose to reduce domain shift via adversarial training. Besides of unstable model optimization, the dis-crimination ability of the network is limited in such ad-versarial design. As shown in Figure 1, adversarial based
GPA [49] tends to produce wrong predictions on the regions
where the target domain characteristics are significant. Al-ternatively, self-training based approaches [1, 16, 22, 23, 55] study the problem from the viewpoint of semi-supervised learning, and propose to generate pseudo object supervision
In this way, many advanced semi-via label distillation. supervised methods can be transferred to this task. How-ever, these approaches are often insufficient to deal with the complex domain shifts. In Figure 1, it is difficult for a semi-supervised method like UBT [27] to aware objects in the target domain. Hence, both types of solutions are unsatis-factory in cross domain object detection.
Based on these discussions, we propose a novel
Target-perceived Dual-branch Distillation (TDD) frame-work, which can effectively tackle domain shift and la-bel deficiency via object perception and knowledge distil-lation in a concise dual-branch detection network. Specifi-cally, our network consists of a source-adaptive branch and a target-like branch, both of which are elaborately designed to be target-oriented for domain shift reduction. For the source-adaptive branch, we introduce a distinct Target Pro-posal Perceiver, which leverages iterative cross-attention to discover target-domain contexts for each proposal. As a result, it can adaptively enhance source branch to per-ceive objects in the target domain image. For the target-like branch, we transfer source images into target-like im-ages. Via training this branch with these labeled images, we can learn discriminative object knowledge of target do-main reliably. Finally, we design a concise Dual Branch
Self Distillation strategy for network training. It is a tai-lored mean-teacher style framework to generate pseudo an-notations of target images from both source-adaptive and target-like branches. Through three well-designed training steps, namely joint-domain pretraining, cross-domain dis-tillation and dual-teacher refinement, we can progressively integrate complementary object knowledge from different domains to boost cross domain object detection.
In summary, this paper has the following contributions.
First, we develop a novel Target-perceived Dual-branch
Distillation (TDD) framework, which leverages two dis-tinct detection branches to address both domain shift and label deficiency in a unified teacher-student learning man-ner. Second, we introduce a smart Target Proposal Per-ceiver module, which can adaptively guide source detec-tion branch to perceive target domain objects, via cross-attention-style transformer on proposal contexts. Finally, we conduct extensive experiments on a number of widely-used benchmarks and our TDD outperforms the state-of-the-art methods with a large margin. 2.