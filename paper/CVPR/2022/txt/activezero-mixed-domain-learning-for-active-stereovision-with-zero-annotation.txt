Abstract
Traditional depth sensors generate accurate real world depth estimates that surpass even the most advanced learn-ing approaches trained only on simulation domains. Since ground truth depth is readily available in the simulation domain but quite difficult to obtain in the real domain, we propose a method that leverages the best of both worlds. In this paper we present a new framework, ActiveZero, which is a mixed domain learning solution for active stereovision systems that requires no real world depth annotation. First, we demonstrate the transferability of our method to out-of-distribution real data by using a mixed domain learning strategy. In the simulation domain, we use a combination of supervised disparity loss and self-supervised losses on a shape primitives dataset. By contrast, in the real domain, we only use self-supervised losses on a dataset that is out-of-distribution from either training simulation data or test real data. Second, our method introduces a novel self-supervised loss called temporal IR reprojection to increase the robustness and accuracy of our reprojections in hard-to-perceive regions. Finally, we show how the method can be trained end-to-end and that each module is important for attaining the end result. Extensive qualitative and quantitative evaluations on real data demonstrate state of the art results that can even beat a commercial depth sensor.
The codes of ActiveZero are available at: https:// github.com/haosulab/active_zero. 1.

Introduction
Depth sensors can provide 3D geometry information about a target scene, which is critical in various robotic applications, including mapping, navigation, and object manipulation [6,17,26]. Among the different types of depth sensors available, active stereovision depth sensors (eg.
Intel RealSense™D series) are the most widely adopted in both industry and academic settings due to their high spatial
Figure 1. ActiveZero produces more accurate and complete disparity estimates on real IR stereo images for objects with complex optical characteristics (specular, transparent) than com-mercial depth sensors with zero real depth annotation using mixed domain learning by leveraging self-supervised reprojection loss on temporal IR patterns in the real domain and direct disparity supervision in the simulation domain. resolution, high accuracy, and low cost [19]. These sensors are composed of an infrared (IR) pattern emitter and two IR cameras with the IR pattern projected onto the target scene to facilitate stereo matching. However, since these sensors use classical stereo algorithms, they suffer from common stereo matching issues such as over smoothing, edge fatten-ing and holes for specular and transparent objects so they are non-ideal for robotic applications which require high precision and completeness [5].
Learning based methods can solve the aforementioned issues by generating more accurate and complete depth maps through the utilization of prior samples to understand how to correctly handle edges and uncertain pixels [2–4, 35]. However, a large scale stereo dataset with ground truth depth is required to train these learning based methods, which is costly and time-consuming to collect in the real world. Therefore, one way to alleviate this problem is to use
self-supervised learning. Self-supervised stereo methods
[38, 39] use reprojection or other related losses between binocular images as supervision, but the fluctuation of these losses prohibit the network from reaching a meaningful optima. Another approach is to use simulation data where ground truth depth is readily available. However due to the domain gap between the simulation and real world, networks trained on only simulation data cannot be reliably transferred to the real domain. Domain adaptation meth-ods have been proposed to overcome the Sim2Real prob-lem [23], but the introduction of GANs makes the training process unstable [20] and the performance suboptimal.
This paper proposes an end-to-end learning stereo method that combines the advantages of self-supervised learning in the real domain and supervised learning in the simulation domain which we call mixed domain learning (Fig. 1).
This strategy significantly boosts the stereo network performance while also stabilizing and speeding up the optimization process. Specifically, by only needing to train on shape primitives in the simulation domain with ground truth depth as supervision and an unrelated set of scenes in the real domain with reprojection as self-supervision, we are able to achieve comparable perfor-mance on completely out-of-distribution objects in the real domain as though we were directly training on those ob-jects.
In addition, we observed that there are fundamental is-sues with performing direct image reprojection as previous works had done so we propose the use of temporal IR by periodically adjusting the brightness of the emitted IR pattern and extracting the binary pattern from the temporal image sequences. The reprojection loss on the temporal binary pattern eliminates the influence of scene texture and also the effect of illumination strength decaying with increased distance. Experimental results demonstrate that our method is able to outperform state-of-the-art learning-based stereo methods and commercial depth sensors, and ablation studies verify the effectiveness of each module in our work. 2.