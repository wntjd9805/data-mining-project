Abstract
Face image super resolution (face hallucination) usu-ally relies on facial priors to restore realistic details and preserve identity information. Recent advances can achieve impressive results with the help of GAN prior. They ei-ther design complicated modules to modify the fixed GAN prior or adopt complex training strategies to finetune the generator. In this work, we propose a generative and con-trollable face SR framework, called GCFSR, which can re-construct images with faithful identity information without any additional priors. Generally, GCFSR has an encoder-generator architecture. Two modules called style modu-lation and feature modulation are designed for the multi-factor SR task. The style modulation aims to generate real-istic face details and the feature modulation dynamically fuses the multi-level encoded features and the generated ones conditioned on the upscaling factor. The simple and elegant architecture can be trained from scratch in an end-* Corresponding author to-end manner. For small upscaling factors (≤8), GCFSR can produce surprisingly good results with only adversar-ial loss. After adding L1 and perceptual losses, GCFSR can outperform state-of-the-art methods for large upscaling fac-tors (16, 32, 64). During the test phase, we can modulate the generative strength via feature modulation by chang-ing the conditional upscaling factor continuously to achieve various generative effects. Code is available at https:
//github.com/hejingwenhejingwen/GCFSR. 1.

Introduction
Face image super resolution (face SR or face halluci-nation) algorithms have been developing rapidly in recent years, with its wide application in video restoration and
AI photographing. Face SR has a close relationship with general image SR [8, 9, 31–33, 38, 41] and face generation tasks [10, 15, 17, 18, 20]. Similar as general image SR, face
SR is a restoration problem, whose goal is to reconstruct correct structures and preserve identity information. Differ-ently, face SR has to deal with very large upscaling factors (8-64) [4, 30, 35], thus requiring to generate a large amount of finer details, which is similar to face generation. As a combination of restoration and generation problem, face SR has unique solution pipelines, which always involve various additional facial priors [2,5,6,21,21,28,36,43], like parsing map and attribution map.
Recent advances have found that a face GAN can take the place of all previous facial priors, and produce realistic face details. This is based on the observation that a well-trained GAN model has already contained enough face in-formation, which is sufficient to provide strong priors. For instance, GLEAN [4] adopts the intermediate features of a
StyleGAN [20] as latent banks, and achieves superior per-formance on large-factor SR tasks. While GFPGAN [30] and GPEN [35] introduce face GAN models to solve blind face restoration problem, and both can recover promising facial details. Their success can be attributed to the utiliza-tion of GAN priors and motivates later works to find more applications.
However, if we must rely on such a prior, face SR will face two apparent limitations. First, as face GAN is trained on specific datasets (e.g., FFHQ [19]), the corresponding face SR methods can only deal with the same kind of face images (e.g., frontal faces with a fixed size), significantly restricting its applications. Second, as face GAN is not spe-cially designed for face SR, we have to add additional op-erations in the network for adaptation [4, 25, 30, 35], which is a waste of computation resources. Then we will ask: can we get rid of these priors, and design a pure data-driven framework?
Another issue unsolved in face SR is the flexibility of generation. Existing methods can only output a single restoration result with a fixed style. However, in real sce-narios, users might want to adjust the generative strength to meet personalized requirements. For example, they will desire more details in old photo restoration, but less hallu-cination effects in surveillance video enhancement. “How to control the amount of generated details” is a practical de-mand. Furthermore, real-world images may have various sizes, but conventional SR models (e.g., GLEAN [4] and
ESRGAN [33]) for fixed upscaling factors cannot handle such diverse cases.
To address the problems, we propose a generative and controllable face SR framework, called GCFSR, which has three appealing properties. First, it could reconstruct faith-ful images with promising identity information. This is also the basic requirement of face SR task. Second, it could generate realistic face details, without reliance on any addi-tional priors, including facial priors and GAN priors. This shows that GAN prior is not an essential part in face SR task. Third, its generative strength can be interactively ad-justed (Figure 1). This can also be used in handling different and continuous upscaling factors. These three properties are guaranteed by three special designs in GCFSR, which are the encoder-generator architecture, style modulation and feature modulation modules. GCFSR enjoys a very con-cise architecture without extra priors or initialization. We will detail our designs in the Method section. More impor-tantly, GCFSR has a nice training property.
It is end-to-end trainable and converges fast. When the upscaling factor is small (≤ 8), it is possible to discard all pixel-wise con-straints and use a single GAN loss to achieve state-of-the-art performance. This has never been revealed in previous SR methods. Extensive experiments and ablation studies have demonstrated the effectiveness of each module. Combing them together, GCFSR could achieve superior performance to GAN based methods in both small and large upscaling factors. We can also observe vivid face details and gradu-ally modulated effects in qualitative results (see Figure 1). 2.