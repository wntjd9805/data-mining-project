Abstract state-of-the-art performance in real deraining.
Image deraining is a typical low-level image restoration task, which aims at decomposing the rainy image into two distin-guishable layers: clean image layer and rain layer. Most of the existing learning-based deraining methods are supervis-edly trained on synthetic rainy-clean pairs. The domain gap between the synthetic and real rains makes them less gener-alized to different real rainy scenes. Moreover, the existing methods mainly utilize the property of the two layers inde-pendently, while few of them have considered the mutually exclusive relationship between the two layers. In this work, we propose a novel non-local contrastive learning (NLCL) method for unsupervised image deraining. Consequently, we not only utilize the intrinsic self-similarity property within samples, but also the mutually exclusive property between the two layers, so as to better differ the rain layer from the clean image. Speciﬁcally, the non-local self-similarity im-age layer patches as the positives are pulled together and similar rain layer patches as the negatives are pushed away.
Thus the similar positive/negative samples that are close in the original space beneﬁt us to enrich more discrimina-tive representation. Apart from the self-similarity sampling strategy, we analyze how to choose an appropriate feature encoder in NLCL. Extensive experiments on different real rainy datasets demonstrate that the proposed method obtains 1.

Introduction
The existing high-level computer vision tasks such as image segmentation [6], and object detection [34] have achieved signiﬁcant progress in recent years. Unfortunately, their performance would suffer from degradation under the rainy weather [1, 22, 29]. To alleviate the inﬂuence of the rain, numerous full-supervised deraining methods have been proposed [11,54,59]. Although they can achieve good results on simulated rainy image, they cannot well generalize to the real rain because of the domain gap between the simpliﬁed synthetic rain and complex real rain [56]. The goal of this work is to remove the real rain in an unsupervised manner.
To handle the real-world complex rainy images, the optimization-based methods are ﬁrstly proposed with hand-crafted priors such as the sparse coding [36], low-rank [4] and Gaussian mixture model [31]. However, these hand-crafted priors are of limited representation ability, especially for highly complex and varied rainy scenes. To rectify this weakness, the learning-based CNN methods [11, 28, 30, 54] have made great progresses. The key idea of these super-vised learning methods tries the best to simulate the rain
∗Corresponding Author
as real as possible with sophisticated models, such as the additive model [25], screen blend model [36], heavy rain model [54], and comprehensive rain model [19], to name a few. Unfortunately, there still exist gap between these syn-thetic rain models and real rain degradation, since the real rainy atmosphere is usually a high-order nonlinear system.
Furthermore, the semi-supervised deraining methods have been proposed to effectively improve the robustness for real rains [20, 35, 48, 49, 55, 56], where they employ the simu-lated labels for good initialization and unlabeled real rains for generalization. Their performances still depend on the distribution gap between the simulated and real rainy images to some extent. Once the distributions are of large distance, these semi-supervised deraining results would be less sat-isfactory. Very recently, the unsupervised methods have raised more attentions for real rain removal, mainly includ-ing the CycleGAN-based unpaired image translation meth-ods [23,50,60] and the optimization-model driven deep prior network [58]. However, the previous methods including the unsupervised ones mainly pay attention to the property of the image or rain layer independently, yet seldom consider the mutually exclusive relationship between the two layers.
To overcome these problems, we formulate the image deraining into a contrastive learning framework [7, 18] from an unsupervised perspective. The core idea of contrastive learning is that the representation of similar samples should be pulled close together, while that of dissimilar samples should be pushed far away in the embedding space [16, 52].
Figure 2 illustrates the main idea of proposed method. The image deraining is formulated as an image decomposition task, in which the clean image patches are regarded as the positives while the rain layer patches as the negatives. Thus, we not only take advantage of the properties of both image and rain layers, but also model the mutually exclusive re-lationship between the two layers for better decomposition.
On the other hand, the proposed method does not require the clean supervision, which makes it generalize well for the real-world rainy images.
The key factor of contrastive learning is how to construct different views for both the positive and negative samples.
The main stream is to augment a single instance with differ-ent transformations as the positive samples so as to learn the invariant representations [7]. However, these instance-level hand-crafted augmentations are not adequate to cover vari-ous situations. In this work, we provide a new perspective via the patch-level self-similarity within a single image. While non-local self-similarity [3] has been extensively studied in the literature, this intrinsic property for capturing the cross-patch relation in a single image with contrastive learning has barely been explored for visual representation learning.
To the best of our knowledge, we are the ﬁrst to incor-porate non-local self-similarity into contrastive learning for positive/negative sampling. The advantage of the proposed
Figure 2. Most previous methods model the property of the image layer and rain layer independently in a supervised manner. In this work, we go further by considering the mutually exclusive relation-ship between the two layers, and propose an unsupervised non-local contrastive learning method to learn mutually exclusive relationship by pushing away the image positives and rain negatives. Moreover, the non-local self-similarity has been exploited to improve the positive/negative sampling with discriminative representation. non-local sampling is twofold. First, the non-local self-similarity sampling strategy would naturally guarantee more compact clusters for positives and negatives respectively, which would beneﬁt us to differ the positives from negatives.
Second, these positive non-local patches are the samples searched from real images with diverse variable information, not manually generated fake samples, which would provide more faithful information for representation. Note that, the non-local strategy is not only applicable for the positive sam-ples, but also beneﬁcial to the negative samples. Overall, our contributions can be summarized as follow:
• We propose a non-local contrastive learning method (NLCL) for unsupervised image deraining. Compared with previous deraining methods, we not only exploit the speciﬁc property of the image and rain layers, but also model the contrastive relationship between them for better decoupling the rain layer from the clean image.
• We connect the contrastive learning with the non-local self-similarity. The non-local patch sampling strategy nat-urally endows the positive/negative samples with more compact and discriminative representation for better de-composition. In addition, we provide an guidance of how to design a good encoder for better embedding in NLCL.
• We conduct extensive experiments on both synthetic and real-world datasets, and show that NLCL outperforms fa-vorably state-of-the-art methods on real image deraining. 2.