Abstract
We propose a learned method for stereo image com-pression that leverages the similarity of the left and right images in a stereo pair due to overlapping fields of view.
The left image is compressed by a learned compression method based on an autoencoder with a hyperprior entropy model. The right image uses this information from the pre-viously encoded left image in both the encoding and decod-In particular, for the right image, we encode ing stages. only the residual of its latent representation to the opti-mally shifted latent of the left image. On top of that, we also employ a stereo attention module to connect left and right images during decoding. The performance of the pro-posed method is evaluated on two benchmark stereo image datasets (Cityscapes and InStereo2K) and outperforms pre-vious stereo image compression methods while being signif-icantly smaller in model size. 1.

Introduction
Lossy image compression is a fundamental task in image processing that aims to preserve the visual image content while reducing the bitrate needed for storage or transmis-sion. It is a long-studied problem and a very active field of research both in traditional hand-crafted approaches and newly emerging learned methods. The traditional image en-coding and decoding pipeline (“codec”) typically consist of partitioning the image into small blocks to be processed sep-arately, a linear transform to decorrelate the image values, intra block prediction (motion search) and residual coding to exploit repetition and self-similarity of the image content and decrease the entropy of its representation, quantization to obtain a finite set of symbols to code, and an entropy coder to store the resulting representation most efficiently.
The decoding pipeline performs analogous operations in re-verse.
In contrast, modern learned compression methods typically process the image as a whole, without partitioning, by models, based on variational autoencoders, in which the latent representation is quantised and entropy coded with a learned probability distribution. The parametrization of this distribution, the entropy model, along with the autoencoder, are trained to minimize the cross-entropy against the true la-tent distribution so that the whole codec can be trained by optimizing the weighted rate/distortion loss.
In stereo image compression, the primary objective is the same with the additional possibility to achieve better performance by exploiting the mutual information between left and right images caused by their overlapping fields of view (albeit from slightly different viewpoints).
In tradi-tional methods, this can be achieved by the same set of tools available for inter-frame or motion prediction. Motion vec-tor search in learned compression methods is far less ex-plicit and extending them to stereo compression is therefore paradoxically more difficult. In the current literature, there are two existing deep learning based methods explicitly tar-geting stereo image compression – the DSIC model by Liu et al. [21] and HESIC model by Deng et al. [13]. In DSIC, a dense warp field is estimated, and warped features from the left image are fed to the encoder and decoder of the right image. In HESIC, a rigid homography transform in the im-age space is used. In both cases, the models are augmented by additional modules for joint entropy modelling and im-age enhancement, and as a result, they are rather large, and their training far from straightforward.
In contrast, the proposed model is very lightweight (4% and 10% the size of DSIC and HESIC, respectively, in num-ber of parameters), conceptually simple, and does not re-quire any special training procedure without sacrificing per-formance. The “backbone” of our method is an adaption of [38], but in principle, any general single image compres-sion encoder-decoder model can be used as the backbone.
The left image is encoded normally. After the right image is processed by the encoder, we find optimal horizontal shifts (minimizing the mean-square error) of each channel of its latent representation to the corresponding channel of the left image latent and subtract the two shifted channels so that only the residual is encoded for the right latent. This is motivated by the observation that the dominant rigid trans-form between rectified images in a stereo pair is a horizontal shift and working in the latent space results in larger effec-tive disparity range due to downsampling. To account for
smaller local displacements caused by depth variation, we also connect the two image representations by a stereo at-tention module [40], proposed originally for stereo image superresolution. A full description of the method is given in
Sec. 3.
To summarize, we propose a method for stereo image compression with the following highlights:
• The principle of the method mimics the same tech-niques that are used for stereo compression in tradi-tional codecs but remains fully end-to-end learnable.
• The method outperforms existing stereo image com-pression state-of-the-art on two standard test datasets.
• The method is very lightweight and easy to train, and its code is publicly available.1
In the rest of the paper, we summarize the related previ-ous work, give a full description of the method and present and discuss the experimental results. 2.