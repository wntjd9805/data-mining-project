Abstract
Mixup is a powerful data augmentation method that in-terpolates between two or more examples in the input or feature space and between the corresponding target labels.
However, how to best interpolate images is not well de-ﬁned. Recent mixup methods overlay or cut-and-paste two or more objects into one image, which needs care in se-lecting regions. Mixup has also been connected to autoen-coders, because often autoencoders generate an image that continuously deforms into another. However, such images are typically of low quality.
In this work, we revisit mixup from the deformation perspective and introduce AlignMixup, where we geomet-rically align two images in the feature space. The cor-respondences allow us to interpolate between two sets of features, while keeping the locations of one set. Interest-ingly, this retains mostly the geometry or pose of one im-age and the appearance or texture of the other. We also show that an autoencoder can still improve representa-tion learning under mixup, without the classiﬁer ever see-ing decoded images. AlignMixup outperforms state-of-the-art mixup methods on ﬁve different benchmarks. Code available at https://github.com/shashankvkt/
AlignMixup_CVPR22.git 1.

Introduction
Data augmentation [10, 36, 43] is a powerful regular-ization method that increases the amount and diversity of data, be it labeled or unlabeled [16]. It improves the gen-eralization performance and helps learning invariance [49] at almost no cost, because the same example can be trans-formed in different ways over epochs. However, by operat-ing on one image at a time and limiting to label-preserving transformations, it has limited chances of exploring beyond the image manifold. Hence, it is of little help in combating memorization of training data [67] and sensitivity to adver-sarial examples [53].
Mixup operates on two or more examples at a time, in-terpolating between them in the input space [69] or fea-ture space [58], while also interpolating between target la-Image 1
Input mixup [69]
CutMix [65]
Image 2
Manifold mixup [58]
AlignMixup (Ours)
Figure 1. Different mixup methods. AlignMixup retains the pose of image 2 and the texture of image 1. This different from overlay (Input and Manifold mixup) or combination of two objects (Cut-Mix). Manifold mixup and AlignMixup visualized by a decoder (subsection 3.3) that is not used at training. bels for image classiﬁcation. This ﬂattens class represen-tations [58], reduces overly conﬁdent incorrect predictions, and smoothens decision boundaries far away from training data. However, input mixup images are overlays and tend to be unnatural [65]. Interestingly, recent mixup methods focus of combining two [32, 65] or more [31] objects from different images into one in the input space, making efﬁ-cient use of training pixels. However, randomness in the patch selection and thereby label mixing may mislead the classiﬁer to learn uninformative features [57], which raises the question: what is a good interpolation of images?
Bengio et al. [3] show that traversing along the manifold of representations obtained from deeper layers of the net-work more likely results in ﬁnding realistic examples. This is because the interpolated points smoothly traverse the un-derlying manifold of the data, capturing salient characteris-tics of the two images. Furthermore, [4] show the ability of autoencoders to capture semantic correspondences obtained by decoding mixed latent codes. This is because the au-toencoder may disentangle the underlying factors of varia-tion. Efforts have followed on mixing latent representations of autoencoders to generate realistic images for data aug-mentation. However, these approaches are more expensive, requiring three networks (encoder, decoder, classiﬁer) [4] and more complex, often also requiring an adversarial dis-criminator [2, 39]. More importantly, they perform poorly compared to standard input mixup on large datasets [39], due to the low quality of generated images.
In this work, we are motivated by the idea of deformation as a natural way of interpolating images, where one image may deform into another, in a continuous way. Contrary to previous efforts, we do not interpolate directly in the input space, we do not limit to vectors as latent codes and we do not decode. We rather investigate geometric alignment for mixup, based on explicit semantic correspondences in the feature space. In particular, we explicitly align the feature tensors of two images, resulting in soft correspondences.
The tensors can be seen as sets of features with coordinates.
Hence, each feature in one set can be interpolated with few features in the other.
By choosing to keep the coordinates of one set or the other, we deﬁne an asymmetric operation. What we obtain is one object continuously morphing, rather than two ob-jects in one image. Interestingly, observing this asymmetric morphing reveals that we retain the geometry or pose of the image where we keep the coordinates and the appearance or texture of the other. Figure 1 illustrates that our method,
AlignMixup, retains the pose of image 2 and the texture of image 1, which is different from existing mixup methods.
Note that, as in manifold mixup, we do not decode, hence we are not concerned about the quality of generated images.
We make the following contributions: 1. We introduce a novel mixup operation, called Align-Mixup, advocating interpolation of local structure in the feature space (subsection 3.2). Feature tensors are ideal for alignment, giving rise to semantic correspon-dences and being of low resolution. Alignment is efﬁ-cient by using Sinkhorn distance [11]. 2. We also show that a vanilla autoencoder can further improve representation learning under mixup training, without the classiﬁer seeing decoded clean or mixed images (section 4). 3. We set a new state-of-the-art on image classiﬁcation, robustness to adversarial attacks, calibration, weakly-supervised localization and out-of-distribution detec-tion against more sophisticated mixup operations on several networks and datasets (section 4). 2.