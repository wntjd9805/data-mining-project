Abstract
Existing studies for gait recognition are dominated by 2D representations like the silhouette or skeleton of the human body in constrained scenes. However, humans live and walk in the unconstrained 3D space, so projecting the 3D human body onto the 2D plane will discard a lot of crucial information like the viewpoint, shape, and dynamics for gait recognition. Therefore, this paper aims to explore dense 3D representations for gait recognition in the wild, which is a practical yet neglected problem.
In particular, we propose a novel framework to explore the 3D Skinned Multi-Person Linear (SMPL) model of the human body for gait recognition, named SMPLGait. Our framework has two elaborately-designed branches of which one extracts appearance features from silhouettes, the other learns knowledge of 3D viewpoints and shapes from the 3D SMPL model. In addition, due to the lack of suitable datasets, we build the first large-scale 3D representation-based gait recognition dataset, named Gait3D. It contains 4,000 subjects and over 25,000 sequences extracted from 39 cameras in an unconstrained indoor scene. More importantly, it provides 3D SMPL models recovered from video frames which can provide dense 3D information of body shape, viewpoint, and dynamics. Based on Gait3D, we comprehensively compare our method with existing gait recognition approaches, which reflects the superior performance of our framework and the potential of 3D representations for gait recognition in the wild. The code and dataset are available at: https://gait3d.github.io. 1.

Introduction
Visual gait recognition, which aims to identify a target person using her/his walking pattern in a video, has been studied for over two decades [29, 41]. Existing approaches and datasets are dominated by 2D gait representations such as silhouette sequences [54], Gait Energy Images
*This work was done when Jinkai Zheng was an intern at Explore
Academy of JD.com.
†Corresponding author.
Figure 1. Different gait representations of the same person from two viewpoints. Compared with silhouettes and skeletons, 3D meshes retain the shapes and viewpoints of the human body in the 3D space. (Best viewed in color.) (GEIs) [10], 2D skeletons [61], as shown in Figure 1. How-ever, the human body is a 3D non-rigid object, so the 3D-to-2D projection discards a lot of useful information of shapes, viewpoints, and dynamics while presenting ambiguity for gait recognition. Therefore, this paper is focused on 3D gait recognition that is valuable yet neglected by the community.
Recently, deep learning-based methods have dominated the state-of-the-art performance on the widely adopted 2D gait recognition benchmarks like CASIA-B [36] and
OU-MVLP [35] by directly learning discriminative fea-tures from silhouette sequences [5, 8, 55] or GEIs [44].
Despite the excellent results on the in-the-lab datasets, these methods cannot work well in the wild scenarios which have more diverse 3D viewpoints of cameras and more complex environmental interference factors like oc-clusions [61]. Although several works exploit 3D cylin-ders [3] or 3D skeletons [40], these sparse 3D models also 1
lose helpful information of human bodies like viewpoints and shapes. Fortunately, the development of parameter-ized human body models like the Skinned Multi-Person
Linear (SMPL) model [27] and 3D human mesh recovery approaches [17,19,33] makes it possible to estimate precise 3D meshes and viewpoints of human bodies in video frames. The advantages of 3D meshes for gait recognition are two-fold: 1) the 3D mesh can provide not only the pose but also the shape of the human body in the 3D space, which is crucial for learning discriminative features of gait, and 2) the 3D viewpoint can be explored to normalize the orientations of human bodies during cross-view matching.
To this end, we design a novel 3D SMPL model-based
Gait recognition framework, i.e., SMPLGait, to explore the 3D gait representations for human identification. Our
SMPLGait framework has two branches based on deep neural networks. One branch takes the silhouette sequence of a person as the input to learn appearance features like clothing, hairstyle, and belongings. However, due to the extreme viewpoint changes in the wild, the shape of the human body can be distorted, which makes the appearance ambiguous, as shown in Figure 1. To overcome this challenge, we design a 3D Spatial-Transformation Network (3D-STN) as the other branch to learn 3D knowledge of viewpoint and shape from the 3D human mesh. The 3D-STN takes the 3D SMPL model of each frame as the input to learn a spatial transformation matrix. By applying the spatial transformation matrix to the appearance features, these features from different viewpoints are normalized in the latent space. By this means, the gait sequences of the same person will be closer in the feature space.
Nevertheless, there is no suitable dataset that provides 3D meshes of human bodies in the wild. Therefore, to facilitate the research, we build the first large-scale 3D mesh-based gait recognition dataset, named Gait3D, from high-resolution videos captured in the wild. Compared to existing datasets listed in Table 1, the Gait3D dataset has the following featured properties: 1) Gait3D contains 4,000 subjects with over 25,000 sequences captured by 39 cameras in an unconstrained indoor scene which makes it scalable for research and applications. 2) It provides precise 3D human meshes recovered from video frames which can provide 3D pose and shape of human bodies as well as accurate viewpoint parameters. 3) It also provides conventional 2D silhouettes and keypoints which can be explored for gait recognition with multi-modal data.
In summary, the contributions of this paper are as fol-lows:
• We make one of the first attempts towards 3D gait recognition in the real-world scenario, which aims to explore dense 3D representations of the human body for gait recognition.
• We propose a novel 3D gait recognition framework based on the SMPL model, named SMPLGait, to explore 3D human meshes for gait recognition.
• We build the first large-scale 3D gait recognition dataset, named Gait3D, which provides the 3D human meshes of gait collected from unconstrained scenarios.
Through comprehensive experiments, we not only evaluate existing 2D silhouettes/skeleton-based approaches but also demonstrate the effectiveness of the proposed SMPLGait method, which reflects the potential of 3D representations for gait recognition. Moreover, the combination of 3D and 2D representations further improves the performance which shows the complementarity of multi-modal representations. 2.