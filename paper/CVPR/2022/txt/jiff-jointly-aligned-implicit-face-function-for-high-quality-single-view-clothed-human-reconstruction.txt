Abstract
This paper addresses the problem of single view 3D hu-man reconstruction. Recent implicit function based meth-ods have shown impressive results, but they fail to recover fine face details in their reconstructions. This largely de-grades user experience in applications like 3D telepresence.
In this paper, we focus on improving the quality of face in the reconstruction and propose a novel Jointly-aligned
Implicit Face Function (JIFF) that combines the merits of the implicit function based approach and model based ap-proach. We employ a 3D morphable face model as our shape prior and compute space-aligned 3D features that capture detailed face geometry information. Such space-aligned 3D features are combined with pixel-aligned 2D features to jointly predict an implicit face function for high quality face reconstruction. We further extend our pipeline and introduce a coarse-to-fine architecture to predict high quality texture for our detailed face model. Extensive evalu-ations have been carried out on public datasets and our pro-posed JIFF has demonstrates superior performance (both quantitatively and qualitatively) over existing state-of-the-arts. 1.

Introduction
Under the current social distancing measures of the
COVID-19 pandemic, video conferencing has become the major form of daily communication. With the increased popularity of 3D hardware like AR goggles, 3D telepres-ence [42] will soon likely emerge as the next generation communication standard. High quality 3D human recon-struction is at the core of this technology and is one of the current hottest topics. Traditional reconstruction methods depend on expensive capturing hardware and tedious cal-ibration procedure to produce good looking models [15].
This limits their applications to studio settings with expert users and greatly hinders the growth of AR/VR applica-tions. It is highly desirable to develop easy-to-use tools that allow easy creation of high quality 3D human models by
Figure 1. Reconstruction by PIFu [55] and our JIFF. Model recon-structed by JIFF shows much better geometric details and texture than that by PIFu. home users using commodity RGB cameras.
With the advance in deep learning techniques, recent 3D human reconstruction methods have achieved impres-sive results using as few as a single image [29, 55, 74].
These methods can be roughly divided into model based methods [3, 4, 6, 7] and model-free methods [11, 12, 18, 26, 49, 55]. Model based methods typically fit a parametric human model (e.g., SMPL [37]) to an image to produce a naked 3D human model. They have difficulties in recover-ing high-frequency details such as clothing and hair. Model-free methods, on the other hand, solve this problem by pre-dicting the occupancy of a discretized volume space. One very representative model-free method is PIFu [55], which exploits a Multi Layer Perceptron (MLP) to model an im-plicit function for predicting the occupancy value of a query point based on pixel-aligned features extracted from an im-age. PIFu and its variants [34, 56] have achieved state-of-the-art results in free-form full body human reconstruction.
However, their reconstructions are often lack of fine face details (see Fig. 1). Considering the ultra-high-definition rendering standards (i.e. 4K UHD and 8K UHD) that are common nowadays, their face reconstruction quality is ob-viously far from satisfactory and largely degrades user ex-perience in AR/VR applications like 3D telepresence.
To achieve high quality human reconstruction with fine face details, we propose a novel Jointly-aligned Implicit
Face Function (aka JIFF) that combines the merits of the implicit function based approach and model based ap-proach. Specifically, we employ the 3D morphable face model (3DMM) [8] as our shape prior and compute space-aligned 3D features to capture detailed face geometry and texture information. There are also recent methods [25, 72] using 3D priors to enhance the implicit function representa-tion by introducing geometric constraints to regularize the reconstruction. For example, [25] and [72] utilize coarse 3D volume features and SMPL body model, respectively, to improve human body reconstruction. To the best of our knowledge, JIFF is the first method focusing on recovering high quality face details in both shape and texture.
JIFF exploits space-aligned 3D features extracted from 3DMM as well as pixel-aligned 2D features extracted from image to jointly predict an implicit face function for high quality face reconstruction. In summary, our method first fits the 3DMM to the face in an image and employs two sep-arate encoders to compute 3D shape and texture features, re-spectively, from the resulting 3D model. Given a 3D query point, we obtain its space-aligned 3D features with trilinear interpolation. Such space-aligned 3D features are combined with pixel-aligned 2D features for predicting the occupancy value of the query point using a MLP. We further extend our pipeline and introduce a coarse-to-fine architecture to predict high quality texture for our detailed face model.
By taking advantages of both the implicit function based approach and model based approach, our method can suc-cessfully recover fine face details in both shape and texture (see Fig. 1). Our key contributions are as follows:
• We propose JIFF, a novel implicit face function for high quality single view 3D face reconstruction, which inte-grates 3D face prior into the implicit function representa-tion for high quality face shape reconstruction.
• We exploit per-vertex color information provided by the 3DMM and introduce a coarse-to-fine architecture for high quality face texture prediction.
• We demonstrate how JIFF can naturally be extended to produce full body human reconstruction by simply ap-pending a “PIFu” head (implemented as a MLP) to its convolutional image encoder.
• We carry out extensive experiments on public bench-marks and demonstrate that JIFF outperforms current state-of-the-arts by a large margin. 2.