Abstract
We propose the Neurally-Guided Shape Parser (NGSP), a method that learns how to assign fine-grained semantic labels to regions of a 3D shape. NGSP solves this problem via MAP inference, modeling the posterior probability of a label assignment conditioned on an input shape with a learned likelihood function. To make this search tractable,
NGSP employs a neural guide network that learns to ap-proximate the posterior. NGSP finds high-probability la-bel assignments by first sampling proposals with the guide network and then evaluating each proposal under the full likelihood. We evaluate NGSP on the task of fine-grained semantic segmentation of manufactured 3D shapes from Part-Net, where shapes have been decomposed into regions that correspond to part instance over-segmentations. We find that
NGSP delivers significant performance improvements over comparison methods that (i) use regions to group per-point predictions, (ii) use regions as a self-supervisory signal or (iii) assign labels to regions under alternative formulations.
Further, we show that NGSP maintains strong performance even with limited labeled data or noisy input shape regions.
Finally, we demonstrate that NGSP can be directly applied to CAD shapes found in online repositories and validate its effectiveness with a perceptual study. 1.

Introduction
The ability to semantically segment 3D shapes is im-portant for numerous applications in vision, graphics, and robotics: reverse-engineering the part structure of an object to support editing and manipulation; producing training data for structure-aware generative shape models [10, 14, 24]; helping autonomous agents understand how to interact with objects in their environment [1]; and more. These appli-cations often demand that the parts detected be fine-scale (e.g. wheels of an office chair) and hierarchically-organized (e.g. a cabinet door decomposes into a handle, door, and frame). Producing such segmentations has proved to be a challenging task, as it is expensive to gather large amounts of data at this granularity; PartNet [25] is the only existing large-scale dataset of this type.
Recent work on 3D shape semantic segmentation has mainly focused on end-to-end approaches that operate on shape atoms (e.g. mesh faces, point cloud points, occupancy grid voxels), i.e. the lowest-level geometric entity in the input representation [12, 28, 29, 38]. While these methods achieve impressive performance on many tasks, they do not often transfer well to domains with fine-grained labels or when access to labeled data is limited. We postulate that one reason for this phenomenon is that attempting to label shape atoms directly results in a massive search space, allowing learning-based methods to overfit unless the ratio of labeled shape instances to the label set complexity is high.
One way to address this issue is to design systems that make use of shape regions. When the number of shape regions becomes significantly smaller than the number of shape atoms, the label assignment problem becomes easier.
Such a framing may allow methods to learn fine-grained semantic segmentation when access to labeled data is limited.
When shape regions are provided, they can be used in various ways: (i) as a post-process aggregation on top of shape atom predictions, (ii) to formulate auxiliary self-supervised objectives, or (iii) as the object to be labeled. Methods that operate within this last paradigm can more directly reason about relationships between regions, which can help improve fine-grained segmentation performance by better considering the context of a region within the entire shape.
The problem of decomposing a shape into regions useful for semantic segmentation is application-dependent. For
CAD shapes and scenes found in online repositories, this type of region decomposition is often produced as a by-product of the modeling process, e.g. each part instance will be made out of one or more connected mesh compo-nents [22, 34, 43]. Discovering region decompositions for shapes that do not already provide them is a well-studied problem within computer vision and graphics. There has been considerable recent effort on unsupervised techniques that approximate 3D shapes with primitives [6,17,27,32,33],
and there is a long history of research on shape segmentation through purely geometric analysis [3, 15, 36]. There is even reason to believe that region decomposition solutions can generalize across shape categories, i.e. the way that shapes (especially manufactured objects) decompose into parts is largely category-independent [11, 44].
In this paper, we propose the Neurally-Guided Shape
Parser (NGSP), a method that learns to assign fine-grained labels from a semantic grammar to regions of a 3D shape.
Our approach is based on maximum a posteriori (MAP) in-ference in a model of the probability that a label assignment to the shape’s regions is correct. Our likelihood consists of a mixture of modules that each operate on some regions of the shape. One set of modules evaluates the validity of the implied geometry and spatial layout for each label in the semantic grammar. Another module evaluates groups of re-gions formed by the label assignment. As this combinatorial search problem is too complex to solve with exhaustive enu-meration, we employ a neural guide network to approximate the posterior. The guide network reasons locally, predicting the label probability for each region independently. Using the per-region probabilities produced by the guide network,
NGSP importance samples a set of proposed label assign-ments. To choose the best proposal out of this set, each label assignment is evaluated under the full likelihood, and the sample with highest posterior probability is chosen.
We compare NGSP against methods that use shape re-gions as a post-process, a self-supervisory signal, or assign labels to regions with different search strategies and likeli-hood formulations. We evaluate each method on the task of fine-grained semantic segmentation of manufactured 3D shapes from PartNet, where each method has access to re-gions from the annotated part instance over-segmentations (e.g. each semantic part instance may consist of multiple regions). NGSP achieves the best semantic segmentation performance, even in paradigms where access to labeled data is limited or when the input shape regions are noisy.
To validate our design decisions, we run an ablation study measuring the effect of each likelihood term and the neural guide network. Finally, we show that NGSP can find good semantic segmentations on ‘in the wild’ CAD shapes found from online repositories, and evaluate its performance with a forced choice perceptual study against comparison methods.
Code for our method and experiments can be found at found at https://github.com/rkjones4/NGSP .
In summary, our contributions are: (i) We present the Neurally-Guided Shape Parser (NGSP), a method that learns how to assign labels from a seman-tic grammar to regions of a 3D shape. NGSP performs approximate MAP inference, using a guide network to find high-probability label assignments under a learned posterior probability of a label assignment conditioned on an input shape. (ii) We demonstrate that NGSP finds better fine-grained semantic segmentations for manufactured shapes com-pared with methods that use shape regions in alterna-tive learning paradigms. 2.