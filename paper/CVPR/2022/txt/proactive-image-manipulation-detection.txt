Abstract
Image manipulation detection algorithms are often trained to discriminate between images manipulated with particular Generative Models (GMs) and genuine/real im-ages, yet generalize poorly to images manipulated with
GMs unseen in the training. Conventional detection algo-rithms receive an input image passively. By contrast, we propose a proactive scheme to image manipulation detec-tion. Our key enabling technique is to estimate a set of tem-plates which when added onto the real image would lead to more accurate manipulation detection. That is, a template protected real image, and its manipulated version, is better discriminated compared to the original real image vs. its manipulated one. These templates are estimated using cer-tain constraints based on the desired properties of tem-plates. For image manipulation detection, our proposed ap-proach outperforms the prior work by an average precision of 16% for CycleGAN and 32% for GauGAN. Our approach is generalizable to a variety of GMs showing an improve-ment over prior work by an average precision of 10% aver-aged across 12 GMs. Our code is available at https:// www.github.com/vishal3477/proactive_IMD. 1.

Introduction
It’s common for people to share personal photos on so-cial networks. Recent developments of image manipula-tion techniques via Generative Models (GMs) [13] result in serious concerns over the authenticity of the images. As these techniques are easily accessible [7,8,21,27,31,44,61], the shared images are at a greater risk for misuse after ma-nipulation. Generation of fake images can be categorized into two types: entire image generation and partial image manipulation [46, 48]. While the former generates entirely new images by feeding a noise code to the GM, the lat-ter involves the partial manipulation of a real image. Since the latter alters the semantics of real images, it is generally considered as a greater risk, and thus partial image manipu-lation detection is the focus of this work.
Figure 1. Passive vs. proactive image manipulation detec-tion Classic passive schemes take an image as it is to dis-criminate a real image vs. its manipulated one created by a
Generative Model (GM). In contrast, our proactive scheme performs encryption of the real image so that our detection module can better discriminate the encrypted real image vs. its manipulated counterpart.
Detecting such manipulation is an important step to al-leviate societal concerns on the authenticity of shared im-ages. Prior works have been proposed to combat manipu-lated media [12]. They leverage properties that are prone to being manipulated, including mouth movement [39], ste-ganalysis features [51], attention mechanism [11, 23], etc.
However, these methods are often overﬁtted to the image manipulation method and the dataset used in training, and suffer when tested on data with a different distribution.
All the aforementioned methods adopt a passive scheme since the input image, being real or manipulated, is accepted as is for detection. Alternatively, there is also a proactive scheme proposed for a few computer vision tasks, which involves adding signals to the original image. For example, prior works add a predeﬁned template to real images which either disrupt the output of the GM [40, 41, 54] or tag im-ages to real identities [46]. This template is either a one-hot encoding [46] or an adversarial perturbation [40, 41, 54].
Motivated by improving the generalization of manipu-lation detection, as well as the proactive scheme for other tasks, this paper proposes a proactive scheme for the pur-pose of image manipulation detection, which works as fol-lows. When an image is captured, our algorithm adds an imperceptible signal (termed as template) to it, serving as an
Table 1. Comparison of our approach with prior works. Generalizable column means if the performance is reported on datasets unseen during training. [Keys: Img. man. det.: Image manipulation detection, Img. ind.: Image independent]
Method
Cozzolino et al. [10]
Nataraj et al. [28]
Rossler et al. [39]
Zhang et al. [59]
Wang et al. [48]
Wu et al. [51]
Qian et al. [35]
Dang et al. [11]
Masi et al. [26]
Nirkin et al. [29]
Asnani et al. [3]
Segalis et al. [41]
Ruiz et al. [40]
Yeh et al. [54]
Wang et al. [46]
Ours
Year 2018 2019 2019 2019 2020 2020 2020 2020 2020 2021 2021 2020 2020 2020 2021
-Purpose
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Img. man. det.
Detection scheme
Passive
Passive
Passive
Passive
Passive
Passive
Passive
Passive
Passive
Passive
Passive
Proactive Deepfake disruption
Proactive Deepfake disruption
Proactive Deepfake disruption
Proactive
Proactive
Deepfake tagging
Img. man. det.
Manipulation type
Entire/Partial
Entire/Partial
Entire/Partial
Partial
Entire/Partial
Entire/Partial
Entire/Partial
Partial
Partial
Partial
Entire/Partial
Partial
Partial
Partial
Partial
Partial
Generalizable (cid:52) (cid:52) (cid:55) (cid:52) (cid:52) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:52) (cid:55) (cid:55) (cid:55) (cid:55) (cid:52)
Add perturbation (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:52) (cid:52) (cid:52) (cid:52) (cid:52)
Recover perturbation (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:55) (cid:52) (cid:52)
Template learning method
-----------Adversarial attack
Adversarial attack
Adversarial attack
Fixed template
Unsupervised learning
# of templates
-----------1 1 1
> 1
> 1
Img. ind. templates
-----------(cid:52) (cid:52) (cid:52) (cid:55) (cid:52) encryption. If this encrypted image is shared and manipu-lated through a GM, our algorithm accurately distinguishes between the encrypted image and its manipulated version by recovering the added template. Ideally, this encryption process could be incorporated into the camera hardware to protect all images after being captured. In comparison, our approach differs from related proactive works [40,41,46,54] in its purpose (detection vs other tasks), template learning (learnable vs predeﬁned), the number of templates, and the generalization ability.
Our key enabling technique is to learn a template set, which is a non-trivial task. First, there is no ground truth template for supervision. Second, recovering the template from manipulated images is challenging. Third, using one template can be risky as the attackers may reverse engineer the template. Lastly, image editing operations such as blur-ring or compression could be applied to encrypted images, diminishing the efﬁcacy of the added template.
To overcome these challenges, we propose a template es-timation framework to learn a set of orthogonal templates.
We perform image manipulation detection based on the re-covery of the template from encrypted real and manipulated images. Unlike prior works, we use unsupervised learning to estimate this template set based on certain constraints.
We deﬁne different loss functions to incorporate proper-ties including small magnitude, more high frequency con-tent, orthogonality and classiﬁcation ability as constraints to learn the template set. We show that our framework achieves superior manipulation detection than State-of-The-Art (SoTA) methods [10, 28, 46, 59]. We propose a novel evaluation protocol with 12 different GMs, where we train on images manipulated by one GM and test on unseen GMs.
In summary, the contributions of this paper include:
• We propose a novel proactive scheme for image manipu-lation detection.
• We propose to learn a set of templates with desired prop-erties, achieving higher performance than a single tem-plate approach.
• Our method substantially outperforms the prior works on image manipulation detection. Our method is more gen-eralizable to different GMs showing an improvement of 10% average precision averaged across 12 GMs. 2.