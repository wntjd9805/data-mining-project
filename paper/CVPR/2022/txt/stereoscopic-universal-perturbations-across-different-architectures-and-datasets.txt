Abstract
We study the effect of adversarial perturbations of im-ages on deep stereo matching networks for the disparity es-timation task. We present a method to craft a single set of perturbations that, when added to any stereo image pair in a dataset, can fool a stereo network to significantly al-ter the perceived scene geometry. Our perturbation im-ages are “universal” in that they not only corrupt estimates of the network on the dataset they are optimized for, but also generalize to different architectures trained on differ-ent datasets. We evaluate our approach on multiple bench-mark datasets where our perturbations can increase the D1-error (akin to fooling rate) of state-of-the-art stereo net-works from 1% to as much as 87%. We investigate the effect of perturbations on the estimated scene geometry and iden-tify object classes that are most vulnerable. Our analysis on the activations of registered points between left and right images led us to find architectural components that can in-crease robustness against adversaries. By simply designing networks with such components, one can reduce the effect of adversaries by up to 60.5%, which rivals the robustness of networks fine-tuned with costly adversarial data augmen-tation. Our design principle also improves their robustness against common image corruptions by an average of 70%. 1.

Introduction
Deep neural networks are vulnerable to adversarial per-turbations, where small changes in the input image(s) can cause large inference errors, for instance in the label of ob-jects portrayed within. Even when the images contain suffi-cient information for inference, for instance in stereo where the disparity between two calibrated images is used to infer
† denotes authors with equal contributions.
Code: github.com/alexklwong/stereoscopic-universal-perturbations the depth of the scene, adversarial perturbations have been shown to alter the depth map [44]. Such perturbations are ordinarily specific to each individual input, and depend on the particular deep network architecture and the particular dataset on which it is trained.
For classification, [22] showed that a single perturbation can be crafted to disrupt the inference for all images in a dataset with high probability. These are called “universal” adversarial perturbations, even though they are universal to each image in a particular dataset, and usually do not ex-tend to different datasets. In this paper, we show the exis-tence of stereoscopic universal perturbations (SUPs). SUPs are perturbations that can disrupt the depth or disparity es-timate of different stereo networks, with different architec-tures, trained on different datasets, and operating on differ-ent images and domains.
Adversarial perturbations arose mainly as a means to study the topology and geometry of the decision boundary of deep networks. Since individual perturbations had to be crafted for each image, security concerns were far fetched.
Universal adversarial perturbations, however, revealed vul-nerabilities that could be shared among different images.
Still, crafting them required knowledge of the architecture and availability of the training set. In contrast, the existence of universal adversarial perturbations for stereo and other spatial inference tasks, common in robotics and autonomy, suggests that such perturbations could present a concern, es-pecially if they can be applied to different images, processed by different neural network models that are trained on dif-ferent datasets. To the best of our knowledge, we are the first to show, for stereo, that universal perturbations can be applied effectively even without knowledge of the trained model, and generalize across domains and datasets. Such perturbations can be optimized on an off-the-shelf model and realized as a filter to be placed on top of a camera lens.
Our main methodological innovation is to design SUPs so that they are approximately space equivariant. We build
Figure 1. Universality across models and datasets. We optimized a single pair of perturbation images for AANet on the KITTI dataset.
When added to a stereo pair from KITTI 2015, it corrupts the disparity estimates of AANet and PSMNet. The same perturbations can be added to stereo pairs in Flyingthings3D to fool AANet and DeepPruner. the perturbation out of a single tile, repeated periodically.
Although the tile is not constrained to have periodic bound-ary conditions, we notice that the model learns perturba-tions where boundary artifacts are not obvious, partly be-cause the perturbation itself is designed to be small enough to be quasi-imperceptible. Our design naturally regularizes the tile with data, allowing it to generalize to different image pairs, processed with different architectures trained with different datasets – increasing error from 1% to as much as 87% when added to network inputs.
In our experiments, we observe that the errors in dispar-ity induced by SUPs are more pronounced on certain classes of objects. We conjecture that this is due to said classes ex-hibiting more homogeneous regions, which are more prone to errors in disparity due to ambiguity. We also found that there is a systematic bias towards closer distance (larger dis-parity) after perturbations. To study the effect of SUPs on stereo networks, we investigate the activations of left and right feature maps before and after adding perturbations.
We validate empirically that the embedding function am-plifies the adversarial signal: The embedding of perturbed registered features between the images grows more uncor-related throughout a forward pass than the embedding of the original or “clean” registered features, which “fools” a stereo network into estimating incorrect correspondences.
Moreover, we use SUPs to improve robustness in stereo networks. We study the effect that different architectural elements (deformable convolutions, and explicit matching modules) have on mitigating perturbations. We observe that by simply designing networks with these elements (and fol-lowing standard training protocols), one can reduce the ef-fect of adversaries to a similar degree as fine-tuning a model (that lacks such elements) with adversarial data augmen-tation. While robustness is increased with fine-tuning, it come at a significant cost in time and compute. In contrast, the proposed architectural design choices can mitigate at-tacks (60.5% error reduction), and only require a few lines of code; they also improve robustness against common im-age perturbations i.e. lossy compression, noise, blur by an average of 70%. Conclusions are valid for three different architectures, across three datasets. While these are chosen to represent the variety in use today, we cannot exclude that there could be tasks, data and models on which our method to craft perturbations is ineffective, and conversely pertur-bations that are not mitigated by the methods we propose.
Our contributions include: (i) The design of the first stereoscopic universal perturbations (SUPs) that can not only fool the network they are optimized for, but also other networks across multiple datasets. We perform an empir-ical analysis on how SUPs affect (ii) the estimated scene geometry, (iii) different object classes, and (iv) the features of registered points in a stereo pair. Our results shed light on how SUPs fool stereo networks and led us to uncover (v) architectural designs, i.e. deformable convolution and explicit feature matching, that mitigate the effect of SUPs to a similar degree as fine-tuning on them. A discussion of potential negative societal impact is available in Supp. Mat. 2.