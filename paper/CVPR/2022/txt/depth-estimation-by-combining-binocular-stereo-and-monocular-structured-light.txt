Abstract
It is well known that the passive stereo system cannot adapt well to weak texture objects, e.g., white walls. How-ever, these weak texture targets are very common in indoor environments. In this paper, we present a novel stereo sys-tem, which consists of two cameras (an RGB camera and an
IR camera) and an IR speckle projector. The RGB camera is used both for depth estimation and texture acquisition. The
IR camera and the speckle projector can form a monocu-lar structured-light (MSL) subsystem, while the two cam-eras can form a binocular stereo subsystem. The depth map generated by the MSL subsystem can provide external guid-ance for the stereo matching networks, which can improve the matching accuracy significantly. In order to verify the effectiveness of the proposed system, we build a prototype and collect a test dataset in indoor scenes. The evaluation results show that the Bad 2.0 error of the proposed system is 28.2% of the passive stereo system when the network RAFT is used. The dataset and trained models are available at https://github.com/YuhuaXu/MonoStereoFusion. 1.

Introduction
Depth estimation is a fundamental problem in computer vision, which has numerous applications in the fields of 3D modeling, robotics, UAVs, augmented realities (AR), and autonomous driving [1, 10, 31]. Depth estimation methods can be divided into active structured-light, binocular stereo vision, time-of-flight (TOF), and monocular depth estima-tion.
Since Microsoft Kinect [48] was released in 2010, consumer-grade depth sensors have been widely used.
Kinect is based on the monocular structured-light method, which was also used in iPhone X released in 2017. How-ever, it may fail to obtain depth measurements for distant objects, or outdoor scenes under strong light. The binocular stereo vision system has a larger measurement range than
*Corresponding author the structured-light system, and it can also work in outdoor environment with strong sunlight, but it is easily affected by the surface texture of the objects. In recent years, stereo matching methods based on deep learning have achieved remarkable progress. However, these methods may still fail on scenes with weak texture (e.g., white walls). And this kind of weak texture objects are very common in indoor environment. The binocular active structured-light system (e.g., Intel D435 [14]) relies on two IR cameras and an IR projector for depth estimation, which has good adaptability in both indoor and outdoor situations. To acquire texture, a third camera (i.e. RGB camera) is required. Since there is a baseline between the RGB camera and IR camera, a coor-dinate system conversion step is required to make the depth image aligned with the RGB image. Due to the noise of the depth map and the error of the calibration parameters, it is difficult to accurately align the RGB image and depth map. In terms of hardware, three cameras and one projector are required, which is not compact. TOF has poor adapt-ability to objects with low reflectivity and distant objects.
In addition, TOF suffers from multipath interference [30].
The monocular depth estimation methods cannot obtain the depth maps with a certain scale [11].
In this work, we seek a compact depth sensing solu-tion that can integrate the advantages of the monocular structured-light and binocular stereo vision.
The main contributions of this work are: (1) We propose a novel stereo vision system, which con-sists of an RGB camera, an IR camera and an IR speckle projector. Especially, the IR camera is not attached with a filter. Thus the IR camera can receive IR light (invisible to human eyes) and ambient light (visible to human eyes) si-multaneously. The IR camera and IR projector can form a monocular active structured-light system as Kinect, while the IR camera and the RGB camera can form a binocular stereo system. These two types of stereo systems have com-plementary advantages. We can obtain a robust stereo sys-tem by fusing the initial depth map obtained by the active structured-light system in the cost volume of stereo match-ing network.
(2) We build a prototype system and collect a new stereo dataset for integrating the monocular structured light and binocular stereo vision (i.e. MonoBinoStereo) to verify the effectiveness of the proposed method. The dataset will be open for further research. (3) We find that DNN can accurately estimate the dispar-ity map of a pair of asymmetric stereo images, where one is passive and the other is active (with speckles). To the best of our knowledge, this is the first time that DNN is used to process this kind of stereo images with asymmetric texture.
The features of the proposed stereo system are as fol-lows: (1) Compared with the classical binocular stereo vision, it is robust to weak texture objects and rich texture objects simultaneously in indoor environments. (2) Compared with the existing monocular structured-light system (e.g., Kinect [48] and Astra [24]), it has a larger measuring distance range and better performance in outdoor environment. (3) Compared with the existing active depth sensing sys-tem (e.g., Kinect and Intel D435), its output depth maps
In addition, the depth map is have better completeness. naturally aligned with the RGB image pixel-by-pixel. This feature gives our camera a significant advantage in certain applications, such as object segmentation. (4) For the interference of strong sunlight, it will degen-erate into an ordinary passive stereo system in outdoor en-vironments. 2.