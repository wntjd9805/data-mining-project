Abstract
Vision-and-language Navigation (VLN) task requires an embodied agent to navigate to a remote location following a natural language instruction. Previous methods usually adopt a sequence model (e.g., Transformer and LSTM) as the navigator. In such a paradigm, the sequence model pre-dicts action at each step through a maintained navigation state, which is generally represented as a one-dimensional vector. However, the crucial navigation clues (i.e., object-level environment layout) for embodied navigation task is discarded since the maintained vector is essentially un-structured.
In this paper, we propose a novel Structured state-Evolution (SEvol) model to effectively maintain the environment layout clues for VLN. Specifically, we utilise the graph-based feature to represent the navigation state instead of the vector-based state. Accordingly, we devise a Reinforced Layout clues Miner (RLM) to mine and de-tect the most crucial layout graph for long-term navigation via a customised reinforcement learning strategy. More-over, the Structured Evolving Module (SEM) is proposed to maintain the structured graph-based state during nav-igation, where the state is gradually evolved to learn the object-level spatial-temporal relationship. The experiments on the R2R and R4R datasets show that the proposed SEvol model improves VLN models’ performance by large mar-gins, e.g., +3% absolute SPL accuracy for NvEM and +8% for EnvDrop on the R2R test set. 1.

Introduction
In recent years, Embodied-AI (E-AI) that requires em-bodied agents to complete tasks has arrested extensive inter-ests of both computer version and natural language process-ing community. Numerous datasets [3, 31] have been con-structed to simulate realistic environments to support vari-ous embodied tasks such as navigation [31, 42], interactive
*Corresponding author: Si Liu.
Figure 1. At each step t, (a) previous methods predict action at based on a vector-based navigation state st while the object-level layout memory is discarded; (b) we propose SEvol to maintain a graph-based navigation state st, which can effectively record the layout memory via the structured state-evolution. learning [6, 33] and multi-agent cooperation [25], etc.
One of the most attractive application scenarios of E-AI is the Vision-and-Language Navigation (VLN) task [2], where the goal is for an embodied agent in a 3D environ-ment to navigate to the specific location following the nat-ural language instruction. As shown in Figure 1(a), previ-ous methods [8, 21, 22, 34] usually adopt sequence model (e.g., Transformer and LSTM) to model the sequential de-cision process. At each step t, the action is predicted ac-cording to the navigation state st, which maintains the his-torical and current environment information. Commonly,
the navigation state is maintained in the form of unstruc-tured one-dimensional vector. The environment clues at each step, i.e., visual and orientation features, are all com-pressed and pooled into this unstructured vector. Therefore, the structured object-level environment layout information is discarded during this process. However, the environment layout clues are crucial for the embodied VLN task. As shown in Figure 1(a), to fulfill the instruction like ‘go inside the door opposite the bathtub’, the agent of previous meth-ods is confused at step t since the landmark object ‘bathtub’ can not be observed, and the agent needs to utilise the his-torical layout clues (i.e., the door is opposite the bathtub) at step t − 1 to make the right action.
Therefore, we aim to improve the VLN paradigm via maintaining a structured navigation state, in which three im-portant factors need to be considered. (i) How to represent the navigation state to contain structured layout memory. (ii) How to mine the pivotal layout information for the cur-rent and future decisions according to the instruction. (iii)
How to store and update a structured state while satisfying the property of long short-term memory.
To achieve the aforementioned objectives, we propose a
Structured state-Evolution (SEvol) model as shown in Fig-ure 1(b), where multi-fold innovations are made. (i) Instead of the vector-based feature, we propose to adopt the graph-based feature as the navigation state, which is capable of holding a structured layout memory. (ii) We design a Rein-forced Layout clues Miner (RLM) to mine the most crucial layout information. RLM learns to detect and sample the es-sential subgraph from the whole layout graph, conditioned on both the current navigation state and the instruction, e.g., sampling subgraph <door, opposite, bathtub> according to the language ‘go inside the door opposite the bathtub’.
In RLM, we customise a reinforcement learning strategy to make the miner focus on both the immediate interests and the long-term influence of the subgraph sampling. (iii) To effectively store and update a structured graph-based state during the whole navigation process, we devise a Structured
Evolving Module (SEM). Specifically, SEM takes the cur-rent graph features from RLM as input to evolve the naviga-tion state at each step. The evolution of the navigation state is achieved by interacting with a learnable matrix D (shown in Figure 1(b)), which stores the structured layout memory.
D is updated through a matrix version of recurrent neural network. Thus the navigation state contains object-level spatial-temporal relationship that assists the action decision, e.g., the relation ‘door opposite bathtub’ in Figure 1(b).
Experiments on Room-to-Room (R2R) [2] and Room-for-Room (R4R) show that the proposed SEvol model improves
VLN models’ performance by large margins.
To summarise, we make the following contributions:
• We propose a simple yet effective SEvol model that provides new insights to the VLN community. The structured navigation state is leveraged to maintain the object-level environment layout during navigation.
SEvol achieves state-of-the-art performance on R2R.
• We design a Reinforced Layout clues Miner (RLM) to learn how to detect and sample the most critical sub-graph features from the layout graph for current and future action decisions.
• We devise a Structured Evolving Module (SEM) to gradually evolve the structured navigation-state along with the navigation process, maintaining a long short-term layout memory. 2.