Abstract
Pan-sharpening aims to obtain high-resolution multi-spectral (MS) images for remote sensing systems and deep learning-based methods have achieved remarkable success.
However, most existing methods are designed in a black-box principle, lacking sufficient interpretability. Addition-ally, they ignore the different characteristics of each band of MS images and directly concatenate them with panchro-matic (PAN) images, leading to severe copy artifacts [9]. To address the above issues, we propose an interpretable deep neural network, namely Memory-augmented Deep Condi-tional Unfolding Network with two specified core designs.
Firstly, considering the degradation process, it formulates the Pan-sharpening problem as the minimization of a vari-ational model with denoising-based prior and non-local auto-regression prior which is capable of searching the similarities between long-range patches, benefiting the tex-ture enhancement. A novel iteration algorithm with built-in CNNs is exploited for transparent model design. Sec-ondly, to fully explore the potentials of different bands of
MS images, the PAN image is combined with each band of
MS images, selectively providing the high-frequency details and alleviating the copy artifacts. Extensive experimental results validate the superiority of the proposed algorithm against other state-of-the-art methods. 1.

Introduction
With the rapid development of remote sensors, increas-ing satellite images are available for a wide range of ap-plications such as mapping services, military systems, and environmental monitoring. Satellites capture multispectral (MS) and panchromatic (PAN) images simultaneously with complementary information for each modality that PAN im-ages have a high spatial solution and MS images contain rich spectral information [15, 36]. In order to obtain the im-† Co-first authors contributed equally,* corresponding author.
This work was supported by the USTC Research Funds of the Double
First-Class Initiative (Grant YD2100002004, 2100002003).
Figure 1. Trade-off between parameters and model performance for Pan-sharpening on WorldViewII dataset. ages with both high spectral and spatial resolution, the Pan-sharpening technique that aims to fuse the MS and PAN images has attracted increasing attention.
The past decades have witnessed the explosive growth of research works in the Pan-sharpening field, where the fo-cuses include model-based and deep learning (DL)-based methods. Due to the ill-posed property of Pan-sharpening, the former usually requires hand-crafted priors to regularize the solution space of the latent high-resolution (HR) MS im-ages. However, the limited representation ability of hand-crafted priors results in unsatisfactory performance when processing complex scenes. Besides, the traditional meth-ods are challenging in optimization, limiting their prac-Inspired by the success of deep neu-tical applications. ral networks, various DL-based Pan-sharpening algorithms have been proposed. While they demonstrate superiority in feature representation and model generalization, the long-standing issue that existing DL-based Pan-sharpening meth-ods suffer from is the lack of interpretability as most of them are designed in a black-box principle without considering the rationality of models. Integrating the domain knowledge with interpretable DL-based models is therefore promising for improving the Pan-sharpening performance. Addition-ally, existing methods ignore the different characteristics of each band of MS images and directly concatenate them with
PAN images as input along channel dimension, which may lead to the severe copy artifacts [9].
Very recently, a few models attempt to incorporate ad-vantages of both model-based and DL-based methods in the image processing community [11, 32, 60]. Inspired by such designs, Xu et.al [52] propose the first deep unfolding net-work for Pan-sharpening. It formulates Pan-sharpening as two separate optimization problems regularized by a deep prior for both PAN and low-resolution (LR) MS images.
Nevertheless, the designed implicit priors are still difficult to investigate thoroughly their influence and the potential of cross-stages has not been fully explored.
In summary, existing state-of-the-art (SOTA) methods suffer from two-fold issues: 1) lacking sufficient inter-pretability, and 2) ignoring the different characteristics of each band of MS images. To this end, in this paper, we pro-pose an interpretable deep unfolding network by combin-ing advantages of both the model-based and data-driven DL methods, namely Memory-augmented Deep Conditional
Unfolding Network (MDCUN). Considering the degrada-tion process and observing that MS images often con-tain repetitive structures, we formulate the Pan-sharpening problem as the minimization of a variational model with two newly-designed prior terms, including denoising-based prior and non-local auto-regression prior. Specifically, the former aims to reconstruct the latent MS images while the latter learns the similarities between long-range patches, benefiting the texture enhancement and reducing the alias-ing artifacts. Then, a novel effective iteration algorithm with built-in CNNs is exploited for transparent model de-sign to further increase the model interpretability. More-over, to fully explore the potentials of different bands of
MS images, we propose a band-aware PAN-guided high-frequency information extraction module. To be specific, the PAN image is combined with each band of MS image, selectively providing the high-frequency details and allevi-ating the copy artifacts. Additionally, the contextual mem-ory mechanism is introduced to augment the capacity across iterative stages, therefore facilitating the information inter-action. The proposed method is assessed with extensive ex-periments, and the results demonstrate its superiority qual-itatively and quantitatively. The contributions of our work are summarized as follows:
• We formulate the Pan-sharpening as the minimization of a variational model and introduce the denoising-based prior and non-local auto-regression prior to im-prove the long-range coherence.
• We propose an interpretable deep network, namely
Memory-augmented Deep Conditional Unfolding Net-work, which incorporates advantages of both the model-based and data-driven DL methods.
• A band-aware PAN-guided high-frequency informa-tion extraction module is devised to fully explore the potentials of different bands of MS images. The con-textual memory mechanism is additionally introduced to augment the capacity across iterative stages, facili-tating the information interaction.
• Extensive experiments over different satellite datasets demonstrate that our method outperforms state-of-the-art algorithms with fewer parameters. 2.