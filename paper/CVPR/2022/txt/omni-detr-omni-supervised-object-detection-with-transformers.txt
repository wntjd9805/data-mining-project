Abstract
We consider the problem of omni-supervised object de-tection, which can use unlabeled, fully labeled and weakly labeled annotations, such as image tags, counts, points, etc., for object detection. This is enabled by a unified architecture, Omni-DETR, based on the recent progress on student-teacher framework and end-to-end transformer based object detection. Under this unified architecture, dif-ferent types of weak labels can be leveraged to generate ac-curate pseudo labels, by a bipartite matching based filter-ing mechanism, for the model to learn. In the experiments,
Omni-DETR has achieved state-of-the-art results on mul-tiple datasets and settings. And we have found that weak annotations can help to improve detection performance and a mixture of them can achieve a better trade-off be-tween annotation cost and accuracy than the standard com-plete annotation. These findings could encourage larger object detection datasets with mixture annotations. The code is available at https://github.com/amazon-research/omni-detr. 1.

Introduction
Most of the successes of recent object detection are at-tributed to the large-scale well-established object detection datasets [11, 12, 25, 28, 38], which have accurate and com-plete detection annotation (category and bounding box or segmentation mask) for every object of interest in an image.
In general, complete and accurate detection annotation is very expensive. For example, complete annotation of a sin-gle image of MS-COCO [28] takes about 346 seconds, 76.5 seconds on each category elimination and 269.5 seconds on accurate bounding box localization, on average [35]1.
Given this expensive cost, it is very difficult to scale up the data size. For example, OpenImages consisting of 9 million images [25] used a combination of machine annotation and human verification to reduce the annotation cost. The ques-⋆ Work done during internship at Amazon. †Corresponding author. 1Not accurate numbers from [28] but rough estimation from [35].
Figure 1. The top is the visualization of different forms of weak annotations, and the bottom is the trade-off comparison (accu-racy v.s. annotation cost) of supervised/semi-supervised/omni-supervised detection (see Section 5.5 for more details). tion is, do we need accurate and complete annotation which is expensive to achieve strong detection performances?
There are many weaker forms of object annotation as shown in Figure 1 (top), e.g., points, tags, counts, etc., but they are not well explored in the literature and the majority of the object detection frameworks are designed to be used with complete detection annotations. One of the main rea-sons for this is that using weaker forms of annotation has not shown promising results yet. For example, the performance of weakly supervised object detection (WSOD) [23, 32, 44] lags in performance compared to standard supervised detec-tion using complete annotations. In addition, UFO2 [35], as the first work in omni-supervised object detection (OSOD), has shown that using additional weak annotations only has marginal gains. In this paper, however, we will show that, weak annotation can help to improve detection performance and achieve better cost-accuracy trade-off.
Towards this, we propose a unified architecture for
OSOD, Omni-DETR, which can work with different types
of weak annotations, including image tags, object counts, points, loose bounding boxes without tags, etc., or a mixture of them. It is built on recent progresses on student-teacher based semi-supervised object detection (SSOD) [30, 41, 45] to better leverage the data even if it is unlabeled, and the end-to-end detection architecture of [7, 52] with no heuristic detection procedures, like proposal detection, non-maximum suppression, thresholding, etc. The weak ground truth labels are used to filter the teacher predictions to gen-erate pseudo labels for the student to learn. We formulate the pseudo-label filtering as a bipartite matching problem between the sets of predictions and available weak ground truths, and propose a unified pseudo-label filtering strategy to accommodate any form of weak annotations.
Omni-DETR provides a unified framework to explore different weak forms of object annotations. With this frame-work, we have found that 1) weak annotations can bring ad-ditional gains even on a strong baseline; and 2) a mixture of weak and complete annotations can achieve better accuracy-cost trade-offs than just using complete annotations. As seen in Figure 1 (bottom), our Omni-DETR achieves bet-ter results than a standard supervised and a stronger semi-supervised detection baseline.
In addition, some annota-tion forms are more suited than the others depending on the dataset characteristics. For example, as shown in Figure 2, annotating accurate bounding boxes is difficult for Bees [3] and CrowdHuman [39] datasets, since objects are small and very crowded. However, it is easier to annotate with points for these datasets. Similarly, annotating accurate categories is difficult for Objects365 [38] as there are too many cate-gories (365), but annotating just the bounding boxes is rel-atively easy and cheap. Omni-DETR can accommodate all these different cases and help to reduce the cost of anno-tating such datasets, encouraging a larger scale of object detection datasets with mixed annotations.
Our contributions are summarized as: 1) a unified frame-work, Omni-DETR, that can accommodate various forms of object annotations or a mixture of them. 2) a novel and uni-fied pseudo label filtering strategy, based on bipartite match-ing; 3) experimental findings that show weak annotations can provide additional gains and achieve better accuracy-cost trade-off than the standard full detection annotations; 4) the empirical exploration of optimal annotation mixtures for a fixed annotation budget, showing that the optimal mix-ture depends on the dataset. 2.