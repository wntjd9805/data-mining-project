Abstract
Imaging in low light is extremely challenging due to low photon counts. Using sensitive CMOS cameras, it is currently possible to take videos at night under moonlight (0.05-0.3 lux illumination). In this paper, we demonstrate photorealistic video under starlight (no moon present,
<0.001 lux) for the ﬁrst time. To enable this, we develop a
GAN-tuned physics-based noise model to more accurately represent camera noise at the lowest light levels. Using this noise model, we train a video denoiser using a combination of simulated noisy video clips and real noisy still images. We capture a 5-10 fps video dataset with signiﬁcant motion at approximately 0.6-0.7 millilux with no active illumination. Comparing against alternative methods, we achieve improved video quality at the lowest light levels, demonstrating photorealistic video denoising in starlight for the ﬁrst time. 1.

Introduction
Some animals, such as hawkmoths and carpenter bees, can effectively navigate on the darkest moonless nights by the light of the stars (< 0.001 lux) [29, 47, 55], while our best CMOS cameras generally require at least 3/4 moon illumination (> 0.1 lux) to image moving objects at night [11]. Seeing in the darkest settings (moonless, clear nights) is extremely challenging due to the minuscule amounts of light present in the environment. In such dark settings, photographers can use long exposure times (e.g. 20 seconds or higher) to collect enough light from the scene.
This approach works well for still images, but severely limits the temporal resolution and precludes imaging of moving objects. Alternatively, cameras can increase the gain, making each pixel effectively more sensitive to light. This allows shorter exposures, but greatly increases the noise present in each frame. In this setting, motion might be perceptible, but noise overwhelms the images.
Denoising algorithms can be used to improve the image quality in noisy images. Over the years, a number of denoising algorithms have been developed, from classic methods (e.g. BM3D [17], V-BM4D [39]) to deep learning-based approaches [58]. Each of these methods attempt to extract the signal from the noise based on some assumptions about the statistical distributions of the image and noise.
While successful for certain denoising tasks, most of these methods are built upon a simplistic noise model (Gaussian or
Poisson-Gaussian noise), which does not apply in extremely low-light settings. When high sensor gain is used in low-light images, the noise is often non-Gaussian, non-linear, sensor-speciﬁc, and difﬁcult to model or characterize. Without having a good understanding of the structure of the noise in the images, denoising algorithms may fail – mistaking the structured noise for signal.
Recently, several deep learning-based approaches have provided remarkable denoising performance in low light down to 0.1–0.3 lux [13, 14]. Rather than assuming a certain noise model, these methods train a denoiser using clean/noisy image pairs captured by a camera. Such an approach automatically accounts for the low-light noise through deep learning, however this comes at the price
Figure 2. Method overview. (a) First we train our noise generator along with a discriminator, which aims to distinguish between real and synthetic noise. We use a limited dataset of long exposure/low gain and short exposure/high gain non-moving image pairs during this training process. After training, the noise generator can synthesize realistic noise. (b) Next, we train our denoiser using a combination of synthetic clean/noisy video clips produced using our noise generator as well as still clips from our camera. This allows us to train a video denoiser without needing experimental motion-aligned video pairs. of needing to capture thousands of training image pairs.
Furthermore, the dataset is camera-dependent and must be retaken for each different sensor, since noise can be highly camera-speciﬁc. In addition, while it is possible to capture clean/noisy image pairs for non-moving objects by changing the exposure/gain settings, capturing clean/noisy image pairs for moving scenes adds additional complexities (e.g. needing a second camera, aligning motion), making this experimentally impractical [28].
To achieve submillilux video denoising, we propose to use a combination of three things: 1) a very good camera optimized for low-light imaging and set to the highest gain setting (Sec. 4), 2) learning our camera’s noise model using a physics-inspired noise generator and easy-to-obtain still noisy images from the camera (Sec. 3), and 3) using this noise model to generate synthetic clean/noisy video pairs to train a video denoiser (Sec. 5). Since our physics-based noise generator is trained using a limited dataset of still clean/noisy bursts, we do not need to acquire experimental motion-aligned clean/noisy video clips, greatly simplifying the experimental setup and decreasing the amount of data we need to collect. After noise generator training, we hold the noise generator ﬁxed and train our video denoising using a combination of still clean/noisy image bursts paired with synthetic video clips (Sec. 5). Figure 2 summarizes this two-stage training approach for our noise generator and denoiser.
We demonstrate the effectiveness of our denoising network on 5-10 fps videos taken on a moonless clear night in 0.6 millilux, showing photorealistic video denoising in submillilux levels of illumination for the ﬁrst time. We present several challenging scenes with extensive motion, in which subjects dance by only the light of the Milky Way as a meteor shower rains down from above. 2.