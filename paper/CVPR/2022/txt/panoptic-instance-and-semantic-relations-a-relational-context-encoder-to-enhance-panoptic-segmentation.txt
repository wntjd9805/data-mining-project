Abstract
This paper presents a novel framework to integrate both semantic and instance contexts for panoptic segmentation.
In existing works, it is common to use a shared backbone to extract features for both things (countable classes such as vehicles) and stuff (uncountable classes such as roads).
This, however, fails to capture the rich relations among them, which can be utilized to enhance visual understand-ing and segmentation performance. To address this short-coming, we propose a novel Panoptic, Instance, and Seman-tic Relations (PISR) module to exploit such contexts. First, we generate panoptic encodings to summarize key features of the semantic classes and predicted instances. A Panop-tic Relational Attention (PRA) module is then applied to the encodings and the global feature map from the back-bone. It produces a feature map that captures 1) the rela-tions across semantic classes and instances and 2) the re-lations between these panoptic categories and spatial fea-tures. PISR also automatically learns to focus on the more important instances, making it robust to the number of in-stances used in the relational attention module. Moreover,
PISR is a general module that can be applied to any ex-isting panoptic segmentation architecture. Through exten-sive evaluations on panoptic segmentation benchmarks like
Cityscapes, COCO, and ADE20K, we show that PISR at-tains considerable improvements over existing approaches. 1.

Introduction
Panoptic segmentation [22] provides a unifying frame-work encompassing both semantic and instance segmenta-tion. Its objective is to segment an image into things and stuff. Things include countable objects, such as cars and pedestrians, and stuff refers to uncountable concepts like sky and vegetation. Generating individual masks for things is similar to instance segmentation, while predicting masks
* These authors contributed equally.
†Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc.
Figure 1. Our proposed PISR module takes features and predic-tions for semantic and instance segmentation as inputs and ap-plies a relational attention scheme. In this image, we show the in-put/output pairs obtained by applying PISR to a Panoptic-DeepLab model with ResNet50 backbone. The improvements in both the features and panoptic predictions are clearly visible. PISR pro-duces more confident and accurate predictions in regions where a lot of instances are cluttered together (shown with white arrows).
The feature maps are visualized for the persons class. for stuff is equivalent to performing semantic segmentation.
Since it aims to perform both tasks simultaneously, panoptic segmentation presents a challenge beyond conven-tional semantic or instance segmentation. Early works [22] propose to use separate modules for the two tasks, e.g., a Mask-RCNN module for instance segmentation and an
FCN-based module for semantic segmentation. These two outputs are then combined during post-processing to gen-erate panoptic segmentation. However, the accuracy in this case heavily relies on object detection quality. Besides, hav-ing two separate modules leads to redundant computations.
Recently, [27] proposed an architecture to process things and stuff together via a bottom-up, box-free approach.
More specifically, semantic segmentation labels are first predicted, and then the instances are identified based on the grouped pixels. This architecture provides a unified approach, but it does not consider the relations among the semantic classes and instances. The object-contextual rep-resentations (OCR) module proposed by [51] allows mod-eling the relations across semantic classes. However, it is designed for the semantic segmentation task and does not take instance information into account, which is critical for panoptic segmentation. For example, two images can have the same semantic classes, but their respective instances in the images can be very different. Our intuition is that in each semantic class, some instances can have drastically different visual appearances, sizes, and poses, while others may look similar. Therefore, understanding the relations (e.g., visual similarities) among the classes and instances will benefit panoptic segmentation.
In this paper, we propose a novel Panoptic, Instance, and
Semantic Relations (PISR) module, which captures the key relations among semantic classes and instances for panoptic segmentation. Given an image, PISR computes encodings for semantic classes and pivotal instances. During this pro-cess, it automatically identifies on which instances it should focus more. PISR then applies attention to these encodings as well as global features to capture rich contextual relations that are useful for the final panoptic segmentation. PISR is a general component that can be used with any panop-tic segmentation network, such as Panoptic-DeepLab [11],
Panoptic FPN [21], and Maskformer [12]. To the best of our knowledge, this is the first time that relations among both semantic classes and object instances are exploited for panoptic segmentation explicitly.
Our main contributions are summarized as follows:
• We propose a novel Panoptic, Instance, and Semantic
Relations (PISR) model to capture the relations among semantic classes and instances, providing richer con-texts that enhance panoptic segmentation performance.
• We devise a learnable scheme for PISR to automati-cally focus on more important instances while gener-ating relational features. This provides a robust way to process the varying number of instances in each image.
• PISR is a universal module that can be used in any panoptic segmentation network. We show that it con-siderably enhances existing architectures on multiple datasets. We further conduct extensive ablation stud-ies analyzing various aspects of PISR. 2.