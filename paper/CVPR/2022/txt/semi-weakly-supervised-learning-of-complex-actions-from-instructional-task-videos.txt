Abstract
We address the problem of action segmentation in instructional task videos with a small number of weakly-labeled training videos and a large number of unlabeled videos, which we refer to as Semi-Weakly-Supervised
Learning (SWSL) of actions. We propose a general
SWSL framework that can efﬁciently learn from both the existing types of videos and can leverage any of weakly-supervised action segmentation methods. Our key observation is that the distance between the transcript of an unlabeled video and those of the weakly-labeled videos from the same task is small yet often nonzero. Therefore, we develop a Soft Restricted Edit (SRE) loss to encourage small variations between the predicted transcripts of unlabeled videos and ground-truth transcripts of the weakly-labeled videos of the same task. To compute the SRE loss, we develop a ﬂexible transcript prediction (FTP) method that uses the output of the action classiﬁer to ﬁnd both the length of the transcript and the sequence of actions occurring in an unlabeled video. We propose an efﬁcient learning scheme in which we alternate between minimizing our pro-posed loss and generating pseudo-transcripts for unlabeled videos. By experiments on two benchmark datasets, we demonstrate that our approach can signiﬁcantly improve the performance by using unlabeled videos, especially when the number of weakly-labeled videos is small.1. 1.

Introduction
Many of humans everyday tasks are procedural, where a task consists of a sequence of actions that must be followed to achieve the desired goal. Therefore, there has been an explosion of instructional videos on the web, teaching how to perform tasks, such as cooking recipes, repairing devices, assembling furnitures, performing emergency ﬁrst aid, etc. [1, 10, 15, 23, 38, 56, 66, 67]. Automatic learning of procedural tasks from instructional videos has important applications, such as teaching intelligent agents to perform 1Code available at https://github.com/Yuhan-Shen/SWSL.
Figure 1. Transcript variation within each task for three different tasks. complex tasks, constructing large knowledge bases of com-pact instructions, and automatic performance evaluation for executing tasks. Over the past several years, we have seen great advances on different aspects of learning from instructions [1, 4, 8, 15, 19, 20, 33, 35–37, 49, 50, 56, 66, 67].
A major challenge in learning from instructional videos is that videos are long and have many actions, therefore annotation is costly and complex. This poses a major challenge for scaling the learning to a large number of tasks and videos. Therefore, while a few fully-supervised methods have studied learning from densely-annotated videos [24,27,45,49,51,53,64,66], the majority of existing works have focused on using less supervision. Speciﬁcally, weakly-supervised methods assume that each training video is accompanied with its transcript (ordered list of actions)
[5, 7, 12, 30, 35, 44, 67] or action-set (unordered list of actions) [16, 31, 32, 36, 43]. While using weak supervision reduces the annotation cost by removing the need for specifying temporal boundaries of actions, it still requires annotators to watch entire videos. On the other hand, unsupervised methods remove the need for annotation by using unlabeled videos and leveraging the similarity of videos of the same task. However, existing similarity constraints, e.g., videos following the same sequence of actions or the same pairwise action ordering, are limiting and often violated in videos (see Figure 1). This has led to performance of unsupervised methods signiﬁcantly lagging behind that of the weakly-supervised algorithms.
Paper Contributions. Motivated by the above discussion, we study a new action segmentation problem in which we assume having access to a small number of weakly-labeled
training videos and a large number of unannotated videos (with only task labels) from multiple tasks. We refer to this setting as Semi-Weakly-Supervised Learning (SWSL) of actions, whose goal is to learn a video segmentation model using both types of training videos. Using unlabeled videos allows us to effectively regularize learning from a small number of weakly-labeled videos, which would be insufﬁcient for learning action segmentation/classiﬁer using current methods. On the other hand, using weakly-labeled videos allows us to guide learning from unlabeled videos by leveraging a few transcripts of each task.
We propose an SWSL method to ﬁnd the parameters of a video feature learning module and an action classiﬁer by simultaneously learning from weakly-labeled and unlabeled videos. Our key observation is that transcripts of unlabeled videos often have small but nonzero distances to the transcripts of the weakly-labeled videos from the same task, accounting for small variations by which the task could be accomplished. Therefore, we develop a differentiable Soft
Restricted Edit (SRE) loss, which allows us to predict a transcript for an unlabeled video that is close to ground-truth transcripts of the weakly-labeled videos of the same task, yet could be different from them. To compute the
SRE loss, we develop a ﬂexible transcript prediction (FTP) method that uses the output of the action classiﬁer to ﬁnd both the length of the transcript and the sequence of actions occurring in an unlabeled video. Motivated by prior works on self-training [28, 62, 63], we propose a learning scheme in which we alternate between i) minimizing our proposed loss (sum of the weakly-supervised and SRE losses) on both types of videos; ii) adding a few most conﬁdent unlabeled videos and their pseudo-transcripts to the weakly labeled set. An advantage of our method is that it can use any existing weakly-supervised method. By experiments on two benchmark datasets of Breakfast [23] and CrossTask [67], we demonstrate the effectiveness of our approach. 2.