Abstract
The dominant CNN-based methods for cross-view image geo-localization rely on polar transform and fail to model global correlation. We propose a pure transformer-based approach (TransGeo) to address these limitations from a different perspective. TransGeo takes full advantage of the strengths of transformer related to global information mod-eling and explicit position information encoding. We further leverage the ﬂexibility of transformer input and propose an attention-guided non-uniform cropping method, so that un-informative image patches are removed with negligible drop on performance to reduce computation cost. The saved computation can be reallocated to increase resolution only for informative patches, resulting in performance improve-ment with no additional computation cost. This “attend and zoom-in” strategy is highly similar to human behavior when observing images. Remarkably, TransGeo achieves state-of-the-art results on both urban and rural datasets, with signiﬁcantly less computation cost than CNN-based meth-ods. It does not rely on polar transform and infers faster than CNN-based methods. Code is available at https:
//github.com/Jeff-Zilence/TransGeo2022. 1.

Introduction
Image-based geo-localization aims to determine the lo-cation of a query street-view image by retrieving the most similar images in a GPS-tagged reference database. It has a great potential for noisy GPS correction [2, 33] and naviga-tion [12, 17] in crowed cities. Due to the complete coverage and easy access of aerial images from Google Map API [1], a thread of works [10, 14, 19, 21–23, 25, 29, 35] focus on cross-view geo-localization, where the satellite/aerial im-ages are collected as reference images for both rural [14,34] and urban areas [29, 36]. They generally train a two-stream
CNN (Convolutional Neural Network) framework employ-ing metric learning loss [10, 35]. However, such cross-view retrieval systems suffer from the great domain gap between street and aerial views, as CNNs do not explicitly encode the position information of each view.
To bridge the domain gap, recent works apply a pre-deﬁned polar transform [21, 22, 26] on the aerial-view im-ages. The transformed aerial images have a similar geomet-ric layout as the street-view query images, which results in signiﬁcant boost in the retrieval performance. However, the polar transform relies on the prior knowledge of the geom-etry corresponding to the two views, and may fail when the street query is not spatially aligned at the center of aerial images [36] (this point is further demonstrated in Sec. 4.5).
Recently, vision transformer [7] has achieved signiﬁ-cant performance on various vision tasks due to its power-ful global modeling ability and self-attention mechanism.
Although CNN-based methods are still predominant for cross-view geo-localization, we argue vision transformer is more suitable for this task due to three advantages: 1) Vi-sion transformer explicitly encodes the position informa-tion, thus can directly learn the geometric correspondence between two views with the learnable position embedding. 2) The multi-head attention [28] module can model global long-range correlation between all patches starting from the
ﬁrst layer, while CNNs have limited receptive ﬁeld [7] and only learn global information in top layers. Such strong global modeling ability can help learn the correspondence, when two objects are close in one view while far from each other in the other view. 3) Since each patch has an explicit position embedding, it is possible to apply non-uniform cropping, which removes arbitrary patches without chang-ing the input of other patches, while CNNs can only apply uniform cropping (i.e. cropping a rectangle area). Such ﬂex-ibility of patch selection is beneﬁcial for geo-localization.
Since some objects in aerial-view may not appear in street view due to occlusion, they can be removed with non-uniform cropping to reduce computation and GPU memory footprint, while keeping the position information of other patches.
However, vanilla vision transformer [7] (ViT) has some limitation on training data size and memory consump-tion, which must be addressed when applied to cross-view geo-localization. The original ViT [7] requires extremely large training datasets to achieve state-of-the-art, e.g. JFT-300M [7] or ImageNet-21k [5] (a super set of the origi-nal ImageNet-1K). It does not generalize well if trained on medium-scale datasets, because it does not have inductive biases [7] inherent in CNNs, e.g. shift-invariance and lo-cality. Recently, DeiT [27] applies strong data augmenta-tion, knowledge distillation, and regularization techniques, in order to outperform CNN on ImageNet-1K [5], with sim-ilar parameters and inference throughput. However, mixup techniques used in DeiT (e.g. CutMix [27, 32]) are not straight-forward for metric learning losses [10].
In this paper, we propose the ﬁrst pure transformer-based method for cross-view geo-localization (TransGeo).
To make our method more ﬂexible without relying on data augmentations, we incorporate Adaptive Sharpness-Aware
Minimization (ASAM) [11], which avoids overﬁtting to lo-cal minima by optimizing the adaptive sharpness of loss landscape and improves model generalization performance.
Moreover, by analyzing the attention map of top trans-former encoder, we observe that most of the occluded re-gions in aerial images have negligible contribution to the output. This motivates us to introduce the attention-guided non-uniform cropping, which ﬁrst attends to informative image regions based on attention map of transformer en-coder, then increases the resolution only on the selected regions, resulting in an “attend and zoom-in” procedure, similar to human vision. Our method achieves state-of-the-art performance with signiﬁcant less computation cost (GFLOPs) than CNN-based methods, e.g. SAFA [21].
We summarize our contributions as follows:
• The ﬁrst pure transformer-based method (TransGeo) for cross-view image geo-localization, without relying on polar transform or data augmentation.
• A novel attention-guided non-uniform cropping strategy that removes a large number of uninformative patches in reference aerial images to reduce computation with neg-ligible performance drop. The performance is further im-proved by reallocating the saved computation to higher image resolution of the informative regions.
• State-of-the-art performance on both urban and rural datasets with less computation cost, GPU memory con-sumption, and inference time than CNN-based methods. 2.