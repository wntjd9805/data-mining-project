Abstract
Given a source image and a driving video depicting the same object type, the motion transfer task aims to generate a video by learning the motion from the driving video while preserving the appearance from the source image. In this paper, we propose a novel structure-aware motion model-ing approach, the deformable anchor model (DAM), which can automatically discover the motion structure of arbitrary objects without leveraging their prior structure information.
Specifically, inspired by the known deformable part model (DPM), our DAM introduces two types of anchors or key-points: i) a number of motion anchors that capture both appearance and motion information from the source image and driving video; ii) a latent root anchor, which is linked to the motion anchors to facilitate better learning of the representations of the object structure information. More-over, DAM can be further extended to a hierarchical ver-*Work done during an internship at Alibaba Group
†The corresponding author
‡Codes will be available at https://github.com/JialeTao/DAM.git sion through the introduction of additional latent anchors to model more complicated structures. By regularizing mo-tion anchors with latent anchor(s), DAM enforces the corre-spondences between them to ensure the structural informa-tion is well captured and preserved. Moreover, DAM can be learned effectively in an unsupervised manner. We validate our proposed DAM for motion transfer on different bench-mark datasets. Extensive experiments clearly demonstrate that DAM achieves superior performance relative to exist-ing state-of-the-art methods. 1.

Introduction
Recently, motion transfer has gained increasing attention from computer vision researchers, due to its numerous po-tential applications in the fields of video re-enactment [4], fashion design [7], face swapping [24], and so on. Given a source image and a driving video of the same object type, the goal of motion transfer is to generate a video that depicts the motion pattern contained in the driving video while pre-serving the appearance from the source image.
Finding the correspondence between a source image and a driving video is the key to successful motion transfer. Ex-isting motion transfer methods address this issue in two ways. On one hand, model-based methods [9, 14] utilize a pre-trained third-party model to extract the structural in-formation of an object (e.g., human bodies, human faces, etc.). However, specific predefined structure priors are re-quired for different objects. On the other hand, model-free methods [23, 24, 33] treat motion keypoints as unknown variables, then design models to predict them by optimiz-ing the image reconstruction loss. While these approaches do not require a predefined object structure, they often suf-fer from false correspondences, leading to considerable ar-tifacts emerging in the generated videos (see Fig. 2 for ex-amples).
To address these issues, in this paper, we propose a novel structure-aware motion transfer approach referred to as the deformable anchor model (DAM). In DAM, we take advan-tage of both the model-free and model-based methods. On one hand, similar to the model-free methods, we represent motion keypoints (a.k.a., “anchors”) as unknown variables, which enables our model to perform motion transfer on an arbitrary object without knowing its prior structural infor-mation. On the other hand, to prevent the false correspon-dences, we also encode the structural information to con-strain those motion anchors. Unlike model-based methods, our approach does not employ any pre-trained third-party model. Instead, as inspired by the well-known deformable part model (DPM) [8], DAM introduces a latent root an-chor to regularize the motion anchors and model the object structure, enabling the correspondence between the source image and driving video to be enforced and thus further im-proving the performance. Furthermore, by introducing ad-ditional latent anchors, DAM can be easily extended to a hierarchical version that can more effectively model com-plicated object structures. Note that all latent anchors in our
DAM are unknown variables, and that DAM can be learned in an end-to-end manner, similarly to previous model-free methods.
We conduct experiments on four benchmark datasets (i.e., TaiChiHD, FashionVideo, VoxCeleb1 and MGIF) for performance evaluation. The experimental results show that our method not only achieves the best quantitative perfor-mance, but also exhibits a strong capacity to capture the motion structure of different objects, such as human bodies, faces, animals, and so on. 2.