Abstract
Recent years have witnessed signiﬁcant progress in the area of single image dehazing, thanks to the employment of deep neural networks and diverse datasets. Most of the ex-isting methods perform well when the training and testing are conducted on a single dataset. However, they are not able to handle different types of hazy images using a de-hazing model trained on a particular dataset. One possible remedy is to perform training on multiple datasets jointly.
However, we observe that this training strategy tends to compromise the model performance on individual datasets.
Motivated by this observation, we propose a test-time train-ing method which leverages a helper network to assist the dehazing model in better adapting to a domain of inter-est. Speciﬁcally, during the test time, the helper network evaluates the quality of the dehazing results, then directs the dehazing network to improve the quality by adjusting its parameters via self-supervision. Nevertheless, the inclu-sion of the helper network does not automatically ensure the desired performance improvement. For this reason, a meta-learning approach is employed to make the objectives of the dehazing and helper networks consistent with each other.
We demonstrate the effectiveness of the proposed method by providing extensive supporting experiments. 1.

Introduction
Single image dehazing is a classic but still active re-search topic in low-level computer vision, which aims to restore clean images from the degraded hazy counterparts.
Recently, many deep learning approaches [5, 10, 14, 22, 25, 26, 31, 35, 45, 49, 50] have been proposed to address this problem by training a neural network to approximate the mapping from hazy images to haze-free ground truths. As more and more dehazing datasets have been released, such as RESIDE [23], O-Haze [3] and NH-Haze [2], these meth-ods are able to demonstrate their outstanding ability in han-dling different haze patterns. However, one important issue is left behind for consideration, i.e., handling different types 26.93 26.25 26.13 26.11 25.58 25.72 24.77 24.09 23.98
Figure 1: Average PSNR values of GDN [26], MSBDN [11] and DW-GAN [14] across four datasets. It can be observed that the dehazing methods perform better if the training and validation are conducted on a single dataset. of hazy images by a single network. To be speciﬁc, current methods are usually trained on the training split of a particu-lar dataset and tested on the corresponding testing split. For example, the test accuracy on RESIDE indoor test set [23] is obtained by validating a dehazing model trained on the
RESIDE indoor training set. Such an evaluation strategy al-lows the neural network to focus on a speciﬁc domain but evades the important problem of learning a general model across datasets. A seemingly simple remedy is to train a single dehazing model on all available datasets jointly. In-tuitively, with the increase of data, the network can beneﬁt from considering more kinds of haze patterns, leading to boosted performance on every single dataset [1].
Somewhat surprisingly, we ﬁnd that this naive solution actually compromises the dehazing performance on indi-vidual datasets. Indeed, it can be seen from Figure 1 that the dehazing models perform better when the training and testing are conducted on a single dataset (as opposed to all datasets combined). This unusual fact contradicts the common belief that the increase in data usually leads to im-proved performance. One possible explanation is that each 1
(i) source (ii) hazy
RESIDE Indoor
RESIDE Outdoor (iii) IDS
Figure 2: Visualization of image features using t-SNE [42].
Image features are obtained using a ResNet18 [16] pre-trained on ImageNet [9]. The fact that the features are clus-tered around four different centers shows clear discrepan-cies between the distributions of these datasets. (iv) w/o scale
O-HAZE
NH-HAZE
Figure 3: Representative examples from RESIDE in-door/outdoor, O-Haze and NH-Haze. dataset has a speciﬁc distribution which might be signiﬁ-cantly different from that of another dataset (see Figure 2).
The representative examples from the four datasets under consideration are shown in Figure 3, where one can observe that both the haze pattern and background scene of the four datasets are signiﬁcantly different from each other. In the
RESIDE indoor and outdoor datasets, the haze pattern is homogeneous but the background scenes are vastly differ-ent (indoor vs. outdoor environments). In the O-Haze and
NH-Haze datasets, background scenes are consistent (out-door environments) but the haze patterns have remarkable distinctions. Against this backdrop, learning a general de-hazing model on multiple datasets can be categorized as a multi-domain learning (MDL) problem.
In this paper, we propose a method that can enable a sin-gle dehazing model to cope with multiple domains. Here, each domain is formed by a dataset with a distinctive haze pattern and scene. Our goal is to ﬁnd a model that can min-imize the risk on the collection of domains for the dehaz-ing task. Note that our problem deﬁnition is signiﬁcantly different from the related ﬁeld of domain adaptation and multi-task learning in the sense that the former aims to min-imize the risk on a speciﬁc target domain while the latter performs optimization on a collection of tasks paired with a single domain.
In principle, one can address the refor-mulated multi-domain dehazing problem by following the common practice in MDL. However, this requires design-ing sophisticated neural network structures with domain-speciﬁc modules, which is a highly non-trivial and cumber-some task in general.
To alleviate the design burden, we propose a novel MDL approach for single image dehazing by helping a given de-2 hazing network to adapt to a speciﬁc domain when it is needed. To achieve this, we propose a method to adjust the dehazing network during the testing phase. In this method, the parameters of the network are optimized using a self-supervised loss function which is basically provided by an-other entity called the helper network. This network is de-signed to learn diverse haze patterns using paired hazy and haze-free images (across multiple domains) and output a re-constructed version of the hazy image that is fed into it.
At the test time, the helper network uses its knowledge to assess the quality of the output of the dehazing network, which is a dehazed image. In other words, this image to-gether with its corresponding hazy counterpart are given to the helper network as its inputs. If the output of the helper network is close to the hazy image, then a small reconstruc-tion loss is expected. However, if the dehazed image is de-fective, then a large reconstruction loss may be derived at the helper network. Considering the fact that the quality of dehazed image can be represented by the reconstruction loss of the helper network, we update the parameters of the dehazing network by minimizing this loss function.
Now a natural question arise: How to guarantee that the end-to-end performance of the dehazing network is eventu-ally optimized by minimizing the reconstruction loss of the helper network. In order to ensure the consistency between the objectives of two networks, we adopt the meta-learning approach [8, 13, 41]. Here, the goal of meta-learning is to adjust the parameters of the dehazing network by minimiz-ing the reconstruction loss of the helper network so that the dehazing output based on the adjusted parameters better matches the ground-truth haze-free image.
Our contributions can be summarized as follows. Firstly, we point out a largely unnoticed phenomenon in single im-age dehazing, namely, a model trained on multiple datasets
exhibits compromised performance on individual datasets.
This leads to the formulation of designing a dehazing model for distribution-wise distinctive datasets as a MDL problem.
Secondly, we put forward a solution to this problem by in-troducing a test-time training approach for better adapting the dehazing network to every single observation. Finally, we provide extensive experiments to demonstrate the effec-tiveness of our proposed method in addressing the multi-domain dehazing problem. 2.