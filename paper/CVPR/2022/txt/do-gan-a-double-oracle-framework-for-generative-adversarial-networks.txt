Abstract
In this paper, we propose a new approach to train Gen-erative Adversarial Networks (GANs) where we deploy a double-oracle framework using the generator and discrim-inator oracles. GAN is essentially a two-player zero-sum game between the generator and the discriminator. Train-ing GANs is challenging as a pure Nash equilibrium may not exist and even ﬁnding the mixed Nash equilibrium is difﬁcult as GANs have a large-scale strategy space. In DO-GAN, we extend the double oracle framework to GANs. We
ﬁrst generalize the players’ strategies as the trained models of generator and discriminator from the best response or-acles. We then compute the meta-strategies using a linear program. For scalability of the framework where multi-ple generators and discriminator best responses are stored in the memory, we propose two solutions: 1) pruning the weakly-dominated players’ strategies to keep the oracles from becoming intractable; 2) applying continual learning to retain the previous knowledge of the networks. We apply our framework to established GAN architectures such as vanilla GAN, Deep Convolutional GAN, Spectral Normaliza-tion GAN and Stacked GAN. Finally, we conduct experiments on MNIST, CIFAR-10 and CelebA datasets and show that
DO-GAN variants have signiﬁcant improvements in both subjective qualitative evaluation and quantitative metrics, compared with their respective GAN architectures. 1.

Introduction
Generative Adversarial Networks (GANs) [8] have been applied in various domains such as image and video gen-eration, text-to-image synthesis and equipment condition monitoring [18, 29–31]. Various architectures are proposed
*Equal contribution
†Corresponding author to generate more realistic samples [23, 27, 28] as well as regularization techniques [1, 25]. From the game-theoretic perspective, GANs can be viewed as a two-player game where the generator samples the data and the discriminator classiﬁes the data as real or generated. They are alternately trained to maximize their respective utilities till convergence corresponding to a pure Nash Equilibrium (NE).
Figure 1. Training images with ﬁxed noise for SGAN and DO-SGAN/P (pruning) until termination. Both during training and after convergence, DO-SGAN/P can generate better quality images with
FID score of 6.32 against SGAN’s FID score of 6.98.
However, pure NE cannot be reliably reached by exist-ing algorithms as pure NE may not exist [7, 21]. This also leads to unstable training in GANs depending on the data and the hyperparameters. Therefore, mixed NE is a more suitable solution concept [11]. Several recent works propose mixture architectures with multiple generators and discrimi-nators that consider mixed NE such as MIX+GAN [2] and
MGAN [10] but they cannot guarantee to converge to mixed
NE. Mirror-GAN [11] computes the mixed NE by sampling over the inﬁnite-dimensional strategy space and proposes provably convergent proximal methods. However, the sam-pling approach may not be efﬁcient as mixed NE may only have a few strategies in the support set.
Double Oracle (DO) algorithm [20] is a powerful frame-work to compute mixed NE in large-scale games. The algo-rithm starts with a restricted game that is initialized with a small set of actions and solves it to get the NE strategies of the restricted game. The algorithm then computes players’ best-responses using oracles to the NE strategies and add them into the restricted game for the next iteration. DO framework has been applied in various disciplines [4, 13], as well as Multi-agent Reinforcement Learning (MARL) [15].
Inspired by successful applications of DO framework, we, for the ﬁrst time, propose a Double Oracle Framework for
Generative Adversarial Networks (DO-GAN). This paper presents four key contributions. First, we treat the generator and the discriminator as players and obtain the best responses from their oracles and add the utilities to a meta-matrix. Sec-ond, we propose a linear program to obtain the probability distributions of the players’ pure strategies (meta-strategies) for the respective oracles. The linear program computes an exact mixed NE of the meta-matrix game in polynomial time.
Third, since multiple generators and discriminator from the best responses oracles are stored in the memory, the algo-rithm may be memory-inefﬁcient for problems to train GAN with large-scaled real-world datasets. Thus, we propose two solutions for the scalable double oracle framework: 1) a pruning method for reducing the support set of best response strategies to prevent the oracles from becoming intractable as there is a risk of the meta-matrix growing very large with each iteration of oracle training; 2) applying continual learn-ing to retain the previous knowledge of the networks for the best responses from the generator and discriminator oracles in the multi-task learning setup. We also address the prob-lems in continual learning such as catastrophic forgetting.
Finally, we provide comprehensive evaluation on the perfor-mance of DO-GAN with different GAN architectures using both synthetic and real-world datasets. Experiment results show that DO-GAN variants have signiﬁcant improvements in terms of both subjective qualitative evaluation and quanti-tative metrics such as inception score and FID score. 2.