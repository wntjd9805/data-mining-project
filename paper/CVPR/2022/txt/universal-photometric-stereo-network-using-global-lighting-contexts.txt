Abstract
This paper tackles a new photometric stereo task, named universal photometric stereo. Unlike existing tasks that as-sumed specific physical lighting models; hence, drastically limited their usability, a solution algorithm of this task is supposed to work for objects with diverse shapes and ma-terials under arbitrary lighting variations without assum-ing any specific models. To solve this extremely challenging task, we present a purely data-driven method, which elimi-nates the prior assumption of lighting by replacing the re-covery of physical lighting parameters with the extraction of the generic lighting representation, named global light-ing contexts. We use them like lighting parameters in a cal-ibrated photometric stereo network to recover surface nor-mal vectors pixelwisely. To adapt our network to a wide variety of shapes, materials and lightings, it is trained on a new synthetic dataset which simulates the appearance of objects in the wild. Our method is compared with other state-of-the-art uncalibrated photometric stereo methods on our test data to demonstrate the significance of our method. 1.

Introduction
Photometric stereo is a problem of recovering the surface normal map from appearances of an object under varying lighting conditions. For decades, a broad spectrum of tech-niques have been proposed to expand the scope of target geometry, material and acquisition setup [15, 23, 24, 42] in the framework of the physics-based inverse rendering. Re-cently, advances in deep learning have been eliminating the dependence on physics-based modeling from photometric stereo methods, which contributes to handle complex opti-cal phenomena which are hardly described in a mathemati-cally tractable form [12, 21, 39, 44].
However, despite the long journey in this research field, each photometric stereo algorithm is still limited to a spe-cific physical lighting model, which severely compromises its usability. In reality, most recent (semi-)calibrated [11, 21, 39, 40, 44] and uncalibrated [12, 27] photometric stereo methods still assume the single lighting in a dark environ-ment. Others address natural lighting conditions, however both calibrated and uncalibrated methods still assume con-vex Lambertian surfaces and their lighting models are lim-ited to spherical harmonics lighting [8, 17], dominant sun lighting [6, 20] and equivalent directional lighting [16, 36] which cannot represent the complex illumination.
To address this limitation, this paper proposes the “third” task in photometric stereo problem following calibrated and uncalibrated tasks. We name it universal photometric stereo (UniPS) which denotes the setup without prior assumption of physical lighting models; hence, arbitrary lighting con-ditions should be considered unlike calibrated and uncali-brated tasks that consider specific ones as in Table 1.1 1It would be ideal if the task were universal on materials as well. How-ever, since some objects such as mirrors and transparent objects must be excluded, we consider only lighting conditions to be universal in this task.
Table 1. Comparison of different photometric stereo tasks.
Lighting
Calibration
Required
Free
Free
Lighting
Model
Required
Required
Free
Lighting
Condition
Specific
Specific
Arbitrary
Calibrated
Uncalibrated
Universal
In this paper, we present a first viable method for UniPS based on key insights as follows. Conventional uncalibrated photometric stereo algorithms recovered physical lighting parameters and surface normals sequentially or simultane-ously; thus, constrained by specific lighting models. How-ever, we show that the recovery of physical lighting param-eters is not essential in a UniPS network, and can be re-placed with the extraction of global lighting contexts from individual images by their interaction with others. In order to keep the receptive field of our network constant, contexts are extracted at the predefined canonical resolution which is independent of the input image resolution. By using global lighting contexts like calibrated lighting parameters, surface normal vectors can be recovered in similar to existing pixel-wise calibrated photometric stereo networks (e.g. [21, 22]) which easily scale to high-resolution images. While our net-work drops a prior assumption of lighting, its adaptation to diverse shapes, materials and lightings has to be ensured by training data. Since existing training datasets for photo-metric stereo networks are limited to the single, directional lighting setup, we create a dataset for our task by physi-cally rendering the appearance of objects with more than 10, 000 combinations of shape, material and lighting us-ing high quality commercial 3-D assets. We also create an evaluation dataset with 50 sets of attributes using different assets to compare our method with state-of-the-art uncali-brated photometric stereo algorithms specifically designed for directional lighting [12] and natural lighting [17, 36].
Finally, the qualitative evaluation demonstrates that our method even works for real objects under the challenging spatially-varying lighting conditions that were convention-ally considered to be intractable (See Fig. 1). 2.