Abstract
Data mixing (e.g., Mixup, Cutmix, ResizeMix) is an es-sential component for advancing recognition models.
In this paper, we focus on studying its effectiveness in the self-supervised setting. By noticing the mixed images that share the same source images are intrinsically related to each other, we hereby propose SDMP, short for Simple Data
Mixing Prior, to capture this straightforward yet essential prior, and position such mixed images as additional positive pairs to facilitate self-supervised representation learning.
Our experiments verify that the proposed SDMP enables data mixing to help a set of self-supervised learning frame-works (e.g., MoCo) achieve better accuracy and out-of-distribution robustness. More notably, our SDMP is the first method that successfully leverages data mixing to improve (rather than hurt) the performance of Vision Transformers in the self-supervised setting. Code is publicly available at https://github.com/OliverRensu/SDMP. 1.

Introduction
Data mixing is one of the key ingredients for improving recognition models. The concept of data mixing is firstly introduced in Mixup [47], which trains models on convex combinations of pairs of images and their labels. This idea subsequently inspires several follow-ups, including mix-ing images and cropped patches [45], mixing images and thumbnails [44], and mixing among cropped patches [4,38].
However, interestingly, data mixing plays little role in the recent surge of self-supervised learning. For instance, while na¨ıvely replacing original images with their mixed counterparts substantially improves Vision Transformers (ViTs) in the supervised setting [39], it cannot improve
ViTs under the self-supervised setting. Though many ef-forts [27, 31, 42] have been made recently by developing more sophisticated training strategies in data mixing, they
*Corresponding authors: Shengfeng He (hesfe@scut.edu.cn), Cihang
Xie (cixie@ucsc.edu)
Figure 1. For the mixed images that share the same source (e.g., a cat image and a dog image), they are semantically related and can be treated as additional positive pairs in self-supervised learning. are exclusively focusing on Convolutional Neural Networks (CNNs). As shown in Table 1 in Section 4, all these meth-ods still fail to help (or even hurt) ViTs [16].
In this paper, we aim to develop a generic training strat-egy in data mixing that can improve the self-supervised rep-resentation learning of both CNNs and ViTs. By taking a closer look at the popular data mixing implementation where an image is mixed with another image that sampled from the same batch but with the flipped order1, we observe such created mixed samples are inherently related in pairs (e.g., an example is provided in Figure 1). This indicates that, now for one mixed image, there exist three related sam-ples (i.e., a pair of source images and a mixed image cre-ated with a different mixing parameter) in the same training batch. This intrinsic relationship qualifies the pair of mixed images to be treated as additional positive samples in self-supervised learning to facilitate representation learning. 1The traditional data mixing implementation randomly samples two batches and then mixes them with each other; while this instantiation of data mixing only samples one batch and then mixes pairs of images from the same batch. It generally will not hurt performance, and is very popular in many libraries (e.g., timm [43]), due to its faster computational speed.
Motivated by the observation above, we hereby propose to leverage this Simple Data Mixing Prior (dubbed SDMP) to holistically model the relationship among samples for en-hancing self-supervised learning. Different from previous methods [27, 31, 32, 36, 42], SDMP not only considers the relationships between source images and the mixed counter-parts, but also encodes the connections between mixed sam-ples in representation learning. We further enhance SDMP’s representation learning by semantically weighting the loss to accurately capture the relationships among samples.
Our empirical results verify that the proposed SDMP successfully helps a set of self-supervised learning frame-works gain better accuracy on different visual benchmarks and robustness on out-of-distribution samples, using both
CNNs and ViTs. More essentially, we would like to high-light that our SDMP is the first strategy that enables data mixing to improve self-supervised ViTs. For example, by building upon the latest MoCo v3 [11], while existing train-ing strategies [27, 31, 42] all hurt the top-1 ImageNet accu-racy of ViT-S by 0.2% - 1.6%, SDMP successfully improves the top-1 ImageNet accuracy of ViT-S by 0.6%. We hope the technical insights and results provided in this work will be helpful for future works on studying data mixing in self-supervised learning. 2.