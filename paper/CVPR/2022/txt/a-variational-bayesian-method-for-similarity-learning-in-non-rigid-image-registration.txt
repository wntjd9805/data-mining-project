Abstract
We propose a novel variational Bayesian formulation for diffeomorphic non-rigid registration of medical images, which learns in an unsupervised way a data-speciﬁc sim-ilarity metric. The proposed framework is general and may be used together with many existing image registra-tion models. We evaluate it on brain MRI scans from the
UK Biobank and show that use of the learnt similarity met-ric, which is parametrised as a neural network, leads to more accurate results than use of traditional functions, e.g.
SSD and LCC, to which we initialise the model, without a negative impact on image registration speed or transfor-mation smoothness. In addition, the method estimates the uncertainty associated with the transformation. The code and the trained models are available in a public repository: https://github.com/dgrzech/learnsim. 1.

Introduction
Image registration attempts to align images so that cor-responding locations contain the same semantic informa-tion. It is a necessary pre-processing step for the statistical analysis of clinical imaging data, computer-aided diagnosis, and computer-assisted intervention.
In order to calculate the transformation, traditional image registration methods minimise an energy function which consists of task-speciﬁc similarity and regularisation terms, e.g. [4, 27, 38]. The al-gorithm needs to be run independently for every pair of im-ages to be aligned and optimisation of the energy function is performed in an iterative manner.
Traditional image registration methods minimise an en-ergy function, which is similar to the training of neural net-works by the minimisation of loss functions. However, us-ing deep learning for medical image registration is difﬁcult due to the lack of ground truth transformations. DLIR [15] and VoxelMorph (VXM) [5, 6, 13, 14] both use neural net-works in order to learn in an unsupervised way a function that outputs a deformation ﬁeld given a pair of input images, instead of optimising an energy function independently for each image pair. The calculation of transformations by eval-uation of the neural network in a single forward pass speeds up the process by several orders of magnitude and maintains an accuracy comparable to traditional methods. The claim that deep learning models for image registration are limited to self- and unsupervised learning was recently countered by training a generative model exclusively on synthetic im-ages and segmentations [25].
In this work, we present a new model for atlas-based diffeomorphic non-rigid image registration which, given a dataset of images, learns in an unsupervised way a suit-able similarity metric for the task. The model implements the similarity metric as a neural network that takes as in-put two three-dimensional images and outputs the value of a function which needs to be minimised to align them. The few existing approaches for unsupervised similarity learn-ing rely either on feature extraction used together with clas-sical similarity metrics [12, 44, 45] or ad-hoc adversarial training [17, 18, 36].
In contrast to them, we reﬁne the similarity metric itself, working within a rigorous Bayesian framework. The choice of a Bayesian model makes it possi-ble to learn a data-speciﬁc similarity metric with relatively little data, improves robustness by proxy of the approximate variational posterior of the transformation parameters, and allows to quantify the uncertainty associated with the out-put. The following are the main contributions of our work: 1. We propose a novel variational Bayesian method for unsupervised similarity learning in atlas-based non-rigid medical image registration; 2. We show that the learnt metric outperforms traditional similarity metrics used in image registration on the ex-amples of SSD and LCC, to which we initialise the model;
3. Furthermore, we show that the learnt metrics gener-alise well by comparing the accuracy of VXM trained using the baseline and learnt similarity metrics; 4. The proposed formulation also makes it possible to es-timate the voxel-wise uncertainty associated with the diffeomorphic transformation.