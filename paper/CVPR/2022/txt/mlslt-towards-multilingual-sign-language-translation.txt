Abstract
Most of the research to date focuses on bilingual sign language translation (BSLT). However, such models are in-efficient in building multilingual sign language translation systems. To solve this problem, we introduce the multilin-gual sign language translation (MSLT) task. It aims to use a single model to complete the translation between multiple sign languages and spoken languages. Then, we propose
MLSLT, the first MSLT model, which contains two novel dy-namic routing mechanisms for controlling the degree of pa-rameter sharing between different languages.
Intra-layer language-specific routing controls the proportion of data flowing through shared parameters and language-specific parameters from the token level through a soft gate within the layer, and inter-layer language-specific routing controls and learns the data flow path of different languages at the language level through a soft gate between layers. In order to evaluate the performance of MLSLT, we collect the first publicly available multilingual sign language understand-ing dataset, Spreadthesign-Ten (SP-10), which contains up to 100 language pairs, e.g., CSL→en, GSG→zh. Experi-mental results show that the average performance of ML-SLT outperforms the baseline MSLT model and the com-bination of multiple BSLT models in many cases.
In ad-dition, we also explore zero-shot translation in sign lan-guage and find that our model can achieve comparable performance to the supervised BSLT model on some lan-guage pairs. Dataset and more details are at https:
//mlslt.github.io/. 1.

Introduction
Sign languages are the primary means of communica-tion for an estimated 466 million deaf or hard-of-hearing people worldwide [38]. However, the difference between sign language and spoken language causes some communi-cation barriers between them and hearing-unimpaired peo-ple, which brings inconvenience to their daily lives. This
*Corresponding author. (a) MSLT system based on multi-models
Figure 1. An example to illustrate the advantages of the MSLT model over the BSLT model in constructing a multilingual sign language translation system. (b) MSLT system based on single model motivates researchers to design more efficient and accurate sign language translation systems [23, 24, 52, 56].
Due to the lack of data, almost all previous studies fo-cus on building a bilingual sign language translation (BSLT) model [2,3,27,37,53,57] (such as American Sign Language to English or British Sign Language to English). However, there are more than 300 sign languages in the world [34], and there are 389 languages spoken by more than one mil-lion people worldwide [9, 40]. So if each model can only handle one language pair, then in order to handle all situa-tions, we need to create 116,700 models. Even if all sign languages are translated into English and then translated into other languages with the help of a machine translation system, we still need to create 300 models, which is unac-ceptable for practical applications.
Therefore, we aim in this work to design a single model to realize the translation between multiple sign languages and spoken languages. Figure 1 shows the advantages of the multilingual sign language translation (MSLT) model compared to the BSLT model in constructing an MSLT system. However, there are many challenges in building such a MSLT model. First, we lack an MSLT corpus. Al-most all public sign language translation datasets contain only one sign language, and they are mainly concentrated
in a few sign language categories such as CLS, GSG, and
ASE [2, 8, 57]. Secondly, while joint training brings bene-ficial knowledge transfer, it also introduces language diver-gence and representation bottlenecks as the number of data and languages increases [6].
In order to solve the above challenges and promote progress in the field of MSLT, we construct the first large-scale parallel multilingual sign language understanding dataset, Spreadthesign-Ten (SP-10). SP-10 contains videos and corresponding spoken translations in ten sign languages collected from spreadthesign [15]. There is also a corre-sponding relationship between videos of different sign lan-guages, which means that this dataset is also suitable for the multilingual text-to-video sign language generation task and the multilingual video-to-video sign language transla-tion task.
Then, we propose the MLSLT model, an end-to-end
MSLT model based on the Transformer [49] architecture.
To alleviate language conflicts and representation bottle-necks, we meticulously design two end-to-end data-driven routing mechanisms, inter-layer language-specific routing (InterLSR) and intra-layer language-specific routing (In-traLSR), to help the model control parameter sharing be-tween different languages. As shown in Figure 2, InterLSR is used to control the degree of sharing of different sign lan-guages in the Transformer layer. Without InterLSR, the de-gree of sharing of all sign languages in any layer is 100%.
Any sign language on each layer has a corresponding gate to control the proportion of this sign language flowing through this layer. Optimizing the state of the gate during train-ing can adjust the network structure to maximize translation quality. IntraLSR is used to control the proportion of par-ticular language flowing through language shared parame-ters and language-specific parameters in the layer. During training, each token is simply projected and then added ac-cording to the ratio calculated by the gate. In inferencing, we first linearly combine the shared feature extraction ex-pert and the language-specific feature extraction expert, and then perform matrix multiplication, which can save half of the calculation. In addition, we also encourage shared fea-ture extraction experts and language-specific feature extrac-tion experts to encode different aspects of the input by using soft orthogonal subspace constraints [1].
On the SP-10 dataset, we respectively implement the al-gorithms proposed by Camg¨oz et al. [3] and Johnson et al. [20] as the baseline for BSLT and MSLT. The experi-mental results on the SP-10 dataset show that the average
BLEU and ROUGE scores obtained by MLSLT exceed the
MSLT baseline and the BSLT baseline, although MLSLT uses fewer parameters than them. This fully proves the ef-fectiveness of our proposed method and shows the great po-tential of multilingual sign language translation. We also explore zero-shot translation in sign language and find that our model can achieve comparable performance to the su-pervised BSLT model on some language pairs, which shows that our model builds an implicit bridge between the target language pairs.
Our main contributions are summarized as follows,
• We contribute a large-scale multilingual sign language understanding dataset suitable for multiple tasks such as multilingual sign language translation, multilingual text-to-video sign language generation, and multilin-gual video-to-video sign language translation.
• We are the first to explore the MSLT problem, and we propose MLSLT, an MSLT framework based on dy-namic neural network. Two novel dynamic routing mechanisms are used to control parameter sharing be-tween different sign languages.
• Extensive experimental results show that our proposed single model can perform better than the MSLT base-line and multiple BSLT models while using fewer pa-rameters. A broad range of new baseline results can guide future research in this field. 2.