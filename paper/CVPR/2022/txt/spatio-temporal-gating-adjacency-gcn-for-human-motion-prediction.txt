Abstract
Predicting future motion based on historical motion sequence is a fundamental problem in computer vision, and it has wide applications in autonomous driving and robotics. Some recent works have shown that Graph Convo-lutional Networks(GCN) are instrumental in modeling the relationship between different joints. However, consider-ing the variants and diverse action types in human mo-tion data, the cross-dependency of the spatio-temporal re-lationships will be difficult to depict due to the decoupled modeling strategy, which may also exacerbate the problem of insufficient generalization. Therefore, we propose the
Spatio-Temporal Gating-Adjacency GCN(GAGCN) to learn the complex spatio-temporal dependencies over diverse ac-tion types. Specifically, we adopt gating networks to en-hance the generalization of GCN via the trainable adap-tive adjacency matrix obtained by blending the candidate spatio-temporal adjacency matrices. Moreover, GAGCN addresses the cross-dependency of space and time by bal-ancing the weights of spatio-temporal modeling and fusing the decoupled spatio-temporal features. Extensive exper-iments on Human 3.6M, AMASS, and 3DPW demonstrate that GAGCN achieves state-of-the-art performance in both short-term and long-term predictions. 1.

Introduction
The aim of human motion prediction is to predict the motion trend of the skeleton-based human body in the fu-ture period from a given historical motion sequence, which is a significant computer vision task with many potential applications, such as autonomous driving, human-robotics interaction, target tracking, and motion planning.
The skeleton-based human motion sequence is a struc-tured time series, which means that the movement of a sin-gle joint is affected by the coupling of spatial connections with other joints and the temporal trajectory tendency. We call these complex spatio-temporal relationships as cross-*Corresponding author.
Figure 1. The illustration of our method. Given the historical in-put human motion sequence, we try to predict the future motion sequence by enhancing, balancing, and fusing two key factors, i.e. the joint dependencies and the temporal correlations. dependency. The challenges lie in motion prediction are mainly two-fold. First, earlier literature based on Recur-rent Neural Network(RNN), such as LSTM and GRU sug-gests that predicting the long-term sequence will meet the inherent error accumulation problem [5,7–10,14,27,32,34].
Though subsequent convolution-based approaches [3, 11, 17] for sequence-to-sequence prediction reduce the error of long-term prediction to some extent, the error accumula-tion is still a problem to be solved. Second, it is difficult to model the spatio-temporal relationships since the skeleton-based human motion is very complex and diverse. Rather than using the basic motion representation(joint angle, posi-tion, and velocity) directly or extracting the spatial features of the motion with a simple fully connected layer, recent studies try to use GCN to depict the spatio-temporal rela-tionships [6, 18–20, 22, 24–26, 28].
Though GCN-based works are instrumental for solving the long-term prediction problem to some extent, there are two issues to be explored: 1. The inter-joint and inter-frame relationships will change with the motion variance and ac-tion types, therefore a stable adjacency matrix will lead to
inherent poor generalization on multi-action motions; 2. Di-rect concatenation of the decoupled spatial and temporal features can not fully explore the cross-dependency of the spatio-temporal relationships.
In this paper, we propose the Spatio-Temporal Gating-Adjacency GCN(GAGCN) to learn the complex spatio-temporal dependencies over diverse action types. To solve the above two issues, our key idea mainly consists of two parts, namely, the enhancing strategy and the balancing and fusing strategy(shown in Fig. 1). First, given differ-ent historical motion sequences, the gating network in our
GAGCN output corresponding blending coefficients which are then used to blend the trainable candidate adjacency matrices. The inter-joint and inter-frame relationships of different motions are learned by the adaptive blended adja-cency matrix dynamically, which enhances the generaliza-tion of our model on multi-action motions. Second, the pro-posed GAGCN can be utilized to balance the weight of spa-tial and temporal modeling by scaling the number of candi-date matrices. And the spatio-temporal features are fused to mine the hidden cross-dependency of spatio-temporal rela-tionships from the historical motion sequence. conducted on Hu-man3.6M [12], AMASS [23] and 3DPW [33]. We demonstrate that our method outperforms state-of-the-art methods in both short-term and long-term motion pre-dictions. The main contributions of our work can be summarized as follows: experiments
Extensive are 1. To the best of our knowledge, we are the first to use the gating network to enhance the generalization of GCN on human motion prediction. The adaptive adjacency matrix obtained by blending candidate matrices helps to enhance the scalability of our network across multi-action motions. 2. We capture the cross-dependency of space and time by balancing and fusing the decoupled joint dependencies and temporal correlations to learn the more expressive embedding features. 3. We carry out extensive experiments on Human3.6M,
AMASS and 3DPW both quantitatively and qualita-tively to demonstrate that the results of our method outperform state-of-the-art works. 2.