Abstract
This paper addresses incremental few-shot instance seg-mentation, where a few examples of new object classes ar-rive when access to training examples of old classes is not available anymore, and the goal is to perform well on both old and new classes. We make two contributions by extend-ing the common Mask-RCNN framework in its second stage – namely, we specify a new object class classifier based on the probit function and a new uncertainty-guided bounding-box predictor. The former leverages Bayesian learning to address a paucity of training examples of new classes. The latter learns not only to predict object bounding boxes but also to estimate the uncertainty of the prediction as a guid-ance for bounding box refinement. We also specify two new loss functions in terms of the estimated object-class distribution and bounding-box uncertainty. Our contribu-tions produce significant performance gains on the COCO dataset over the state of the art – specifically, the gain of
+6 on the new classes and +16 on the old classes in the
AP instance segmentation metric. Furthermore, we are the first to evaluate the incremental few-shot setting on the more challenging LVIS dataset. 1.

Introduction
This paper addresses the two related problems of incre-mental few-shot object detection (iFSOD) and instance seg-mentation (iFSIS). Initially, we are given a large training set of base object classes, which can be used for pre-training an instance segmenter. After this pre-training, access to train-ing examples of the base classes becomes unavailable. With an arrival of a few training examples of new classes, the goal is to achieve successful object detection and instance segmentation on both new and base classes. Our key chal-lenges include: how to address a paucity of data for new classes, and how to train on the new classes such that the base classes are not “forgotten”.
Tab. 1 compares iFSOD and iFSIS with other related problems. iFSOD and iFSIS are important problems aris-ing in many applications, where access to old training data
Figure 1. Our iFS-RCNN is first pre-trained on abundant exam-ples of base classes, and then fine-tuned on a few examples of new classes. iFS-RCNN modifies the classification head of Mask-RCNN by estimating the class-weight distribution via Bayesian learning. iFS-RCNN modifies the bounding-box head of Mask-RCNN by computing uncertainty of predicting the left (L), right (R), top (T), and bottom (B) sides of the bounding boxes. For test-ing, the last layers learned on the new classes (diagonal stripes) are concatenated with the corresponding ones learned on the base classes (solid color). becomes unavailable, due to, e.g., privacy and security is-sues or new legal regulations of data access. Also, they are critical in applications where limited time budgets prohibit retraining on both base and new classes.
There is scant work on iFSOD and iFSIS. Following re-cent FSIS approaches, we use Mask-RCNN [13], and mod-ify its prediction heads, as shown in Fig. 1. Mask-RCNN is first pre-trained with abundant examples of base classes, and then fine-tuned on new classes by “freezing” all mod-Settings
Pretrained on Fine-tuned on Tested on
FSOD - FSIS gFSOD - gFSIS
CL iFSOD - iFSIS base base base base new new base + new base + new base + new base + new new new
Table 1. A comparison of related problems. The blue and red in-dicate abundant and a few examples, respectively, of base and new classes. FSOD (FSIS): few-shot object detection (instance seg-mentation), gFSOD (gFSIS): generalized FSOD (FSIS), CL: con-tinual learning, iFSOD (iFSIS): incremental FSOD (FSIS). iFSOD (iFSIS) are more challenging than: FSOD (FSIS), since we test on both classes; gFSOD (gFSIS), since our training cannot access the base classes; CL, since they work with more examples. ules except for the classification head, bounding-box head, and segmentation-mask head. Finally, for testing on both base and new classes, weights learned on the new classes are concatenated with weights learned on the base classes to make the corresponding last layers in the classification, bounding-box, and segmentation-mask heads.
As shown in Fig. 1 and depicted in more detail in Fig. 2, we make two contributions aimed at addressing overfit-ting of Mask-RCNN in few-shot fine-tuning and improving its generalization to query images with large appearance-shape-scale variations of both base and new classes.
Inspired by deep Bayesian learning [2], our first contri-bution is about learning a distribution of the classification head’s weights on the new classes, and using the estimated distribution for regularization of the fine-tuning. Instead of using the standard Monte Carlo sampling of weights for this
Bayesian learning, our key technical novelty is in casting the weight-distribution learning as a Bayesian logistic re-gression problem, and specifying an efficient approximation to this intractable problem using the probit function. From our ablation studies, our probit-based approximation gives a significantly better performance than the Monte Carlo sam-pling, even under a reasonable training-time budget.
Our second contribution is about estimating the uncer-tainty of bounding-box localization on the new classes, and using the estimated uncertainty for two purposes – to refine the bounding-box prediction and to appropriately weight the loss of bounding-box prediction. As shown in Fig. 2, we use the estimated uncertainty along with the ROI-aligned-pooled feature map as input to a new bounding-box refine-ment module. The refined bounding box is subsequently input to the segmentation head. Also, we define a new loss between the ground truth and predicted bounding box, such that the loss becomes smaller for highly uncertain predic-tions, i.e., our fine-tuning stronger penalizes errors on train-ing examples with highly certain bounding-box predictions.
It is worth noting that we neither use Bayesian learn-ing nor explicitly estimate uncertainty for fine-tuning of the segmentation head of Mask-RCNN. This is because fine-tuning of the segmentation head on a few examples of the new classes does not face the common challenges of few-shot learning. Recall that the segmentation head predicts pixel labels independently with a 1 × 1 convolution. Conse-quently, every (pixel, label) pair is an independent training example, giving rise to a sufficiently large training set for fine-tuning of the segmentation mask.
Our extension of Mask-RCNN for incremental few-shot setting gives the name to our approach – iFS-RCNN. iFS-RCNN is evaluated on the COCO dataset [24] for few-shot object detection and instance segmentation with the iFSOD, iFSIS, FSOD, and FSIS tasks. iFS-RCNN significantly out-performs a recent approach [11]. In comparison with the standard Mask-RCNN trained in the gFSOD and gFSIS set-tings, iFS-RCNN shows a considerable improvement on the new classes while retaining the same performance on the base classes. On iFSOD and iFSIS, we also achieve the higher COCO AP rates by +6 and +16 for the new and base classes, respectively, relative to the state of the art.
In addition, we are the first to report the results of iFSOD, FSIS, and iFSIS on the more challenging LVIS dataset [12] having significantly more classes and long-tailed class distributions.
In the following, Sec. 2 reviews prior work; Sec. 3 spec-ifies iFS-RCNN; and Sec. 4 presents our implementation details and experimental results. 2.