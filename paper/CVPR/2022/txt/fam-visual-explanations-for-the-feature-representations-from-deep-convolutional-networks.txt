Abstract
In recent years, increasing attention has been drawn to the internal mechanisms of representation models. Tradi-tional methods are inapplicable to fully explain the feature representations, especially if the images do not ﬁt into any category. In this case, employing an existing class or the similarity with other image is unable to provide a complete and reliable visual explanation. To handle this task, we propose a novel visual explanation paradigm called Fea-ture Activation Mapping (FAM) in this paper. Under this paradigm, Grad-FAM and Score-FAM are designed for vi-sualizing feature representations. Unlike the previous ap-proaches, FAM locates the regions of images that contribute most to the feature vector itself. Extensive experiments and evaluations, both subjective and objective, showed that Score-FAM provided most promising interpretable vi-sual explanations for feature representations in Person Re-Identiﬁcation. Furthermore, FAM also can be employed to analyze other vision tasks, such as self-supervised represen-tation learning. 1.

Introduction
Over the last few years, the model explanation in-creasingly draws attention due to the wide applications of
Convolutional Neural Networks (CNNs). To this end, vari-ous visual explanation methods have been proposed.
For interpreting classiﬁcation problem, Class Activation
Map (CAM) [1, 33] is proposed to locate which regions of input image were looked at by the model for assigning the label. Recent CAM-based works could be divided into two branches, one is gradient-based CAMs [14] which use gradient of class conﬁdence to incorporate the importance of inputs, the other is gradient-free CAMs [12, 22] which capture the importance by the change of class conﬁdence.
Meanwhile, a number of methods, e.g., DeepLift [16] and integrated gradients [20], approximate the contribution of inputs based on the element-wise product with gradients.
It is noteworthy that a target neuron or score must be speciﬁed to evaluate gradient for the above approaches. In classiﬁcation, class conﬁdence usually is the target. How-ever, in some tasks, the class of a test sample might not exist in train set. As a zero-shot learning problem, the identities of test set in Person Re-Identiﬁcation (Re-ID) are totally different from train set. As showed in Figure 1 (b), Score-CAM merely concerns on the similar part to the given train identity, such as umbrella, pants and shoes, rather than the person body in the test image. In this case, employing an existing class cannot provide a reliable explanation.
Much less works have focused on understanding the fea-ture representation [34]. RAM [23] and CG-RAM [15] are proposed to reveal the associated visual cues between a pair of images, and other gradient-based methods also can be applied to the gradient of similarity value. However, the similarity-based methods still are unable to explain the fea-ture representation completely. As showed in Figure 1 (c), the visualization results of RAM based on different images were quite different, and mostly depend on the selection of another image. The shoes got high activations in the result based on the rank-2 gallery image, but got low activations in others. Based on these conﬂicting results, it is hard to interpret the contribution degree of shoes on feature repre-sentation in this image. Other similarity-based approaches are also unable to explain this question. Besides that, a suit-able image for comparison sometimes might be unavailable in practical work. These issues have restricted interpreting
Re-ID model to assure the reliability.
To ameliorate the aforementioned ﬂaws, we pro-pose a novel visual explanation paradigm called Feature
Activation Mapping (FAM). FAM highlights the regions of images that contribute most to the global feature represen-tation. Speciﬁcally, we ﬁrst proposed Gradient-weighted
FAM (Grad-FAM), which eliminates the dependency of another image in RAM. Inspired by Score-CAM, a different gradient-free FAM method Score-weighted FAM (Score-FAM) is then proposed. Objective evaluation of Score-FAM outperformed the other methods by large scale on public datasets. The experimental results demonstrate that
Figure 1. (a) A test image in Market1501 and the corresponding result of Score-FAM; (b) Score-CAM results w.r.t. the top three similar identities in train set according to the class conﬁdences; (c) RAM results w.r.t. the top three similar gallery images according to ranking results. (d) The different colors in the visualizaition results represent corresponding activation values, which are shown in the color bar.
Score-CAM merely concerned on the similar part to the given train identity. RAM got quite different results for different pairs. Score-FAM provided a complete visual explanation for the feature vector.
Score-FAM provides a faithful visual explanation of the em-bedding process on Person Re-ID.
Furthermore, our proposed FAM can be applied to more vision tasks including representation learning [2] and open-set recognition [5]. For a model that outputs feature vec-tors, the traditional visual explanation approaches require an additional classiﬁer. Instead, FAM-based methods can interpret the feature representations directly.
Our key contributions are summarized as follows:
• We propose a novel localization technique FAM, in-cluding Grad-FAM and Score-FAM, to generate com-plete visual explanations for the feature vectors. Un-like the previous approaches, FAM is applicable to vi-sion tasks that output feature vectors, such as Re-ID and representation learning.
• We propose new metrics in this work to objectively evaluate the faithfulness of visual explanations on Per-son Re-ID, i.e., whether the visualization result di-rectly correlates with feature representation. Our re-sults with these metrics show superior performance of Score-FAM over other approaches on dataset Mar-ket1501 [30] and CUHK03 [7].
• FAM can be employed to visualize self-supervised rep-resentation learning models without separately train-ing linear classiﬁers.
The rest of this paper is organized as follows. Section 2 refers to recent works of Visualizing CNNs and Person Re-ID. In Section 3, we propose Grad-FAM and Score-FAM respectively. Experimental results in Section 4 demonstrate the effectiveness and outperformance of our proposed meth-ods. We draw conclusions in Section 5. 2.