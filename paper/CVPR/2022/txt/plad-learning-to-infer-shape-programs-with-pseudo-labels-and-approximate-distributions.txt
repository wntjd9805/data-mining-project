Abstract
Inferring programs which generate 2D and 3D shapes is important for reverse engineering, editing, and more. Train-ing models to perform this task is complicated because paired (shape, program) data is not readily available for many domains, making exact supervised learning infeasible.
However, it is possible to get paired data by compromising the accuracy of either the assigned program labels or the shape distribution. Wake-sleep methods use samples from a generative model of shape programs to approximate the dis-tribution of real shapes. In self-training, shapes are passed through a recognition model, which predicts programs that are treated as ‘pseudo-labels’ for those shapes. Related to these approaches, we introduce a novel self-training variant unique to program inference, where program pseudo-labels are paired with their executed output shapes, avoiding label mismatch at the cost of an approximate shape distribution.
We propose to group these regimes under a single concep-tual framework, where training is performed with maximum likelihood updates sourced from either Pseudo-Labels or an Approximate Distribution (PLAD). We evaluate these techniques on multiple 2D and 3D shape program infer-ence domains. Compared with policy gradient reinforcement learning, we show that PLAD techniques infer more accurate shape programs and converge significantly faster. Finally, we propose to combine updates from different PLAD meth-ods within the training of a single model, and find that this approach outperforms any individual technique. 1.

Introduction
Having access to a procedure which generates a visual datum reveals its underlying structure, facilitating high-level manipulation and editing by a person or autonomous agent.
Thus, inferring such programs from visual data is an im-portant problem. In R2, inferring shape programs has ap-plications in the design of diagrams, icons, and other 2D graphics. In R3, it has applications in reverse engineering of
CAD models, procedural modeling for 3D games, and 3D structure understanding for autonomous agents.
We formally define shape program inference as obtaining a latent program z which generates a given observed shape x. We model p(z|x) with deep neural networks that train over a distribution of real shapes in order to amortize the cost of shape program inference on unseen shapes (e.g. a test set). This is a challenging problem: it is a structured prediction problem whose output is high-dimensional and can feature both discrete and continuous components (i.e. program control flow vs. program parameters). Nevertheless, learning p(z|x) becomes tractable provided that one has access to paired (X, Z) data (i.e. a dataset of shapes and the programs which generate them) [31]. Unfortunately, while shape data is increasingly available in large quantities [2], these shapes do not typically come with their generating program.
To circumvent this data problem, researchers have typ-ically synthesized paired data by generating synthetic pro-grams and pairing them with the shapes they output [24, 28].
However, as there is typically significant distributional mis-match between these synthetic shapes and “real” shapes from the distribution of interest, S∗, various techniques must be employed to fine-tune p(z|x) models towards S∗.
A number of these fine-tuning strategies attempt to di-rectly propagate gradients from geometric similarity mea-sures back to p(z|x). When the program executor is not a black-box, it may be possible to do this by implementing a differentiable relaxation of its behavior [16], but this re-quires knowledge of its functional form. One can also try learning a differentiable proxy of the executor’s behavior
[28], but this approximation introduces errors. Moreover, as shape programs typically involve many discrete struc-tural decisions, training such a model end-to-end is usually infeasible in many domains. Thus, many prior works of-ten resort to general-purpose policy gradient reinforcement learning [8, 24], which treats the program executor as a (non-differentiable) black-box. The downside of this strategy is that RL is notoriously unstable and slow to converge.
In this paper, we study a collection of methods that create
(shape, program) data pairs used to train p(z|x) models with maximum likelihood estimation (MLE) updates while treating the program executor as a black-box. As discussed, ground-truth (shape, program) pairs are often unavailable, so these techniques must make compromises in how they formulate paired data. In wake-sleep, a generative model p(z) is trained to convergence on alternating cycles with respect to p(z|x). When training p(z|x), paired data can be created by sampling from p(z). Each program label z is valid with respect to its associated x shape, but there is often a distributional mismatch between the generated set of shapes, X, and shapes from the target distribution, S∗. In self-training, one uses p(z|x) to infer latent z’s for unlabeled input x’s; these z’s then become “pseudo-labels” which are treated as ground truth for another round of supervised training. In this paradigm, there is no distributional shift between X and S∗, but each z is only an approximately correctly label with respect to its paired x.
We observe that shape program inference has a unique property that makes it especially well-suited for self-training: the distribution p(x|z) is known a priori—this is a delta distribution defined by the program executor. When using a model p(z|x) to infer a program z from some shape x∗ of interest, one can use this executor to produce a shape x that is consistent with the program z: in the terminology of self-training, z is guaranteed to be the “correct label” for x. However, similar to wake-sleep, formulating X as shape executions produced by model inferred programs can cause a distributional shift between X and S∗. Since this variant of self-training involves executing the inferred latent program z, we call this procedure latent execution self-training (LEST).
As all of the aforementioned fine-tuning regimes use ei-ther Pseudo-Labels or Approximate Distributions to formu-late (shape, program) pairs, we group them under a single conceptual framework: PLAD. We evaluate PLAD meth-ods experimentally, using them to fine-tune shape program inference models in multiple shape domains: 2D and 3D constructive solid geometry (CSG), and assembly-based modeling with ShapeAssembly, a domain-specific language for structures of manufactured 3D objects [14]. We find that PLAD training regimes offer substantial advantages over the de-facto approach of policy gradient reinforcement learning, achieving better shape reconstruction performance while requiring significantly less computation time. Further, we explore combining training updates from a mixture of
PLAD methods, and find that this approach leads to better performance compared with any individual method. Code for our method and experiments can be found at found at https://github.com/rkjones4/PLAD .
In summary, our contributions are: 1. Proposing the PLAD conceptual framework to group a family of related self-supervised learning techniques for shape program inference. 2. Introducing latent execution self-training, a PLAD method, to take advantage of the unique properties of the shape program inference problem. 3. Experiments across multiple 2D and 3D shape program inference domains, demonstrating that (i) fine-tuning under PLAD regimes outperforms policy gradient rein-forcement learning and (ii) combining PLAD methods is better than any individual technique. 2.