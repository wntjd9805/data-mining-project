Abstract
Recently, significant progress has been made on image denoising with strong supervision from large-scale datasets.
However, obtaining well-aligned noisy-clean training im-age pairs for each specific scenario is complicated and costly in practice. Consequently, applying a conventional supervised denoising network on in-the-wild noisy inputs is not straightforward. Although several studies have chal-lenged this problem without strong supervision, they rely on less practical assumptions and cannot be applied to practi-cal situations directly. To address the aforementioned chal-lenges, we propose a novel and powerful self-supervised de-noising method called CVF-SID based on a Cyclic multi-Variate Function (CVF) module and a self-supervised im-age disentangling (SID) framework. The CVF module can output multiple decomposed variables of the input and take a combination of the outputs back as an input in a cyclic manner. Our CVF-SID can disentangle a clean image and noise maps from the input by leveraging various self-supervised loss terms. Unlike several methods that only consider the signal-independent noise models, we also deal with signal-dependent noise components for real-world ap-plications. Furthermore, we do not rely on any prior as-sumptions about the underlying noise distribution, making
CVF-SID more generalizable toward realistic noise. Ex-tensive experiments on real-world datasets show that CVF-SID achieves state-of-the-art self-supervised image denois-ing performance and is comparable to other existing ap-proaches. The code is publicly available from this link. 1.

Introduction
Image denoising is an active research topic and has at-tracted increasing attention due to its practicality in com-puter vision. The fundamental idea of image denoising is to remove unwanted noise signals from a given input and restore a noise-free clean image. Following the recent ad-*equal contribution
Input Noisy
Ground Truth
N2V [18]: 24.00dB
N2S [4]: 25.34dB
R2R [25]: 30.37dB
CVF-SID (Ours): 32.99dB
Figure 1. Real-world image denoising results on the SIDD val-idation dataset. In contrast to R2R, our CVF-SID is directly ap-plicable to sRGB images. N2V and N2S fail to restore the clean image, and R2R loses the details evidenced in the yellow patch. vances in convolutional neural networks (CNN), the lat-est denoising methods have achieved dramatic performance compared to the traditional algorithms. Specifically, those methods resort to supervised learning on the large-scale synthetic dataset, where noise is simply modeled with ad-ditive white Gaussian (AWGN) [9, 11, 20, 33, 35].
Nevertheless, recent studies [3, 12] have observed that the denoising models learned on synthetic images do not generalize well on practical examples. The primary rea-son for this issue is that real-world noise distribution differs from the synthetic AWGN. To deal with this limitation, few attempts have been made to acquire realistic noisy-clean im-age pairs [1] in the wild. Still, this process is challenging and sometimes unavailable as it requires multiple shots un-der the same static scene with several constraints.
Advanced methods overcome the lack of paired images by adopting novel un-/self-supervised frameworks. The generation-based approaches [13, 16] utilize unsupervised adversarial training. They first generate noisy samples from a set of clean images by imitating the noise distribution of
the target dataset. Then, a denoising model can be trained in a supervised manner with the generated noisy-clean im-age pairs. Nevertheless, they require appropriate clean im-ages that are not always available due to domain differences between noisy and clean images. Rather than using clean ground-truth data, Noise2Noise (N2N) [21] uses two noisy images taken from the same scene and configuration. While
N2N shows comparable performance with the supervised methods, it is less practical as multiple noisy images under the same scene are required.
As an alternative solution, several strategies [4, 14, 18, 24, 25, 27] have been proposed to train their methods on noisy images only. To generate feasible input-target pairs from a single noisy image, these recent approaches try to synthesize two independent noisy images from the input.
However, these methods are usually constructed by assum-ing a specific distribution, e.g., AWGN, or less practical configurations for the underlying noise. Such an assump-tion limits their practical applications where the assump-tion does not hold. For instance, recent Recorrupted-to-Recorrupted (R2R) [25] is not applicable to sRGB inputs directly, while digital images are usually stored using sRGB color space. Also, this method requires additional prior knowledge, e.g., a pre-trained model with provided noise level function (NLF) [22] by Raw-RGB images, on real-world noise, which is not trainable using sRGB images only.
To mitigate the limitations mentioned above, we present a self-supervised denoising method for the real-world sRGB images. To this end, we propose a novel cyclic multi-variate function (CVF), which disentangles its input into several sub-components and retakes a combination of its outputs as an input. We utilize CVF to design our self-supervised image disentangling model (CVF-SID) for sRGB image de-noising. Under various self-supervised training objectives, our CVF-SID can learn to disentangle the noise-free im-age, signal-dependent and signal-independent noises from a given noisy sRGB input. Furthermore, we propose a self-supervised data augmentation strategy for CVF-SID to ef-fectively increase the number of training samples. Our main contributions can be summarized as follows:
• We introduce CVF-SID, a novel self-supervised method for image denoising based on our defined cyclic multi-variate function (CVF). CVF-SID disen-tangles a given real-world noisy input to clean image, signal-dependent, and signal-independent noises.
• For fully self-supervised CVF-SID, we propose vari-ous training objectives and an augmentation strategy.
• Experimental results demonstrate that our CVF-SID achieves superior denoising performance among sev-eral un-/self-supervised methods on real-world sRGB images as shown in Figure 1 and is comparable with the other approaches.
Figure 2. The proposed Cyclic multi-Variate Function (CVF).
Our CVF f takes a combination g (s1X, s2Y, s3Z, . . .) of multi-ple variables as an input and outputs the decomposed variables. 2.