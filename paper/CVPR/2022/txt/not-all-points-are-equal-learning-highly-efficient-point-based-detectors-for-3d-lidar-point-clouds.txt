Abstract
We study the problem of efﬁcient object detection of 3D
LiDAR point clouds. To reduce the memory and compu-tational cost, existing point-based pipelines usually adopt task-agnostic random sampling or farthest point sampling to progressively downsample input point clouds, despite the fact that not all points are equally important to the task of object detection. In particular, the foreground points are in-herently more important than background points for object detectors. Motivated by this, we propose a highly-efﬁcient single-stage point-based 3D detector in this paper, termed
IA-SSD. The key of our approach is to exploit two learn-able, task-oriented, instance-aware downsampling strate-gies to hierarchically select the foreground points belong-ing to objects of interest. Additionally, we also introduce a contextual centroid perception module to further estimate precise instance centers. Finally, we build our IA-SSD fol-lowing the encoder-only architecture for efﬁciency. Exten-sive experiments conducted on several large-scale detec-tion benchmarks demonstrate the competitive performance of our IA-SSD. Thanks to the low memory footprint and a high degree of parallelism, it achieves a superior speed of 80+ frames-per-second on the KITTI dataset with a sin-gle RTX2080Ti GPU. The code is available at https:
//github.com/yifanzhang713/IA-SSD. 1.

Introduction
Accurate recognition and localization of speciﬁc 3D ob-jects is a fundamental research problem in 3D computer vi-sion [10]. As a commonly-used 3D representation, point cloud has attracted increasing attention for its ﬂexibility and compactness. However, the task of 3D object detection in
LiDAR point clouds (i.e., predicting 3D bounding boxes with 7 degrees-of-free including 3D-location, 3D-size, ori-entation, and class labels) remains highly challenging due to the complex geometrical structure and non-uniform density.
*Corresponding author
Figure 1. Comparison of the detection performance (accuracy) and efﬁciency (computational and memory) of different methods in KITTI benchmark. All experiments are conducted on a single
RTX2080Ti GPU. Note that, we evaluate the memory efﬁciency by calculating the maximum number of parallel frames during in-ference when fully utilizing the GPU memory. Additionally, the
FPS is calculated with the full utilization of GPU memory, more detailed analysis could be found in Table 6.
Due to the unstructured and orderless nature of 3D point clouds, early works usually ﬁrst convert the raw point clouds into intermediate regular representation, including projecting the 3D point clouds into 2D images from birds-eye-view or frontal view [1, 17, 18, 41, 42, 50, 60], or trans-formed into dense 3D voxels [49, 61]. Then, several well-developed 2D detection paradigms can be deployed into the task of 3D object detection. Although remarkable progress has been achieved recently [2, 3, 7, 11, 24, 39, 53, 54], these
methods introduce the quantization error due to the 3D-2D projection or voxelization, which inevitably limits their performance of existing methods. Another stream of tech-niques following the point-based pipeline to directly operate on raw point clouds [12, 13, 15, 38, 40, 48, 52]. They usu-ally learn point-wise features and then aggregate through speciﬁc symmetric functions such as max-pooling [31, 32].
Although promising and without any explicit information loss, these methods still suffer from expensive computa-tional/memory costs and limited detection performance.
In this paper, we ﬁrst dive deep into the existing point-based frameworks and experimentally ﬁnd that the heuris-tic sampling strategies used are far from satisfactory, since a number of the important foreground points have been dropped before the ﬁnal bounding box regression step. As such, the detection performance, especially for small ob-jects such as pedestrians, has been fundamentally limited.
In this paper, we argue that not all points are equally im-portant to the task of object detection. In particular, only the foreground points, are the things we really care about.
Motivated by this, we aim to propose a task-oriented, to explicitly instance-aware downsampling framework, preserve foreground points while reducing the mem-ory/computational cost. Speciﬁcally, two variants, namely class-aware and centroid-aware sampling strategies are proposed. In addition, we also present a contextual instance centroid perception, to fully exploit the meaningful con-text information around bounding boxes for instance cen-ter regression. Finally, we build our IA-SSD based on the bottom-up single-stage framework. As shown in Figure 1, the proposed IA-SSD demonstrated to be highly efﬁcient (up to inference 100 frames in parallel in a single pass, with a speed of 83 FPS on a single RTX 2080Ti GPU) and ac-curate on the KITTI benchmark [8]. In particular, thanks to the high instance recall ratio of the proposed sampling strat-egy, the proposed IA-SSD can be directly trained with mul-tiple object categories, rather than the common practice, i.e., train separate models for different categories. Extensive ex-periments on Section 4 justify the compelling performance and superior efﬁciency of our method.
To summarize, the contributions are listed as follows:
• We identify the sampling issue in existing point-based detectors, and proposed an efﬁcient point-based 3D detector by introducing two learning-based instance-aware downsampling strategies.
• The proposed IA-SSD is highly efﬁcient and capable of detecting multi-class objects on LiDAR point clouds in a single pass. We also provided a detailed memory footprint vs. inference-speed analysis to further vali-date the superiority of the proposed method.
• Extensive experiments on several large-scale datasets demonstrate the superior efﬁciency and accurate de-tection performance of the proposed method. 2.