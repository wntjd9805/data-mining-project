Abstract
We propose an effective and easy-to-implement method for simultaneously performing landmark detection in im-ages and obtaining an ingenious uncertainty measurement for each landmark. Uncertainty measurements for land-marks are particularly useful in medical imaging applica-tions: rather than giving an erroneous reading, a landmark detection system is more useful when it flags its level of confidence in its prediction. When an automated system is unsure of its predictions, the accuracy of the results can be further improved manually by a human.
In the medi-cal domain, being able to review an automated system’s level of certainty significantly improves a clinician’s trust in it. This paper obtains landmark predictions with un-certainty measurements using a three stage method: 1) We train our network on one-hot heatmap images, 2) We cali-brate the uncertainty of the network using temperature scal-ing, 3) We calculate a novel statistic called ‘Expected Ra-dial Error’ to obtain uncertainty measurements. We find that this method not only achieves localization results on par with other state-of-the-art methods but also an uncer-tainty score which correlates with the true error for each landmark thereby bringing an overall step change in what a generic computer vision method for landmark detection should be capable of. In addition we show that our uncer-tainty measurement can be used to classify, with good accu-racy, what landmark predictions are likely to be inaccurate.
Code available at: https://github.com/jfm15/
ContourHuggingHeatmaps.git 1.

Introduction
Automatic landmark detection from images is an impor-tant task in a number of applications from monitoring a driver’s vital signs [3] to medical imaging applications on numerous body parts including the knee, spine and lungs
[4–6]. Most modern approaches to landmark detection use a deep learning pipeline and obtain impressive localization results. However these deep learning methods always detect some landmarks erroneously during testing. Take, for ex-(a) Gaussian distributions out-put by Kumar et al. [1] - LU-VLi Landmarks. (b) Gaussian distributions out-put by LEE et al. [2] which uses a Bayesian CNN. (c) Contours of the heatmaps output by our method. The dark blue dots are the predicted landmark points and the bright green dots are the ground truth. We call our heatmaps contour hugging because of the way they bend around the edges (in this case of the head). Our probability distributions are not restricted to being symmetrical and uni-modal.
Figure 1. Images demonstrating the difference in how our method quantifies the uncertainty of its landmark positions compared to previous approaches.
ample, the task of cephalometric landmark detection from x-rays of the head. These landmarks are used to compute clinically useful angles and measurements from which clin-icians can diagnose patients [7]. However, even the lat-est deep learning approaches detect at least 13% of land-marks outside the clinically accepted range (greater than 2mm error) [8, 9] so it could be dangerous to build these systems into safety-critical clinical workflows, especially if there was no human expert supervision. In this paper we address this problem by formulating the task of landmark detection as a classification task over all pixels in an image.
This allows us to obtain more expressive and interpretable heatmaps as shown in Figure 1c. These heatmaps can be calibrated (Section 3.3) and then analysed using our novel statistic called Expected Radial Error ERE (Section 3.4).
This statistic correlates well with the true localization er-ror and can be used to flag potentially erroneous predictions (Section 5.3.1). 2.