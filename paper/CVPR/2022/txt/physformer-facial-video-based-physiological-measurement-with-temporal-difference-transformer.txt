Abstract
Remote photoplethysmography (rPPG), which aims at measuring heart activities and physiological signals from facial video without any contact, has great potential in many applications. Recent deep learning approaches fo-cus on mining subtle rPPG clues using convolutional neu-ral networks with limited spatio-temporal receptive fields, which neglect the long-range spatio-temporal perception and interaction for rPPG modeling.
In this paper, we propose the PhysFormer, an end-to-end video transformer based architecture, to adaptively aggregate both local and global spatio-temporal features for rPPG representation enhancement. As key modules in PhysFormer, the tempo-ral difference transformers first enhance the quasi-periodic rPPG features with temporal difference guided global at-tention, and then refine the local spatio-temporal represen-tation against interference. Furthermore, we also propose the label distribution learning and a curriculum learning inspired dynamic constraint in frequency domain, which provide elaborate supervisions for PhysFormer and al-leviate overfitting. Comprehensive experiments are per-formed on four benchmark datasets to show our supe-rior performance on both intra- and cross-dataset testings.
One highlight is that, unlike most transformer networks needed pretraining from large-scale datasets, the proposed
PhysFormer can be easily trained from scratch on rPPG datasets, which makes it promising as a novel transformer baseline for the rPPG community. The codes are available at https://github.com/ZitongYu/PhysFormer. 1.

Introduction
Physiological signals such as heart rate (HR), respiration frequency (RF), and heart rate variability (HRV) are impor-tant vital signs to be measured in many circumstances, es-pecially for healthcare or medical purposes. Traditionally, the Electrocardiography (ECG) and Photoplethysmograph (PPG) are the two most common ways for measuring heart
*Corresponding author
Figure 1. The trajectories of rPPG signals around t1, t2, and t3 share similar properties (e.g., trends with rising edge first then falling edge later, and relatively high magnitudes) induced by skin color changes. It inspires the long-range spatio-temporal attention (e.g., blue tube around t1 interacted with red tubes from intra- and inter-frames) according to their local temporal difference features for quasi-periodic rPPG enhancement. Here ‘tube’ indicates the same regions across short-time consecutive frames. activities and corresponding physiological signals. How-ever, both ECG and PPG sensors need to be attached to body parts, which may cause discomfort and are inconve-nient for long-term monitoring. To counter for this issue, remote photoplethysmography (rPPG) [12, 36, 66] methods are developing fast in recent years, which aim to measure heart activity remotely without any contact.
In earlier studies of facial rPPG measurement, most methods analyze subtle color changes on facial regions of interest (ROI) with classical signal processing ap-proaches [30, 49, 50, 55, 57]. Besides, there are a few color subspace transformation methods [13, 59] which uti-lize all skin pixels for rPPG measurement. Based on the prior knowledge from traditional methods, a few learning based approaches [25, 44, 45, 51] are designed as non-end-to-end fashions. ROI based preprocessed signal represen-tations (e.g., time-frequency map [25] and spatio-temporal map [44, 45]) are generated first, and then learnable mod-els could capture rPPG features from these maps. However, these methods need the strict preprocessing procedure and neglect the global contextual clues outside the pre-defined
ROIs. Meanwhile, more and more end-to-end deep learn-ing based rPPG methods [11, 34, 53, 65, 67] are developed,
which treat facial video frames as input and predict rPPG and other physiological signals directly. However, pure end-to-end methods are easily influenced by the complex sce-narios (e.g., with head movement and various illumination conditions) and rPPG-unrelated features can not be ruled out in learning, resulting in large performance decrease [63] in realistic datasets (e.g., VIPL-HR [45]).
Recently, due to its excellent long-range attentional mod-eling capacities in solving sequence-to-sequence issues, transformer [22, 32] has been successfully applied in many artificial intelligence tasks such as natural language pro-cessing (NLP) [56], image [15] and video [3] analysis. Sim-ilarly, rPPG measurement from facial videos can be treated as a video sequence to signal sequence problem, where the long-range contextual clues should be exploited for seman-tic modeling. As shown in Fig. 1, rPPG clues from different skin regions and temporal locations (e.g., signal trajectories around t1, t2, and t3) share similar properties (e.g., trends with rising edge first then falling edge later and relative high magnitudes), which can be utilized for long-range fea-ture modeling and enhancement. However, different from the most video tasks aiming at huge motion representation, facial rPPG measurement focuses on capturing subtle skin color changes, which makes it challenging for global spatio-temporal perception. Furthermore, video-based rPPG mea-surement is usually a long-time monitoring task, and it is challenging to design and train transformers with long video sequence inputs.
Motivated by the discussions above, we propose an end-to-end video transformer architecture, namely PhysFormer, for remote physiological measurement. On one hand, the cascaded temporal difference transfomer blocks in Phys-Former benefit the rPPG feature enhancement via global spatio-temporal attention based on the fine-grained tempo-ral skin color differences. On the other hand, to alleviate the interference-induced overfitting issue and complement the weak temporal supervision signals, elaborate supervi-sion in frequency domain is designed, which helps Phys-Former learn more intrinsic rPPG-aware features.
The contributions of this work are as follows:
• We propose the PhysFormer, which mainly consists of a powerful video temporal difference transformer backbone. To our best knowledge, it is the first time to explore the long-range spatio-temporal relationship for reliable rPPG measurement.
• We propose an elaborate recipe to supervise Phys-Former with label distribution learning and curriculum learning guided dynamic loss in frequency domain to learn efficiently and alleviate overfitting.
• We conduct intra- and cross-dataset testings and show that the proposed PhysFormer achieves superior or on par state-of-the-art performance without pretraining on large-scale datasets like ImageNet-21K. 2.