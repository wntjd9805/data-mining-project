Abstract
Different self-supervised tasks (SSL) reveal different fea-tures from the data. The learned feature representations can exhibit different performance for each downstream task.
In this light, this work aims to combine Multiple SSL tasks (Multi-SSL) that generalizes well for all downstream tasks.
For this study, we investigate binaural sounds and image data. For binaural sounds, we propose three SSL tasks namely, spatial alignment, temporal synchronization of fore-ground objects and binaural sounds and temporal gap pre-diction. We investigate several approaches of Multi-SSL and give insights into the downstream task performance on video retrieval, spatial sound super resolution, and seman-tic prediction using OmniAudio dataset. Our experiments on binaural sound representations demonstrate that Multi-SSL via incremental learning (IL) of SSL tasks outperforms single SSL task models and fully supervised models in the downstream task performance. As a check of applicability on other modalities, we also formulate our Multi-SSL models for image representation learning and we use the recently proposed SSL tasks, MoCov2 and DenseCL. Here, Multi-SSL surpasses recent methods such as MoCov2, DenseCL and
DetCo by 2.06%, 3.27% and 1.19% on VOC07 classification and +2.83, +1.56 and +1.61 AP on COCO detection. 1.

Introduction
Self-supervised learning (SSL) is a popular paradigm to train deep networks on pretext tasks that readily extract super-vision from the data. Typically, this allows models to learn data representations, which are then used for downstream tasks. The objectives for these SSL tasks are designed based on the corresponding downstream tasks. As a result, pre-trained deep networks on SSL tasks yield good performance on that downstream task or related tasks when finetuned. We note in the literature [16, 67] that these pretrained models are not generic enough to give a satisfactory performance on a diverse pool of downstream tasks. For instance, some pretext tasks [9, 28] on images focus on learning global image fea-ture representation while few others [8, 43, 67, 61] focuses (a) Pipeline of our approach (b) Classification vs Object detection tradeoff
Figure 1: Self Supervised Learning (SSL) tasks are designed for specific downstream tasks. Our work demonstrates how a single model learns to combine Multiple SSL tasks (i.e.,
Multi-SSL) that generalizes well for all the downstream tasks. Figure (b) shows comparison of single SSL tasks: Mo-Cov2 [28] and DenseCL [67] with our Multi-SSL models. on local features. The former works well on downstream tasks like image retrieval or classification while the latter helps more for dense prediction/labelling tasks. For instance, this is evident in Figure 1(b) where MoCov2 [28] performs good for classification while DenseCL [67] comes out better for object detection task.
Be it visual, sound, or linguistic data, how well the data representations are learned determines the generalization capability of a model. When the models are generic, feature representations from them perform satisfactorily on several
diverse downstream tasks. In this light, our work tries to investigate how to train a self-supervised model using Multi-ple SSL tasks (Multi-SSL as in Figure 1(a)) that generalizes well.
In the last few years, a number of self-supervised ap-proaches are proposed in the language, sound and vision research community, from natural language text corpus
[14, 57, 59], images [43, 36], videos [1, 27, 38], and audios
[24, 39]. In sound representation learning, a few prominent ones are audio-visual correspondence [4, 75], audio context prediction [63], and among others. Colorization [41], image inpainting [56], etc., are among the vision tasks for image representations. To assess the model, a standard set of down-stream tasks for their corresponding areas is picked, and the model is retrained and tested on several datasets.
With the aim of extracting well generalized sound and image representations, this paper explores ways of combin-ing Multiple SSL tasks as shown in Figure 1(a). We call it Multi-SSL. While there have been a few works in this area on sound representation [60, 72, 69], language [66] or visual representation learning [16, 22], they have only con-sidered addressing this in the standard multi-tasking frame-work [16, 67]. This work, however, introduces Multi-SSL which investigates different design options to combine mul-tiple SSL tasks and provide insights into the downstream tasks. Through this comprehensive analysis, we highlight how Multi-SSL models improve over strong baselines for different downstream tasks. In the paper, we experiment with binaural sound and image data representations.
For binaural sound representation learning, we propose a set of SSL tasks. Firstly, spatial alignment task is proposed for learning spatial features in sounds. The task leverages the correspondence between binaural sounds and the rich spatial cues present in 360Â° videos. Our second task is to learn temporal synchronization of moving objects in the scene and binaural sounds. We call this task as foreground alignment as it learns to align foreground objects and sounds. The third task of temporal gap prediction encourages the sound models to learn a sense of time gap between binaural sounds. For training the above tasks, we use the OmniAudio dataset [65] and evaluate the performance on three downstream tasks: a) video retrieval, b) auditory semantic prediction and c) spatial sound super resolution (S3R).
In addition, we examine the performance of the proposed
Multi-SSL approach for visual representation learning. For
SSL tasks, we consider the recently proposed contrastive learning paradigms on representation learning. Following
MoCoV2 [28], the first SSL task works with contrastive learning at the level of global image features. For the second task, we select dense contrastive learning [67] which focuses on the local features. We train the above SSL tasks on the
ImageNet dataset [13] and then evaluate the performance on downstream tasks of image classification on Pascal VOC dataset [18] and object detection and instance segmentation on MS COCO dataset [45].
Furthermore, we propose different Multi-SSL methods such as Concatenation, Multi-task, ProgressiveNet, Incre-mental Learning (IL) and others, that are detailed in Section 4. Experiment results show that a) All the above Multi-SSL methods improve over single SSL tasks, b) they also outper-form supervised models, and finally c) IL approach performs the best among the Multi-SSL methods as in Figure 1(b).
We note that these observations are consistent for both sound and vision domains.
Here is a summary of our contributions. (1) We propose different approaches to self-supervised learning (SSL) for binaural sound representation learning; (2) We introduce several approaches of Multi-SSL that learns to combine multiple SSL tasks; (3) We also train and evaluate our Multi-SSL approach for image representation learning. 2.