Abstract
Consistency learning using input image, feature, or net-work perturbations has shown remarkable results in semi-supervised semantic segmentation, but this approach can be seriously affected by inaccurate predictions of unlabelled training images. There are two consequences of these in-accurate predictions: 1) the training based on the “strict” cross-entropy (CE) loss can easily overfit prediction mis-takes, leading to confirmation bias; and 2) the perturba-tions applied to these inaccurate predictions will use poten-tially erroneous predictions as training signals, degrading consistency learning. In this paper, we address the predic-tion accuracy problem of consistency learning methods with novel extensions of the mean-teacher (MT) model, which include a new auxiliary teacher, and the replacement of
MT’s mean square error (MSE) by a stricter confidence-weighted cross-entropy (Conf-CE) loss. The accurate pre-diction by this model allows us to use a challenging com-bination of network, input data and feature perturbations to improve the consistency learning generalisation, where the feature perturbations consist of a new adversarial per-turbation. Results on public benchmarks show that our ap-proach achieves remarkable improvements over the previ-ous SOTA methods in the field.1 Our code is available at https://github.com/yyliu01/PS-MT. 1.

Introduction
Semantic segmentation is an essential pixel-wise classi-fication task that has reached remarkable success in recent years. However, the training of such a task is known to be data-hungry, where the labelling process is particularly costly and time-consuming [34]. To tackle this limitation, semi-supervised semantic segmentation has become an im-portant research direction that has drawn a growing atten-tion recently [9,21,34]. This problem relies on a small set of pixel-level labelled images and a large set of unlabelled im-ages, where both types of images are drawn from the same 1Supported by Australian Research Council through grants
DP180103232 and FT190100525.
Figure 1.
In (a), we compare our method (red star) to the cur-rent SOTA on Pascal VOC 2012 under different partition protocols based on the augmented set [16], and (b) shows a simple diagram of our consistency-based model, which includes two mean teach-ers (denoted by the encoders t(1) enc. and decoders t(1) dec. and t(2) dec.) that produce accurate segmentation maps for unlabelled images xu and the student (encoder senc. and decoder sdec.), with three types of perturbations (network, feature and input image) that are used in the minimisation of our strict Conf-CE loss. enc. and t(2) data distribution. The challenge is how to extract additional and useful training signal from the unlabelled images to al-low the training of the model to generalise beyond the small labelled set.
Current state-of-the-art (SOTA) semi-supervised seman-tic segmentation models are based on consistency learning, which enforces the agreement between the outputs from dif-ferent views of unlabelled images [9, 14, 34, 44]. These dif-ferent views can be obtained via perturbations applied to the input image with data augmentation [44] or to the feature space with noise injection [34]. Another way of obtaining different views is with network perturbation, which encour-ages similar predictions between multiple models trained from different initialization, and has been shown to enable better consistency regularization than input image and fea-ture perturbations [9, 21]. One potential weakness of con-sistency learning is that it assumes accurate predictions for unlabelled images, such that the perturbation does not push the image feature to the wrong side of the true (hidden) classification decision boundary. Unfortunately, in prac-tice this assumption is not always met by SOTA methods, making the training signal of consistency learning meth-ods potentially incorrect. This problem is exacerbated for consistency learning based on network perturbation because incorrect predictions from one model will deteriorate the training for the other model, and vice versa. Another con-sequence of these inaccurate predictions is that consistency learning methods that rely on a “strict” cross-entropy (CE) loss can easily overfit prediction mistakes, which can lead to confirmation bias.
In this paper, we address the prediction accuracy prob-lem of consistency based methods by extending the mean teacher (MT) model [9, 14, 21, 37] with a new auxiliary teacher, and the replacement of MT’s means square er-ror (MSE) loss by a stricter confidence-weighted CE loss (Conf-CE) that has better training convergence. These accu-rate predictions enable the use of more challenging pertur-bations, combining input image, feature and network pertur-bations to improve the generalisation of consistency learn-ing. Furthermore, we propose a new type of adversarial feature perturbation that learns the perturbation to be ap-plied to the student model using virtual adversarial train-ing [33] from the teachers (T-VAT), instead of injecting dif-ferent types of noise in the image features [34]. To sum-marise, our contributions are:
• New consistency based semi-supervised semantic seg-mentation MT model designed to improve the segmen-tation accuracy of unlabelled training images with a new auxiliary teacher and a replacement of MT’s MSE loss by a stricter confidence-weighted CE loss (Conf-CE) that allows stronger convergence and overall bet-ter training accuracy;
• A new challenging combination of input data, feature and network perturbations to improve model generali-sation; and
• A new type of feature perturbation, called T-VAT, based on an adversarial noise learned from the both teachers of our MT model and applied to the student model, which results in the generation of challenging noise to promote an effective training of the student model.
Our experimental evaluation shows that our approach achieves the best results on Pascal VOC 2012 [12]. Our ap-proach also shows the best performance on Cityscapes [10]. 2.