Abstract
Unsupervised domain adaptation (UDA) is an impor-tant topic in the computer vision community. The key diffi-culty lies in defining a common property between the source and target domains so that the source-domain features can align with the target-domain semantics.
In this paper, we present a simple and effective mechanism that regular-izes cross-domain representation learning with a domain-agnostic prior (DAP) that constrains the features extracted from source and target domains to align with a domain-agnostic space. In practice, this is easily implemented as an extra loss term that requires a little extra costs. In the stan-dard evaluation protocol of transferring synthesized data to real data, we validate the effectiveness of different types of
DAP, especially that borrowed from a text embedding model that shows favorable performance beyond the state-of-the-art UDA approaches in terms of segmentation accuracy.
Our research reveals that UDA benefits much from better proxies, possibly from other data modalities. 1.

Introduction
In the deep learning era, the most powerful approach for visual recognition is to train deep neural networks with abundant, labeled data. Such a data-driven methodology suffers the difficulty of transferring across domains, which raises an important research field named domain adaptation.
This paper focuses on the setting of unsupervised domain adaptation (UDA), which assumes that the source domain offers full supervision but the target domain has no annota-tions available. In particular, we investigate semantic seg-mentation – provided the increasing amount of unlabeled data and the expensiveness of annotation, it becomes in-creasingly important to gain the ability of transferring mod-els from a known domain (e.g., labeled or synthesized data).
The goal of semantic segmentation is to assign each pixel with a class label. In the scenarios that annotations are ab-sent, this is even more challenging than image-level pre-diction (e.g., classification) because the subtle differences
Figure 1. Top: The goal is to transfer a segmentation model trained in the source domain to the target domain, but some semantically similar classes (see the left of (a) for examples of bike and mo-torbike) are difficult to distinguish due to domain shift. Bottom: segmentation results of the upper-right image without and with
DAP, where (b) shows incorrect segmentation (bike→motorbike and sidewalk→road) of the baseline (DACS [49]), and (c) shows how DAP improves segmentation. at the pixel level can be easily affected by the change of data distribution. Note that this factor can bring in the risk that pseudo labels are inaccurate and thus deteriorate transfer performance, and the risk becomes even higher when the target domain lacks sufficient data for specific classes or class pairs. Fig 1 shows an example that such ap-proaches [64, 49] are difficult in distinguishing semantically similar classes (e.g., motorbike vs. bike, road vs. sidewalk) from each other.
To alleviate the above issue, we first offer a hypothesis about the confusion – the proportion of similar categories in 1
the two domains varies too much or they often appear adja-cent to each other and the border is difficult to find ( there are limited pixels around the boundary). Consequently, it is difficult for the deep network to learn the discrimina-tion boundary based on the transferred image features. To compensate, we propose to add a domain-agnostic prior (DAP) to force the features from the source and target do-mains to align with an auxiliary space that is individual to both domains. According to the Bayesian theory, a properly designed prior relieves the instability of likelihood (pro-vided by the limited training data with similar classes co-occurring) and leads to more accurate inference.
We implement our algorithm upon DACS, a recent ap-proach built upon an advanced data augmentation named
ClassMix [37]. The training procedure of DACS involves sampling a pair of source and target images and making use of pseudo labels to generate a mixed image with partly-pseudo labels, and feeding the source and mixed images into the deep network. We introduce DAP into the frame-work by defining a high-dimensional, domain-agnostic em-bedding vector for each class, and force the features ex-tracted from both the source and mixed images to align with the embedding vectors through an auxiliary module. We in-vestigate two types of domain-agnostic embedding, namely, one-hot vectors and the word2vec features [35], and show that both of them bring consistent gain in transferring. As a side note, DAP is efficient to carry out – the auxiliary module is lightweight that requires around 7% extra train-ing computation and is removed during the inference stage.
We evaluate DAP on two standard UDA segmentation benchmarks, in which the source domain is defined by a synthesized dataset (i.e., GTAv [39] or SYNTHIA [40]) while the target domain involves Cityscapes [10], a dataset captured from the real world. With the word2vec features as prior, DAP achieves segmentation mIOU scores of 55.0% and 50.2% from GTAv and SYNTHIA, respectively, with absolute gains of 2.9% and 1.3% over the DACS baseline, setting the new state-of-the-art among single-model, single-round approaches for UDA segmentation.
The main contribution of this work lies in the proposal and implementation of domain-agnostic prior for UDA seg-mentation. With such a simple and effective approach, we reveal that much room is left behind UDA. We expect more sophisticated priors and/or more effective constraints to be explored in the future. 2.