Abstract
We study the problem of multi-robot active mapping, which aims for complete scene map construction in min-imum time steps. The key to this problem lies in the goal position estimation to enable more efficient robot movements.
Previous approaches either choose the frontier as the goal position via a myopic solution that hinders the time effi-ciency, or maximize the long-term value via reinforcement learning to directly regress the goal position, but does not guarantee the complete map construction. In this paper, we propose a novel algorithm, namely NeuralCoMapping, which takes advantage of both approaches. We reduce the problem to bipartite graph matching, which establishes the node correspondences between two graphs, denoting robots and frontiers. We introduce a multiplex graph neural network (mGNN) that learns the neural distance to fill the affinity matrix for more effective graph matching. We optimize the mGNN with a differentiable linear assignment layer by max-imizing the long-term values that favor time efficiency and map completeness via reinforcement learning. We compare our algorithm with several state-of-the-art multi-robot active mapping approaches and adapted reinforcement-learning baselines. Experimental results demonstrate the superior performance and exceptional generalization ability of our algorithm on various indoor scenes and unseen number of robots, when only trained with 9 indoor scenes. 1.

Introduction
Constructing the map of indoor environments is of great importance to a wide range of applications in the computer vision and robotics communities. With the fast develop-ment of range sensors (Kinect, RealSense), many scene mapping approaches [23, 29, 11, 15] are developed to em-*Joint first authors
†Corresponding authors power scene traversal by human operators with handheld sen-sors, yet incomplete or unaligned scene meshes are common flaws for inexperienced users due to the noisy and unstable scanned trajectory. To alleviate the inconvenience of human-operated traversal, there emerges autonomous map construc-tion [46, 17, 24, 32] via active sensor movement, also known as active mapping. Previous works in this field mainly focus on using a single robot, which is time-consuming for large-scale environments. In this paper, we study the problem of multi-robot active mapping: coordinating multiple robots for the autonomous reconstruction of unknown scenes.
The goal of active mapping is mainly twofold: time effi-ciency, and map completeness. The pioneering work for ac-tive mapping [46] introduces the concept of frontier: regions on the boundary between open space and unexplored space.
By continuously moving the robot to new frontiers, the scene map can be completely constructed when no frontier can be found. Many follow-up approaches in the following decades
[6, 16, 31] aim to improve the time efficiency of the process.
However, the problem of active mapping is highly ambigu-ous, which makes a theoretically-optimal solution almost impossible to be found in an unknown environment.
The key module of active mapping that influences time ef-ficiency is the global planner that estimates the goal position for path planning. The vast majority of literature for both single robot [3, 37, 39, 1] and multiple robots [4, 30, 14, 16] are frontier-based, which decides the goal position from a set of frontiers. However, these approaches are mostly myopic
[6] and hence hinder the time efficiency, since they either handcraft heuristics [46, 17, 21] to choose the frontier in the shortest geodesic distance to the robot, or find the one that maximizes the information gain over the next few actions via information-theoretic optimization [37, 1]. The more re-cent approaches adopt the reinforcement learning strategies
[13, 8, 31] as a replacement of the traditional approaches to decide the goal position for single robot. These policy learning approaches have dominated the active mapping field lately, thanks to their potential to achieve more efficient solu-tions by maximizing the long-term value [22, 25]. However, as their goal positions are mostly regressed and may not lay on the frontiers, it has no guarantee to construct the complete map [13, 8]. When the setting of active mapping is extended to the multi-robot scenario, the action space is linearly in-creased with the robot number, which makes the problem even more ambiguous. The past multi-robot approaches
[4, 30, 14, 16, 18] are mostly frontier-based myopic solu-tions and are still limited in time efficiency.
In this paper, we propose a novel multi-robot active map-ping approach that takes advantage of both the traditional frontier-based and recent reinforcement learning solutions for more efficient and complete map construction. To be specific, we coordinate multiple robots to decide the goal positions from a set of frontiers according to the neural distance optimized by maximizing the long-term value via reinforcement learning. To achieve this goal, we reduce the multi-robot active mapping problem to bipartite graph matching, which establishes node correspondences between two graphs, denoting robots and frontiers separately. The key issue for bipartite graph matching lies in the computa-tion of the affinity matrix between two sets of nodes. The traditional frontier-based approaches can be considered as handcrafting the affinity matrix with the geodesic distance between robots and frontiers, which limits the time efficiency of active mapping. In our algorithm, we propose to learn the neural distance with a multiplex graph neural network (mGNN) to estimate the affinity matrix for graph matching.
The problem of graph matching is NP-hard in nature [5] and often formulated as quadratic assignment programming, which is expensive and complex to solve. Many recent works relax graph matching as a linear assignment problem [42], which can be efficiently tackled with a differentiable and approximate solution [36]. Therefore, we optimize the graph neural network with the differentiable linear assignment by maximizing the long-term value that favors high time effi-ciency and map completeness via reinforcement learning.
Our algorithm is trained with only 9 indoor scenes, and exhibits exceptional generalization ability to various indoor scene datasets and unseen number of robots. The experimen-tal results demonstrate the superiority of our algorithm over state-of-the-art multi-robot active mapping approaches and a couple of adapted reinforcement-learning baselines.
All in all, our contributions can be summarized as follows:
• We reduce the multi-robot active mapping problem to bipartite graph matching, which is solved by a novel multi-robot active mapping algorithm that takes advan-tage of both the traditional frontier-based and recent reinforcement learning approaches.
• Our algorithm employs a multiplex graph neural net-work to estimate the affinity matrix, followed by a linear assignment layer for graph matching. The entire pro-cess is optimized by maximizing the long-term value via reinforcement learning.
• While achieving the complete map construction, our algorithm outperforms the existing multi-robot active mapping approaches over time efficiency by a large margin, and demonstrates exceptional generalization ability to unseen robot numbers. 2.