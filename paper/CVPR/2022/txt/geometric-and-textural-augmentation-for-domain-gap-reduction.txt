Abstract
Research has shown that convolutional neural networks for object recognition are vulnerable to changes in depiction because learning is biased towards the low-level statistics of texture patches. Recent works concentrate on improving robustness by applying style transfer to training examples to mitigate against over-fitting to one depiction style. These new approaches improve performance, but they ignore the geometric variations in object shape that real art exhibits: artists deform and warp objects for artistic effect. Motivated by this observation, we propose a method to reduce bias by jointly increasing the texture and geometry diversities of the training data. In effect, we extend the visual object class to include examples with shape changes that artists use. Specifically, we learn the distribution of warps that cover each given object class. Together with augmenting textures based on a broad distribution of styles, we show by experiments that our method improves performance on several cross-domain benchmarks. 1.

Introduction
Recognising objects is a well-researched area of visual computing, with performance rates exceeding 90%. More exactly, state-of-the-art performance is attained for photographic style inputs, performance falls significantly when artwork is input. Consequently, object recognition regardless of depiction remains a significant open problem. Not only is this an interesting in-principle problem, but is one which if solved would support many applications that currently are out of reach, indexing digital collections in art galleries is an obvious example. Less obvious applications we have come across include curating large multi-media databases, building interactive interfaces for professional artists, and IP protection.
The so-called “cross depiction” problem is that all classifiers (trained on photographs) show a fall in performance when given art work – this has been observed for some time [24]. One expla-nation is that most learning algorithms assume that the training (e.g., photographs) and test sets (e.g., art work) have very dif-ferent low-level statistics. Furthermore, various types of built-in bias (e.g., selection bias, capture bias, and negative set bias) are ubiquitous in existing datasets [34,71]. Several studies [7,39,82] have investigated the similarities and differences between neural networks and human perception. Researchers [19, 62] found the human visual system generalizes robustly across depictions, whereas neural networks are vulnerable to depiction shifts.
Some research considers the problem as one of domain gen-eralization (DG), with each depiction style being a different domain [23, 41, 52]. However, it has been established that the distance between the two images in the same object class but dif-ferent styles tends to be larger than two images in the same style but different objects [24] – sufficiently large to frustrate many general DG approaches. Additionally, photographs and artworks of objects do not appear in equal abundance. As a result, moving from training data comprising almost exclusively of photographs to test sets containing artwork is a significant challenge.
In response to such problems, recent literature has made use of style transfer to widen visual object classes so that different depiction domains are included [18]. The underlying idea is that because the input texture varies, the network is forced to learn object-class models that are not biased towards the low-level statistics of any texture class (e.g., photo, line drawing, etc.), rather they should rely more on characteristics such as shape [27, 46].
Using style transfer as a way to avoid depiction bias has met with some success – performance levels are raised [18, 46, 55].
However, texture is not the only aspect of object appearance that artists change: artists also warp and deform the objects they render. This so-called “geometric style” has started to influence the style transfer literature [37, 49], and has been shown to have a significant impact on subjective judgments regarding style similarity [49]. In other words, people notice that the geometry of objects in artwork differs from the geometry of objects in photographs.
Contributions: First, we bridge the depiction-domain gap in terms of both geometric and texture style, rather than tex-ture alone. The underlying idea is inspired from the literature (see