Abstract
As a popular geometric representation, point clouds have attracted much attention in 3D vision, leading to many applications in autonomous driving and robotics. One im-portant yet unsolved issue for learning on point cloud is that point clouds of the same object can have significant ge-ometric variations if generated using different procedures or captured using different sensors. These inconsistencies induce domain gaps such that neural networks trained on one domain may fail to generalize on others. A typical tech-nique to reduce the domain gap is to perform adversarial training so that point clouds in the feature space can align.
However, adversarial training is easy to fall into degener-ated local minima, resulting in negative adaptation gains.
Here we propose a simple yet effective method for unsuper-vised domain adaptation on point clouds by employing a self-supervised task of learning geometry-aware implicits, which plays two critical roles in one shot. First, the geo-metric information in the point clouds is preserved through the implicit representations for downstream tasks. More im-portantly, the domain-specific variations can be effectively learned away in the implicit space. We also propose an adaptive strategy to compute unsigned distance fields for arbitrary point clouds due to the lack of shape models in practice. When combined with a task loss, the proposed outperforms state-of-the-art unsupervised domain adapta-tion methods that rely on adversarial domain alignment and more complicated self-supervised tasks. Our method is evaluated on both PointDA-10 and GraspNet datasets.
Code and data are available at: https://github. com/Jhonve/ImplicitPCDA. 1.

Introduction
Point clouds captured under different settings can exhibit prominent variations that cause performance drop when neural networks are tested on a domain that is different from the training ones. This can be troublesome if the net-‡The authors from Zhejiang University are affiliated with the State Key
Lab of CAD&CG. ∗Equal Contributions, †Corresponding Authors.
Figure 1. Point clouds in the real world exhibit diverse geomet-ric variations caused by differences in the data capture pipeline.
Given these variations, networks trained on one collection of point clouds may incur a performance drop when tested on different ones. Thus adaptation is needed to alleviate generalization issues, especially for domains where the annotation is scarce. work can not be fine-tuned due to time constraints or lim-ited computational budget. More often, labels needed for fine-tuning on the test domain are simply unavailable due to high annotation cost, which is the situation we are in-terested in and is always formulated as unsupervised do-main adaptation (UDA) problems. In UDA, the source do-main comes with rich annotations, while the target domain has no annotation at all. The key to a successful domain adaptation lies in two folds. First, the two domains have to be (statistically) aligned, either in the point cloud space or in a feature space, so that the shared mapping to the out-put space can now operate on the same ground across do-mains. Moreover, the alignment between domains has to be semantically meaningful, e.g., chairs in the source should be aligned with chairs in the target. Otherwise, the shared mapping can still fail in predicting the labels even if the two domains are aligned.
Existing UDA methods on point clouds mainly rely on two mechanisms to align the domains. One is to per-form domain adversarial training and enforce the features of point clouds from both domains to be indistinguishable by domain discriminators. Since adversarial training is unsta-ble and easy to get stuck at degenerated local minimas, there is little guarantee that the alignment would be semantically meaningful. For example, adversarial training could distort the geometric information in the point clouds by eliminat-ing too many variations while aligning the domains. In this case, the alignment can result in negative adaptation gains.
An extra layer of difficulty is that the alignment process could be highly sensitive to the architecture of the discrim-inators for point clouds as shown in [32], thus making the alignment more uncontrollable.
The other mechanism is to perform domain alignment through learning self-supervised tasks. The underlying mo-tivation is that a well-designed self-supervised task can fa-cilitate learning domain invariant features since the task it-self is shared across domains. A diverse set of carefully de-signed self-supervised tasks are proposed, which focus on predictive tasks where the self-supervised labels are gener-ated by augmenting or modifying the original point clouds.
For instance, rotation angle classification [40] and deforma-tion regression [1]. Compared to domain adversarial train-ing, self-supervised learning enables explicit control over the invariants been learned by adjusting the self-supervised tasks. Consequently, one can also regularize the alignment process through this knob.
We take the latter approach, but we resort to a self-supervised task where the supervision comes from the point clouds themselves, instead of manually designed classifica-tion labels. Specifically, we ask for a latent space that en-codes the underlying geometry of the point clouds through implicit functions. As the geometry is explicitly modeled and preserved, these latents or implicits should maintain sufficient information for the main task and help prevent mismatch in semantics caused by distortions during the alignment. Due to the lack of shape models, we propose an adaptive unsigned distance field that enables training the implicits for arbitrary point clouds, especially for the ones that are sparse and irregularly sampled. After the initial round of adaptation, we follow the literature and apply self-training with pseudo labels in the target domain to further close the gap. We experiment on two major point cloud datasets, PointDA-10 [22] and GraspNet [9], to report the performance of the proposed method and evaluate the ef-fectiveness of each component. Our contributions are:
• The first method leverages implicit function learn-ing as a self-supervised task for unsupervised domain adaptation on point clouds.
• Effective training strategies to make our method robust to diverse artifacts exhibited in the point clouds.
• State-of-the-art performance on two major datasets,
PointDA-10 [22] and GraspNet [9]. Moreover, we are the first to report results on GraspNet. 2.