Abstract
Image noise modeling is a long-standing problem with many applications in computer vision. Early attempts that propose simple models, such as signal-independent addi-tive white Gaussian noise or the heteroscedastic Gaussian noise model (a.k.a., camera noise level function) are not suf-ficient to learn the complex behavior of the camera sensor noise. Recently, more complex learning-based models have been proposed that yield better results in noise synthesis and downstream tasks, such as denoising. However, their dependence on supervised data (i.e., paired clean images) is a limiting factor given the challenges in producing ground-truth images. This paper proposes a framework for training a noise model and a denoiser simultaneously while relying only on pairs of noisy images rather than noisy/clean paired image data. We apply this framework to the training of the
Noise Flow architecture. The noise synthesis and density es-timation results show that our framework outperforms pre-vious signal-processing-based noise models and is on par with its supervised counterpart. The trained denoiser is also shown to significantly improve upon both supervised and weakly supervised baseline denoising approaches. The results indicate that the joint training of a denoiser and a noise model yields significant improvements in the denoiser. 1.

Introduction
Image noise modeling is a long-standing problem in computer vision that has relevance for many applications
[6, 9, 10, 21, 22, 29]. Recently, data-driven noise mod-els based on deep learning have been proposed [2, 12, 23].
Unfortunately, these models generally require clean (i.e., noise-free) images, which are practically challenging to col-lect in real scenarios [1]. In this work we propose a new ap-proach, Noise2NoiseFlow, which can accurately learn noise models without the need for clean images.
Instead, only pairs of noisy images of a fixed scene are required.
While efforts are made to reduce noise during cap-ture, post-capture modeling is a critical piece of many
*Work performed while interns at the Samsung AI Center–Toronto.
Figure 1. Overview of Noise2NoiseFlow. (top) Given pairs of noisy images of the same scene, Noise2NoiseFlow simultaneouly trains both a noise model and a denoiser. (middle) Noise synthe-sis results from Camera NLF, Noise Flow, and Noise2NoiseFlow compared to the real noise in the SIDD dataset. Noise generated by Noise2NoiseFlow is the most similar to the real noise both vi-sually and in KL divergence but without requiring clean, noise-free images. (bottom) Example denoising results from the jointly trained denoiser compared to its supervised DnCNN baseline, and a DnCNN trained with Noise2Noise loss. downstream tasks and in many domains large amounts of noise are intrinsic to the problem—for example, astro-photography and medical imaging. As a result, noise is an integral and significant part of signal capture in many imaging domains, and modeling it accurately is critical. For instance, noise model estimation is necessary for remov-ing fixed pattern effects from CMOS sensors [11] and en-hancing video in extreme low-light conditions [32]. Noise
models can also be used to train downstream tasks to be ro-bust in the presence of realistic input noise. Most naturally, they can also be used to train noise reduction algorithms without the need to collect pairs of clean and noisy images
[2, 26, 38]. However, as mentioned in [3, 31, 39] denoisers trained with unrealistic noise models—for example, simple
Gaussian noise—may not perform well on real data.
Early attempts at noise modeling were limited and failed to fully capture the characteristics of real noise. Sim-ple IID Gaussian noise (also called a homoscedastic Gaus-sian noise) ignores the fact that photon noise is signal-dependent. Heteroscedastic Gaussian noise (e.g., [9]) cap-tures this by modeling noise variance as a linear function of clean image intensity but does not take into account the spatial non-uniformity of noise power, amplification noise, quantization effects, and more. More recently, Noise Flow
[2] was proposed as a new parametric structure that uses conditional normalizing flows to model noise in the camera imaging pipeline. This model is a combination of uncon-ditional and conditional transformations that map simple
Gaussian noise into a more complex, signal-, camera-, and
ISO-dependent noise distribution and outperformed previ-ous baselines by a large margin in the normalizing flows
[17] framework. However, it required supervised noise data—namely, pairs of clean and noisy images—in order to learn the noise model. Unfortunately gathering super-vised data consisting of corresponding clean and noisy im-ages can be challenging [1, 3, 28, 34] and is a limiting factor in the realistic characterization of noise. This is even worse for other downstream tasks, which typically require large amounts of data for training.
In the context of image denoising specifically, there has been significant recent interest in methods that avoid the need for supervised data, either from careful collection or synthesis. The well-known BM3D method [8] proposed a denoising scheme based on transform domain represen-tation without clean image correspondence. However, the similar patch search step makes the inference time complex-ity inefficient for large-scale datasets. Recently, Lehtinen et al. [20] introduced the Noise2Noise framework, which allowed for training of a denoiser given pairs of noisy im-ages of the same underlying image signal. Following this work, several others were proposed aiming to further re-duce the data requirements; in particular Noise2Void [18] and Noise2Self [4] allow training of a denoiser with only individual noisy images by forcing the denoiser to predict the intensity of each pixel using only its neighbours. Other methods attempted to add additional noise to noisy input images [25, 27, 35] or use unpaired images in a GAN frame-work [5, 7, 13–15]. However, in all cases these methods are aimed primarily at denoising instead of noise modeling.
In this work, we aim to leverage these recent advances in training denoisers without direct supervision in the context of noise modeling. Specifically, we extend the Noise2Noise framework to train a noise model with pairs of indepen-dently sampled noisy images rather than clean data. The resulting approach, called Noise2NoiseFlow and illustrated in Figure 1, produces both a denoiser and an explicit noise model, both of which are competitive with or out-perform fully supervised training of either model individually. 2.