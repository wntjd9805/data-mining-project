Abstract
Transformers trained with self-supervision using self-distillation loss (DINO) have been shown to produce atten-tion maps that highlight salient foreground objects. In this paper, we show a graph-based method that uses the self-supervised transformer features to discover an object from an image. Visual tokens are viewed as nodes in a weighted graph with edges representing a connectivity score based on the similarity of tokens. Foreground objects can then be seg-mented using a normalized graph-cut to group self-similar regions. We solve the graph-cut problem using spectral clustering with generalized eigen-decomposition and show that the second smallest eigenvector provides a cutting so-lution since its absolute value indicates the likelihood that a token belongs to a foreground object.
Despite its simplicity, this approach significantly boosts the performance of unsupervised object discovery: we im-prove over the recent state-of-the-art LOST by a mar-gin of 6.9%, 8.1%, and 8.1% respectively on the VOC07,
VOC12, and COCO20K. The performance can be further improved by adding a second stage class-agnostic detec-tor (CAD). Our proposed method can be easily extended to unsupervised saliency detection and weakly supervised ob-ject detection. For unsupervised saliency detection, we im-prove IoU for 4.9%, 5.2%, 12.9% on ECSSD, DUTS, DUT-OMRON respectively compared to state-of-the-art. For weakly supervised object detection, we achieve competitive performance on CUB and ImageNet. Our code is available at: https://www.m-psi.fr/Papers/TokenCut2022/ 1.

Introduction
Object detection is a key enabling technology for real-world vision systems for tasks such as robotics, autonomous driving, traffic monitoring, manufacturing, and embodied artificial intelligence [21, 63, 64]. However, the perfor-*Corresponding Author (a) DINO [6] (b) LOST [45]. (c) TokenCut (ours) (d) Attention maps associated to different patches
Figure 1. The attention map of the class token used in
DINO [6] (a) and the map of the inverse degrees used in
LOST [45] (b) are noisy for foreground / background sepa-ration. Our proposed method provides a clean attention map that can be used to segment salient objects (c). Considering the attention map associated to different patches highlight different regions of the object (d), it is reasonable to build a graph computing attention maps from multiple patches. mance of current state-of-the-art object detectors is limited by the high cost of annotating sufficient training data [33] for supervised learning. This limitation becomes even more apparent when using transfer learning to adapt a pre-trained object detector to a new application domain. Approaches such as active learning [1], semi-supervised learning [34], and weakly-supervised learning [39] have attempted to overcome this barrier by providing more efficient learning, but with only limited success.
In this work, we focus on object discovery in natural images with no human annotations. This is an important
problem and a critical step for many downstream applica-tions [56]. Poor object discovery can lead to poor over-all system performance. Current approaches for this prob-lem adopt some forms of bounding box proposal mecha-nism [11, 55, 56, 61] and formulate object discovery as an optimization problem. However, this approach can be com-putationally expensive [55] as each pair of bounding box proposals across different images needs to be compared, and the optimization may fail to scale to larger datasets due to the quadratic computation overhead [57].
Transformers have recently been shown to outperform convolutional neural networks for visual recognition. Vi-sion Transformers, such as ViT [18] accept image patches as input tokens and use stacked layers of encoders with self-attention to map tokens to image-level class labels. Re-cent results with DINO [6] have shown that when trained with self-distillation loss [25], the attention maps associ-ated to the class token from the last layer indicate salient foreground regions. However, as illustrated in Fig. 1a, such attention maps are noisy and it is not clear that they can be used for unsupervised object discovery.
With LOST [45], the authors propose construction of a graph and use the inverse degrees of nodes to segment ob-jects. A heuristic seed expansion strategy is used to over-come noise (Fig. 1b) and detect a single bounding box for a foreground object. The attention maps associated with dif-ferent nodes often contain meaningful information, as illus-trated in Fig. 1d. We have investigated whether it is possible to use the information in the entire graph by projecting the graph into a low dimensional subspace using eigendecom-position. We have discovered that such a projection can be used with Normalized Cut [43] (Ncut) to significantly im-prove foreground / background segmentation (Fig. 1c).
In this paper, we propose TokenCut, a simple but ef-fective graph-based approach for unsupervised object dis-covery. We build on the self-supervised vision transformer trained with DINO [6] as our backbone feature encoder and
Instead of us-locate objects with the resulting features. ing only the class token, we use all token features. We construct an undirected graph based on the token features in the last self-attention layer, where the visual tokens are viewed as graph nodes with edges representing a connec-tivity score based on similarity of the features. We then use a normalized graph-cut to group self-similar regions and delimit the foreground objects. We solve the graph-cut problem using spectral clustering with generalized eigen-decomposition and show that the second smallest eigenvec-tor provides a cutting solution indicating the likelihood that a token belongs to a foreground object. Our approach can be considered as a run-time adaptation, which means that the model is able to adapt to each specific test image despite the shared training model.
Despite its simplicity, our approach significantly im-The method proves unsupervised object discovery. achieves 68.8%, 72.1% and 58.8% on VOC07 [19],
VOC12 [20], COCO20K [33] respectively, thus outper-forming LOST [45] by a margin of 6.9%, 8.1% and 8.1% respectively. TokenCut with second stage CAD further im-proves the performance to 71.4%, 75.3% and 62.6% on
VOC07, VOC12, COCO20k respectively, which outper-forms LOST + CAD by 5.7%, 4.9% and 5.1% respectively.
In addition, we show that TokenCut can be easily ex-tended to weakly supervised object detection and unsuper-vised saliency detection. For weakly supervised object de-tection, the goal is to detect objects using only image-level annotations. We freeze the encoder and fine-tune a linear classifier with weakly-supervised image labels. We then ap-ply TokenCut on the features extracted from the fine-tuned encoder. Our approach produces clearly improved results on the CUB dataset [59] and competitive performance on
ImageNet-1K [14]. For unsupervised saliency detection, we use the foreground region discovered by the proposed ap-proach and apply Bilateral Solver [5] as a post-processing step to refine edges of the foreground region. In terms of results, our approach significantly improves previous state-of-the-art methods on ECSSD [44], DUTS [60] and DUT-OMRON [66].
In summary, our main contributions are as follows:
• We propose a simple and effective method to discover objects in images without supervision based on the self-supervised vision transformers. This method signifi-cantly outperforms previous state-of-the-art methods for unsupervised object discovery when tested on multiple datasets;
• We extend the proposed method to weakly-supervised object detection and show that the simple approach can achieve competitive performance;
• We also show that this method can be used for unsuper-vised saliency detection. The results demonstrate that To-kenCut significantly improves the previous state-of-the-art performance on multiple datasets. 2.