Abstract
Federated learning (FL) is a promising strategy for per-forming privacy-preserving, distributed learning with a net-work of clients (i.e., edge devices). However, the data dis-tribution among clients is often non-IID in nature, making efﬁcient optimization difﬁcult. To alleviate this issue, many
FL algorithms focus on mitigating the effects of data hetero-geneity across clients by introducing a variety of proximal terms, some incurring considerable compute and/or mem-ory overheads, to restrain local updates with respect to the global model. Instead, we consider rethinking solutions to data heterogeneity in FL with a focus on local learning gen-erality rather than proximal restriction. To this end, we ﬁrst present a systematic study informed by second-order indi-cators to better understand algorithm effectiveness in FL.
Interestingly, we ﬁnd that standard regularization methods are surprisingly strong performers in mitigating data het-erogeneity effects. Based on our ﬁndings, we further pro-pose a simple and effective method, FedAlign, to overcome data heterogeneity and the pitfalls of previous methods.
FedAlign achieves competitive accuracy with state-of-the-art FL methods across a variety of settings while minimiz-ing computation and memory overhead. Code is available at https://github.com/mmendiet/FedAlign. 1.

Introduction
Federated learning (FL) [17] enables a large number of clients to perform collaborative training of machine learn-ing models without compromising data privacy. In the FL setting, participating clients are typically deployed in a va-riety of environments or owned by a diverse set of users.
Therefore, the distribution of each client’s local data can vary considerably (i.e., data heterogeneity). This non-IID data distribution among participating devices in FL makes optimization particularly challenging. As each client trains locally on their own data, they step towards their respec-tive local minimum. However, this local convergence point may not be well aligned with the objective of the global model (that is, the model being learned though aggrega-tion at the central server). Therefore, the client model of-ten drifts away from the ideal global optimization point and overﬁts to its local objective. When such client drifting oc-curs, the performance of the central aggregated model is hindered [9, 14].
One straight-forward solution to this phenomenon is to simply limit the number of local training epochs performed between central aggregation steps. However, this severely hinders the convergence speed of the FL system, and many communication rounds are required to achieve adequate performance. The time to convergence and immense com-munication overhead incurred by such an approach are often not tolerable for real-world distributed systems. Therefore, effectively addressing data heterogeneity is of paramount concern in federated learning.
Many algorithmic solutions to this problem have been proposed in the literature [1, 10, 15, 23]. These strategies typically focus on mitigating the effects of data heterogene-ity across clients by introducing a variety of proximal terms to restrain local updates with respect to the global model.
However, by restraining the drift, they also inherently limit the local convergence potential; less novel information is gathered per communication round. Consequently, many current FL algorithms do not provide stable performance improvements across different non-IID settings in compar-ison to classic baselines [14, 15], especially on vision tasks beyond the difﬁculty of MNIST [13]. Furthermore, existing methods have paid little attention to the resource constraints of the client, typically scarce for deployed FL edge de-vices, and in some cases incur considerable compute and/or memory overheads on the client in their effort to allevi-ate client drift. For example, the state-of-the-art (SOTA) method MOON performs well on federated image tasks, but to do so incurs a ∼3x overhead in both memory and com-pute compared to the standard FedAvg baseline [17].
Motivation. In the centralized training paradigm, net-work generalization capability has been well studied to combat overﬁtting. Even in standard settings where the training and test data are drawn from a similar distribu-tion, models still overﬁt on the training data if no precau-tions are taken. This effect is further intensiﬁed when the training and test data are of different distributions. Various regularization techniques are introduced to enforce learning generality during training and preserve suitable test perfor-mance. Similarly, overﬁtting to the local training data of each device in FL is detrimental to overall network perfor-mance, as the client drifting effect creates conﬂicting ob-jectives among local models. Thus, a focus on improving model generality should be of primary concern in the pres-ence of data heterogeneity. Improving local learning gener-ality during training would inherently position the objective of the clients closer to the overall global objective. How-ever, despite its intuitive motivations, this perspective has been overlooked by the bulk of current FL literature.
Therefore, in this paper, we propose rethinking ap-proaches to data heterogeneity in terms of local learning generality rather than proximal restriction. Speciﬁcally, we carefully analyze the effectiveness of various data and structural regularization methods at reducing client drift and improving FL performance (Section 3). Utilizing second-order information and insights from out-of-distribution gen-erality literature [19, 21], we identify theoretical indicators for successful FL optimization, and evaluate across a vari-ety of FL settings for empirical validation.
Although some of the regularization methods perform well at mitigating client drift, signiﬁcant resource over-heads are still incurred to achieve the best performance (see
Section 4). Therefore, we propose FedAlign, a distillation-based regularization method that promotes local learning generality while maintaining excellent resource efﬁciency.
Speciﬁcally, FedAlign focuses on regularizing the Lipschitz constants of the ﬁnal block in a network with respect to its representations. By focusing solely on the last block, we effectively regularize the portion of the network most prone to overﬁtting and keep additional resource needs to a min-imum. Therefore, FedAlign achieves state-of-the-art accu-racy on multiple datasets across a variety of FL settings, while requiring signiﬁcantly less computation and memory overhead in comparison to other state-of-the-art methods.
Our contributions are as follows:
• We approach one of the most troublesome FL challenges (i.e. client drift caused by data heterogeneity) from a unique angle than any other previous work. We do not focus on reparameterization tricks to maintain closeness to the central model, or adjust the aggregation scheme to mitigate the effects of non-IID data distributions. Rather, we propose the rethinking of this problem from funda-mental machine learning training principles. In this way, we analyze the performance of standard regularization methods on FL and their effectiveness against data het-erogeneity.
• Not only do we empirically analyze the performance of regularization methods in FL, we also propose to take a deeper look. Speciﬁcally, we inform our analysis with theoretical indicators of learning generality to provide insight into which methods are best and why. We ﬁnd that Hessian eigenvalue/trace measurements and Hessian matching across clients to be meaningful indicators for optimal FL methods. Additionally, we perform a thor-ough ablation study across a variety of FL settings to un-derstand the empirical effects of different methods. Our aim is to provide this valuable knowledge to the FL com-munity to inspire new, productive research directions.
• Informed by our analysis and examining the pitfalls of previous methods, we propose FedAlign, which achieves competitive state-of-the-art accuracy while maintaining memory and computational efﬁciency. 2.