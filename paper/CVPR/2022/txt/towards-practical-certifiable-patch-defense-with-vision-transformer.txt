Abstract
Patch attacks, one of the most threatening forms of phys-ical attack in adversarial examples, can lead networks to induce misclassification by modifying pixels arbitrarily in a continuous region. Certifiable patch defense can guaran-tee robustness that the classifier is not affected by patch at-tacks. Existing certifiable patch defenses sacrifice the clean accuracy of classifiers and only obtain a low certified accu-racy on toy datasets. Furthermore, the clean and certified accuracy of these methods is still significantly lower than the accuracy of normal classification networks, which lim-its their application in practice. To move towards a prac-tical certifiable patch defense, we introduce Vision Trans-former (ViT) into the framework of Derandomized Smooth-ing (DS). Specifically, we propose a progressive smoothed image modeling task to train Vision Transformer, which can capture the more discriminable local context of an image while preserving the global semantic information. For effi-cient inference and deployment in the real world, we inno-vatively reconstruct the global self-attention structure of the original ViT into isolated band unit self-attention. On Ima-geNet, under 2% area patch attacks our method achieves 41.70% certified accuracy, a nearly 1-fold increase over the previous best method (26.00%). Simultaneously, our method achieves 78.58% clean accuracy, which is quite close to the normal ResNet-101 accuracy. Extensive exper-iments show that our method obtains state-of-the-art clean and certified accuracy with inferring efficiently on CIFAR-10 and ImageNet. 1.

Introduction
Despite achieving outstanding performance on various computer vision tasks [18, 19, 22–26, 28, 34, 41, 42, 44, 45], deep neural networks (DNNs) are vulnerable and susceptive to adversarial examples [11, 14, 15], which are attached to a perturbation on images by adversaries [33]. Patch attack is one of the most threatening forms of adversarial examples,
*indicates equal contributions.
†indicates corresponding author. which can modify pixels arbitrarily in a continuous region, and can implement physical attacks on autonomous systems via their perception component. For example, putting stick-ers on traffic signals can make the model misprediction [10].
While several practical patch defenses are proposed [12, 30], they only obtain robustness against known attacks but not against more powerful attacks that may be developed in the future [5,35]. Therefore, we focus on certifiable defense against patch attacks in this paper, which allows guaranteed robustness against all possible attacks for the given threat model. In recent years, this community has received great attention. For example, Chiang et al. propose the first cer-tifiable defense against patch attacks by extending interval bound propagation (IBP) [5] on CIFAR10. Then later work introduces small receptive fields or randomized smoothing to improve certification on CIFAR10 and scale to ImageNet.
However, the accuracy gap between certifiable patch de-fense and normal model limits the practical application of these defense methods. For example, PatchGuard [39] can achieve 84.7% clean accuracy and 57.7% certified accuracy under 4×4 patches on CIFAR10. However, when Patch-Guard [39] is extended to large-scale datasets, such as Ima-geNet, it can only obtain 54.6% clean accuracy and 26.0% certified accuracy under 2% patches, which is much lower than the normal ResNet-50 [13] (76.2%). Consequently, a breakthrough is needed urgently to narrow the gap and move towards practical certifiable patch defenses.
Recently, transformer [36] has achieved significant suc-cess in speech recognition and natural language processing.
Inspired by this, Vision Transformer (ViT) [9] has been pro-posed and obtain potential performance in computer vision, such as image classification [1, 9], objects detection [4] and semantic segmentation [1]. ViT models the context between different patches and obtains long-range dependencies by self-attention. Compared with convolutional neural net-works (CNNs), ViT has achieved promising performance, which has the potential to improve certification. Further-more, Derandomize smoothing (DS) [21] is a classic cer-tifiable patch defense based on randomized smoothing ro-bustness schemes and provides high confident certified ro-bustness by structured ablation. It can also be generalized to
other network architectures. Therefore, integrating ViT into
DS is a potential certifiable patch defense. However, direct replacing the CNN structure in DS with ViT leads to trivial results: (1) the accuracy is still lower than normal classifi-cation networks; (2) the excessive inference time limits the application of the method in practice.
To address these issues and move towards practical cer-tifiable patch defense, we propose an efficient certifiable patch defense with ViT to improve accuracy and inference efficiency. First, we introduce a progressive smoothed im-age modeling task to train ViT. Specifically, the training objective is to gradually recover the original image tokens based on the smoothed image bands. By gradually recon-structing, the base classifier can explicitly capture the local context of an image while preserving the global semantic information. Consequently, more discriminative local rep-resentations can be obtained through very limited image in-formation (a thin smoothed image band), which improves the performance of the base classifier. Then, we renovate the global self-attention structure of the original ViT into the isolated band-unit self-attention. The input image is divided into bands and the self-attention in each band-like unit is calculated separately, which provides the feasibility for the parallel calculation of multiple bands. Finally, our method achieves 78.58% clean accuracy on ImageNet and 41.70% certified accuracy within efficient inference under 2% area patch attacks. The clean accuracy is quite close to the normal ResNet-101 accuracy. Extensive experiments demonstrate that our method obtains state-of-the-art clean and certified accuracy with inferring efficiently on CIFAR-10 and ImageNet. Our major contributions are as follows:
• We introduce ViT into certifiable patch defense and propose a progressive smoothed image modeling task, which lets the model capture more discriminable lo-cal context of an image while preserving the global se-mantic information.
• We renovate the global self-attention structure of the
ViT into the isolated band-unit self-attention, which considerably accelerates inference.
• Experiments show that our method obtains state-of-the-art clean and certified accuracy with inferring ef-ficiently on CIFAR-10 and ImageNet. Additionally, our method achieves 78.58% clean accuracy on Ima-geNet and 41.70% certified accuracy in efficient infer-ence under 2% area patch attacks. The clean accuracy is quite close to the normal ResNet-101 accuracy. 2.