Abstract
Object detection under imperfect data receives great attention recently. Weakly supervised object detection (WSOD) suffers from severe localization issues due to the lack of instance-level annotation, while semi-supervised object detection (SSOD) remains challenging led by the inter-image discrepancy between labeled and unlabeled data.
In this study, we propose the Single Instance annotated Object Detection (SIOD), requiring only one instance annotation for each existing category in an image.
Degraded from inter-task (WSOD) or inter-image (SSOD) discrepancies to the intra-image discrepancy, SIOD pro-vides more reliable and rich prior knowledge for mining the rest of unlabeled instances and trades off the annota-tion cost and performance. Under the SIOD setting, we propose a simple yet effective framework, termed Dual-Mining (DMiner), which consists of a Similarity-based
Pseudo Label Generating module (SPLG) and a Pixel-level
Group Contrastive Learning module (PGCL). SPLG ﬁrstly mines latent instances from feature representation space to alleviate the annotation missing problem. To avoid being misled by inaccurate pseudo labels, we propose PGCL to boost the tolerance to false pseudo labels. Extensive experiments on MS COCO verify the feasibility of the SIOD setting and the superiority of the proposed method, which obtains consistent and signiﬁcant improvements compared to baseline methods and achieves comparable results with fully supervised object detection (FSOD) methods with only 40% instances annotated. Code is available at https:
//github.com/solicucu/SIOD. 1.

Introduction
With the boom of Convolutional Neural Network (CNN) and Vision Transformer [9, 16, 13, 23, 30, 33], object
*Work partially done during the Youtu Lab internship
†Corresponding author (a) WSOD (b) SSOD (c) SAOD (d) SIOD (Ours)
Figure 1. Different annotation setup for (a) WSOD, (b) SSOD, (c)
SAOD and (d) SIOD (Ours). detection [3, 5, 20, 22, 26, 27, 28, 50] has achieved great improvements with a large number of instance-level an-notations. However, these annotations are not only labor-intensive and time-consuming, but also prevent detectors from generalizing to most realistic scenarios where only few labeled data is available.
Weakly supervised object detection (WSOD), which requires only image-level labels for training, has received much attention in computer vision community. Although great advances [2, 19, 34, 29, 8] have been achieved in recent years, it still remains a huge performance gap be-tween WSOD and FSOD. WSOD suffers from severe local-ization issues due to the large discrepancy between image-level annotation and instance-level task. Semi-supervised object detection (SSOD) is an alternative few-label object detection task, where only a small number of instance-level annotations are available. SSOD methods [14, 15, 1, 35, 17, 49] obtain superior localization accuracy compared to
WSOD methods, but the inter-image discrepancy between labeled and unlabeled data limits further improvement by a large margin due to the lack of explicit inter-image communication in popular mini-batch optimization manner.
Sparsely annotated object detection (SAOD) is recently proposed, which annotates a part of instances in each image.
Speciﬁcally, SAOD methods [37, 43, 45] usually imitate sparse annotation by randomly erasing different proportion of annotations from completely annotated object detection
In this way, it’s inevitable that there are datasets [21]. not any annotations for all instances of some categories in an image, which leads to inter-image discrepancy as
SSOD. To this end, we propose a new task, termed as
Single Instance annotated Object Detection (SIOD), which annotates only one instance for each existing category in an image. Compared to WSOD, SSOD and SAOD, SIOD reduces the inter-task or inter-image discrepancies to intra-image discrepancy and trades off the annotating cost and performance. Fig. 1 illustrates the annotation details of
WSOD, SSOD, SAOD and the proposed SIOD.
Pseudo label-based methods are the most popular so-lution under the imperfect data and achieve impressive progress. However, pseudo labels generated by detector in the early training phase are usually inaccurate and make it difﬁcult for stable training. In this study, we propose a sim-ple yet effective framework under the SIOD setup, called
Dual-Mining (DMiner), which consists of a Similarity-based Pseudo Label Generating module (SPLG) and a
Pixel-level Group Contrastive Learning module (PGCL). In contrast to detector-based pseudo labels, the SPLG instead utilizes the feature similarity to mines latent instances, which is based on the ability of equi-variance of CNN.
We then propose the PGCL, which self-mines a group of positive pairs for each category for group contrastive learning, to boost the tolerance to false pseudo labels and minimize the distances between instances of same category in each image. COCO style evaluation protocol does not
ﬁlter the detected boxes with extremely low conﬁdence and thus results in illusory advances in object detection by recalling a large number of objects with low conﬁdence. We therefore introduce additional conﬁdence constraint to coco style evaluation metrics that a predicted box is determined as a true match only when it satisﬁes the speciﬁc IoU (Interaction Over Union) and conﬁdence threshold.
In summary, the contributions in this study include:
• Investigate the SIOD task, which provides more pos-sibility of the development of object detection with lower annotated cost.
• Propose the DMiner framework to mine unlabeled in-stances and boost the tolerance to false pseudo labels.
• Extensive experiments verify the superiority of SIOD and the proposed DMiner obtains consistent and sig-niﬁcant gains compared with baseline methods. 2.