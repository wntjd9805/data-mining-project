Abstract
Despite most existing anomaly detection studies assume the availability of normal training samples only, a few la-beled anomaly examples are often available in many real-world applications, such as defect samples identiﬁed during random quality inspection, lesion images conﬁrmed by radi-ologists in daily medical screening, etc. These anomaly ex-amples provide valuable knowledge about the application-speciﬁc abnormality, enabling signiﬁcantly improved detec-tion of similar anomalies in some recent models. However, those anomalies seen during training often do not illus-trate every possible class of anomaly, rendering these mod-els ineffective in generalizing to unseen anomaly classes.
This paper tackles open-set supervised anomaly detection, in which we learn detection models using the anomaly ex-amples with the objective to detect both seen anomalies (‘gray swans’) and unseen anomalies (‘black swans’). We propose a novel approach that learns disentangled repre-sentations of abnormalities illustrated by seen anomalies, pseudo anomalies, and latent residual anomalies (i.e., sam-ples that have unusual residuals compared to the normal data in a latent space), with the last two abnormalities de-signed to detect unseen anomalies. Extensive experiments on nine real-world anomaly detection datasets show supe-rior performance of our model in detecting seen and unseen anomalies under diverse settings. Code and data are avail-able at: https://github.com/choubo/DRA 1.

Introduction
Anomaly detection (AD) aims at identifying excep-tional samples that do not conform to expected patterns
[35]. It has broad applications in diverse domains, e.g., le-sion detection in medical image analysis [48, 56, 70], in-specting micro-cracks/defects in industrial inspection [3,4], crime/accident detection in video surveillance [11, 20, 51, 69], and unknown object detection in autonomous driv-ing [10, 55]. Most of existing anomaly detection methods
*Corresponding author: CS (e-mail: chunhua@me.com). This work was in part done when GP and CS were with The University of Adelaide.
†First two authors contributed equally.
Figure 1. t-SNE visualization of features learned by SotA unsu-pervised (KDAD [46]) and supervised (DevNet [34, 36]) models, and our open-set supervised model (DRA) on the test data of two
MVTec AD datasets, Leather and Tile. KDAD is trained with nor-mal data only, learning less discriminative features than DevNet and DRA that are trained using ten samples from the seen anomaly classes, in addition to the normal data. DevNet is prone to over-ﬁtting the seen anomalies, failing to distinguish unseen anomalies from the normal data, while DRA effectively mitigates this issue.
[2,8,11,13,32,38,38,41,43,45,46,48,57–59,68,73] are un-supervised, which assume the availability of normal train-ing samples only, i.e., anomaly-free training data, because it is difﬁcult, if not impossible, to collect large-scale anomaly data. However, a small number of (e.g., one to multiple) labeled anomaly examples are often available in many rel-evant real-world applications, such as some defect sam-ples identiﬁed during random quality inspection, lesion im-ages conﬁrmed by radiologists in daily medical screening, etc. These anomaly examples provide valuable knowledge about application-speciﬁc abnormality [29, 34, 36, 44], but the unsupervised detectors are unable to utilize them. Due to the lack of knowledge about anomalies, the learned fea-tures in unsupervised models are not discriminative enough to distinguish anomalies (especially some challenging ones) from normal data, as illustrated by the results of KDAD
[46], a recent state-of-the-art (SotA) unsupervised method, on two MVTec AD defect detection datasets [3] in Fig. 1.
In recent years, there have been some studies [29, 34, 36, 44] exploring a supervised detection paradigm that aims at exploiting those small, readily accessible anomaly data— rare but previously occurred exceptional cases/events, a.k.a.
gray swans [22] – to train anomaly-informed detection models. The current methods in this line focus on ﬁtting these anomaly examples using one-class metric learning with the anomalies as negative samples [29,44] or one-sided anomaly-focused deviation loss [34,36]. Despite the limited amount of the anomaly data, they achieve largely improved performance in detecting anomalies that are similar to the anomaly examples seen during training. However, these seen anomalies often do not illustrate every possible class of anomaly because i) anomalies per se are unknown and ii) the seen and unseen anomaly classes can differ largely from each other [35], e.g., the defective features of color stains are very different from that of folds and cuts in leather defect inspection. Consequently, these models can overﬁt the seen anomalies, failing to generalize to unseen/unknown anomaly classes—rare and previously unknown exceptional cases/events, a.k.a. black swans [54], as shown by the re-sult of DevNet [34, 36] in Fig. 1 where DevNet improves over KDAD in detecting the seen anomalies but fails to
In discriminate unseen anomalies from normal samples. fact, these supervised models can be biased by the given anomaly examples and become less effective in detecting unseen anomalies than unsupervised detectors (see DevNet vs. KDAD on the Tile dataset in Fig. 1).
To address this issue, this paper tackles open-set su-pervised anomaly detection, in which detection models are trained using the small anomaly examples in an open-set environment, i.e., the objective is to detect both seen anomalies (‘gray swans’) and unseen anomalies (‘black swans’). To this end, we propose a novel anomaly de-tection approach, termed DRA, that learns disentangled representations of abnormalities to enable the generalized detection. Particularly, we disentangle the unbounded ab-normalities into three general categories: anomalies similar to the limited seen anomalies, anomalies that are similar to pseudo anomalies created from data augmentation or exter-nal data sources, and unseen anomalies that are detectable in some latent residual-based composite feature spaces. We further devise a multi-head network, with separate heads enforced to learn each type of these three disentangled ab-normalities. In doing so, our model learns diversiﬁed ab-normality representations rather than only the known ab-normality, which can discriminate both seen and unseen anomalies from the normal data, as shown in Fig. 1.
In summary, we make the following main contributions:
• To tackle open-set supervised AD, we propose to learn disentangled representations of abnormalities il-lustrated by seen anomalies, pseudo anomalies, and latent residual-based anomalies. This learns diversi-ﬁed abnormality representations, extending the set of anomalies sought to both seen and unseen anomalies.
• We propose a novel multi-head neural network-based model DRA to learn the disentangled abnormality rep-resentations, with each head dedicated to capturing one speciﬁc type of abnormality.
• We further introduce a latent residual-based abnor-mality learning module that learns abnormality upon the residuals between the intermediate feature maps of normal and abnormal samples. This helps learn discriminative composite features for the detection of hard anomalies (e.g., unseen anomalies) that cannot be detected in the original non-composite feature space.
• We perform comprehensive experiments on nine real-application datasets from industrial inspection, rover-based planetary exploration and medical image analy-sis. The results show that our model substantially out-performs ﬁve SotA competing models in diverse set-tings. The results also establish new baselines for fu-ture work in this important emerging direction. 2.