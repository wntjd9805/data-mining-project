Abstract
The recently developed DEtection TRansformer (DETR) establishes a new object detection paradigm by eliminat-ing a series of hand-crafted components. However, DETR suffers from extremely slow convergence, which increases the training cost significantly. We observe that the slow convergence is largely attributed to the complication in matching object queries with target features in different fea-ture embedding spaces. This paper presents SAM-DETR, a Semantic-Aligned-Matching DETR that greatly acceler-ates DETR’s convergence without sacrificing its accuracy.
SAM-DETR addresses the convergence issue from two per-spectives. First, it projects object queries into the same em-bedding space as encoded image features, where the match-ing can be accomplished efficiently with aligned seman-tics. Second, it explicitly searches salient points with the most discriminative features for semantic-aligned match-ing, which further speeds up the convergence and boosts de-tection accuracy as well. Being like a plug and play, SAM-DETR complements existing convergence solutions well yet only introduces slight computational overhead. Extensive experiments show that the proposed SAM-DETR achieves superior convergence as well as competitive detection ac-curacy. The implementation codes are publicly available at https://github.com/ZhangGongjie/SAM-DETR . 1.

Introduction
Object detection is one of the most fundamental tasks in computer vision and has achieved unprecedented progress with the development of deep learning [27]. However, most object detectors often suffer from complex detection pipelines and sub-optimal performance due to their over-reliance on hand-crafted components such as anchors, rule-based target assignment, and non-maximum suppression (NMS). The recently proposed DEtection TRansformer (DETR) [3] removes the need for such hand-designed com-ponents and establishes a fully end-to-end framework for
* Corresponding author.
Figure 1. Convergence curves of our proposed SAM-DETR and other detectors on COCO val 2017 under the 12-epoch training scheme. All competing methods are single-scale. SAM-DETR converges much faster than the original DETR, and can work in complementary with existing convergence-boosting solutions, reaching a comparable convergence speed with Faster R-CNN. object detection. Despite its simple design and promising results, one of the most significant drawbacks of DETR is its extremely slow convergence on training, which requires 500 epochs to converge on the COCO benchmark [26], while
Faster R-CNN [35] only takes 12∼36 epochs instead. This slow convergence issue significantly increases the training cost and thus hinders its more comprehensive applications.
DETR employs a set of object queries in its decoder to detect target objects at different spatial locations. As shown in Fig. 2, in the cross-attention module, these object queries are trained with a set-based global loss to match the target objects and distill corresponding features from the matched regions for subsequent prediction. However, as pointed out in [10, 31, 63], each object query is almost equally matched to all spatial locations at initialization, thus
search multiple salient points and use them for semantic-aligned matching, which naturally fits in the DETR’s orig-inal multi-head attention mechanism. Our approach only introduces a plug-and-play module into the original DETR while leaving most other operations unchanged. Therefore, the proposed method can be easily integrated with existing convergence solutions in a complementary manner.
In summary, the contributions of this work are four-fold. First, we propose Semantic-Aligned-Matching DETR (SAM-DETR), which significantly accelerates DETR’s con-vergence by innovatively interpreting its cross-attention as a
‘matching and distillation’ process and semantically align-ing object queries with encoded image features to facilitate their matching. Second, we propose to explicitly search for objects’ salient points with the most discriminative features and feed them to the cross-attention module for semantic-aligned matching, which further boosts the detection accu-racy and speeds up the convergence of our model. Third, ex-periments validate that our proposed SAM-DETR achieves significantly faster convergence compared with the original
DETR. Fourth, as our approach only adds a plug-and-play module into the original DETR and leaves other operations mostly unchanged, the proposed SAM-DETR can be easily integrated with existing solutions that modify the attention mechanism to further improve DETR’s convergence, lead-ing to a comparable convergence speed with Faster R-CNN even within 12 training epochs. 2.