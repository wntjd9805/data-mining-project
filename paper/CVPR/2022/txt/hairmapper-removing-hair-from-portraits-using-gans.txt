Abstract
Removing hair from portrait images is challenging due to the complex occlusions between hair and face, as well as the lack of paired portrait data with/without hair. To this end, we present a dataset and a baseline method for removing hair from portrait images using generative adver-sarial networks (GANs). Our core idea is to train a fully connected network HairM apper to find the direction of hair removal in the latent space of StyleGAN for the train-ing stage. We develop a new separation boundary and dif-fuse method to generate paired training data for males, and a novel “female-male-bald” pipeline for paired data of fe-males. Experiments show that our method can naturally deal with portrait images with variations on gender, age, etc. We validate the superior performance of our method
*Corresponding author. by comparing it to state-of-the-art methods through exten-sive experiments and user studies. We also demonstrate its applications in hair design and 3D face reconstruction. 1.

Introduction
Hair is not only an important component of the human body, but also a key element of personality and fashion.
However, the presence of hair in a portrait image poses sig-nificant challenges for digital hair design and 3D face re-construction. Regarding hair design, a direct overlay of the new hair can easily cause problems due to mixing up with the old hair, while replacing the old hair with the new hair requires error-prone matting and inpainting techniques [38].
For 3D face reconstruction, most existing methods cannot handle the hair in front of the face and it remains in the texture [10, 23], resulting in noticeable artifacts of the re-constructed face (see Fig. 1f). This motivates us to develop a hair manipulation method that can naturally remove hair from portraits to facilitate such real applications.
Although image inpainting methods [24,25,39] can help to generate or edit facial structure, they only allow manip-ulating face semantic attributes at the image level. Thanks to the development of StyleGAN [19], the exploration in its latent space [3, 29, 31, 36, 37] enables editing facial seman-tics at the manifold level. However, none of these meth-ods is able to remove hair while preserving facial identity due to the following main challenges. First, a dataset of paired portraits with/without hair is not available. More-over, it is not easy to prepare such a dataset, especially for females. Second, besides the lack of ground truth of “bald woman”, synthetic portrait generation based on StyleGAN is infeasible as “bald woman” is an invalid semantic combi-nation. Third, hair removal is not a simple inpainting task, since the newly generated contents for the original hair re-gion should be compatible with the original face in terms of skin color, shadow effect, etc. However, extreme light con-ditions, shadows, and different hairstyles can easily cause imperfections given the variety of faces.
To address the above challenges, we present a novel method that can effectively remove hair from portraits while preserving original face semantics and portrait quality, even
In the for female portraits with long and complex hair.
StyleGAN latent space, hair removal is not a simple linear mapping problem. To find a specific hair manipulation path and avoid expensive data annotation, we design two differ-ent pipelines to generate paired latent codes with/without hair for males and females while keeping their facial iden-tities. The paired data with/without hair are used to train a fully connected network HairM apper to manipulate the latent code of a real portrait for hair removal during testing.
The final result is obtained by exploiting Poisson editing to blend the mapped portrait with the original portrait. The experiments demonstrate that our method results in high-quality portraits of different ages and gender groups. The user studies further show that our work can generate satis-factory outputs that accord with human preferences.
The major contributions of our paper are: 1) We intro-duce an automatic method to remove hair from real portrait images. It can generate a new portrait without hair while preserving facial identity. 2) We develop a novel “female-male-bald” pipeline to generate bald female data that does not exist in the StyleGAN latent space, and use a fully con-nected network to find the hair removal path in the latent space. 3) We create the first dataset that contains 6,000 high-quality portrait images with hair removed. 2.