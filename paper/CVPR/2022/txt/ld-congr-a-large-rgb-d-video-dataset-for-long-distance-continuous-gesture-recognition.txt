Abstract
Gesture recognition plays an important role in natural human-computer interaction and sign language recogni-tion. Existing research on gesture recognition is limited to close-range interaction such as vehicle gesture control and face-to-face communication. To apply gesture recog-nition to long-distance interactive scenes such as meetings and smart homes, a large RGB-D video dataset LD-ConGR is established in this paper. LD-ConGR is distinguished from existing gesture datasets by its long-distance gesture collection, fine-grained annotations, and high video qual-ity. Specifically, 1) the farthest gesture provided by the
LD-ConGR is captured 4m away from the camera while existing gesture datasets collect gestures within 1m from the camera; 2) besides the gesture category, the temporal segmentation of gestures and hand location are also anno-tated in LD-ConGR; 3) videos are captured at high reso-lution (1280 × 720 for color streams and 640 × 576 for depth streams) and high frame rate (30 fps). On top of the
LD-ConGR, a series of experimental and studies are con-ducted, and the proposed gesture region estimation and key frame sampling strategies are demonstrated to be effective in dealing with long-distance gesture recognition and the uncertainty of gesture duration. The dataset and experimen-tal results presented in this paper are expected to boost the research of long-distance gesture recognition. The dataset is available at https://github.com/Diananini/
LD-ConGR-CVPR2022. 1.

Introduction
Gesture is an important way of information transmis-sion. We use gestures to assist our language expression,
*Corresponding author (libo@iscas.ac.cn). This work was supported by the Key Research Program of Frontier Sciences, CAS, Grant No.
ZDBS-LY-JSC038. Libo Zhang was supported CAAI-Huawei MindSpore
Open Fund and Youth Innovation Promotion Association, CAS (2020111).
Figure 1. Example frames from gesture datasets. The upper left corner of each frame marks the dataset from which it is sampled.
The gestures in our dataset LD-ConGR are collected at long dis-tances and are more challenging to recognize. communicate with the deaf, direct traffic, and so on. Fur-thermore, gestures help us interact with machines more nat-urally and conveniently: 1) A simple gesture can replace multiple mouse and keyboard operations. 2) In scenes such as hospitals, conferences, and smart homes, people prefer touchless interaction methods such as gestures and voice. 3) Gesture interaction is more user-friendly and lowers the barrier to using smart devices. There are many datasets
[1, 12, 15, 21, 27] and related research [2, 3, 10, 16, 18, 28] for gesture recognition. These datasets focus on interaction with wearable devices (e.g., EgoGesture [27]), interaction with vehicles (e.g., NVIDIA Gesture [15]), sign language and symbolic gestures (e.g., ChaLearn ConGD [21]), or in-teraction with computers (e.g., Jester [12] and IPN Hand
[1]). As we can see, the existing datasets are all oriented to-wards close-range gesture interaction and collect gestures at a very close distance from the subjects. However, in many scenarios such as the meeting and home automation, users are far away from the machines to be controlled. More-over, limited by the early data acquisition sensors, the exist-ing datasets can not meet the high demand of long-distance gesture recognition for video quality.
In this paper, a large high-quality RGB-D video dataset
LD-ConGR is established for long-distance continuous gesture recognition. Firstly, LD-ConGR draws attention to long-distance gesture interaction. Unlike the existing datasets that record gestures within 1m from the camera, we capture gestures at long distances (between 1m and 4m).
Fig. 1 shows example frames sampled from different ges-ture datasets. It can be seen that the gestures in LD-ConGR are captured with a large field of view, and the hands are small and difficult to recognize, which poses a new chal-lenge for gesture recognition. Secondly, LD-ConGR pro-vides fine-grained annotations for continuous gesture recog-nition. Continuous gesture recognition requires not only to classify gestures but also to detect the specific duration of gestures in the video. In LD-ConGR, each video con-tains multiple gestures, and all gestures are manually la-beled with the categories and the start and end frames in the video. It should be noted that we also annotate the posi-tion of the hand in each frame, which provides researchers with more detailed information and brings more possibil-ities for accurate gesture recognition. Lastly, videos col-lected in LD-ConGR are of high quality. The Kinect V41, equipped with an advanced depth sensor, is used to col-lect high-quality RGB-D video data. The color and depth streams are captured synchronously at 30 fps with resolu-tions of 1280 × 720 and 640 × 570 respectively.
Based on the proposed LD-ConGR dataset, we con-ducted a series of experimental explorations. A baseline model based on 3D ResNeXt [23] is implemented and achieves 85.33% accuracy on RGB data. To make good use of the depth information, we learn from the ideas of [9] and build a multimodal gesture recognition model ResNeXt-MMTM. It achieves an accuracy of 89.66% on LD-ConGR.
To deal with long-distance gesture recognition, we estimate the possible appearing area of the gesture based on hand location and conduct recognition on the estimated gesture region. This strategy increases the accuracy by 9.33% and 7.67% on RGB data and RGB-D data, respectively. More-over, we observe the large difference in gesture duration brings great difficulties to recognition. In view of this, we try to extract key frames of the video based on inter-frame difference to remove redundant frames for long-duration gestures. Results show that the key frame sampling strategy reduces the impact of gesture speed and duration, and real-1https://azure.microsoft.com/en-us/services/kinect-dk izes high-speed and accurate recognition with fewer frames.
In summary, the main contributions of this paper are as follows: 1) We release a new large-scale RGB-D video dataset LD-ConGR. To the best of our knowledge, this is the first dataset for long-distance continuous gesture recog-nition. LD-ConGR is finely annotated with gesture cate-gory, temporal segmentation (the start and end frames of the gesture in the video), and hand position. The dataset will be available to the public. 2) The results of baseline methods and state-of-the-art gesture recognition methods on LD-ConGR are reported to provide references for sub-sequent research. 3) For the two main challenges raised by LD-ConGR: the long-distance recognition and the un-certainty of gesture duration, we explore possible solutions and provide more research directions. 2.