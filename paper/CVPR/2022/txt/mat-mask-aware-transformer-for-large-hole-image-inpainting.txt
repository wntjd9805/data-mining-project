Abstract
Recent studies have shown the importance of model-ing long-range interactions in the inpainting problem. To achieve this goal, existing approaches exploit either stan-dalone attention techniques or transformers, but usually under a low resolution in consideration of computational cost. In this paper, we present a novel transformer-based model for large hole inpainting, which unifies the merits of transformers and convolutions to efficiently process high-resolution images. We carefully design each component of our framework to guarantee the high fidelity and diversity of
*Corresponding author recovered images. Specifically, we customize an inpainting-oriented transformer block, where the attention module ag-gregates non-local information only from partial valid to-kens, indicated by a dynamic mask. Extensive experiments demonstrate the state-of-the-art performance of the new model on multiple benchmark datasets. Code is released at https://github.com/fenglinglwb/MAT. 1.

Introduction
Image completion (a.k.a. inpainting) is a fundamental problem in computer vision, which aims to fill missing re-gions with plausible contents. It has many applications in-cluding image editing [23], image re-targeting [9], photo
restoration [53, 54] and object removal [3].
In inpainting, modeling the contextual information is crucial, especially for large masks. Creating reasonable structures and textures for the missing areas demands con-textual understanding, using distant information according to non-local priors [4, 7, 38, 56] in images. Previous works employ stacked convolutions to reach large receptive fields and model long-range relationships, which works well on aligned (e.g., faces, bodies) and texture-heavy (e.g., forests, water) data. When processing images with complicated structures (i.e., the first example in the 2nd row in Figure 1), it is difficult for fully convolutional neural networks (CNNs) to characterize the semantic correspondences between dis-tant areas. This is mainly due to the inherent properties of
CNNs, the slow growth of the effective receptive field and the inevitable dominance of nearby pixels. To explicitly model long-range dependencies in inpainting, [61, 65, 66] propose to employ attention modules in the CNN-based generator. However, limited by the quadratic computational complexity, the attention module is merely applied to rel-atively small-scale feature maps with a few times, where long-range modeling is not fully exploited.
In contrast to applying attention modules to CNNs, trans-former [52] is a natural architecture to handle non-local modeling, where attention is a basic component in every block. Recent advances [55,68,77] adopt transformer struc-tures to address the inpainting problem. Nonetheless, af-fected by the complexity issue, existing works only em-ploy transformers to infer low-resolution predictions (e.g. 32 × 32) for subsequent processing, hence the produced im-age structure is coarse, compromising the final image qual-ity, especially on large-scale masks.
In this paper, we develop a new inpainting transformer, capable of generating high-resolution completed results for large mask inpainting. Due to the lack of useful infor-mation in some regions (this is common when the given mask rules out most pixels), we find the commonly uti-lized transformer block (LN→MSA→LN→FFN) exhibits inferior performance in adversarial training. In this regard, we customize the vanilla Transformer block to increase op-timization stability and also improve performance, by re-moving the conventional layer normalization [1] and re-placing the residual learning with fusion learning using fea-ture concatenation. We analyze why these modifications are crucial for learning and empirically demonstrate they are non-trivial. Also, to handle possible heavy interactions between all tokens extracted from the high-resolution in-put, we propose a new variant of multi-head self-attention (MSA), named multi-head contextual attention (MCA). It computes non-local relations only using partial valid to-kens. The selection of adopted tokens is indicated by a dy-namic mask, which is initialized by the input mask and up-dated with spatial constraints and long-range interactions, improving the efficiency at no cost of effectiveness. Addi-tionally, we incorporate a novel style manipulation module into the proposed framework, inherently supporting plural-istic generation. As shown in Fig. 1, our method success-fully fills large holes with visually realistic and exception-ally diverse contents. Our contributions are summarized as:
• We develop a novel inpainting framework MAT. It is the first transformer-based inpainting system capable of directly processing high-resolution images.
• We meticulously design components of MAT. The pro-posed multi-head contextual attention conducts long-range dependency modeling efficiently by exploiting valid tokens, indicated by a dynamic mask. We also propose a modified transformer block to make training large masks more stable. Moreover, we design a novel style manipulation module to improve diversity.
• MAT sets new state of the arts on multiple benchmark datasets including Places [78] and CelebA-HQ [25]. It also enables pluralistic completion. 2.