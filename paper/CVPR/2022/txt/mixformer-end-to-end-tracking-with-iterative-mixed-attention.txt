Abstract tracking framework,
Tracking often uses a multi-stage pipeline of feature ex-traction, target information integration, and bounding box estimation. To simplify this pipeline and unify the process of feature extraction and target information integration, we present a compact termed as
MixFormer, built upon transformers. Our core design is to utilize the flexibility of attention operations, and propose a
Mixed Attention Module (MAM) for simultaneous feature extraction and target information integration. This syn-chronous modeling scheme allows to extract target-specific discriminative features and perform extensive communi-cation between target and search area. Based on MAM, we build our MixFormer tracking framework simply by stacking multiple MAMs with progressive patch embedding and placing a localization head on top.
In addition, to handle multiple target templates during online tracking, we devise an asymmetric attention scheme in MAM to reduce computational cost, and propose an effective score prediction module to select high-quality templates. Our
MixFormer sets a new state-of-the-art performance on five tracking benchmarks, including LaSOT, TrackingNet,
VOT2020, GOT-10k, and UAV123.
In particular, our
MixFormer-L achieves NP score of 79.9% on LaSOT, 88.9% on TrackingNet and EAO of 0.555 on VOT2020. We also perform in-depth ablation studies to demonstrate the effectiveness of simultaneous feature extraction and infor-mation integration. Code and trained models are publicly available at https://github.com/MCG-NJU/MixFormer. 1.

Introduction
Visual object tracking [1, 4, 4, 18, 24, 36, 42, 45] has been a fundamental task in computer vision area for decades, aiming to estimate the state of an arbitrary target in video sequences given its initial status. It has been successfully deployed in various applications such as human computer interaction [34] and visual surveillance [54]. However, how (cid:0) : Corresponding author.
Figure 1. Comparison of tracking pipeline. (a) The dominant tracking framework contains three components: a convolutional or transformer backbone, a carefully-designed integration mod-ule, and task-specific heads. (b) Our MixFormer is more compact and composed of two components: a target-search mixed attention based backbone and a simple localization head. to design a simple yet effective end-to-end tracker is still challenging in real-world scenarios. The main challenges are from aspects of scale variations, object deformations, occlusion, and confusion from similar objects.
Current prevailing trackers typically have a multi-stage pipeline as shown in Fig. 1. It contains several components to accomplish the tracking task: (1) a backbone to extract generic features of tracking target and search area, (2) an integration module to allow information communication be-tween tracking target and search area for subsequent target-aware localization, (3) task-specific heads to precisely lo-calize the target and estimate its bounding box. Integration module is the key of tracking algorithms as it is responsible for incorporating the target information to bridge the steps of generic feature extraction and target-aware localization.
Traditional integration methods include correlation-based operations (e.g. SiamFC [2], SiamRPN [29], CRPN [18],
SiamFC++ [55], SiamBAN [8], OCEAN [63]) and on-line learning algorithms (e.g., DCF [36], KCF [22], CSR-DCF [37], ATOM [12], DiMP [3], FCOT [9]). Re-cently, thanks to its global and dynamic modeling capac-ity, transformers [46] are introduced to perform attention based integration and yields good tracking performance (e.g., TransT [6], TMT [49], STMTrack [19], TREG [10],
STARK [56], DTT [58]). However, these transformer based trackers still depend on the CNN for generic feature ex-traction, and only apply attention operations in the latter high-level and abstract representation space. We analyze
that these CNN representations are limited as they are typi-cally pre-trained for generic object recognition and might neglect finer structure information for tracking.
In addi-tion, these CNN representations employ local convolutional kernels and lack global modeling power. Therefore, CNN representation is still their bottleneck, which prevents them from fully unleashing power of self-attention for the whole tracking pipeline.
To overcome the above issue, we present a new perspec-tive on tracking framework design that generic feature ex-traction and target information integration should be cou-pled together within a unified framework. This coupled processing paradigm shares several key advantages. First, it will enable our feature extraction to be more specific to the corresponding tracking target and capture more target-specific discriminative features. Second, it also allows the target information to be more extensively integrated into search area, and thereby to better capture their correlation.
In addition, this will result in a more compact and neat tracking pipeline only with a single backbone and tracking head, without an explicit integration module.
Based on the above analysis, in this paper, we introduce the MixFormer, a simple tracking framework designed for unifying the feature extraction and target integration solely with a transformer-based architecture. Attention module is a very flexible architectural building block with dynamic and global modeling capacity, which makes few assump-tion about the data structure and could be generally applied for general relation modeling. Our core idea is to utilize this flexibility of attention operation, and present a mixed attention module (MAM) that performs both of feature ex-traction and mutual interaction of target template and search area at the same time. In particular, in our MAM, we devise a hybrid interaction scheme with both self-attention and cross-attention operations on the tokens from target tem-plate and search area. The self-attention is responsible to extract their own features of target or search area, while the cross-attention allows for the communications between them to mix the target and search area information. To re-duce computational cost of MAM and thereby allow for multiple templates to handle object deformation, we further present a customized asymmetric attention scheme by prun-ing the unnecessary target-to-search area cross-attention.
Following the successful transformer architecture in im-age recognition, we build our MixFormer backbone by stacking the layers of Patch Embedding and MAM, and fi-nally place a simple localization head to yield our whole tracking framework. As a common practice in dealing with object deformation during tracking procedure, we also pro-pose a score based target template update mechanism and our MixFormer could be easily adapted for multiple target template inputs. Extensive experiments on several bench-marks demonstrate that MixFormer sets a new state-of-the-art performance, with a real-time running speed of 25 FPS on a GTX 1080Ti GPU. Especially, MixFormer-L surpasses
STARK [56] by 5.0% (EAO score) on VOT2020, 2.9% (NP score) on LaSOT and 2.0% (NP score) on TrackingNet.
The main contributions are summarized as follows:
• We propose a compact end-to-end tracking framework, termed as MixFormer, based on iterative Mixed Atten-tion Modules (MAM). It allows for extracting target-specific discriminative features and extensive commu-nication between target and search simultaneously.
• For online template update, we devise a customized asymmetric attention in MAM for high efficiency, and propose an effective score prediction module to select high-quality templates, leading to an efficient and ef-fective online transformer-based tracker.
• The proposed MixFormer sets a new state-of-the-art performance on five challenging benchmarks, includ-ing VOT2020 [26], LaSOT [17], TrackingNet [41],
GOT-10k [23], and UAV123 [40]. 2.