Abstract
Low-light image enhancement, a pervasive but challeng-ing problem, plays a central role in enhancing the visi-bility of an image captured in a poor illumination envi-ronment. Due to the fact that not all photons can pass the Bayer-Filter on the sensor of the color camera, in this work, we first present a De-Bayer-Filter simulator based on deep neural networks to generate a monochrome raw image from the colored raw image. Next, a fully convolu-tional network is proposed to achieve the low-light image enhancement by fusing colored raw data with synthesized monochrome data. Channel-wise attention is also intro-duced to the fusion process to establish a complementary interaction between features from colored and monochrome raw images. To train the convolutional networks, we pro-pose a dataset with monochrome and color raw pairs named
Mono-Colored Raw paired dataset (MCR) collected by us-ing a monochrome camera without Bayer-Filter and a color camera with Bayer-Filter. The proposed pipeline takes ad-vantages of the fusion of the virtual monochrome and the color raw images, and our extensive experiments indicate that significant improvement can be achieved by leverag-ing raw sensor data and data-driven learning. The project is available at https://github.com/TCL-AILab/
Abandon_Bayer-Filter_See_in_the_Dark 1.

Introduction
For a digitalized image, the quality of the image could be severely degraded due to the color distortions and noise under poor illumination conditions such as indoors, at night, or under improper camera exposure parameters.
Long exposure time and high ISO (sensitivity to light) are often leveraged in low-light environments to preserve visual quality. However, overwhelming exposure leads to motion blur and unbalanced overexposing, and high ISO
*These authors contributed equally to this work.
†Work done while interning at TCL AI Lab.
Figure 1. Overview of the proposed pipeline. We propose to gen-erate monochrome raw data by a learned De-Bayer-Filter mod-ule. Then, a dual branch neural network is designed to bridge monochrome and colored raw to achieve the low-light image en-hancement task. amplifies the noise. Though the camera’s flash provides exposure compensation for the insufficient light, it is not suitable for long-distance shots, and also introduces color distortions and artifacts. On the other hand, various algo-rithms have been reported to enhance the low-light image.
Recently, deep neural network models have been utilized to solve the low-light image restoration problem, such as
DeepISP [22] and Seeing In the Dark (SID) [3].
However, those algorithms are restricted in the image processing pipeline, as the photons capture rate and quan-tum efficiency are usually overlooked. In general, high pho-tons capture rate can improve the image’s visual quality sig-nificantly. One of the typical examples is the RYYB-based color filter, which can capture 40% more photons than the
Bayer-RGGB-based color filter1. Hence, the RYYB-based color filter can achieve better performance naturally.
Bayer filter removal is another plausible way to improve the photons capture rate. The Bayer filter is an array of 1Bayer filter, Bayer-array, Bayer-array filter are used interchangeably.
many tiny color filters that cover the image sensor to ren-der color information (see Fig. 1). By removing the Bayer filter and sacrificing the color information, the image sen-sor can capture more photons, which contributes to clearer visibility under poor illumination conditions compared to a camera with a Bayer filter (see Fig. 2 (a)). On the other hand, dual-cameras are one of the trends of today’s smart devices such as smartphones. One type of dual-camera set is the combination of monochrome sensor and colored sen-sor2. The monochrome sensor is usually identical to the colored sensor but without a Bayer array filter. Such a dual-camera setting can achieve better imaging quality in a low-light environment due to more photons received by the sensor. However, an additional cost is needed for the extra camera equipped. Therefore, for most mobile phones that are only equipped with color cameras, preserving the same low-light image quality produced by dual-camera set while only using a single color camera is a challenging task.
Motivated by the above discussion, we proposed a fully end-to-end convolutional neural model that consists of two modules (as illustrated in Fig. a De-Bayer-Filter (DBF) module and a Dual Branch Low-light Enhancement module (DBLE). The DBF module learns to restore the monochrome raw image from the color camera raw data without requiring a monochrome camera. DBLE is de-signed to fuse colored raw with synthesized monochrome raw data and generate enhanced RGB images. 1):
In addition, we propose a dataset to train our end-to-end framework. To the best of our knowledge, no existing dataset contains monochrome and colored raw image pairs captured by an identical type of sensors. To establish such a dataset, one camera with a Bayer filter is used to cap-ture color-patterned raw images. Another camera without a Bayer-filter but equipped with the same type of sensor is utilized to capture monochrome raw images (see Fig. 2 (b)).
The dataset is collected under various scenes, and each col-ored raw image has a corresponding monochrome raw im-age captured with identical exposure settings.
Our contributions can be summarised as: 1. A De-Bayer-Filter model is proposed to simulate a vir-tual monochrome camera and synthesize monochrome raw image data from the colored raw input.The DBF module aims at predicting the monochrome raw im-ages, which resembles a monochrome sensor capabil-ity. To the best of our knowledge, we are the first to ex-plore removing the Bayer-filter using a deep learning-based model. 2. We design a Dual Branch Low-light Enhancement model that is used to fuse the colored raw with the synthesized monochrome raw to produce the final monitor-ready RGB images. To bridge the domain gap 2For example, Huawei P9, Moto Z2 Force between colored raw and monochrome raw, a channel-wise attention layer is adopted to build an interaction between both domains for better restoration perfor-mance. The experiment results indicate that state-of-the-art performance can be achieved. 3. We propose the MCR, a dataset of colored raw and monochrome raw image pairs, captured with the same exposure setting. It is publicly opened as a research material to facilitate community utilization and will be released after publication. 2.