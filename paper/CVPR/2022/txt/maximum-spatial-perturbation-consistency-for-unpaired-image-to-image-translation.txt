Abstract
Unpaired image-to-image translation (I2I) is an ill-posed prob-lem, as an infinite number of translation functions can map the source domain distribution to the target distribution. Therefore, much effort has been put into designing suitable constraints, e.g., cycle consistency (CycleGAN), geometry consistency (GCGAN), and contrastive learning-based constraints (CUTGAN), that help better pose the problem. However, these well-known constraints have limitations: (1) they are either too restrictive or too weak for specific I2I tasks; (2) these methods result in content dis-tortion when there is a significant spatial variation between the source and target domains. This paper proposes a universal reg-ularization technique called maximum spatial perturbation con-sistency (MSPC), which enforces a spatial perturbation function (T ) and the translation operator (G) to be commutative (i.e.,
T ◦ G = G ◦ T ).
In addition, we introduce two adversarial training components for learning the spatial perturbation func-tion. The first one lets T compete with G to achieve maximum per-turbation. The second one lets G and T compete with discrimina-tors to align the spatial variations caused by the change of object size, object distortion, background interruptions, etc. Our method outperforms the state-of-the-art methods on most I2I benchmarks.
We also introduce a new benchmark, namely the front face to pro-file face dataset, to emphasize the underlying challenges of I2I for real-world applications. We finally perform ablation experiments to study the sensitivity of our method to the severity of spatial per-turbation and its effectiveness for distribution alignment. 1.

Introduction
In unpaired image-to-to image translation (I2I), one aims to translate images from a source domain X to a target do-main Y, with data drawn from the marginal distribution of the source domain (PX ) and that of the target domain
† Equal Contribution. Code is released at https://github.com/ batmanlab/MSPC. (a) Consistency regularization with spatial perturbation function T (b) Spatial alignment of spatial perturbation function T
Figure 1. In this figure, we illustrate the the proposed MSPC on (a) consistency regularization under maximum spatial perturbation and (b) aligning the spatial distributions between source XT and
YT via spatial perturbation function T . (PY ). Unpaired I2I has many applications, such as super-resolution [12, 15], image editing [13, 49], and image de-noising [4,41]. However, it is an ill-posed problem, as there is an infinite choice of translators G that can map PX to PY .
Various constraints on the translation function G have been proposed to remedy the ill-posedness of the problem.
For example, cycle consistency (CycleGAN) [50] enforces the cyclic reconstruction consistency: X → G(X) → X, which means G and its inverse are bijections. CUTGAN
[37] maximizes the mutual information between an input image and the translated image via constrastive learning on the patch-level features. The GCGAN [16], on the other hand, effectively uses geometric consistency by applying a
predefined geometry transformation g, i.e., fixed rotation, encouraging G to be robust to geometry transformation.
The underlying assumption of the GCGAN is that the G and g are commutative (i.e., g ◦ G = G ◦ g). However, Cy-cleGAN assumes that the relationship of bijection between source and target, which is limited for most real-life appli-cations [37]. For instance, the translation function is non-invertible in the Cityscapes → Parsing task. Though geom-etry consistency used in GCGAN is a general I2I constraint, it is too weak in the sense that the model would easily mem-orize the pattern of a fixed transformation. CUTGAN en-forces the strong correlation between the input images and the translated images at the corresponded patches; thus it would fail when the patches at the same spatial location do not contain the same content, e.g., in the Front Face → Pro-file task (shown in Figure 5). Thus, the above models are either too restrictive or too weak for specific I2I tasks. Be-sides, all of them overlook the extra spatial variations in image translation, which are caused by the change of object size, object distortion, background interruptions, etc.
To tackle the issues above, we propose a novel regu-larization called the maximum spatial perturbation consis-tency (MSPC), which enforces a new type of constraint and aligns the content’s spatial distribution content across do-mains. Our MSPC generalizes GCGAN by learning a spa-tial perturbation function T , which adaptively transforms each image with an image-dependent spatial perturbation.
Moreover, MSPC is based on the new insight that consis-tency on hard spatial perturbation would boost the robust-ness of translator G. Thus, MSPC enforces the maximum spatial perturbation function (T ) and the translation opera-tor (G) to be commutative (i.e., T ◦G = G◦T ). To generate the maximum spatial perturbation, we introduce a differen-tiable spatial transformer T [24] to compete with the trans-lation network G in a mini-max game, which we mark as the perturbation branch. More specifically, T tries to maximize the distance between T (G(X)) and G(T (X)), and G mini-mizes the difference between them. In this way, our method dynamically generates the hardest spatial transformation for each image, avoiding overfitting G to specific spatial trans-formations. The Figure 1a give a simple illustration of how the image-dependent spatial perturbation works on the I2I framework.
To align the spatial distribution of the content, T and G cooperate to compete with a discriminator Dpert in another mini-max game, which we mark as an alignment branch.
In the alignment branch, T participates in aligning the dis-tribution between the translated images and the target im-ages by alleviating the spatial discrepancy, i.e. adjusting the object’s size, cropping out the noisy background, and fur-ther reducing undesired distortions in the translation net-work G. We evaluate our model on several widely studied benchmarks, and additionally, we construct a Front Face →
Profile dataset with significant domain gaps to emphasize the challenges in real-world applications. The experimen-tal results show that the proposed MSPC outperforms its competitors on most I2I tasks. More importantly, MSPC performs the most stable across various I2I tasks, demon-strating the universality of our constraint. The Figure 1b shows the visual examples the alignment effect on source and target images via dynamic spatial transformation func-tion. 2.