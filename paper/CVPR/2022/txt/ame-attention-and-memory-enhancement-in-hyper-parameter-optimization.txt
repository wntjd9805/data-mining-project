Abstract
Training Deep Neural Networks (DNNs) is inherently subject to sensitive hyper-parameters and untimely feed-backs of performance evaluation. To solve these two dif-ﬁculties, an efﬁcient parallel hyper-parameter optimization model is proposed under the framework of Deep Reinforce-ment Learning (DRL). Technically, we develop Attention and Memory Enhancement (AME), that includes multi-head attention and memory mechanism to enhance the ability to capture both the short-term and long-term relationship-s between different hyper-parameter conﬁgurations, yield-ing an attentive sampling mechanism for searching high-performance conﬁgurations embedded into a huge search space. During the optimization of transformer-structured conﬁguration searcher, a conceptually intuitive yet power-ful strategy is applied to solve the problem of insufﬁcient number of samples due to the untimely feedback. Experi-ments on three visual tasks, including image classiﬁcation, object detection, semantic segmentation, demonstrate the effectiveness of AME. 1.

Introduction
Hyper-Parameter Optimization (HPO) [53] is a crucial subﬁeld in Automatic Machine Learning (AutoML), which is formulated as a bi-level optimization problem. Recently, the rise of deep learning has promoted giant development of machine learning and computer vision, but it also places higher requirements on computing resources. The optimiza-tion of large-scale neural networks often takes days or even weeks and a large number of GPUs to train, thus manu-al tuning of hyper-parameters has gradually become expen-sive. At the same time, the networks are highly sensitive to
∗Corresponding author
Figure 1. Comparison of different conﬁguration searchers. (a)
Random Search. The selection of the new conﬁguration is inde-pendent of other evaluated conﬁgurations. (b) Bayesian Optimiza-tion. Under the given distribution assumption, the new conﬁg-uration is ﬁnally obtained by acquisition function which models the relationship between evaluated conﬁgurations. (c) Attention and Memory Enhancement (AME). The relationship is captured by attentive sampling without distribution assumptions, and is em-ployed for the prediction of all types of new conﬁgurations. the choice of hyper-parameters. Improper hyper-parameters directly lead to the failure of training, e.g., gradient explo-sion. In addition, when training modern neural networks, a large number of hyper-parameters are required to be set, in-cluding architecture hyper-parameters (e.g., network depth and types), optimization hyper-parameters (e.g., learning rate, batch size), and regularization hyper-parameters (e.g., weight decay), which result in a huge search space. More-over, the challenge of HPO varies greatly in various sub-ﬁelds of machine learning. In the ﬁeld of computer vision, hyper-parameters in detection and segmentation are more sensitive than classiﬁcation. Therefore, a practical modern
HPO algorithm must be able to easily handle the selection of several to dozens of hyper-parameters for different tasks within an acceptable time.
Mainstream HPO algorithms consist of two parts, tri-al scheduler and conﬁguration searcher. Among them, the scheduler is responsible for the allocation of computing re-sources. Speciﬁcally, it is capable of judging when to s-tart a new trial, and whether to suspend or terminate the trials according to the corresponding performance and run-ning time. The searcher is in charge of the proposals of new hyper-parameter conﬁguration. For instance, the sim-plest case is that the new conﬁguration is in a position to be obtained by random search [3, 23, 25, 31, 32] (see
Fig. 1(a)), but the trials are independent, i.e., the relation-ship between each other is not considered, so it is extreme-ly unstable in the huge search space. Using Bayesian Op-timization (see Fig. 1(b)) to build an acquisition function by the evaluated conﬁgurations is another type of searcher
[2, 12, 20, 48, 49]. Although this type of searcher select-s the new hyper-parameter to be evaluated in an informed manner, it is limited by strong assumptions, e.g., assum-ing that the distribution obeys the Gaussian Process. Al-so, the modeling is so complicated that is more suitable for the optimization with a low-dimensional search space.
In addition, the searcher based on Evolutionary Algorithm-s [21, 22, 37, 43] is sometimes time-consuming and is not able to cope with hyper-parameters that can not be inherit-ed, mutated or hybridized, such as network depth and types.
In order to maximize the potential of machine learning models, and to select appropriate hyper-parameters more efﬁciently and stably in the search space, this paper propos-es a new conﬁguration searcher based on Deep Reinforce-ment Learning (DRL) [41,46] and Transformer [42,50] (see
Fig. 1(c)). Our searcher enhances the ability to capture the relationship between different conﬁgurations through multi-head attention and memory mechanism. Combined our searcher with the parallel trial scheduler ASHA [32], Atten-tion and Memory Enhancement (AME) is proposed. AME actively encourages searcher to generate high-performance conﬁgurations, and penalizes conﬁgurations that reduce performance. The main contributions are as follows:
• A transformer-structured conﬁguration searcher is de-signed under reinforcement learning. Based on the novel searcher, an efﬁcient parallel HPO model AME is pro-posed, which is sufﬁcient to optimize all types of hyper-parameters, without distribution assumptions.
• AME is capable of learning both the short-term and long-term relationships to achieve attentive conﬁguration sam-pling, and effectively locating high-performance conﬁg-urations in a huge search space.
• Bootstrap is applied to solve the insufﬁcient number of samples caused by the difﬁculty of sample acquisition.
This makes the online training of searcher efﬁcient.
• Experiments demonstrate the efﬁciency of AME on three vision tasks, including image classiﬁcation, object detec-tion, and semantic segmentation. 2.