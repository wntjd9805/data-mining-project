Abstract
As deep neural networks become the state-of-the-art ap-proach in the field of computer vision for dense prediction tasks, many methods have been developed for automatic es-timation of the target outputs given the visual inputs. Al-though the estimation accuracy of the proposed automatic methods continues to improve, interactive refinement is of-tentimes necessary for further correction. Recently, fea-ture backpropagating refinement scheme [25] (f-BRS) has been proposed for the task of interactive segmentation, which enables efficient optimization of a small set of aux-iliary variables inserted into the pretrained network to pro-duce object segmentation that better aligns with user in-puts. However, the proposed auxiliary variables only con-tain channel-wise scale and bias, limiting the optimization to global refinement only. In this work, in order to general-ize backpropagating refinement for a wide range of dense prediction tasks, we introduce a set of G-BRS (General-ized Backpropagating Refinement Scheme) layers that en-able both global and localized refinement for the following tasks: interactive segmentation, semantic segmentation, im-age matting and monocular depth estimation. Experiments on SBD, Cityscapes, Mapillary Vista, Composition-1k and
NYU-Depth-V2 show that our method can successfully gen-eralize and significantly improve performance of existing pretrained state-of-the-art models with only a few clicks. 1.

Introduction
Deep learning has revolutionized the task of dense pre-diction, allowing a breakthrough for pixel-classification problems such as semantic segmentation [2, 17, 18, 36] and pixel-regression problems such as depth estimation [3, 4, 7, 13]. While these automatic methods are constantly im-proving in performance, a user has no resource to make corrections on the estimated output other than using ex-ternal tools that do not leverage any learned features. To enable user interactions, dense prediction tasks such as in-teractive segmentation [9, 14, 16, 21, 30] and image mat-ting [1, 5, 20, 29, 35] use user inputs in forms of distance maps and trimap respectively as network input. Although the additional information can be helpful during forward propagation, deep networks are still free to generate pre-dictions inconsistent with the user-provided inputs.
In this work, we investigate whether a pretrained au-tomatic dense prediction method can be effectively con-verted into an efficient interactive method without any ad-ditional retraining. This is a significant task as deep net-works are commonly applied in interactive ways for pho-tography [11,32,34,37,38], videography [22,23,31], special effects [6,8,28], etc. Two prior works, both focused primar-ily on interactive segmentation, have inspired our method.
Backpropagating Refinement Scheme (BRS) [12] performs interactive segmentation using an initial forward pass given the input image and distance maps generated from a set of clicks as in [30]. To additionally refine the prediction and encourage consistency with the input clicks, it sets the in-put distance maps as the trainable parameters and performs backpropagation using loss computed from the prediction and the clicked labels. BRS also briefly extends this idea to a few other applications: semantic segmentation, saliency detection and medical image segmentation, showing poten-tial use of BRS for CNNs in general. A follow-on work, f -BRS [25] later argues that due to the need for online back-propagation through the entire network, BRS has slow in-ference speed and is computationally expensive. To this end, instead of using the input distance maps as trainable parameters, f -BRS inserts a pair of auxiliary parameters that act as channel-wise scale and bias after an intermediate net-work layer, requiring backpropagation through a subpart of the network while achieving nearly equivalent performance.
Despite the improved efficiency of f -BRS, it comes with a major disadvantage: the proposed auxiliary channel-wise scale and bias are only capable of global modification. This not only neglects the need for localized refinement in many vision applications, but also makes the modified output sus-ceptible to undesired global changes while correcting for existing clicks. To make efficient and effective refinement
generalized for dense prediction models, we propose to ex-pand the idea of auxiliary channel-wise scale and bias to a set of G-BRS (Generalized Backpropagating Refinement
Scheme) layers with more advanced layer architectures.
Our approach enables both global and localized refinement using a channel-weighted bias map in various settings. In addition, we propose a novel consistency loss with an atten-tion mechanism that stabilizes the refinement process and enables more user control. To demonstrate the generality of our approach, we implement G-BRS on four state-of-the-art models for a wide range of dense prediction tasks includ-ing interactive segmentation, semantic segmentation, image matting and depth estimation. We perform thorough evalu-ation on five benchmark datasets: SBD, Cityscapes, Map-illary Vista, Composition-1k and NYU-Depth-V2. Results show that our method enables existing models to achieve significant improvement with interactive clicks and opens up promising directions for equipping automatic methods with interactive features in general. 2. Method 2.1.