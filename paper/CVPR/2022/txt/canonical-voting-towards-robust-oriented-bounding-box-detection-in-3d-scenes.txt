Abstract 3D object detection has attracted much attention thanks to the advances in sensors and deep learning methods for point clouds. Current state-of-the-art methods like VoteNet regress direct offset towards object centers and box orientations with an additional Multi-Layer-Perceptron network. Both their offset and orientation predictions are not accurate due to the fundamental difﬁculty in rotation classiﬁcation. In the work, we disentangle the direct offset into Local Canonical
Coordinates (LCC), box scales and box orientations. Only
LCC and box scales are regressed, while box orientations are generated by a canonical voting scheme. Finally, an
LCC-aware back-projection checking algorithm iteratively cuts out bounding boxes from the generated vote maps, with the elimination of false positives. Our model achieves state-of-the-art performance on three standard real-world bench-marks: ScanNet, SceneNN and SUN RGB-D. Our code is available on https://github.com/qq456cvb/CanonicalVoting. 1.

Introduction
With the use of depth cameras and Lidar sensors, 3D ob-ject detection is becoming more and more important for real-world scene understanding. Recently, with advances in deep networks for point clouds, several methods [16, 20, 22, 26] have shown state-of-the-art 3D detection results. Among them, the recently proposed VoteNet [16] showed remark-able improvement over previous methods on 3D oriented bounding box detection (rotation around gravity axis).
VoteNet passes the input point cloud through a back-bone network and then samples a set of seed points, which generate center votes. These votes are offset, targeted to reach object centers. After that, vote clusters are aggregated through a learned module to generate box orientations and
*Cewu Lu and Weiming Wang are the corresponding authors. Cewu Lu is member of Qing Yuan Research Institute and MoE Key Lab of Artiﬁ-cial Intelligence, AI Institute, Shanghai Jiao Tong University, China and
Shanghai Qi Zhi institute.
Figure 1. We present a method that regresses Local Canoni-cal Coordinates disentangled from orientations. We leverage a canonical voting module to ﬁnd possible orientations and object centers. Back projection validation is utilized to further eliminate false positives. scales. VoteNet resembles with traditional Hough voting in that bounding box centers are proposed in those peaks of votes. However, we ﬁnd that neither box orientations nor offsets towards object centers are accurately predicted for most points, even with modern 3D sparse convolution tech-niques [3]. The absolute error of point-wise predicted offsets and box orientations is not even better than random guess in many cases, as shown in Table 1. Though VoteNet proposes a two-stage pipeline and reﬁnes the center and orientation in the later stage, the accumulated error cannot be eliminated.
To handle this problem, we disentangle direct offset to-wards object centers into the following three parts: Local
Canonical Coordinates (LCC), box scales and box orien-tations. First, we estimate Local Canonical Coordinates (LCC) and box scales instead of regressing orientations.
Offset Error Orientation Error
• State-of-the-art performance on three 3D bounding box
Direct Regression
Random Guess 0.197 0.228 0.806 0.801
Table 1. Mean absolute error of point wise predicted offsets and orientations, evaluated on ScanNet. We see that direct re-gression is only slightly better than random guess on offset predic-tions and worse on orientation predictions.
In LCC, all objects are consistently aligned and centered.
In comparison to conventional orientation regression like voteNet, regression of LCC is generally easier because points belonging to the same part of an object are mapped to simi-lar LCCs, no matter how the object rotates. Based on this, our model only needs to solve a task that is similar to part segmentation, for which we have seen great success in re-cent years [11, 18, 25]. Experiments show that our LCC predictions are far more accurate than direct offset. There-fore, these canonical votes could be directly used without any post-processing step like clustering. Similar ideas on regress-ing local coordinates have also been explored by previous methods like NOCS [24]. However, it requires an additional
Mask-RCNN to do instance segmentation, and then ﬁnds a closed-form solution of translation, rotation and scale. This closed-form solution only exists for a single object. If there are multiple instances, no global closed-form solution exists as far as we know.
To solve this problem, we design a canonical voting algorithm to ﬁnd possible object orientations and centers in
Euclidean space. Object bounding boxes are proposed by looking at those locations with high votes. However, there will be some votes that accidentally accumulate as false positives. In order to eliminate them, it is crucial to project proposed object coordinates back into canonical space and compare them with LCC predictions. We call this step as
LCC checking with back projection.
We evaluate our approach on two challenging large-scale 3D scan datasets: ScanNet [4] and SceneNN [9], and one smaller indoor RGB-D dataset: SUN RGB-D [21]. Our approach achieves state-of-the-art performance on ScanNet and SceneNN, with an absolute advance of 9.6 and 5.1 mAP, respectively. It also shows superior performance on SUN
RGB-D benchmark. In addition, our experiments show that
LCC regression and canonical voting are more robust over direct offset and orientation regression on detecting occluded objects.
To summarize, our contributions are:
• Bypassing orientation regression difﬁculties through
Local Canonical Coordinates and Canonical Voting.
• Devising a back projection validation module to elimi-nate false positives, achieving high average precision. detection benchmarks. 2.