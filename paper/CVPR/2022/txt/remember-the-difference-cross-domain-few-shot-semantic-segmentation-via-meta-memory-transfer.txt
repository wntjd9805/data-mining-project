Abstract
Few-shot semantic segmentation intends to predict pixel-level categories using only a few labeled samples. Existing few-shot methods focus primarily on the categories sampled from the same distribution. Nevertheless, this assumption cannot always be ensured. The actual domain shift problem significantly reduces the performance of few-shot learning.
To remedy this problem, we propose an interesting and chal-lenging cross-domain few-shot semantic segmentation task, where the training and test tasks perform on different do-mains. Specifically, we first propose a meta-memory bank to improve the generalization of the segmentation network by bridging the domain gap between source and target do-mains. The meta-memory stores the intra-domain style in-formation from source domain instances and transfers it to target samples. Subsequently, we adopt a new contrastive learning strategy to explore the knowledge of different cat-egories during the training stage. The negative and pos-itive pairs are obtained from the proposed memory-based style augmentation. Comprehensive experiments demon-strate that our proposed method achieves promising results on cross-domain few-shot semantic segmentation tasks on
COCO-20i , PASCAL-5i, FSS-1000, and SUIM datasets. 1.

Introduction
Recently, semantic segmentation [2, 19, 45] has made remarkable progress benefiting from the large amounts of human-annotated datasets and deep convolutional neural
*Corresponding Author
Figure 1. Comparison with few-shot segmentation and few-shot domain adaptation segmentation. In few-shot learning, the train-ing set and testing sets come from the same domain. In few-shot domain adaptation, the training set and testing sets are from sepa-rate domains, but the label space is the same. In our cross-domain few-shot segmentation task, the training set and testing sets come from different domains, and the categories in the testing set are unseen. networks [11]. However, obtaining these large annotated datasets is time-consuming and labor-intensive, and the trained model always fails to segment novel unseen cate-gories. To tackle this problem, few-shot semantic segmen-tation methods [6, 42, 47] have received a lot of attention in recent years, aiming to produce pixel-level predictions for the novel categories when given only few (one) training im-ages.
Few-shot semantic segmentation methods [1,16] address the challenge of adapting a segmentation network to a new
category represented by few support images via a meta-learning [9, 43], which enables the model to transfer the knowledge from the support set to the query set. Exist-ing approaches assume that the base training set is sam-pled from the same domain as the testing set. However, collecting sufficient examples in specific areas, such as der-matology or satellite imagery, is infeasible or impossible.
Alternatively, we train a satisfactory few-shot semantic seg-mentation network for the test dataset (target domain) by transferring the knowledge from the existing base training dataset (source domain). Consequently, we formulate a new but essential problem called cross-domain few-shot seman-tic segmentation.
Recently, a tiny number of cross-domain few-shot meth-ods [21, 31, 34] have been developed to tackle the similar issue on image classification. However, the proposed meth-ods are hard to apply to our scenario because the pixel-level segmentation is fundamentally different from the image-level classification. Another close work is domain adap-tation [18, 26, 40] or few-shot domain adaptation semantic segmentation [46, 49], which eliminates domain shift issue with few-shot labeled target images. But our setting is more challenging because we have disjoint categories between the source and target domains. The comparison is shown in Figure 1.
The fundamental challenges for cross-domain few-shot semantic segmentation lie in two aspects. (1) There is a do-main shift problem between the training and testing tasks due to sampling from different domains.
It leads to per-formance degrades significantly for conventional few-shot semantic segmentation methods. (2) The labeled data of new categories is scarce, so the fine-tuning or distribution alignment methods are challenging. In this paper, we pro-pose a novel cross-domain few-shot semantic segmenta-tion framework, named as CDFSS. Our framework mainly focuses on reducing the domain gap by domain general-ization and exploring the discriminative information from the few-shot novel categories. Specifically, we first con-struct a meta-memory to collect domain-specific informa-tion among source domain instances. The source instances continuously register the stylized domain information into the meta-memory as the training progresses. Aggregated style information can effectively describe the source data distribution and enhance the target domain features. Then, we load the stored memory into both the source and tar-get domain to enhance the model’s generalization. For the meta-training stage on the source domain, the loaded memory is mainly responsible for augmenting the features stylization, and the model is encouraged to produce con-sistent representations despite the style differences. In the test stage on the target domain, the model loads the source meta-knowledge to guide the feature enhancement and alle-viate the domain gap in cross-domain problems. Memory-enhanced features help novel categories generate more di-versified prototypes so that the model can provide robust predictions. Moreover, we adopt the contrastive loss using the memory enhanced features to further constrain the pro-totypes between categories to improve the model’s adapt-ability in few-shot learning.
The contributions of this article are summarized as fol-lows: 1. We propose a novel framework to solve the cross-domain problem in few-shot semantic segmentation.
Compared to the standard few-shot segmentation net-work, we use the most primitive feature transfer to solve the cross-domain problem and effectively broaden the use scenarios of few-shot segmentation tasks. 2. We propose a plug-and-play meta-knowledge module to transfer the prior source distribution to the target do-main. Our model can effectively alleviate the influence of domain shift in few-shot segmentation with exclu-sive contrastive loss. 3. We demonstrate the effectiveness of our framework on four different cross-domain few-shot segmentation scenarios. In particular, it can achieve state-of-the-art performance under the cross-domain setting. 2.