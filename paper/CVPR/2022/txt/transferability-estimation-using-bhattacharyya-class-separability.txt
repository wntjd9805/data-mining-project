Abstract
Transfer learning has become a popular method for leveraging pre-trained models in computer vision. How-ever, without performing computationally expensive fine-tuning, it is difficult to quantify which pre-trained source models are suitable for a specific target task, or, conversely, to which tasks a pre-trained source model can be eas-In this work, we propose Gaussian Bhat-ily adapted to. tacharyya Coefficient (GBC), a novel method for quanti-fying transferability between a source model and a target dataset. In a first step we embed all target images in the feature space defined by the source model, and represent them with per-class Gaussians. Then, we estimate their pairwise class separability using the Bhattacharyya coef-ficient, yielding a simple and effective measure of how well the source model transfers to the target task. We eval-uate GBC on image classification tasks in the context of dataset and architecture selection. Further, we also per-form experiments on the more complex semantic segmen-tation transferability estimation task. We demonstrate that
GBC outperforms state-of-the-art transferability metrics on most evaluation criteria in the semantic segmentation set-tings, matches the performance of top methods for dataset transferability in image classification, and performs best on architecture selection problems for image classification. 1.

Introduction
The goal of transfer learning is to reuse knowledge learned on a source task to help train a model for a target task. Currently, the most common form of transfer learn-ing in computer vision is to pre-train a source model on the
ILSVRC’12 dataset [55] and then fine-tune it on the target dataset [3, 14, 23, 24, 30, 35, 57, 75]. However, each target task may benefit from a different source model architec-ture [12, 25, 45, 53] or different source dataset [42, 46, 71].
The challenge then becomes to determine which (pre-*Currently at Waymo.
Figure 1. This figure illustrates the high-level overview of our approach. On the left, we use the pre-trained source models to embed data into the source models’ feature space. On the right, we use GBC to rank these methods based on how much classes overlap in corresponding embedding spaces. trained) source model is most suitable for a particular target task, or to which target task a specific model can be easily adapted. Determining this by fine-tuning all combinations of source models and target datasets is computationally pro-hibitive.
To address this problem, several recent works introduced transferability metrics [4, 38, 47, 60, 61, 72], which aim at predicting how well a source model transfers to a given tar-get dataset. A good transferability metric is computation-ally efficient, and its predictions correlate well with the fi-nal performance of a model after fine-tuning on the target dataset. Typically a transferability metric is estimated by applying the source model to the target dataset to extract embeddings or predictions, which are then combined with the target ground-truth labels to measure transferability.
This paper proposes a novel transferability metric: the
Gaussian Bhattacharyya Coefficient (GBC). The main idea is to measure the amount of overlap between target classes in the feature space of the source model (Fig. 1). If this over-lap is small, the target classes are easily separated which means the knowledge in the source model is useful for the
target task and the source model should transfer well. Con-versely, if the overlap is large, the target classes are difficult to separate and the source model transfers badly to this tar-get task.
In order to estimate the amount of overlap, we apply the feature extractor of the source model to the target dataset and model each target class as a Gaussian distribu-tion in this space. Importantly, we carefully apply regular-ization techniques to ensure that the Gaussian model can accurately represent each class. Then, we measure the sum of the overlaps between each pair of target classes using the
Bhattacharyya coefficient. The Bhattacharyya coefficient has a closed-form solution when applied on Gaussian dis-tributions. We use this overlap as our transferability metric.
We perform extensive experiments on two tasks. First we consider image classification, the primary focus of pre-vious works on transferability metrics [4, 38, 47, 60, 61, 72].
Additionally, we consider a realistic transfer learning sce-nario for the task of semantic segmentation by consider-ing transfer across a large variety of datasets from different image domains. Our experiments demonstrate that GBC outperforms several state-of-the-art transferability metrics:
LEEP [47], LogME [72], H-score [4]. Furthermore, we demonstrate that our method is computationally efficient.
In summary, our paper makes the following contribu-tions: 1) We introduce GBC, a new transferability met-ric which measures the amount of overlap between target classes in the source feature space. Since we model the target samples with per-class Gaussians, the GBC can be estimated in closed form; 2) We lift transferability experi-ments to a realistic transfer learning scenario for semantic segmentation; 3) We experimentally demonstrate that our
GBC method outperforms other transferability metrics, in-cluding LEEP [47], LogME [72], and H-score [4]. 2.