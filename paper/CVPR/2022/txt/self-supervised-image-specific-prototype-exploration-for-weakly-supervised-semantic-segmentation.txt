Abstract
Weakly Supervised Semantic Segmentation (WSSS) based on image-level labels has attracted much attention due to low annotation costs. Existing methods often rely on
Class Activation Mapping (CAM) that measures the corre-lation between image pixels and classiﬁer weight. However, the classiﬁer focuses only on the discriminative regions while ignoring other useful information in each image, re-sulting in incomplete localization maps. To address this is-sue, we propose a Self-supervised Image-speciﬁc Prototype
Exploration (SIPE) that consists of an Image-speciﬁc Pro-totype Exploration (IPE) and a General-Speciﬁc Consis-tency (GSC) loss. Speciﬁcally, IPE tailors prototypes for ev-ery image to capture complete regions, formed our Image-Speciﬁc CAM (IS-CAM), which is realized by two sequential steps. In addition, GSC is proposed to construct the con-sistency of general CAM and our speciﬁc IS-CAM, which further optimizes the feature representation and empow-ers a self-correction ability of prototype exploration. Ex-tensive experiments are conducted on PASCAL VOC 2012 and MS COCO 2014 segmentation benchmark and results show our SIPE achieves new state-of-the-art performance using only image-level labels. The code is available at https://github.com/chenqi1126/SIPE. 1.

Introduction
Semantic segmentation aims to assign a semantic cat-egory label to each pixel in an image, which has been widely applied in autonomous driving [14], medical imag-ing [38] and remote sensing image interpretation [17]. Ben-eﬁting from Convolutional Neural Networks (CNNs), se-mantic segmentation has achieved remarkable progress in fully supervised manner. However, training a fully su-pervised segmentation model requires a large number of
*Corresponding Author
Figure 1. Main motivation. We visualize the pixel-level feature distribution of four cat images by t-SNE [39]. The original CAM activates each pixel using class center (green star). Our method extracts image-speciﬁc prototypes (pink star) to generate Image-Speciﬁc CAM (IS-CAM) that captures more complete regions. pixel-level annotations, which is notoriously expensive and time-consuming to collect. An alternative approach is to learn from weak labels, e.g., image-level labels [2], bound-ing boxes [26, 49], scribbles [29, 34, 46] and points [3, 5].
Among these works, image-level labels based Weakly Su-pervised Semantic Segmentation (WSSS) has enjoyed great popularity within the community.
Most of existing methods leverage Class Activation
Mapping (CAM) [53] technology to provide localization cues of target object. Speciﬁcally, these methods train a classiﬁer and regard its learned weights as a general repre-sentation of each class, i.e., class center. Then, this class center is used to correlate with image pixels to obtain local-ization maps as shown in Fig. 1. However, CAM tends to
focus on a few primary regions (cat’s head) while ignoring other useful cues (cat’s body). To explain the problem, we visualize pixel-level features of foreground extracted from a trained classiﬁcation network. Those features are shown with four different colors and their transparency degree in-dicate the activation of CAM. We ﬁnd that the class cen-ter always gives high activations to the close pixels (cor-respond to some primary regions) and ignores the distant pixels. The imbalanced activations lead to the incomplete
In addition, localization map as demonstrated in Fig. 1. activating features on each image by the centroid of that features (pink star) can be beneﬁcial to explore more com-plete regions (see Image-Speciﬁc CAM (IS-CAM) shown in
Fig. 1). Therefore, this paper aims to tailor image-speciﬁc prototypes to adaptively describe the image itself.
To this end, we propose a novel weakly supervised semantic segmentation framework, called Self-supervised
Image-speciﬁc Prototype Exploration (SIPE). The proposed
SIPE consists of an Image-speciﬁc Prototype Exploration (IPE) and a General-Speciﬁc Consistency (GSC) loss, which is illustrated in Fig. 2. Speciﬁcally, IPE is realized as two sequential steps to characterize prototypes, allow-ing to capture more complete localization maps.
In the
ﬁrst step, we utilize inter-pixel semantics to explore spatial structure cues, locating robust seed regions of each class.
Given the seed regions, we extract image-speciﬁc proto-types and then produce our IS-CAM by prototypical cor-relation. In addition, GSC is proposed to construct the con-sistency of general CAM and our speciﬁc IS-CAM. This self-supervised signal further optimizes the feature repre-sentation and empowers a self-correction ability of proto-type exploration. Extensive experiments are conducted on
Pascal VOC 2012 [11] and MS COCO 2014 [30] and re-sults show that our SIPE achieves new state-of-the-art per-formance when only image-level labels are available.
Our main contributions are summarized as:
• We propose Self-supervised Image-speciﬁc Prototype
Exploration (SIPE) to learn image-speciﬁc knowledge for weakly supervised semantic segmentation.
• We propose Image Prototype Exploration (IPE) that tailors image-speciﬁc prototypes for each image, which is achieved by structure-aware seed locating and background-aware prototype modeling. It enables the model to capture more complete localization maps.
• We propose a General-Speciﬁc Consistency (GSC) loss to effectively regularize the original CAM and IS-CAM, empowering the feature representation. 2.