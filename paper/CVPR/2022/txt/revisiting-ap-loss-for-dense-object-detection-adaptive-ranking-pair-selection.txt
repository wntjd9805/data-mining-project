Abstract
Average precision (AP) loss has recently shown promis-ing performance on the dense object detection task. How-ever, a deep understanding of how AP loss affects the detec-tor from a pairwise ranking perspective has not yet been de-veloped. In this work, we revisit the average precision (AP) loss and reveal that the crucial element is that of select-ing the ranking pairs between positive and negative sam-ples. Based on this observation, we propose two strate-gies to improve the AP loss. The ﬁrst of these is a novel
Adaptive Pairwise Error (APE) loss that focusing on rank-ing pairs in both positive and negative samples. Moreover, we select more accurate ranking pairs by exploiting the normalized ranking scores and localization scores with a clustering algorithm. Experiments conducted on the MS-COCO dataset support our analysis and demonstrate the superiority of our proposed method compared with current classiﬁcation and ranking loss. The code is available at https://github.com/Xudangliatiger/APE-Loss. 1.

Introduction
Object detection is one of the fundamental computer vi-sion tasks and aims to predict both the category labels and the bounding-box coordinates of all objects in a given im-It also plays an important role in age [3, 19, 21, 27, 30]. many down-stream applications such as instance segmenta-tion [1, 9, 31, 33] and face detection [6]. Modern object de-tectors can be divided into two-stage approaches [3,27] and one-stage approaches [35, 39]. One-stage detectors adopt dense prediction without a region proposal phase; thus they are also known as dense object detectors. One-stage ob-ject detectors are also naturally faster than two-stage de-tectors and popular in real-world applications such as that on edge devices [35, 39]. Most one-stage object detec-tors [16, 19, 21, 26, 30, 38, 40] rely on a classiﬁcation task to discriminate the category of objects, i.e., directly pre-* Corresponding author. dicting the category probability for every patch in an im-age. However, it often suffers from an extreme imbalance problem, as huge numbers of background patches (i.e., neg-ative samples) can overwhelm the sufﬁcient loss gradients for foreground patches (i.e., positive samples). Recently, to alleviate this sensitivity to the ratio of negative and positive samples, Average Precision Loss [4] converts the classiﬁca-tion task into a ranking task by explicitly modeling sample relationships that are calculated by comparing all sample pairs.
Despite AP loss performing well at addressing the sam-ple imbalance problem, the essential mechanism of how
AP loss affects the detector is still veiled. Accordingly, in this paper, we delve into AP loss from a pairwise ranking perspective [2]; speciﬁcally, the crucial part of AP loss is the minimizing of the pairwise error between the positive and negative samples. To ﬁnd out the essential properties of AP loss, we analyze components of pairwise error sep-arately and reveal that the key factor is the accurate and complete ranking pair selection. Consequently, we improve the AP loss by adjusting the way in which ranking pairs are constructed and selected. Proper ranking pair selection achieves notable performance gains for object detection.
More speciﬁcally, we ﬁrst derive a reformulation of the
AP loss and show that it contains three main components of generalized pairwise error: distance function, balance con-stant and ranking pair selection. We conduct detailed exper-iments to verify these different components’ effects and de-termine that proper ranking pair selection plays a vital role in producing accurate detection results. We then investigate the barriers to good performance encountered by existing ranking pair selection strategies and identify the following issues: (1) Traditional strategies [13, 19, 30, 38] ignore the ranking pairs between positive samples, which may lead to inaccurate category probability prediction, and harms the
Non-Maximum Suppression (NMS) result; (2) The prob-ability of image content in the ranking task and accuracy in the localization task, i.e., ranking score and localization score have different distributions, which brings imbalanced attentions to those two tasks during the pair selection pro-(cid:28629) (cid:28660) (cid:28662) (cid:28670) (cid:28661) (cid:28674) (cid:28673) (cid:28664) (cid:28595) (cid:28641) (cid:28664) (cid:28679) (cid:28682) (cid:28674) (cid:28677) (cid:28670) (cid:28595) (cid:28682) (cid:28668) (cid:28679) (cid:28667) (cid:28595) (cid:28633) (cid:28643) (cid:28641)
Ranking Sub-net:
Feature map (cid:3024) (cid:3009) (cid:28772)D (cid:3020) (cid:3020) (cid:28772) (cid:28772)4 (cid:3009) (cid:3020) (cid:28772) (cid:3024) (cid:3020) (cid:28772)256
Localization Sub-net: (cid:28772)4 (cid:3009) (cid:3020) (cid:28772) (cid:3024) (cid:3020) (cid:28772)256
Ranking heatmap (cid:3024) (cid:3009) (cid:28772) (cid:3020) (cid:3020) (cid:28772)C
Localization  heatmap (cid:3024) (cid:3009) (cid:28772) (cid:3020) (cid:3020) (cid:28772)4
Normalized Ranking Scores
Normalized Localization Scores (a)                                                                                   (b) (c)
Figure 1. Comparison between our ranking pair selection and a traditional methods. Here, the large red and blue dots are used to highlight positive and negative samples, respectively, while the two-way arrows are used to highlight typical ranking pairs. (a) Current pairwise ranking methods ignore the pair between positive positions and focus on the anchor-based IoU to select ranking pairs. The red and white boxes are the ground truth and preset anchor. (b) FCOS detector (this paper omits the center-ness branch). (c) Our method can make up for the loss of ranking pairs between positive samples and focus on the distribution of prediction scores to adaptively select more accurate ranking pairs. cessing as in Probabilistic Anchor Assignment (PAA) [13].
To alleviate these barriers, we propose a simple yet ef-fective Adaptive Ranking Pair Selection (ARPS) approach to provide complete and more accurate ranking pairs for cal-culating pairwise error. To begin with, we build extra rank-ing pairs from the positive set to calculate Adaptive Pair-wise Error (APE), which is differentiable and easy to im-plement and can exploit the ranking information between positive samples. It is worth noting that APE loss can also be considered a more accurate AP loss formulation. Sec-ond, we align the instance-level ranking scores and local-ization scores via normalization and feed them into a clus-tering algorithm (e.g.Gaussian Mixture Model in PAA [13]) to create a better split between the positive and the negative set. After that, ranking pairs can be easily obtained from ev-ery combination pair of two clusters. Experimental results show that our method can optimize the training procedure of ranking tasks with higher accuracy.
The contributions of this work are three-fold and can be summarized as follows: 1) We conduct thorough experi-ments to verify each part of AP loss from a pairwise per-spective and reveal that inappropriate ranking pair selection is the main obstacle; 2) we propose a ranking pair selection algorithm, i.e., ARPS, to exploit complete and more accu-rate ranking pairs automatically; 3) our method achieves competitive performance when evaluated against all other existing classiﬁcation and ranking methods. 2.