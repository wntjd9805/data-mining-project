Abstract
Hyperspectral imaging has attracted significant attention to identify spectral signatures for image classification and automated pattern recognition in computer vision. State-of-the-art implementations of snapshot hyperspectral imaging rely on bulky, non-integrated, and expensive optical elements, including lenses, spectrometers, and filters. These macro-scopic components do not allow fast data processing for, e.g. real-time and high-resolution videos. This work introduces
Hyplex™, a new integrated architecture addressing the limi-tations discussed above. Hyplex™ is a CMOS-compatible, fast hyperspectral camera that replaces bulk optics with nanoscale metasurfaces inversely designed through artificial intelligence. Hyplex™ does not require spectrometers but makes use of conventional monochrome cameras, opening up the possibility for real-time and high-resolution hyperspec-tral imaging at inexpensive costs. Hyplex™ exploits a model-driven optimization, which connects the physical metasur-faces layer with modern visual computing approaches based on end-to-end training. We design and implement a pro-totype version of Hyplex™ and compare its performance against the state-of-the-art for typical imaging tasks such as spectral reconstruction and semantic segmentation. In all benchmarks, Hyplex™ reports the smallest reconstruction error. We additionally present what is, to the best of our knowledge, the largest publicly available labeled hyperspec-tral dataset for semantic segmentation. 1 1.

Introduction
Hyperspectral imaging is gaining considerable interest in many areas including civil, environmental, aerial, military, and biological sciences for estimating spectral features that allow the identification and remote sensing of complex mate-rials [10, 29]. Ground-based hyperspectral imaging enables automated classification for food inspection, surgery, biol-1Dataset available on https://github.com/makamoa/hyplex.
Figure 1. Hardware implemented Hyplex™ imaging system. (a)
Example of metasurface pixel arrays (blue squares). (b) Schematic of meta-pixel array on top of a camera sensor. (c) Closeup showing the metasurface projectors as subpixels of the array. (d) Scanning electron microscope image of a fabricated metasurface pixel. (e)
Optical micrograph of the metasurface pixel array. (f) Illustration of the barcode generated by (e). ogy, dental and medical diagnosis [1, 21, 34, 42]. Likewise, aerial and submarine hyperspectral imaging are currently opening new frontiers in agriculture and marine biology for the taxonomic classification of fauna, and through aerial drone footage for precision agriculture [2, 10, 13, 14]. The present state-of-the-art in hyperspectral imaging, however, is still affected by problems of expensive setup costs, time-consuming post-data processing, low speed of data acquisi-tion, and the needs of macroscopic optical and mechanical components [41, 58]. A single hyperspectral image obtained from a high-resolution camera typically requires gigabytes of storage space, making it impossible to perform real-time
video analysis with today’s computer vision techniques [28].
Computational hyperspectral reconstruction from a single
RGB image is a promising technique to overcome some of the challenges mentioned above [4, 7, 18, 22, 25, 26, 38, 44, 54, 63]. Heidrich et al. [24] proposed hyperspectral cameras based on integrated diffractive optical elements, while other groups [12,60] leveraged deep neural networks for designing spectral reconstruction filters. While these approaches could help address the problem of speed, they are not yet able to tackle the issues of high cost and slow data processing. Other bottlenecks are the use of elementary filter responses, which are not optimized beyond primitive thin-film interference patterns, and the lack of integrated structures that could exploit the modern footprint of CCD/CMOS sensors.
We here introduce the Hyplex™ system (Fig. 1), a data-driven hyperspectral imaging camera (Fig. 1, a-b), which uses state-of-the-art metasurfaces to replace macro-scopic components with highly integrated dielectric nanores-onators that manipulate light as a feed-forward neural net-work [9, 17, 19]. Metasurfaces have successfully demon-strated the ability to integrate various basic optical compo-nents for different applications [48–50]. Hyplex™ leverages this technology to compress high-dimensional spectral data into a low-dimensional space via suitably defined projectors (Fig. 1, c-d), designed with end-to-end learning of large hy-perspectral datasets. ALFRED [16, 19, 37], an open-source, inverse-design software exploiting artificial intelligence (AI), provides the means to design the metasurface projectors.
These nanostructures encode broadband information carried by incoming spectra into a barcode composed of a discrete pattern of intensity signals (Fig. 1, e-f). A physical model-aware framework finds the optimal projectors’ response with various learning schemes, designed based on user end tasks.
We summarize our contribution as follows: (i) We pro-pose and implement an inexpensive and fast-processing data-driven snapshot hyperspectral camera that uses two inte-grated components: inverse-designed spectral encoders and a monochrome camera. (ii) We implement an end-to-end framework for hyperspectral semantic image segmentation and spectral reconstruction, and benchmark it against the state-of-the-art, reporting the highest performance to date. (iii) We create FVgNET, the largest publicly available dataset of 317 samples of labeled hyperspectral images for semantic segmentation and classification. 2.