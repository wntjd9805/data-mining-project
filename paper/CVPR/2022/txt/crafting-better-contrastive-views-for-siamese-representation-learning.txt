Abstract
Recent self-supervised contrastive learning methods greatly benefit from the Siamese structure that aims at min-imizing distances between positive pairs. For high per-formance Siamese representation learning, one of the keys is to design good contrastive pairs. Most previous works simply apply random sampling to make different crops of the same image, which overlooks the semantic information that may degrade the quality of views.
In this work, we propose ContrastiveCrop, which could effectively generate better crops for Siamese representation learning. Firstly, a semantic-aware object localization strategy is proposed within the training process in a fully unsupervised manner.
This guides us to generate contrastive views which could avoid most false positives (i.e., object vs. background).
Moreover, we empirically find that views with similar ap-pearances are trivial for the Siamese model training. Thus, a center-suppressed sampling is further designed to enlarge the variance of crops. Remarkably, our method takes a careful consideration of positive pairs for contrastive learn-ing with negligible extra training overhead. As a plug-and-play and framework-agnostic module, ContrastiveCrop consistently improves SimCLR, MoCo, BYOL, SimSiam by 0.4% ∼ 2.0% classification accuracy on CIFAR-10,
CIFAR-100, Tiny ImageNet and STL-10. Superior results are also achieved on downstream detection and segmenta-tion tasks when pre-trained on ImageNet-1K. 1.

Introduction
Self-supervised learning (SSL) has attracted much at-tention in the computer vision community due to its po-tential of exploiting large amount of unlabeled data. As a mainstream approach in SSL, contrastive learning has achieved higher performance on several downstream tasks
*Equal contribution.
†Corresponding author. (a) (c) (b) (d)
Figure 1. The motivation of our proposed ContrastiveCrop. (a) and (c) are generated by typical RandomCrop, while (b) and (d) are crops from our method. We address the false positive prob-lem (object vs. background) shown in (a) by localizing the object and restricting the crop center within the bounding box (the black dashed box) in (b). Moreover, we enlarge the variance of crops in (d) by keeping them away from the center, which avoids the close appearance as shown in (c). (e.g., object detection, segmentation and pose estimation
[16, 18, 21, 27, 32]) than its supervised counterpart. Such promising results can be largely attributed to the Siamese structure, which is commonly applied in state-of-the-art un-supervised methods, including SimCLR [5], MoCo [20],
BYOL [17] and SimSiam [8]. Typically, the Siamese struc-ture takes two augmented views from an image as input, and minimizes their distance in the embedding space. With proper views selected, Siamese networks demonstrate a strong capability to learn generic visual features [37].
One of the key issues of contrastive learning is to design positives selection. Some works generate different positive views by strong data augmentation, such as color distor-tion and jigsaw transformation [4, 37]. Another work [34] applies mixture [48, 49] in an unsupervised manner to pro-duce positive pairs that incorporate multiple samples. Addi-tionally, different from data augmentation, [50] creates hard positives with transformation at the feature level. Despite different techniques, these works commonly apply Ran-domCrop to sample multiple views of an image, and further make the views more diverse.
As a basic sampling method, RandomCrop enables all in-dividual crops to be selected equiprobably. However, it fails to look at the semantic information of paired views, which helps to learn better representations more efficiently and ac-curately. As shown in Fig. 1a, random crops are prone to miss the object when no prior of object (e.g., scale and lo-cation) is given. Optimizing the distance between object and background in the embedding space would mislead the learning of representations. Besides, Fig. 1c indicates that random crops cannot always carry sufficient variances of an object. Such views with large similarity are trivial for learn-ing discriminative models.
In this paper, we propose ContrastiveCrop, aiming to craft better contrastive pairs for Siamese representation learning. False positives indicate that a better sampling strategy for contrastive learning should consider the content of an image. Hereby, we propose a semantic-aware local-ization scheme, which serves as a guidance to select crops and avoid most false positives, as shown in Fig. 1b. More-over, we propose a center-suppressed sampling strategy to tackle trivial positive pairs with large similarity. Fig. 1d shows that our crops are more likely to cover different parts of the object. The semantic-aware localization and center-suppressed sampling scheme can be gracefully combined to generate better crops for contrastive learning.
The proposed ContrastiveCrop considers both semantic information and maintaining large variance when making pairs. As a plug-and-play method, it can be easily ap-plied into the Siamese structure. More importantly, our ap-proach is agnostic to contrastive frameworks, regardless us-ing negative samples or not. With negligible training over-head, our strategy consistently improves SimCLR, MoCo,
BYOL, SimSiam by 0.4% ∼ 2.0% classification accuracy on CIFAR-10, CIFAR-100, Tiny ImageNet and STL-10.
Superior results are also achieved on downstream detection and segmentation tasks when pre-trained on ImageNet-1K.
The main contributions of this paper are summarized as:
• To the best of our knowledge, this is the first work to investigate the problem of commonly used Random-Crop in contrastive learning. We propose Contrastive-Crop that is customized to generate better views for this task.
• In ContrastiveCrop, the semantic-aware localization is adopted to avoid most false positives and the center-suppressed sampling strategy is applied to reduce triv-ial positive pairs.
• ContrastiveCrop consistently outperforms Random-Crop with popular contrastive methods on a variety of datasets, showing its effectiveness and generality for
Siamese representation learning. 2.