Abstract
Low-dimensional parametric models are the de-facto standard in computer vision for intrinsic camera calibra-tion. These models explicitly describe the mapping between incoming viewing rays and image pixels. In this paper, we explore an alternative approach which implicitly models the lens distortion. The main idea is to replace the parametric model with a regularization term that ensures the latent dis-tortion map varies smoothly throughout the image. The pro-posed model is effectively parameter-free and allows us to optimize the 6 degree-of-freedom camera pose without ex-plicitly knowing the intrinsic calibration. We show that the method is applicable to a wide selection of cameras with varying distortion and in multiple applications, such as vi-sual localization and structure-from-motion. 1.

Introduction
The intrinsic calibration of a camera describes the map-ping between 2D pixels in the image and the corresponding rays in 3D. Knowing the intrinsic calibration, i.e. being able to project into the image (or vice versa), is a prerequisite for most geometric vision tasks. This mapping is usually pa-rameterized using a low-dimensional parametric model.
In this paper we propose to instead implicitly model the intrinsic calibration. More speciﬁcally we look at estimat-ing the 6 degree-of-freedom camera pose from given 2D-3D correspondences when the intrinsic calibration is un-known. Our approach assumes that the camera is central and radially-symmetric (i.e. the distortion only varies with the radial offset and not the angle) which is the case for most consumer cameras. The main idea is to replace the ex-plicit parametric model with a regularization term that force the underlying distortion map to be smooth. The proposed implicit distortion model allows us to essentially parameter-ize the intrinsic calibration in terms of the camera’s extrin-sic parameters. It is effectively parameter-free and gener-alizes to a wide selection of camera and lens combinations from well-behaved pinhole images to highly non-linear op-tical systems such as ﬁsheye or catadioptric cameras. The
Figure 1. Example of the point-wise focal lengths fi computed from (8) versus the image radii ri. Top: Fisheye lens. Middle: 45mm lens. Bottom: Catadioptric camera. Negative values for the focal lengths correspond to points behind the camera center. method can be further extended to leverage multiple images from the same camera and even be incorporated into a full bundle-adjustment, jointly reﬁning 3D points and cameras. 2.