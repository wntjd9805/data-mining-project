Abstract
Although provably robust to translational perturbations, convolutional neural networks (CNNs) are known to suffer from extreme performance degradation when presented at test time with more general geometric transformations of inputs. Recently, this limitation has motivated a shift in fo-cus from CNNs to Capsule Networks (CapsNets). However,
CapsNets suffer from admitting relatively few theoretical guarantees of invariance. We introduce a rigourous math-ematical framework to permit invariance to any Lie group of warps, exclusively using convolutions (over Lie groups), without the need for capsules. Previous work on group con-volutions has been hampered by strong assumptions about the group, which precludes the application of such tech-niques to common warps in computer vision such as afﬁne and homographic. Our framework enables the implemen-tation of group convolutions over any ﬁnite-dimensional
Lie group. We empirically validate our approach on the benchmark afﬁne-invariant classiﬁcation task, where we achieve ∼30% improvement in accuracy against conven-tional CNNs while outperforming most CapsNets. As fur-ther illustration of the generality of our framework, we train a homography-convolutional model which achieves supe-rior robustness on a homography-perturbed dataset, where
CapsNet results degrade. 1.

Introduction
Symmetry (reversible, composable change) is ubiquitous in the visual reality perceived by humans. It is therefore no surprise that symmetry now occupies a fundamental and in-creasingly well-understood role in machine learning, partic-ularly in computer vision [6, 5, 8, 33, 34, 31, 11, 22, 3, 32].
Invariance with respect to symmetries is particularly de-sirable in machine learning. Presently this is frequently achieved by training models on large volumes of symmetry-perturbed data. However, where there is a paucity of data or a need for explainability, architectural approaches such as
*lachlan.macdonald@adelaide.edu.au
Figure 1: Domains of applicability of our framework and existing convolutional frameworks.
CapsNets may be preferable [16, 29, 13].
CapsNets admit very few theoretical guarantees of in-variance [19]. However they are not the only means of achieving architectural invariance. Provable architectural invariance to translational symmetries is already pervasive in computer vision in the form of CNNs. The convolutions implemented in modern CNNs are, by deﬁnition, sums over responses between ﬁlter and feature, as the ﬁlter is trans-lated across different positions. Crucially, these operations are equivariant in the sense that translating the input fea-ture and then convolving is the same as ﬁrst convolving and then translating the response. Carefully designed downsam-pling operations [37] turn this equivariance into invariance, so that translation of the input signal does not change the re-sponse. The respect of CNNs for the spatial locality inher-ent in natural images, together with their equi/in-variance, constitute the inductive biases that have seen CNNs become the industry standard in many computer vision tasks.
More recently still, in the seminal paper by Cohen et. al. [6], it was observed that the translational convolutions of CNNs could be replaced by more general group convo-lutions that have for decades played an important role in mathematics, particularly in operator theory and noncom-mutative geometry [9, 17]. Given a group G of warps, a
G-convolution is a sum over warps belonging to G of re-sponses between a warped ﬁlter and feature; when G is the group of translations, one recovers ordinary convolution as 1
used in conventional CNNs. When built into neural net-works, these group convolutions achieve better weight shar-ing and superior performance on image classiﬁcation tasks than their conventional cousins, especially on datasets con-sisting of G-warped data [6, 5, 8, 33, 34, 31, 11, 22, 3, 32].
One aspect of group-convolutional neural networks which has received relatively little attention is their capacity for a mild form of out-of-distribution generalisation. Just as well-designed conventional CNNs perform well when tested on translationally perturbed data, a network with
G-convolutional layers and appropriate downsampling will theoretically perform well on G-perturbed data. As far as the authors are aware, the only place this problem has been studied is in [7], where spherical CNNs (in which G is the special orthogonal group) are trained on data on a sphere and tested on rotated data with excellent results. One of the primary reasons for this scarcity of study appears to be the lack of a sufﬁciently general theoretical framework. While
G-convolutions can be efﬁciently implemented for ﬁnite groups [6] and a small family of continuous (Lie) groups
[7, 5, 11], current techniques do not allow for the implemen-tation of G-convolutions for Lie groups that are common in natural images, such as the afﬁne and homography groups.
Should this hurdle be overcome, G-convolutions could con-stitute an effective tool for common computer vision prob-lems which circumvent the need for data augmentation and huge numbers of parameters.
Contributions: First, we introduce a rigourous mathe-matical framework using tools from topology to enable well-deﬁned convolutional networks over arbitrary ﬁnite-dimensional Lie groups. Up until now, convolutional net-works could only be implemented over ﬁnite groups or Lie groups with surjective exponential map, ruling out many natural warps. Second, we introduce tools from differential geometry and Lie theory to enable Markov Chain Monte-Carlo (MCMC) sampling from Haar measure for arbitrary
Lie groups. This sampling may be done in a scalable and easily parallelisable fashion, permitting fast approximation of group convolutions. Sampling from Haar measure had previously not been possible beyond a small family of Lie groups [21, 11]. Third and ﬁnally, we illustrate the va-lidity of our mathematical framework by testing it on the benchmark afﬁne-invariant image classiﬁcation task, where it outperforms the SOTA E(2)-equivariant CNN [31], and all but one of the existing CapsNet benchmarks. Finally, we demonstrate the generality of our theory by establishing a new benchmark on homography-invariant image classiﬁca-tion, which to the best of our knowledge has not previously been studied. On this benchmark, our method exhibits sta-ble performance, while that of the CapsNets for which we could obtain code [29, 19] degrades1.
Acknowledgements: We thank the reviewers for their sub-stantive critiques, which have helped to improve the paper. 2.