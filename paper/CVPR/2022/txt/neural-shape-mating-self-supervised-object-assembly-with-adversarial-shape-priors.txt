Abstract
Learning to autonomously assemble shapes is a crucial skill for many robotic applications. While the majority of existing part assembly methods focus on correctly posing semantic parts to recreate a whole object, we interpret as-sembly more literally: as mating geometric parts together to achieve a snug ﬁt. By focusing on shape alignment rather than semantic cues, we can achieve across category general-ization and scaling. In this paper, we introduce a novel task, pairwise 3D geometric shape mating, and propose Neural
Shape Mating (NSM) to tackle this problem. Given point clouds of two object parts of an unknown category, NSM learns to reason about the ﬁt of the two parts and predict a pair of 3D poses that tightly mate them together. In addi-tion, we couple the training of NSM with an implicit shape reconstruction task, making NSM more robust to imperfect point cloud observations. To train NSM, we present a self-supervised data collection pipeline that generates pairwise shape mating data with ground truth by randomly cutting an object mesh into two parts, resulting in a dataset that consists of 200K shape mating pairs with numerous object meshes and diverse cut types. We train NSM on the collected dataset and compare it with several point cloud registration methods and one part assembly baseline approach. Exten-sive experimental results and ablation studies under various settings demonstrate the effectiveness of the proposed algo-rithm. Additional material is available at: neural-shape-mating.github.io. 1.

Introduction
The human-built world is ﬁlled with objects that are shaped to ﬁt, snap, connect, or mate together. Reassem-bling a broken object and inserting a plug into a socket are both instances of shape mating. This kind of geometric mat-ing has many practical applications and appears in domains ranging from computer graphics [28], 3D design [6, 17], robotics [8, 46, 53, 54], and biology [41]. This paper intro-duces the problem of pairwise shape mating without known models, which is an integral subroutine in the broader prob-lem of multi-part geometric assembly including applications in robotics [27] and AR/VR [42].
There have been many attempts that learn shape-to-shape matching algorithms in application-speciﬁc domains: fur-niture assembly [15, 27, 29], object assembly [1, 30], and
object packing [46]. Most of these assembly algorithms operate under the assumption that each shape corresponds to a recognizable semantic object part [15, 27, 29]. While these results are promising, they rely heavily on semantic information (e.g., part segmentation), target shapes [29] as guidance, and ground-truth part pose annotations [15, 29].
This reliance makes these methods application speciﬁc, hard to scale, and difﬁcult to generalize.
In this paper, we consider shape mating from a geomet-ric perspective, without relying on semantic information or prespeciﬁed target shapes as guidance. Speciﬁcally, we study the pairwise 3D geometric shape mating task, where shape mating is done based solely on geometric cues. To achieve this, we propose Neural Shape Mating (NSM). As shown in Figure 1, given a pair of shapes in the form of point clouds with random intial poses, NSM predicts a plausible mating conﬁguration for them using geometric cues. The proposed task is challenging yet practical with mating being a subroutine in applications in robotics such as object kit-ting [8] and form ﬁtting [53] and in biology such as protein binding [41] (where the binding between proteins requires reasoning about the geometric ﬁt between two proteins).
We formulate the proposed task as a pose prediction prob-lem and develop a Transfomer-based module [44] that takes as input the point clouds of the two shapes, reasons about the ﬁt by attending to asymmetric correlations between lo-cal geometric cues, and predicts respective poses that bring them together. In addition, we adopt an adversarial learning scheme that learns shape priors for evaluating the plausibility of the generated shape mating conﬁgurations. Furthermore, to account for imperfect point cloud observations (e.g., noisy point clouds), we couple the training of NSM with an im-plicit shape reconstruction task [35, 40].
To train NSM, we present a self-supervised data collec-tion pipeline that generates pairwise shape mating data with ground truth by randomly cutting an object mesh with dif-ferent cut types into two parts. We collect object meshes from the Thingi10K [56], Google Scanned Objects [13], and
ShapeNet [5] datasets and apply our data generation algo-rithm to each object mesh. The resulting geometric shape mating dataset covers a diverse set of cut types applied to nu-merous object instances of 11 categories, combining a total of 200K shape pairs suitable for evaluating the proposed task.
We train NSM on the collected dataset in a self-supervised fashion and compare our method with several point cloud registration algorithms and one part assembly baseline ap-proach. Extensive experimental results and ablation studies under various settings demonstrate the effectiveness of the proposed algorithm.
Summary of contributions: 1. We introduce a novel task of pairwise geometric shape mating and propose Neural Shape Mating that predicts mating conﬁgurations using geometric cues. 2. We collect a large-scale geometric shape mating dataset for evaluation. 3. We compare NSM with several point cloud registration methods and one part assembly baseline approach. 4. Experimental results and analysis support our design choices and demonstrate the robustness of NSM when presented with realistically noisy observations. 2.