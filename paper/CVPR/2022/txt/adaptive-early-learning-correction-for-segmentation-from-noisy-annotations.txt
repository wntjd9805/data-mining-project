Abstract
Input
Ground Truth
Baseline
Baseline+ADELE
Deep learning in the presence of noisy annotations has been studied extensively in classiﬁcation, but much less in segmentation tasks.
In this work, we study the learning dynamics of deep segmentation networks trained on inaccu-rately annotated data. We observe a phenomenon that has been previously reported in the context of classiﬁcation: the networks tend to ﬁrst ﬁt the clean pixel-level labels during an “early-learning” phase, before eventually memorizing the false annotations. However, in contrast to classiﬁcation, memorization in segmentation does not arise simultaneously for all semantic categories. Inspired by these ﬁndings, we propose a new method for segmentation from noisy annota-tions with two key elements. First, we detect the beginning of the memorization phase separately for each category dur-ing training. This allows us to adaptively correct the noisy annotations in order to exploit early learning. Second, we incorporate a regularization term that enforces consistency across scales to boost robustness against annotation noise.
Our method outperforms standard approaches on a medical-imaging segmentation task where noises are synthesized to mimic human annotation errors. It also provides robustness to realistic noisy annotations present in weakly-supervised semantic segmentation, achieving state-of-the-art results on
PASCAL VOC 2012. 1 1.

Introduction
Semantic segmentation is a fundamental problem in com-puter vision. The goal is to assign a label to each pixel in an image, indicating its semantic category. Deep learn-ing models based on convolutional neural networks (CNNs) achieve state-of-the-art performance [9, 39, 51, 65]. These models are typically trained in a supervised fashion, which requires pixel-level annotations. Unfortunately, gathering pixel-level annotations is very costly, and may require signif-icant domain expertise in some applications [17, 32, 40, 48].
Furthermore, annotation noise is inevitable in some appli-*The ﬁrst two authors contribute equally, order decided by coin ﬂipping. 1Code is available at https://github.com/Kangningthu/
ADELE
Figure 1. Visualization of the segmentation results of the base-line method SEAM [52] and the baseline combined with the pro-posed ADaptive Early-Learning corrEction (ADELE). Our pro-posed ADELE improves segmentation quality. More examples can be found in Appendix A.1. cations. For example, in medical imaging, segmentation annotation may suffer from inter-reader annotation varia-tions [22, 63]. Learning to perform semantic segmentation from noisy annotations is thus an important topic in practice.
Prior works on learning from noisy labels focus on clas-siﬁcation tasks [33, 46, 57]. There are comparatively fewer works on segmentation, where existing works focus on de-signing noise-robust network architecture [50] or incorpo-rating domain speciﬁc prior knowledge [42]. We instead focus on improving the performance in a more general per-spective by studying the learning dynamics. We observe that the networks tend to ﬁrst ﬁt the clean annotations during an “early-learning” phase, before eventually memorizing the false annotations, thus jeopardizing generalization perfor-mance. This phenomenon has been reported in the context of classiﬁcation [33]. However, this phenomenon in seman-tic segmentation differs signiﬁcantly from its counterpart in classiﬁcation in the following ways:
• The noise in segmentation labels is often spatially de-pendent. Therefore, it is beneﬁcial to leverage spatial information during training.
• In semantic segmentation, early learning and memoriza-tion do not occur simultaneously for all semantic cate-gories due to pixel-wise imbalanced labels. Previous meth-ods [28,33] in noisy label classiﬁcation often assume class
(cid:38)(cid:68)(cid:87)(cid:72)(cid:74)(cid:82)(cid:85)(cid:92) (cid:47)(cid:68)(cid:69)(cid:72)(cid:79)(cid:86) (cid:69)(cid:76)(cid:85)(cid:71) (cid:83)(cid:72)(cid:85)(cid:86)(cid:82)(cid:81)(cid:3)(cid:3)(cid:3)(cid:71)(cid:82)(cid:74)(cid:3)(cid:3)(cid:3)(cid:3)(cid:86)(cid:82)(cid:73)(cid:68) (cid:69)(cid:76)(cid:78)(cid:72) (cid:44)(cid:80)(cid:68)(cid:74)(cid:72)(cid:86) (cid:49)(cid:82)(cid:76)(cid:86)(cid:92)(cid:3)(cid:54)(cid:72)(cid:74)(cid:80)(cid:72)(cid:81)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81) (cid:38)(cid:79)(cid:68)(cid:86)(cid:86)(cid:76)(cid:73)(cid:76)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81) (cid:80)(cid:82)(cid:71)(cid:72)(cid:79) (cid:38)(cid:36)(cid:48) (cid:51)(cid:76)(cid:91)(cid:72)(cid:79)(cid:16)(cid:90)(cid:76)(cid:86)(cid:72) (cid:76)(cid:81)(cid:76)(cid:87)(cid:76)(cid:68)(cid:79) (cid:68)(cid:81)(cid:81)(cid:82)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86) (cid:51)(cid:76)(cid:91)(cid:72)(cid:79)(cid:16)(cid:90)(cid:76)(cid:86)(cid:72)(cid:3)(cid:81)(cid:82)(cid:76)(cid:86)(cid:92) (cid:68)(cid:81)(cid:81)(cid:82)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:76)(cid:81)(cid:74)(cid:3)(cid:76)(cid:80)(cid:68)(cid:74)(cid:72)(cid:86) (cid:54)(cid:72)(cid:74)(cid:80)(cid:72)(cid:81)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81) (cid:80)(cid:82)(cid:71)(cid:72)(cid:79)
Figure 2. A prevailing pipeline for training WSSS. We aim to improve the segmentation model from noisy annotations. balanced data and thus either detecting or handling wrong labels for different classes at the same time.
• The annotation noise in semantic segmentation can be ubiquitous (all examples have some errors) while the state-of-the-art methods in classiﬁcation [28,33,67] assume that some samples are completely clean.
Inspired by these observations, we propose a new method,
ADELE (ADaptive Early-Learning corrEction), that is de-signed for segmentation from noisy annotations. Our method detects the beginning of the memorization phase by monitor-ing the Intersection over Union (IoU) curve for each category during training. This allows it to adaptively correct the noisy annotations in order to exploit early-learning for individual classes. We also incorporate a regularization term to promote spatial consistency, which further improves the robustness of segmentation networks to annotation noise.
To verify the effectiveness of our method, we consider a setting where noisy annotations are synthesized and con-trollable. We also consider a practical setting – Weakly-Supervised Semantic Segmentation (WSSS), which aims to perform segmentation based on weak supervision signals, such as image-level labels [24, 54], bounding box [11, 44], or scribbles [30]. We focus on a popular pipeline in WSSS.
This pipeline consists of two steps (See Figure 2). First, a classiﬁcation model is used to generate pixel-level annota-tions. This is often achieved by applying variations of Class
Activation Maps (CAM) [66] combined with post-processing techniques [3, 25]. Second, these pixel-level annotations are used to train a segmentation model (such as deeplabv1 [8]).
Generated by a classiﬁcation model, the pixel-wise anno-tations supplied to the segmentation model are inevitably noisy, thus the second step is indeed a noisy segmentation problem. We therefore apply ADELE to the second step. In summary, our main contributions are:
• We analyze the behavior of segmentation networks when trained with noisy pixel-level annotations. We show that the training dynamics can be separated into an early-learning and a memorization stage in segmentation with annotation noise. Crucially, we discover that these dynam-ics differ across each semantic category.
• We propose a novel approach (ADELE) to perform se-mantic segmentation with noisy pixel-level annotations, which exploits early learning by adaptively correcting the annotations using the model output.
• We evaluate ADELE on the thoracic organ segmentation task where annotations are corrupted to resemble human errors. ADELE is able to avoid memorization, outper-forming standard baselines. We also perform extensive experiments to study ADELE on various types and levels of noises.
• ADELE achieves the state of the art on PASCAL VOC 2012 for WSSS. We show that ADELE can be combined with several different existing methods for extracting pixel-level annotations [3, 14, 52] in WSSS, consistently improv-ing the segmentation performance by a substantial margin. 2. Methodology 2.1. Early learning and memorization in segmenta-tion from noisy annotations
In a typical classiﬁcation setting with label noise, a subset of the images are incorrectly labeled. It has been observed in prior works that deep neural networks tend to ﬁrst ﬁt the training data with clean labels during an early-learning phase, before eventually memorizing the examples with in-correct labels [4, 33]. Here, we show that this phenomenon also occurs in segmentation when the available pixel-wise an-notations are noisy (i.e. some of the pixels are incorrect). We consider two different problems. First, segmentation in med-ical imaging, where annotation noise is mainly due to human error. Second, the annotation noise in weakly-supervised semantic segmentation due to the bias of classiﬁcation mod-els, as they mostly focus on discriminative regions, and the post-processing errors may result in systematic over or under segmentation.
Given noisy annotations for which we know the ground truth, we can quantify the early-learning and memorization phenomena by analyzing the model output on the pixels that are incorrectly labeled:
• early learning IoUel: We quantify early learning us-ing the overlap (measured in terms of the Intersection over Union (IoU) metric) between the outputs and the corresponding ground truth label on the pixels that are incorrectly labeled, denoted by IoUel.
• memorization IoUm: We quantify memorization using the overlap (measured in IoU) between the CNN outputs and the incorrect labels, denoted by IoUm.
Figure 3 demonstrates the phenomena of early-learning and memorization on a randomly corrupted CT-scan segmen-tation dataset (SegTHOR [27]). We analyze the learning
Figure 3. We visualize the effect of early learning (IoUel, green curves) and memorization (IoUm, red curves) on incorrectly annotated pixels with (solid lines) and without (dashed lines) ADELE for each foreground category of a medical dataset SegThor [27]. The model is a UNet trained with noisy annotations that mimic human errors. IoUel is the IOU between the model output and the ground truth computed over the incorrectly-labeled pixels. IoUm is the IOU between the model output and the incorrect annotations. For all classes,
IoUm increases substantially as training proceeds because the model gradually memorizes the incorrect annotations. This occurs at different speeds for different categories. In contrast, IoUel ﬁrst increases during an early-learning stage where the model learns to correctly segment the incorrectly-labeled pixels, but eventually decreases as memorization occurs. Like memorization, early-learning also happens at varying speeds for the different semantic categories. See Figure 10 in Appendix for the plot on PASCAL VOC. curve on the incorrectly-annotated pixels during the training process. The plots show the IoUm (dashed red line) and
IoUel (dashed green line) at different training epochs. For all classes, the IoU between the output and the incorrect labels (IoUm) increases substantially as training proceeds because the model gradually memorizes the incorrect annota-tions. This memorization process occurs at varying speeds for different semantic categories (compare heart and Aorts with Traches or Esophagus in the SegThor dataset). The IoU between the output and the correct labels (IoUel) follows a completely different trajectory: it ﬁrst increases during an early-learning stage where the model learns to correctly seg-ment the incorrectly-labeled pixels, but eventually decreases as memorization occurs (for the WSSS dataset, we observe a very similar phenomenon shown in Figure 11 in the Ap-pendix). Like memorization, early-learning also happens at varying speeds for the different semantic categories.
Figure 4 illustrates the effect of early learning and memo-rization on the model output. In the medical-imaging appli-cation, the noisy annotations (third column) are synthesized to resemble human annotation errors which either miss or encompass the ground truth regions (compare to second col-umn). Right after early learning, these regions are identiﬁed by the segmentation model (fourth column), but after memo-rization the model overﬁts to the incorrect annotations and forgets how to segment these regions correctly (ﬁfth column).
Similar effects are observed in WSSS, in which the noisy an-notations generated by the classiﬁcation model are missing some object regions, perhaps because they are not particu-larly discriminative (e.g. the body of the dog, cat and people in the ﬁrst, second, and fourth row respectively, or the upper half of the bus in the third row). The segmentation model
ﬁrst identify these regions but eventually overﬁts to the in-correct annotations. Our goal in this work is to modify the training of segmentation models on noisy annotations in or-der to prevent memorization. This is achieved by combining two strategies described in the next two sections. Figure 3 and Figure 4 shows that the resulting method substantially mitigates memorization (solid red lines) and promotes con-tinued learning beyond the early-learning stage (solid green lines). 2.2. Adaptive label correction based on early-learning
The early-learning phenomenon described in the previous section suggests a strategy to enhance segmentation models: correcting the annotations using the model output. Simi-lar ideas have inspired works in classiﬁcation with noisy labels [33, 37, 46, 60]. However, different from the classiﬁca-tion task where the noise is mainly sample-wise, the annota-tion noise is ubiquitous across examples and distributed in a pixel-wise manner. There is a key consideration for this approach to succeed: the annotations cannot be corrected too soon, because this degrades their quality. Determining when to correct the pixel-level annotations using the model output is challenging for two reasons:
• Correcting all classes at the same time can be sub-optimal.
• During training, we do not have access to the performance of the model on ground-truth annotations (otherwise we would just use them to train the model in the ﬁrst place!).
To overcome these challenges we propose to update the annotations corresponding to different categories at different times by detecting when early learning has occurred and memorization is about to begin using the training perfor-mance of the model.
In our experiments, we observe that the segmentation performance on the training set (measured by the IoU be-Input
Ground truth
Noisy annotations
Model output after early learning
Model output after memorization
Corrected annotations in
ADELE
Figure 4. Visual examples illustrating the early-learning and memorization phenomena. For several images in a medical dataset Segthor [27] (top tow rows) and the WSSS dataset VOC 2012 [13] (bottom four rows), we show the ground-truth annotations (second column), noisy annotations (third column) obtained by a synthetic corruption process for the medical data and by the classiﬁcation-based SEAM [52] model for WSSS, the output of a model segmentation model trained on the noisy annotations after early learning (fourth column), and the output of the same model after memorization (ﬁfth column). The model for the medical dataset is a UNet. The WSSS model is a standard DeepLab-v1 network trained with the SEAM annotations. As suggested by the graphs in Figure 3 after early learning the model corrects some of the annotation errors, but these appear again after memorization. ADELE is able to correct the labels leveraging the early learning output, thereby avoiding memorization (sixth column). We set the background color to light gray for ease of visualization. tween the model output and the noisy annotations) improves rapidly during early learning, and then much more slowly during memorization (see the rightmost graph in Figure 5).
We propose to use this deceleration to decide when to update the noisy annotations. To estimate the deceleration we ﬁrst
ﬁt the following exponential parametric model to the training
IoU using least squares:
  and c 0 are ﬁtting parameters. Then we compute the derivative f 0(t) of the parametric model with respect to t at t = 1 and at the current iteration.2 For each semantic category, the annotations are corrected when the relative change in derivative is above a certain threshold r, i.e. when where t represents training time and 0 < a
 
⇣
⌘ f (t) = a 1 tc e  b
·
, (1)
| f 0(1) f 0(t)
  f 0(1)
|
|
|
> r, (2) 1, b 0,
 
 2The derivative is given by f 0(t) = abce  btc tc 1.
 
Esophagus
Heart
Trachea
Aorta
Figure 5. Illustration of the proposed curve ﬁtting method to decide when to begin label correction in ADELE (Results on SegThor). First column: On the top, we plot the IoU between the model predictions and the initial noisy annotations for the same model used in Figures 3 and 4 and the corresponding ﬁt with the parametric model in Equation 1. The label correction beginning iteration is based on the relative slope change of the ﬁtted curve. The bottom image shows the label correction times for different semantic categories, showing that they are quite different. Second and third columns: the green lines show the IoUel for different categories Esophagus, Heart, Trachea and
Aorta. The IoUel equals the IoU between the model output and the ground truth computed over the incorrectly-labeled pixels, and therefore quantiﬁes early-learning. The label correction begins close to the end of the early-learning phase, as desired. More result in section A.1 in
Appendix shows that this also occurs for VOC 2012. which we set to 0.9, and at every subsequent epoch. We only correct annotations for which the model output has conﬁdence above a certain threshold ⌧ , which we set to 0.8.
A detailed description about the label correction is attached in the Appendix B. As shown in Table 2, adaptive label correction based on early learning improves segmentation models in the medical-imaging applications and WSSS, both on its own and in combination with multiscale-consistency regularization. Figure 4 shows some examples of annotation corrections (rightmost column). 2.3. Multiscale consistency
As we previously mentioned, model outputs after early-learning are used to correct noisy annotations. Therefore, the quality of model outputs is crucial for the effectiveness of the proposed method. Following a common procedure that has shown to result in more accurate segmentation from the outputs [31, 58], we average model outputs correspond-ing to multiple rescaled copies of inputs to form the ﬁnal segmentation, and use them to correct labels. Furthermore, we incorporate a regularization that imposes consistency of the outputs across multi-scales and is able to make av-eraged outputs more accurate (See the right graph of Fig-ure 6). This idea is inspired by consistency regularizations, a popular concept in the semi-supervised learning litera-ture [6, 15, 23, 26, 36, 43, 47] that encourages the model to produce predictions that are robust to arbitrary semantic-preserving spatial perturbations. In segmentation with noisy annotation, we introduce the consistency loss to provide an extra supervision signal to the network, preventing the network from only training on the noisy segmentation anno-tations, and overﬁtting to them. This regularization effect is also observed in the literature of classiﬁcation with label noise [10, 28]. Since our method uses the network predic-tions to correct labels, it is crucial to avoid overﬁtting to the noisy segmentation. 0.7, no scaling, and upscaling
To be more speciﬁc, let s be the number of scaling operations. In our experiments we set s = 3 (downscal-1.5). We denote by ing
⇥
⇥ pk(x), 1 s, the model predictions for an input x rescaled according to these operations (see Figure 6). We
LMultiscale to promote propose to use a regularization term consistency between pk(x), 1 s, and the average k
 q(x) = 1 s s k=1 pk(x):


 k
P
LMultiscale(x) =
  1 s s
KL (pk(x) q(x)) , (3) k
Xk=1 where KL denotes the Kullback-Leibler divergence. The term is only applied to the input x where the maximum entry of q(x) is above a threshold ⇢ (equal to 0.8 for all exper-iments). The regularization is weighted by a parameter   (set to one in all experiments) and then combined with a cross-entropy loss based on the available annotations. As shown in Tables 2, with multiscale consistency regulariza-tion, adaptive label correction further improves segmentation performance in both medical-imaging applications and the
Figure 6. Left: In the proposed multiscale-consistency regularization, rescaled copies of the same input (here upscaled 1.5 and downscaled 0.7) are fed into the segmentation model. The outputs (˜p1, p2 and ˜p3) are rescaled to have the same dimensionality (p1, p2 and p3).
⇥
Regularization promotes consistency between these rescaled outputs and their elementwise average q. Right: Multi-scale consistency regularization leads to more accurate corrected annotations (results on SegThor, results for VOC 2012 can be found in Figure 12).
⇥
WSSS. 3.