Abstract
Vehicle trajectory prediction is nowadays a fundamen-tal pillar of self-driving cars. Both the industry and re-search communities have acknowledged the need for such a pillar by providing public benchmarks. While state-of-the-art methods are impressive, i.e., they have no off-road pre-diction, their generalization to cities outside of the bench-mark remains unexplored. In this work, we show that those methods do not generalize to new scenes. We present a method that automatically generates realistic scenes caus-ing state-of-the-art models to go off-road. We frame the problem through the lens of adversarial scene generation.
The method is a simple yet effective generative model based on atomic scene generation functions along with physical constraints. Our experiments show that more than 60% of existing scenes from the current benchmarks can be modi-fied in a way to make prediction methods fail (i.e., predict-ing off-road). We further show that the generated scenes (i) are realistic since they do exist in the real world, and (ii) can be used to make existing models more robust, yielding 30 − 40% reductions in the off-road rate. The code is avail-able online: https://s-attack.github.io/. 1.

Introduction
Vehicle trajectory prediction is one of the main building blocks of a self-driving car, which forecasts how the future might unfold based on the road structure (i.e., the scene) and the traffic participants. State-of-the-art models are com-monly trained and evaluated on datasets collected from a few cities [14, 19, 23]. While their evaluation has shown impressive performance, i.e., almost no off-road prediction, their generalization to other types of possible scenes e.g., other cities, remains unknown. Figure 1 shows a real-world example where a state-of-the-art model reaching zero off-road in the known benchmark [19] failed in South St, New
∗ Equal contribution as the first authors.
Figure 1. A real-world place (location) in New York where the trajectory prediction model (here [32]) fails. We find this place by retrieving real-world locations which resemble our conditional generated scenes for the prediction model.
York, USA. Since collecting and annotating data of all real-world scenes is not a viable and affordable solution, we present a method that automatically investigates the robust-ness of vehicle trajectory prediction to the scene. We tackle the problem through the lens of realistic adversarial scene generation.
Given an observed scene, we want to generate a realis-tic modification of it such that the prediction models fail in.
Having an off-road prediction is a clear indication of a fail-ure in the the model’s scene reasoning and has been used in some previous works [8, 16, 36, 38]. To find a realistic example where the models go off-road, the huge space of possible scenes should be explored. One solution is data-driven generative models that mimic the distribution of a dataset [35]. Yet, they do not essentially produce realistic scenes due to the possible artifacts. Moreover, they will
represent a portion of real-world scenes as they cannot gen-erate scenes beyond what they have observed in the dataset (cannot extrapolate). We therefore suggest a simple yet effi-cient alternative. We show that it is possible to use a limited number of simple functions for transforming the scene into new realistic but challenging ones. Our method can explic-itly extrapolate to new scenes.
We introduce atomic scene generation functions where given a scene in the dataset, the functions generate multi-ple new ones. These functions are chosen such that they can cover a range of realistic scenes. We then choose the scenes where the prediction model produces an off-road trajectory. Using three state-of-the-art trajectory predic-tion models trained on Argoverse public dataset [19], we demonstrate that more than 60% of the existing scenes in the dataset can be modified in such a way that it will make state-of-the-art methods fail (i.e., predict off-road). We con-firm that the generated scenes are realistic by finding real-world locations that partially resemble the generated scenes.
We also demonstrate off-road predictions of the models in those locations. To this end, we extract appropriate fea-tures from each scene and use image retrieval techniques to search public maps [1]. We finally show that these gener-ated scenes can be used to improve the robustness of the models.
Our contributions are fourfold:
• we highlight the need for a more in-depth evaluation of the robustness of vehicle trajectory prediction models;
• our work proposes an open-source evaluation frame-work through the lens of realistic adversarial scene generation by promoting an effective generative model based on atomic scene generation functions;
• we demonstrate that our generated scenes are realistic by finding similar real-world locations where the mod-els fail;
• we show that we can leverage our generated scenes to make the models more robust. scene [10, 17, 18, 25, 40]. Carnet [45] used attention mech-anism to determine the scene regions that were attended more, leading to an interpretable solution. Some recent work showed that scene can be represented by vector for-mat instead of images [7, 24, 32, 47]. To further improve the reasoning of the model and generate predictions admissible with respect to the scene, use of symmetric cross-entropy loss [38, 41], off-road loss [8], and REINFORCE loss [16] have been proposed. Despite all these efforts, there has been limited attention to assess the performance of trajectory pre-diction models on new scenes. Our work proposes a frame-work for such assessments.
Evaluating self-driving systems. Self-driving cars deal with dynamic agents nearby and the static environment around. Several works studied the robustness of self-driving car modules with respect to the status of dynamic agents on the road, e.g., other vehicles. Some previous works change the behavior of other agents in the road to act as attack-ers and evaluate the model’s performance with regards to the interaction with other agents [3, 4, 20, 26, 28, 30, 43, 52].
Others directly modify the raw sensory inputs to change the status of the agents in an adversarial way [15, 49, 51, 53].
In addition to the dynamic agents, driving is highly de-pendant on the static scene around the vehicle. The scene understanding of the models can be assessed by modifying the input scene. Previous works modify the raw sensory in-put by changing weather conditions [33, 50, 54], generating adversarial drive-by billboards [29, 55], and adding care-fully crafted patches/lines to the road [12, 46]. These works have not changed the shape of the scene, i.e., the structure of the road. In contrast, we propose a conditional scene gen-eration method to assess the scene reasoning capability of trajectory prediction models. Also our approach is differ-ent from data-driven scene generation based on graph [35] or semantic maps [44]. Data-driven generative models are prone to have artifacts and cannot extrapolate beyond the training data. Ours is an adversarial one which can extrap-olate to new scenes. 2.