Abstract
Continuous normalizing flows (CNFs) construct invert-ible mappings between an arbitrary complex distribution and an isotropic Gaussian distribution using Neural Ordi-nary Differential Equations (neural ODEs). It has not been tractable on large datasets due to the incremental complex-ity of the neural ODE training. Optimal Transport theory has been applied to regularize the dynamics of the ODE to speed up training in recent works. In this paper, a tempo-ral optimization is proposed by optimizing the evolutionary time for forward propagation of the neural ODE training.
In this appoach, we optimize the network weights of the
CNF alternately with evolutionary time by coordinate de-scent. Further with temporal regularization, stability of the evolution is ensured. This approach can be used in conjunc-tion with the original regularization approach. We have ex-perimentally demonstrated that the proposed approach can significantly accelerate training without sacrifying perfor-mance over baseline models. 1.

Introduction
As an impressive example of unsupervised learning, deep generative models have exhibited powerful modeling performance across a wide range of tasks, including varia-tional autoencoders (VAE) [1], Generative Adversarial Nets (GAN) [2], autoregressive models [3] and Flow-based mod-els [4, 5].
Generative models based on normalizing flows have been recently realized with great success in the problems of probabilistic modeling and inference. Normalizing flows
[6] provide a general and extensible framework for mod-elling highly complex and multimodal distributions through a series of differentiable and invertible transformations.
Since these transformations are invertible, the framework of
*Equal contribution. Order determined by coin toss.
†Corresponding author: Delu Zeng. normalizing flows allows for powerful exact density estima-tion by computing the Jacobian determinant [7]. Like a fluid flowing through a set of tubes, the initial density ‘flows’ through the sequence of invertible mappings by repeatedly applying the rule for change of variables until a desired probability at the end of this sequence is obtained. Normal-izing flows are an increasingly active area of machine learn-ing research. Applications include image generation [5, 8], noise modelling [9], video generation [10], audio genera-tion [11–13], graph generation [14], reinforcement learning
[15–17], computer graphics [18], and physics [19–23]. A key strength of normalizing flows is their expressive power as generative models due to its ability to approximate the posterior distribution arbitrarily, while maintaining explicit parametric forms.
Thanks to recent advances in deep generative architec-tures using maximum likelihood estimation and approxi-mate approach like VAE for large-scale probabilistic mod-els, continuous normalizing flows (CNF) obtained by solv-ing an ordinary differential equations (ODE) were later de-veloped in neural ODEs [24]. Neural ODEs form a family of models that approximate the ResNet architecture by us-ing continuous-time ODEs. The neural ODE’s dynamics can be chosen almost arbitrarily while ensuring invertibil-ity. The jump to continuous-time dynamics affords a few computational benefits over its discrete-time counterpart, namely the presence of a trace in place of a determinant in the evolution formulae for the density, as well as the ad-joint method for memory-efficient backpropagation. Due to their desirable properties, such as invertibility and parame-ter efficiency, neural ODEs have attracted increasing atten-tion recently. For example, Grathwohl et al [25] proposed a neural ODE-based generative model—the FFJORD—to solve inverse problems; Quaglino et al [26] used a higher-order approximation of the states in a neural ODE,and pro-posed the SNet to accelerate computation. Further algo-rithmic improvements to the framework were presented by
YAN et al [27] and Anumasa et al [28], exploring the ro-bustness properties of neural ODEs. Effective neural ODE
architectures remain the subject of ongoing research — see for example [29–31].
Training neural ODEs consists of minimizing a loss function over the network weights subject to the nonlinear
ODE constraint. To some extent, training can be seen as an optimal control problem. Applying optimal control theory to improve the training has become an appealing research area and more attention has been paid in recent years. For example, Pontryagin’s maximum principle has been used to efficiently train networks with discrete weights [32], multi-grid methods have been proposed to parallelize forward propagation during training [33], and analyzing the con-vergence on the continuous and discrete level has led to novel architectures [34]. Our goal in this paper is to extend this discussion by optimizing the integral interval of ODEs and perform similar experiments for continuous normaliz-ing flows using neural ODEs from a novel perspective.
In summary, our contributions are as follows:
• Firstly, we are the first to propose an improved algo-rithm based on temporal optimization, which is simple yet effective in significantly boosting the training of neural ODEs. We find that the temporal optimization can attain competitive performance compared to origi-nal models but with significantly less training time.
• Secondly, we introduce temporal regularization and clipping function, which effectively stablize the train-ing process and do not result in degradation of model performance.
• Moreover, we optimize the stopping time T alternately with the parameters θ of the movement speed f , and end up with more compatible T and θ to cause less number of function evaluation (NFE), and also obtain the decreasing training loss. 2. Preliminaries 2.1.