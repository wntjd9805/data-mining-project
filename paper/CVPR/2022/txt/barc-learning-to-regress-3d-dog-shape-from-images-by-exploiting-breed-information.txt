Abstract
Our goal is to recover the 3D shape and pose of dogs from a single image. This is a challenging task because dogs exhibit a wide range of shapes and appearances, and are highly articulated. Recent work has proposed to di-rectly regress the SMAL animal model, with additional limb scale parameters, from images. Our method, called BARC (Breed-Augmented Regression using Classiﬁcation), goes beyond prior work in several important ways. First, we modify the SMAL shape space to be more appropriate for representing dog shape. But, even with a better shape model, the problem of regressing dog shape from an image is still challenging because we lack paired images with 3D ground truth. To compensate for the lack of paired data, we formulate novel losses that exploit information about dog breeds. In particular, we exploit the fact that dogs of the same breed have similar body shapes. We formulate a novel breed similarity loss consisting of two parts: One term encourages the shape of dogs from the same breed to be more similar than dogs of different breeds. The sec-ond one, a breed classiﬁcation loss, helps to produce rec-ognizable breed-speciﬁc shapes. Through ablation studies, we ﬁnd that our breed losses signiﬁcantly improve shape accuracy over a baseline without them. We also com-pare BARC qualitatively to WLDO with a perceptual study and ﬁnd that our approach produces dogs that are signif-icantly more realistic. This work shows that a-priori in-formation about genetic similarity can help to compensate for the lack of 3D training data. This concept may be applicable to other animal species or groups of species.
Our code is publicly available for research purposes at https://barc.is.tue.mpg.de/. 1.

Introduction
Learning to infer 3D models of articulated and non-rigid objects from 2D images is challenging. For the case of hu-mans, recent methods leverage detailed parametric models of human body shape and pose, like SMPL [10]. Such mod-els have been learned from thousands of high-resolution 3D scans of people in varied poses. This approach cannot be
replicated for most animal species because they are difﬁ-cult, or even impossible, to scan in a controlled environ-ment. Moreover, paired training data of animals with known 3D shape is even rarer. To make progress, we must leverage side information that can be easily obtained, yet constrains the task of 3D shape and pose estimation.
Speciﬁcally,
The 3D reconstruction of animal shape and pose has ranging from biology and many real-life applications, the non-biomechanics to conservation. invasive capture of 3D body shape supports morphology and health-from-shape analysis. Markerless motion capture allows 3D motion analysis for animals that it is not possi-ble to capture in a lab setting. Here we focus on dogs as a rich, representative, test case. Dogs exhibit a wide range of shapes, are non-rigid, and have complex articulation. Con-sequently, dogs are challenging and representative of many other animals.
Here, our goal is to learn to estimate a dog’s 3D shape and pose from a monocular, uncontrolled image. Given the lack of 3D training data, we train a regression network with 2D supervision, in the form of keypoints and silhouettes.
With only such 2D information, the problem is, however, heavily under-constrained: many 3D shapes can explain the 2D image evidence equally well. To make the task well-posed, we need additional, prior information. Here we ex-plore a novel source of a-priori knowledge: a dog’s shape is determined, in part, by its breed. Even a trained amateur can recognize the breed by looking at a dog’s shape (and appearance).
Dogs are a particularly interesting case to explore the role of breeds because of their large variety. Dogs have been domesticated and bred for a long time, for diverse purposes such as companionship, hunting, or herding, but also racing, pulling sleds, ﬁnding trufﬂes, etc. Consequently, breeders have selected for a range of traits including body shape (as well as temperament, appearance, etc.) which has led to a large number of breeds with very different characteristics.
A recent analysis of the dog genome illustrates the relation-ship between different breeds that exist today [5]. Breeds are grouped into clades, often with high shape similarity within a clade. Figure 2 shows a cladogram of 161 domes-tic dog breeds [5].
Here, we explore the use of genetic side information, in the form of breed labels, to train a regressor that infers 3D dog shape from 2D images. Speciﬁcally, we train a novel neural network called BARC, for “Breed-Augmented Re-gression using Classiﬁcation.” We follow the approach of regressing a parametric 3D shape model directly from im-age pixels, which is common in human pose and shape es-timation. Here, we use the SMAL animal model [32] to deﬁne the kinematic chain and mesh template. We extend
SMAL in several ways to be a better foundation for learning about dog shape, this includes adding limb scale factors and
Figure 2. Cladogram of domestic dog breeds. The diagram rep-resents clustering according to genetic similarity. Reproduced from [5]. extending its shape space with additional 3D dog shapes.
To solve the problem of estimating dog shape from im-ages, we make several contributions. (1) We propose a novel neural network architecture to regress 3D dog shape and 3D pose from images. (2) To make training feasi-ble from 2D silhouettes and keypoints, we exploit the fact that 2D images of the same breed should produce similar 3D shapes, while different breeds (mostly) have different shapes. With this assumption, we impose classiﬁcation and triplet losses on the training images, which come with breed labels. (3) As a result, we learn a breed-aware latent shape space, in which we can identify breed clusters and relation-ships in agreement with the cladogram in Fig. 2. (4) Op-tionally, we show how to exploit 3D models, if available for some breeds.
Although we use one of the largest dog datasets in the literature, the large number of dog breeds (in our case 120) means there are only a few images per breed. One can inter-pret our method as learning a common shape manifold for all dogs (as not enough examples are available per breed), while using the breed labels to locally regularize it. To our knowledge, this is the ﬁrst method that exploits breed infor-mation to regress the 3D shape of animals from images.
We train the network on the Stanford Extra (StanExt) [1, 9] training set, which we extend with eye, withers and throat keypoints, and test our approach on the StanExt test set.
We evaluate on this dataset of 120 different dog breeds and show that we learn a latent shape space for dogs in which more closely related dogs are in closer proximity (Fig. 3).
Through ablation studies, we evaluate the impact of differ-ent types of breed information and ﬁnd that each loss leads to a signiﬁcant improvement in shape accuracy. We evalu-ate accuracy with standard 2D measures like PCK and IOU, but these do not necessarily reﬂect 3D accuracy. Conse-quently, we create a dataset of 3D dogs to evaluate shape of corresponding breeds. This allows a quantitative evaluation, and we signiﬁcantly outperform the prior art (WLDO [1]).
Finally, to evaluate shape estimates for in-the-wild images, we use a perceptual study to compare methods. We ﬁnd that our ﬁnal model is more realistic than ablated versions or WLDO. 2.