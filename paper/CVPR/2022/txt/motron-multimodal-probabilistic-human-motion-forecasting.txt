Abstract
Autonomous systems and humans are increasingly shar-ing the same space. Robots work side by side or even hand in hand with humans to balance each other’s limi-tations. Such cooperative interactions are ever more so-phisticated. Thus, the ability to reason not just about a human’s center of gravity position, but also its granular motion is an important prerequisite for human-robot inter-action. Though, many algorithms ignore the multimodal nature of humans or neglect uncertainty in their motion forecasts. We present Motron, a multimodal, probabilistic, graph-structured model, that captures human’s multimodal-ity using probabilistic methods while being able to out-put deterministic maximum-likelihood motions and corre-sponding conﬁdence values for each mode. Our model aims to be tightly integrated with the robotic planning-control-interaction loop; outputting physically feasible human mo-tions and being computationally efﬁcient. We demonstrate the performance of our model on several challenging real-world motion forecasting datasets, outperforming a wide array of generative/variational methods while providing state-of-the-art single-output motions if required. Both us-ing signiﬁcantly less computational power than state-of-the art algorithms. 1.

Introduction
The key desideratum of autonomous systems is to pro-vide added-value to humans while ensuring safety. Tradi-tionally, safety aspects limit such robots to low-risk tasks with minimal human interaction. An understanding of hu-mans and their distribution of feasible anticipated move-ment is key to develop safe, risk-aware human-interactive autonomous systems. Such systems could operate in closer proximity to humans, performing tasks involving higher levels of interaction, providing enhanced added value.
However, capturing the complexity of human motion in a computational model is challenging due to the multi-tude of continuous movement possibilities (multimodality), even within ﬁxed boundaries of physical limitations. Tra-ditionally, over-conservative systems rely solely on those constraints to ensure safety, while predictive single-motion-output methods discard the potential of many high-level fu-Figure 1. Two examples of multiple possible poses at a given pre-diction time weighted by their probability. Left: Start of high vari-ance jumping motion. Right: Landing from jump. Lower body is predicted with low uncertainty as feet will come to a stop during landing. Our parametric output distribution captures the full mul-timodal uncertainty in human motion; enabling subsequent evalu-ation of samples, individual modes, or most-likely motion as well as their respective conﬁdence values. tures in favor of a single possible motion.
In contrast to such deterministic regressors, Monte-Carlo method models aim to produce samples of human future motion. However, for different reasons (e.g., simulation purposes), they prioritize generative diversity over repre-senting actual plausible motions. For robotic use cases, we aim for samples to represent the underlying distribution of possible motions; or even better a parametric description thereof (Fig. 1).
Both, single-output and sampled, human motion predic-tions have been developed independently to maximize their strengths in accuracy and diversity. Still, many of them have been developed without directly accounting for real-world robotic use cases; they settle for diversity instead of accu-racy, ignore physical boundaries, and are computationally too expensive. We target robotic use cases, where predic-tions are used in a control loop. As such, a model has to capture the underlying distribution of possible human mo-tions without being over-conﬁdent or over-diverse within an imminent time horizon; combining and balancing the desiderata of both research strands. In consequence, we are interested in developing a human motion prediction model that (I) represents the inherent multimodal structure of hu-man motion; (II) accurately captures humans’ probabilistic
and diverse nature while obeying rigid skeleton constraints; (III) by directly incorporating structural information of the human skeleton; (IV) while being able to deal with imper-fect data; (V) outputting the maximum amount of informa-tion for the use of subsequent systems.
To achieve those desiderata, our contribution is three-fold: First, we describe a new efﬁcient way to model graph-structured problems where nodes have a ﬁxed semantic class, usable for generic graph-structured problems. Sec-ondly, we present Motron, which uniquely uses a probabilis-tic output structure based on the Concentrated Gaussian dis-tribution in SO3 and a parallel weight sharing approach in-corporating the skeleton’s structure. It is designed to mirror the multimodal and uncertain nature of humans. Motron’s
ﬂexible output structure is designed to serve downstream robotic modules such as motion planning, decision mak-ing, and control. Finally, we evaluate our model on the fulﬁllment of our desiderata using single-output metrics and metrics based on samples; combining both research strands.
We outperform an extensive selection of Monte-Carlo based motion prediction methods while showing state-of-the-art performance on single-output evaluation procedures using a variety of metrics and datasets. Our contributions are sub-stantiated by a thorough ablation study. We further show that Motron can deal with occluded data often present in real-world applications by including the additional uncer-tainty in its output. 2.