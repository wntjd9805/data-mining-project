Abstract
Equivariance has been a long-standing concern in vari-ous fields ranging from computer vision to physical model-ing. Most previous methods struggle with generality, sim-plicity, and expressiveness — some are designed ad hoc for specific data types, some are too complex to be accessible, and some sacrifice flexible transformations. In this work, we propose a novel and simple framework to achieve equiv-ariance for point cloud analysis based on the message pass-ing (graph neural network) scheme. We find the equivariant property could be obtained by introducing an orientation for each point to decouple the relative position for each point from the global pose of the entire point cloud. There-fore, we extend current message passing networks with a module that learns orientations for each point. Before ag-gregating information from the neighbors of a point, the net-works transforms the neighbors’ coordinates based on the point’s learned orientations. We provide formal proofs to show the equivariance of the proposed framework. Empir-ically, we demonstrate that our proposed method is com-petitive on both point cloud analysis and physical model-ing tasks. Code is available at https://github.com/ luost26/Equivariant-OrientedMP. 1.

Introduction 3D point cloud has become a prevalent data structure for representing a wide range of 3D objects such as 3D scenes
[1, 4, 8, 36], molecules [12, 15, 28], and physical particles
[7,31]. To capture the geometric relationship among points, message passing networks (graph neural networks) [9] and their variants such as DGCNN [33] and PointNet++ [24] have become standard tools to model 3D point cloud data.
A characteristic of 3D point cloud is that most of the scalar
Figure 1. An illustration of the proposed method. It first learns ori-entations for each point in the point cloud. By projecting the rela-tive coordinate of neighbor points before information aggregation, the model successfully decouples global rotation and achieves equivariance. features of the point cloud are invariant1 to global rotation and translation, and the vector features of point clouds are equivariant to global rotation and translation. For instance, the category of a shape and its part semantics are not af-fected by their poses in the 3D space, and the normal vector of each point rotates together with the shape. Therefore, designing a new type of message passing network that pre-serves invariance and equivariance for point clouds is a crit-ical challenge with broad impacts on both computer vision and other science domains.
The key module of conventional message passing net-works for modeling point clouds is to construct the mes-sage from point j to i using the difference between 3D coordinates xj − xi which is usually transformed by non-equivariant layers such as regular MLPs. Hence, it is clear that the outputs of these models are not equivariant to the rotation of point clouds.
Recently, two notable lines of methods have been pro-posed to address the equivariance problem: tensor field-based neural networks [7, 31] and vector-based neural net-* equal contribution. 1Note that invariance is a special case of equivariance.
works [5, 10, 27, 29]. Tensor field-based networks operate in the 3D space using continuous convolutions and the fil-ters in the model are constrained to be the composite of a learnable radial function and a spherical harmonic. Though achieving equivariance, they suffer from high space and time complexity because a significant amount of the spheri-cal harmonics need to be calculated on the fly. The com-plicated formulation of tensor field networks also makes them less accessible to the community. Vector-based neu-ral networks are a good alternative to tensor field networks.
The core part of vector neural networks is their linear layer which takes a list of vectors in 3D space as input and out-puts multiple linear combinations of the input vectors. The output vectors are equivariant to input rotations by the na-ture of the linear combination. However, as the fully con-nected layer of vector networks linearly combines input vectors, different dimensions of the vectors are separated, which prohibits flexible vector transformations and hinders information flows between dimensions. In addition, vector-based neural networks are inadequate to model essential ge-ometric relationships such as angles due to the linearity of the vector propagation.
To address this challenge, we introduce a novel equiv-ariant message passing model by learning the orientation of each point during the message passing process. The over-all learning process includes three key steps. First, it learns the orientation matrix for each point. Second, we project the relative position vector between these two points to the learned orientations, which decouples the relative position of two points from global rotations. Next, the projected rel-ative position difference is integrated into neural messages by some specific network architecture. In the end, we can get both invariant and equivariant properties based on the output features of message passing layers along with the learned orientations.
In comparison to previous equivariant models, our method is much simpler but more flexible. Specifically, we can easily extend our model by applying arbitrary trans-forms to the projected relative position vector to compose the message, while vector-based networks only allow the linear combination of vectors.
To summarize, our main contributions include: (1) We propose a new framework for equivariant point cloud anal-ysis and provide formal formulation and proof of the equiv-(2) We show the framework’s generality by us-ariance. ing it to augment classical point cloud networks including
DGCNN and RS-CNN. (3) We conduct extensive experi-ments on various tasks including point cloud classification, segmentation, normal estimation, and many-body model-ing, and demonstrate that the proposed method achieves competitive performance. 2.