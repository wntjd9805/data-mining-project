Abstract
Noisy View
Contrastive learning relies on an assumption that posi-tive pairs contain related views that share certain underly-ing information about an instance, e.g., patches of an im-age or co-occurring multimodal signals of a video. What if this assumption is violated? The literature suggests that contrastive learning produces suboptimal representations in the presence of noisy views, e.g., false positive pairs with no apparent shared information. In this work, we pro-pose a new contrastive loss function that is robust against noisy views. We provide rigorous theoretical justiﬁcations by showing connections to robust symmetric losses for noisy binary classiﬁcation and by establishing a new contrastive bound for mutual information maximization based on the
Wasserstein distance measure. The proposed loss is com-pletely modality-agnostic and a simple drop-in replacement for the InfoNCE loss, which makes it easy to apply to ex-isting contrastive frameworks. We show that our approach provides consistent improvements over the state-of-the-art on image, video, and graph contrastive learning bench-marks that exhibit a variety of real-world noise patterns. 1.

Introduction
Contrastive learning [1, 2, 3] has become one of the most prominent self-supervised approaches to learn representa-tions of high-dimensional signals, producing impressive re-sults with image [4, 5, 6, 7, 8, 9], text [10, 11, 12, 13], au-dio [14, 15, 16], and video [17, 18, 19]. The central idea is to learn representations that capture the underlying in-formation shared between different “views” of data [3, 20].
For images, the views are typically constructed by applying common data augmentation techniques, such as jittering, cropping, resizing and rotation [6], and for video the views are often chosen as adjacent frames [21] or co-occurring multimodal signals, such as video and the corresponding optical ﬂow [22], audio [19] and transcribed speech [17].
Designing the right contrasting views has shown to be
Clean View2
Noisy View2
View1
Figure 1. Noisy views can deteriorate contrastive learning. We propose a new contrastive loss function (RINCE) that rescales the sample importance in the gradient space based on an estimated noise level. With a simple turn of a knob (q (0, 1]), we can up-weight or downweight sample pairs with low shared information. 2 a key ingredient of contrastive learning [6, 23]. This often requires domain knowledge, intuition, trial-and-error (and luck!). What would happen if the views are wrongly chosen and do not provide meaningful shared information? Prior work has reported deteriorating effects of such noisy views in contrastive learning under various scenarios, e.g., un-related image patches due to extreme augmentation [20], irrelevant video-audio pairs due to overdubbing [24], and misaligned video-caption pairs [17]. The major issue with noisy views is that representations of different views are forced to align with each other even if there is no meaning-ful shared information. This often leads to suboptimal rep-resentations that merely capture spurious correlations [25] or make them collapse to a trivial solution [26]. Worse yet, when we attempt to learn from large-scale unlabeled data – i.e., the scenario where self-supervised learning is par-ticularly expected to shine – the issue is only aggravated
because of the increased noise in the real-world data [27], hindering the ultimate success of contrastive learning.
Consequently, a few attempts have been made to design contrastive approaches that are noise-tolerant. For example,
Morgado et al. [24] optimize a soft instance discrimination loss to weaken the impact of noisy views. Miech et al. [17] address the misalignment between video and captions by aligning multiple neighboring segments of a video. How-ever, existing approaches are often tied to speciﬁc modali-ties or make assumptions that may not hold for general sce-narios, e.g., MIL-NCE [17] is not designed to address the issues of irrelevant audio-visual signals.
In this work, we develop a principled approach to make contrastive learning robust against noisy views. We start by making connections between contrastive learning and the classical noisy binary classiﬁcation in supervised learn-ing [28, 29]. This allows us to explore the wealth of litera-ture on learning with noisy labels [30, 31, 32]. In particular, we focus on a family of robust loss functions that has the symmetric property [29], which provides strong theoretical guarantees against noisy labels in binary classiﬁcation. We then show a functional form of contrastive learning that can satisfy the symmetry condition if given a proper symmetric loss function, motivating the design of new contrastive loss functions that provide similar theoretical guarantees. 2
This leads us to propose Robust InfoNCE (RINCE), a contrastive loss function that satisﬁes the symmetry condi-tion. RINCE can be understood as a generalized form of the contrastive objective that is robust against noisy views. In-tuitively, its symmetric property provides an implicit means to reweight sample importance in the gradient space with-out requiring an explicit form of noise estimator.
It also provides a simple “knob” (a real-valued scalar q (0, 1]) that controls the behavior of the loss function balancing the exploration-exploitation trade-off (i.e., from being conser-vative to playing adventures on potentially noisy samples).
We also provide a theoretical analysis of the proposed
RINCE objective and show that it extends the analyses by
Ghosh et al. [29] to the self-supervised contrastive learning regime. Furthermore, we relate the proposed loss function to dependency measurement. Analogous to InfoNCE loss, which is a lower bound of mutual information between two views [3], we show that RINCE is a lower bound of Wasser-sein Dependency Measure (WDM) [33], even in the noisy setting. By replacing the KL divergence in the mutual in-formation estimator with the Wasserstein distance, WDM is able to capture the geometry of the representation space via the equipped metric space and provides robustness against noisy views better than the KL divergence, both in theory and practice. In particular, the features learned with RINCE achieve better class-wise separation, which is proved to be crucial to improve generalization [34].
Despite its rigorous theoretical background, implement-ing RINCE requires only a few lines code and can be a sim-ple drop-in replacement for the InfoNCE loss to make con-trastive learning robust against noisy views. Since InfoNCE sets the basis for many modern contrastive methods such as
SimCLR [6] and MoCo-v1/v2/v3 [5, 7, 35], our construc-tion can be easily applied to many existing frameworks.
Finally, we provide strong empirical evidence demon-strating the robustness of RINCE against noisy views un-der various scenarios with different modalities and noise types. We show that RINCE improves over the state-of-the-art in image [36, 37], video [27, 38] and graph [39] self-supervised learning benchmarks, demonstrating its general-ity across different modalities. We also show that RINCE exhibits strong robustness against different types of noise such augmentation noise [20, 40], label noise [28, 41], and noisy audio-visual correspondence [24]. The improvement is consistently observed across different dataset scales and training epochs, demonstrating the scalability and compu-tational efﬁciency. In short, our main contributions are:
• We propose RINCE, a new contrastive learning objec-tive that is robust against noisy views of data;
• We provide a theoretical analysis to relate the proposed loss to symmetric losses and dependency measurement;
• We demonstrate our approach on real-world scenarios of image, video, and graph contrastive learning. 2.