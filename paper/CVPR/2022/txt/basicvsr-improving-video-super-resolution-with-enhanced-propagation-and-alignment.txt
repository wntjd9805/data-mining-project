Abstract
A recurrent structure is a popular framework choice for the task of video super-resolution. The state-of-the-art method BasicVSR adopts bidirectional propagation with feature alignment to effectively exploit information from the entire input video. In this study, we redesign BasicVSR by proposing second-order grid propagation and flow-guided deformable alignment. We show that by empowering the re-current framework with enhanced propagation and align-ment, one can exploit spatiotemporal information across misaligned video frames more effectively. The new com-ponents lead to an improved performance under a simi-lar computational constraint. In particular, our model Ba-sicVSR++ surpasses BasicVSR by a significant 0.82 dB in
PSNR with similar number of parameters. BasicVSR++ is generalizable to other video restoration tasks, and obtains three champions and one first runner-up in NTIRE 2021 video restoration challenge. 1.

Introduction
Video super-resolution (VSR) is challenging in that one needs to gather complementary information across mis-aligned video frames for restoration. One prevalent ap-proach is the sliding-window framework [9, 28, 31, 35], where each frame in the video is restored using the frames within a short temporal window. In contrast to the sliding-window framework, a recurrent framework attempts to ex-ploit the long-term dependencies by propagating the latent features. In general, these methods [8, 10â€“12, 14, 24] allow a more compact model compared to those in the sliding-window framework. Nevertheless, the problems of trans-mitting long-term information and aligning features across frames in a recurrent model remain challenging.
We study the problems above by choosing the recent state of the art, BasicVSR [3], as our base model. Improving
BasicVSR is non-trivial because it has already been used to explore different schemes and is one of the most effective designs for feature propagation and alignment. In particular,
BasicVSR adopts bidirectional propagation to aggressively exploit information from the entire input video for recon-struction. For alignment, it designs an effective module that uses optical flow for feature warping (see Fig. 1).
We wish to explore if there are more effective ways to aggregate temporal information in a video, so that one can restore finer details and deal with occluded and complex regions better than BasicVSR. Such a study is meaningful and fundamental as it will benefit the design of future VSR models. To this end, we redesign BasicVSR by devising second-order grid propagation and flow-guided deformable alignment that allow information to be propagated and ag-gregated more effectively.
While the basic backbone and structure of our network is inspired by BasicVSR (so as to allow fair comparisons), our two components are novel. No previous literature has explored the notion of grid-like second-order propagation and flow-guided deformable alignment. In particular, 1) The proposed second-order grid propagation, as shown in
Fig. 1(a), addresses two limitations in exiting recurrent VSR networks: i) we allow more aggressive bidirectional propa-gation arranged in a grid-like manner, and ii) we relax the assumption of first-order Markov property, and incorporate a second-order connection into the network so that infor-mation can be aggregated from different spatiotemporal lo-cations. Both modifications ameliorate information flow in the network and improve robustness of the network against occluded and fine regions. 2) Inaccurate flow estimation could jeopardize the restora-tion performance. Deformable alignment [28, 29, 31] has demonstrated its superiority in VSR, but it is difficult to train in practice [4]. To take advantage of deformable align-ment while overcoming the training instability, we propose flow-guided deformable alignment, as shown in Fig. 1(b).
In the proposed module, instead of learning the DCN off-sets directly [6, 39], we reduce the burden of offset learning by using optical flow field as base offsets refined by flow field residue. The latter can be learned more stably than the original DCN offsets.
Enhanced by the above design improvements, Ba-sicVSR++ can adopt a more lightweight backbone than its counterparts: BasicVSR++ surpasses existing state of the arts by a large margin while maintaining efficiency (Fig. 1(c)). In particular, when compared to its predeces-sor BasicVSR, a considerable gain of 0.82 dB in PSNR on
REDS4 [31] is obtained with similar numbers of parame-ters. We show that the proposed components can further benefit other video restoration tasks such as compressed video enhancement and real-world VSR. 2.