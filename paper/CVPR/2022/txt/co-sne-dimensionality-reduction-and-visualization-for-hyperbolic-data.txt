Abstract
Hyperbolic space can naturally embed hierarchies that often exist in real-world data and semantics. While high-dimensional hyperbolic embeddings lead to better repre-sentations, most hyperbolic models utilize low-dimensional embeddings, due to non-trivial optimization and visualiza-tion of high-dimensional hyperbolic data.
We propose CO-SNE, which extends the Euclidean space visualization tool, t-SNE, to hyperbolic space. Like t-SNE, it converts distances between data points to joint probabil-ities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of high-dimensional data X and low-dimensional embedding Y . However, unlike Eu-clidean space, hyperbolic space is inhomogeneous: A vol-ume could contain a lot more points at a location far from the origin. CO-SNE thus uses hyperbolic normal distribu-tions for X and hyperbolic Cauchy instead of t-SNE’s Stu-dent’s t-distribution for Y , and it additionally seeks to pre-serve X’s individual distances to the Origin in Y .
We apply CO-SNE to naturally hyperbolic data and su-pervisedly learned hyperbolic features. Our results demon-strate that CO-SNE deﬂates high-dimensional hyperbolic data into a low-dimensional space without losing their hy-perbolic characteristics, signiﬁcantly outperforming pop-ular visualization tools such as PCA, t-SNE, UMAP, and
HoroPCA which is also designed for hyperbolic data. 1.

Introduction
Datasets with hierarchical structures are ubiquitous. So-cial networks [9] and complex networks [1] are representa-tive examples of hierarchical data. Euclidean space cannot embed entities in such hierarchical datasets without distor-tion. Hyperbolic space, a non-Euclidean space with con-stant negative curvature, has been widely used for embed-ding hierarchical data since hyperbolic metric can closely approximate the tree metric. Hyperbolic space has thus been used in the representation learning of word embed-dings [22] (Figure 1) and visual inputs [12, 17]. Several al-gorithms also directly operate on hyperbolic space [5,6,31].
Higher embedding dimension can generally lead to bet-Figure 1. Our CO-SNE method deﬂates a high-dimensional hyper-bolic representation while preserving their global hierarchy and lo-cal similarities. We generate the Poincar´e embeddings [22] of the mammal subtree from WordNet in a ﬁve-dimensional hyperbolic space. We apply the standard t-SNE [30], the recently proposed
HoroPCA [4] and our proposed CO-SNE method to visualize the embeddings in a two-dimensional Euclidean (in t-SNE) or hyper-bolic space (in HoroPCA and CO-SNE). CO-SNE preserves the global hierarchy (root node is in the center and leaf nodes are close to boundary) and the local similarity (sibling nodes are close) in the two-dimensional embeddings. ter hyperbolic representation quality [10, 22]. However, learning with two-dimensional hyperbolic space is preva-lent [10, 22]. One of the reasons is the ease of visualiza-tion. There are several isometrically equivalent models for representing hyperbolic space. The Poincar´e ball model is arguably the most widely used model in hyperbolic repre-sentation learning [8, 10, 22]. With the Poincar´e ball model, we can easily visualize two-dimensional hyperbolic embed-dings within a unit Euclidean circle. However, to visualize high-dimensional hyperbolic data is not easy, as most visu-alization methods assume the data exist in Euclidean space.
Embeddings in Poincar´e ball have two notable proper-ties: 1) The embeddings have a global hierarchical struc-ture. Root nodes are in the center of the ball and leaf nodes are close to the boundary of the ball. 2) The embeddings possess a local similarity structure. Sibling nodes should be close in the embedding space. t-SNE [30] is a popular visualization tool for visualiz-ing high-dimensional Euclidean data. However, t-SNE can-not preserve the global hierarchy of the hyperbolic embed-dings. HoroPCA [4] is recently proposed as an extension of PCA on hyperbolic space. However, HoroPCA can-not preserve the local similarity of the hyperbolic embed-dings. In this paper, we propose CO-SNE which can pre-serve both the global hierarchy and local similarity of high-dimensional hyperbolic embeddings in a low- dimensional
In Figure 1, the mammal subtree hyperbolic space (1). from WordNet [20] is embedded in a ﬁve-dimensional hy-perbolic space via Poincar´e embeddings [22]. We use t-SNE [30], HoroPCA [4] and CO-SNE to visualize the em-beddings in a two-dimensional space. CO-SNE can pre-serve the structure of the data well.
In CO-SNE, for maintaining local similarity structure, we adopt the same idea as in the standard t-SNE to minimize the KL-divergence between the high-dimensional similari-ties and the low-dimensional similarities. We adopt hyper-bolic versions of the normal distribution and Cauchy distri-bution to compute the similarities. To maintain the global hierarchical structure, we adopt a distance loss function which seeks to preserve the individual distances of high-dimensional hyperbolic embeddings to the Origin in low-dimensional hyperbolic space.
In summary, we make the following contributions, hyperbolic
• We propose CO-SNE which can represent high-dimensional low-dimensional hyperbolic space while maintaining the local similarity and the global hierarchical structure. datapoints in a
• We propose to use hyperbolic Cauchy distribution for computing low-dimensional similarities which is cru-cial for producing good visualization in hyperbolic space.
• We apply CO-SNE to visualize synthetic hyper-bolic data, hierarchical biological datasets and hyper-bolic embeddings learned by supervised and unsu-pervised learning methods to better understand high-dimensional hyperbolic data. Across all the cases, CO-SNE produces much better visualization than the base-lines. 2.