Abstract 1.

Introduction
INS-Conv,
We propose an INcremental Sparse
Convolutional network which enables online accurate 3D semantic and instance segmentation. Benefiting from the incremental nature of RGB-D reconstruction, we only need to update the residuals between the reconstructed scenes of consecutive frames, which are usually sparse.
For layer design, we define novel residual propagation rules for sparse convolution operations, achieving close approximation to standard sparse convolution. For network architecture, an uncertainty term is proposed to adaptively select which residual further improving the to update, inference accuracy and efficiency. Based on INS-Conv, an online joint 3D semantic and instance segmentation pipeline is proposed, reaching an inference speed of 15 FPS on GPU and 10 FPS on CPU. Experiments on
ScanNetv2 and SceneNN datasets show that the accuracy of our method surpasses previous online methods by a large margin, and is on par with state-of-the-art offline methods.
A live demo on portable devices further shows the superior performance of INS-Conv.
* Equal contribution. (cid:66) Corresponding author. Mail: fanglu@tsinghua.edu.cn.
Acknowledgement: This work is supported in part by Natural Sci-ence Foundation of China (NSFC) under contract No. 62125106, 61860206003 and 62088102, in part by National Key R&D Program of China (2021ZD0109901), in part by Beijing National Research Cen-ter for Information Science and Technology (BNRist) under Grant No.
BNR2020RC01002. 3D semantic and instance segmentation aims to detect objects of a 3D scene and provide per point semantic pre-diction simultaneously, which is fundamental to robotics or
AR/VR applications. Recent methods [4, 8, 12, 13, 16, 26] that focus on offline 3D segmentation have shown great improvements in terms of segmentation accuracy, where sparse convolutional networks are widely used as back-bones to extract 3D features [8, 12, 16]. While these offline methods achieve leading accuracy, they may take up to sec-onds to make a single update, because their backbone net-works usually require global geometry as input, which can-not meet the online segmentation purpose, e.g., real-time interaction of AR agents with the surrounding environment.
For the task of online 3D segmentation, a common so-lution is the 2D-to-3D approach, which means to perform 2D convolutions on RGBD frames, followed by projecting the 2D predictions to 3D space and fusing with the pre-vious results via a probabilistic model [18, 20, 22]. These methods utilize 2D information merely, leading to low seg-mentation accuracy. Although recent methods achieve im-provements by using 3D point convolution to process 2D features [15, 29], the problem remains unsolved, because neither 2D features nor local 3D convolutions are aware of the global information of the 3D scene. As a result, they still suffer from the low accuracy. Moreover, most online 3D segmentation methods only provide semantic predic-tions, without instance-level understanding. How to achieve
highly accurate 3D semantic instance segmentation while enabling online inference along with 3D reconstruction is still an open question.
We propose INS-Conv, an incremental sparse convolu-tional network, which enables online accurate 3D seman-tic and instance segmentation. We observe that in online
RGB-D reconstruction, the reconstructed scenes at each time step form an incrementally growing 3D geometry se-quence, where the residuals between two continuous 3D frames are usually sparse. Therefore, a lot of redundant computation could be saved by performing incremental in-ference on the residuals of continuous frames. More specif-ically, for layer design, we define novel residual propaga-tion rules for sparse convolution operations. By replacing the layers of a standard sparse convolutional network with our INS-Conv layers, we can achieve efficient incremen-tal inference with minimal loss of accuracy. For network architecture, an uncertainty term is proposed to adaptively select which residual to update, by ignoring the unneces-sary updating of the points that already have very confi-dent predictions, while incorporating points that may have changed states in the future, further improving the infer-ence accuracy and efficiency. Based on INS-Conv, an on-line joint 3D semantic and instance segmentation pipeline is proposed. At each time step, after the 3D features are extracted through the INS-Conv backbone network, we use clustering to generate instance predictions on the updated points, which are later fused into the previous results to get the final instance segmentation results using an instance fu-sion stage. To summarize, our contributions include:
• An incremental sparse convolutional network, INS-Conv. With the novel residual propagation strategy, along with adaptive residual selection through uncer-tainty prediction, it achieves fast and accurate infer-ence of 3D convolutional networks.
• An online 3D joint semantic and instance segmentation pipeline implemented based on INS-Conv. It achieves state-of-the-art segmentation accuracy among online methods, on par with offline methods.
• A live demo of INS-Conv running locally on a portable device. The superior performance of INS-Conv in terms of both accuracy and efficiency makes it partic-ularly adapted to AR/VR or robotics applications.
• The code is available at: https://github.com/
THU-luvision/INS-Conv 2.