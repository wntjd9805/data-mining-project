Abstract
Active learning is a promising alternative to alleviate the issue of high annotation cost in the computer vision tasks by consciously selecting more informative samples to la-bel. Active learning for object detection is more challeng-ing and existing efforts on it are relatively rare. In this pa-per, we propose a novel hybrid approach to address this problem, where the instance-level uncertainty and diver-sity are jointly considered in a bottom-up manner. To bal-ance the computational complexity, the proposed approach is designed as a two-stage procedure. At the ﬁrst stage, an
Entropy-based Non-Maximum Suppression (ENMS) is pre-sented to estimate the uncertainty of every image, which performs NMS according to the entropy in the feature space to remove predictions with redundant information gains. At the second stage, a diverse prototype (DivProto) strategy is explored to ensure the diversity across images by progres-sively converting it into the intra-class and inter-class di-versities of the entropy-based class-speciﬁc prototypes. Ex-tensive experiments are conducted on MS COCO and Pas-cal VOC, and the proposed approach achieves state of the art results and signiﬁcantly outperforms the other counter-parts, highlighting its superiority. 1.

Introduction
During the past decade, visual object detection [23, 30] has been greatly advanced by deep Convolutional Neural
Networks (CNN) [12, 27] with persistently increasing per-formance reported. Unfortunately, strong CNNs generally make use of huge amounts of annotated data to ﬁt extensive numbers of parameters, and training such detectors requires bounding-box labels on images, which is quite expensive and time-consuming. As one of the most promising alterna-tives to alleviate this dilemma, active learning [25, 38] aims to reduce this high cost by consciously selecting more in-*Corresponding author. formative samples to label, and it is expected to deliver a higher accuracy with much fewer annotated images com-pared to that conducted in the random way.
In the community of computer vision, active learning is mainly discussed on image classiﬁcation [15, 25, 28], where current methods roughly go into two categories, i.e. uncertainty-based [9, 36] and diversity-based [22, 25].
Uncertainty-based methods [9, 36] screen informative sam-ples from entire databases according to their ambiguities [3, 9, 15, 36]. As the samples are separately predicted, they are efﬁcient but tend to incur high correlations. Diversity-based methods [1, 22, 25] claim that informative samples are the representatives of the whole data distribution and identify a subset using distance metric [25] or class probability [1].
They prove effective for small models, but suffer from high computational complexity. In addition, there exists another trend to combine the uncertainty- and diversity-based meth-ods as hybrid ones [2, 6, 35], and the achieved superiority
ﬁgures out a promising alternative to other tasks.
As we know, object detection is more complicated than image classiﬁcation, where object category and location are simultaneously output. In this case, active learning is de-sired to deal with various numbers of objects within images and the essential issue is to make image-level decisions ac-cording to instance-level predictions. The diversity-based method, CDAL [1], applies spatial pooling to roughly ap-proximate instance aggregation and formulates image se-lection as a reinforcement learning process. Regarding uncertainty-based methods, Learn Loss [36] designs a task-free loss prediction module, and computes the image un-certainty by image-level features instead of instance-level ones, while MIAL [37] deﬁnes the image uncertainty as that of the top-K instances and estimates it with multiple instance learning based re-weighting. Since the diversity-based methods do not fully make use of categorical infor-mation and the uncertainty-based ones do not well measure the discrepancy of informative samples, the two types of methods leave room for performance improvement.
In this study, we propose a novel hybrid approach to
Figure 1. Framework overview. The hollow circles refer to uncertainty predictions and the solid ones denote the aggregated prototypes.
At each cycle, the detector is trained with labeled images and infers the unlabeled ones. Instance uncertainty is ﬁrst computed based on the entropy. ENMS then performs on each image to remove redundant instances. DivProto aggregates the instances of each image to prototypes and rejects the images close to the selected ones. The priority of active acquisition is illustrated with 3 examples: I1, I2, I3. At the end of each cycle, the selected images (e.g. I2, I3) are labeled by an oracle. active learning for object detection, which considers both the uncertainty and diversity at the instance level. To balance the computational complexity, the proposed ap-proach works in a two-stage manner, as Fig. 1 displays. At the ﬁrst stage, we estimate the uncertainty of each image by an Entropy-based Non-Maximum Suppression (ENMS).
ENMS performs Non-Maximum Suppression on the calcu-lated entropy in the feature space to remove instances that bring redundant information gains, where a bigger value of the entropy reﬁned by ENMS indicates the selection priority of an unlabeled image. At the second stage, unlike existing uncertainty-based methods [24,37] which choose the top-K images for annotation, we introduce the diverse prototype (DivProto) strategy to ensure instance-level diversity across images. It employs the prototypes [29, 33] as the image-level representatives by aggregating the class-speciﬁc in-stances, and decomposes the cross-image diversity into the intra-class and inter-class ones. We then acquire the images of the minority classes for inter-class diversity and reject the ones that incur redundancy for intra-class diversity. In this way, the proposed approach combines the advantages of the uncertainty and diversity based ones in a bottom-up manner.
We evaluate the proposed approach on MS COCO [19] and
Pascal VOC [7, 8] and deliver state of the art scores on both of them, highlighting its effectiveness. 2.