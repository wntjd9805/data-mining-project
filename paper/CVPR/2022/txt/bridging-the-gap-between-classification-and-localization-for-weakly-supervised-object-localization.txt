Abstract
Weakly supervised object localization aims to ﬁnd a target object region in a given image with only weak supervision, such as image-level labels. Most existing methods use a class activation map (CAM) to generate a localization map; however, a CAM identiﬁes only the most discriminative parts of a target object rather than the entire object region. In this work, we ﬁnd the gap between classiﬁcation and localization in terms of the misalignment of the directions between an input feature and a class-speciﬁc weight. We demonstrate that the misalignment suppresses the activation of CAM in areas that are less discriminative but belong to the target object. To bridge the gap, we propose a method to align feature directions with a class-speciﬁc weight. The proposed method achieves a state-of-the-art localization performance on the CUB-200-2011 and ImageNet-1K benchmarks. 1.

Introduction
Object localization aims to ﬁnd the area of a target object in a given image [5, 13, 18, 19, 23]. However, fully super-vised approaches require accurate bounding box annotations, which require a tremendous cost. Weakly supervised object localization (WSOL) has been a great alternative because it requires only image-level labels to train a localization model [3, 4, 17, 21, 27].
The most commonly used approach for WSOL is a class activation map (CAM) [33]. CAM-based methods employ a global average pooling (GAP) layer [12] followed by a fully connected (FC) layer, and generate a CAM with the feature maps prior to the GAP layer. A highly activated area in a CAM is predicted to be an object location. However, it is widely observed that CAM identiﬁes only the most discriminative parts of an object rather than the entire object area, resulting in low localization performance [11, 15, 30].
We ask the question, “Why does CAM generated from an
*Correspondence to: Sungroh Yoon (sryoon@snu.ac.kr).
Figure 1. (a) Examples of CAM and decomposed terms from the classiﬁer trained with the vanilla method [33] and with EIL [15]. (b) Visualization of the changes of CAM and decomposed terms as training with our method progresses. accurate classiﬁer fail to highlight the entire object area?”
To answer this, we provide a new perspective of decompos-ing CAM into two terms: (1) activation in a feature map and (2) cosine similarity between the feature vector at each spatial location and the class-speciﬁc weight in the FC layer.
Fig. 1(a) shows that only the bird’s body is highly activated in the CAM of the vanilla model, leaving the wing less acti-vated. However, looking at the activation in the feature map, the wing as well as the body is highly activated. The low similarity of the wing region offsets the activation in the
feature map, making the region invisible in the CAM. Here, we ﬁnd that the low cosine similarity, i.e., misalignment of feature directions to the class-speciﬁc weights, prevents the less discriminative part belonging to a target object from being highly activated in a CAM. This is because training for classiﬁcation only considers the feature averaged over all locations, not the feature at each spatial location. This brings the gap between classiﬁcation and localization.
Although various approaches have been proposed to ex-pand the activated region to the entire object area in a
CAM [4, 15, 27, 28, 30, 31], none of them discovered or mitigated the misalignment. Fig. 1(a) shows that EIL [15], one of those approaches, expands the activated region in the feature map. However, it fails to increase the similarity in the object region; hence, the expansion effect is not as large in the CAM as in the activation of the feature map.
To bridge the gap between classiﬁcation and localization, we propose feature direction alignment, a method to enhance the alignment of feature directions in the entire object region to the directions of class-speciﬁc weights while discouraging the alignment in the background region. We also introduce consistency with attentive dropout, which ensures that the target object region has uniformly high activation in the fea-ture map. Fig. 1(b) shows that our method gradually aligns the feature directions to the class-speciﬁc weight as the train-ing progresses. The alignment results in high activation of less discriminative regions, e.g., wing, in the CAM, enabling accurate localization of the entire object. We evaluate our method on the most widely used WSOL benchmark datasets:
CUB-200-2011 [25] and ImageNet-1K [19]. Our method achieves a state-of-the-art localization performance for both datasets.
The contributions of this paper can be summarized as follows:
• We interpret a CAM in terms of the degree of alignment between the direction of input features and the direc-tion of class-speciﬁc vectors, and ﬁnd the gap between classiﬁcation and localization.
• We propose a method to bridge the gap between classi-ﬁcation and localization by aligning feature directions with class-speciﬁc weights.
• We demonstrate that our proposed method outperforms other state-of-the-art WSOL methods on the CUB-200-2011 and ImageNet-1K datasets. 2.