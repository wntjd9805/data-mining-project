Abstract
Semantic patterns of fine-grained objects are determined by subtle appearance difference of local parts, which thus inspires a number of part-based methods. However, due to uncontrollable object poses in images, distinctive de-tails carried by local regions can be spatially distributed or even self-occluded, leading to a large variation on ob-ject representation. For discounting pose variations, this paper proposes to learn a novel graph based object rep-resentation to reveal a global configuration of local parts for self-supervised pose alignment across classes, which is employed as an auxiliary feature regularization on a deep representation learning network. Moreover, a coarse-to-fine supervision together with the proposed pose-insensitive constraint on shallow-to-deep sub-networks encourages discriminative features in a curriculum learning manner.
We evaluate our method on three popular fine-grained ob-ject classification benchmarks, consistently achieving the state-of-the-art performance. Source codes are available at https://github.com/yangxh11/P2P-Net. 1.

Introduction
Semantic patterns in image-based object classification are determined by visual appearance and shape of ob-ject classes. The problem of classifying fine-grained ob-jects is made more challenging due to the inherently sub-tle shape difference across the subordinate categories (e.g. bird breeds [34] and vehicle brands [18]). As a result, fine-grained classification relies on distinguished appearance de-tails on local parts, which typically desires detection on those specific parts additionally using expensive part anno-tations [19, 38]. Learning a discriminative representation for fine-grained objects remains non-trivial in the context of deep learning. Generally, a good representation in fine-grained classification should not only be sensitive to the subtle detail changes that usually anchored on specific parts
*Corresponding authors
Figure 1. Different from direct concatenation of local and global features in conventional part-based methods, the main idea of the proposed P2P-Net is to incorporate a pose-insensitive configura-tion of local distinctive details into object representation via uti-lizing self-supervised pose alignment as feature regularization to narrow intra-category variance and enlarge inter-category margin. but also be invariant to the deformations of object parts and the changes of viewing angles.
On the one hand, a large number of deep approaches were devoted to the former challenge of capturing fine-grained details in local regions, which relied on detecting discriminative parts to extract local features to complement the global one [31, 41, 46]. On the other hand, another group of deep methods [17, 39, 45] avoided explicitly local-izing object parts but tried to enhance the object representa-tion’s discrimination by applying bilinear pooling operation on feature vectors from two independent network streams.
However, only a few works have paid attention to the chal-lenge of feature inconsistency caused by the changes of ob-ject pose or viewing angle.
Similar to other pose estimation problems [1, 16], poses of fine-grained objects can approximately be described as a geometric configuration of discrete object parts. As a result, we argue that reliable object parts localization and parts alignment are essential to model object poses, which can be utilized to generate pose insensitive object representations
[33] so as to eliminate object pose variations. Evidently, explicitly regression on object poses as an auxiliary task is a straightforward solution, but in the context of fine-grained classification object poses typically suffers from inherent annotation ambiguities and a lack of sufficient samples. In view of this, we propose an unsupervised part-to-pose net-work (P2P-Net) which captures both part details and object poses to regularize the representation learning with no ad-ditional annotations of part position or pose information.
Inspired by Feature Pyramid Networks (FPN) [20] that is originally designed for object detection, our P2P-Net dis-tinguishes the confidently class-discriminative regions from region proposals in a weakly supervised learning manner.
To incorporate the fine-grained appearance details on spe-cific parts, the global object representation is regularized with local representations of the detected salient regions via minimizing distribution difference with the contrastive loss.
The major differences between the P2P-Net and the ex-isting part-based methods, as shown in Fig. 1, lie in: 1) we align the parts in a self-supervised learning manner so as to discount the pose variations; 2) a feature regularization to strengthen representation discrimination is available only at training, i.e., our method can discard the time consum-ing part branch (highlighted in light blue in Fig. 1) during testing. The effectiveness of the proposed self-supervised part-based pose alignment as feature regularization can be demonstrated in our experiments. Besides, we also propose curriculum supervision to capture discriminative details at coarse-to-fine scales for further improvement. The pro-posed P2P-Net consistently outperforms the state-of-the-art fine-grained classifiers on three popular benchmarks.
Our contributions can be summarized as follows:
• This paper proposes an end-to-end P2P-Net to incor-porate discriminative features on confidential parts and then promotes the discrimination of object representa-tions via pose-insensitive feature regularization.
• Technically, our P2P-Net designs an adaptive graph matching algorithm on confidential parts and achieves feature consistency against pose variations in an unsu-pervised learning manner.
• A generic curriculum supervision on image classifica-tion is introduced by designing label-smoothing based easy-to-hard supervision signals coupled with shallow-to-deep sub-networks.
• Experimental results on multiple public benchmarks demonstrate that the proposed method can achieve a new state-of-the-art performance on the problem of fine-grained image classification . 2.