Abstract
The 3D Lookup Table (3D LUT) is a highly-efficient tool for real-time image enhancement tasks, which mod-els a non-linear 3D color transform by sparsely sampling it into a discretized 3D lattice. Previous works have made efforts to learn image-adaptive output color values of LUTs for flexible enhancement but neglect the importance of sam-pling strategy. They adopt a sub-optimal uniform sampling point allocation, limiting the expressiveness of the learned
LUTs since the (tri-)linear interpolation between uniform sampling points in the LUT transform might fail to model local non-linearities of the color transform. Focusing on this problem, we present AdaInt (Adaptive Intervals Learn-ing), a novel mechanism to achieve a more flexible sampling point allocation by adaptively learning the non-uniform sampling intervals in the 3D color space.
In this way, a 3D LUT can increase its capability by conducting dense sampling in color ranges requiring highly non-linear trans-forms and sparse sampling for near-linear transforms. The proposed AdaInt could be implemented as a compact and efficient plug-and-play module for a 3D LUT-based method.
To enable the end-to-end learning of AdaInt, we design a novel differentiable operator called AiLUT-Transform (Adaptive Interval LUT Transform) to locate input colors in the non-uniform 3D LUT and provide gradients to the sampling intervals. Experiments demonstrate that meth-ods equipped with AdaInt can achieve state-of-the-art per-formance on two public benchmark datasets with a negli-gible overhead increase. Our source code is available at https://github.com/ImCharlesY/AdaInt. 1.

Introduction
Recent advances in machine learning techniques remark-ably boosted the performance of automatic photo enhance-*Equal Contribution †Corresponding Author
Work partially done during an internship of C. Yang at Alibaba Group.
Figure 1. Comparison between uniform and non-uniform sam-pling on curve approximation and space partitioning. The illustra-tion is given in 1D but can be easily extended to 3D. ment methods [5, 6, 9, 19, 21, 48], aiming to replace a sequence of meticulously-designed operations [2, 24, 25, 33, 43, 50] in the camera imaging pipeline [20] for en-hanced visual quality. However, these methods suffer from heavy computational burdens due to complicated optimiza-tion processes [10, 13, 19, 21, 49] or neural architecture de-signs [5, 6, 9, 47].
In fact, most of the commonly-used enhancement operations are pixel-independent, as revisited in [17]. Their total effect is approximately equivalent to a 3D color transform function (R3 → R3) that maps an input color point to another one in or across the color spaces. One can adopt a multi-layer perceptron (MLP) to design such a transform [17] but requires a cascade of several linear and nonlinear sub-operations to increase the model capability.
To overcome the computational complexity of a series of sub-operations in the transform, the 3D lookup table (LUT) is a promising data structure to conduct efficient mapping
by sparsely sampling a range of input values and storing the corresponding output values in a 3D lattice. The non-linearities in the transform are typically approximated by a set of (tri-)linear interpolation functions distributed in the lattice cells. Since a LUT can transform images using only memory access and interpolation operations, it shows an ad-vantage of high efficiency and practicality.
Previous works [45, 51] have made efforts to learn an image-adaptive LUT, mimicking the underlying optimal color transform with adaption to extensively varied image content. These methods embody the image-adaptiveness of the 3D LUTs only in the output color values, which are automatically learned by neural networks [45, 51]. How-ever, they conduct sampling with equal intervals, not con-sidering the adaption of sampling point density to image contents.
It results in a sub-optimal sampling point allo-cation, limiting the expressiveness of the LUTs to model local non-linearities. Specifically, input pixels with similar color values but requiring highly non-linear contrast stretch-ing (e.g., enhancement on low-light texture regions) are pos-sibly compressed into the same lattice cell, which ends up producing linear-scaling results. The reasons lie in limited sampling points and (tri-)linear interpolation in the LUT transform. As depicted in the left part of Figure 1, for ex-ample, a uniform spacing undersamples a color range where the transform exhibits high curvature, resulting in distortion of the non-linearities in the transform. Ideally, increasing the number of sampling points might mitigate the issues but will significantly increase the overhead of the 3D LUT.
Besides, it would also aggravate the oversampling in color space where few pixels fall into, causing waste in the LUT capacity, as shown in the right part of Figure 1.
To achieve a better tradeoff between effectiveness and efficiency when given limited sampling points, we develop a novel deep learning-based approach to adjust the layout of the 3D lattice by dynamically learning the non-uniform sampling intervals. This idea is encapsulated into a compact network module called AdaInt, that can adaptively allo-cate more sampling points to color ranges requiring highly non-linear transforms and reduce redundant sampling point quota for strongly linear ranges. As illustrated in Figure 2, with the incorporation of AdaInt, a lightweight convolu-tional neural network (CNN) takes a down-sampled image as input to simultaneously predict two components of a ded-icated 3D LUT – the non-uniform sampling coordinates and the corresponding output color values. These two com-ponents are combined to compose an image-adaptive 3D
LUT that transforms the original image via a novel differen-tiable operator called AiLUT-Transform, which can provide gradients to AdaInt for end-to-end learning. This operator is essential for locating input colors in a non-uniform 3D lattice by introducing a low-complexity binary search into the lookup procedure of a LUT transform. Therefore, our method could be a plug-and-play module for 3D LUTs and still presents high efficiency.
The main contributions of this paper are three-fold: (1)
We view the learning of 3D LUTs from the viewpoint of sampling and point out the importance of the sampling strat-egy for modeling color transforms with higher non-linear capability. (2) We present a novel AdaInt module and the corresponding AiLUT-Transform operator to enable the adaptive learning of a 3D LUT with a non-uniform layout. (3) We demonstrate the effectiveness and efficiency of our method on two large-scale publicly available datasets. 2.