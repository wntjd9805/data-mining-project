Abstract
Domain adaptive semantic segmentation aims to learn a model with the supervision of source domain data, and produce satisfactory dense predictions on unlabeled target domain. One popular solution to this challenging task is self-training, which selects high-scoring predictions on tar-get samples as pseudo labels for training. However, the produced pseudo labels often contain much noise because the model is biased to source domain as well as majority categories. To address the above issues, we propose to di-rectly explore the intrinsic pixel distributions of target do-main data, instead of heavily relying on the source domain.
Specifically, we simultaneously cluster pixels and rectify pseudo labels with the obtained cluster assignments. This process is done in an online fashion so that pseudo labels could co-evolve with the segmentation model without extra training rounds. To overcome the class imbalance problem on long-tailed categories, we employ a distribution align-ment technique to enforce the marginal class distribution of cluster assignments to be close to that of pseudo labels. The proposed method, namely Class-balanced Pixel-level Self-Labeling (CPSL), improves the segmentation performance on target domain over state-of-the-arts by a large margin, especially on long-tailed categories. The source code is available at https://github.com/lslrh/CPSL. 1.

Introduction
Semantic segmentation is a fundamental computer vision task, which aims to make dense semantic-level predictions on images [8,27,28,43,53]. It is a key step in numerous ap-plications, including autonomous driving, human-machine interaction, and augmented reality, to name a few. In the past few years, the rapid development of deep Convolu-tional Neural Networks (CNNs) has boosted semantic seg-mentation significantly in terms of accuracy and efficiency.
However, the performance of deep models trained in one
*Corresponding Author domain often drops largely when they are applied to un-seen domains. For example, in autonomous driving the seg-mentation model is confronted with great challenges when weather conditions are changing constantly [56]. A natural way to improve the generalization ability of segmentation model is to collect data from as many scenarios as possible.
However, it is very costly to annotate pixel-wise labels for a large amount of images [11]. More effective and practi-cal approaches are required to address the domain shifts of semantic segmentation.
Unsupervised Domain Adaptation (UDA) provides an important way to transfer the knowledge learned from one labeled source domain to another unlabeled target domain.
For example, we can collect many synthetic data whose dense annotations are easy to get by using game engines such as GTA5 [36] and SYNTHIA [37]. Then the ques-tion turns to how to adapt the model trained from a labeled synthetic domain to an unlabeled real image domain. Most previous works of UDA bridge the domain gap by align-ing data distributions at the image level [17, 25, 33], feature level [7, 17, 18, 24] or output level [29, 32, 39], through ad-versarial training or auxiliary style transfer networks. How-ever, these techniques will increase the model complexity and make the training process unstable, which impedes their reproducibility and robustness.
Another important approach is self-training [52, 56, 57], which alternatively generates pseudo labels by selecting high-scoring predictions on target domain and provides su-pervision for the next round of training. Though these methods have produced promising performance, there are still some major limitations. On one hand, the segmenta-tion model tends to be biased to source domain so that the pseudo labels produced on target domain are error-prone; on the other hand, highly-confident predictions may only provide very limited supervision information for the model training. To solve these issues, some methods [50, 51] have been proposed to produce more accurate and informative pseudo labels. For example, instead of using the classi-fier trained on source domain to generate pseudo labels,
Zhang et al. [51] assigned pseudo labels to pixels based on
their distances to the category prototypes. These prototypes, however, were built in source domain and usually deviated much from the target domain. ProDA [50] leveraged the feature distances from prototypes to perform online recti-fication, but it was challenging to construct prototypes for long-tailed categories, which often led to unsatisfactory per-formance.
Different from previous self-training methods which use classifier-based noisy pseudo labels for supervision, in this paper we propose to perform online pixel-level self-labeling via clustering on target domain, and use the resulting soft cluster assignments to correct pseudo labels. Our idea comes from the fact that pixel-wise cluster assignments could reveal the intrinsic distributions of pixels in target domain, and provide useful supervision for model training.
Compared to conventional label generation methods that are often biased towards source domain, cluster assignment in target domain is more reliable as it explores inherent data distribution. Considering that the classes of segmentation dataset are highly imbalanced (please refer to Fig. 2), we employ a distribution alignment technique to enforce the class distribution of cluster assignments to be close to that of pseudo labels, which is more favorable to class-imbalanced dense prediction tasks. The proposed Class-balanced Pixel-level Self-Labeling (CPSL) module works in a plug-and-play fashion, which could be seamlessly incorporated into existing self-training framework for UDA. The major con-tributions of this work are summarized as follows:
• A pixel-level self-labeling module is developed for do-main adaptive semantic segmentation. We cluster pixels in an online fashion and simultaneously rectify pseudo la-bels based on the resulting cluster assignments.
• A distribution alignment technique is introduced to align the class distribution of cluster assignments to that of pseudo labels, aiming to improve the performance over long-tailed categories. A class-balanced sampling strat-egy is adopted to avoid the dominance of majority cate-gories in pseudo label generation.
• Extensive experiments demonstrate that the proposed
CPSL module improves the segmentation performance on target domain over state-of-the-arts by a large mar-gin. It especially shows outstanding results on long-tailed classes such as “motorbike”, “train”, “light”, etc. 2.