Abstract
We propose a novel method for solving regression tasks us-ing few-shot or weak supervision. At the core of our method is the fundamental observation that GANs are incredibly suc-cessful at encoding semantic information within their latent space, even in a completely unsupervised setting. For mod-ern generative frameworks, this semantic encoding manifests as smooth, linear directions which affect image attributes in a disentangled manner. These directions have been widely used in GAN-based image editing. In this work, we lever-age them for few-shot regression. Specifically, we make the simple observation that distances traversed along such di-rections are good features for downstream tasks – reliably gauging the magnitude of a property in an image. In the absence of explicit supervision, we use these distances to solve tasks such as sorting a collection of images, and ordi-nal regression. With a few labels — as little as two — we calibrate these distances to real-world values and convert a pre-trained GAN into a state-of-the-art few-shot regression model. This enables solving regression tasks on datasets and attributes which are difficult to produce quality super-vision for. Extensive experimental evaluations demonstrate that our method can be applied across a wide range of do-mains, leverage multiple latent direction discovery frame-works, and achieve state-of-the-art results in few-shot and low-supervision settings, even when compared to methods designed to tackle a single task.
Code is available on our project website. 1.

Introduction
In recent years, Generative Adversarial Networks (GANs)
[17] have been at the forefront of deep learning research.
GANs revolutionized countless generative tasks, such as unconditional image synthesis [6, 28], cross-domain image-to-image translation [24, 72] and super-resolution [30]. Be-yond generative tasks, numerous works have proposed to use GANs for downstream discriminative objectives, such as classification. Their shared premise is that a generator can synthesize novel samples - often in a controllable man-ner. These generated samples can then serve as a dataset for training models for downstream tasks. While this approach appears promising on paper [4, 33, 43, 53], this simple idea has enjoyed fairly limited success [12, 40].
We propose an alternative approach to harnessing the rapid advancement of GANs for downstream tasks. Specif-ically, we deviate from previous attempts to generate or augment training data. Instead, we focus on extracting infor-mation from the incredibly well-behaved latent space of mod-ern GAN architectures, and specifically StyleGAN [27, 28].
The latent spaces of StyleGAN have been studied exten-sively [63], and were shown to be highly semantic and dis-entangled, properties which led to their wide use across a range of generative tasks. In this work, we leverage these properties in order to train few-shot regression models.
Specifically, we consider distances traversed along the normal vector of semantic hyperplanes (see fig. 1(a) for an illustration) and demonstrate that they are incredibly dis-criminative features for the task of regression. These normal vectors are commonly referred to as linear editing direc-tions and many previous works proposed methods to identify them [20, 37, 45, 46].
What makes these latent-space distances useful features?
First, the distances are globally consistent: all latent codes at a distance d from a semantic hyperplane resolve into images with similar attribute strengths (e.g. the same age). Hence, the link between distance and the corresponding attribute can be described with a function f . Second, distance is a scalar, allowing us to work with lower dimensional functions f : R → R. Third, the relationship between the distances and attribute strength is monotone. Therefore, a total order of the distances corresponds to a total order on attribute strength. These attributes are already sufficient to make latent-space distances applicable as direct regression scores for applications where no conventional units are required or exist, e.g. ordinal regression.
To produce results with conventional units, such as head pose in degrees, we need to find an explicit approximation for f . Surprisingly, we find that a simple linear function: f (d) = a · d + b produces the best results for all attributes tested (see Figure 1(b)). Thus, we are able to fit an incredibly
(a) (b)
Figure 1. Latent distances from semantic hyperplanes serve as descriptive features. (a) An illustration of a hyperplane ⃗P and its normal
⃗n which defines a latent editing direction [45]. The latent code for the original image (black frame) is located at a distance of d from the hyperplane. (b) Scatter plot depicting the relationship between latent-space distances and the yaw angle [70] of real images. As can be seen, there is an approximately linear correlation between the two, R2 = 0.92 (over the entire set). simple function with only two parameters to regress complex semantic attributes in images. This allows us to perform regression in data domains and for semantic attributes where quality supervision is prohibitively difficult to acquire.
In order to perform regression on real images, the latent code corresponding to a given image is required. For this end, we use an off-the-shelf GAN Inversion encoder. We show that our method is compatible with several different encoders, namely pSp [41], e4e [54] and ReStyle [3].
Our model, outlined in Figure 2, is thus composed of several steps. First, we invert an image into the latent space.
Next, we calculate the distance of the resulting latent code from a given semantic hyperplane. And last, we either use the distance as an uncalibrated score or, in the presence of a few labeled samples, use a simple regression model to con-vert it to real-world valued predictions. By following these steps, our method distills the strength of any semantic prop-erty into a single scalar, using only a pretrained generator and weak supervision.
In practice, we observe that the optimal latent space for
GAN inversion may differ from the optimal space for finding semantic latent directions. In this case, a simple distance from the hyperplane cannot be calculated. To bridge the gap and derive a latent distance, we learn a task-specific mapping between distances in the two spaces using only latent-space considerations, with no additional supervision.
Through extensive evaluation, we show that our model can produce state-of-the-art results on few-shot learning tasks such as pose and age estimation, without any direct supervision on other domains, and that it can even match or outperform fully-supervised methods designed for specific tasks and trained on tens of thousands of samples. Where no supervision is available, we show that our model produces meaningful scores by demonstrating its applicability to the tasks of ordinal regression and sorting collections of images by the strength of a semantic property.
In summary, our contributions are:
• The observation that latent-space distances are highly semantic features, useful for downstream tasks.
• A scheme for converting a pretrained generator and a semantic latent-direction into a state-of-the-art few-shot regressive model.
• A new approach to analyzing layer-importance and mapping semantic distances between the latent spaces of a GAN. 2.