Abstract
We solve object localisation in partial scenes, a new prob-lem of estimating the unknown position of an object (e.g. where is the bag?) given a partial 3D scan of a scene. The proposed solution is based on a novel scene graph model, the Spatial Commonsense Graph (SCG), where objects are the nodes and edges define pairwise distances between them, enriched by concept nodes and relationships from a common-sense knowledge base. This allows SCG to better generalise its spatial inference to unknown 3D scenes. The SCG is used to estimate the unknown position of the target object in two steps: first, we feed the SCG into a novel Proximity Predic-tion Network, a graph neural network that uses attention to perform distance prediction between the node representing the target object and the nodes representing the observed ob-jects in the SCG; second, we propose a Localisation Module based on circular intersection to estimate the object position using all the predicted pairwise distances in order to be inde-pendent of any reference system. We create a new dataset of partially reconstructed scenes to benchmark our method and baselines for object localisation in partial scenes, where our proposed method achieves the best localisation performance.
Code and Dataset are available here: https://github. com/IIT-PAVIS/SpatialCommonsenseGraph 1.

Introduction
The localisation of unobserved objects given a partial observation of a scene is a fundamental task that humans solve often in their everyday life as shown in Fig. 1. Such a task is useful for many automation applications, includ-ing domotics for assisting visually impaired humans to find everyday items [10], visual search for embodied agents [3], and layout proposal for interior design [23]. Yet, object lo-calisation in partial scenes has never been formally studied
This project has received funding from the European Union’s Hori-zon 2020 research and innovation programme “MEMEX” under grant agreement No 870743, and the Italian Ministry of Education, Universities and Research (MIUR) through PRIN 2017 - Project Grant 20172BH297:
I-MALL and “Dipartimenti di Eccellenza 2018-2022”.
Figure 1: Given a set of objects (indicated in the green cir-cles) in a partially known scene, we aim at estimating the position of a target object (indicated in the orange circle).
We treat this localisation problem as an edge prediction prob-lem by constructing a novel scene graph representation, the
Spatial Commonsense Graph (SCG), that contains both the spatial knowledge extracted from the reconstructed scene, i.e. the proximity (black edges) and the commonsense knowl-edge represented by a set of relevant concepts (indicated in the pink circles) connected by relationships, e.g. UsedFor (orange edges) and AtLocation (blue edges). in the literature. We formalise the problem as the inference of the position of an arbitrary object in an unknown area of a scene based only on a partial observation of the scene.
Humans perform this object localisation task not only by using the partially observed environment, but also by relying on the commonsense knowledge that is acquired during our lifetime experience. For example, by knowing that pillows are often close to beds (the spatial relationship), and that chairs and beds are often used for resting (the affordance relationship), one could infer the whereabouts of pillows even if only a bed and a chair were observed. In this paper, we question whether it is possible to computationally solve this task by injecting the commonsense knowledge within a scene graph representation [19, 12, 32], so that a machine can also reasonably localise an object in the unseen part of the scene, without the use of any visual/depth information.
In this work, we propose a new scene graph representa-tion, the Spatial Commonsense Graph (SCG), having het-erogeneous nodes and edges that embed the commonsense knowledge together with the spatial proximity of objects as measured in the partial 3D scan of the scene. The underlying intuition is that commonsense knowledge extracted from an external knowledge base is not specific to any observed visual scene, and thus allows for a better generalisation, but at the cost of a coarser localisation. At the same time, the objects’ arrangement in the known portion of the scene is useful in providing better pairwise object distances, strength-ening the estimate of the target object position. The main challenge here is devising a model that promotes the gener-alisation of commonsense while increasing the accuracy of the scene-specific metrics.
The proposed scene graph, as shown in Fig. 2, is first de-fined by nodes representing the known objects in the scene that are fully connected through edges representing the prox-imity, i.e. the relative distance between a pair of objects. We call this spatial representation the Spatial Graph (SG) of the known partial 3D scan. Then, the SG is further expanded into the SCG by adding and connecting nodes that repre-sent concepts through relevant commonsense relationships extracted from ConceptNet [29].
The SCG is instrumental to address the localisation prob-lem. In this work, we propose a two-stage solution, dubbed
SCG Object Localiser (SCG-OL). First we predict the pair-wise proximity between the target object node, having an un-known position, and each of the known object nodes through our graph-based Proximity Prediction Network (PPN), for-mulating the task as an edge regression problem. We then use our Localisation Module to compute the position of the target based on the pairwise distances. The localisation mod-ule estimates the most probable position as the intersection of the circular areas defined by all pairwise object distances.
Note that by only using distances between pairs of objects, our model does not depend on the scene’s reference frame, thus being considered agnostic to the coordinate system.
We also introduce a new dataset built from partial re-constructions of real-world indoor scenes using RGB-D se-quences from ScanNet [7], which we will use as a benchmark for this novel problem. We construct the dataset to reflect different completeness levels of the reconstructed scenes.
We define the evaluation protocol via a set of performance measures to quantify the localisation success and accuracy.
To summarise, our core contributions are the following:
• We identify a novel task of object localisation in partial scenes and propose a graph-based solution. We make available a new dataset and evaluation protocol, and show that our method achieves the best performance w.r.t. other comparing methods.
• We propose a new heterogeneous scene graph, the Spa-tial Commonsense Graph, for an effective integration between the commonsense knowledge and the spatial scene, using attention-based message passing for the graph updates to prioritise the assimilation of knowl-edge relevant to the task.
• We propose SCG Object Localiser, a two-staged lo-calisation solution that is agnostic to scene coordinates.
The distances between the unseen object and all known objects are first estimated and then used for the locali-sation based on circular intersections. 2.