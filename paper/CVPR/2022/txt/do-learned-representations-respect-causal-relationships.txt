Abstract
Data often has many semantic attributes that are causally associated with each other. But do attribute-specific learned representations of data also respect the same causal relations? We answer this question in three steps. First, we introduce NCINet, an approach for obser-vational causal discovery from high-dimensional data.
It is trained purely on synthetically generated representations and can be applied to real representations, and is specif-ically designed to mitigate the domain gap between the two. Second, we apply NCINet to identify the causal rela-tions between image representations of different pairs of at-tributes with known and unknown causal relations between the labels. For this purpose, we consider image represen-tations learned for predicting attributes on the 3D Shapes,
CelebA, and the CASIA-WebFace datasets, which we an-notate with multiple multi-class attributes. Third, we an-alyze the effect on the underlying causal relation between learned representations induced by various design choices in representation learning. Our experiments indicate that (1) NCINet significantly outperforms existing observational causal discovery approaches for estimating the causal rela-tion between pairs of random samples, both in the presence and absence of an unobserved confounder, (2) under con-trolled scenarios, learned representations can indeed sat-isfy the underlying causal relations between their respective labels, and (3) the causal relations are positively correlated with the predictive capability of the representations. Code and annotations are available at: https://github. com / human - analysis / causal - relations -between-representations. 1.

Introduction
Consider the face image in Fig. 1a. Automated face analysis systems typically involve extracting semantic at-tributes from the face. These attributes are often related through an underlying causal mechanism governing the re-lations between them. Modern computer vision systems ex-cel at predicting such attributes by learning from large-scale (a) Illustration of causal relations between attribute labels (b) Causal relations between attribute-specific learned representations
Figure 1. Visual data may have multiple causally associated at-tributes. The goal of this paper is to determine whether attribute-specific learned representations respect the underlying causal rela-tionships between the attributes? And if so, to what extent? annotated datasets. This is achieved by learning compact attribute-specific representations of the image from which the attribute prediction is made. This setting naturally raises the following questions (Fig. 1b): (1) Can we estimate the causal relations between high-dimensional representations purely from observational data with high accuracy?, (2)
Do the learned attribute-specific representations also sat-isfy the same underlying causal relations, and if so to what extent?, and finally (3) How are the causal relations affected by factors such as the extent of training, overfitting, network architecture, etc. Answering these questions is the primary goal of this paper.
Our work is motivated by the empirical observation that modern representation learning algorithms are inclined to uncontrollably absorb all correlations in the data [50]. Con-sequently, while such systems have exhibited significantly improved empirical performance across many applications, it has also led to unintended consequences, ranging from bias against demographic groups [4] to loss of privacy by extracting and leaking sensitive information [49]. Identify-ing the causal relations between representations can help
mitigate the deleterious effects of spurious correlations.
With the proliferation of computer vision systems that em-ploy such representations, it is imperative to devise tools to discover the causal relations given a set of representations.
Discovering causal relations from learned representa-tions poses two main challenges. First, causal discovery typically involves interventions [44] on the data which are either difficult or impossible on the observational represen-tation space. For instance, in the image space, interventions may be possible during the image acquisition process for certain attributes such as hair color, eyeglasses, etc. Such interventions are, perhaps, not possible for attributes such as gender or ethnicity. On the other hand, it is not appar-ent how to intervene on any of these attributes directly in the representation space. Second, causal discovery meth-ods, for pairs or whole graphs, are typically evaluated on small-scale low-dimensional datasets with multiple related attributes. However, there are no large-scale image datasets labeled with multiple causally associated attributes, nor are there any standardized protocols for evaluating the effec-tiveness of causal discovery methods on learned represen-tations. While existing datasets such as MSCOCO [32] and
CelebA [34] are labeled with multiple attributes they are ei-ther not causally related to each other (e.g., MSCOCO) or only have binary labels that suffer from severe class imbal-ance (e.g., CelebA).
To mitigate these challenges; (1) We propose Neural
Causal Inference Net (NCINet) â€“ a learning-based approach for observational causal discovery from high-dimensional representations, both in the presence and absence of a con-founder. NCINet is trained on a custom synthetic dataset of representations generated through a known causal mech-anism. And, to ensure that it generalizes to real represen-tations with complex causal relations we, (a) incorporate a diverse set of function classes with varying complexity into the data generating mechanism, and (b) introduce a learn-ing objective that is explicitly designed to encourage do-main generalization. (2) We develop an experimental pro-tocol where, (a) existing datasets can be controllably resam-pled to induce a desired known causal relationship between the attribute labels, (b) learn attribute representations from the resampled data and infer the causal relations between them. We adopt three image datasets, namely, 3D Shapes dataset [7], CelebA [34] and CASIA WebFace [60], where we annotate the latter with multiple multi-label attributes.
Contributions: First, we propose a learning-based tool,
NCINet, for causal discovery from high-dimensional obser-vational data, both in the presence and absence of a con-founder. Numerical experiments on both synthetic and real-world data causal discovery problems indicate that NCINet exhibits significantly better causal inference generalization than existing approaches. Second, we employ NCINet for causal inference on attribute-specific learned represen-tations and make the following observations; (1) Learned attribute-specific representations do satisfy the same causal relations between the corresponding attribute labels under controlled scenarios with high causal strength. (2) The causal consistency is highly correlated with the predictive capability of the attribute classifiers (e.g., causal consis-tency degrades with overfitting). 2.