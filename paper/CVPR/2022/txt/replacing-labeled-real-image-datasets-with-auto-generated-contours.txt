Abstract
In the present work, we show that the performance of formula-driven supervised learning (FDSL) can match or even exceed that of ImageNet-21k without the use of real images, human-, and self-supervision during the pre-training of Vision Transformers (ViTs). For example, ViT-Base pre-trained on ImageNet-21k shows 81.8% top-1 ac-curacy when ﬁne-tuned on ImageNet-1k and FDSL shows 82.7% top-1 accuracy when pre-trained under the same conditions (number of images, hyperparameters, and num-ber of epochs).
Images generated by formulas avoid the privacy/copyright issues, labeling cost and errors, and bi-ases that real images suffer from, and thus have tremendous potential for pre-training general models.
To understand the performance of the synthetic images, we tested two hypotheses, namely (i) object contours are what matter in FDSL datasets and (ii) increased number of parameters to create labels affects performance improve-ment in FDSL pre-training. To test the former hypothe-sis, we constructed a dataset that consisted of simple object contour combinations. We found that this dataset can match the performance of fractals. For the latter hypothesis, we found that increasing the difﬁculty of the pre-training task generally leads to better ﬁne-tuning accuracy. 1.

Introduction
Image recognition has greatly beneﬁted from labeled real-image datasets. Conventional image datasets comprise real images of various objects on a general background annotated by humans. A visual representation can be ac-quired by learning from real images with such annotations.
Supervised learning (SL) is the most trusted approach for this task. However, in recent years self-supervised learning (SSL) has gained ground [6–9, 16].
SSL methods have recently been used to pre-train Vision
Transformers (ViTs) [13]; however, datasets with hundreds
Figure 1. We have found that vision transformers (ViT) can be successfully pre-trained without real images, human- and self-supervision, and can exceed the accuracy of ImageNet-21k pre-training when ﬁne-tuned on ImageNet-1k. We constructed a new dataset Radial Contour DataBase (RCDB) based on the as-sumption that contours are what matter for the pre-training of
ViT. RCDB also exceeded the performance of ImageNet-21k pre-training, while consisting only of contours. of millions of images are required [11, 32]. The learning methods DINO [5] and MoCoV3 [10] show that it is possi-ble to train on relatively small datasets such as ImageNet-1k (ILSVRC) [31]. SSL methods remove the time-consuming labeling of a dataset, but do not address privacy, copyright, and societal biases when real images are used [2, 37].
Formula-driven supervised learning (FDSL) trains on synthetic images generated by mathematical formulas and thus avoids such issues [1, 3, 19–21, 27]. The images can be categorized and labeled automatically based on the pa-rameters of the equations used to generate them. Because the images are generated by mathematical formulas, they avoid the ethical problems associated with labeled real-image datasets. If FDSL can be used to pre-train models to the same accuracy as that achieved with real images, it could replace SL/SSL to avoid ethical issues.
To improve FDSL methods, Kataoka et al. [21] used fractal geometry based on the assumption that fractals are a natural phenomenon. They found that the actual perfor-mance depends on the number of hyperparameters in order
In the present work, we inves-to create FDSL datasets. tigate the most inﬂuential factors for generating synthetic images from formulas and the possibility of using alterna-tives to fractals. We establish some basic guidelines that lead to better FDSL methods to avoid the iterative process of rendering and pre-training.
In this paper, we enhance the performance of FDSL in the context of pre-training ViTs [13]. We ﬁrst test the fol-lowing two hypotheses. Hypothesis 1: object contours are increased what matter in FDSL datasets. Hypothesis 2: number of parameters affects performance improvement in
FDSL pre-training. Preliminary study that led to these hy-potheses are shown in Section 3.1. Through the valida-tion of these hypotheses, we generate an improved synthetic dataset that allowed us to pre-train ViTs with a higher accu-racy than that of real-image datasets.
Impact of the paper. We show that the performance of pre-training ViTs with FDSL can match or even exceed that of pre-training ViT with ImageNet-21k. When ﬁne-tuned on ImageNet-1k, ViT-Base pre-trained on ImageNet-21k has a top-1 accuracy of 81.8% and that pre-trained on Ex-tended Fractal DataBase (ExFractalDB) and Radial Contour
DataBase (RCDB) (which has the same number of classes and instances per class) has an accuracy of 82.7 and 82.4%, respectively (Figure 1, Table 7).
Effect of Hypothesis 1. To understand the performance of fractal images, we explore alternative formulas for gen-erating images. In our preliminary study (see Section 3.1), we found that the object contours in the fractal images play an important role. Therefore, we created a dataset that is speciﬁcally tailored to drawing object contours (called
RCDB). The performance of this dataset matches that of
FractalDB (Table 3).
Effect of Hypothesis 2. We ﬁnd that higher complexity of the mathematically generated images improves the accu-racy of FDSL (Table 5). The complexity of the images can be increased by adjusting the parameters of the formula-driven image generation. For example, RCDB becomes more complex when the number of vertices is increased; its complexity can also be changed by adjusting the con-tour smoothness, number of polygons, and radius (Table 2).
The complexity of FractalDB can be increased by applying an iterative function system (IFS) in three-dimensional (3D) space instead of two-dimensional (2D) space. 2.