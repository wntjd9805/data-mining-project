Abstract
In this work, we focus on scene flow learning on point clouds in a self-supervised manner. A real-world scene can be well modeled as a collection of rigidly moving parts, therefore its scene flow can be represented as a combina-tion of rigid motion of each part. Inspired by this obser-vation, we propose to generate pseudo scene flow for self-supervised learning based on piecewise rigid motion es-timation, in which the source point cloud is decomposed into a set of local regions and each region is treated as rigid. By rigidly aligning each region with its potential counterpart in the target point cloud, we obtain a region-specific rigid transformation to represent the flow, which together constitutes the pseudo scene flow labels of the en-tire scene to enable network training. Compared with most existing approaches relying on point-wise similarities for scene flow approximation, our method explicitly enforces region-wise rigid alignments, yielding locally rigid pseudo scene flow labels. We demonstrate the effectiveness of our self-supervised learning method on FlyingThings3D and
KITTI datasets. Comprehensive experiments show that our method achieves new state-of-the-art performance in self-supervised scene flow learning, without any ground truth scene flow for supervision, even outperforming some super-vised counterparts.
Figure 1. Comparison of the pseudo scene flow labels produced by nearest neighbor search and our proposed method. (a) Input point clouds from two consecutive frames; (b) Pseudo labels generated by the point matching with per-point nearness as a measure; (c)
Pseudo labels generated by our proposed method. Green line rep-resents the correct pseudo label with absolute error less than 0.1m or relative error less than 10%. Red line represents the incorrect pseudo label. 1.

Introduction
Scene flow [35] is a 3D motion field to describe the mo-tion of every point between two time steps. As an essen-tial representation of dynamics, scene flow can be applied in numerous downstream applications, such as robotics and autonomous driving, for dynamic scene understanding. Due to the wide applications of 3D sensors, scene flow estima-tion with point clouds as input has attracted broad inter-*Corresponding author: G. Lin. (e-mail: gslin@ntu.edu.sg ) est. However, scene flow data is difficult to collect
[25], which makes supervised learning approaches suffer from a shortage of real-world training samples. To overcome the reliance on scene flow data, scene flow learning in a self-supervised manner is proposed as a promising solution, which is the focus of our work here.
To enable deep network training under the self-supervised setting, it is crucial to approximate the scene flow labels given unlabelled point cloud data. To do so,
most previous approaches [1, 13, 16, 27, 29, 34, 42] perform point matching between two consecutive point clouds to es-tablish point correspondences and treat the 3D coordinate difference between each matching pair as the pseudo scene flow label. However, the point matching strategies applied in these approaches mainly consider point-wise similari-ties, but often fail to capture potential structured motions of points, leading to inconsistent pseudo scene flow labels.
Fig. 1 (b) shows an example of the estimated pseudo scene flow labels based on point matching with per-point nearness as a measure.
For a real-world scene, most of the structures in this scene are rigid or almost so [23]. This allows us to decom-pose a non-rigid scene into a collection of rigidly moving parts, such that the entire scene flow can be approximated by estimating the rigid motion of individual parts. Based on this intuition, in this work, we propose to generate the pseudo scene flows from point clouds by piecewise rigid motion estimations.
To achieve this goal, an over-segmentation approach is employed to decompose the source point cloud into super-voxels and these supervoxels are treated as rigid during the pseudo label generation. By solving an independent rigid registration for each supervoxel, we find a rigid transfor-mation that rigidly aligns this supervoxel with its poten-tial counterpart in the target point cloud. Based on the rigid transformation estimate, we produce the rigid flow of each supervoxel, thereby generating the entire scene flow approximation as pseudo labels for self-supervised learning. Different from most existing self-supervised ap-proaches that neglect potential structured motions of points, our method explicitly enforces region-wise rigid alignments and generates locally rigid pseudo scene flow labels, where the pseudo labels of points in the same supervoxel obey the same rigid motion pattern.
Main contributions of this paper are listed as follows:
• We present a new self-supervised scene flow learn-ing approach (RigidFlow) that solves the pseudo scene flow label generation as a piecewise rigid motion esti-mation task;
• By decomposing the source point cloud into a set of local regions, we propose a piecewise pseudo label generation module that explicitly enforces region-wise rigid alignments and produces rigid pseudo flow for each local region.
• Our proposed RigidFlow achieves state-of-the-art per-formance in self-supervised scene flow learning, with-out any ground truth scene flow for supervision, even outperforming some supervised counterparts. 2.