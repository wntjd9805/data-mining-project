Abstract
General object detectors are always evaluated on hand-designed datasets, e.g., MS COCO and Pascal VOC, which tend to maintain balanced data distribution over different classes. However, it goes against the practical applica-tions in the real world which suffer from a heavy class im-balance problem, known as the long-tailed object detec-In this paper, we propose a novel method, named tion.
Adaptive Hierarchical Representation Learning (AHRL), from a metric learning perspective to address long-tailed object detection. We visualize each learned class represen-tation in the feature space, and observe that some classes, especially under-represented scarce classes, are prone to cluster with analogous ones due to the lack of discrimina-tive representation. Inspired by this, we propose to split the whole feature space into a hierarchical structure and elim-inate the problem in a coarse-to-fine way. AHRL contains a two-stage training paradigm. First, we train a normal baseline model and construct the hierarchical structure un-der the unsupervised clustering method. Then, we design an
AHR loss that consists of two optimization objectives. On the one hand, AHR loss retains the hierarchical structure and keeps representation clusters away from each other. On the other hand, AHR loss adopts adaptive margins accord-ing to specific class pairs in the same cluster to further opti-mize locally. We conduct extensive experiments on the chal-lenging LVIS dataset and AHRL outperforms all the existing state-of-the-art methods, with 29.1% segmentation AP and 29.3% box AP on LVIS v0.5 and 27.6% segmentation AP and 28.7% box AP on LVIS v1.0 based on ResNet-101. We hope our simple yet effective approach will serve as a solid baseline to help stimulate future research in long-tailed ob-ject detection. Code will be released soon. 1.

Introduction
The emerging of convolutional neural networks (CNNs) leads to prosperity in object detection. With effort of re-Figure 1. Comparisons between the state-of-the-art methods and our AHRL on LVIS v0.5 [8]. We report different task results (ob-ject detection and instance segmentation) on both ResNet-50(red) and ResNet-101(blue) backbones. AP s stands for the segmen-tation AP, while AP b means the box AP. Our proposed AHRL outperforms all the existing methods. searchers, recent advances in object detection achieve en-couraging results in manually balanced datasets, like Pas-cal VOC [5] and MS COCO [18]. However, in real-ity, we always need to face long-tailed distributed data
[25], where head classes(classes with plenty of instances) and tailed/scarce classes(classes with few instances) signifi-cantly differ in the number of instances. Nevertheless, many traditional detection models are hard to take care of head classes and tailed classes in the same time, resulting in the desire for an adaptive solution.
Different from long-tailed object recognition, an addi-tional localization sub-task makes long-tailed object detec-tion more challenging. Extreme imbalance of the instance number for each class still restricts its performance. Almost all the past works [3, 12, 15, 31, 35, 37] on long-tailed ob-ject detection reach a consensus that classifier is the major bottleneck for further improvements. As shown in Figure
(a) Variance of weights (b) t-SNE visualization of class weights (c) Results of coarse and fine classification
Figure 2. (a) The average variance for different frequent groups. (b) t-SNE visualization of classifier weights in Mask R-CNN. Red, green and blue points stand for the class weight/center of rare, common and frequent classes, respectively. And dotted ellipses mark some obvious clusters. (c) Results of coarse and fine classification. The blue bar represents the standard result of Mask R-CNN on LVIS v0.5, while orange bar represents the coarse result by ignoring misclassification in the same cluster. 2a, we calculate the variance of the classification weight for each class during the model training and take average ac-cording to their frequency groups, i.e., rare, common, and frequent in LVIS v0.5 [8]. Head classes dominate the model optimization due to the more diverse samples, while tailed classes are seldom tackled because of the heavy data imbal-ance. Thus, it always leads to unsatisfactory performance.
Following long-tailed object recognition, early attempts in long-tailed object detection exploit data re-sampling [3, 8] and loss re-weighting [7,14,23,29,31,35] strategies to solve this problem. By data re-sampling, a more balanced dataset is given to the model, preventing the bias to head classes to some extent. Compared with directly balancing dataset, loss re-weighting approaches elaborately modify the weight to adapt to the long-tailed scene. However, these methods suffer from overfitting to the limited data, and the overall performance is always sensitive to the re-weighting or re-sampling hyperparameters.
In this work, we present a simple yet effective method, named Adaptive Hierarchical Representation Learning (AHRL), from a metric learning perspective to address the long-tailed object detection problem. As shown in Figure 2b, we take Mask R-CNN [10] as an example model to train on LVIS v0.5 [8] dataset and utilize t-SNE [33] to visualize each class weight. Each dot in Figure 2b stands for a spe-cific class center, and we select 247 out of 1230 classes for better illustration. Moreover, rare, common, and frequent classes are marked in red, green, and blue, respectively (de-tailed class information for those dots can be found in our supplementary materials). We can find an interesting phe-nomenon that some classes, especially under-represented scarce classes, are prone to cluster with analogous ones due to the lack of discriminative representation. Thus, these classes tend to be misclassified and result in poor perfor-mance. Go a step further. We adopt K-Means to group all the class centers into 50 clusters and ignore the mis-classification in the same cluster to re-evaluate the perfor-mance. As depicted in Figure 2c, we distinguish this evalu-ation method and the standard one as coarse and fine classi-fication results, respectively, and we observe that coarse re-sults are much better than fine results, especially for scarce classes, which also verifies our assumption above. This dis-covery opens up room to optimize the long-tailed object detection performance and inspires us to handle this tough problem in a coarse-to-fine way.
Motivated by the observation above, we resort to a coarse-to-fine strategy to tackle this problem and design a two-stage training procedure AHRL from a hierarchical
In the first stage, we representation learning perspective. follow standard settings in [8, 10, 31] to train a typical base-line model, i.e., Mask R-CNN. Then, we adopt unsuper-vised clustering algorithms, i.e., K-Means, to build the hier-archical feature space based on the classification weights of the pre-trained model.
In the second stage, we pro-pose a novel loss function, named Adaptive Hierarchical
Representation loss (or AHR loss), to implement our coarse-to-fine design. AHR loss involves two optimiza-tion objectives, one for coarse-grained classification and the other one for fine-grained classification. On the one hand, AHR loss retains the constructed hierarchical struc-ture and prompts all clusters to repel each other. On the other hand, AHR loss adopts dynamic and adaptive margins according to the specific relationship between each class pair in the same cluster, the more similar pairs they are and the larger margins between them are performed during the whole training process, to make indistinguishable classes more discriminative. We conduct extensive experiments on
LVIS dataset and achieve new state-of-the-art results with both ResNet-50 [11] and ResNet-101 [11] backbones, as shown in Figure 1.
To sum up, the contributions of this work are as follow:
• We delve deep into the long-tailed object detection problem and present a strong baseline to help ease fu-ture research, which already beats the most state-of-the-art methods.
(a) Objectness score (b) Proposals per instance (c) Norm of class weights
Figure 3. (a) Average objectness score per instance in RPN during training. All boxes are filtered by IOU threshold and matched with corresponding ground-truth to get their labels and frequency. Different frequency groups are marked by different colors. (b) Proposals per instance. We monitor the average proposals per instance for different frequency groups during the model training. (c) Magnitude of weight vectors for different classes. Different background colors stand for different frequency groups. The norms of weights are sorted in descending order in every frequency group.
Hierarchical
• We present a simple and effective approach, named
Learn-Adaptive ing(AHRL), from a metric learning perspective to eliminate long-tailed object detection in a coarse-to-fine way. A novel AHR loss is also proposed to make AHRL work better.
Representation
• Compared with other existing state-of-the-art methods, our proposed method outperforms them and achieves a new state-of-the-art performance on LVIS benchmarks with various backbones. 2.