Abstract
Current Knowledge Distillation (KD) methods for se-mantic segmentation often guide the student to mimic the teacher’s structured information generated from individ-ual data samples. However, they ignore the global se-mantic relations among pixels across various images that are valuable for KD. This paper proposes a novel Cross-Image Relational KD (CIRKD), which focuses on transfer-ring structured pixel-to-pixel and pixel-to-region relations among the whole images. The motivation is that a good teacher network could construct a well-structured feature space in terms of global pixel dependencies. CIRKD makes the student mimic better structured semantic relations from the teacher, thus improving the segmentation performance.
Experimental results over Cityscapes, CamVid and Pascal
VOC datasets demonstrate the effectiveness of our proposed approach against state-of-the-art distillation methods. The code is available at https://github.com/winycg/CIRKD. 1.

Introduction
Semantic segmentation is a crucial and challenging task in computer vision. It aims to classify each pixel in the input image with an individual category label. The applications of segmentation often focus on autonomous driving, virtual reality and robots. Although popular state-of-the-art seg-mentation networks, such as DeepLab [3, 5], PSPNet [51] and OCRNet [47], achieve remarkable performance, they often need high computational costs. This weakness makes them difﬁcult to be deployed for real-world scenarios over resource-limited mobile devices. Therefore, a series of lightweight segmentation networks are proposed, such as
ESPet [24], ICNet [50] and BiSeNet [46]. Moreover, model compression is also an alternative ﬁeld to pursue com-∗Corresponding author. (a) Intra-image relational KD. (b) Cross-image relational KD.
Figure 1. Overview of intra-image (left) and our proposed cross-image relational distillation (right). The circles ( or
) with the same color denote pixel embeddings from the identical image. ti and si represent the pixel embeddings of the i-th pixel location tagged in an image from the teacher and student, respectively. The dotted line (
) shows the similarity relationship between two pixels. The circles and lines construct a relational graph. pact networks, mainly divided into quantization [37], prun-ing [2, 43] and knowledge distillation (KD) [16, 30, 41].
This paper investigates KD to improve the performance of a compact student network under the guidance of a high-capacity teacher network for semantic segmentation. A broad range of KD approaches [16, 18, 41, 48] have been well studied but mostly for image classiﬁcation tasks. Un-like image-level recognition, the segmentation task aims at dense pixel predictions, which is more challenging. Pre-vious researches [18, 22] have found that directly utilizing classiﬁcation-based KD methods to deal with dense predic-tion tasks may not achieve desirable performance. This is because strictly aligning the coarse feature maps between the teacher and student networks may lead to negative con-straints and ignore the structured context among pixels.
Recent works attempt to propose specialized KD meth-ods [14, 20, 21, 30, 35, 40] for semantic segmentation. Most focus on mining correlations or dependencies among spa-tial pixel locations because segmentation needs a structured output. Typical knowledge can be local pixel afﬁnity [40], global pairwise relations [14, 20] and intra-class pixel vari-ation [35]. Such methods often perform better than the tra-ditional point-wise alignment in capturing structured spatial knowledge. More recently, Shu et al. [30] revealed that each channel represents a category-speciﬁc mask and thus pro-posed Channel-Wise KD (CWD) [30]. CWD achieves state-of-the-art distillation performance and demonstrates the im-portance of channel-level information for dense prediction tasks. However, previous segmentation KD methods often guide a student to mimic the teacher’s structured informa-tion generated from individual data samples. They ignore cross-image semantic relations among pixels for knowledge transfer, as shown in Fig. 1.
Based on this motivation, we propose Cross-Image Re-lational Knowledge Distillation (CIRKD) for semantic seg-mentation. The core idea is to construct global pixel re-lations across the whole training images as meaningful knowledge. A good pre-trained teacher network could of-ten generate a well-structured pixel embedding space and capture better pixel correlations than a student network.
Based on this property, we transfer such pixel relations from teacher to student. Speciﬁcally, we propose pixel-to-pixel distillation and pixel-to-region distillation to fully exploit structured relations across various images. The former aims to transfer similarity distributions among pixel embeddings.
The latter focuses on transferring pixel-to-region similar-ity distributions complementary to the former. The region embedding is generated by averagely pooling pixel embed-dings from the same class and represents that class’s fea-ture center. The pixel-to-region relations indicate the rela-tive similarities between pixels and class-wise prototypes.
A naive way for constructing cross-image relations is to derive embeddings from the current mini-batch. How-ever, the batch size of the segmentation task is often small, limiting the network to capture broader pixel dependencies.
Motivated by previous self-supervised learning [31, 38], we introduce a pixel queue and a region queue in the mem-ory bank to store abundant embeddings for modelling long-range pixel relations. The embeddings in queues are con-sistent during the distillation process, since they are gener-ated from the pre-trained and frozen teacher network. We regard the teacher and student pixel embeddings from the current mini-batch as anchors. We randomly sample con-trastive embeddings from the queues to model pixel-to-pixel as well as pixel-to-region similarity distributions. Then we align such soft relations via KL-divergence from the student to teacher.
CIRKD guides the student network to learn the global property of relative pixel structures across training im-ages from the teacher, further improving the segmenta-tion performance. We evaluate our method over popular
DeepLabV3 [5] and PSPNet [51] architectures on three seg-mentation benchmark datasets: Cityscapes [7], CamVid [1] and Pascal VOC [9]. Experimental results indicate that
CIRKD outperforms other state-of-the-art distillation ap-proaches, demonstrating the value of transferring global pixel relationships in semantic segmentation.
The main contributions are summarized as follows:
• We propose cross-image relational KD to transfer global pixel relationships. We may be the ﬁrst to build pixel dependencies across global images for segmen-tation KD.
• We propose pixel-to-pixel and pixel-to-region distilla-tion with the memory bank mechanism to fully explore structured relations for transfer.
• Our CIRKD achieves the best distillation performance among state-of-the-art methods on the public segmen-tation datasets. 2.