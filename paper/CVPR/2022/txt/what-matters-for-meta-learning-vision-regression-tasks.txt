Abstract
Meta-learning is widely used in few-shot classification and function regression due to its ability to quickly adapt to unseen tasks. However, it has not yet been well ex-plored on regression tasks with high dimensional inputs such as images. This paper makes two main contributions that help understand this barely explored area. First, we design two new types of cross-category level vision regres-sion tasks, namely object discovery and pose estimation of unprecedented complexity in the meta-learning domain for computer vision. To this end, we (i) exhaustively evaluate common meta-learning techniques on these tasks, and (ii) quantitatively analyze the effect of various deep learning techniques commonly used in recent meta-learning algo-rithms in order to strengthen the generalization capability: data augmentation, domain randomization, task augmenta-tion and meta-regularization. Finally, we (iii) provide some insights and practical recommendations for training meta-learning algorithms on vision regression tasks. Second, we propose the addition of functional contrastive learning (FCL) over the task representations in Conditional Neural
Processes (CNPs) and train in an end-to-end fashion. The experimental results show that the results of prior work are misleading as a consequence of a poor choice of the loss function as well as too small meta-training sets. Specifi-cally, we find that CNPs outperform MAML on most tasks without fine-tuning. Furthermore, we observe that naive task augmentation without a tailored design results in un-derfitting. 1.

Introduction
Humans are able to rapidly learn the fundamentals of new tasks within minutes of experience based on prior knowledge. For instance, humans can classify novel ob-jects by capturing the distinguishable properties (e.g., tex-tures, shapes and scales) from only a few examples. Meta-learning is proposed to learn relevant knowledge from var-ious tasks and generalize to unseen tasks with only a few
Figure 1. Meta-learning vision regression tasks are designed to i) identify the queried object from context and predict its position for target images (Distractor), ii) identify the object’s canonical pose from context and predict the 1D rotation relative to the canonical pose for target images (ShapeNet1D), iii) predict the 2D rotation w.r.t. the canonical pose with random background (ShapeNet2D).
Predictions are performed on unseen objects. samples. Of the various meta-learning algorithms, MAML-based models [1–4] and Neural Processes (NPs) [5–8] are two variants which are receiving increasing attention in the recent years. Both algorithms try to learn good prior knowl-edge from related tasks without expanding the learned pa-rameters or sacrificing efficiency at inference. While these methods have shown promising results in many domains, such as few-shot classification [2, 9–12] and hyperparam-eter optimization [13–15], an extensive study on meta-learning vision regression tasks has not yet been conducted.
This is in particular true for NPs which have mostly been investigated on tasks with low-dimensional input such as function regression or pixel-wise completion [16–19].
In this paper, we make two major contributions to the largely unexplored area of meta-learning on high-in-dimensional input tasks. On the algorithmic level,
spired by SimCLR [20], we propose an improvement to
NPs by employing contrastive learning at the functional space (FCL) and still train the model in an end-to-end fash-ion. On the experimental side, we propose two applica-tion datasets, object discovery and pose estimation, which are based on high-dimensional inputs and require the meta-learning models to learn and reason at an image level.
For the first application we create a regression task called
“Distractor” (see Fig. 1), where each image contains two objects, the queried object and a distractor object, placed at random positions. The goal of this task is to identify the queried object and predict its position in the image plane. Unlike previous tasks such as image completion, where each pixel is considered as an independent input, our task requires the model to learn a high-level representation from the entire image. The second application (i.e., pose estimation) is inspired by prior work [21–24] on the Pas-cal1D dataset. As this dataset shows limited object varia-tions and features only 1D rotation around the azimuth axis, we generate two new datasets with increasing task diversity, e.g., by introducing random background, cross-categorical object variations and 2D rotation. Since the background is generated from real-world images instead of blank as in prior work, our datasets significantly increase the task dif-ficulty and allow us to perform a thorough investigation of the performance for the considered meta-learning ap-proaches. Examples of our datasets are shown in Fig. 1 where i) ShapeNet1D contains 1D rotations as in Pascal1D, however with larger object variations and ii) ShapeNet2D features 2D rotation and random background.
For both applications, we evaluate the performance on novel objects at both intra-category (IC) and cross-category (CC) levels. The results on Distractor show that our proposed algorithmic improvements significantly in-crease the performance, indicating our methods can en-hance the task expressivity. The results on pose estima-tion demonstrate that meta-learning can successfully be ap-plied to predict poses of unknown objects, which has a huge potential in robotic grasping and virtual/augmented reality (VR/AR).
Prior work [21–24] on Pascal1D also demonstrates that meta-learning algorithms suffer from overfitting, especially with limited training data. Our work analyzes the effect of different techniques commonly adopted in recent meta-learning methods (i.e., data augmentation, task augmenta-tion, regularization and domain randomization) on afore-mentioned datasets. We empirically find that the meta-learning algorithms employed in our work ultimately lead to overfitting regardless of dataset size for both applica-tions. Moreover, our work shows that the results in prior work [21, 22], where MAML typically performs best for such tasks, are misleading.
In particular, we find Condi-tional Neural Processes (CNPs) [5] are more flexible and efficient than MAML in the investigated pose regression tasks. Additionally, we find that MAML [1] suffers from underfitting especially on large-scale datasets and depends heavily on hyperparameter tuning.
The primary contributions of this work can be summa-rized as follows: (1) We investigate meta-learning algo-rithms on vision regression tasks and demonstrate their abil-ity to tackle structured problems. (2) We propose functional contrastive learning on the task representation of CNPs and thereby improve its expressivity. (3) We quantitatively an-alyze various deep learning techniques to alleviate meta overfitting. Our results rectify misleading conceptions from prior work, e.g., that MAML performs best for such tasks.
We also present insights and practical recommendations on designing and implementing meta-learning algorithms on vision regression tasks. 2.