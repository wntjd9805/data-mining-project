Abstract
Modern Earth observation satellites capture multi-exposure bursts of push-frame images that can be super-resolved via computational means. In this work, we pro-pose a super-resolution method for such multi-exposure se-quences, a problem that has received very little attention in the literature. The proposed method can handle the signal-dependent noise in the inputs, process sequences of any length, and be robust to inaccuracies in the exposure times. Furthermore, it can be trained end-to-end with self-supervision, without requiring ground truth high resolution frames, which makes it especially suited to handle real data. i) a
Central to our method are three key contributions: base-detail decomposition for handling errors in the expo-sure times, ii) a noise-level-aware feature encoding for im-proved fusion of frames with varying signal-to-noise ratio and iii) a permutation invariant fusion strategy by tempo-ral pooling operators. We evaluate the proposed method on synthetic and real data and show that it outperforms by a significant margin existing single-exposure approaches that we adapted to the multi-exposure case. 1.

Introduction
High resolution (HR) satellite imagery is a key element in a broad range of tasks, including human activity mon-itoring and disaster relief. Super-resolution by computa-tional methods has recently been adopted [7, 41] by the re-mote sensing industry (Planet SkySat, Satellogic Aleph-1).
By leveraging high frame rate low-resolution (LR) acquisi-tions, low-cost constellations can be effective competitors to more traditional high-cost satellites. In order to capture the full dynamic range of the scene, some satellites use ex-posure bracketing, resulting in sequences with varying ex-posures. While several works have addressed multi-image super-resolution (MISR) of single-exposure sequences, al-most no previous work considers the multi-exposure case.
MISR techniques exploit the aliasing in several LR ac-quisitions to reconstruct a HR image. The maximum attain-able resolution is capped by the spectral decay of the blur kernel resulting from the sensor’s pixel integration and the camera optics, which imposes a frequency cutoff beyond which there is no usable high frequency information.
Aggregating many frames is also interesting as it allows significant noise reduction. If the LR frames are acquired with bracketed exposures, it is possible to integrate them in a super-resolved high dynamic range (HDR) image. Long exposures have higher signal-to-noise ratio (SNR) which helps reduce the noise in dark regions, whereas short expo-sures provide information in bright regions which can cause saturation with longer exposure times.
In this work, our goal is to perform joint super-resolution and denoising from a time series of bracketed satellite im-ages. We focus on push-frame satellite sensors such as the
SkySat constellation from Planet. We increase the resolu-tion by a factor of two, which is the frequency cutoff of the combined optical and sensor’s imaging system. The SkySat satellites [41] contain a full-frame sensor capable of cap-turing bursts of overlapping frames: a given point on the ground is seen in several consecutive images. However, our technique is general and can be applied to other satellites, or beyond satellite imagery to consumer cameras capable of multi-exposure burst or video acquisition.
Several methods have addressed either MISR or HDR imaging from multiple exposures, but their combination has received little attention. Existing works consider an ideal setup in which frames can be aligned with an affinity [7,53] or a homography [55], and the number of acquisitions is large enough to render the problem an overdetermined sys-tem of equations. Such motion models are good approxi-mations for satellite bursts, but ignore parallax [8], which can be noticeable for mountains and tall buildings.
In the case of satellite imaging, push-frame cameras ca-pable of capturing multi-exposure bursts are relatively re-cent, which explains why all previous works on MISR focus on the single-exposure case [7, 17, 40, 43], except for SkySat’s proprietary method [41] producing the L1B product, whose details are not public. Deep learning methods currently outperform traditional model-based ap-proaches [47]. In general, learning-based methods require large realistic datasets with ground truth to be trained, as
LR1
LR2
LR3
LR4
LR5
LR6
LR7
LR8
LR9
LR10
ME S&A
Planet L1B [41]
BD-ACT [7]
DSA [43]
Our HDR-DSP
Figure 1. Super-resolution from a real multi-exposure sequence of 10 SkySat images. Top row: Original low resolution images with different exposures. Bottom row: Reconstructions from five methods, including ours trained with self-supervision (right). methods trained on synthetic data [4] fail to generalize to real images [14]. One of such datasets is the PROBA-V dataset [37], acquired with a satellite equipped with two cameras of different resolutions. This dataset has fostered the publication of several deep learning approaches to satel-lite MISR [9,17,39]. However, the PROBA-V dataset is not appropriate for MISR of LR image bursts acquired at a high frame rate, as the PROBA-V sequences are multi-date and present significant content and illumination changes.
A promising direction is to use self-supervised learning techniques, which have been applied to video restoration tasks such as denoising and demosaicing [18–20, 51, 58], and recently to MISR [43]. These techniques benefit from the temporal redundancy in videos. Instead of using ground truth labels, one of the degraded frames in the input se-quence is withheld from the network and used as label.
Our work builds upon Deep Shift-and-Add (DSA) [43], a self-supervised deep learning method for MISR of single-exposure bursts of satellite images. The model is trained without supervision by exploiting the frame redundancy.
In this work, we propose High Dynamic
Contributions.
Range Deep Shift-and-Pool, HDR-DSP a self-supervised method for joint super-resolution and denoising of brack-eted satellite imagery. The method is able to handle time-series with a variable number of frames and is robust to errors in the exposure times, as the ones provided in the metadata are often inaccurate. This makes our method di-rectly applicable to real image data (see Figure 1). This is, to the best of our knowledge, the first multi-exposure MISR method for satellite imaging, and beyond satellite imagery, it is the first approach based on deep-learning.
Our contributions are the following:
Feature Shift-and-Pool. We propose a shift-and-pool mod-ule that merges features (computed by an encoder network on each input LR frame) into a HR feature map by tempo-ral pooling using permutation invariant statistics: average, maximum, and standard deviation. This gives a rich fused representation which yields a substantial improvement over the average [43], in both single and multiple exposure cases.
Robustness to inaccurate exposure times via base-detail de-composition. We propose normalizing the input frames and decomposing them into base and detail. The errors caused by the inaccurate exposure times affect mainly the base, whereas the detail containing the aliasing required for super-resolution can be safely processed by the network.
Note that vignetting and stray light can also cause exposure issues that affect single and multi-exposure MISR alike.
Noise-level-aware detail encodings. The noise present in the LR images is signal-dependent, its variance being an affine function of the intensity. To deal with such noise, we provide the un-normalized LR images to the encoder in addition to the normalized detail components. This gives the encoder information about the noise level of each pixel, necessary for an optimal fusion.
Self-supervised loss with grid shifting. Using random shifts of the high-resolution grid, we make the self-supervised loss of [43] translation equivariant, leading to improved results.
We validate our contributions with an ablation study on a synthetic dataset (§5.2), designed to model the main char-acteristics of real bracketed SkySat sequences. Since there are no previous works on multi-exposure MISR, we com-pare against state-of-the-art single-exposure MISR methods which we adapt and retrain to multi-exposure inputs (§5.3).
We also introduce a dataset of 2500 multi-exposure real
SkySat bursts (§5.4). The dataset only consists of noisy
LR images, but we can nevertheless train our network on it, since it is self-supervised. Both on synthetic and real data, the proposed HDR-DSP method attains the best results by a significant margin even though it is trained without high resolution ground truth data. The dataset is available for download on the project website.
2.