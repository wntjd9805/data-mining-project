Abstract
In many real-life image analysis applications, particu-larly in biomedical research domains, the objects of inter-est undergo multiple transformations that alters their visual properties while keeping the semantic content unchanged.
Disentangling images into semantic content factors and transformations can provide significant benefits into many domain-specific image analysis tasks. To this end, we pro-pose a generic unsupervised framework, Harmony, that simultaneously and explicitly disentangles semantic con-tent from multiple parameterized transformations. Har-mony leverages a simple cross-contrastive learning frame-work with multiple explicitly parameterized latent repre-sentations to disentangle content from transformations. To demonstrate the efficacy of Harmony, we apply it to disen-tangle image semantic content from several parameterized transformations (rotation, translation, scaling, and con-trast). Harmony achieves significantly improved disentan-glement over the baseline models on several image datasets of diverse domains. With such disentanglement, Harmony is demonstrated to incentivize bioimage analysis research by modeling structural heterogeneity of macromolecules from cryo-ET images and learning transformation-invariant rep-resentations of protein particles from single-particle cryo-EM images. Harmony also performs very well in disen-tangling content from 3D transformations and can perform coarse and fast alignment of 3D cryo-ET subtomograms.
Therefore, Harmony is generalizable to many other imag-ing domains and can potentially be extended to domains beyond imaging as well. 1.

Introduction
In many real-life image analysis applications, particu-larly in biomedical research domains (e.g., electron mi-*Corresponding author croscopy, tomography, nanobody images, etc.), the appear-ance of the objects of interests are affected by a sequence of transformations. For instance, in single-particle cryo-electron microscopy (cryo-EM) images, the shapes, trans-lations, rotations, and projections of protein particles are
In cryo-electron tomography (cryo-ET), confounded [1]. macromolecules are present in different orientations and shifts in different subtomograms (3D cryo-ET subimages each containing a macromolecule) [27,29]. A Magnetic res-onance image (MRI) of brain can be differently scaled and illuminated due to different imaging settings [23]. Conse-quently, in these image analysis domains, images can be encoded into and generated from a semantic content factor that is specific to the shape of the object of interest and a se-quence of parameterized transformations that are unspecific to the shape of the object. This is referred to as disentan-gling content and transformations in the highly non-linear latent space of the images. Such content-transformation disentangling can provide insights into the shape space and transformation distributions inherent in the images [1] and further facilitate several downstream analysis tasks like image classification, image alignment, image translation, and image extrapolation for the corresponding imaging do-mains.
Disentangling semantic content from parameterized transformations has not been widely studied until very re-cently. Traditional disentangled representation learning (DRL) methods [3,13,18] decompose data into various gen-erative latent factors (e.g., face, color, hair, etc.), and do not perform particularly well at content-transformation dis-entangling [1, 5]. To this end, some explicit DRL meth-ods [1, 5, 8, 17] have been proposed with satisfactory per-formance. These explicit DRL methods constrain some la-tent factors explicitly to represent generative factors that are known to be inherent in the data beforehand. In the afore-mentioned image analysis applications, the types of trans-formations are usually known beforehand and can be esti-Figure 1. The full workflow of our proposed method ‘Harmony’. The encoder fθ infers the transformation factors k and semantic latent distribution Φx for a input datum x. k is then used to transform x with a differentiable transformer and matched with the decoded output generated from semantic latent factor zx drawn from a distribution PΦx proposed by decoder gϕ. A similar mechanism is adopted for a randomly transformed datum x. Then corresponding transformed instances by learned transformation factors k and k′ are matched with each other. In addition, the corresponding distributions Φx and Φx′ are contrasted with a KL loss. The transformation factors k, k′, and the distributions Φx and Φx′ are all updated with gradient-descent while training. mated using few parameters. In such cases, it is particularly advantageous to use explicit methods that take into account the prior knowledge when designing content-transformation disentangling methods.
Recently, some supervised and semi-supervised explicit methods [8, 17] have been developed that disentangle con-tent and parameterized transformation latent factors. But these methods require labeled data, which makes them un-desirable in the aforementioned image analysis domains where labeled data is hard to obtain. The only notable unsu-pervised method that explicitly disentangles contents from parameterized transformations is SpatialVAE [1], which uses a specialized decoder architecture to disentangle con-tent from rotation and translation in 2D images. SpatialVAE and its variants [16] have been applied to different imag-ing domains, such as, astronomical images, electron mi-croscopy, nanorod images, and etc and has been remarkably successful. However, these methods [1, 16] do not provide a generic framework as they can not disentangle semantic content from other types of transformations (e.g., scaling, contrast, etc.). Moreover, efficacy of these methods for 3D images has been unexplored. Developing an unsupervised generic framework for disentangling semantics and trans-formations remains an open problem.
In this work, we develop a generic unsupervised frame-work, Harmony (Figure 1), to explicitly disentangle seman-tic content from multiple parameterized transformations.
Harmony takes a set of images as inputs without any label information and learns disentangled latent representations where one latent factor corresponds only to shape-specific semantic contents of objects and the others correspond to the different parameterized transformations of the objects.
To this end, like other explicit DRL methods [1, 5, 16], Har-mony only uses types of transformations that are known to be present beforehand. To perform DRL, Harmony explic-itly constrains one latent factor to correspond to the seman-tic content and others to represent transformation param-eters of known transformation types. However, only us-ing this constraint often results in trivial parameterization of transformations and consequently poor disentanglement.
To avoid such trivial parameterization, Harmony incorpo-rates cross-contrastive learning with data augmentations. It creates an augmented version of the input image with the known transformation types and enforces the decoded im-ages to be similar to both the input and augmented im-ages. For both images, it models the semantic latent fac-tors as multivariate Gaussian distributions and enforces the two distributions to be similar to each other. Harmony is the first method to leverage cross-contrastive learning for unsu-pervised content-transformation disentangling and achieve remarkable success.
We experimented with Harmony to disentangle content from multiple geometric transformations in two real single-particle cryo-EM datasets and several simulated and real 3D cryo-ET subtomogram datasets. To assess the generaliza-tion ability of Harmony’s method, we used it to disentangle contents from transformations in a randomly rotated, trans-lated, and scaled version of MNIST digit dataset and disen-tangle content from lighting condition transformation in a variant of celebA facial image dataset. In all of our exper-iments, Harmony demonstrated significantly improved re-sults over baseline methods in both qualitative and quantita-tive evaluations. In an ideal disentanglement setting, chang-ing the semantic content factor would only alter the shapes
of the objects that are specific to image class, whereas hav-ing no effect on the transformations. Our experiments show that, Harmony performs very close to the ideal setting. As
Harmony does not make any assumptions on input domain, it can be used for many other image analysis applications ( astronomical images, nanobody image, etc.) and may be leveraged for domains beyond imaging (e.g.,voice, speech, etc.) as well.
Our primary contributions are as follows: (i) We introduce a generic framework, Harmony, to dis-entangle semantic content from multiple parameter-ized transformations without requiring any image as-sociated labels. We, for the first time, used cross-contrastive learning to accurately disentangle semantic content from transformations. (ii) As an application of Harmony, we disentangle seman-tic content from multiple geometric and lighting con-dition transformations in various imaging datasets with significant improvement over baseline methods. (iii) By disentangling content from transformations with
Harmony, we resolved transformation-invariant repre-sentations of proteins from 2D single-particle cryo-EM images. We learned more accurate representation than previous methods with improved efficiency. (iv) We, for the first time, disentangled transformation pa-rameters from 3D images and applied it to model struc-tural heterogeneity of extremely noisy real and simu-lated 3D cryo-ET subtomograms. Harmony can also perform coarse and fast unsupervised groupwise im-age alignment of cryo-ET subtomograms. 2.