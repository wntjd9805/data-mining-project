Abstract
The success of deep learning methods relies on the avail-ability of well-labeled large-scale datasets. However, for medical images, annotating such abundant training data of-ten requires experienced radiologists and consumes their limited time. Few-shot learning is developed to alleviate this burden, which achieves competitive performances with only several labeled data. However, a crucial yet previ-ously overlooked problem in few-shot learning is about the selection of template images for annotation before learn-ing, which affects the final performance. We herein propose a novel Sample Choosing Policy (SCP) to select “the most worthy” images for annotation, in the context of few-shot medical landmark detection. SCP consists of three parts: 1) Self-supervised training for building a pre-trained deep model to extract features from radiological images, 2) Key
Point Proposal for localizing informative patches, and 3)
Representative Score Estimation for searching the most rep-resentative samples or templates. The advantage of SCP is demonstrated by various experiments on three widely-used public datasets. For one-shot medical landmark de-tection, its use reduces the mean radial errors on Cephalo-metric and HandXray datasets by 14.2% (from 3.595mm to 3.083mm) and 35.5% (4.114mm to 2.653mm), respectively. 1.

Introduction
It is widely known that the success of deep learning re-lies on data availability. Learning from datasets of a larger quantity and higher quality likely brings a higher perfor-mance and better generalization for neural networks. Yet, the labeling of datasets needs well-trained, highly-engaged radiologists for medical image analysis tasks [48,49], which is especially challenging as physicians are costly and busy.
To alleviate this problem, many researchers [3,17,19,34] utilize labeled data together with unlabeled data in a semi-supervised style to boost performance. A classic method is mean teacher [17, 34], which aggregates multiple predic-tions of unlabeled data by a teacher model pre-trained from
Figure 1. The distribution of the mean radial error (MRE) when choosing a different image as a template in one-shot medical land-mark detection task. The x-axis refers to MRE and the y-axis refers to the percentage of MRE lying in the corresponding ranges.
Evidently, the choice of template affects the performance sig-nificantly. labeled data. The aggregated results work as more reliable pseudo labels for unlabeled data in rest part of the method.
Another group of researchers, aiming to achieve a high per-formance at a low labeling cost, propose a strategy to se-lect instances for annotation incrementally [15, 31, 35, 45].
The basic idea is to first train a model with few labeled data, and then use the model to select instances from un-labeled data iteratively, which are annotated by special-ists for the next round of training. Meanwhile, some re-searchers attempt to drain all potential of limited labeled data. With the power of self-training and self-supervised learning [1,4,24,39,43,47,51], it is possible to develop a ro-bust, few-shot model even with several labeled samples. For example, Yao et al. [42] introduce a self-supervised proxy task that matches multi-layers features from images with different augmentations in the training stage, and use a sin-gle image as the template, whose patches centered at land-marks are matched with target images to make predictions.
However, during our research following the work of
[42], we observe an interesting phenomenon (see Figure 1).
The template choice highly impacts the final performance.
The mean radial error (MRE) of our trained model varies from 2.9mm under the “best” template to 4.5mm under the
“worst” template. It is evident that there is a large gap lying between the best and the worst choices. Thus, a selection question naturally stands out: Regarding the “gap” over samples, how to find and annotate the most “valuable” im-ages in order to achieve the best performance with a deep model trained under such a limited supervision? To the best of our knowledge, there is no ready answer to the above question. In this paper, we attempt to fill this blank.
To answer this question, we have to address three diffi-culties. (1) No supervised signal: For a landmark detection task, there are no labels to guide our image selection — We need to find substitutes for landmarks; (2) No proper met-ric: Mean radial error (MRE) is often employed as a perfor-mance metric for landmark detection, but we cannot com-pute MRE when no landmarks are available — we need to find proxy for MRE; (3) Missing effective feature extrac-tion: Can we train a deep model that effectively extracts the features for template selection?
In this paper, we propose a framework named Sample
Choosing Policy (SCP) to find the most annotation-worthy images as templates. First, to handle the situation of no landmark label, we choose handcrafted key points as sub-stitutes for landmarks of interest. Second, to replace the
MRE, we proposed to use a similarity score between a template and the rest based on the features of such poten-tial key points. Third, considering landmark detection is a pixel-wise task, we apply pixel-wise self-supervised learn-ing with all non-labeled data to build a basic feature extrac-tor, which extracts features from each image. Finally, we can find out the subset of images with the highest similar-ities as the candidate templates to be labeled, from which a model is learned for few-shot landmark detection. With the help of SCP, we improve the MRE performance of one-shot medical landmark detection from 3.595mm (with a ran-dom template) to 3.083mm (with our selected template) in
Cephalometric Xray dataset and 4.114mm (with a random template) to 2.635mm (with our selected template) in Hand
Xray dataset; refer to Section 4. 2.