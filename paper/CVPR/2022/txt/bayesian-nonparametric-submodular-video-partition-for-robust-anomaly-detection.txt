Abstract
Multiple-instance learning (MIL) provides an effective way to tackle the video anomaly detection problem by mod-eling it as a weakly supervised problem as the labels are usually only available at the video level while missing for frames due to expensive labeling cost. We propose to con-duct novel Bayesian non-parametric submodular video par-tition (BN-SVP) to significantly improve MIL model training that can offer a highly reliable solution for robust anomaly detection in practical settings that include outlier segments or multiple types of abnormal events. BN-SVP essentially performs dynamic non-parametric hierarchical clustering with an enhanced self-transition that groups segments in a video into temporally consistent and semantically coherent hidden states that can be naturally interpreted as scenes.
Each segment is assumed to be generated through a non-parametric mixture process that allows variations of seg-ments within the same scenes to accommodate the dynamic and noisy nature of many real-world surveillance videos.
The scene and mixture component assignment of BN-SVP also induces a pairwise similarity among segments, result-ing in non-parametric construction of a submodular set function. Integrating this function with an MIL loss effec-tively exposes the model to a diverse set of potentially posi-tive instances to improve its training. A greedy algorithm is developed to optimize the submodular function and support efficient model training. Our theoretical analysis ensures a strong performance guarantee of the proposed algorithm.
The effectiveness of the proposed approach is demonstrated over multiple real-world anomaly video datasets with ro-bust detection performance. 1.

Introduction
Anomaly detection from videos poses fundamental chal-lenges as abnormal activities are usually rare, complicated, and unbounded in nature [15]. Furthermore, segment or frame labels are typically unavailable due to high labeling cost and therefore, the detection models have to rely on the weak video level labels [19]. There are two main streams of work to handle the challenging anomaly detection task.
The first stream treats anomaly detection as an unsuper-vised learning problem [21].
It assumes that an event is considered to be abnormal if it deviates significantly from a predefined set of normal events included in the training data [2, 24, 26]. However, a model trained on limited nor-mal data is likely to capture only specific characteristics present in the training dataset, and therefore, testing nor-mal events deviating significantly from the training normal events will lead to a high false alarm rate [27]. The sec-ond stream of research has attempted to address the limita-tion by formulating the problem as multiple instance learn-ing (MIL) that models each video as a bag and its seg-ments (or frames) as instances within the bag [19]. The goal is to learn a model that can effectively make frame-level anomaly predictions relying on the video-level labels during the training process. One effective MIL learning ob-jective is to maximize the gap between two instances having the respective highest anomaly scores from a pair of posi-tive and negative bags. The maximum score based MIL (re-ferred as MMIL) model outperformed the unsupervised ap-proaches and achieved promising performance in real-world long surveillance videos [19].
However, there are two key limitations with the MMIL model. First, the presence of noisy outliers (different from other normal events) in both abnormal and normal videos may significantly impact the overall model performance.
This is because the objective function solely focuses on the individual segments from both positive and negative bags, making the training process sensitive to noises. Figure 1 (a-b) shows the example normal frames that are significantly different from other normal ones in real-world surveillance videos. The first frame is from the burglary video that looks similar to an abnormal frame from a video with an arson event. The second frame is from the shooting video that looks similar to a fighting frame. Hence, they may serve as outliers in the corresponding videos.
Second, if multiple types of abnormal events (referred to as multi-modal anomaly) present in a single abnormal video, MMIL may only detect one type of anomaly while
(a) Burglary (Outlier 1) (b) Walking (Outlier 2) (c) Running (Modality 1) (d) Loitering (Modality 2) (e) Walking (Modality 3)
Figure 1. Examples of outlier (a-b) and multimodal frames (c-e) from the Avenue dataset (a) Avenue (b) ShanghaiTech
Figure 2. Highly fluctuating detection performance w.r.t. k missing other important ones due to the limitation of the ob-jective function. Figure 1 (c)-(e) demonstrate three frames with different anomaly types from an example video in the
Avenue dataset [16]. In Figure 1 (c), the person is running, which is regarded as a strange action in that context [16].
In (b), it shows a person waiting in a place holding some object in the hand, and (c) involves a person walking in the wrong direction. Therefore, the single video has multiple anomaly frames leading to a multimodal scenario.
Top-k ranking loss has been adopted in an attempt to ad-dress the issues as outlined above. It maximizes the gap be-tween the mean score of the top-k predicted instances from a positive bag and that of a negative one [18, 22]. However, there are inherent limitations by using a top-k loss. First, it tends to be extremely sensitive to the selected k value. Fig-ure 2 shows the highly fluctuating detection performance from two real-world surveillance video datasets. Since there is no frame (or segment) labels available during model train-ing, setting an optimal k through cross-validation is infeasi-ble or highly costly. Furthermore, given the diverse videos, the number of abnormal instances may vary significantly from one video to another implying we should have a dif-ferent k for each video. Hence, applying the same k to all videos as in the existing approaches fails to capture the na-ture of the data. Another serious but more subtle issue is that all (or most of) the selected k segments may come from the same sub-sequence of the video. Using a consecutive set of visually similar segments is less effective for model train-ing, making it more likely to suffer from outlier and mul-timodal scenarios. As a result, top-k approaches will fall short in providing a reliable detection performance in most practical settings as evidenced by our experiments.
To address the fundamental limitations of existing solu-tions, we propose novel Bayesian non-parametric construc-tion of a submodular set function, which is integrated with multiple instance learning to deliver robust video anomaly detection performance under practical settings.
Instead of choosing a set of instances with the highest predic-tion scores that are likely from a consecutive sub-sequence, maximizing a specially designed submodular function can involve a more diverse set of instances and expose the model to all potentially abnormal segments for more ef-fective model training. Furthermore, the submodular set function is constructed in a non-parametric way, which in-duces a pairwise similarity among different segments in a video based on the diverse nature of the data. More specif-ically, an infinite Hidden Markov Model with a Hierarchi-cal Dirichlet prior (HDP-HMM) [20] augmented with an enhanced self-transition is employed to partition a video through dynamic non-parametric clustering of its segments.
To more effectively accommodate the dynamic and noisy nature of real-world surveillance videos, the emission pro-cess of the HMM is also governed by a non-parametric mixture model to allow segments within the same hidden state to have visual and spatial variations. This unique de-sign is instrumental to discover temporally consistent and semantically coherent hidden states that can be naturally interpreted as scenes. Pairwise similarity among different segments is defined according to the state-component struc-ture, which leads to the construction of a submodular set function. We then develop a novel submodularity diversi-fied MIL loss function to ensure robust anomaly detection from real-world surveillance videos with outlier and multi-modal scenarios. Our key contributions include:
• Formulation of a novel submodularity diversified MIL loss that simultaneously extracts a diverse set of poten-tially positive instances while maximizing the gap be-tween the mean score of these instances from a positive bag and a negative one, respectively.
• Bayesian non-parametric construction of the submod-ular set function that infers the diversity from the video data to induce a pairwise similarity among different seg-ments in a video and provide an upper bound on the size of the diverse set.
• A greedy algorithm that leverages the state-component hierarchical structure resulting from the non-parametric construction for submodular set function optimization and efficient model training.
• Theoretical results to ensure strong performance guar-antee of the greedy algorithm.
The proposed approach achieves the state-of-the-art robust anomaly detection performance on real-world surveillance videos with noisy and multimodal scenarios.
2.