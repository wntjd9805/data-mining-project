Abstract
To deal with the great number of untrimmed videos pro-duced every day, we propose an efficient unsupervised ac-tion segmentation method by detecting boundaries, named action boundary detection (ABD). In particular, the pro-posed method has the following advantages: no training stage and low-latency inference. To detect action bound-aries, we estimate the similarities across smoothed frames, which inherently have the properties of internal consistency within actions and external discrepancy across actions. Un-der this circumstance, we successfully transfer the bound-ary detection task into the change point detection based on the similarity. Then, non-maximum suppression (NMS) is conducted in local windows to select the smallest points as candidate boundaries. In addition, a clustering algorithm is followed to refine the initial proposals. Moreover, we also extend ABD to the online setting, which enables real-time action segmentation in long untrimmed videos. By evaluat-ing on four challenging datasets, our method achieves state-of-the-art performance. Moreover, thanks to the efficiency of ABD, we achieve the best trade-off between the accuracy and the inference time compared with existing unsupervised approaches. 1.

Introduction
There are tera-bytes of videos uploaded to cloud or edge storage to be processed every day. Efficiently analyzing the contents of these untrimmed videos is a nontrivial step towards real-world deployment, which has a great range of applications from video retrieval to surveillance analy-sis [9, 27, 33, 46]. Tremendous progress has recently been made on supervised action segmentation due to the intro-duction of large-scale datasets and the development of deep neural networks [12, 21, 26, 43]. However, building fully supervised learning models requires manual data labeling, which is slow, expensive and error-prone. Thus unsuper-vised action segmentation has gained great popularity.
Due to the temporal coherence of videos, when segment-ing actions from a long, untrimmed video, human beings would pay primary attention to detecting action boundaries,
Figure 1. The overview of our method. gt represents the smoothed feature for the t-th frame, and bi the i-th detected boundary. We observe that the calculated frame-wise similarities based on the smoothed frame features for individual action instance take a “⊓”-shaped curve. Action boundaries can be directly pinpointed by detecting change points along the similarity curve. and take the frames between adjacent temporal boundaries as an action instance. Building on this insight, we pro-pose an efficient and effective unsupervised action segmen-tation method by detecting action boundaries, dubbed ac-tion boundary detection (ABD). The overview of the pro-posed method is illustrated in Figure 1.
Motivated by the Canny detector [6] in image processing and the segmentation method [18] in time series, we pro-pose a bottom-up action segmentation method. For action segmentation, the ideal features should be consistent within an action and inconsistent across different actions. How-ever, due to the occlusion, changing viewpoint or lighting, the features within an action may fail to maintain strictly consistent as expected. Therefore, we first utilize a smooth-ing filter on original features to dilute the effect of noise.
Moreover, different from the Canny detector that finds in-tensity gradients of images, we pinpoint temporal action boundary proposals based on the similarity between adja-cent frames. Then, we adopt non-maximum suppression (NMS) inside local windows and select smallest points as initial candidate action boundaries. In addition, we intro-duce a bottom-up method to refine initial segmentation re-sults based on semantic segment-wise similarity.
There have been several attempts to detect action bound-aries by stacking complicated neural networks or generating less-relevant pseudo labels [11,17,32,48]. Directly depend-ing on the similarity between frames is more reliable and interpretative. We hope our exploration will motivate com-munities to rethink the fundamental roles of feature similar-ity within and across actions for action segmentation.
Our method has the following advantages: 1) No training is needed. A powerful family of models for weakly- and unsupervised representations are collected under the umbrella of “self-supervised” learning, which concentrates on acquiring pseudo-labels that can be used for supervised training to obtain higher-level semantic fea-tures [11, 28, 30, 36, 38, 40, 42]. However, the less-related labels have limited contribution to the detection results, and the train-and-transfer strategy would sacrifice the generaliz-ability of models. Instead, we directly exploit original fea-tures without any training, guaranteeing the robustness and transferability of our method. 2) Fast and state-of-the-art. The proposed method achieves the best trade-off between model accuracy and in-ference time compared with weakly supervised and unsu-pervised action segmentation methods [11, 39, 42]. Specif-ically, our method yields competitive performance com-pared with state-of-the-art approaches on four challenging datasets and significantly increases the inference speed. In addition, our ABD can be further extended into the on-line setting, which enables real-time action segmentation in untrimmed videos. 2.