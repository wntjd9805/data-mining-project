Abstract
Multi-view Stereo (MVS) with known camera parame-ters is essentially a 1D search problem within a valid depth range. Recent deep learning-based MVS methods typically densely sample depth hypotheses in the depth range, and then construct prohibitively memory-consuming 3D cost volumes for depth prediction. Although coarse-to-fine sam-pling strategies alleviate this overhead issue to a certain extent, the efficiency of MVS is still an open challenge.
In this work, we propose a novel method for highly ef-ficient MVS that remarkably decreases the memory foot-print, meanwhile clearly advancing state-of-the-art depth prediction performance. We investigate what a search strat-egy can be reasonably optimal for MVS taking into ac-count of both efficiency and effectiveness. We first formu-late MVS as a binary search problem, and accordingly pro-pose a generalized binary search network for MVS. Specif-ically, in each step, the depth range is split into 2 bins with extra 1 error tolerance bin on both sides. A classifi-cation is performed to identify which bin contains the true depth. We also design three mechanisms to respectively handle classification errors, deal with out-of-range sam-ples and decrease the training memory. The new formu-lation makes our method only sample a very small number of depth hypotheses in each step, which is highly memory efficient, and also greatly facilitates quick training conver-gence. Experiments on competitive benchmarks show that our method achieves state-of-the-art accuracy with much less memory. Particularly, our method obtains an overall score of 0.289 on DTU dataset and tops the first place on challenging Tanks and Temples advanced dataset among all the learning-based methods. Our code will be released at https://github.com/MiZhenxing/GBi-Net. 1.

Introduction
Multi-view Stereo (MVS) is a long-standing and fun-damental topic in computer vision, which aims to recon-struct 3D geometry of a scene from a set of overlap-ping images [9, 10, 26, 32, 35]. With known camera pa-Figure 1. (a) Comparison with previous state-of-the-art learning-based MVS methods [5,11,33,34,41,44,45] on DTU [2]. The rela-tionship between the overall error and the GPU memory overhead with image size 1152 × 1600 and image number 5. (b) Compari-son of the previous dense search and the proposed binary search. rameters, MVS matches pixels across images to compute dense correspondences and recover 3D points, which is essentially a 1D search problem [8]. A depth map is widely used as 3D representation due to its regular for-mat. To overcome the issue of coarse matching in previ-ous purely geometry-based methods, recent learning-based
MVS methods [14, 21, 41, 42] designed deep networks for dense depth prediction to significantly advance traditional pipelines. For instance, MVSNet [41] and RMVSNet [42] propose to construct 3D cost volumes from 2D image fea-tures with dense depth hypotheses. A 3D cost volume is a 5D tensor and is typically regularized by a 3D Convolu-tional Neural Network (CNN) or a Recurrent Neural Net-work (RNN) for depth prediction.
The importance of 3D cost volume regularization for ac-curate depth prediction has been confirmed by other works
[4, 5, 11]. However, a severe problem is that 3D cost volumes are highly memory-consuming. Existing works made significant efforts to address this issue via decreasing the resolution of feature maps [41], using a coarse-to-fine strategy that gradually increases resolution of feature maps while decreasing the depth hypothesis number [4, 5, 11], and removing expensive 3D CNN or RNN [33, 40]. Al-though the memory can be alleviated to some extent, rela-tively lower accuracy is commonly observed. The size of 3D cost volume, specifically the depth hypothesis number,
plays a dominant role in causing a large memory footprint.
Due to the significance of 3D cost volumes in both model efficiency and effectiveness, a critical question nat-urally arises: what is a minimum volume size to secure satisfactory accuracy while maintaining as small as possi-ble the memory overhead? In this work, we investigate this question by exploring from a perspective of discrete search strategies, to identify a minimal depth hypotheses number, a key factor in 3D cost volumes. As shown in Fig. 1b, the vanilla MVSNet [41] can be seen as a dense search method that checks all depth hypotheses similar to a linear search in a parallel manner. The coarse-to-fine methods [5, 11] per-form a multi-granularity search, which starts from a coarse level and gradually refines the prediction. However, these two types of methods both consider dense search in each stage. We argue that the dense search does not necessarily guarantee better accuracy due to a much larger prediction space and significantly increases model complexity, leading to higher optimization difficulty in model training.
To explore a reasonably optimal search strategy, we first formulate MVS as a binary search problem, which can re-markably reduce the cost volume size to an extremely low bound.
It performs comparisons and eliminates half of the search space in each stage (see Fig. 1b), and can con-vergence quickly to a fine granularity within logarithmic stages. In contrast to regression-based methods, which di-rectly sample depth values from the depth range, we first divide the depth range into 2 bins. In our design, the ‘com-parisons’ by the network is to determine which bin contains the true depth value via performing a binary discrete classi-fication. We use center points of the two bins to represent them and construct 3D cost volumes. The binary search offers superior efficiency, while it brings an issue of out-of-bin error. If in some stage the prediction selects a wrong bin, the error will accumulate in later search stages causing unstable optimization gradients and relatively low accuracy.
To tackle this issue, we further design three effective mechanisms, and accordingly propose a generalized binary search deep network, termed as GBi-Net, for highly effi-cient MVS. The first mechanism is that we pad two error tolerance bins on the two sides to reduce the prediction er-ror of out of bins. The second mechanism is for training.
If the network generates an error of prediction out of bins for a pixel at a search stage, we stop the forward pass of this pixel in the next stage, and the gradients at this stage are not used to update the network. Extensive experiments show that the proposed GBi-Net can largely decrease the size of 3D cost volumes for a significantly efficient net-work, and more importantly, without any trade-off on the depth prediction performance. The third is efficient gradi-ent updating. It updates the network parameters immedi-ately at each search stage without accumulating across dif-ferent stages as most works do. It can largely reduce the training memory while maintaining the performance. Our method achieves state-of-the-art performance on different competitive datasets including DTU [2] and Tanks & Tem-ples [17]. Notably, on DTU, we achieve an overall score of 0.289 (lower is better), remarkably improving the pre-vious best performing method, and also obtain a memory efficiency improvement of 48.0% compared to UCSNet [5] and 54.1% compared to CasMVSNet [11] (see Fig. 1a).
In summary, our contribution is three-fold:
• We investigate efficient MVS from a perspective of search strategies, and propose a discrete binary search method for MVS (Bi-Net) which can vastly decrease the memory usage of 3D cost volumes.
• We design a highly-efficient generalized binary search network (GBi-Net) via further designing three mech-anisms (i.e. padding error tolerance bins, gradients masking, and efficient gradient updating) with the bi-nary search to avoid error accumulation of false net-work predictions and improve efficiency.
• We evaluate our method on several challenging MVS datasets and significantly advance existing state-of-the-art methods in terms of both the depth prediction accuracy and the memory efficiency. 2.