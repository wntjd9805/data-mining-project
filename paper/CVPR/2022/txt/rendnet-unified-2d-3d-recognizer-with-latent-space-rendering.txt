Abstract
Vector graphics (VG) have been ubiquitous in our daily life with vast applications in engineering, architecture, de-signs, etc. The VG recognition process of most existing methods is to first render the VG into raster graphics (RG) and then conduct recognition based on RG formats. How-ever, this procedure discards the structure of geometries and loses the high resolution of VG. Recently, another cat-egory of algorithms is proposed to recognize directly from the original VG format. But it is affected by the topological errors that can be filtered out by RG rendering. Instead of looking at one format, it is a good solution to utilize the for-mats of VG and RG together to avoid these shortcomings.
Besides, we argue that the VG-to-RG rendering process is essential to effectively combine VG and RG information. By specifying the rules on how to transfer VG primitives to RG pixels, the rendering process depicts the interaction and correlation between VG and RG. As a result, we propose
RendNet, a unified architecture for recognition on both 2D and 3D scenarios, which considers both VG/RG representa-tions and exploits their interaction by incorporating the VG-to-RG rasterization process. Experiments show that Rend-Net can achieve state-of-the-art performance on 2D and 3D object recognition tasks on various VG datasets. 1.

Introduction
Deep learning has opened a new era for visual perception with machines. Most current methods deal with sensory in-put such as pixel images, called raster graphics (RG). They benefit from the easy accessibility of input data. However, for human drafted graphics like floor plans, graphic designs, and CAD models, another data format is widely used, called vector graphics (VG). In this paper, we focus on recognition
*This work was done when the author was an intern at MSRA.
Figure 1. Rendering of vector graphics. The renderer knows the correlation between sparse VG attributes and the rendered RG. tasks taking VG as input, such as VG-based image classifi-cation and object detection.
Vector graphics contain a set of primitives defined with parametric equations, such as lines, curves, and circles, which are almost impossible for a human to directly per-ceive. It needs to be rendered into the format as the raster graphics by rasterization technique (as shown in Fig. 1), so it can be displayed on monitors or printed on paper.
Most of the existing VG recognizers take the rendered RG as input, taking advantage of mature RG-based recognition methods like convolutional neural networks [16] or Point-Net [33]. However, rendered pixels discard the structure of geometries and lose the high-resolution property of VG. As a result, recently some pioneering works [18, 19] are pro-posed to directly recognize VG from its original format. Al-though achieving encouraging performance improvements,
VG-based methods are affected by human un-perceivable topological errors, which can be filtered out by rasterization.
For example, Fig. 2 shows two lines whose ends shall meet but do not meet by a small margin, and this error is absent in the rendered RG. Different from the existing methods that consider only one format, this paper proposes a method that leverages the merits of both VG and RG.
How to effectively combine the information of VG and
RG remains an open question. An intuitive way is to use the separate model on VG and RG respectively and fuse the
mances are achieved. 2.