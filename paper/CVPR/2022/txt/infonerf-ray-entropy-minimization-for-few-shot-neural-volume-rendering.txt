Abstract
We present an information-theoretic regularization tech-nique for few-shot novel view synthesis based on neural im-plicit representation. The proposed approach minimizes po-tential reconstruction inconsistency that happens due to in-sufficient viewpoints by imposing the entropy constraint of the density in each ray. In addition, to alleviate the poten-tial degenerate issue when all training images are acquired from almost redundant viewpoints, we further incorporate the spatial smoothness constraint into the estimated images by restricting information gains from additional rays with slightly different viewpoints. The main idea of our algo-rithm is to make reconstructed scenes compact along indi-vidual rays and consistent across rays in the neighborhood.
The proposed regularizers can be plugged into most of exist-ing neural volume rendering techniques based on NeRF in a straightforward way. Despite its simplicity, we achieve con-sistently improved performance compared to existing neural view synthesis methods by large margins on multiple stan-dard benchmarks. Our codes and models are available in the project website1. 1.

Introduction
Understanding 3D structure of a natural scene is a criti-cal step for various high-level computer vision applications including object recognition, photorealistic rendering, au-1http://cvlab.snu.ac.kr/research/InfoNeRF
tonomous driving, virtual reality, and many others. Recent advance of deep learning capacitates high-fidelity 3D recon-struction and recognition, but learning with 3D data is inher-ently more difficult than its counterpart based on 2D images due to unstructured nature of data format, high memory requirement, and lack of principled architectures. Hence, many researchers investigate the standard models with ap-propriate training algorithms and the methods for reducing their computational costs, and attempt to solve various chal-lenging tasks.
Novel view synthesis based on neural implicit represen-tations is one of the 3D learning tasks that draws a lot of at-tention these days since Neural Radiance Field (NeRF) [20] has been introduced. NeRF delivers accurate 3D recon-struction results without explicit modeling of 3D scene structures, but the requirement of many images captured from multiple calibrated cameras hampers the applicabil-ity of the method. Therefore, several recent approaches aim to reduce the high computational cost and alleviate the con-straints related to datasets [7, 11, 37].
In this line of research, we explore the few-shot prior-free novel view synthesis task, where only a limited num-ber of training images are accessible and other prior infor-mation, such as object categories and semantic structures of target scenes, are unavailable. There exist several prior works for this task, but they either work barely with few ex-amples [11] or require narrow baseline assumption to find correspondences using an external module [7]. Other ap-proaches rely on prior knowledge of scenes such as object classes or features. For example, PixelNeRF [37] takes advantage of the features extracted from seen images to compensate for missing information in unseen views while
[14, 23] focus on a particular object class, e.g., human, in novel view synthesis.
We address the fundamental drawbacks of existing few-shot novel view synthesis methods: inconsistent reconstruc-tion, which generates noise, blur, or artifacts in rendered images, and overfitting to seen views, which leads to degen-erate or trivial solutions. The proposed approach, referred to as InfoNeRF, alleviates the reconstruction inconsistency by imposing the sparsity on the estimated scene, which is achieved by entropy minimization in each ray. The overfit-ting issues are handled by enforcing the smoothness of the reconstruction with respect to viewpoint changes, which is controlled by minimizing information gains from a pair of slightly different viewpoints. Figure 1 illustrates the out-standing quality of rendered images and depth maps esti-mated by our model, which delineates clear object bound-aries and fine structures using only 4 input views with wide baselines.
Overall, the main contributions and benefits of our algo-rithm are summarized as follows:
• We propose a novel information-theoretic approach,
InfoNeRF, for the regularization of the neural implicit representations for volume rendering. Our method points out key drawbacks of the existing few-shot novel view synthesis techniques, and introduces two effective regularization schemes, ray entropy mini-mization and ray information gain reduction.
• Since InfoNeRF is a generic regularization technique and does not require any other external data structures, e.g., voxels or meshes, or additional learnable parame-ters, it can be applied to various neural volume render-ing algorithms with and without scene prior.
• The proposed regularization technique turns out to be effective to alleviate reconstruction inconsistency across multiple views and prevent degenerate solutions by overfitting despite its simplicity. We demonstrate outstanding performance of InfoNeRF on several stan-dard benchmarks for few-shot novel view synthesis.
• To our knowledge, InfoNeRF is the first NeRF variant that performs few-shot novel view synthesis on wide-baseline image datasets without prior information. 2.