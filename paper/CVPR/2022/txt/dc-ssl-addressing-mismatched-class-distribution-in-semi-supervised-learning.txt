Abstract
Consistency-based Semi-supervised learning (SSL) has achieved promising performance recently. However, the success largely depends on the assumption that the labeled and unlabeled data share an identical class distribution, which is hard to meet in real practice. The distribution mis-match between the labeled and unlabeled sets can cause severe bias in the pseudo-labels of SSL, resulting in signif-icant performance degradation. To bridge this gap, we put forward a new SSL learning framework, named Distribu-tion Consistency SSL (DC-SSL), which rectifies the pseudo-labels from a distribution perspective. The basic idea is to directly estimate a reference class distribution (RCD), which is regarded as a surrogate of the ground truth class distribution about the unlabeled data, and then improve the pseudo-labels by encouraging the predicted class distribu-tion (PCD) of the unlabeled data to approach RCD gradu-ally. To this end, this paper revisits the Exponentially Mov-ing Average (EMA) model and utilizes it to estimate RCD in an iteratively improved manner, which is achieved with a momentum-update scheme throughout the training proce-dure. On top of this, two strategies are proposed for RCD to rectify the pseudo-label prediction, respectively. They cor-respond to an efficient training-free scheme and a training-based alternative that generates more accurate and reli-able predictions. DC-SSL is evaluated on multiple SSL benchmarks and demonstrates remarkable performance im-provement over competitive methods under matched- and mismatched-distribution scenarios. 1.

Introduction
Recent consistency-based semi-supervised learning (SSL) methods have seen fast progress and shown compet-itive performance to supervised learning [21, 22]. These methods commonly utilize the model trained on labeled samples to generate pseudo-labels on unlabeled samples,
*Corresponding authors (luping.zhou@sydney.edu.au). The authors thank Australian Research Council (ARC DP200103223), National Key
Research and Development Program of China (2019YFC0118300), and
NSFC Major Program (62192783) for the support of this work. (a) Matched Distribution (b) Mismatched Distribution (c) Test accuracy for (a) (d) Test accuracy for (b)
Figure 1. (a) and (b) show the class distributions on CIFAR10 in the matched and mismatched distributions settings, respectively. (c) and (d) show the corresponding test performance on the recent
SOTA SSL methods and our proposed DC-SSL with training-free (TF) and training-based (TB) strategies. and then enforce prediction consistency against their cor-responding perturbed variants. An implicit assumption in such methods is that the labeled and unlabeled data share the same class distribution. However, such a strong assump-tion cannot hold in real practice. The scarcity of labeled samples or the sampling errors can inevitably lead to a dis-tribution mismatch between the labeled and unlabeled data.
This could, unfortunately, invalidate most of the advanced
SSL methods.
To illustrate this problem, this paper conducted a per-formance comparison under matched and mismatched dis-tribution scenarios. As shown in Figure 1c, two state-of-the-art (SOTA) SSL methods, FixMatch [26] and Co-Match [18], can achieve promising results on CIFAR-10 with only 40 labeled samples when the labeled and unla-beled class distributions are matched, e.g., a high test accu-racy of 93.21% of CoMatch. However, when there exists a distribution mismatch as shown in Figure 1b, the test ac-curacy can drop sharply by around 30% on FixMatch and severely more than 40% on CoMatch.
It is because the pseudo-labels on the unlabeled set are severely biased and
unreliable in a mismatched distribution setting, resulting in a significant performance degradation.
Inspired by distribution alignment (DA) [4], we aim to improve the biased pseudo-labels from a distribution per-spective. The basic logic is to modify the pseudo-labels by encouraging the predicted class distribution (PCD) of the unlabeled data to be close to the underlying ground-truth class distribution (GCD) across the training. How-ever, the existing works using DA [4, 11, 18, 28] widely as-sumed that the labeled and unlabeled data fall in the same class distribution, and therefore took the provided labeled class distribution (LCD) as the GCD on the unlabeled set to rectify pseudo-labels. As shown in Figure 1c, built into
FixMatch, although DA significantly improves the perfor-mance in the matched distribution setting (i.e. LCD=GCD), it causes severe negative impact under the mismatched dis-tribution scenario (i.e. LCD̸=GCD) with a sharp accuracy drop as shown in Figure 1d. A key rescue and challenge is to employ an accurate distribution to guide PCD on the unlabeled data, whereas the unlabeled GCD is commonly unknown and the known LCD is biased and unreliable.
To address the above limitations, we propose a simple but effective method, named Distribution Consistency SSL (DC-SSL), which can effectively rectify the pseudo-labels from a distribution perspective. The design of DC-SSL is based on two main components. First, instead of using
LCD, DC-SSL directly estimates a reference class distri-bution (RCD) from the unlabeled data, which is regarded as a surrogate of the unknown GCD. To this end, we re-visit the exponentially moving averaged (EMA) model in
SSL and carefully study i) why the EMA model is employed merely for the testing instead of the training process in re-cent SOTA SSL methods [1, 13, 14, 18, 26], and ii) how the
EMA model can benefit the distribution estimation on unla-beled samples. Based on this investigation, we design our framework to involve EMA to estimate a robust RCD by a momentum-updated scheme over historical label predic-tions. As shown in Figure 2, the estimated RCD gradually approaches GCD with the progression of the training pro-cedure. Second, on top of the estimated distributions, two direct and indirect updating strategies are proposed, respec-tively, to modify the pseudo-labels, corresponding to the training-free and the training-based strategies shown in Fig-ure 3. The training-free (TF) strategy directly modifies the pseudo-labels by scaling them with a ratio of RCD to PCD, while the training-based (TB) strategy minimizes a distribu-tion consistency loss between PCD and RCD to indirectly enhance the SSL performance. Both strategies are orthogo-nal to existing consistency-based SSL methods and can be easily applied with minimal change of implementation.
Despite of it simplicity, our method can consistently im-prove the SOTA SSL methods, especially when the labeled and unlabeled data follow different distributions. For ex-(a) After 50 epochs (b) After 100 epochs (c) After 200 epochs (d) After 400 epochs
Figure 2. (a)-(d) compares the RCD in DC-SSL (TB) and GCD at different training stages with the mismatched setting in Fig. 1b. ample, in conventional matched distribution settings, DC-SSL (TF) can achieve a higher average accuracy of 95.31% on CIFAR10 (40 labels) compared to the previous SOTA of 93.21% and the baseline FixMatch of 86.19%.
In the mismatched settings, our methods consistently outperform other SSL methods, e.g., DC-SSL (TB) can obtain an av-erage accuracy of 63.95% on CIFAR10 in a mismatched setting as in Figure 1b, compared to Fixmatch of 57.54% and CoMatch of 52.73%. Our main contributions are sum-marized as follows:
• We revisit the EMA model in SSL and observe that it can be helpful in estimating unlabeled class distribu-tions, although it may not produce more accurate high-confidence pseudo-labels directly.
• We propose a new method, DC-SSL, to enhance SSL performance from a distribution perspective. Two ef-fective strategies are designed to improve the pseudo-labels by encouraging PCD of unlabeled data to ap-proach an iteratively-improved RCD gradually.
• Our method can obtain new SOTA performance across different amounts of labeled data on standard SSL im-age classification benchmarks under both matched and mismatched distribution scenarios. 2.