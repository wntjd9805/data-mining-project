Abstract
Recent progress on Transformers and multi-layer per-ceptron (MLP) models provide new network architectural designs for computer vision tasks. Although these models proved to be effective in many vision tasks such as image recognition, there remain challenges in adapting them for low-level vision. The inﬂexibility to support high-resolution images and limitations of local attention are perhaps the main bottlenecks. In this work, we present a multi-axis MLP based architecture called MAXIM, that can serve as an ef-ﬁcient and ﬂexible general-purpose vision backbone for im-age processing tasks. MAXIM uses a UNet-shaped hierar-chical structure and supports long-range interactions en-abled by spatially-gated MLPs. Speciﬁcally, MAXIM con-tains two MLP-based building blocks: a multi-axis gated
MLP that allows for efﬁcient and scalable spatial mixing of local and global visual cues, and a cross-gating block, an alternative to cross-attention, which accounts for cross-feature conditioning. Both these modules are exclusively based on MLPs, but also beneﬁt from being both global and ‘fully-convolutional’, two properties that are desirable for image processing. Our extensive experimental results show that the proposed MAXIM model achieves state-of-the-art performance on more than ten benchmarks across a range of image processing tasks, including denoising, de-blurring, deraining, dehazing, and enhancement while re-quiring fewer or comparable numbers of parameters and
FLOPs than competitive models. The source code and trained models will be available at https://github. com/google-research/maxim. 1.

Introduction
Image processing tasks, such as restoration and enhance-ment, are important computer vision problems, which aim to produce a desired output from a degraded input. Vari-ous types of degradations may require different image en-hancement treatments, such as denoising, deblurring, super-∗Work done during an internship at Google.
Figure 1. Our proposed MAXIM model signiﬁcantly advances state-of-the-art performance on ﬁve image processing tasks in terms of PSNR: 1) Denoising (+0.24 dB on SIDD [1]), 2) De-blurring (+0.15 dB on GoPro [57]) 3) Deraining (+0.86 dB on
Rain100L [95]), 4) Dehazing (+0.94 dB on RESIDE [43]), and 5)
Retouching (Enhancement) (+1.15 dB on FiveK [6]). resolution, dehazing, low-light enhancement, and so on.
Given the increased availability of curated large-scale train-ing datasets, recent high-performing approaches [13, 15, 18, 20, 47, 48, 56, 100, 101, 115] based on highly designed con-volutional neural network (CNN) have demonstrated state-of-the-art (SOTA) performance on many tasks.
Improving the architectural design of the underlying model is one of the keys to improving the performance of most computer vision tasks, including image restora-tion. Numerous researchers have invented or borrowed in-dividual modules or building blocks and implemented them into low-level vision tasks, including residual learning [40, 86, 110], dense connections [86, 111], hierarchical struc-tures [34, 38, 39], multi-stage frameworks [14, 32, 101, 103], and attention mechanisms [60, 83, 100, 101].
Recent research explorations on Vision Transformers (ViT) [9, 22, 53] have exempliﬁed their great potential as alternatives to the go-to CNN models. The elegance of
ViT [22] has also motivated similar model designs with sim-pler global operators such as MLP-Mixer [79], gMLP [50],
GFNet [69], and FNet [41], to name a few. Despite suc-cessful applications to many high-level tasks [3, 22, 53, 77, 81, 93], the efﬁcacy of these global models on low-level en-hancement and restoration problems has not been studied extensively. The pioneering works on Transformers for low-level vision [8,13] directly applied full self-attention, which only accepts relatively small patches of ﬁxed sizes (e.g.,
48×48). Such a strategy will inevitably cause patch bound-ary artifacts when applied on larger images using crop-ping [13]. Local-attention based Transformers [48,88] ame-liorate this issue, but they are also constrained to have lim-ited sizes of receptive ﬁeld, or to lose non-locality [22, 85], which is a compelling property of Transformers and MLP models relative to hierarchical CNNs.
To overcome these issues, we propose a generic im-age processing network, dubbed MAXIM, for low-level vi-sion tasks. A key design element of MAXIM is the use of multi-axis approach (Sec. 3.2) that captures both local and global interactions in parallel. By mixing information on a single axis for each branch, this MLP-based opera-tor becomes ‘fully-convolutional’ and scales linearly with respect to image size, which signiﬁcantly increases its ﬂex-ibility for dense image processing tasks. We also deﬁne and build a pure MLP-based cross-gating module (Sec. 3.3), which adaptively gate the skip-connections in the neck of
MAXIM using the same multi-axis approach, and which further boosts performance.
Inspired by recent restora-tion models, we develop a simple but effective multi-stage, multi-scale architecture consisting of a stack of MAXIM backbones. MAXIM achieves strong performance on a range of image processing tasks, while requiring very few number of parameters and FLOPs. Our contributions are:
• A novel and generic architecture for image processing, dubbed MAXIM, using a stack of encoder-decoder back-bones, supervised by a multi-scale, multi-stage loss.
• A multi-axis gated MLP module tailored for low-level vision tasks, which always enjoys a global receptive ﬁeld, with linear complexity relative to image size.
• A cross gating block that cross-conditions two separate features, which is also global and fully-convolutional.
• Extensive experiments show that MAXIM achieves
SOTA results on more than 10 datasets including denois-ing, deblurring, deraining, dehazing, and enhancement. 2.