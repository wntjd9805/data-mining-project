Abstract
Real noisy-clean pairs on a large scale are costly and difficult to obtain. Meanwhile, supervised denoisers trained on synthetic data perform poorly in practice. Self-supervised denoisers, which learn only from single noisy images, solve the data collection problem. However, self-supervised denoising methods, especially blindspot-driven ones, suffer sizable information loss during input or net-work design. The absence of valuable information dramat-ically reduces the upper bound of denoising performance.
In this paper, we propose a simple yet efficient approach called Blind2Unblind to overcome the information loss in blindspot-driven denoising methods. First, we introduce a global-aware mask mapper that enables global perception and accelerates training. The mask mapper samples all pix-els at blind spots on denoised volumes and maps them to the same channel, allowing the loss function to optimize all blind spots at once. Second, we propose a re-visible loss to train the denoising network and make blind spots visible. The denoiser can learn directly from raw noise im-ages without losing information or being trapped in identity mapping. We also theoretically analyze the convergence of the re-visible loss. Extensive experiments on synthetic and real-world datasets demonstrate the superior performance of our approach compared to previous work. Code is avail-able at https://github.com/demonsjin/Blind2Unblind. 1.

Introduction
Image denoising, an essential task of low-level image processing, aims to remove noise and restore a clean image.
In vision applications, the quality of denoising significantly affects the performance of downstream tasks, such as super-resolution [16], semantic segmentation [22], and object de-tection [31]. In addition, the denoiser can significantly im-prove the quality of images captured by mobile phones and other devices, reflecting a broad demand in imaging fields.
âˆ—Corresponding author
With the development of neural networks, learning-based denoisers [3, 6, 13, 29, 35, 36, 38, 39] have recently shown superior performance than traditional methods [5, 8, 9, 12]. However, supervised denoisers, e.g., U-Net [29],
DnCNN [38], FFDNet [39], RIDNet [3], SANet [6], rely on numerous noisy-clean pairs, which are costly and hard to collect. The performance of denoisers drops dramati-cally once processing unknown noise patterns. Lehtinen et al. [21] then propose to recover clean signals directly from corrupted image pairs. Using corrupted pairs reduces the difficulty of data collection but remains challenging for dy-namic scenes with deformations and image quality varia-tions.
To alleviate the above limitations, self-supervised de-noising [4, 15, 18, 20, 26, 32, 33] that learns from a single noisy image has attracted much interest from researchers.
Ulyanov et al. [32] learn deep prior only from a single noisy image. Namely, each degraded image has to be trained from scratch. Manual masking, e.g., Noise2Self [4],
Noise2Void [18], avoids custom denoising for each image.
Since blind spots on the inputs occupy a large area, the re-ceptive field of predicted pixels loses much valuable con-text, resulting in poor performance. Moreover, optimiz-ing partial pixels in each iteration causes slow convergence.
Laine et al. [20] design a blind spot network to bound the re-ceptive field in four directions instead of manual masking.
Masked convolution accelerates training and increases the receptive field to all areas except the blind spot. Similarly, the dilated blindspot network [33] sets blindspots on the receptive field without masking the inputs. Regardless of masked input or blind-spot networks, lower accuracy limits practical applications. Bayesian estimation [19, 20, 33] is used for explicit noise modeling as post-processing. How-ever, noise modeling performs poorly on real-world data with complex patterns. Some works [25, 34] perform noise reduction for noisier-noise pairs even though the additional noise increases the information loss and requires that the extra noise has the same distribution as the original one.
Subsequently, Pang et al. [26] develop a data augmentation technique with the known noise level to address the overfit-ting caused by the absence of truth images. Recently, Huang et al. [15] propose to train the network with training pairs sub-sampled from the same noisy image. However, using sub-sampling pairs for supervision lead to over smoothing as neighboring pixels are approximated.
In this paper, we propose Blind2Unblind, a novel self-supervised denoising framework that overcomes the above limitations. Our framework consists of a global-aware mask mapper based on mask-driven sampling and a training strat-egy without blind spots based on re-visible loss. Specifi-cally, we divide each noisy image into blocks and set spe-cific pixels in each block as blind spots, so that we can ob-tain a global masked volume as input, which consists of a set of images with order masks. Then, the volume with global masks is fed into the network in the same batch.
The global mapper samples denoised volumes at blind spots and projects them onto the same plane to generate denoised images. The operation speeds up training, enables global optimization, and allows the application of re-visible loss.
However, masked images result in a sizable loss of valuable information, severely reducing the upper bound of denois-ing performance. Therefore, we consider learning from raw noisy images without masks and relief from identity map-ping. Furthermore, the intermediate medium of gradient up-date must be introduced since raw noisy images cannot par-ticipate in backpropagation during training. We assume that masked images serve as a medium and propose a re-visible loss to enable the transition from blind-spot denoising to non-blind denoising. The proposed self-supervised denois-ing framework, which does not involve noise model prior or the removal of valuable information, shows surprising per-formance. Moreover, advanced models can be applied to our proposed method.
The contributions of our work are as follows: 1. We propose a novel self-supervised denoising frame-work that makes blind spots visible, without sub-sample, noise model priors and identity mapping. 2. We provide a theoretical analysis of re-visible loss and present its upper and lower bounds on convergence. 3. Our approach shows superior performance compared with state-of-the-art methods, especially on real-world datasets with complex noise patterns. 2.