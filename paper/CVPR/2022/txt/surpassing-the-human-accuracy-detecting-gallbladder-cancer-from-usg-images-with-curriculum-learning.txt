Abstract
We explore the potential of CNN-based models for gall-bladder cancer (GBC) detection from ultrasound (USG) im-ages as no prior study is known. USG is the most common diagnostic modality for GB diseases due to its low cost and accessibility. However, USG images are challenging to ana-lyze due to low image quality, noise, and varying viewpoints due to the handheld nature of the sensor. Our exhaustive study of state-of-the-art (SOTA) image classification tech-niques for the problem reveals that they often fail to learn the salient GB region due to the presence of shadows in the
USG images. SOTA object detection techniques also achieve low accuracy because of spurious textures due to noise or adjacent organs. We propose GBCNet to tackle the chal-lenges in our problem. GBCNet first extracts the regions of interest (ROIs) by detecting the GB (and not the can-cer), and then uses a new multi-scale, second-order pooling architecture specializing in classifying GBC. To effectively handle spurious textures, we propose a curriculum inspired by human visual acuity, which reduces the texture biases in GBCNet. Experimental results demonstrate that GBC-Net significantly outperforms SOTA CNN models, as well as the expert radiologists. Our technical innovations are generic to other USG image analysis tasks as well. Hence, as a validation, we also show the efficacy of GBCNet in detecting breast cancer from USG images. Project page with source code, trained models, and data is available at https://gbc-iitd.github.io/gbcnet.
Figure 1. (a), (b), and (c) Normal, benign, and malignant GB sam-ple in USG images, respectively. While normal or benign GB have regular anatomy, clear boundary is absent in malignant GB. (d) A malignant (biopsy-proven) GB sample. (e) Shadows having visual traits of a GB leads to localization error in ResNet50. (f) GBCNet tackles shadow artifacts well. (g) Another sample of malignant
GB. (h) The radiologist incorrectly diagnosed the GB as benign based on the stone and wall thickening. (i) GBCNet helps the ra-diologist to identify the salient region with liver infiltration by the
GB, a critical feature of GBC, and correct the prediction. 1.

Introduction
According to GLOBOCAN 2018 [10], worldwide about 165,000 people die of GBC annually. For most patients, GBC is detected at an advanced stage, with a mean survival rate for patients with advanced GBC of six months and a 5-year survival rate of 5% [28,41]. Detecting GBC at an early stage could ameliorate the bleak survival rate.
Lately, machine learning models based on convolutional neural network (CNN) architectures have made transforma-tional progress in radiology, and medical diagnosis for dis-eases such as breast cancer, lung cancer, pancreatic cancer, and melanoma [3,5,16,17,29]. However, their usage is con-spicuously absent for the GBC detection. Although there has been prior work involving segmentation and detection of the
GB abnormalities such as stones and polyps [14, 31, 35], detection of GBC is missing from the list. A search on
Google Scholar with keywords “artificial intelligence” and
“gallbladder cancer” returned 204 articles between 2015-In these, we did not find any published article on 2021. deep learning-based GBC detection from USG images.
Early diagnosis and resection are critical for improving the survival rate of GBC. Due to the non-ionizing radiation, low cost, portability, and accessibility, USG is a popular di-agnostic imaging modality. Although identifying anoma-lies such as stones or GB wall thickening at routine USG is easy, accurate characterization is challenging [25, 27]. Of-ten, USG is the sole diagnostic imaging performed for pa-tients with suspected GB ailments. If malignancy is not sus-pected, no further testing is usually performed, and GBC could silently advance. Therefore, it is imperative to de-velop and understand the characterization of GB malignancy from USG images.
There are significant challenges in using CNN models for
USG image analysis. Unlike MRI or CT, USG images suffer from low imaging quality due to noise and other sensor ar-tifacts. The views are also not aligned due to the handheld nature of the sensor. We observe that modern CNN classi-fiers fail to localize the salient GB region due to the presence of shadows which often have similar visual traits of a GB in USG images (Fig. 1). Training object detectors for GBC detection gets biased towards learning from spurious tex-tures due to noise and adjacent organ tissues rather than the shape or boundary of GB wall, which results in poor accu-racy. Further, unlike normal and benign GB regions, which have regular anatomy, malignant cases are much harder to detect due to the absence of a clear GB boundary or shape and the presence of a mass.
Contributions: The key contributions of this work are: (1) We focus on circumventing the challenges for auto-mated detection of GBC from USG images and propose a deep neural network, GBCNet, for detecting GBC from USG images. GBCNet extracts candidate regions of interest (ROIs) from the USG to mitigate the effects of shadows and then uses a new multi-scale, second-order pooling-based (MS-SoP) classifier on the ROIs to classify gallbladder malignancy. MS-SoP encodes rich feature representations for malignancy detection. (2) Even though GBCNet shows improvement in GB ma-lignancy detection over multiple SOTA models, the spurious texture present in an ROI bias the classifica-tion unit towards generating false positives. To allevi-ate the issue, we propose a training curriculum inspired by human visual acuity [33, 53]. Visual acuity refers to the sharpness of visual stimuli. The proposed cur-riculum mitigates texture bias and helps GBCNet focus on shape features important for accurate GBC detection from USG images. (3) A lack of publicly available USG image datasets re-lated to GB malignancy adds to the difficulty of uti-lizing CNN models for detecting GBC. We have col-lected, annotated, and curated a USG image dataset of 1255 abdominal USG images collected from 218 pa-tients. We refer this dataset as the Gallbladder Cancer
Ultrasound (GBCU) dataset. 2.