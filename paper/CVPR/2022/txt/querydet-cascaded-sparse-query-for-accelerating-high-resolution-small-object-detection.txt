Abstract
While general object detection with deep learning has achieved great success in the past few years, the perfor-mance and efficiency of detecting small objects are far from satisfactory. The most common and effective way to promote small object detection is to use high-resolution images or feature maps. However, both approaches in-duce costly computation since the computational cost grows squarely as the size of images and features increases. To get the best of two worlds, we propose QueryDet that uses a novel query mechanism to accelerate the inference speed of feature-pyramid based object detectors. The pipeline composes two steps: it first predicts the coarse locations of small objects on low-resolution features and then com-putes the accurate detection results using high-resolution features sparsely guided by those coarse positions. In this way, we can not only harvest the benefit of high-resolution feature maps but also avoid useless computation for the background area. On the popular COCO dataset, the pro-posed method improves the detection mAP by 1.0 and mAP-small by 2.0, and the high-resolution inference speed is im-proved to 3.0× on average. On VisDrone dataset, which contains more small objects, we create a new state-of-the-art while gaining a 2.3× high-resolution acceleration on average. Code is available at https://github.com/
ChenhongyiYang/QueryDet-PyTorch. 1.

Introduction
With the recent advances of deep learning [15, 53], vi-sual object detection has achieved massive improvements in both performance and speed [3, 12, 26, 27, 29, 37, 39, 49].
It has become the foundation for widespread applications, such as autonomous driving and remote sensing. However, detecting small objects is still a challenging problem. There is a large performance gap between small and normal scale objects. Taking RetinaNet [27], one of the state-of-the-art
*Work done when working as a full-time research intern at TuSimple.
Figure 1. QueryDet achieves highly effective small object detec-tion in high-resolution features. The locations (query keys) where small objects might exist are first predicted in the low-resolution features, and a sparse feature map (query values) is constructed using high-resolution features in those locations. Finally, a sparse detection head is used to output the detected boxes. This paradigm is applied in a cascaded manner, enabling fast and accurate small object detection. object detectors, as an example, it achieves 44.1 and 51.2 mAP on objects with medium and large sizes but only ob-tains 24.1 mAP on small objects on COCO [28] test-dev set. Such degradation is mainly caused by three factors: 1) the features that highlight the small objects are extinguished because of the down-sampling operations in the backbone of Convolutional Neural Networks (CNN); hence the fea-tures of small objects are often contaminated by noise in the background; 2) the receptive field on low-resolution fea-tures may not match the size of small objects as pointed in
[25]; 3) localizing small objects is more difficult than large objects because a small perturbation of the bounding box may cause a significant disturbance in the Intersection over
Union (IoU) metric.
Small object detection can be improved by scaling the size of input images or reducing the down-sampling rate of CNN to maintain high-resolution features, as they in-crease the effective resolution in the resulted feature map.
However, merely increasing the resolution of feature maps can incur considerable computation costs. Several works [1, 26, 29] proposed to build a feature pyramid by reusing the multi-scale feature maps from different layers of a CNN to address this issue. Objects with various scales are han-dled on different levels: large objects tend to be detected on high-level features, while small objects are usually de-tected on low levels. The feature pyramid paradigm saves the computation cost of maintaining high-resolution fea-ture maps from shallow to deep in the backbone. Never-theless, the computation complexity of detection heads on low-level features is still enormous. For example, adding an extra pyramid level P2 into RetinaNet will bring about 300% more computation (FLOPs) and memory cost in the detection head; hence severely lowering down the inference speed from 13.6 FPS to 4.85 FPS on NVIDIA 2080Ti GPU.
In this paper, we propose a simple and effective method,
QueryDet, to save the detection head’s computation while promoting the performance of small objects. The motiva-tion comes from two key observations: 1) the computation on low-level features is highly redundant. In most cases, the spatial distribution of small objects is very sparse: they occupy only a few portions of the high-resolution feature maps; hence a large amount of computation is wasted. 2)
The feature pyramids are highly structured. Though we cannot accurately detect the small objects in low-resolution feature maps, we can still infer their existence and rough locations with high confidence.
A natural idea to utilize these two observations is that we can only apply the detection head to small objects’ spatial locations. This strategy requires locating the rough location of small objects at a low cost and sparse computation on the desired feature map. In this work, we present QueryDet that is based on a novel query mechanism Cascade Sparse Query (CSQ), as illustrated in Fig. 1. We recursively predict the rough locations of small objects (queries) on lower resolu-tion feature maps and use them to guide the computations in higher resolution feature maps. With the help of sparse con-volution [13, 55], we significantly reduce the computation cost of detection heads on low-level features while keep-ing the detection accuracy for small objects. Note that our approach is designed to save the computation spatially, so it is compatible with other accelerating methods like light-weighted backbones [44], model pruning [16], model quan-tization [51], and knowledge distillation [5].
We evaluate our QueryDet on the COCO detection benchmark [28] and a challenging dataset, VisDrone [59], that contains a large amount of small objects. We show our method can significantly accelerate inference while improv-ing the detection performance. In summary, we make two main contributions:
• We propose QueryDet, in which a simple and effective
Cascade Sparse Query (CSQ) mechanism is designed.
It can reduce the computation costs of all feature pyra-mid based object detectors. Our method can improve the detection performance for small objects by effec-tively utilizing high-resolution features while keeping fast inference speed.
• On COCO, QueryDet improves the RetinaNet baseline by 1.1 AP and 2.0 APS by utilizing high-resolution features, and the high-resolution detection speed is im-proved by 3.0× on average when CSQ is adopted.
On VisDrone, we advance the state-of-the-art results in terms of the detection mAP and enhance the high-resolution detectopm speed by 2.3× on average. 2.