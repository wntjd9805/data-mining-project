Abstract
Learning to estimate object pose often requires ground-truth (GT) labels, such as CAD model and absolute-scale object pose, which is expensive and laborious to obtain in the real world. To tackle this problem, we propose an un-supervised domain adaptation (UDA) for category-level ob-ject pose estimation, called UDA-COPE. Inspired by recent multi-modal UDA techniques, the proposed method exploits a teacher-student self-supervised learning scheme to train a pose estimation network without using target domain pose labels. We also introduce a bidirectional filtering method between the predicted normalized object coordinate space (NOCS) map and observed point cloud, to not only make our teacher network more robust to the target domain but also to provide more reliable pseudo labels for the student network training. Extensive experimental results demon-strate the effectiveness of our proposed method both quan-titatively and qualitatively. Notably, without leveraging target-domain GT labels, our proposed method achieved comparable or sometimes superior performance to existing methods that depend on the GT labels. 1.

Introduction
Object pose estimation is one of the crucial tasks used in various robotics and computer vision applications for robot manipulation [8, 34, 37, 39] and augmented reality (AR) [23,24,28]. Using sensor data such as images or point clouds, this task aims to estimate the poses of target objects including 3D orientation, 3D location, and size information.
Previous 6D object pose estimation methods follow the instance-level pose estimation schemes [12, 13, 25, 27, 31, 34, 38] that rely on given 3D CAD model information (e.g., keypoints, geometry) and the size of known objects. How-ever, these methods typically have difficulty estimating the pose of unknown objects since they do not yet have 3D
CAD models as priors.
In contrast to the instance-level scheme, category-level object pose estimation [4, 5, 20, 30, 35, 36] approaches are more efficient in that a single network can infer multiple classes at once. In particular, Wang et al. [35] introduced a pioneering representation called Normalized Object Co-ordinate Space (NOCS), to align different object instances within one category in a shared 3D orientation. By estimat-ing per-category NOCS maps, it is able to estimate the 6D pose of unseen objects without prior 3D CAD models. Its strengths have led to the use of NOCS representation in the following studies [4, 5, 20, 30, 36].
However, current object pose estimation research mostly relies on supervised learning, which requires expensive GT labels such as 3D object CAD models and absolute object pose. These labels are not only difficult to obtain in the real world but are also unreliable due to the human-annotation.
Because of this difficulty, most of the training depends on synthetic datasets [15, 29, 31] and is usually not feasible in real-world applications due to domain gaps.
To cope with the real-world data scarcity problem, we take a look at unsupervised domain adaptation (UDA) meth-ods [14, 19, 42]. UDA approaches often consider two types of datasets, the source domain (i.e. synthetic dataset) and the target domain (i.e. real-world dataset) dataset. The main goal of the UDA methods is to successfully make deep learning networks robust to the target domain using only the
GT labels of the source domain. Various techniques exist, such as pseudo label generation [14, 19], teacher and stu-dent networks with momentum updates [1, 40], adversarial learning [2, 3, 16], and etc.
In this paper, we propose an Unsupervised Domain
Adaptation for Category-level Object Pose Estimation (UDA-COPE). The proposed method effectively transfers task knowledge from a synthetic domain to a real domain by exploiting a multi-modal self-supervised learning scheme using pseudo labels. Our UDA-COPE concentrates on how to make high-quality pseudo-labels that are efficiently tar-geted for the category-level pose estimation task. To this end, we designed bidirectional point filtering to remove noisy and inaccurate points based on pose optimization. Ex-tensive experiments demonstrate that our UDA-COPE and bidirectional point filtering successfully can reduce the do-main gap between synthetic and real datasets. Moreover, our framework achieved better performance than the previ-ous supervised methods [4, 30, 35, 36]. The contributions of our method are summarized as:
• We propose an RGB-D based Unsupervised Domain
Adaptation for Category-level Object Pose Estimation (UDA-COPE) framework that addresses the problem of data deficiency in real-world scenarios.
• We design a teacher-student framework where high-quality pose-aware pseudo labels can be obtained via the proposed bidirectional point filtering.
• Our method shows comparable or sometimes better re-sults than supervised pose estimation approaches. 2.