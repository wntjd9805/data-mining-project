Abstract
Domain generalization (DG) aims to improve the gener-alization performance for an unseen target domain by us-ing the knowledge of multiple seen source domains. Main-stream DG methods typically assume that the domain la-bel of each source sample is known a priori, which is chal-lenged to be satisfied in many real-world applications. In this paper, we study a practical problem of compound DG, which relaxes the discrete domain assumption to the mixed source domains setting. On the other hand, current DG al-gorithms prioritize the focus on semantic invariance across domains (one-vs-one), while paying less attention to the holistic semantic structure (many-vs-many). Such holis-tic semantic structure, referred to as meta-knowledge here, is crucial for learning generalizable representations. To this end, we present COmpound domain generalization via
Meta-knowledge ENcoding (COMEN), a general approach to automatically discover and model latent domains in two steps. Firstly, we introduce Style-induced Domain-specific
Normalization (SDNorm) to re-normalize the multi-modal underlying distributions, thereby dividing the mixture of source domains into latent clusters. Secondly, we harness the prototype representations, the centroids of classes, to perform relational modeling in the embedding space with two parallel and complementary modules, which explicitly encode the semantic structure for the out-of-distribution generalization. Experiments on four standard DG bench-marks reveal that COMEN exceeds the state-of-the-art per-formance without the need of domain supervision. 1.

Introduction
The success of many computer vision algorithms hinges on a strong presumption that the training and test data are independent and identically distributed (i.i.d.). In practice, however, this hypothesis is prone to be violated due to the
*Corresponding author
Figure 1. Top: (a) Vanilla domain generalization. (b) Compound domain generalization. Bottom: The workflow of our approach. change of environments, imaging devices, selection bias, to name a few. How to generalize a well-trained model to out-of-distribution domains has motivated a body of research on
Domain Adaptation (DA) [15, 37, 48, 52, 54, 68, 70] and Do-main Generalization (DG) [2, 8, 9, 31, 34, 41]. In contrast to DA problem where the unlabeled or partially labeled tar-get data is available, DG considers a harder problem setting where a model trained on a set of source domain data should directly generalize to an unseen target domain with differ-ent data statistics, without the need of accessing to target domain data for retraining or fine-tuning (cf. Fig. 1 (a)).
Mainstream DG literature typically assumes that the do-main label of each source sample is known a priori, which is too restrictive to be satisfied in many practical applica-tions. For instance, with the explosive increase of the multi-source data from Internet, a mixture of multiple source data can be easily collected. However, manually dividing the crawled images into multiple domains requires tedious labor-intensive work given a large amount of training data.
Meanwhile, the latent domains may blend and interact in
complex ways. Thus, it is non-trivial and significant to auto-matically discover and model distinct underlying domains.
In this paper, we investigate a practical problem of com-pound domain generalization, where the domain label is unavailable for training (cf. Fig. 1 (b)). An intuitive ap-proach is to use the embedded features along with clus-tering strategies to conduct domain separation in advance.
However, the source samples are naturally divided into dif-ferent clusters according to their semantic categories rather than the domain-wise distinctions. When the source data contains heterogeneous but unknown latent domains, most conventional DG methods will not be applicable. Although some recent works [2,23,33,43] do not require domain label information during training, the informative latent domain structure contained in the source data is neglected.
On the other hand, existing DG methods, which mainly span domain invariant feature learning [16,34,35,41,42,69], gradient based meta-learning [9, 30, 31], and augmentation based generalization [50, 58], are devoted to learn seman-tic representations in virtue of one-vs-one consistency con-straints. Unfortunately, the learned representations may be insufficient to precisely encode the semantic informa-tion. By prioritizing the focus on semantic invariance across domains, the holistic semantic structure, which contains rich many-vs-many information regarding the inter-class relations and interactions, is yet to be thoroughly investi-gated. In particular, we refer such holistic semantic struc-ture as meta-knowledge, namely, knowledge that is domain-agnostic and generalizable for unseen target domains.
Grounded on these findings, we present a novel DG framework called COmpound domain generalization via
Meta-knowledge ENcoding (COMEN). The basic idea of the
COMEN is to identify latent domain structure and model the semantic correlations among different categories across domains. To achieve this goal, we establish the COMEN in two stages. During the first stage, we introduce Style-induced Domain-specific Normalization (SDNorm) to re-veal the complex combinations of latent domains and learn a set of domain assignment probabilities for each source sample. SDNorm is end-to-end trainable and can be eas-ily plugged into modern deep neural networks. In the sec-ond stage, based on the discovered latent domains, we resort to prototypes (the feature centroids of categories) to model the relations among different semantic categories via two parallel modules, i.e., Prototypical Graph Reasoning (Pro-toGR) and Prototypical Category-aware Contrastive Learn-ing (ProtoCCL). ProtoGR helps each categorical prototype attend and reason over its neighborhoods’ prototypical fea-tures instead of using pairwise alignment, thereby captur-ing the topological structure of semantic space. ProtoCCL compensates for the shortage of samples in the prototypi-cal feature space by contrastively learning the relations of different categories while preserving their discriminability.
These two modules work in a synergistic manner towards encoding semantic structures into the embedding space.
Our contributions can be summarized as follows:
• We introduce a more practical compound DG setting that imposes no prior knowledge on the domain label of each source sample. Then, a unified learning frame-work, called COMEN, is introduced to jointly discover and model the latent domains.
• In terms of latent domain discovery, we uncover and re-normalize the multimodal underlying distributions with the proposed SDNorm.
• In terms of encoding the semantic structure, we pro-pose two complementary modules, ProtoGR and Pro-toCCL, to explicitly explore the relations and interac-tions of prototype in the common feature space.
• Experiments on four standard DG benchmarks (PACS,
Digits-DG, VLCS, and Office-Home) demonstrate that
COMEN outperforms the state-of-the-art methods by large margins without the need of domain supervision. 2.