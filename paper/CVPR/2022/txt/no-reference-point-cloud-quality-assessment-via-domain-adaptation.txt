Abstract
We present a novel no-reference quality assessment met-ric, the image transferred point cloud quality assessment (IT-PCQA), for 3D point clouds. For quality assessment, deep neural network (DNN) has shown compelling perfor-mance on no-reference metric design. However, the most challenging issue for no-reference PCQA is that we lack large-scale subjective databases to drive robust networks.
Our motivation is that the human visual system (HVS) is the decision-maker regardless of the type of media for qual-ity assessment. Leveraging the rich subjective scores of the natural images, we can quest the evaluation criteria of hu-man perception via DNN and transfer the capability of pre-diction to 3D point clouds.
In particular, we treat natu-ral images as the source domain and point clouds as the target domain, and infer point cloud quality via unsuper-vised adversarial domain adaptation. To extract effective latent features and minimize the domain discrepancy, we propose a hierarchical feature encoder and a conditional-discriminative network. Considering that the ultimate pur-pose is regressing objective score, we introduce a novel con-ditional cross entropy loss in the conditional-discriminative network to penalize the negative samples which hinder the convergence of the quality regression network. Experi-mental results show that the proposed method can achieve higher performance than traditional no-reference metrics, even comparable results with full-reference metrics. The proposed method also suggests the feasibility of assessing the quality of specific media content without the expensive and cumbersome subjective evaluations. Code is available at https://github.com/Qi-Yangsjtu/IT-PCQA. 1.

Introduction
Point clouds have achieved compelling performance in augmented reality [16], automatic driving [7] and indus-trial robots [26]. Accurate point cloud quality assess-ment (PCQA) is a critical safeguard for providing high-∗ equal contribution. Corresponding author is Yiling Xu.
Figure 1. Motivation of domain adaption in PCQA. The source do-main (natural images) and target domain (point clouds) have dif-ferent domain distribution. Refer to the evaluation criterion speci-fied by HVS, we use unsupervised adversarial domain adaptation (UADA) to map the domain distribution and regress quality score. quality point clouds for human vision tasks, such as vir-tual/augmented reality and cultural heritage. However, point clouds are subject to more complex distortion com-pared with image/video due to their data format, which means PCQA is a more challenging task. Specifically, point clouds consist of scattered points with spatial coordinates and attributes (e.g., color, normal, and opacity). To amelio-rate the urgent demand of PCQA, MPEG first adopts point-to-point/plane (p2point, p2plane) [23, 30] to quantify point clouds geometrical distortion, and suggests to use the peak signal noise ratio (PSNR) of luminance and chrominance to deduce color distortion [31]. After that, more reliable and robustness metrics are proposed, such as PCQM [24],
GraphSIM [38], MPED [37] and MS-GraphSIM [43]. De-spite the emergence of these metrics alleviating the urgent demand of PCQA, these metrics are all full-reference met-rics, which means the final evaluation results need the assis-tance of reference samples.
However, in many practical applications, reference sam-ples are not available, such as point clouds rendered af-ter the transmission system [17]. And some samples natu-rally do not have a high-quality reference, such as the point clouds captured in the wild. Therefore, a more urgent task is studying PCQA in a no-reference case. Refer to the de-velopment of IQA, a no-reference metric usually based on natural scene statistic [15] or convolutional neural network (CNN) [42]. Both methods need to analyze point cloud characteristics based on a large number of samples. But current PCQA databases are usually small, which are insuf-ficient to derive a robust no-reference model. Therefore, the challenge of no-reference PCQA lies in lacking a complete subjective database with accurate labels.
Therefore, in the absence of a large-scale subjective ex-periment, we propose to solve no-reference PCQA whereby unsupervised adversarial domain adaptation (UADA). Do-main adaptation (DA) can reduce the need for costly labeled data in the target domain via using the rich samples and labels in the source domain [35]. Considering the natural image quality assessment (IQA) research is relatively ma-ture, we treat natural images as the source domain and point clouds as the target domain, and infer point cloud quality via inheriting the prior knowledge in the image field.
Specifically, there are two reasons behind that. First, there are numerous IQA databases [28] [25] with accurate subjective ratings, and the scale of IQA databases is much larger than that of PCQA. Second, based on previous re-searches, there are strong connections between 2D and 3D perception, such as reconstruction (e.g., from image to 3D object [20]) and tracking [22]. For quality assessment, our human visual system (HVS) is the universal evaluator, which means the perception characteristics shown in IQA share possible homogeneity with that in PCQA. Refer to
Fig. 1, the characteristics of the natural image (i.e., the red curve) and point cloud (i.e., the green curve) have their map-ping relationship with human perception, respectively. Via revealing the potential relationship between natural image and point cloud, we can use the prior knowledge of IQA to guide point cloud distortion evaluation.
To transfer useful information from the 2D natural im-age domain to the 3D point cloud domain, the point clouds are first projected into images to satisfy a shared feature ex-traction and processing network with natural images. Then we design an effective feature generator, i.e., the hierarchi-cal SCNN (H-SCNN), and a sophisticated discriminator, i.e., the conditional-discriminative network, to minimize domain discrepancy and produce robust features. SCNN is a lightweight network proposed in [41] for evaluating natural image quality. The motivation of H-SCNN is that multiscale features are canonical for both natural images and point clouds in terms of the full-reference IQA and
PCQA [34] [39] [38]. Considering the ultimate purpose of our model is quality assessment rather than simply minimiz-ing the domain discrepancy, we propose a conditional cross entropy loss (CCEL) for the conditional-discriminative net-work. While reducing the domain discrepancy, we penalize the features that are less irrelevant for quality regression and improve the final results.
In the proposed model called image transferred point 2. cloud quality (IT-PCQA), which is shown in Fig. we first use six-perpendicular-projection to generate multi-prospective texture images for point clouds. Then, the im-ages are sent into H-SCNN to generate latent features. Next, the conditional-discriminative network matches the feature distributions of source and target domains and refine the features so that they are more related to objective score re-gression. Finally, the quality regression network maps the features to objective scores.
The main contributions of this paper include:
• We propose a novel unsupervised no-reference PCQA framework, called IT-PCQA, which uses the ground truth of
IQA to emulate the human perception of 3D point clouds.
To the best of our knowledge, this is the first unsupervised deep-learning-based no-reference PCQA metric via domain adaption, which reveals the potential relevance between 2D and 3D media in the field of quality assessment.
• To realize transfer learning concerning using the natu-ral images as the source domain, we use multi-perspective images of the point cloud as the network input. To extract effective features for both natural and multi-perspective im-ages, we propose a hierarchical feature encoder, H-SCNN, to fuse multiscale structure features. Compared with classi-cal image feature encoder, e.g., VGG16, ResNet, AlexNet, and original SCNN, the proposed H-SCNN presents obvi-ously better performance on PCQA.
• Considering that regressing objective scores is our fi-nal goal, we propose a conditional-discriminative network to produce robust features for quality prediction while min-imizing the domain discrepancy. A novel loss function, i.e.,
CCEL, is advocated to penalize the samples that negatively impact the perception prediction and stabilize the results of adversarial learning.
• We compare the proposed IT-PCQA with multiple full-reference metrics and two typical no-reference PCQA baselines. Experimental results show that the proposed IT-PCQA presents better performances than the two typical su-pervised learning networks in most cases, and it is even su-perior to some full-reference metrics. 2.