Abstract
Powerful priors allow us to perform inference with in-In this paper, we propose an au-sufficient information. toregressive prior for 3D shapes to solve multimodal 3D tasks such as shape completion, reconstruction, and gener-ation. We model the distribution over 3D shapes as a non-sequential autoregressive distribution over a discretized, low-dimensional, symbolic grid-like latent representation of 3D shapes. This enables us to represent distributions over 3D shapes conditioned on information from an arbitrary set of spatially anchored query locations and thus perform shape completion in such arbitrary settings (e.g. generating
*indicates equal contribution 1 a complete chair given only a view of the back leg). We also show that the learned autoregressive prior can be leveraged for conditional tasks such as single-view reconstruction and language-based generation. This is achieved by learning task-specific ‘naive’ conditionals which can be approxi-mated by light-weight models trained on minimal paired data. We validate the effectiveness of the proposed method using both quantitative and qualitative evaluation and show that the proposed method outperforms the specialized state-of-the-art methods trained for individual tasks. The project page with code and video visualizations can be found at https://yccyenchicheng.github.io/AutoSDF/.
1.

Introduction 3D representations are essential for applications in robotics, self-driving, virtual/augmented reality, and online marketplaces. This has led to an increasing number of di-verse tasks that rely on effective 3D representations – a robot might need to predict the shape of the objects it en-counters, an artist may want to imagine what a ‘thin couch’ would look like, or a woodworker may want to explore pos-sible tabletop designs to match the legs they carved. A com-mon practice for tackling these tasks, such as 3D comple-tion or single-view prediction is to utilize task-specific data and train individual systems for each task, requiring a large amount of compute and data resources.
While tasks such as shape completion or image-conditioned prediction are seemingly different, they require similar outputs – a distribution over the plausible 3D struc-ture conditioned on the corresponding input. A general-ized notion of what ‘tables’ are is useful for both predicting the full shape from the left half and imagining what a ‘tall round table’ may look like. In this work, we operationalize this observation and show that a generic shape prior can be leveraged across these different inference tasks. In particu-lar, we propose to learn an expressive autoregressive shape prior from abundantly available raw 3D data. This prior can then help augment the task-specific conditional distri-butions which require paired training data (e.g. language-shape pairs), and significantly improve performance when such paired data is difficult to acquire.
Learning such a prior directly over the continuous and high-dimensional space of 3D shapes is computationally intractable.
Inspired by recent approaches that overcome similar challenges for image synthesis, we first leverage discrete representation learning to compute discretized and low-dimensional representations for 3D shapes. This not only preserves the essential information for decoding high-quality outputs but also makes the training of autoregressive models tractable. Moreover, to learn such a prior for a broad set of tasks such as shape completion where arbitrary sub-sets maybe observed e.g. 4 legs of a chair, we propose to learn a ‘non-sequential’ autoregressive prior i.e. one capa-ble of using random subsets as conditioning. To enable this, we also enforce that the discrete elements over which this prior is learned are encoded independently.
We then present a common framework for leveraging our learned prior for conditional generation tasks e.g. single-view reconstruction or language-guided generation (see
Figure 1). Instead of modeling the complex conditional dis-tribution directly, we propose to approximate it as a product of the prior and task-specific ‘naive’ conditionals, the lat-ter of which can be learned without extensive training data.
Combined with the rich and expressive shape prior, we find that this unified and simple approach leads to improvements over task-specific state-of-the-art methods. 2.