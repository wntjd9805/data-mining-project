Abstract
Large-scale multi-label classification datasets are com-monly, and perhaps inevitably, partially annotated. That is, only a small subset of labels are annotated per sam-ple. Different methods for handling the missing labels in-duce different properties on the model and impact its ac-curacy. In this work, we analyze the partial labeling prob-lem, then propose a solution based on two key ideas. First, un-annotated labels should be treated selectively accord-ing to two probability quantities: the class distribution in the overall dataset and the specific label likelihood for a given data sample. We propose to estimate the class distri-bution using a dedicated temporary model, and we show its improved efficiency over a na¨ıve estimation computed us-ing the dataset’s partial annotations. Second, during the training of the target model, we emphasize the contribu-tion of annotated labels over originally un-annotated labels by using a dedicated asymmetric loss. With our novel ap-proach, we achieve state-of-the-art results on OpenImages dataset (e.g. reaching 87.3 mAP on V6). In addition, ex-periments conducted on LVIS and simulated-COCO demon-strate the effectiveness of our approach. Code is available at https://github.com/Alibaba-MIIL/PartialLabelingCSL. 1.

Introduction
Recently, a remarkable progress has been made in multi-label classification [4, 8, 17, 32]. Dedicated loss functions were proposed in [2, 6, 30], as well as transformers based approaches [5, 17, 21, 26].
In many common cases, such as [7, 9, 12, 15, 16, 18], as the amounts of samples and labels in the data increase, it becomes impractical to fully annotate each image. For example, OpenImages dataset [16] con-sists of 9 million training images and having 9,600 classes.
An exhaustive annotation process would require annotating more than 86 billion labels. As a result, partially labeled data is inevitable in realistic large-scale multi-label classi-fication tasks. A partially labeled image is annotated with
Figure 1. Challenges in partial annotation. (1) “Lip” and “Yel-low” are clearly present in the left image but were not annotated as positive labels. The middle and right images are annotated with
“Yellow” and “Lip” respectively, while not being dominant labels in those images. (2) The deficiency of positive annotations is a key challenge: classes that frequently appear in images (e.g. “Black”,
“Lip”) may be annotated much less compared to infrequent classes (“Flower”, “Guitar”) (3) Most labels are un-annotated. How to ex-ploit a temporary model’s predictions for the un-annotated labels when training a target model? a subset of positive labels and a subset of negative labels, where the rest un-annotated labels are considered as un-known (Figure 1). Typically, the majority of the labels are un-annotated. For example, on average, a picture in Open-Images is annotated with only 7 labels. Thus, the question of how to treat the numerous un-annotated labels may have a considerable impact on the learning process.
The basic training mode for handling the un-annotated labels is simply to ignore their contribution in the loss function, as proposed in [7]. We denote this mode as Ig-nore. While ignoring the un-annotated labels is a reason-able choice, it may lead to a poor decision boundary as it exploits only a fraction of the data, see Figure 2(b). More-over, in a typical multi-label dataset, the probability of a label being negative is very high. Consequently, treating the un-annotated labels as negative may improve the dis-criminative power as it enables the exploitation of the entire data [15]. However, this training mode, denoted as Neg-Figure 2. Illustration of training modes for handling partial labeling. (a) In a partially labeled dataset, only a portion of the samples are annotated for a given class. (b) Ignore mode exploits only a subset of the samples which may lead to a limited decision boundary. (c)
Negative mode treats all un-annotated labels as negatives. It may produce suboptimal decision boundary as it adds noise of un-annotated positive labels. Also, annotated and un-annotated negative samples contribute similarly to the optimization process. (d) Our approach aims at mitigating these drawbacks by adjusting the training mode for each label selectively. ative, has two main drawbacks: adding label noise to the training, and inducing a high imbalance between negative and positive samples [2], see Figure 2(c).
While treating the un-annotated labels as negative can be useful for many classes, it may significantly harm the learn-ing of labels that tend to appear frequently in the images al-though not being sufficiently annotated. For example, color classes are labeled in only a small number of samples in
OpenImages [16], e.g. class “Black” is annotated in 1,688 samples, which is only 0.02% of the samples, while they are probably present in most of the images (see an example in
Figure 1). Consequently, such classes are trained with many wrong negative samples. Thus, it would be worthwhile to first identify the frequent classes in the data and treat them accordingly. While in fully annotated multi-label datasets (e.g. MS-COCO [20]) the class frequencies can be directly inferred by counting the number of their annotations, in par-tially annotated datasets it is not straightforward. Counting the number of positive annotations per class is misleading as the numbers are usually not proportional to the true class frequencies. In OpenImages, assumably infrequent classes like “Boat” and “Snow” are annotated in more than 100,000 samples, while frequent classes as colors are annotated in only ∼1,500 images. Therefore, the class distribution is re-quired to be estimated from the data.
In this paper, we propose a Selective approach that aims at mitigating the weaknesses raised by the primary training modes (Figure 2). In particular, we will select one of the pri-mary mode (Ignore or Negative) for each label individually by utilizing two probabilistic conditions, termed as label likelihood and label prior. The label likelihood quantifies the probability of a label being present in a specific image.
The label prior represents the probability of a label being present in the data. To acquire a reliable label prior, we pro-pose a method for estimating the class distribution. To that end, we train a classification model using Ignore mode and evaluate it on a representative dataset. Then, when train-ing the final model, to handle the high negative-positive im-balance, we adopt the asymmetric loss [2], which enables focusing on the hard samples, while at the same time con-trolling the impact from the positive and negative samples.
We further suggest decoupling the focusing levels of the an-notated and un-annotated terms in the loss to emphasize the contributions from the annotated negative samples.
Extensive experiments were conducted on three datasets:
OpenImages [16] (V3 and V6) and LVIS [9] which are par-tially annotated datasets with 9,600 and 1,203 classes, re-spectively.
In addition, we simulated partially annotated versions of the MS-COCO [20] for exploring and verifying our approach. Results and comparisons demonstrate the ef-fectiveness of our proposed scheme. Specifically, on Open-Images (V6) we achieve a state-of-the-art result of 87.34% mAP score. The contributions of the paper can be summa-rized as follows:
• Introducing a novel selective scheme for handling par-tially labeled data, that treat each un-annotated label sep-arately based on two probabilistic quantities: label likeli-hood and label prior. Our approach outperforms previous methods in several partially labeled benchmarks.
• We identify a key challenge in partially labeled data, regarding the inaccuracy of calculating the class distri-bution using the annotations, and offer an effective ap-proach for estimating the class distribution from the data.
• A partial asymmetric loss is proposed to dynamically control the impact of the annotated and un-annotated negative samples. 2.