Abstract
As 3D object detection on point clouds relies on the ge-ometrical relationships between the points, non-standard object shapes can hinder a method’s detection capability.
However, in safety-critical settings, robustness to out-of-domain and long-tail samples is fundamental to circumvent dangerous issues, such as the misdetection of damaged or rare cars. In this work, we substantially improve the gener-alization of 3D object detectors to out-of-domain data by deforming point clouds during training. We achieve this with 3D-VField: a novel data augmentation method that plausibly deforms objects via vector ﬁelds learned in an adversarial fashion. Our approach constrains 3D points to slide along their sensor view rays while neither adding nor removing any of them. The obtained vectors are trans-ferable, sample-independent and preserve shape and occlu-sions. Despite training only on a standard dataset, such as
KITTI, augmenting with our vector ﬁelds signiﬁcantly im-proves the generalization to differently shaped objects and scenes. Towards this end, we propose and share CrashD: a synthetic dataset of realistic damaged and rare cars, with a variety of crash scenarios. Extensive experiments on KITTI,
Waymo, our CrashD and SUN RGB-D show the general-izability of our techniques to out-of-domain data, different models and sensors, namely LiDAR and ToF cameras, for both indoor and outdoor scenes. Our CrashD dataset is available at https://crashd-cars.github.io. 1.

Introduction
With the established wide-spread progress of learning-based methods tackling a variety of perception tasks (e.g.,
∗ The authors contributed equally.
◦ Contact author: Alexander Lehner (alexander.lehner@tum.de).
Work partly sponsored by the German Federal Ministry for Economic
Affairs and Energy (grant 19A19005B), VDA KI-Absicherung project.
Figure 1. Predictions of PointPillars [18] trained on KITTI [13], without and with our adversarial augmentations on out-of-domain samples from the proposed CrashD dataset. CrashD comprises rare (top) and damaged (bottom) vehicles, resulting in natural ad-versarial examples [17]. As the models were applied to CrashD without ﬁne-tuning, due to the different object shapes, the stan-dard PointPillars delivered two false negatives and a false positive.
Images used with courtesy of BeamNG GmbH. object detection, semantic and panoptic segmentation), a re-cent trend denoted a focus shift towards ensuring the safe applicability of these powerful approaches in critical sce-narios, such as autonomous driving and robotics [27]. This has led to the pursuit of improving the model robustness and generalization [12,22,37], especially against out-of-domain data, which can naturally occur in the real world [17]. Such approaches include domain adaptation [39] and generaliza-tion [37], uncertainty estimation [11], simulations [4], and adversarial alterations [35].
Since corner cases are difﬁcult to be captured as they oc-cur in a dynamic real-life scenario, current datasets include only a limited amount of them, if any [5], leaving most of these cases out-of-domain. However, taking care of cor-ner cases is particularly important in safety-critical settings, where long-tail and out-of-distribution samples could lead to dangerous issues if not accounted for during training [5].
While several works have addressed some of these con-cerns on the imaging domain [4, 11, 16, 26], this is still
mostly unexplored for 3D point clouds [35], also due to the inherent challenges of point clouds, as they are unordered, sparse and irregularly sampled. Nevertheless, as the output of 3D sensors (e.g., LiDAR, ToF cameras), point clouds are especially useful in high automation, where robustness and redundancy are intertwined with safety.
In this context, real non-standard objects, such as dam-aged and rare cars, or those from different regions, can lead to false negatives, as shown in Figure 1, since the inter-point geometry on which 3D detectors rely is different than usual. While these examples can naturally occur in the real-world [17], they can also be generated artiﬁcially with ad-versarial attacks [14]. This kind of approaches show the vulnerabilities of a model, which can then be addressed to improve robustness. Recent adversarial point cloud alter-ation methods [35] have tackled this problem to improve the generalization to out-of-distribution data. However, despite being effective attacks, existing adversarial defor-mation strategies [19, 40] are sample-speciﬁc, lack wide-applicability, and by being designed without considering a 3D sensor, are mostly unconstrained in space [19].
In this work, we substantially improve the generaliza-tion capability of 3D object detectors to out-of-domain data, bridging this gap by deforming point clouds during train-ing. We propose 3D-VField: a novel adversarial augmenta-tion method that learns to deform point clouds via widely-applicable and sample-independent vector ﬁelds (i.e., col-lections of vectors linked to a set of points in a given space).
Our deformations preserve the overall object shape, only slide points along the view ray, and do not add or remove any points. After learning a vector ﬁeld, we use it to al-ter objects as data augmentation. The main contributions of this paper can be summarized as follows:
• We raise awareness on natural adversarial examples, such as those represented by damaged and rare cars, around their ability to fool popular 3D object detectors.
• We propose 3D-VField: a sensor-aware adversarial point cloud deformation method based on vector ﬁelds able to increase the generalization of 3D object detec-tors to out-of-domain samples via data augmentation.
• We introduce and publicly release CrashD: a dataset of damaged and rare cars. Extensive experiments on four outdoor and indoor datasets, namely KITTI [13],
Waymo [33], our CrashD, and SUN RGB-D [30], show the wide applicability of our approach. 2.