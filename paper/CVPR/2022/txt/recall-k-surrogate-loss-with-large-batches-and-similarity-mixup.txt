Abstract
This work focuses on learning deep visual representa-tion models for retrieval by exploring the interplay between a new loss function, the batch size, and a new regulariza-tion approach. Direct optimization, by gradient descent, of an evaluation metric, is not possible when it is non-differentiable, which is the case for recall in retrieval. A differentiable surrogate loss for the recall is proposed in this work. Using an implementation that sidesteps the hardware constraints of the GPU memory, the method trains with a very large batch size, which is essential for metrics com-puted on the entire retrieval database. It is assisted by an ef-ficient mixup regularization approach that operates on pair-wise scalar similarities and virtually increases the batch size further. The suggested method achieves state-of-the-art performance in several image retrieval benchmarks when used for deep metric learning. For instance-level recogni-tion, the method outperforms similar approaches that train using an approximation of average precision. 1.

Introduction
Minimization of a loss that is a function of the test-time evaluation metric has shown to be beneficial in deep learn-ing for numerous computer vision and natural language pro-cessing tasks. Examples include intersection-over-union as a loss that boosts performance for object detection [48, 70] and semantic segmentation [37], and structural similar-ity [34], peak signal-to-noise ratio [4] and perceptual [40] as reconstruction losses for image compression that give better results according to the respective evaluation metrics.
Training deep networks via gradient descent on the evaluation metric is not possible when the metric is non-differentiable. Deep learning methods resort to a proxy loss, a differentiable function, as a workaround, which em-pirically leads to a reasonable performance but may not align well with the evaluation metric. Examples exist in ob-ject detection [70], scene text recognition [42, 43], machine translation [3] and image retrieval [6, 41].
Figure 1. A comparison between recall@k and rs@k, the pro-posed differentiable recall@k surrogate. Examples show a query, the ranked database images sorted according to the similarity and the corresponding values for recall@k and rs@k and their depen-dence on similarity score change. Note that the values of recall@k and rs@k are close. Changes to similarity and ranking in some cases may not affect the original recall@k but can affect the surro-gate, with the latter having a more significant impact than the for-mer. Similarity values of all negatives are fixed for ease of under-standing. The similarity values of the positives that were changed in rows 2, 3 and 4 are underlined.
This paper deals with the training of image retrieval posed as deep metric learning and Euclidean search in the learned image embedding space.
It is the task of rank-ing all database examples according to the relevance to a query, which is of vital importance for many applications.
The standard evaluation metrics are precision and recall in the top retrieved results and the mean Average Precision (mAP). These metrics are standard in information retrieval, they reflect the quality of the retrieved results and allow for flexibility to focus either on the few top results or the whole ranked list of examples, respectively. Recall at top-k re-trieved results, denoted by recall@k in the following, is the primary focus of this work.
The problem related to the optimization of non-differentiable evaluation metrics applies to recall@k as well. Estimating the position of positive images in the list of retrieved results and counting how many positives appear inside a short-list of a fixed size involves non-differentiable operations. Note that methods for training on non-differentiable losses, such as actor-critic [3] and learning surrogates [42] are not directly applicable to re-call@k. This is due to the fact that these methods are lim-ited to decomposable functions, where a per-example per-formance measure is available. Such an attempt is made by
Engilberge et al. [13], where an LSTM learns sorting-based metrics, but is not adapted in consequent work due to slow training. As an alternative, deep metric learning approaches for image retrieval often use ranking proxy losses, termed pairwise losses.
In the embedding space, loss functions such as contrastive [18], triplet [53], and margin [69] pull the examples from the same class closer to one another and push the examples from a different class away. These losses are hand-crafted to reflect the objectives of the retrieval task and, consequently, the evaluation metric. The loss value de-pends on the image-to-image similarity for image pairs or triplets and does not take into account the whole ranked list of examples. Changes in the similarity value without any change in the overall ranking alter the loss value indicate that they are not well correlated with ranking [6]. Recent methods focus on optimizing Average Precision (AP) and use a surrogate function as a loss [6, 7, 19, 47, 49]. A surro-gate of an evaluation metric is a function that approximates it in a differentiable manner.
The proposed method attains state-of-the-art results for 4 fine-grained retrieval datasets, namely iNaturalist [61], Ve-hicleID [61], SOP [39] and Cars196 [27], and 2 instance-level retrieval datasets, namely Revisited Oxford and
Paris [45]. This is accomplished by the demonstrated syn-ergy between the three following elements. First, a new loss that is proposed as a surrogate of an established retrieval evaluation metric, namely recall at top k, and is experi-mentally shown to consistently outperform existing com-petitors. A comparison between the evaluation metric and the proposed loss is shown in Figure 1. Second, the use of a very large batch size, in the order of several thousand large resolution images on a single GPU. This is inspired by the instance-level retrieval literature [47] and is introduced for the first time in the context of fine-grained categoriza-tion. In a recent work of verifying prior results in deep met-ric learning for fine-grained categorization [36] the batch-size is considered fixed to a single and small value among a large set of comparisons for different losses; in this work we reach batch-sizes that are two orders of magnitude larger than in the work of Musgrave et al. [36]. The third ele-ments is the proposed mixup regularization technique that is computationally efficient and that virtually enlarges the batch. Its efficiency is obtained by operating on the very last stage of similarity estimation, i.e. scalar similarities are mixed, while its applicability goes beyond the combination with the proposed loss in this work. The proposed loss is used for training widely used ResNet architectures [20] but also recent vision-transformers (ViT) [10]. The superior-ity of this loss compared to existing losses is demonstrated with both architectures, while with ViT-B/16 top results are achieved at lower throughput than with ResNet. 2.