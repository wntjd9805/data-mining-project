Abstract
Real-world image manipulation has achieved fantastic progress in recent years as a result of the exploration and utilization of GAN latent spaces. GAN inversion is the first step in this pipeline, which aims to map the real image to the latent code faithfully. Unfortunately, the majority of existing
GAN inversion methods fail to meet at least one of the three requirements listed below: high reconstruction quality, ed-itability, and fast inference. We present a novel two-phase strategy in this research that fits all requirements at the same time. In the first phase, we train an encoder to map the input image to StyleGAN2 W-space, which was proven to have excellent editability but lower reconstruction quality. In the second phase, we supplement the reconstruction ability in the initial phase by leveraging a series of hypernetworks to recover the missing information during inversion. These two steps complement each other to yield high reconstruc-tion quality thanks to the hypernetwork branch and excellent editability due to the inversion done in the W-space. Our method is entirely encoder-based, resulting in extremely fast inference. Extensive experiments on two challenging datasets demonstrate the superiority of our method. 1 1.

Introduction
Generative adversarial networks (GANs) [13] in modern deep learning have allowed us to synthesize expressively re-alistic images, a trend that has continued to flourish in recent years. GANs can now be trained to generate images of high-resolution [22] with diverse styles [23–25] and apparently fewer artifacts [26]. Moreover, the latent spaces learned by these models also encode a diverse set of interpretable semantics. These semantics provide a tool to manipulate the synthesized images. Therefore, understanding and explor-ing a well-trained GAN model is an important and active research area. Several studies [7, 16, 40, 41, 50] have been conducted to examine the latent spaces learned by GANs, 1Project page: https://di-mi-ta.github.io/HyperInverter
Figure 1. Our end-to-end encoder-based method has more accu-rate reconstruction while having fast inference (toward the bottom left of each plot). As can be seen, our work outperform other encoder-based inversion methods (pSp [37], e4e [44], ReStyle [3]) significantly. Comparing with per-image optimization inversion technique [1], our method is on par of quality but 3000× faster.
Only PTI [38] has reconstruction quality better than our work.
However, PTI requires per-image generator fine-tuning during the inference phase, which took a long time, 1100× longer. which convey a wide range of interpretable semantics.
To apply the semantic directions explored from GAN la-tent space to real-world images, the common-used practice is the ”invert first, edit later” pipeline. GAN Inversion is a typical line of work that aims to first map a real photograph to a latent code of a GAN model so that the model can accu-rately reconstruct the photograph. Then, we can manipulate the latent code to edit different attributes of the reconstructed picture. There are two general approaches to determining a latent code of a GAN model given an input image: by an iterative optimization [1, 10, 21, 25, 32] and by inference with an encoder [35, 37, 44, 58]. The optimization-based method tends to perform reconstruction more accurately than encoder-based one but requires significantly more computa-tion time, hindering use cases for interactive editing.
• A new method for real-world image interpolation that
While the goal of GAN inversion is not only to reconstruct the input image faithfully but also to effectively perform image editing later, there is the so-called reconstruction-editing trade-off raised by multiple previous works [44, 59].
This trade-off is shown to depend on the embedding space where an input image is mapped to. The native StyleGAN
W space and the extended version W + space [1] are two most popular embedding spaces for StyleGAN inversion.
Specifically, inverting an image to W space usually has excellent editability, but they are proved to be infeasible to reconstruct the input image faithfully [1]. On the contrary,
W + space allows to obtain more accurate reconstructions but it surfers from editing ability [44]. To mitigate the effects of this trade-off, a diverse set of methods has been proposed.
Some of them [44, 59] introduce the ways (e.g., regularizer or adversarial training) to select the latent code in the high editable region of W + space and accept a bit of sacrifice in the reconstruction quality. Another option is to utilize a two-stage approach. PIE [43] opts first to use an optimization process to locate the latent code in W space to preserve the editing ability and then optimize further the latent in the
W + space to enhance the reconstruction quality. PTI [38] approaches the same as PIE in the first stage. However, in the second stage, they choose the generator fine-tuning option to improve reconstruction results further. As can be seen, such methods require either optimization or fine-tuning process for each new image, leading to expensive inference time.
Motivated from above weakness, we propose a novel pure encoder-based two-phase method for StyleGAN inversion.
Our method not only runs very fast but also obtains robust reconstruction quality. Specifically, in the first phase, we change to use a standard encoder to regress the image to the latent code in W space instead of utilizing optimization process as PTI and PIE. Then, in the second phase, we lever-age the hypernetworks to predict the residual weights, which can recover the lost details of the input image after the first phase. We then use the residual weights to update the origi-nal generator for synthesizing the final reconstructed image.
Our design would help migrate optimization or fine-tuning procedures in the inference phase, significantly reducing processing time. In summary, our contributions are:
• A completely encoder-based two-phase GAN inversion ap-proach allows faithful reconstruction of real-world images while keeping editability and having fast inference;
• A novel network architecture that consists of a series of hypernetworks to update the weights of a pre-trained Style-GAN generator, thereby improving reconstruction quality;
• An extensive benchmark of GAN inversion that demon-strates the superior performance of our method compared to the existing works; interpolates both latent code and generator weights. 2.