Abstract
We present an approach to learn dense, continuous 2D-3D correspondence distributions over the surface of ob-jects from data with no prior knowledge of visual ambigu-ities like symmetry. We also present a new method for 6D pose estimation of rigid objects using the learnt distribu-tions to sample, score and refine pose hypotheses. The cor-respondence distributions are learnt with a contrastive loss, represented in object-specific latent spaces by an encoder-decoder query model and a small fully connected key model.
Our method is unsupervised with respect to visual ambigu-ities, yet we show that the query- and key models learn to represent accurate multi-modal surface distributions. Our pose estimation method improves the state-of-the-art sig-nificantly on the comprehensive BOP Challenge, trained purely on synthetic data, even compared with methods trained on real data. The project site is at surfemb.github.io. 1.

Introduction
Establishing 2D-3D correspondences is a core problem in computer vision. For an image of an object with no visual ambiguity, a 3D object point can in theory be uniquely iden-tified for a 2D point in the image. However, under visual ambiguities caused by symmetry, occlusion, lighting, etc., there can be a set of possible 3D correspondences. Ideally, we would have not just a best guess, but a full distribution over possible correspondences. To the best of our knowl-edge, we are the first to present such distributions. We learn the distributions implicitly from data with no information about symmetries or other ambiguities.
There is a wide range of pose estimation methods for rigid objects. Many establish 2D-3D correspondences
[12, 21, 25, 26, 28, 31] followed by PnP-RANSAC [9], and mainly differ in how they establish correspondences. Some methods establish correspondences for a fixed set of object keypoints [26, 28] while others establish dense (pixel-wise)
Figure 1. Proposed method for learning 2D-3D correspondence distributions. An image crop is fed through a query model, pro-viding a query image. Visible object coordinates under the ground truth pose are fed through a key model to provide positive keys, and uniformly sampled object points are fed through the same key model to provide negative keys for contrastive learning. correspondences [5, 12, 21, 25, 31]. Regressing coordinates directly [5, 21, 25, 28, 31] assumes a uni-modal distribution, which is problematic in case of visual ambiguities, lead-ing most of them to handle global symmetries explicitly.
This, however, only handles global symmetries, not other kinds of visual ambiguity. A recent approach [12] handles ambiguities implicitly by estimating a probability distribu-tion over surface fragments. This model is able to represent multi-modal distributions, but the representation is limited by the computational cost of representing a large amount of surface fragments. They mitigate this by choosing 64 frag-ments and regressing a within-fragment offset, but this still amounts to 256 output channels per object in their encoder-decoder network, and their representation is effectively re-duced to a discrete probability distribution over 64 refined object coordinates.
Another recent work [23] proposes to establish dense 2D-3D correspondences using continuous surface embed-dings with few output channels. However, they only estab-lish a single correspondence per pixel and do not discuss or show the ability to represent distributions or other ways to handle ambiguities, nor do they use it for object pose esti-mation.
This work presents an approach to learning dense and continuous 2D-3D correspondence distributions with a con-trastive loss. At inference, we evaluate the distributions for approximately 75.000 object coordinates. The correspon-dence distributions are represented by two models: a small fully connected network, the key model, mapping object co-ordinates to key embeddings, and an encoder-decoder con-volutional network, the query model, mapping color images to dense query embedding images. Each query then repre-sents a correspondence distribution over keys, and the two models are trained jointly with a contrastive loss. This rep-resentation enables the models to represent accurate multi-modal correspondence distributions with low computational requirements.
We obtain an initial pose estimate with PnP-RANSAC, where many pose hypotheses are sampled based on the cor-respondence distributions and evaluated using a score based on the training loss. Our models are thus explicitly trained to maximize the score for the correct pose. We further re-fine the best scoring pose hypothesis to obtain our final pose estimate.
We evaluate our method on the seven varied datasets in the BOP Challenge [14]. For ITODD [7], we show a 79% relative improvement over the previous state-of-the-art
RGB method, and for T-LESS [13] and HB [15] our RGB method trained purely on synthetic data is state-of-the-art, even compared with methods trained on real data and meth-ods using depth. Our RGB method shows state-of-the-art results across all seven datasets, compared to other methods trained on synthetic data, and our RGBD method trained on purely synthetic data is state-of-the-art on the BOP Chal-lenge, even compared with methods trained on real data.
Our primary contributions are:
• Presenting continuous 2D-3D correspondence distri-butions that are accurate up to ambiguities like sym-metry.
• A state-of-the-art object pose estimation method us-ing the distributions to sample, score and refine poses, handling symmetries and other ambiguities implicitly.
Interactive examples and all code to reproduce the results in this work is available on the project site. 2.