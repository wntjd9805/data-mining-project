Abstract
We propose Human-centered 4D Scene Capture (HSC4D) to accurately and efficiently create a dynamic digital world, containing large-scale indoor-outdoor scenes, diverse human motions, and rich interactions be-tween humans and environments. Using only body-mounted
IMUs and LiDAR, HSC4D is space-free without any ex-ternal devices’ constraints and map-free without pre-built maps. Considering that IMUs can capture human poses but always drift for long-period use, while LiDAR is stable for global localization but rough for local positions and orien-tations, HSC4D makes both sensors complement each other by a joint optimization and achieves promising results for long-term capture. Relationships between humans and en-vironments are also explored to make their interaction more realistic. To facilitate many down-stream tasks, like AR,
VR, robots, autonomous driving, etc., we propose a dataset containing three large scenes (1k-5k m2) with accurate dynamic human motions and locations. Diverse scenarios
*Corresponding author. (climbing gym, multi-story building, slope, etc.) and challenging human activities (exercising, walking up/down stairs, climbing, etc.) demonstrate the effectiveness and the generalization ability of HSC4D. The dataset and code is available at lidarhumanmotion.net/hsc4d. 1.

Introduction
The development of digital society is overwhelming be-cause it can enrich peoples’ life by serving Augmented Re-ality, Virtual Reality, smart city, robots, autonomous driv-ing, etc. Humans and environments are two main compo-nents for creating the digital world. Current research works always separate dynamic human motions and static envi-ronments. Actually, taking account their interactions can help improve both capture accuracy. It is a trend to directly capture the whole scene with consecutive human activities.
To capture human motions, IMU sensors are widely used and always be mounted on different parts of the human body, like arms, legs, feet, head, etc. It can capture accu-rate short-term motions but suffer from severe drift with the acquisition time increasing. Some methods [6,13,39,47,48] utilize extra external RGB or RGBD cameras as a remedy to improve the accuracy, but result in limited capture space, human activities, and interactions. HPS [9] uses a head-mounted camera, which looks outwards like the human eyes, to complement IMUs in global localization. Without the constraint of external cameras, it can recover the full-body pose and register the human in large 3D scan of real scenes. However, HPS requires pre-built maps and a huge image database for self-localization.
For accurate localization and mapping [51], LiDAR is the most applicable sensor in current days, which is popu-lar for mobile robots and autonomous vehicles. LiDAR is also extensively used for large-scale scene scans. Although there are many LiDAR-captured datasets, including indoor scenes [4, 30] and large-scale outdoor scenes [7, 23], they focus on scene understanding and 3D perception, ignoring accurate human poses. PedX [16] provides 3D poses of pedestrians by using SMPL [22] parameterization for joint locations of instances on third-person-view images, which is not accurate as IMUs. Furthermore, it focuses on traf-fic scenes and is not applicable for generating diverse 3D human motions.
Taking advantage of IMUs-based motion caption and
LiDAR-based localization and scene capture, we propose
Human-centered 4D Scene Capture (HSC4D) to accurately and efficiently create a dynamic digital world with con-secutive human motions in indoor-outdoor scenes. Using only body-mounted sensors, HSC4D is space-free and pose-free, and the interaction between humans and the environ-ment inside is also free, which makes it possible to capture most of the human-involved real-world scenes. Compared with camera-based localization, LiDAR is more precise for global localization, which dramatically reduces the drift of
IMUs, and does not need pre-built maps. IMUs can improve the accuracy of LiDAR-captured local trajectories, where the error is caused by the jitter of the body. Making use of the complement of both sensors, we propose a joint opti-mization to improve the performance of motion estimation and human-scene mapping by considering several physical constraints.
To facilitate further research and down-stream applica-tions, we propose a dataset containing three large scenes (1k-5k m2) with accurate dynamic human motions and lo-cations. As Fig. 1 shows, the dataset contains diverse sce-narios, like climbing gym, multi-story building, slope, etc., and challenging human activities, such as exercising, walk-ing up/down stairs, climbing, etc. Accurate human poses and natural interactions between human and the environ-ment demonstrate the effectiveness and the generalization ability of HSC4D.
Our contributions are summarized as follows:
• Based on body-mounted IMUs and LiDAR, we pro-pose Human-centered 4D Scene Capture (HSC4D) for creating a human-centered dynamic digital world, which is space-free, pose-free, and interaction-free.
• We propose a joint optimization method by integrat-ing LiDAR SLAM results and IMU poses with scene constraints, resulting in natural human motions and ac-curate global localization in large scenes.
• We provide a new dataset containing LiDAR point cloud of large-scale scenes, IMU data of human poses, and the results of poses and mapping by our optimiza-tion, which also demonstrates the effectiveness and the generalization ability of HSC4D. 2.