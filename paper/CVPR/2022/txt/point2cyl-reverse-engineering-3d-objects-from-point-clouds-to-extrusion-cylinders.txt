Abstract 1.

Introduction
We propose Point2Cyl, a supervised network transform-ing a raw 3D point cloud to a set of extrusion cylinders.
Reverse engineering from a raw geometry to a CAD model is an essential task to enable manipulation of the 3D data in shape editing software and thus expand their usages in many downstream applications. Particularly, the form of
CAD models having a sequence of extrusion cylinders — a 2D sketch plus an extrusion axis and range — and their boolean combinations is not only widely used in the CAD community/software but also has great expressivity of shapes, compared to having limited types of primitives (e.g., planes, spheres, and cylinders). In this work, we introduce a neural network that solves the extrusion cylinder decomposition problem in a geometry-grounded way by ﬁrst learning un-derlying geometric proxies. Precisely, our approach ﬁrst predicts per-point segmentation, base/barrel labels and nor-mals, then estimates for the underlying extrusion param-eters in differentiable and closed-form formulations. Our experiments show that our approach demonstrates the best performance on two recent CAD datasets, Fusion Gallery and DeepCAD, and we further showcase our approach on reverse engineering and editing.
Our everyday environments are ﬁlled with objects fabri-cated following a carefully engineered computer-aided de-sign. This makes reverse engineering in the wild a vital workﬂow in situations where copies or variations of a physi-cal object are required, but the corresponding CAD model is not available [51]. This situation often occurs when repair-ing machinery or digitizing objects manufactured in the pre-digital era [11]. To this end, an object is ﬁrst scanned using a 3D sensor producing a point cloud and later decomposed into a set of consistent primitives or surfaces which could be parsed by existing shape modelers such as Fusion360 [3] or
SolidWorks [45]. However, at the user level, a CAD model is designed as a sequence of operations, where the designer
ﬁrst draws a planar 2D sketch as a closed curve and later extrudes it into a 3D solid [55] (cf . Fig. 2). These Extrusion
Cylinders can then be combined through boolean operations.
As this modeling paradigm is hard to summarize using traditional primitives such as planes or cylinders, we set off to ask: how can we reverse engineer point clouds into primi-denotes equal contribution 0
⇤
tives that are interpretable and usable in the modeling pro-cess of CAD designers? Traditional approaches answer this question by following a three-step procedure where (i) the point cloud is ﬁrst converted into a mesh, (ii) subsequently explained by a collection of trimmed parametric surfaces resulting in a watertight solid (a.k.a. boundary representa-tion or B-Rep) [7], and (iii) a CAD program, which could generate the input B-Rep is inferred [56]. Recent trends in
ﬁtting primitives to point clouds [9, 24, 46] can bypass the initial meshing stage, but they either assume a ﬁnite set of
ﬁxed primitives, e.g., planes, cylinders, cones [16, 24, 48] or output a disjoint set of primitives yet to be stitched [8, 33] and thus cannot allow, for example, convenient shape editing or variations. Note that geometric primitives have unique parameterizations and hence cannot be handled by general 3D model detection pipelines like [27, 35]. As such, the presented problem is much ﬁner-grained than explaining a scene with a retrieved set of CAD models, as done in [2, 50].
Finally, both of the problems we address, CAD model re-construction from point sets and user editing of CAD shapes are cast as future work by the recent CAD generative model,
DeepCAD [55].
To be able to achieve a geometry-grounded and editable reconstruction, within a CAD-grammar, we propose to cast the problem as a decomposition task into Extrusion Cylin-ders. Our novel approach views Extrusion Cylinder as a parametric primitive can jointly represent a set of sketch-extrude operations and hence is suitable for representing
CAD models. We learn to decompose a given raw point cloud into Extrusion Cylinder instances. In particular, our neural network learns to predict per-point extrusion instance segmentation, surface normal, and base/barrel membership1.
Given this decomposition, we show how to solve for each primitive’s underlying parameters, including the extrusion axis, center, sketch, sketch scale, and extrusion extent, all in a geometry-grounded way. In return, as shown in Fig. 1, these enable us to reverse engineer the point cloud into an editable 3D CAD model in a format that is directly consum-able by existing CAD modelers [1, 3], allowing for further variation creation, e.g., adding ﬁllets/chamfers, modifying the sketch and varying parameters such as center and extents.
In summary, our contributions are the following: 1. We introduce a novel approach that casts the 3D recon-struction task as a Extrusion Cylinder decomposition problem, making it well-suited for CAD modeling. 2. We architect a neural network that decompose an input point cloud into a set of Extrusion Cylinders by learn-ing geometric proxies, which can then used to estimate the extrusion parameters in differentiable, closed-form formulations. 3. We validate our approach quantitatively and qualitatively on two existing CAD datasets, Fusion Gallery [54] and 1Here, barrel means the cylinder side, the surface swept by the sketch.
Figure 2. Solid model creation as a sequence of sketch-extrude operations. a) Initial sketch. b) Volume extruded from that sketch. c) A second sketch. d) The second sketch is extruded and the boolean union of the two extruded volumes is created. e) A third sketch. f) The ﬁnal sketch extruded and subtracted from the solid.
DeepCAD [55], surpassing baselines, and further show-case its applications on reconstruction and shape editing.
Our project page can be found at point2cyl.github.io. 2.