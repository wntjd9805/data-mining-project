Abstract 1.

Introduction
Transparent and semi-transparent materials pose sig-nificant challenges for existing scene understanding and segmentation algorithms due to their lack of RGB texture which impedes the extraction of meaningful features.
In this work, we exploit that the light-matter interactions on glass materials provide unique intensity-polarization cues for each observed wavelength of light. We present a novel learning-based glass segmentation network that leverages both trichromatic (RGB) intensities as well as trichromatic linear polarization cues from a single photograph captured without making any assumption on the polarization state of the illumination. Our novel network architecture dynami-cally fuses and weights both the trichromatic color and po-larization cues using a novel global-guidance and multi-scale self-attention module, and leverages global cross-domain contextual information to achieve robust segmen-tation. We train and extensively validate our segmenta-tion method on a new large-scale RGB-Polarization dataset (RGBP-Glass), and demonstrate that our method outper-forms state-of-the-art segmentation approaches by a signif-icant margin.
Autonomous robots, aerial drones, and self-driving ve-hicles rely on an array of sophisticated sensors and algo-rithms that enable them to sense and understand their en-vironment. However, objects with transparent or semi-transparent materials remain an open challenge for exist-ing scene understanding methods.
In contrast to opaque materials, transparent materials typically lack texture, and their complex dynamic appearance depends over various lo-cal and global properties, ranging from light-matter interac-tions (i.e., reflection, refraction, and transmission), object shape, and background, resulting in out-of-distribution ob-servations that are difficult to model.
The majority of existing segmentation methods for trans-parent materials leverage either contextual information [27, 41] or rely on boundary detection [11, 40]. Both strategies operate in the RGB domain where the interactions between light waves and transparent materials only produce weak cues. A few works have investigated leveraging richer rep-resentations of light-matter interactions for transparent ma-terial recognition, such as light fields [23, 34, 43] and polar-ization [17,19,20,37,39]. However, these method also rely on strong assumption on the target size and reflectivity, or assume restricted capture conditions.
⋆ Xin Yang (xinyang@dlut.edu.cn) and Xiaopeng Wei are the corre-sponding authors. Xin Yang and Bo Dong lead this project.
In this work, based on that glass materials often pro-vide a distinctive spectral-polarimetric response, we lever-age both trichromatic intensity and trichromatic linear po-larization cues from images captured in-the-wild to infer rich contextual information for robust transparent material segmentation. Linear polarization cues, described by the degree of linear polarization (DoLP) and the angle of po-larization (AoLP), can provide strong cues [17] for trans-parent object segmentation (Figure 1) and can be thought of as intrinsic object textures for transparent materials. How-ever, depending on the view and lighting conditions, these cues might not be equally informative over all three wave-lengths, or even confound valid RGB intensity cues. To address these challenges, we design a Polarization Glass
Segmentation Network, which we dub “PGSNet”, that uti-lizes an Early Dynamic Attention (EDA) module to dynami-cally estimate three global scaling weights for each channel of the trichromatic DoLP and AoLP. The weighted DoLP and AoLP, together with the RGB image features, are fed into a Conformer [31] backbone network to extract robust global and local features. The multi-modal local features are then fused by a Dynamic Multimodal Feature Integra-tion (DMFI) module guided by the global features, and subsequently used by a Global Context Guided Decoder (GCGD).
To train PGSNet, we introduce a large-scale RGB-Polarization dataset, dubbed RGBP-Glass, which contains 4,511 manually annotated RGB intensity images and the corresponding trichromatic (i.e., RGB) AoLP and DoLP images. To ensure diversity, we capture the images in the
RGBP-Glass dataset from different real-world scenes that have significant variations in location, type, shape, color contrast, and light conditions.
We demonstrate the effectiveness of our approach and show the importance of multi-chromatic polarization cues for glass segmentation. Our extensive experiments show that our method significantly outperforms competing meth-ods. We make the following contributions
• the first learning based method to exploit multi-chromatic polarization cues for glass segmentation on photographs taken in-the-wild;
• a novel attention-based glass segmentation network that dynamically fuses RGB and multi-chromatic po-larization cues; and
• a new and unique large-scale RGB-P glass segmenta-tion dataset. 2.