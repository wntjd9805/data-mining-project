Abstract 1.

Introduction
Learning to capture human motion is essential to 3D human pose and shape estimation from monocular video.
However, the existing methods mainly rely on recurrent or convolutional operation to model such temporal informa-tion, which limits the ability to capture non-local context relations of human motion. To address this problem, we propose a motion pose and shape network (MPS-Net) to effectively capture humans in motion to estimate accurate and temporally coherent 3D human pose and shape from a video. Specifically, we first propose a motion continuity at-tention (MoCA) module that leverages visual cues observed from human motion to adaptively recalibrate the range that needs attention in the sequence to better capture the mo-tion continuity dependencies. Then, we develop a hierar-chical attentive feature integration (HAFI) module to effec-tively combine adjacent past and future feature represen-tations to strengthen temporal correlation and refine the feature representation of the current frame. By coupling the MoCA and HAFI modules, the proposed MPS-Net ex-cels in estimating 3D human pose and shape in the video.
Though conceptually simple, our MPS-Net not only outper-forms the state-of-the-art methods on the 3DPW, MPI-INF-3DHP, and Human3.6M benchmark datasets, but also uses fewer network parameters. The video demos can be found at https://mps-net.github.io/MPS-Net/.
*Both authors contributed equally to this work
†Mark Liao is also a Chair Professor of Providence University
Estimating 3D human pose and shape by taking a simple picture/video without relying on sophisticated 3D scanning devices or multi-view stereo algorithms, has important ap-plications in computer graphics, AR/VR, physical therapy and beyond. Generally speaking, the task is to take a single image or video sequence as input and to estimate the pa-rameters of a 3D human mesh model as output. Take, for example, the SMPL model [24]. For each image, it needs to estimate 85 (including pose, shape, and camera) param-eters, which control the 6890 vertices that form the full 3D mesh of a human body [24]. Despite recent progress on 3D human pose and shape estimation, it is still a frontier chal-lenge due to depth ambiguity, limited 3D annotations, and complex motion of non-rigid human body [6, 17, 20, 21].
Different from 3D human pose and shape estimation from a single image [11, 17, 21, 29, 31], estimating it from monocular video is a more complex task [6,8,18,20,25,34].
It needs to not only estimate the pose, shape and camera parameters of each image, but also correlate the continuity of human motion in the sequence. Although existing sin-gle image-based methods can predict a reasonable output from a static image, it is difficult for them to estimate tem-porally coherent and smooth 3D human pose and shape in the video sequence due to the lack of modeling the conti-nuity of human motion in consecutive frames. To solve this problem, several methods have recently been proposed to extend the single image-based methods to the video cases,
poral similarities and dissimilarities of visual representa-tions in the action sequence, thereby revealing the conti-nuity of human motion. Second, NSSM is regarded as the a priori knowledge and applied to guide the learning of the self-attention module, which allows it to adaptively recali-brate the range that needs attention in the sequence to cap-ture the motion continuity dependencies. In the second in-sight, motivated by the temporal feature integration scheme in 3D human mesh estimation [6], we develop a hierarchi-cal attentive feature integration (HAFI) module that utilizes adjacent feature representations observed from past and fu-ture frames to strengthen temporal correlation and refine the feature representation of the current frame. By coupling the
MoCA and HAFI modules, our MPS-Net can effectively capture humans in motion to estimate accurate and tempo-rally coherent 3D human pose and shape from monocular video (see Figure 1). We characterize the main contribu-tions of our MPS-Net as follows:
• We propose a MoCA module that leverages visual cues observed from human motion to adaptively recalibrate the range that needs attention in the sequence to better capture the motion continuity dependencies.
• We develop a HAFI module that effectively combines adjacent past and future feature representations in a hierarchical attentive integration manner to strengthen temporal correlation and refine the feature representa-tion of the current frame.
• Extensive experiments on three standard benchmark datasets demonstrate that our MPS-Net achieves the state-of-the-art performance against existing methods and uses fewer network parameters. 2.