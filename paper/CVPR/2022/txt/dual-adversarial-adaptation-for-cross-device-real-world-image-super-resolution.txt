Abstract
Due to the sophisticated imaging process, an identical scene captured by different cameras could exhibit distinct imaging patterns, introducing distinct proficiency among the super-resolution (SR) models trained on images from different devices. In this paper, we investigate a novel and practical task coded cross-device SR, which strives to adapt a real-world SR model trained on the paired images cap-tured by one camera to low-resolution (LR) images captured by arbitrary target devices. The proposed task is highly challenging due to the absence of paired data from vari-ous imaging devices. To address this issue, we propose an unsupervised domain adaptation mechanism for real-world
SR, named Dual ADversarial Adaptation (DADA), which only requires LR images in the target domain with avail-able real paired data from a source camera. DADA em-ploys the Domain-Invariant Attention (DIA) module to es-tablish the basis of target model training even without HR supervision. Furthermore, the dual framework of DADA fa-cilitates an Inter-domain Adversarial Adaptation (InterAA) in one branch for two LR input images from two domains, and an Intra-domain Adversarial Adaptation (IntraAA) in two branches for an LR input image.
InterAA and In-traAA together improve the model transferability from the source domain to the target. We empirically conduct ex-periments under six Real→Real adaptation settings among three different cameras, and achieve superior performance compared with existing state-of-the-art approaches. We also evaluate the proposed DADA to address the adapta-tion to the video camera, which presents a promising re-search topic to promote the wide applications of real-world super-resolution. Our source code is publicly available at https://github.com/lonelyhope/DADA. 1.

Introduction
Figure 1. Comparison of real SR results across different trained models from different camera data in the DRealSR dataset [18].
The Difference Map denotes the absolute difference between ground-truth HR and SR image (The brightness in the map reflects the magnitude of the difference).
Figure 2. Degradation kernels for bicubic down-sampling and three different cameras in DRealSR [18]. USRNet [22] is em-ployed to estimate those kernels by minimizing ∥(HR ⊗ k) ↓s
−LR∥, where ⊗ means convolution, and ↓s means down-sampling for scaling factor s by choosing the upper left item for every s ∗ s grid. The kernel size is set to 25 ∗ 25 and the scaling factor s is 4.
Single image super-resolution (SISR), which super-resolves low-resolution images (LRs) and reconstructs their
*Corresponding author: weipx3@mail.sysu.edu.cn high-resolution counterparts (HRs), is a fundamental task in low-level computer vision. The emergence of deep learning significantly contributes to the SR progress and SISR is usu-ally cast as a supervised learning task with paired LR-HR
ences from ground truth HR image. To explain this phe-nomenon, degradation kernels for different (camera) degra-dations are analyzed in Fig.2. Real image degradation kernels are different across different cameras. We regard device-specific degradation gap as domain gap in this work and also empirically demonstrate its consequence of the performance degradation in cross-device/domain setting in
Fig. 3. However, this domain gap is ubiquitous for many realistic applications, e.g., image/video enhancement for all kinds of phones or GoPro cameras, and classic old movie restoration. Usually, it is extremely labor-intensive and dif-ficult to collect paired data for each camera, and even is impossible to obtain paired data, e.g., classic old movies.
To mitigate this issue, we are the first to explore Unsu-pervised Domain Adaptation (UDA) for Real-World Image
Super-Resolution across Devices. Under this setting, given paired real LR-HR images captured by one camera (source camera/domain), the goal is to adapt the model to the tar-get domain that has only LR images captured by another camera (Real → Real adaptation). This is more rational than conventional UDA SR from source domain with paired synthesized LR-HR images to target domain with real im-ages (Synthetic → Real adaptation). As shown in Fig. 2, synthetic degradation (e.g., widely-used bicubic downsam-pling) is engaged with simple kernels; realistic degradation is heterogeneous and more complex. The complexity of real kernels brings challenges to the Real → Real adaptation task. Due to the significant distinction between synthetic and real degradation, it is certainly difficult to coordinate a source model of synthetic degradation to a target domain with realistic data, and has an inferior performance in the target domain. This is evidenced in Fig. 4. Overall, our
UDA SR across devices, namely Real → Real adaptation, is more practical for realistic applications.
In this paper, we propose a Dual ADversarial Adap-tation model (DADA) to explore unsupervised domain adaptation for real-world image super-resolution across devices. Rooted in the Component Divide-and-Conquer model (CDC) [18], DADA has a source branch and a target branch in a symmetric architecture and each branch is es-sentially a cycle image reconstruction with an up-sampling module and a down-sampling module. DADA employs the
Domain-Invariant Attention (DIA) module to provide com-ponent guidance masks for up-sampling modules in two branches for each input. Additionally, the dual framework of DADA facilitates an Inter-domain Adversarial Adapta-tion (InterAA) in one branch for two LR input images from two domains, and an Intra-domain Adversarial Adaptation (IntraAA) in two branches for an LR input image.
In-terAA and IntraAA together improve the model transfer-ability from the source domain to the target.
In summary, our main contributions are three-fold:
• We are devoted to the early attempt to explore the
Figure 3. Cross-device evaluation of real SR models trained from images of individual cameras. We use models trained on the data collected by different cameras to test the images taken by a specific camera.
Figure 4. SR result comparison between synthetic to real adapta-tion and real to real adaptation (Sony → Panasonic). images [3,7,8,16,24]. However, due to the difficulty of col-lecting LR-HR image pairs, typical learning-based methods learn to map synthetic low-resolution images to the origi-nal counterpart to achieve super-resolution reconstruction, which is constantly criticized with poor model generaliza-tion in practical scenarios. Accordingly, real SR has come up to explore the real image degradation and several real-world SR datasets collected by capturing paired LR-HR data via optical zoom of DSLR cameras emerged imme-diately, e.g., RealSR [1] and DRealSR [18]. Considering the vulnerability of deep networks for quasi-imperceptible noises, robust real-world SR is further investigated to de-fense the adversarial attacks for practical applications [21].
In comparison with synthetic image degradation, real-world SR exhibits a crucial challenge, i.e., diverse degra-dation processes among devices, due to different imaging processes across devices, especially across different cam-era types. The cross-device domain gap is demonstrated in Fig. 1.
It is observed that in cross-device real SR model evaluation (Sony→Panasonic, or Panasonic→Sony), it presents a distinct device-specific degradation gap: com-pared with that trained on Panasonic (Sony) images, an SR model trained only on Sony (Panasonic) images (i.e., Sony (Panasonic) model) super-resolve an LR image, captured by
Panasonic (Sony) camera, into an SR image that has more blurry details or even distorted artifacts and larger differ-cross-device domain gap in real-world image super-resolution. To mitigate this issue, a Dual ADversarial
Adaptation model (DADA) is proposed for unsuper-vised domain adaptation from the source domain with paired real data to the target with only real LR images.
• We propose the Inter-domain adversarial Adaptation (InterAA) and the Intra-domain adversarial Adaptation (IntraAA) to train the model in a dual architecture for unsupervised Real to Real SR adaptation.
• Extensive experiments on six Real to Real adaptation settings among three different camera domains demon-strate the superiority of our DADA over traditional SR methods on real-world image super-resolution when adapting the model across different cameras. 2.