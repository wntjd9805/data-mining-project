Abstract
Recently, learned image compression techniques have achieved remarkable performance, even surpassing the best manually designed lossy image coders. They are promis-ing to be large-scale adopted. For the sake of practical-ity, a thorough investigation of the architecture design of learned image compression, regarding both compression performance and running speed, is essential.
In this pa-per, we first propose uneven channel-conditional adaptive coding, motivated by the observation of energy compaction in learned image compression. Combining the proposed uneven grouping model with existing context models, we obtain a spatial-channel contextual adaptive model to im-prove the coding performance without damage to running speed. Then we study the structure of the main transform and propose an efficient model, ELIC, to achieve state-of-the-art speed and compression ability. With superior per-formance, the proposed model also supports extremely fast preview decoding and progressive decoding, which makes the coming application of learning-based image compres-sion more promising. 1.

Introduction
In the past years, lossy image compression based on deep learning develops rapidly [4, 5, 15, 20, 22, 24, 29, 39, 40, 49, 50]. They have achieved remarkable progress on improv-ing the rate-distortion performance, with usually much bet-ter MS-SSIM [47] than conventional image formats like
JPEG [26] and BPG [8], which indicates better subjec-tive quality. Some very recent works [18–20, 22, 49, 50] even outperform the still image coding of VVC [2], one of the best hand-crafted image and video coding standards at present, on both PSNR and MS-SSIM. These results are en-*Equal contribution.
†Corresponding author. This work is done when Ziming Yang, Weikun
Peng and Rui Ma are interns at SenseTime Research.
Figure 1. Rate-speed comparison on Kodak. Left-top is better. couraging, as learned image compression has been proved as a strong candidate for next generation image compres-sion techniques. In the near future, it is quite possible to deploy this line of image compression models in industrial applications. Yet, to make these approaches practical, we must carefully assess the running speed, especially the de-coding speed of learned image compression.
One of the most important techniques in learned im-age compression is the joint backward-and-forward adap-tive entropy modeling [15,20,22,29,39,40,48–50]. It helps convert the marginal probability model of coding-symbols to a joint model by introducing extra latent variables as prior [5, 39, 40], leading to less redundancy and lower bit-rate. However, the backward-adaptive models along spa-tial dimension significantly break the parallelism, which in-evitably slows down the decoding. To address the issue,
He et al. [24] proposes to adopt checkerboard convolution as a parallel replacement to the serial autoregressive context model, which has a much better degree of parallelism with constant complexity. Minnen et al. [40] proposes to adopt a context model along channel dimension instead of the serial-decoded spatial ones, which also improves the par-allelism. However, to achieve a non-trivial bit-saving with this channel-conditional model, the symbols are divided to
10 groups and coded progressively, which still slows down the overall inference.
It is promising to delve into paral-lel multi-dimension contextual adaptive coding by combing these two models to achieve better coding ability [24], con-stituting one of the motivation of our work. In this paper, we investigate an uneven grouping scheme to speed up the channel-conditional method, and further combine it with a parallel spatial context model, to promote RD performance while keeping a fast running speed.
More and more complex transform networks also slow down the inference. As learned image compression is for-mulated as a sort of nonlinear transform coding [3, 21], an-other plot improving coding performance is the develop-ment of main transform. Prior works introduce larger net-works [15, 20, 22, 32], attention modules [15, 22, 33, 35] or invertible structures [37, 50] to main analysis and synthe-sis networks. These heavy structures significantly improve the RD performance but hurt the speed. We notice that, with a relative strong and fast adaptive entropy estimation (i.e. the above mentioned adaptive coding approaches with hyperprior and context model), we can re-balance the com-putation between main transform and entropy estimation, to obtain low-latency compression models. This further moti-vates us to promote the contextual modeling technique.
Learned image compression is growing mature and tends to be widely used, but its lack of efficiency is still a critical issue. In this paper, we contribute to this field from follow-ing perspectives:
• We introduce information compaction property as an inductive bias to promote the expensive channel-conditional backward-adaptive entropy model. Com-bining it with the spatial context model, we propose a multi-dimension entropy estimation model named
Space-Channel ConTeXt (SCCTX) model, which is fast and effective on reducing the bit-rate.
• With the proposed SCCTX model, we further pro-pose ELIC model. The model adopts stacked residual blocks as nonlinear transform, instead of GDN lay-ers [4].
It surpasses VVC on both PSNR and MS-SSIM, achieving state-of-the-art performance regard-ing coding performance and running speed (Figure 1 and Table 2).
• We propose an efficient approach to generate preview images from the compressed representation. To our knowledge, this is the first literature addressing the very-fast preview issue of learned image compression. 2.