Abstract
The recently proposed camouflaged object detection (COD) attempts to segment objects that are visually blended into their surroundings, which is extremely complex and dif-ficult in real-world scenarios. Apart from high intrinsic similarity between the camouflaged objects and their back-ground, the objects are usually diverse in scale, fuzzy in appearance, and even severely occluded. To deal with these problems, we propose a mixed-scale triplet network, Zoom-Net, which mimics the behavior of humans when observing vague images, i.e., zooming in and out. Specifically, our
ZoomNet employs the zoom strategy to learn the discrim-inative mixed-scale semantics by the designed scale inte-gration unit and hierarchical mixed-scale unit, which fully explores imperceptible clues between the candidate objects and background surroundings. Moreover, considering the uncertainty and ambiguity derived from indistinguishable textures, we construct a simple yet effective regularization constraint, uncertainty-aware loss, to promote the model to accurately produce predictions with higher confidence in candidate regions. Without bells and whistles, our pro-posed highly task-friendly model consistently surpasses the existing 23 state-of-the-art methods on four public datasets.
Besides, the superior performance over the recent cutting-edge models on the SOD task also verifies the effectiveness and generality of our model. The code will be available at https://github.com/lartpang/ZoomNet. 1.

Introduction
Camouflaged objects are often “seamlessly” integrated into the environment by changing their appearance, col-oration or pattern to avoid detection, such as chameleons, cuttlefishes and flatfishes. This is mainly due to their self-protection mechanism in the harsh living environment.
†These authors contributed equally to this work.
*Corresponding author.
Figure 1. Illustration of ZoomNet. Based on zoom strategy, our model distills the differentiated features at different “zoom” scales.
Then we design SIUs to screen and aggregate scale-specific fea-tures, and HMUs to reorganize and enhance mixed-scale features.
Under the supervision of BCEL and the proposed UAL, the model produces the accurate and reliable camouflaged object prediction.
Note that BCEL is computed based on ground truth while UAL is not. f : feature map; A: attention map. LastCBR: the last “Conv-l/m/s: Different input
BN-ReLU” layer before the prediction. scales. The whiter region denotes the larger activation response.
Broadly speaking, camouflaged objects also refer to the objects that are extremely small in size, highly similar to the background, or heavily obscured. They subtly hide themselves in the surroundings, making them difficult to be found, e.g., soldiers wearing camouflaged uniforms and lions hiding in the grass. Camouflaged object detection (COD) is far more complex and challenging than tradi-tional salient object detection or other object segmenta-tion. Recently, it has attracted ever-growing research in-terest from the computer vision community and facilitates many valuable real-life applications, such as search and res-cue [6], species discovery [36], and medical image analy-sis [8, 9, 12, 18, 55].
Recently, numerous deep learning-based methods have been proposed and achieved significant progress. Neverthe-less, they are still struggled to accurately and reliably detect camouflaged objects, due to visual insignificance of cam-ouflaged objects, and high diversity in scale, appearance
and occlusion. By observing our experiments, it is found that the current COD detectors are susceptible to distrac-tors from background surroundings. Thus it is difficult to excavate discriminative and subtle semantic cues for cam-ouflaged objects, resulting in the inability to clearly seg-ment the camouflaged objects from the chaotic background and the predictions of some uncertain (low-confidence) re-gions. Taking these into mind, in this paper, we summa-rize the COD issue into two aspects: 1) How to accurately locate camouflaged objects under conditions of inconspicu-ous appearance and various scales? 2) How to suppress the obvious interference from the background and infer cam-ouflaged objects more reliably? Intuitively, to accurately find the vague or camouflaged objects in the scene, humans may try to refer to and compare the changes in the shape or appearance at different scales by zooming in and out (re-scaling) the image. This specific behavior pattern of hu-man beings motivates us to identify camouflaged objects by mimicking the zooming in and out strategy.
With this inspiration, in this paper, we propose a mixed-scale triplet network, ZoomNet, which significantly im-proves the existing camouflaged object detection perfor-mance. Firstly, for accurate object location, we employ scale space theory [23, 24, 43] to imitate zooming in and out strategy. Specifically, we design two key modules, i.e., the scale integration unit (SIU) and the hierarchical mixed-scale unit (HMU). As shown in Fig. 1, our model extracts differentiated camouflaged object features at differ-ent “zoom” scales using the triplet architecture, then adopts
SIUs to screen and aggregate scale-specific features, and utilizes HMUs to further reorganize and enhance mixed-scale features. Thus, our model is able to mine the accu-rate and subtle semantic clues between objects and back-ground under the mixed scales, and produce accurate pre-dictions. Besides, we use the shared weight strategy, which achieves a good balance of efficiency and effectiveness.
Secondly, it is related to reliable prediction in complex sce-narios. Although the object is accurately located, the indis-tinguishable texture and background will easily bring neg-ative effects to the model learning, e.g. predicting uncer-tain/ambiguity regions, which greatly reduces the detection performance and cannot be ignored. This can be seen in
Fig. 6 (Row 3 and 4) and Fig. 1 in the supp. To this end, we design an uncertainty-aware loss (UAL) to guide the model training, which is only based on the prior knowledge that a good COD prediction should have a clear polarization trend.
Its GT-independent characteristic makes it suitable for en-hancing the GT-based BCE loss. This targeted enhancement strategy can force the network to optimize the prediction of the uncertain regions during the training process, enabling our ZoomNet to distinguish the uncertain regions and seg-ment the camouflaged objects reliably.
Our contributions can be summarized as follows: 1)
For the COD task, we propose a mixed-scale triplet net-work, ZoomNet, which can credibly capture the objects in complex scenes by characterizing and unifying the scale-specific appearance features at different “zoom” scales and 2) To obtain the the purposeful optimization strategy. discriminative feature representation of camouflaged ob-jects, we design SIUs and HMUs to distill, aggregate and strengthen the scale-specific and subtle semantic represen-tation for accurate COD. 3) We propose a simple yet ef-fective optimization enhancement strategy, UAL, which can significantly suppress the uncertainty and interference from the background without increasing extra parameters. 4) Our model greatly surpasses recent 23 state-of-the-art methods under seven metrics on four COD datasets. Furthermore, it shows good generalization in the SOD task and the superior performance compared with the existing SOD methods. 2.