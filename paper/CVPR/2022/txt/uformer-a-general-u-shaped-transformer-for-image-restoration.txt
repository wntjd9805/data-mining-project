Abstract
In this paper, we present Uformer, an effective and efﬁ-cient Transformer-based architecture for image restoration, in which we build a hierarchical encoder-decoder network
In Uformer, there are two using the Transformer block. core designs. First, we introduce a novel locally-enhanced window (LeWin) Transformer block, which performs non-overlapping window-based self-attention instead of global self-attention.
It signiﬁcantly reduces the computational complexity on high resolution feature map while capturing local context. Second, we propose a learnable multi-scale restoration modulator in the form of a multi-scale spatial bias to adjust features in multiple layers of the Uformer decoder. Our modulator demonstrates superior capabil-ity for restoring details for various image restoration tasks while introducing marginal extra parameters and compu-tational cost. Powered by these two designs, Uformer en-joys a high capability for capturing both local and global dependencies for image restoration. To evaluate our ap-proach, extensive experiments are conducted on several im-age restoration tasks, including image denoising, motion deblurring, defocus deblurring and deraining. Without bells and whistles, our Uformer achieves superior or compara-ble performance compared with the state-of-the-art algo-rithms. The code and models are available at https:
//github.com/ZhendongWang6/Uformer. 1.

Introduction
With the rapid development of consumer and industry cameras and smartphones, the requirements of removing undesired degradation (e.g., noise, blur, rain, and so on) in images are constantly growing. Recovering genuine images from their degraded versions, i.e., image restoration, is a classic task in computer vision. Recent state-of-the-art meth-ods [9, 47, 74, 76, 77] are mostly ConvNets-based, which achieve impressive results but show a limitation in capturing
∗Part of this work was done during an internship in Huawei Noah’s Ark
Lab.
†Corresponding author.
Figure 1. PSNR vs. computational cost on the SIDD dataset [1]. long-range dependencies. To address this problem, several recent works [31, 39, 83] start to employ single or few self-attention layers in low resolution feature maps due to the self-attention computational complexity being quadratic to the feature map size.
In this paper, we aim to leverage the capability of self-attention in feature maps at multi-scale resolutions to recover more image details. To this end, we present Uformer, an effective and efﬁcient Transformer-based structure for image restoration. Uformer is built upon an elegant architecture
UNet [49], wher we modify the convolution layers to Trans-former blocks while keeping the same overall hierarchical encoder-decoder structure and the skip-connections.
We propose two core designs to make Uformer suitable for image restoration tasks. First, we propose the Locally-enhanced Window (LeWin) Transformer block, which is an efﬁcient and effective basic component. The LeWin Trans-former block performs non-overlapping window-based self-attention instead of global self-attention, which signiﬁcantly reduces the computational complexity on high resolution fea-ture maps. Since we build hierarchical feature maps and keep the window size unchanged, the window-based self-attention at low resolution is able to capture much more global de-pendencies. On the other hand, local context is essential for image restoration, we further introduce a depth-wise con-volutional layer between two fully-connected layers of the feed-forward network in the Transformer block to better cap-ture local context. We also notice that recent works [35, 72]
use the similar design for different tasks.
Second, we propose a learnable multi-scale restoration modulator to handle various image degradations. The mod-ulator is formulated as a multi-scale spatial bias to adjust features in multiple layers of the Uformer decoder. Speciﬁ-cally, a learnable window-based tensor is added to features in each LeWin Transformer block to adapt the features for restoring more details. Beneﬁting from the simple operator and window-based mechanism, it can be ﬂexibly applied for various image restoration tasks in different frameworks.
Based on the above two designs, without bells and whis-tles, e.g., the multi-stage or multi-scale framework [77, 78] and the advanced loss function [28, 29], our simple U-shaped Transformer structure achieves state-of-the-art per-formance on multiple image restoration tasks. For de-noising, Uformer outperforms the previous state-of-the-art method (NBNet [9]) by 0.14 dB and 0.09 dB on the
SIDD [1] and DND [46] benchmarks, respectively. For the motion blur removal task, Uformer achieves the best (Go-Pro [45], RealBlur-R [48], and RealBlur-J [48]) or compet-itive (HIDE [52]) performance, displaying its strong capa-bility of deblurring. Uformer also shows the potential on the defocus deblurring task [3] and outperforms the previous best model [54] by 1.04 dB. Also, on the SPAD dataset [61] for deraining, it obtains 47.84 dB on PSNR, an improvement of 3.74 dB over the previous state-of-the-art method [47]. We expect our work will encourage further research to explore
Transformer-based architectures for image restoration.
Overall, we summarize the contributions of this paper as follows:
• We present Uformer, a general and superior U-shaped Transformer for various image restoration tasks.
Uformer is built on the basic LeWin Transformer block that is both efﬁcient and effective.
• We present an extra light-weight learnable multi-scale restoration modulator to adjust on multi-scale features.
This simple design signiﬁcantly improves the restora-tion quality.
• Extensive experiments show that Uformer establishes new state-of-the-arts on various datasets for image restoration tasks. 2.