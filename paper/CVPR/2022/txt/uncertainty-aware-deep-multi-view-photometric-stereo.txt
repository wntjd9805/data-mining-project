Abstract
This paper presents a simple and effective solution to the longstanding classical multi-view photometric stereo (MVPS) problem. It is well-known that photometric stereo (PS) is excellent at recovering high-frequency surface de-tails, whereas multi-view stereo (MVS) can help remove the low-frequency distortion due to PS and retain the global ge-ometry of the shape. This paper proposes an approach that can effectively utilize such complementary strengths of PS and MVS. Our key idea is to combine them suitably while considering the per-pixel uncertainty of their estimates. To this end, we estimate per-pixel surface normals and depth using an uncertainty-aware deep-PS network and deep-MVS network, respectively. Uncertainty modeling helps se-lect reliable surface normal and depth estimates at each pixel which then act as a true representative of the dense surface geometry. At each pixel, our approach either se-lects or discards deep-PS and deep-MVS network predic-tion depending on the prediction uncertainty measure. For dense, detailed, and precise inference of the object’s surface profile, we propose to learn the implicit neural shape repre-sentation via a multilayer perceptron (MLP). Our approach encourages the MLP to converge to a natural zero-level set surface using the confident prediction from deep-PS and deep-MVS networks, providing superior dense surface re-construction. Extensive experiments on the DiLiGenT-MV benchmark dataset show that our method provides high-quality shape recovery with a much lower memory footprint while outperforming almost all of the existing approaches. 1.

Introduction
In the coming decade, dense 3D data acquisition of ob-jects is likely to become one of the most important problems in computer vision and industrial machine vision. More-over, it can be helpful for a wide range of other cutting-edge scientific disciplines such as metrology [12], geometry pro-cessing [4], forensics [44], etc. At present, it is widely ac-cepted that methods such as structure-from-motion [21,55],
*Corresponding Author (k.sur46@gmail.com) multi-view stereo [12], photometric stereo [30, 54, 61], and other standalone approaches [34,35,43,47,60] are not suffi-cient on their own to provide detailed and precise 3D recon-struction for all kinds of surfaces [44]. Therefore, methods that combine complementary surface estimates by leverag-ing more than one modality are often preferred [36, 46].
Among the passive 3D shape acquisition methods, multi-view stereo (MVS) has become the most popular approach
[13, 55, 62], especially after the proliferation of cheap digi-tal cameras for high-quality imaging. Yet, MVS works best for Lambertian textured surfaces and gives unreliable re-sults for non-textured objects with non-Lambertian surface reflectance property. Moreover, high-frequency surface de-tails such as indentations and scratches are difficult to re-cover using MVS methods (see Fig.1(a)).
On the other hand, photometric stereo (PS) is mag-nificent at recovering high-frequency surface details using light-varying images [61].
It is also effective for non-textured, and non-Lambertian surfaces [6]. PS allows the recovery of per-pixel depth of the object by integration of the estimated surface normals [24]. However, PS suffers from the main shortcoming: The recovered surface profile is globally deformed by a low-frequency distortion [46]. Such distortion is likely due to numerical integration of the sur-face normal map without explicit constraints between mul-tiple disconnected regions of the object’s surface [46,52,64] or non-directional lighting effects (see Fig.1(b)).
Combining the complementary responses of MVS and
PS is known as multi-view photometric stereo (MVPS)
[22]. In this paper, we propose an approach that can effec-tively exploit such complementary surface information. Our work leverages recent advances in deep neural networks. To this end, we use a PatchMatch-based deep-MVS network
[59] to infer the per-pixel depth and a CNN-based deep-PS network [27] to infer per-pixel surface normal. But, we know that such deep network models have their accuracy limits and can predict erroneous depth or surface normals in certain parts of the object.
In that case, if we naively combine the output predicted by these networks, we may end up having a bad overall result. To resolve this, we ex-tend the deep-PS and deep-MVS networks with per-pixel uncertainty estimation capability. Using the prediction un-certainty as a measure, we select and combine only reliable
(a) Multi-View Stereo (MVS) Reconstruction (b) Photometric Stereo (PS) Reconstruction (c) Our Approach
Figure 1. Our method handles the high and low-frequency surface components quite well. It overcomes the high and low-frequency surface reconstruction problem by suitably utilizing the complementary surface estimates via uncertainty modeling, and neural level set optimization (a) MVS reconstruction preserves the plane geometry but loses the finer details. (b) PS captures the fine geometric details but introduces global distortion. (c) Our approach. surface estimates at each pixel, that is either deep-PS nor-mal, deep-MVS depth, both, or none of the prediction.
Using our approach of selecting and discarding surface estimates may result in the loss of some pixels’ correspond-ing 3D surface details. To recover those lost geometric details, we introduce a neural network (MLP layers only) based optimization to recover the overall dense shape from those selected surface predictions by representing the ob-ject’s shape as level sets of the neural network. Our overall loss function optimization encourages the zero-level set of the neural network to converge to the confident surface es-timates. To that end, we first convert the depth estimate to point cloud while keeping the predicted surface normals representation as it is. Our approach then optimizes for parameters of an MLP so that it approximates a signed-distance-function (SDF) to a plausible surface based on the point cloud, surface normals, and an implicit geometric reg-ularization term developed on the Eikonal partial differen-tial equation [8]. Fig.1(c) shows an example reconstruction using our approach. In summary, we make the following contributions:
• We present an effective and easy-to-use deep neural network-based solution to the classical MVPS problem for dense, detailed, and precise recovery of 3D shapes.
• We introduce uncertainty-aware deep-PS and deep-MVS modeling in the MVPS pipeline. Modeling uncertainty helps as a measure in automatic discarding of unreliable surface estimates at a pixel, hence improving robustness.
• We propose an implicit neural shape representation based on the Eikonal term in the MLP loss for natural zero level set surface recovery [8].
It reliably infers the object’s dense surface geometry defined by the confident deep-PS and deep-MVS prediction with better memory foot-print than the methods based on mesh processing [36, 49]. 2.