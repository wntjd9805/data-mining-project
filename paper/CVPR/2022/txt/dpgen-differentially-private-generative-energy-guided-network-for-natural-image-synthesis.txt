Abstract
Despite an increased demand for valuable data, the pri-vacy concerns associated with sensitive datasets present a barrier to data sharing. One may use differentially private generative models to generate synthetic data. Unfortunately, generators are typically restricted to generating images of low-resolutions due to the limitation of noisy gradients. Here, we propose DPGEN, a network model designed to synthe-size high-resolution natural images while satisfying differ-ential privacy. In particular, we propose an energy-guided network trained on sanitized data to indicate the direction of the true data distribution via Langevin Markov chain Monte
Carlo (MCMC) sampling method. In contrast to the state-of-the-art methods that can process only low-resolution images (e.g., MNIST and Fashion-MNIST), DPGEN can generate differentially private synthetic images with resolutions up to 128 × 128 with superior visual quality and data utility. Our code is available at https://github.com/chiamuyu/DPGEN 1.

Introduction
Image synthesis (e.g., through generative adversarial net-works (GANs) [16]) with differential privacy (DP) [12] can be a solution to enable data release without compromis-ing privacy. For example, differentially private GANs (DP-GANs) [6, 47] are generally trained using differentially pri-vate stochastic gradient descent (DPSGD) [1] that perturbs the gradients in each iteration and provides an alternative to direct data release. In particular, generators from DPGANs can be made public; users can then generate synthetic data for their downstream tasks. Nevertheless, GANs have been known to be considerably difﬁcult to train [18, 37, 44]. The situation becomes even worse when noise is introduced in
DPSGD. Hence, generators are typically restricted to gen-erating images of resolutions as low as 32 × 32, and are unsuitable for practical applications of image synthesis.
Difﬁculty in Generating High-Resolution Images from DPGAN. The gradient instability caused by inter-active training from the minimax optimization of GANs is a major concern in the synthesis of high-resolution im-ages [14, 24, 25, 26]. Nonetheless, despite various difﬁcul-ties in the training of GANs, currently GANs can generate photo-realistic image of resolutions up to 1024×1024. Thus, a straightforward design of DPGANs would be applying DP to the state-of-the-art (SOTA) GANs. However, because of the increased batch size and model complexity, such a naïve combination and therefore the use of DPSGD lead to four se-rious problems. 1) Training Inefﬁciency: Although larger batch sizes improve training stability, they also lead to a sig-niﬁcant degradation in training efﬁciency (10× slower) [7] due to the per-sample gradient modiﬁcation, which requires backpropagation be performed on each example in a training batch. 2) Difﬁculty in Tuning Hyperparameters: Due to the complexity of neural network (NN) architectures (e.g., skip connection and attention layers), accurate estimation of global sensitivity is infeasible. This implies the occurrence of either information loss or an excessive noise scale during gradient clipping in DPSGD. 3) Large Noise Magnitude:
The increased number of dimensions required by layers in
NNs to accommodate high-resolution data leads to a catas-trophic amount of noise. 4) The Damage of Visual Quality from Direction of Noisy Gradient: Despite the perceptual loss used in the backpropagation, the noisy gradient affected by the DP noise may dramatically deviate from the direc-tion supposed to move forward, resulting in a synthesis of perceptually awful images.
In summary, when DPSGD is applied to train GANs, the techniques used by GANs for high-resolution image synthesis instead amplify the drawbacks of DPSGD.
Key Insights. The synthesis of perceptually realistic images in a DP manner is very challenging. Notably, our result is in possession of the following novelty.
From the perspective of gradient updates in the param-eter space, DP noise in DPSGD completely destroys the gradients; this severely degrades the training stability. To tackle the aforementioned problems 1)∼4) simultaneously, we abandon DPSGD and take a fundamentally different ap-proach. We instead use a sampling method on the training data. More speciﬁcally, we discretize the movement direc-tions (in terms of MCMC described later) and randomize the
true directions (toward perceptually realistic images) through a ﬁxed number of carefully chosen images in a pixel space where perceptually realistic images can be easily deﬁned to maximize training stability while preserving DP. In this way, we are guaranteed to generate perceptually realistic images and at the same time have the features preserved.
Overview of Proposed Method. Here, we propose a framework using the Markov chain Monte Carlo (MCMC) sampling method [55] to synthesize images, wherein the movement directions are guided by an energy-based network.
Note that as drawing random samples takes considerable time, sampling methods such as Langevin MCMC [17, 43] or
Hamiltonian Monte Carlo [11, 39] are often used to increase efﬁciency. To enable the above framework to satisfy DP, we propose a Differentially Private Generative Energy-guided
Network (DPGEN) architecture for high-resolution image synthesis. In particular, an energy-guided network trained from DP-sanitized data helps indicate routes to sampling perceptually realistic images with high utility.
In general, DPGEN aims to privatize Langevin MCMC.
The process ﬂow of DPGEN is illustrated in Figure 1. More speciﬁcally, we privatize training images such that the san-itized data can be used to train an energy-guided network involved in the Langevin MCMC sampler. Note that all im-ages in the sanitized dataset are visibly degraded by noise, but preserves the information about the directions of the training images. As a result, the energy-guided network trained on the sanitized dataset in a non-DP manner can synthesize perceptually realistic images by leveraging the directional information hidden in the sanitized dataset.
Contributions. The contributions are summarized below. (a) We propose DPGEN, an instantiation of DP variant of EBM (described in Section 3), that synthesizes high-resolution images (up to 128 × 128 resolutions) in an ε-DP manner, in contrast to the other DPSGD-assisted GAN-based (ε, δ)-DP approaches. In fact, DPGEN can achieve the best of both worlds; i.e., it is able to synthesize perceptually real-istic images that can well preserve the features such that the downstream classiﬁcation task has high accuracy. (b) Through extensive evaluations on various datasets, we demonstrate that DPGEN signiﬁcantly improves the sample quality of synthetic images over SOTA approaches. 2.