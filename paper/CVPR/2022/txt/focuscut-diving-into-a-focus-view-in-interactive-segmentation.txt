Abstract
Global View
Focus View
Interactive image segmentation is an essential tool in pixel-level annotation and image editing. To obtain a high-precision binary segmentation mask, users tend to add in-teraction clicks around the object details, such as edges and holes, for efficient refinement. Current methods regard these repair clicks as the guidance to jointly determine the global prediction. However, the global view makes the model lose focus from later clicks, and is not in line with user inten-tions. In this paper, we dive into the view of clicks’ eyes to endow them with the decisive role in object details again.
To verify the necessity of focus view, we design a simple yet effective pipeline, named FocusCut, which integrates the functions of object segmentation and local refinement. Af-ter obtaining the global prediction, it crops click-centered patches from the original image with adaptive scopes to re-fine the local predictions progressively. Without user per-ception and parameters increase, our method has achieved state-of-the-art results. Extensive experiments and visual-ized results demonstrate that FocusCut makes hyper-fine segmentation possible for interactive image segmentation. 1.

Introduction
Interactive image segmentation aims to obtain an accu-rate binary mask of the target object with the least inter-It has developed into an indispensable tool action cost. in serving pixel-level data annotation and image editing.
The research mainly focuses on two aspects. One is a more efficient mode of user interaction, and the other is to make more efficient use of the interaction provided by users. For the former, the interactive modes are widely explored and mainly based on the bounding box [50], the polygon [1, 6, 32], clicks [2, 29, 36], scribbles [3, 48], and some combinations [34, 52]. Among them, the click-based method has become the mainstream because of its simplic-ity. For the latter, researchers have explored the interaction ambiguity [9, 26, 30], input information [31, 35], backprop-agating [20,41], etc. These methods provide better segmen-tation results without changing the user input.
*C.L. Guo is the corresponding author.
Figure 1. Visual display of FocusCut. The details of the eagle claw are refined with an additional focus view. The red and green clicks are provided by users to indicate the foreground and background in interactive segmentation. The yellow mask is the prediction.
In recent years, with the increase of large screen equip-ments and the improvement of aesthetic, both image anno-tation and image editing need more delicate segmentation masks. In high-precision interactive segmentation, the re-finement of object details, such as edges and holes, often requires more interactive clicks and time. When users click in mislabeled regions, they tend to focus on the detail region for efficient repairing. However, current methods consider previous clicks together to determine the global prediction.
In a new round of interaction, a join predicting process may weaken the decisive effect of the newly-input click on its surrounding details and feed back disagreeable results.
For more effective refinement, we dive into the view of a click to consider its surrounding information, which is called the focus view.
In the paper, we design a concise pipeline, FocusCut, to verify the importance of the focus view. The original function of the interactive segmentation network has been changed, and instead, we endow it with a new role, allowing it to not only segment the target ob-ject but also repair local details. Specifically, after global segmentation, which is called the global view in our paper, it crops a local patch from original images centered by the newly-clicked point as the focus view to further refine ob-ject details using the same network. The progressive crop-ping scopes are adjusted dynamically according to predic-tion variation in the global view. Then the crop scope will gradually decrease according to our progressive focus strat-egy. To keep it fair with other methods and better prove our opinion, almost no parameters and specific modules have been inserted into the common-used architecture of interac-tive segmentation. Comprehensive experiments have been carried out on GrabCut [40], Berkeley [37], SBD [15], and
DAVIS [39] datasets to prove the effectiveness of FocusCut.
The contributions can be summarized as follows:
• We introduce the focus view to grasp user intentions by considering the local segmentation from clicks’ eyes.
• Based on our opinion, we propose the FocusCut, a simple yet effective pipeline to strengthen the local refinement.
• Without additional parameters, the FocusCut achieves state-of-the-art performance, and the visualized results reflect its effectiveness in fine segmentation. 2.