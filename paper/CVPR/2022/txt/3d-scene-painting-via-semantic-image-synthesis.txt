Abstract
We propose a novel approach to 3D scene painting us-ing a conﬁgurable 3D scene layout. Our approach takes a 3D scene with semantic class labels as input and trains a 3D scene painting network that synthesizes color values for the input 3D scene. We exploit an off-the-shelf 2D seman-tic image synthesis method to teach the 3D painting net-work without explicit color supervision. Experiments show that our approach produces images with geometrically cor-rect structures and supports scene manipulation, such as the change of viewpoint, object poses, and painting style.
Our approach provides rich controllability to synthesized images in the aspect of 3D geometry. 1.

Introduction
Creating realistic 3D scenes becomes crucial due to the increasing demands of unobserved content for virtual real-ism. However, it is regarded as a challenging problem be-cause many components depend on human labor [5, 7, 10, 24] or manual capture of real scenes [45]. In particular, painting a scene is hard for a human, and it takes extra effort if we want to change the style after the creation. There are some attempts to focus on automatic 3D scene painting to resolve the issues. For instance, given a 3D scene and ref-erence image, they ﬁnd a texture from a texture database, which has a similar color distribution to the reference im-age [54]. However, making a large-scale texture set is a bur-den due to the variety of scene geometry.
We propose an automatic painting approach for 3D scene creation in this work. For 3D scene painting, our approach learns a 3D scene painting network that takes a 2D semantic map and 3D coordinate map as input and produces a 2D im-age with realistic RGB colors. Training a 3D scene painting network, on the other hand, requires numerous colored 3D scenes with semantic labels for supervision, which are hard to acquire. To overcome this, we propose to utilize tech-niques already developed for 2D image synthesis. Specif-∗Part of this work was done while the ﬁrst author was a research intern at Microsoft Research Asia.
Input 3D Scene Painting
Rendered Image
Change View
Edit Scene
Change Style
Figure 1. The colored 3D scenes using the proposed method. Our framework learns to paint a scene given 3D geometry and semantic label map. The images are rendered from colored 3D scenes and provide a way to change viewpoints, scene style manipulation, and scene editing. ically, given a 3D scene with object-wise semantic labels, we render 2D maps of 3D coordinates and semantic labels.
The rendered maps are then fed to a realistic image synthe-sis module to synthesize 2D RGB images, which are used as pseudo-ground-truth labels for training our 3D scene paint-ing network to produce realistic colors. As our network is conditioned on 3D coordinates, it produces consistent col-ors under the change of viewpoint.
The proposed method has a few merits compared to pre-vious works on 3D scene painting or texture mapping. First, our approach can generate a quality texture of a scene with the aid of a generative adversarial loss. Second, our ap-proach can change the style of a scene by simply manipulat-ing a style vector. Third, our approach allows a user detailed control of scene layouts, and change of the viewpoint or the positions of objects for image rendering.
The proposed scene painting network can be regarded as a geometrically conditioned image synthesis from an im-age synthesis perspective. Concurrent image synthesis ap-proaches utilize a rough guide, such as image class [2, 21, 31, 34, 51], semantic labels [18, 38, 41, 47], attributes [43], poses [3], voxelized scenes [14], or viewing-directions [32].
On the other hand, our approach opens a new research di-rection for cases when 3D scenes are provided.
We apply our approach to various indoor scenes. Our qualitative and quantitative experimental results verify that our method is highly controllable and produces high-quality colored scenes and images.
Our contributions can be summarized as follows:
• We propose a novel approach for automatic 3D scene painting, which is based on a novel 3D scene painting network that produces realistic RGB colors from 3D coordinates and semantic class labels.
• Our approach can learn 3D scene painting without ground-truth colored 3D scenes by combining off-the-shelf 2D semantic image synthesis and 2D renderings of 3D semantic labels and coordinates.
• Our approach allows detailed control over scene lay-outs and change of the viewpoint and object poses. 2.