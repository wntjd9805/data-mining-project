Abstract
Though unsupervised domain adaptation (UDA) has achieved very impressive progress recently, it remains a great challenge due to missing target annotations and the rich discrepancy between source and target distributions.
We propose Spectral UDA (SUDA), an effective and efficient
UDA technique that works in the spectral space and can generalize across different visual recognition tasks. SUDA addresses the UDA challenges from two perspectives. First, it introduces a spectrum transformer (ST) that mitigates inter-domain discrepancies by enhancing domain-invariant spectra while suppressing domain-variant spectra of source and target samples simultaneously. Second, it introduces multi-view spectral learning that learns useful unsupervised representations by maximizing mutual information among multiple ST-generated spectral views of each target sample.
Extensive experiments show that SUDA achieves superior accuracy consistently across different visual tasks in object detection, semantic segmentation and image classification.
Additionally, SUDA also works with the transformer-based network and achieves state-of-the-art performance on ob-ject detection.
Figure 1. Illustration of the proposed spectrum transformer (ST):
For images of different domains with clear distribution discrep-ancies as shown in (a), ST converts them into frequency space and decomposes the converted frequency signals into multiple fre-quency components (FCs) in low, middle, and high frequency bands as shown in (b). It learns to identify and enhance domain-invariant FCs and suppress domain-variant FCs which effectively mitigates the inter-domain discrepancy as shown in (c). Note we increase the image contrast for better visualizing (c). 1.

Introduction
Deep learning techniques [29,44,71] have achieved great success in various visual recognition tasks such as image classification [29,44,71], image segmentation [3,10,51,63] and object detection [8,20,21,50,60,61]. The great success is at the price of large quantities of annotated training data which are often prohibitively laborious and time-consuming to collect [14, 15, 18, 49]. One alternative that could miti-gate this constraint is to leverage the off-the-shelf labeled data from one or multiple related source domains. How-ever, the model trained with source-domain data often ex-periences clear performance drop while applied to a target domain where the data often have discrepant distributions as compared with the source-domain data [13, 68, 72].
*Equal contribution
â€ Corresponding author
Unsupervised domain adaptation (UDA) has been ex-plored to mitigate the discrepancy between source and tar-get domains. One typical approach is image-to-image trans-lation with generative adversarial networks (GANs) which aligns source and target data in the input space by modifying source data to have similar styles as target data [40, 43, 48].
However, image-to-image translation needs to learn large amounts of parameters which is usually computationally intensive.
In addition, it impairs the end-to-end feature of UDA as it needs to train GANs first before applying them for image translation [40, 43, 48]. Further, it could degrade UDA by undesirably modifying domain-invariant image structures that are closely entangled with domain-variant image styles in the spatial space [23, 89].
We propose Spectral UDA (SUDA) that tackles UDA challenges by learning domain-invariant spectral features efficiently and effectively. SUDA works from two per-spectives. First, it introduces a spectrum transformer (ST) that learns to reduce inter-domain discrepancies by enhanc-ing domain-invariant frequency components (FCs) and sup-pressing domain-variant FCs as illustrated in Fig. 1. To this end, we design novel adversarial spectrum attention (ASA) that can identify domain-variant and domain-invariant FCs accurately. Second, we design multi-view spectral learn-ing (MSL) that learns diverse target representations by maximizing the mutual information among multiple ST-generated spectral views for each target sample. MSL in-troduces certain self-supervision which mitigates the lack of target annotations effectively.
The proposed SUDA has three desirable features. First, it is generalizable and performs consistently well across dif-ferent visual tasks such as image classification, image seg-mentation and object detection. Second, it is an online and learnable technique whereas GANs-based image translation is offline and traditional image preprocessing is mostly non-learnable. Third, it is complementary with existing UDA methods and can be incorporated with consistent and clear performance boosts but little extra computation.
The contributions of this work are threefold. First, we designed SUDA that tackles UDA challenges effectively by learning domain-invariant spectral features. Second, we de-sign an online learnable spectrum transformer that mitigates inter-domain discrepancy by enhancing domain-invariant
FCs and suppressing domain-variant FCs simultaneously.
To this end, we design ASA that leverages contextual in-formation to identify domain-variant and domain-invariant
FCs accurately. Third, we design MSL that can learn di-verse target representations by maximizing mutual informa-tion among multiple spectral views of each target sample.
MSL mitigates the lack of target annotations effectively. 2.