Abstract
We address the problem of registering synchronized color (RGB) and multi-spectral (MS) images featuring very different resolution by solving stereo matching correspon-dences. Purposely, we introduce a novel RGB-MS dataset framing 13 different scenes in indoor environments and pro-viding a total of 34 image pairs annotated with semi-dense, high-resolution ground-truth labels in the form of dispar-ity maps. To tackle the task, we propose a deep learning architecture trained in a self-supervised manner by exploit-ing a further RGB camera, required only during training data acquisition. In this setup, we can conveniently learn cross-modal matching in the absence of ground-truth labels by distilling knowledge from an easier RGB-RGB matching task based on a collection of about 11K unlabeled image triplets. Experiments show that the proposed pipeline sets a good performance bar (1.16 pixels average registration error) for future research on this novel, challenging task. 1.

Introduction
Traditional RGB sensors acquire images with three channels, approximately mimicking color perception in trichromatic mammals like humans, where three kinds of
∗ Joint first authorship. cone cells are sensitive to three different ranges of wave-lengths in the visible spectrum. This is usually achieved by using bandpass optical filters corresponding to such col-ors, arranged in a Bayer pattern [6]. Multi-spectral (MS) imaging devices generalize such image acquisition mechan-ics and enable acquisition of images with a larger number of channels, i.e. ten or more, usually corresponding to nar-rower wavelength ranges. MS sensors may also be sensi-tive to wavelengths outside the visible spectrum, e.g.in the infra-red or ultra-violet bands. By extending the range of wavelengths as well as the granularity of their quantiza-tion into image channels, MS devices enable extraction of additional information about the sensed scene that human eyes fail to capture, which in turns forms the basis of pe-culiar applications. For instance, MS imaging devices are used to perform analysis of artworks [15], remote sensing for agriculture [81] and land use [79], target tracking [21], pedestrian detection [31], counterfeit detection, e.g. of ban-knotes [3], diagnostic medicine and skin inspection [39], food inspection [54] and contamination detection [20]. In spite of such broad range of applications, deployment of MS sensors is usually limited to industrial settings or expensive equipment like satellites. However, the ability to run several of these applications on mobile phones and other consumer devices directly operated by end users could open up inter-esting scenarios, like, e.g., enabling early diagnosis of skin diseases [35], democratizing food quality control [4], mak-ing plant phenotyping easier [69], and others yet to imagine.
While the number of traditional cameras on high-end phones have been growing steadily in recent years, MS sen-sors have not been ported yet on consumer devices like phones or action cameras due to several limitations [22].
In particular, MS sensors resolution is significantly smaller than standard RGB cameras which feature several Megapix-els of resolution, because the most suitable technology to re-alize them extends the Bayer pattern used for color imaging into multi-spectral filter arrays [41], with each native pixel of the imaging sensor detecting one band by placing in front of it the corresponding optical filter, i.e. one MS “pixel” for a camera sensing 16 bands uses a 4×4 grid of native pix-els. Thus, MS sensors tend also to be larger and bulkier than RGB cameras; and they are orders of magnitude more expensive, i.e. MS cameras cost at least tens of thousands of dollars/euros. There exist linear MS cameras [62] or
MS cameras realized with filter wheel technology [8] which may feature high resolution but can sense only static scenes and are not appropriate for deployment on mobile devices.
As a result of these technological limitations, MS cam-eras compatible with cost and size requirements of mobile devices feature very small resolution, insufficient for the ap-plications listed above. Moreover, beside up-sampling the
MS image to usable resolutions, it is usually important to align MS information with RGB streams coming from tra-ditional cameras on the device, where objects or areas of interest can be easily identified with effective algorithms.
Due to the challenges of matching images across spectra, the mostly explored setup to acquire MS images and RGB images simultaneously has been to physically align their op-tical centers by using beam splitters [11,31], which are how-ever unfeasible to deploy in mobile devices, where instead the dense registration between the images in the pair must be computed by computer vision algorithms.
Although establishing dense image correspondences is one of the fundamental and most studied problems in com-puter vision, solutions that address the cross-spectral im-ages and/or unbalanced resolutions are rare. They only investigated case is the special incarnation of the prob-lem where an RGB image is matched to a Near Infra-Red (NIR) or Infra-Red (IR) one at the same resolution
[14, 36, 37, 59, 78]. To the best of our knowledge, the gen-eral MS-RGB case, both balanced and unbalanced in terms of resolution, is yet unexplored in literature. Research on this topic has also been hindered by the lack of publicly available datasets: existing methods tackling the NIR/IR-RGB case have been tested on datasets acquired with cus-tom hardware setups targeting specific use cases, like au-tonomous driving or object detection, and never made pub-licly available [14, 78] or are tested on small datasets with sparse ground-truth: e.g. the dataset used by [36, 37] and proposed in [59] has 7 image pairs where 50-100 object cor-ners on average per pair have been manually annotated, i.e. less 700 ground-truth correspondences.
In this work, we propose the first large-scale and publicly-available dataset to study RGB-MS registration.
In particular, we cast the registration problem as a stereo matching one due to the two cameras being synchronized.
Our dataset features more than 11K stereo pairs composed of a low-res 510×254 MS image and a high-res 3222×1605
RGB image which can be used to compute a high-res MS image registered at pixel-level with the RGB image. Exam-ples of pairs are shown in Fig. 1a-b. Another key feature of our dataset is that 34 stereo pairs coming from 13 dif-ferent scenes are densely annotated (Fig. 1c), thanks to an original acquisition methodology whereby a second RGB image and several projectors are used to create a very ac-curate active space-time stereo setup [16], which result in more than 125 millions of ground-truth correspondences.
We also propose a deep learning architecture to tackle the challenging cross-spectral and resolution-unbalanced prob-lem, that can be used to compute registered MS images at arbitrary resolutions and serves as a baseline for the dataset, whose results are shown in Fig. 1d. When train-ing the network, we leverage the large body of unlabelled images in our dataset by sourcing proxy-labels, which are obtained by exploiting again the second RGB camera to run passive stereo matching. Our dataset enables the commu-nity to study the challenging problem of cross-spectral and resolution-unbalanced matching of images, which is key to enable porting of existing MS applications in the consumer space as well as to unlock new applications of MS imaging specific to the mobile device setup. Our contributions are:
• we propose the first investigation into the challenging problem of cross-spectral and resolution-unbalanced dense matching, which is a key enabling technology to unlock MS applications on mobile devices;
• we present the first large-scale publicly available dataset for the problem;
• thanks to a peculiar acquisition methodology exploit-ing two registered high-res RGB cameras, we also make available the first densely labelled set of images for this problem and we propose a training methodology which can leverage unlabelled images via proxy supervision;
• we propose a deep architecture to compute correspon-dences between images at different resolutions and with dif-ferent spectral content, which can be used to generate MS images registered at pixel-level with the RGB stream.
The project page is available at https://cvlab-unibo.github.io/rgb-ms-web/. 2.