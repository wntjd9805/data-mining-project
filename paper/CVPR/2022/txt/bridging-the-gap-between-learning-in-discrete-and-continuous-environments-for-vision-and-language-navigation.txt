Abstract
Most existing works in vision-and-language naviga-tion (VLN) focus on either discrete or continuous environ-ments, training agents that cannot generalize across the two. Although learning to navigate in continuous spaces is closer to the real-world, training such an agent is sig-niﬁcantly more difﬁcult than training an agent in discrete spaces. However, recent advances in discrete VLN are chal-lenging to translate to continuous VLN due to the domain gap. The fundamental difference between the two setups is that discrete navigation assumes prior knowledge of the connectivity graph of the environment, so that the agent can effectively transfer the problem of navigation with low-level controls to jumping from node to node with high-level ac-tions by grounding to an image of a navigable direction.
To bridge the discrete-to-continuous gap, we propose a predictor to generate a set of candidate waypoints during navigation, so that agents designed with high-level actions can be transferred to and trained in continuous environ-ments. We reﬁne the connectivity graph of Matterport3D to ﬁt the continuous Habitat-Matterport3D, and train the waypoints predictor with the reﬁned graphs to produce ac-cessible waypoints at each time step. Moreover, we demon-strate that the predicted waypoints can be augmented dur-ing training to diversify the views and paths, and therefore enhance agent’s generalization ability.
Through extensive experiments we show that agents nav-igating in continuous environments with predicted way-points perform signiﬁcantly better than agents using low-level actions, which reduces the absolute discrete-to-continuous gap by 11.76% Success Weighted by Path
Length (SPL) for the Cross-Modal Matching Agent and 18.24% SPL for the VLNœBERT. Our agents, trained with a simple imitation learning objective, outperform previous methods by a large margin, achieving new state-of-the-art results on the testing environments of the R2R-CE and the
RxR-CE datasets.
* Authors contributed equally
1.

Introduction
Vision-and-language navigation (VLN) [3] is a challeng-ing cross-domain research problem which requires an agent to interpret human instructions and navigate in previously unseen environments by executing a sequence of actions.
Two distinct scenarios have been proposed for VLN re-search, being navigation in discrete environments (R2R,
RxR [3, 33]) and in continuous environments (R2R-CE,
RxR-CE [32]). Due to the large domain gap, navigation in the two scenarios have been studied independently in previous works, and a large number of prominent advances achieved by agents in discrete spaces, such as by leveraging pre-trained visiolinguistic transformers [20, 24] or by using scene memory [16, 53] cannot be directly applied to agents traversing continuous spaces.
The fundamental difference between navigation in dis-crete and in continuous environments is the reliance on the connectivity graph which contains numbers of sparse nodes (waypoints) distributed across accessible spaces of the en-vironment. With the prior knowledge of the connectivity graph, the agent can move with a panoramic high-level ac-tion space [17], i.e., teleport to an adjacent waypoint on the graph by selecting a single direction from the discrete set of navigable directions. Compared to navigation in continu-ous environments, which usually relies on a limited ﬁeld of view to infer low-level controls (e.g., turn left 15 de-grees or move forward 0.25 meters) [32], navigation with panoramic actions and the connectivity graph simpliﬁes the complicated decision making problem by formulating it as an explicit text-to-image grounding task. First, the agents are not required to infer the important concepts of accessi-bility (openspace vs. obstacles) from sensory inputs. Sec-ond, distinct visual representations can be deﬁned for each navigable direction, so the agents only need to match con-textual clues from instruction to visual options to move, which greatly reduces the agent’s state space and facilitates the learning. As a result, many previous works in VLN with high-level actions address the navigation problem mostly from the visual-textual matching perspective. A large num-ber of innovations such as back-translation [51], back-tracking [29, 37], scene memory [16, 53] and transformer-based pre-training [20, 24, 38] bring remarkable improve-ment but they cannot be directly transferred to agents in continuous environments. There remains about a 20% gap in success rate for agents with the same architecture navi-gating in discrete and in continuous spaces [32].
Despite the great efﬁciency of learning in a discrete en-vironment, navigation in continuous spaces is much closer to the real-world. In this paper, we address the problem of bridging the learning between the two domains, aiming to effectively adapt agents designed for discrete VLN to con-tinuous environments. First of all, we identify and quan-titatively evaluate the value of high-level controls in VLN, showing the importance of knowing accessible waypoints.
Second, inspired by Sim2Real-VLN [2], we introduce a powerful candidate waypoints predictor to estimate naviga-ble locations in continuous spaces, the module constructs a local navigability graph centered at the agent at each time step using the visual observations. In Sim2Real-VLN [2], the sub-goal module is trained on the pre-deﬁned connec-tivity graphs of the Matterport3D environment (MP3D) [6], where there exist edges going through obstacles and nodes
In contrast, we transfer the dis-in inaccessible spaces. crete MP3D graph onto the continuous Habitat-MP3D [48] spaces, and represent the transferred waypoints as targets for learning a mixture of Gaussian probability map, result-ing in a robust waypoints predictor in unvisited environ-ments that supports navigation. Furthermore, we propose a simple augmentation method to move the position of way-points during training of the agent, so that the agent can learn to reach the same target using diverse observations and step lengths, thereby improving the generalization ability.
With the proposed candidate waypoints predictor, we evaluate the performance of agents designed for discrete
VLN in continuous environments. The selected agents, in-cluding the cross-modal matching agent (CMA) [54] and the VLNœBERT [24] are widely applied methods that are distinct in network architecture. Our experiments show that agents in continuous environments trained with the predicted waypoints signiﬁcantly improves over navigation without using waypoints, reducing the discrete-continuous gap, and achieving new state-of-the-art performance of 39% and 19.61% SPL on the benchmarking R2R-CE and RxR-CE test sets [3,32,33], respectively. This results suggest that our proposed candidate waypoints predictor can enable an effective discrete-to-continuous transfer as well as showing a huge potential of beneﬁting other navigation problems. 2.