Abstract
In this paper, we propose a new deep learning-based method for estimating room layout given a pair of 360◦ panoramas. Our system, called Position-aware Stereo Merg-ing Network or PSMNet, is an end-to-end joint layout-pose estimator. PSMNet consists of a Stereo Pano Pose (SP2) transformer and a novel Cross-Perspective Projection (CP2) layer. The stereo-view SP2 transformer is used to implicitly infer correspondences between views, and can handle noisy poses. The pose-aware CP2 layer is designed to render features from the adjacent view to the anchor (reference) view, in order to perform view fusion and estimate the visible layout. Our experiments and analysis validate our method, which significantly outperforms the state-of-the-art layout estimators, especially for large and complex room spaces. 1.

Introduction
Image-based room layout estimation is an important step to constructing models of home interiors for a variety of applications, such as virtual tours, path planning, floor plan
†Work done while Haiyan Wang was an intern at Zillow.
∗Authors contributed equally. generation, and home insights on square footage and archi-tectural style. Much work has been done in room layout estimation, and current techniques perform well on simple
Manhattan and Atlanta-world layouts. However, their per-formance degrade for large and complex rooms, e.g., those that have more than 10 corners.
It is not unusual (at least in North America) to find room layouts that are significantly more complex than cuboids or
L-shapes. Examples include large open spaces with merged kitchen, dining room, and living room. The prevalence of complex rooms is evidenced by the statistics of real residen-tial homes in ZInD [4]. Figure 1 illustrates the difficulty of layout estimation for a complex indoor space with many self-occlusions. Here, single image solutions would not be adequate due to occlusion. This is because no panorama is able to see the entire open space. Using both panoramas would, in principle, be able to better extract the layout. In addition, given that reliability is distance dependent (due to reductions in resolution at farther distances), such depen-dence is reduced with multiple views.
In this paper, we recover the room layout from two 360◦ panoramas. This has its challenges, because relative camera pose of the panorama pair needs to be estimated jointly with layout. While techniques such as structure-from-motion
exist, our goal is to generate layouts of complex rooms that may lack features due to occlusions. Wide baseline 2-view
Structure from Motion (SfM) is still an open problem. In this work we assume that an input pose, potentially noisy, is provided. For example, this could be based on a rough user input [4] or matching corresponding semantic elements with noisy predictions [29].
Our solution is a joint pose-layout deep architecture to predict 2D room layout and refine a noisy 3 DOF relative camera pose in an end-to-end manner. Our system, called
Position-aware Stereo Merging Network (PSMNet), consists of a transformer-based Stereo Pose Estimation (SP2) network and a new pose-aware Cross-Perspective Projection (CP2) module. CP2 generates the final layout with the help of an attention-based merging model (inspired by SEBlock [12]) that weights regions based on certainty. The pose and lay-out modules share the same encoder for efficiency, and are trained end-to-end.
In our work, we make the same assumptions as ZInD [4]: input panoramas are both captured upright at approximate same height, and layouts are based on Atlanta world (hor-izontal floor and ceiling, and vertical walls). The ceiling height is used for visualization.
The contributions of our work are: (i) First end-to-end joint layout-pose deep architecture (to our knowledge) for large and complex room layout estimation from a pair of panoramas. (ii) New Cross-Perspective Projection (CP2) module with attention-based merging for layout generation. (iii) An integrated transformer-based relative Stereo Pano
Pose (SP2) network to refine noisy input pose. (iv) State-of-the-art performance on a challenging, stereo panoramas dataset, sampled from ZInD [4]. 2.