Abstract
The deep stereo models have achieved state-of-the-art performance on driving scenes, but they suffer from severe performance degradation when tested on unseen scenes.
Although recent work has narrowed this performance gap through continuous online adaptation, this setup requires continuous gradient updates at inference and can hardly deal with rapidly changing scenes. To address these chal-lenges, we propose to perform continual stereo matching where a model is tasked to 1) continually learn new scenes, 2) overcome forgetting previously learned scenes, and 3) continuously predict disparities at deployment. We achieve this goal by introducing a Reusable Architecture Growth (RAG) framework. RAG leverages task-specific neural unit search and architecture growth for continual learning of new scenes. During growth, it can maintain high reusabil-ity by reusing previous neural units while achieving good performance. A module named Scene Router is further in-troduced to adaptively select the scene-specific architecture path at inference. Experimental results demonstrate that our method achieves compelling performance in various types of challenging driving scenes. 1.

Introduction
The reconstruction of the surrounding 3D scene struc-ture is the foundation of many vision tasks. Depth is the useful precursor to sensing 3D geometry, which is prefer-entially recovered by well-posed stereo matching due to its simple settings, high accuracy, and acceptable cost. Bene-fiting from the convolutional neural networks (CNNs), deep stereo methods have achieved remarkable progress recently in driving scenes [3, 5, 6, 14, 45, 48], constantly improving
*Corresponding author.
Figure 1. Schematic representation of our framework deployed on real-world continuous driving scenes. The scene-specific architec-ture path will be loaded for inference according to Scene Router. stereo benchmarks like KITTI [11, 26].
However, deep stereo models suffer from performance degradation when deployed to unseen scenarios [41]. This is often caused by the gap between training and testing data domains, e.g., synthetic [25] and real-world data [11, 26].
Domain-adaptive methods [22,29,39] can achieve good per-formance, but they inherently rely on the types of scenes available at training time. Unfortunately, collecting enough data from all kinds of scenes at hand, such as various weather and road conditions in autonomous driving, is quite expensive and unfeasible in reality.
Imagine a car driving in real-world scenarios shown in
Fig. 1. The car may experience continuous scenes changing from cloudy to rainy, or from the city to the countryside.
A stereo model with a single fixed architecture can hardly perform well on all types of scenes. Moreover, it is also dif-ficult to continue to learn new scenes without forgetting pre-vious knowledge. For optimal performance, an ideal model
should adaptively load suitable architectures for the scenes at inference. The model also needs to avoid the performance drop on previous scenes while learning on the new scenes.
The previous method MADNet [43] utilizes an online learning scheme to continuously adapt to current scenes.
The follow-up work MAD++ [31] leverages prior labels to improve the performance while alleviating catastrophic for-getting in stereo. Nevertheless, continuous online gradient updates are required at inference even when the model has adapted well to the current scene, which is computation-ally unnecessary. Besides, when faced with rapidly chang-ing scenes at inference, MAD++ still needs buffer time to adapt since it cannot leverage previously learned scenes to help. In contrast, we reformulate this problem as a contin-ual stereo matching problem. By doing this, the model can continually learn to estimate the disparity of new heteroge-neous scenes and quickly adapt to rapidly changing contin-uous scenes without online gradient updates at inference.
In this work, we propose a Reusable Architecture
Growth (RAG) framework to address the continual stereo problem. RAG can overcome the catastrophic forgetting by freezing the model parameters learned in the previous scenes. Since different scenes vary in color, lighting, and disparity distributions, we assign task-specific neural units for each new scene and adapt the model to them by ar-chitecture growth. To obtain a more compact architec-ture, we explicitly reuse the learned neural units during ar-chitecture growth and thereby achieve a balance between model performance and parameter efficiency. Under differ-ent weather and road conditions, our method achieves com-parable or better performance compared with the state-of-the-art methods. At deployment time, we further propose a module called Scene Router to automatically select the scene-specific architecture path according to the scene type of the input.
Our contributions are summarized as follows:
• We propose a Reusable Architecture Growth frame-work consisting of task-specific neural units search and architecture growth. The framework can continually learn to estimate the disparity of new scenes without catastrophic forgetting while exhibiting good reusabil-ity of the learned neural units.
• A Scene Router module is further introduced to adap-tively select the scene-specific architecture path for the current scene at inference. In contrast to continuous adaptation methods [31, 43], our method can quickly adapt to rapid scene switches and is more computa-tionally efficient.
• Experiments demonstrate that our method achieves compelling performance under different challenging weather and road conditions on DrivingStereo [46],
KITTI raw [10], and Virtual KITTI [2] datasets. 2.