Abstract
Neural Architecture Search (NAS) aims to find efficient models for multiple tasks. Beyond seeking solutions for a single task, there are surging interests in transferring net-work design knowledge across multiple tasks. In this line of research, effectively modeling task correlations is vital yet highly neglected. Therefore, we propose Arch-Graph, a transferable NAS method that predicts task-specific opti-mal architectures with respect to given task embeddings. It leverages correlations across multiple tasks by using their embeddings as a part of the predictor’s input for fast adap-tation. We also formulate NAS as an architecture relation graph prediction problem, with the relational graph con-structed by treating candidate architectures as nodes and their pairwise relations as edges. To enforce some basic properties such as acyclicity in the relational graph, we add additional constraints to the optimization process, convert-ing NAS into the problem of finding a Maximal Weighted
Acyclic Subgraph (MWAS). Our algorithm then strives to eliminate cycles and only establish edges in the graph if the rank results can be trusted. Through MWAS, Arch-Graph can effectively rank candidate models for each task with only a small budget to finetune the predictor. With exten-sive experiments on TransNAS-Bench-101, we show Arch-Graph’s transferability and high sample efficiency across numerous tasks, beating many NAS methods designed for both single-task and multi-task search. It is able to find top 0.16% and 0.29% architectures on average on two search spaces under the budget of only 50 models.1 1.

Introduction
Neural Architecture Search (NAS) methods [2, 40] have the potential to democratize deep learning and reduce costly
*Corresponding author. 1Code: https://github.com/Centaurus982034/Arch-Graph
Figure 1. Overview of our Arch-Graph that trains a pairwise re-lation predictor on a source task and transfers to target task by finetuning. It constructs an architecture relation graph based on the pairwise relation predictor. After selecting the MWAS of the architecture relation graph, Arch-Graph can give a proper ranking of different candidate architectures. human labor in designing neural networks. By automati-cally searching for optimal architectures, many NAS meth-ods have discovered models exceeding human-designed ones on various tasks. However, many NAS solutions are computationally expensive as they require training over nu-merous candidate architectures. Under cases where net-works for multiple tasks are needed, searching for an archi-tecture for each task requires repeatedly running NAS meth-ods from scratch to find the top performing network, throw-ing away potentially valuable knowledge accumulated over the course of searching. There are many recent attempts
[15, 34] investigating transferable NAS problems over dif-ferent tasks by mining task correlations. For instance, [15] proposes to use meta-learning to generate architectures for a given new task. However, it makes a strong assumption that information on top-performing architectures for each pretrain task is always available, which can limit its use case. [34] proposed to use task embeddings to inform an
RNN controller of the task information and framed NAS as a reinforcement learning (RL) problem, which inherits the sample inefficiency problem from RL. Weight-sharing
techniques [16–18, 25] are recently more popular among researchers due to their efficiency in cost reduction, typ-ically by training a supernet and then inheriting weights from it. However, due to their restrictions in supernet de-sign, weight-sharing methods are usually constrained in the choice of network search space.
Predictor-based NAS methods [23, 28, 33, 35, 37] alle-viate these concerns by sampling architecture-performance pairs and fitting a proxy accuracy predictor to reduce com-putation costs. However, training a large number of archi-tectures for fitting a good predictor can also be computa-tionally challenging. Besides, this approach is ultimately converting NAS into a regression problem, which can be hard to solve since the model space is usually highly non-convex, making accurately identifying top performers ex-tremely difficult. In this paper, we instead argue that ap-proaching NAS as a ranking problem can bring along many extra benefits compared to other methods, largely due to its added constraints that provide extra learning signals.
This key observation motivated us to develop a predic-tor that captures pairwise relations among architectures and formulate NAS as a graph ordering problem. Our method,
Arch-Graph, treats architectures as nodes and order infor-mation as directed edges, such that an edge pointing from arch a to arch b represents the superiority of arch a in its performance when compared to arch b. We propose to use a pairwise relation predictor to construct this graph. This predictor is optimized with objective of finding the correct pairwise order of nodes in the graph, which greatly im-proves data efficiency and prediction accuracy comparing to previous pointwise predictor that directly predict archi-tecture performance.
To allow transfering among different tasks without re-training the predictor, another key ingredient task embed-ding that represents a task during the predictor training pro-cess stablizes the knowledge transfer between tasks. Previ-ous works on task embedding mostly focus on classification tasks [1], whereas our proposed task embedding method is more general and can be applied to many other vision do-mains such as autoencoding and semantic segmentation.
After constructing the relation graph through the pair-wise predictor, the architecture selection can then be for-mulated as a topological ordering problem on this graph.
Under this setting, it is vital to enforce that the graph fol-lows basic properties of a partial order, such as acyclicity, which prohibits circular ordering (A > B > C while C > A).
Therefore, a central component of our work is the definition of a Maximal Weighted Acyclic Subgraph (MWAS) prob-lem with Trust Score to make sure the constructed graph follows the irreflexive, transitive, and anti-symmetric prop-erties of a partial order. We propose an approximation solu-tion to it by iteratively applying the max-MAS algorithm.
Our experiments on TransNAS-Bench-101 proves the ef-fectiveness of Arch-Graph, identifying architectures with average rank 5.24 (top 0.16%) and 12.2 (top 0.29%) on macro and micro search space respectively, with only ran-domly sampling 50 architectures, saving at least 37.5% of samples in other methods to achieve comparable results.
To conclude, the contributions of our work can be sum-marized as follows:
• We propose Arch-Graph, a task transferable NAS method by formulating NAS from a novel perspective:
A graph ordering problem, and solve this problem by training a pairwise relation predictor, which is more data efficient, saving at least 37.5% training samples.
• We generalize task embeddings to any kind of tasks, and further enables task-transferable NAS by predict-ing architecture relation on any given task embeddings.
• To remove incorrect edges in the relation graph con-structed by the predictor, we define the Maximal
Weighted Acyclic Subgraph problem and propose an approximation algorithm to solve it.
• Extensive experiments demonstrate that Arch-Graph can beat many existing transferable NAS methods by a large margin, finding top 0.16% and 0.29% architec-tures on two search spaces. 2.