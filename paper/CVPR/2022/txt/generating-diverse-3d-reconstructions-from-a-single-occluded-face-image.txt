Abstract 1.

Introduction
Occlusions are a common occurrence in unconstrained face images. Single image 3D reconstruction from such face images often suffers from corruption due to the pres-ence of occlusions. Furthermore, while a plurality of 3D reconstructions is plausible in the occluded regions, exist-ing approaches are limited to generating only a single so-lution. To address both of these challenges, we present
Diverse3DFace, which is specifically designed to simulta-neously generate a diverse and realistic set of 3D recon-structions from a single occluded face image. It comprises three components; a global+local shape fitting process, a graph neural network-based mesh VAE, and a determinan-tal point process based diversity-promoting iterative opti-mization procedure. Quantitative and qualitative compar-isons of 3D reconstruction on occluded faces show that Di-verse3DFace can estimate 3D shapes that are consistent with the visible regions in the target image while exhibit-ing high, yet realistic, levels of diversity in the occluded regions. On face images occluded by masks, glasses, and other random objects, Diverse3DFace generates a distri-bution of 3D shapes having ∼50% higher diversity on the occluded regions compared to the baselines. Moreover, our closest sample to the ground truth has ∼40% lower MSE than the singular reconstructions by existing approaches.
Code and data available at: https://github.com/human-analysis/diverse3dface
Single image-based 3D face reconstruction has improved significantly in recent years [9, 54]. This includes advances in statistical models [3,21,26,27] as well as neural network-based models [11, 12, 33, 38–41, 45, 46]. However, facial occlusions remain a significant challenge to this task. In-the-wild face images often come with several forms of oc-clusions and unless dealt with explicitly, often lead to er-roneous 3D reconstruction in terms of shape, expression, pose, etc. [8, 9, 42]. 3D reconstruction of partially occluded faces presents two main challenges. First, 3D reconstruction models need to selectively use features from the visible regions while ig-noring those from the occluded parts. Failure to do so, ei-ther implicitly or explicitly, will lead to poor 3D reconstruc-tions with an incorrect pose, expression, or both. Second, there could be a distribution of 3D reconstructions that are consistent with the visible parts in the image yet diverse on the occluded parts. Failure to account for all such modes limits the utility of 3D reconstruction models. Addressing these two challenges is the primary goal of this paper.
Existing 3D face reconstruction solutions, however, are ill-equipped to overcome both of these challenges simul-taneously. From a reconstruction perspective, a major-ity of the approaches that reconstruct 3D faces from a sin-gle image restrict themselves to fully-visible face images.
And, even those that explicitly account for facial occlu-sions [8, 42], do so only in a holistic manner using a global model that implicitly uses features from the occluded re-gions as well. This form of global model-based fitting can introduce errors (see Fig. 1) in the pose and expression of the 3D reconstruction, especially when large portions of the face are occluded. From a diversity perspective, existing approaches are, by design, limited to only generating a sin-gle plausible 3D reconstruction. However, in many practical applications, for a single occluded face image, it is desir-able to generate multiple reconstructions that are consistent on the visible parts of the face, while spanning a diverse yet realistic set of reconstructions on the occluded parts (see
Fig. 1). While the concept of generating diverse solutions has been explored in other contexts such as image genera-tion [10], image completion [51], super-resolution [1] and trajectory forecasting [49], they have not been explored for monocular 3D face reconstruction of occluded faces.
In this paper, we propose Diverse3DFace which is de-signed to simultaneously yield a diverse, yet plausible, set of 3D reconstructions from a single occluded face image.
Diverse3DFace consists of three modules: a global + local shape fitting process, a graph neural network based varia-tional autoencoder (Mesh-VAE), and a Determinantal Point
Process (DPP) [20] based iterative optimization procedure.
The global + local shape fitting process affords robustness against large occlusions by decoupling shape fitting on the visible regions from that of the occluded regions. The
Mesh-VAE enables to learn a distribution over a compact latent space over the different factors of variation in the 3D shapes of faces. And, the DPP-based iterative optimization procedure enables us to sample from the latent space of the
Mesh-VAE and optimize them to generate a diverse set of reconstructions spanning the different modes of the latent space. Our specific contributions in this paper are: – We propose Diverse3DFace, a simple yet effective diver-sity promoting 3D face reconstruction approach that gener-ates multiple plausible 3D reconstructions corresponding to a single occluded face image. – For robustness to occlusions, we propose a global+local
PCA model-based shape fitting that disentangles the fitting on each facial component from the others. The models are learned from a dataset of FLAME [21] registered 3D meshes. During inference, the local perturbations on vari-ous facial components are added on top of a coarse global fit to generate the final detailed fitting. – We employ a DPP [20] based diversity loss in the con-text of generating diverse 3D reconstructions of faces. We define the quality and similarity terms in the DPP kernel to maximize diversity while remaining in the space of realistic 3D head shapes. – We conduct extensive qualitative and quantitative exper-iments to show the efficacy of the proposed approach in generating 3D reconstructions that are faithful to the visible face while simultaneously capturing multiple diverse modes on the occluded parts. The solution from Diverse3DFace that is closest to the ground truth is on average 30-50% better than the unique solutions of the baselines [11, 21] in terms of per-vertex ℓ2-error. 2.