Abstract
The existing pose estimation approaches often require a large number of annotated images to attain good estimation performance, which are laborious to acquire. To reduce the human efforts on pose annotations, we propose a novel
Meta Agent Teaming Active Learning (MATAL) framework to actively select and label informative images for effective learning. Our MATAL formulates the image selection pro-cedure as a Markov Decision Process and learns an optimal sampling policy that directly maximizes the performance of the pose estimator based on the reward. Our framework consists of a novel state-action representation as well as a multi-agent team to enable batch sampling in the active learning procedure. The framework could be effectively op-timized via Meta-Optimization to accelerate the adaptation to the gradually expanded labeled data during deployment.
Finally, we show experimental results on both human hand and body pose estimation benchmark datasets and demon-strate that our method signiﬁcantly outperforms all base-lines continuously under the same amount of annotation budget. Moreover, to obtain similar pose estimation accu-racy, our MATAL framework can save around 40% labeling efforts on average compared to state-of-the-art active learn-ing frameworks. 1.

Introduction
Human hand (or body) pose estimation, aiming to lo-calize the positions of speciﬁc key points in images, is an important task that has a wide range of applications such as augmented reality [11], sign language translation [21], and human-robot interaction [40]. Despite the great suc-cess of existing deep learning based pose estimation meth-ods [63, 2, 15, 59, 19, 10, 56], they are notoriously data-hungry. Furthermore, acquiring pose annotation is often
* Corresponding Author very expensive and time-consuming, e.g., annotating a sin-gle image in MPII dataset [1] takes around 40 seconds, which limits the development of large-scale datasets. Ac-cordingly, with the limited scale of the dataset, it is essential to develop algorithms to use data more efﬁciently.
Active learning (AL), which proactively selects the most informative unlabeled images to annotate, is one promising solution to this problem. Recent active learning-based pose estimation frameworks [38, 58, 4, 5, 22] can be categorized into uncertainty-based or distribution-based methods. The uncertainty-based methods [22, 58, 38] query annotations for the samples with the lowest conﬁdence scores. How-ever, as shown in [24], neural networks tend to be over-conﬁdent with unfamiliar samples, leading to overestimated model performance and therefore lowering the labeling ef-ﬁciency. Meanwhile, the distribution-based methods [35, 4] aim to query annotations for representative images from the unlabeled dataset. However, the most representative images w.r.t. the unlabeled set may not always be the most infor-mative ones to the pose estimator, as the estimator may have already learned similar knowledge from earlier samples. As the result, for both types of methods, their image selection strategy does not directly relate to the improvements of the pose estimator, leading to suboptimal performance.
Moreover, these methods suffer in the batch setting, where the active learning algorithm selects multiple images for annotation in one turn. Existing traditional methods
[22, 58] rely on selecting the most informative or represen-tative images to construct a batch, disregarding the redun-dancies in the formed batch. Recently, several works [4, 35] explore the usage of distance-based clustering to identify unique images yet maintain good coverage of the dataset.
However, the adopted clustering algorithms tend to be less effective in the high-dimensional space, leading to less effective sample selection processes during AL iterations
[34]. Therefore, it is important to construct a batch of sam-ples for annotation in an intelligent way, taking care of both the informativeness of each individual image and the overall diversity of the batch.
To address the aforementioned issues in a single end-to-end learning framework, we propose a novel Meta Agent
Teaming Active Learning (MATAL) model for human hand (or body) pose estimation, which leverages an agent team to learn a teaming sampling policy from data. Our main in-sight is that selecting a batch of informative yet diverse im-ages for annotation can be viewed as a teamwork of a set of agents, where each agent in the team selects one image col-laboratively based on the other agents’ decisions. Then this active learning procedure can be formulated as a Markov
Decision Process (MDP) [45], which could be solved with
Reinforcement Learning (RL). The agent team receives a state signal characterizing the distribution of the images in the dataset and cooperatively generates a batch of actions to decide which images should be labeled. To help the agent team to identify informative samples for annotation, we introduce a novel state-action representation by leverag-ing Kinetic Chain Space (KCS) to encode the topological information of the hand (or body) pose. Finally, as the la-beled dataset will expand with the new annotated data, we train our model via meta-learning to facilitate fast adapta-tion to the iteratively enlarged labeled dataset.
In summary, our main contributions are: 1) We for-mulate the pose estimation active learning procedure as a
Markov Decision Process (MDP) and develop a Reinforce-ment Learning (RL) based framework for effective sample selection. 2) To help the learning of the agents, we propose a state-action representation to characterize the informative-ness and representativeness of the samples. 3) We validate the efﬁcacy of the proposed MATAL framework on both human hand and body pose benchmarks. 2.