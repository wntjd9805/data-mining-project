Abstract
Reconstructing an accurate 3D object model from a few image observations remains a challenging problem in com-puter vision. State-of-the-art approaches typically assume accurate camera poses as input, which could be difﬁcult to obtain in realistic settings. In this paper, we present FvOR, a learning-based object reconstruction method that predicts accurate 3D models given a few images with noisy input poses. The core of our approach is a fast and robust multi-view reconstruction algorithm to jointly reﬁne 3D geome-try and camera pose estimation using learnable neural net-work modules. We provide a thorough benchmark of state-of-the-art approaches for this problem on ShapeNet. Our approach achieves best-in-class results. It is also two or-ders of magnitude faster than the recent optimization-based approach IDR [67]. 1.

Introduction
Reconstructing the 3D shape of objects solely from un-registered RGB inputs is a long-standing problem in com-puter vision. One popular pipeline is to integrate Structure-from-Motion (SfM) and Multi-view Stereo (MVS) [24, 35].
A common principle of this popular pipeline is to recover relative camera poses, establish pixel correspondences (ei-ther explicitly or implicitly), and solve triangulation to ob-tain a dense reconstruction. The success of this paradigm relies on dense image coverage to obtain accurate camera poses and correspondences [1, 18, 19, 49]. Enabled by the emergence of large scale 3D datasets that provide shape pri-ors about 3D objects, a recent line of works focus on learn-ing monocular 3D reconstruction [9, 13, 14, 21, 59, 60]. The general idea is to learn multi-scale correlation priors among different regions of geometric shapes, which are used to in-fer complete geometry from partial observations.
Acquiring dense input views is crucial for achieving good 3D reconstruction quality on current pipelines, but it is also a very tedious and not user-friendly process. For in-∗ Experiments are conducted by Z. Yang at The University of Texas at Austin. Email: yzp@utexas.edu
OccNet† [2, 37]
IDR [67]
FvOR (Ours)
Figure 1. Our approach FvOR outperforms state-of-the-art ap-proaches of few-view 3D reconstruction. stance, a casual non-expert user that just began using 3D reconstruction applications (such as creating 3D models of their house), may overlook the strict requirements of cap-turing high-quality dense views.
In this paper, we study the setting of few-view recon-struction [9], which sits between dense-view reconstruction and single-view reconstruction. The promise of this setting is that the input views cover the most of underlying object, and one only needs to ﬁll in a small portion of missing re-gions, a task that is easier to achieve than single-view recon-struction. The ultimate goal is to match the quality of dense reconstruction while signiﬁcantly reducing the number of inputs. While both few-view reconstruction and single-view reconstruction fall into the category of learning-based ap-proaches, the performance of few-view reconstruction re-lies on accurate image poses, which could be challenging to estimate from the input images themselves in realistic scenarios. In dense-view reconstruction, the SfM pipeline estimates image poses by ﬁrst predicting relative camera poses using feature correspondences and then performing synchronization [6, 11] to extract absolute camera poses.
However, this pipeline does not apply to few-view recon-struction as there are only a few images, which makes the
Pose Init
Shape Update
Pose Update
ˆg(x) fi
ˆfi
Cross Image Attention f3D fimage
Levenberg–Marquardt step
Figure 2. Our approach consists of two stages. The ﬁrst stage is pose initialization which predicts an initial pose for each input image. The second stage alternates between shape update and pose update to give an accurate reconstruction with jointly improved camera poses. accurate pose prediction using correspondence difﬁcult.
This paper introduces a novel learning-based approach for joint optimization of the shape reconstruction and the camera poses associated with the input images. The core of our approach consists of a pose initialization module, a shape module, and a pose reﬁnement module. The pose ini-tialization module computes an initial camera pose for each input image. The shape and pose reﬁnement modules are alternated to improve the shape reconstruction and the cam-era poses jointly. We design the pose initialization module using a geometric approach, aiming to reduce outlier pre-dictions of camera poses that are difﬁcult to rectify in pose reﬁnement. The shape module combines the strengths of per-view image features and 3D convolutional features to obtain an accurate implicit 3D reconstruction with shape details. The pose reﬁnement module performs geometric alignments between rendered images and real images in a learned feature space. Both the shape and pose modules are end-to-end trainable. Compared to existing learning-based image pose estimation techniques, our approach uses a dynamically changing 3D reconstruction and geometric constraints, both of which are unavailable in standard end-to-end pose estimation approaches [16, 27, 54, 62]. state-of-the-art
Our approach achieves results on
ShapeNet. The shape reconstruction module also improves upon state-of-the-art approaches under the setting of known camera poses. Due to the efﬁciency of our neural network modules, our approach is two orders of magnitude faster than the recent optimization-based approach IDR [67]. 2.