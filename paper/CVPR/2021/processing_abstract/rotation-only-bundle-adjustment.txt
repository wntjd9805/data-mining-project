We propose a novel method for estimating the global ro-tations of the cameras independently of their positions and the scene structure. When two calibrated cameras observeﬁve or more of the same points, their relative rotation can be recovered independently of the translation. We extend this idea to multiple views, thereby decoupling the rotation es-timation from the translation and structure estimation. Our approach provides several beneﬁts such as complete immu-nity to inaccurate translations and structure, and the accu-racy improvement when used with rotation averaging. We perform extensive evaluations on both synthetic and real datasets, demonstrating consistent and signiﬁcant gains in accuracy when used with the state-of-the-art rotation aver-aging method. 