w/o AugmentationReal-world training data usually exhibits long-tailed dis-tribution, where several majority classes have a signiﬁ-cantly larger number of samples than the remaining mi-nority classes. This imbalance degrades the performance of typical supervised learning algorithms designed for bal-anced training sets. In this paper, we address this issue by augmenting minority classes with a recently proposed im-plicit semantic data augmentation (ISDA) algorithm [37], which produces diversiﬁed augmented samples by translat-ing deep features along many semantically meaningful di-rections. Importantly, given that ISDA estimates the class-conditional statistics to obtain semantic directions, we ﬁnd it ineffective to do this on minority classes due to the insuf-ﬁcient training data. To this end, we propose a novel ap-proach to learn transformed semantic directions with meta-learning automatically. In speciﬁc, the augmentation strat-egy during training is dynamically optimized, aiming to minimize the loss on a small balanced validation set, which is approximated via a meta update step. Extensive empirical results on CIFAR-LT-10/100, ImageNet-LT, and iNaturalist 2017/2018 validate the effectiveness of our method. 