Images synthesized by powerful generative adversar-ial network (GAN) based methods have drawn moral and privacy concerns. Although image forensic models have reached great performance in detecting fake images from real ones, these models can be easily fooled with a sim-ple adversarial attack. But, the noise adding adversarial samples are also arousing suspicion.In this paper, in-stead of adding adversarial noise, we optimally search ad-versarial points on face manifold to generate anti-forensic fake face images. We iteratively do a gradient-descent with each small step in the latent space of a generative model, e.g. Style-GAN, to ﬁnd an adversarial latent vector, which is similar to norm-based adversarial attack but in latent space. Then, the generated fake images driven by the ad-versarial latent vectors with the help of GANs can defeat main-stream forensic models. For examples, they make the accuracy of deepfake detection models based on Xception or EfﬁcientNet drop from over 90% to nearly 0%, mean-while maintaining high visual quality. In addition, we ﬁnd manipulating noise vectors n at different levels have differ-ent impacts on attack success rate, and the generated ad-versarial images mainly have changes on facial texture or face attributes. 