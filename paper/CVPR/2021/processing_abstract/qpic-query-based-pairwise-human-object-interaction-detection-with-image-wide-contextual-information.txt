We propose a simple, intuitive yet powerful method for human-object interaction (HOI) detection. HOIs are so diverse in spatial distribution in an image that existingCNN-based methods face the following three major draw-backs; they cannot leverage image-wide features due toCNN’s locality, they rely on a manually deﬁned location-of-interest for the feature aggregation, which sometimes does not cover contextually important regions, and they cannot help but mix up the features for multiple HOI in-stances if they are located closely. To overcome these draw-backs, we propose a transformer-based feature extractor, in which an attention mechanism and query-based detec-tion play key roles. The attention mechanism is effective in aggregating contextually important information image-wide, while the queries, which we design in such a way that each query captures at most one human-object pair, can avoid mixing up the features from multiple instances.This transformer-based feature extractor produces so effec-tive embeddings that the subsequent detection heads may be fairly simple and intuitive. The extensive analysis re-veals that the proposed method successfully extracts con-textually important features, and thus outperforms existing methods by large margins (5.37 mAP on HICO-DET, and 5.6 mAP on V-COCO). The source codes are available at https://github.com/hitachi-rd-cv/qpic. 