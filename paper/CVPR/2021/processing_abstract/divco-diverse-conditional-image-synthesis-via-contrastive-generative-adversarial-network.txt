Class AClass BClass AClass BConditional generative adversarial networks (cGANs) target at synthesizing diverse images given the input condi-tions and latent codes, but unfortunately, they usually suffer from the issue of mode collapse. To solve this issue, previ-ous works [47, 22] mainly focused on encouraging the cor-relation between the latent codes and their generated im-ages, while ignoring the relations between images generat-ed from various latent codes. The recent MSGAN [27] tried to encourage the diversity of the generated image but only considers “negative” relations between the image pairs.In this paper, we propose a novel DivCo framework to properly constrain both “positive” and “negative” rela-tions between the generated images speciﬁed in the latent space. To the best of our knowledge, this is the ﬁrst attemp-t to use contrastive learning for diverse conditional image synthesis. A novel latent-augmented contrastive loss is in-troduced, which encourages images generated from adja-cent latent codes to be similar and those generated from distinct latent codes to be dissimilar. The proposed latent-augmented contrastive loss is well compatible with var-ious cGAN architectures. Extensive experiments demon-strate that the proposed DivCo can produce more diverse images than state-of-the-art methods without sacriﬁcing vi-sual quality in multiple unpaired and paired image genera-tion tasks. Training code and pretrained models are avail-able at https://github.com/ruiliu-ai/DivCo. 