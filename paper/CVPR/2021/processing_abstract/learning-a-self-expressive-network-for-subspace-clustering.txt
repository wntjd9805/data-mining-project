State-of-the-art subspace clustering methods are based on the self-expressive model, which represents each data point as a linear combination of other data points. How-ever, such methods are designed for a ﬁnite sample dataset and lack the ability to generalize to out-of-sample data.Moreover, since the number of self-expressive coefﬁcients grows quadratically with the number of data points, their ability to handle large-scale datasets is often limited.In this paper, we propose a novel framework for subspace clus-tering, termed Self-Expressive Network (SENet), which em-ploys a properly designed neural network to learn a self-expressive representation of the data. We show that ourSENet can not only learn the self-expressive coefﬁcients with desired properties on the training data, but also han-dle out-of-sample data. Besides, we show that SENet can also be leveraged to perform subspace clustering on large-scale datasets. Extensive experiments conducted on syn-thetic data and real world benchmark data validate the ef-fectiveness of the proposed method.In particular, SENet yields highly competitive performance on MNIST, FashionMNIST and Extended MNIST and state-of-the-art perfor-mance on CIFAR-10. 