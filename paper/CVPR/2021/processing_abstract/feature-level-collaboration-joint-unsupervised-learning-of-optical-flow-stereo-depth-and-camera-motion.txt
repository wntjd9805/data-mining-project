Precise estimation of optical ﬂow, stereo depth and cam-era motion are important for the real-world 3D scene un-derstanding and visual perception. Since the three tasks are tightly coupled with the inherent 3D geometric con-straints, current studies have demonstrated that the three tasks can be improved through jointly optimizing geometricIn this pa-loss functions of several individual networks. per, we show that effective feature-level collaboration of the networks for the three respective tasks could achieve much greater performance improvement for all three tasks than only loss-level joint optimization. Speciﬁcally, we propose a single network to combine and improve the three tasks.The network extracts the features of two consecutive stereo images, and simultaneously estimates optical ﬂow, stereo depth and camera motion. The whole network mainly con-tains four parts: (I) a feature-sharing encoder to extract features of input images, which can enhance features’ rep-resentation ability; (II) a pooled decoder to estimate both optical ﬂow and stereo depth; (III) a camera pose estima-tion module which fuses optical ﬂow and stereo depth infor-mation; (IV) a cost volume complement module to improve the performance of optical ﬂow in static and occluded re-gions. Our method achieves state-of-the-art performance among the joint unsupervised methods, including opticalﬂow and stereo depth estimation on KITTI 2012 and 2015 benchmarks, and camera motion estimation on KITTI VO dataset. 