Recent generative models can synthesize “views” of ar-tiﬁcial images that mimic real-world variations, such as changes in color or pose, simply by learning from unla-beled image collections. Here, we investigate whether such views can be applied to real images to beneﬁt downstream analysis tasks such as image classiﬁcation. Using a pre-trained generator, we ﬁrst ﬁnd the latent code correspond-ing to a given real input image. Applying perturbations to the code creates natural variations of the image, which can then be ensembled together at test-time. We use StyleGAN2 as the source of generative augmentations and investigate this setup on classiﬁcation tasks involving facial attributes, cat faces, and cars. Critically, we ﬁnd that several design decisions are required towards making this process work; the perturbation procedure, weighting between the augmen-tations and original image, and training the classiﬁer on synthesized images can all impact the result. Currently, weﬁnd that while test-time ensembling with GAN-based aug-mentations can offer some small improvements, the remain-ing bottlenecks are the efﬁciency and accuracy of the GAN reconstructions, coupled with classiﬁer sensitivities to arti-facts in GAN-generated images. 