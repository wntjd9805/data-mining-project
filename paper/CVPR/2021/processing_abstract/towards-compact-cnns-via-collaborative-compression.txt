Channel pruning and tensor decomposition have re-ceived extensive attention in convolutional neural network compression. However, these two techniques are tradition-ally deployed in an isolated manner, leading to signiﬁcant accuracy drop when pursuing high compression rates. In this paper, we propose a Collaborative Compression (CC) scheme, which joints channel pruning and tensor decom-position to compress CNN models by simultaneously learn-ing the model sparsity and low-rankness. Speciﬁcally, weﬁrst investigate the compression sensitivity of each layer in the network, and then propose a Global CompressionRate Optimization that transforms the decision problem of compression rate into an optimization problem. After that, we propose multi-step heuristic compression to remove re-dundant compression units step-by-step, which fully con-siders the effect of the remaining compression space (i.e., unremoved compression units). Our method demonstrates superior performance gains over previous ones on vari-ous datasets and backbone architectures. For example, we achieve 52.9% FLOPs reduction by removing 48.4% pa-rameters on ResNet-50 with only a Top-1 accuracy drop of 0.56% on ImageNet 2012. 