We tackle the challenging task of image change caption-ing. The goal is to describe the subtle difference between two very similar images by generating a sentence caption.While the recent methods mainly focus on proposing new model architectures for this problem, we instead focus on an alternative training scheme. Inspired by the success of multi-task learning, we formulate a training scheme that uses an auxiliary task to improve the training of the change captioning network. We argue that the task of composed query image retrieval is a natural choice as the auxiliary task. Given two almost similar images as the input, the primary network generates a caption describing the Ô¨Åne change between those two images. Next, the auxiliary net-work is provided with the generated caption and one of those two images.It then tries to pick the second image among a set of candidates. This forces the primary net-work to generate detailed and precise captions via having an extra supervision loss by the auxiliary network. Further-more, we propose a new scheme for selecting a negative set of candidates for the retrieval task that can effectively im-prove the performance. We show that the proposed training strategy performs well on the task of change captioning on benchmark datasets. 