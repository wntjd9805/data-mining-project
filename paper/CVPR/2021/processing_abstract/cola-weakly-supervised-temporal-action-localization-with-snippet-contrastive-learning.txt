Weakly-supervised temporal action localization (WS-TAL) aims to localize actions in untrimmed videos with only video-level labels. Most existing models follow the“localization by classiﬁcation” procedure: locate temporal regions contributing most to the video-level classiﬁcation.Generally, they process each snippet (or frame) individu-ally and thus overlook the fruitful temporal context relation.Here arises the single snippet cheating issue: “hard” snip-pets are too vague to be classiﬁed. In this paper, we argue that learning by comparing helps identify these hard snip-pets and we propose to utilize snippet Contrastive learn-ing to Localize Actions, CoLA for short. Speciﬁcally, we propose a Snippet Contrast (SniCo) Loss to reﬁne the hard snippet representation in feature space, which guides the network to perceive precise temporal boundaries and avoid the temporal interval interruption. Besides, since it is in-feasible to access frame-level annotations, we introduce aHard Snippet Mining algorithm to locate the potential hard snippets. Substantial analyses verify that this mining strat-egy efﬁcaciously captures the hard snippets and SniCo Loss leads to more informative feature representation. Extensive experiments show that CoLA achieves state-of-the-art re-sults on THUMOS’14 and ActivityNet v1.2 datasets. 