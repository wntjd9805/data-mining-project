This paper proposes a framework for the interactive video object segmentation (VOS) in the wild where users can choose some frames for annotations iteratively. Then, based on the user annotations, a segmentation algorithm reÔ¨Ånes the masks. The previous interactive VOS paradigm selects the frame with some worst evaluation metric, and the ground truth is required for calculating the evaluation met-ric, which is impractical in the testing phase. In contrast, in this paper, we advocate that the frame with the worst eval-uation metric may not be exactly the most valuable frame that leads to the most performance improvement across the video. Thus, we formulate the frame selection problem in the interactive VOS as a Markov Decision Process, where an agent is learned to recommend the frame under a deep reinforcement learning framework. The learned agent can automatically determine the most valuable frame, making the interactive setting more practical in the wild. Experi-mental results on the public datasets show the effectiveness of our learned agent without any changes to the underlyingVOS algorithms. Our data, code, and models are available at https://github.com/svip-lab/IVOS-W . 