Non-maximum Suppression (NMS) is an essential post-processing step in modern convolutional neural networks for object detection. Unlike convolutions which are inher-ently parallel, the de-facto standard for NMS, namely Gree-dyNMS, cannot be easily parallelized and thus could be the performance bottleneck in convolutional object detec-tion pipelines. MaxpoolNMS is introduced as a paralleliz-able alternative to GreedyNMS, which in turn enables faster speed than GreedyNMS at comparable accuracy. However,MaxpoolNMS is only capable of replacing the GreedyNMS at the ﬁrst stage of two-stage detectors like Faster-RCNN.There is a signiﬁcant drop in accuracy when applying Max-poolNMS at the ﬁnal detection stage, due to the fact thatMaxpoolNMS fails to approximate GreedyNMS precisely inIn this paper, we pro-terms of bounding box selection. pose a general, parallelizable and conﬁgurable approachPSRR-MaxpoolNMS, to completely replace GreedyNMS at all stages in all detectors. By introducing a simple Re-lationship Recovery module and a Pyramid Shifted Max-poolNMS module, our PSRR-MaxpoolNMS is able to ap-proximate GreedyNMS more precisely than MaxpoolNMS.Comprehensive experiments show that our approach out-performs MaxpoolNMS by a large margin, and it is proven faster than GreedyNMS with comparable accuracy. For theﬁrst time, PSRR-MaxpoolNMS provides a fully paralleliz-able solution for customized hardware design, which can be reused for accelerating NMS everywhere.Figure 1. (Top) Visualized comparison of MaxpoolNMS [2], our method and GreedyNMS at the ﬁnal detection stage of Faster-RCNN. Compared to MaxpoolNMS, our method behaves more like GreedyNMS. (Bottom) Pipeline of PSRR-MaxpoolNMS. Re-lationship Recovery to build up the conﬁdence score maps, fol-lowed by Pyramid Shifted MaxpoolNMS to eliminate overlapped boxes and only keep the boxes with peak scores. Each cell on the map encodes the conﬁdence score, scale/ratio (C) and spatial location (X, Y ) of bounding boxes. 