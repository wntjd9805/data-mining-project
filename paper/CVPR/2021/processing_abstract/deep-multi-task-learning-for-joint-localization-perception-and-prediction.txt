Over the last few years, we have witnessed tremendous progress on many subtasks of autonomous driving includ-ing perception, motion forecasting, and motion planning.However, these systems often assume that the car is accu-rately localized against a high-deﬁnition map. In this paper we question this assumption, and investigate the issues that arise in state-of-the-art autonomy stacks under localization error. Based on our observations, we design a system that jointly performs perception, prediction, and localization.Our architecture is able to reuse computation between the three tasks, and is thus able to correct localization errors efﬁciently. We show experiments on a large-scale autonomy dataset, demonstrating the efﬁciency and accuracy of our proposed approach. 