Single image low light enhancement is an important task and it has many practical applications. Most existing meth-ods adopt a single image approach. Although their per-formance is satisfying on a static single image, we found, however, they suffer serious temporal instability when han-dling low light videos. We notice the problem is because existing data-driven methods are trained from single image pairs where no temporal information is available. Unfortu-nately, training from real temporally consistent data is also problematic because it is impossible to collect pixel-wisely paired low and normal light videos under controlled envi-ronments in large scale and diversities with noise of iden-tical statistics. In this paper, we propose a novel method to enforce the temporal stability in low light video enhance-ment with only static images. The key idea is to learn and in-fer motion ﬁeld (optical ﬂow) from a single image and syn-thesize short range video sequences. Our strategy is gen-eral and can extend to large scale datasets directly. Based on this idea, we propose our method which can infer mo-tion prior for single image low light video enhancement and enforce temporal consistency. Rigorous experiments and user study demonstrate the state-of-the-art performance of our proposed method. Our code and model will be pub-licly available at https://github.com/zkawfanx/StableLLVE. 