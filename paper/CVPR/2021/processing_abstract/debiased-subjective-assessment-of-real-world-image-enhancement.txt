In real-world image enhancement, it is often challeng-ing (if not impossible) to acquire ground-truth data, pre-venting the adoption of distance metrics for objective qual-ity assessment. As a result, one often resorts to subjec-tive quality assessment, the most straightforward and re-liable means of evaluating image enhancement. Conven-tional subjective testing requires manually pre-selecting a small set of visual examples, which may suffer from three sources of biases: 1) sampling bias due to the extremely sparse distribution of the selected samples in the image space; 2) algorithmic bias due to potential overﬁtting the selected samples; 3) subjective bias due to further potential cherry-picking test results. This eventually makes the ﬁeld of real-world image enhancement more of an art than a sci-ence. Here we take steps towards debiasing conventional subjective assessment by automatically sampling a set of adaptive and diverse images for subsequent testing. This is achieved by casting sample selection into a joint maxi-mization of the discrepancy between the enhancers and the diversity among the selected input images. Careful visual inspection on the resulting enhanced images provides a de-biased ranking of the enhancement algorithms. We demon-strate our subjective assessment method using three popu-lar and practically demanding image enhancement tasks: dehazing, super-resolution, and low-light enhancement. 