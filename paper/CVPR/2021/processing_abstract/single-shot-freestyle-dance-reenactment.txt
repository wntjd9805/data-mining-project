The task of motion transfer between a source dancer and a target person is a special case of the pose transfer prob-lem, in which the target person changes their pose in ac-cordance with the motions of the dancer. In this work, we propose a novel method that can reanimate a single im-age by arbitrary video sequences, unseen during training.The method combines three networks: (i) a segmentation-mapping network, (ii) a realistic frame-rendering network, and (iii) a face reﬁnement network. By separating this task into three stages, we are able to attain a novel sequence of realistic frames, capturing natural motion and appearance.Our method obtains signiﬁcantly better visual quality than previous methods and is able to animate diverse body types and appearances, which are captured in challenging poses. 