Human behavior understanding with unmanned aerial vehicles (UAVs) is of great signiﬁcance for a wide range of applications, which simultaneously brings an urgent de-mand of large, challenging, and comprehensive benchmarks for the development and evaluation of UAV-based models.However, existing benchmarks have limitations in terms of the amount of captured data, types of data modalities, cat-egories of provided tasks, and diversities of subjects and environments. Here we propose a new benchmark - UAV-Human - for human behavior understanding with UAVs, which contains 67,428 multi-modal video sequences and 119 subjects for action recognition, 22,476 frames for pose estimation, 41,290 frames and 1,144 identities for person re-identiﬁcation, and 22,263 frames for attribute recogni-tion. Our dataset was collected by a ﬂying UAV in mul-tiple urban and rural districts in both daytime and night-time over three months, hence covering extensive diversities w.r.t subjects, backgrounds, illuminations, weathers, occlu-sions, camera motions, and UAV ﬂying attitudes. Such a comprehensive and challenging benchmark shall be able to promote the research of UAV-based human behavior un-derstanding, including action recognition, pose estimation, re-identiﬁcation, and attribute recognition. Furthermore, we propose a ﬁsheye-based action recognition method that mitigates the distortions in ﬁsheye videos via learning un-bounded transformations guided by ﬂat RGB videos. Exper-iments show the efﬁcacy of our method on the UAV-Human dataset. 