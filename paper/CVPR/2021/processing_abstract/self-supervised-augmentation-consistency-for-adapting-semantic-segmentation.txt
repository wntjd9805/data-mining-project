We propose an approach to domain adaptation for se-mantic segmentation that is both practical and highly ac-curate. In contrast to previous work, we abandon the use of computationally involved adversarial objectives, network ensembles and style transfer. Instead, we employ standard data augmentation techniques – photometric noise, ﬂipping and scaling – and ensure consistency of the semantic pre-dictions across these image transformations. We develop this principle in a lightweight self-supervised framework trained on co-evolving pseudo labels without the need for cumbersome extra training rounds. Simple in training from a practitioner’s standpoint, our approach is remarkably ef-fective. We achieve signiﬁcant improvements of the state-of-the-art segmentation accuracy after adaptation, consistent both across different choices of the backbone architecture and adaptation scenarios. 