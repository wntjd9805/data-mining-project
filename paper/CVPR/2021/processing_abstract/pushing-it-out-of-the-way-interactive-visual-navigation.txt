Interactive_Visual_Navigation.We have observed signiﬁcant progress in visual naviga-tion for embodied agents. A common assumption in study-ing visual navigation is that the environments are static; this is a limiting assumption. Intelligent navigation may involve interacting with the environment beyond just moving for-ward/backward and turning left/right. Sometimes, the best way to navigate is to push something out of the way. In this paper, we study the problem of interactive navigation where agents learn to change the environment to navigate more ef-ﬁciently to their goals. To this end, we introduce the NeuralInteraction Engine (NIE) to explicitly predict the change in the environment caused by the agent’s actions. By model-ing the changes while planning, we ﬁnd that agents exhibit signiﬁcant improvements in their navigational capabilities.More speciﬁcally, we consider two downstream tasks in the physics-enabled, visually rich, AI2-THOR environment: (1) reaching a target while the path to the target is blocked (2) moving an object to a target location by pushing it. For both tasks, agents equipped with an NIE signiﬁcantly outperform agents without the understanding of the effect of the ac-tions indicating the beneﬁts of our approach. The code and dataset are available at github.com/KuoHaoZeng/ 