Fully Unsupervised TrainingA common practice in unsupervised representation learn-ing is to use labeled data to evaluate the quality of the learned representations. This supervised evaluation is then used to guide critical aspects of the training process such as selecting the data augmentation policy. However, guid-ing an unsupervised training process through supervised evaluations is not possible for real-world data that does not actually contain labels (which may be the case, for ex-ample, in privacy sensitive ﬁelds such as medical imaging).Therefore, in this work we show that evaluating the learned representations with a self-supervised image rotation task is highly correlated with a standard set of supervised evalua-tions (rank correlation > 0.94). We establish this correlation across hundreds of augmentation policies, training settings, and network architectures and provide an algorithm (Self-Augment) to automatically and efﬁciently select augmenta-tion policies without using supervised evaluations. Despite not using any labeled data, the learned augmentation poli-cies perform comparably with augmentation policies that were determined using exhaustive supervised evaluations. 