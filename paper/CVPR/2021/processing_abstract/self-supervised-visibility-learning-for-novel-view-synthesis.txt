We address the problem of novel view synthesis (NVS) from a few sparse source view images. Conventional image-based rendering methods estimate scene geometry and syn-thesize novel views in two separate steps. However, erro-neous geometry estimation will decrease NVS performance as view synthesis highly depends on the quality of estimated scene geometry. In this paper, we propose an end-to-endNVS framework to eliminate the error propagation issue.To be speciﬁc, we construct a volume under the target view and design a source-view visibility estimation (SVE) module to determine the visibility of the target-view voxels in each source view. Next, we aggregate the visibility of all source views to achieve a consensus volume. Each voxel in the consensus volume indicates a surface existence probability.Then, we present a soft ray-casting (SRC) mechanism to ﬁnd the most front surface in the target view (i.e., depth). Specif-ically, our SRC traverses the consensus volume along view-ing rays and then estimates a depth probability distribution.We then warp and aggregate source view pixels to synthe-size a novel view based on the estimated source-view visi-bility and target-view depth. At last, our network is trained in an end-to-end self-supervised fashion, thus signiﬁcantly alleviating error accumulation in view synthesis. Experi-mental results demonstrate that our method generates novel views in higher quality compared to the state-of-the-art. 