People touch their face 23 times an hour, they cross their arms and legs, put their hands on their hips, etc.While many images of people contain some form of self-contact, current 3D human pose and shape (HPS) regres-sion methods typically fail to estimate this contact. To ad-dress this, we develop new datasets and methods that sig-niﬁcantly improve human pose estimation with self-contact.First, we create a dataset of 3D Contact Poses (3DCP) con-taining SMPL-X bodies ﬁt to 3D scans as well as poses from AMASS, which we reﬁne to ensure good contact. Sec-ond, we leverage this to create the Mimic-The-Pose (MTP) dataset of images, collected via Amazon Mechanical Turk, containing people mimicking the 3DCP poses with self-contact.Third, we develop a novel HPS optimization method, SMPLify-XMC, that includes contact constraints and uses the known 3DCP body pose during ﬁtting to cre-ate near ground-truth poses for MTP images. Fourth, for more image variety, we label a dataset of in-the-wild im-ages with Discrete Self-Contact (DSC) information and use another new optimization method, SMPLify-DC, that ex-ploits discrete contacts during pose optimization. Finally, we use our datasets during SPIN training to learn a new 3D human pose regressor, called TUCH (Towards Under-standing Contact in Humans). We show that the new self-contact training data signiﬁcantly improves 3D human pose estimates on withheld test data and existing datasets like 3DPW. Not only does our method improve results for self-contact poses, but it also improves accuracy for non-contact poses. The code and data are available for research pur-poses at https://tuch.is.tue.mpg.de. 