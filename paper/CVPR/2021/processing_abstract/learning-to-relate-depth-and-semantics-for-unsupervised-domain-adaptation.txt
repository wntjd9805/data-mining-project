We present an approach for encoding visual task rela-tionships to improve model performance in an Unsuper-vised Domain Adaptation (UDA) setting. Semantic seg-mentation and monocular depth estimation are shown to be complementary tasks; in a multi-task learning setting, a proper encoding of their relationships can further im-prove performance on both tasks. Motivated by this ob-servation, we propose a novel Cross-Task Relation Layer (CTRL), which encodes task dependencies between the se-mantic and depth predictions. To capture the cross-task re-lationships, we propose a neural network architecture that contains task-speciﬁc and cross-task reﬁnement heads. Fur-thermore, we propose an Iterative Self-Learning (ISL) train-ing scheme, which exploits semantic pseudo-labels to pro-vide extra supervision on the target domain. We experi-mentally observe improvements in both tasks’ performance because the complementary information present in these tasks is better captured. Speciﬁcally, we show that: (1) our approach improves performance on all tasks when they are complementary and mutually dependent; (2) the CTRL helps to improve both semantic segmentation and depth es-timation tasks performance in the challenging UDA setting; (3) the proposed ISL training scheme further improves the semantic segmentation performance. The implementation is available at https://github.com/susaha/ctrl-uda. 