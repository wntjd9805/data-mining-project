In this paper, we present a large scale unlabeled per-son re-identiﬁcation (Re-ID) dataset “LUPerson” and make the ﬁrst attempt of performing unsupervised pre-training for improving the generalization ability of the learned personRe-ID feature representation. This is to address the prob-lem that all existing person Re-ID datasets are all of limited scale due to the costly effort required for data annotation.Previous research tries to leverage models pre-trained onImageNet to mitigate the shortage of person Re-ID data but suffers from the large domain gap between ImageNet and person Re-ID data. LUPerson is an unlabeled dataset of 4M images of over 200K identities, which is 30× larger than the largest existing Re-ID dataset.It also covers a much diverse range of capturing environments (e.g., cam-era settings, scenes, etc.). Based on this dataset, we system-atically study the key factors for learning Re-ID features from two perspectives: data augmentation and contrastive loss. Unsupervised pre-training performed on this large-scale dataset effectively leads to a generic Re-ID feature that can beneﬁt all existing person Re-ID methods. Using our pre-trained model in some basic frameworks, our meth-ods achieve state-of-the-art results without bells and whis-tles on four widely used Re-ID datasets: CUHK03, Mar-ket1501, DukeMTMC, and MSMT17. Our results also show that the performance improvement is more signiﬁcant on small-scale target datasets or under few-shot setting. 