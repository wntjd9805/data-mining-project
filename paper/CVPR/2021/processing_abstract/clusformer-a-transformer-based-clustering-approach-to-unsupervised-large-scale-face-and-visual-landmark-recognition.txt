The research in automatic unsupervised visual cluster-ing has received considerable attention over the last cou-ple years.It aims at explaining distributions of unla-beled visual images by clustering them via a parameterized model of appearance. Graph Convolutional Neural Net-works (GCN) have recently been one of the most popular clustering methods. However, it has reached some limita-tions. Firstly, it is quite sensitive to hard or noisy sam-ples. Secondly, it is hard to investigate with various deep network models due to its computational training time. Fi-nally, it is hard to design an end-to-end training model be-tween the deep feature extraction and GCN clustering mod-eling. This work therefore presents the Clusformer, a sim-ple but new perspective of Transformer based approach, to automatic visual clustering via its unsupervised atten-tion mechanism. The proposed method is able to robustly deal with noisy or hard samples. It is also ï¬‚exible and ef-fective to collaborate with different deep network models with various model sizes in an end-to-end framework. The proposed method is evaluated on two popular large-scale visual databases, i.e. Google Landmark and MS-Celeb-1M face database, and outperforms prior unsupervised clustering methods. Code will be available at https://github.com/VinAIResearch/Clusformer 