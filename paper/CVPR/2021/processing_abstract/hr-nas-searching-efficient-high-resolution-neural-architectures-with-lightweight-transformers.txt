High-resolution representations (HR) are essential for dense prediction tasks such as segmentation, detection, and pose estimation. Learning HR representations is typically ignored in previous Neural Architecture Search (NAS) meth-ods that focus on image classiﬁcation. This work proposes a novel NAS method, called HR-NAS, which is able to ﬁnd efﬁcient and accurate networks for different tasks, by ef-fectively encoding multiscale contextual information whileIn HR-NAS, maintaining high-resolution representations. we renovate the NAS search space as well as its search-ing strategy. To better encode multiscale image contexts in the search space of HR-NAS, we ﬁrst carefully design a lightweight transformer, whose computational complexity can be dynamically changed with respect to different objec-tive functions and computation budgets. To maintain high-resolution representations of the learned networks, HR-NAS adopts a multi-branch architecture that provides convolu-tional encoding of multiple feature resolutions, inspired byHRNet [73]. Last, we proposed an efﬁcient ﬁne-grained search strategy to train HR-NAS, which effectively explores the search space, and ﬁnds optimal architectures given var-ious tasks and computation resources. As shown in Fig.1 (a), HR-NAS is capable of achieving state-of-the-art trade-offs between performance and FLOPs for three dense pre-diction tasks and an image classiﬁcation task, given only small computational budgets. For example, HR-NAS sur-passes SqueezeNAS [63] that is specially designed for se-mantic segmentation while improving efﬁciency by 45.9%.Code is available at https://github.com/dingmyu/HR-NAS. 