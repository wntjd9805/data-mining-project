Training deep networks for semantic segmentation re-quires large amounts of labeled training data, which presents a major challenge in practice, as labeling seg-mentation masks is a highly labor-intensive process. To address this issue, we present a framework for semi-supervised semantic segmentation, which is enhanced by self-supervised monocular depth estimation from unlabeled image sequences. In particular, we propose three key con-tributions: (1) We transfer knowledge from features learned during self-supervised depth estimation to semantic seg-mentation, (2) we implement a strong data augmentation by blending images and labels using the geometry of the scene, and (3) we utilize the depth feature diversity as well as the level of difﬁculty of learning depth in a student-teacher framework to select the most useful samples to be annotated for semantic segmentation. We validate the pro-posed model on the Cityscapes dataset, where all three modules demonstrate signiﬁcant performance gains, and we achieve state-of-the-art results for semi-supervised se-mantic segmentation. The implementation is available at https://github.com/lhoyer/improving_segmentation_ with_selfsupervised_depth. 