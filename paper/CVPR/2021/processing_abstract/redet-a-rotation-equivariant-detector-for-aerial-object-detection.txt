Recently, object detection in aerial images has gained much attention in computer vision. Different from objects in natural images, aerial objects are often distributed with arbitrary orientation. Therefore, the detector requires more parameters to encode the orientation information, which are often highly redundant and inefÔ¨Åcient. Moreover, as or-dinary CNNs do not explicitly model the orientation varia-tion, large amounts of rotation augmented data is needed to train an accurate object detector.In this paper, we propose a Rotation-equivariant Detector (ReDet) to ad-dress these issues, which explicitly encodes rotation equiv-ariance and rotation invariance. More precisely, we in-corporate rotation-equivariant networks into the detector to extract rotation-equivariant features, which can accu-rately predict the orientation and lead to a huge reduc-tion of model size. Based on the rotation-equivariant fea-tures, we also present Rotation-invariant RoI Align (RiRoIAlign), which adaptively extracts rotation-invariant features from equivariant features according to the orientation ofRoI. Extensive experiments on several challenging aerial image datasets DOTA-v1.0, DOTA-v1.5 and HRSC2016, show that our method can achieve state-of-the-art perfor-mance on the task of aerial object detection. Compared with previous best results, our ReDet gains 1.2, 3.5 and 2.6 mAP on DOTA-v1.0, DOTA-v1.5 and HRSC2016 re-spectively while reducing the number of parameters by 60% (313 Mb vs. 121 Mb). The code is available at: https://github.com/csuhan/ReDet. 