Real-world videos contain many complex actions with inherent relationships between action classes. In this work, we propose an attention-based architecture that models these action relationships for the task of temporal action localization in untrimmed videos. As opposed to previous works that leverage video-level co-occurrence of actions, we distinguish the relationships between actions that oc-cur at the same time-step and actions that occur at dif-ferent time-steps (i.e. those which precede or follow each other). We deﬁne these distinct relationships as action de-pendencies. We propose to improve action localization per-formance by modeling these action dependencies in a novel attention-based Multi-Label Action Dependency (MLAD) layer. The MLAD layer consists of two branches: a Co-occurrence Dependency Branch and a Temporal Depen-dency Branch to model co-occurrence action dependencies and temporal action dependencies, respectively. We ob-serve that existing metrics used for multi-label classiﬁca-tion do not explicitly measure how well action dependencies are modeled, therefore, we propose novel metrics that con-sider both co-occurrence and temporal dependencies be-tween action classes. Through empirical evaluation and extensive analysis, we show improved performance over state-of-the-art methods on multi-label action localization benchmarks (MultiTHUMOS and Charades) in terms of f-mAP and our proposed metric. Code is publicly available at https://github.com/ptirupat/MLAD. 