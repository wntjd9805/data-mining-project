A fundamental challenge faced by existing Fine-GrainedSketch-Based Image Retrieval (FG-SBIR) models is the data scarcity – model performances are largely bottlenecked by the lack of sketch-photo pairs. Whilst the number of pho-tos can be easily scaled, each corresponding sketch still needs to be individually produced. In this paper, we aim to mitigate such an upper-bound on sketch data, and study whether unlabelled photos alone (of which they are many) can be cultivated for performance gain. In particular, we in-troduce a novel semi-supervised framework for cross-modal retrieval that can additionally leverage large-scale unla-belled photos to account for data scarcity. At the center of our semi-supervision design is a sequential photo-to-sketch generation model that aims to generate paired sketches for unlabelled photos.Importantly, we further introduce a discriminator-guided mechanism to guide against unfaith-ful generation, together with a distillation loss-based regu-larizer to provide tolerance against noisy training samples.Last but not least, we treat generation and retrieval as two conjugate problems, where a joint learning procedure is de-vised for each module to mutually beneﬁt from each other.Extensive experiments show that our semi-supervised model yields a signiﬁcant performance boost over the state-of-the-art supervised alternatives, as well as existing methods that can exploit unlabelled photos for FG-SBIR. 