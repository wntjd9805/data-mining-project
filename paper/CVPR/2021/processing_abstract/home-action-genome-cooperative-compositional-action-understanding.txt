Existing research on action recognition treats activities as monolithic events occurring in videos. Recently, the ben-eÔ¨Åts of formulating actions as a combination of atomic-actions have shown promise in improving action under-standing with the emergence of datasets containing such annotations, allowing us to learn representations capturing this information. However, there remains a lack of studies that extend action composition and leverage multiple view-points and multiple modalities of data for representation learning. To promote research in this direction, we intro-duce Home Action Genome (HOMAGE): a multi-view ac-tion dataset with multiple modalities and view-points sup-plemented with hierarchical activity and atomic action la-bels together with dense scene composition labels. Lever-aging rich multi-modal and multi-view settings, we proposeCooperative Compositional Action Understanding (CCAU), a cooperative learning framework for hierarchical action recognition that is aware of compositional action elements.CCAU shows consistent performance improvements across all modalities. Furthermore, we demonstrate the utility of co-learning compositions in few-shot action recognition by achieving 28.6% mAP with just a single sample. 