In this paper, we present a joint end-to-end line seg-ment detection algorithm using Transformers that is post-processing and heuristics-guided intermediate processing (edge/junction/region detection) free. Our method, namedLinE segment TRansformers (LETR), takes advantages of having integrated tokenized queries, a self-attention mech-anism, and encoding-decoding strategy within Transform-ers by skipping standard heuristic designs for the edge ele-ment detection and perceptual grouping processes. We equipTransformers with a multi-scale encoder/decoder strategy to perform ﬁne-grained line segment detection under a direct endpoint distance loss. This loss term is particularly suitable for detecting geometric structures such as line segments that are not conveniently represented by the standard bounding box representations. The Transformers learn to gradually reﬁne line segments through layers of self-attention. In our experiments, we show state-of-the-art results on Wireframe and YorkUrban benchmarks. 