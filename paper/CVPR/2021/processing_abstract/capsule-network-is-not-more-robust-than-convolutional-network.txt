The Capsule Network is widely believed to be more ro-bust than Convolutional Networks. However, there are no comprehensive comparisons between these two networks, and it is also unknown which components in the CapsNet affect its robustness. In this paper, we ﬁrst carefully exam-ine the special designs in CapsNet that differ from that of a ConvNet commonly used for image classiﬁcation. The examination reveals ﬁve major new/different components in CapsNet: a transformation process, a dynamic rout-ing layer, a squashing function, a marginal loss other than cross-entropy loss, and an additional class-conditional re-construction loss for regularization. Along with these ma-jor differences, we conduct comprehensive ablation studies on three kinds of robustness, including afﬁne transforma-tion, overlapping digits, and semantic representation. The study reveals that some designs, which are thought critical to CapsNet, actually can harm its robustness, i.e., the dy-namic routing layer and the transformation process, while others are beneﬁcial for the robustness. Based on these ﬁnd-ings, we propose enhanced ConvNets simply by introduc-ing the essential components behind the CapsNet’s success.The proposed simple ConvNets can achieve better robust-ness than the CapsNet. 