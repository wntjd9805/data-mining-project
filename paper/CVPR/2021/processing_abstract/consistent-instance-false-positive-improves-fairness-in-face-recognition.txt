Demographic bias is a signiﬁcant challenge in practical face recognition systems. Existing methods heavily rely on accurate demographic annotations. However, such annota-tions are usually unavailable in real scenarios. Moreover, these methods are typically designed for a speciﬁc demo-graphic group and are not general enough. In this paper, we propose a false positive rate penalty loss, which mit-igates face recognition bias by increasing the consistency of instance False Positive Rate (FPR). Speciﬁcally, we ﬁrst deﬁne the instance FPR as the ratio between the number of the non-target similarities above a uniﬁed threshold and the total number of the non-target similarities. The uniﬁed threshold is estimated for a given total FPR. Then, an ad-ditional penalty term, which is in proportion to the ratio of instance FPR overall FPR, is introduced into the denom-inator of the softmax-based loss. The larger the instanceFPR, the larger the penalty. By such unequal penalties, the instance FPRs are supposed to be consistent. Com-pared with the previous debiasing methods, our method re-quires no demographic annotations. Thus, it can mitigate the bias among demographic groups divided by various at-tributes, and these attributes are not needed to be previ-ously predeﬁned during training. Extensive experimental results on popular benchmarks demonstrate the superiority of our method over state-of-the-art competitors. Code and pre-trained models are available at https://github. com/xkx0430/FairnessFR. 