Temporal modeling still remains challenging for action recognition in videos. To mitigate this issue, this paper presents a new video architecture, termed as Temporal Dif-ference Network (TDN), with a focus on capturing multi-scale temporal information for efﬁcient action recognition.The core of our TDN is to devise an efﬁcient temporal mod-ule (TDM) by explicitly leveraging a temporal difference operator, and systematically assess its effect on short-term and long-term motion modeling. To fully capture temporal information over the entire video, our TDN is established with a two-level difference modeling paradigm. Speciﬁcally, for local motion modeling, temporal difference over consec-utive frames is used to supply 2D CNNs with ﬁner motion pattern, while for global motion modeling, temporal differ-ence across segments is incorporated to capture long-range structure for motion feature excitation. TDN provides a sim-ple and principled temporal modeling framework and could be instantiated with the existing CNNs at a small extra com-putational cost. Our TDN presents a new state of the art on the Something-Something V1 & V2 datasets and is on par with the best performance on the Kinetics-400 dataset.In addition, we conduct in-depth ablation studies and plot the visualization results of our TDN, hopefully providing in-sightful analysis on temporal difference modeling. We re-lease the code at https://github.com/MCG-NJU/TDN. 