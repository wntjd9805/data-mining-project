Despite existing pioneering works on sign language translation (SLT), there is a non-trivial obstacle, i.e., the limited quantity of parallel sign-text data. To tackle this parallel data bottleneck, we propose a sign back-translation (SignBT) approach, which incorporates massive spoken language texts into SLT training. With a text-to-gloss trans-lation model, we ﬁrst back-translate the monolingual text to its gloss sequence. Then, the paired sign sequence is gen-erated by splicing pieces from an estimated gloss-to-sign bank at the feature level. Finally, the synthetic parallel data serves as a strong supplement for the end-to-end training of the encoder-decoder SLT framework.To promote the SLT research, we further contribute CSL-It providesDaily, a large-scale continuous SLT dataset. both spoken language translations and gloss-level annota-tions. The topic revolves around people’s daily lives (e.g., travel, shopping, medical care), the most likely SLT applica-tion scenario. Extensive experimental results and analysis of SLT methods are reported on CSL-Daily. With the pro-posed sign back-translation method, we obtain a substantial improvement over previous state-of-the-art SLT methods. 