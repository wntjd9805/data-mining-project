We address the task of converting a ﬂoorplan and a set of associated photos of a residence into a textured 3D mesh model, a task which we call Plan2Scene. Our system 1) lifts a ﬂoorplan image to a 3D mesh model; 2) synthesizes sur-face textures based on the input photos; and 3) infers tex-tures for unobserved surfaces using a graph neural network architecture. To train and evaluate our system we create indoor surface texture datasets, and augment a dataset ofﬂoorplans and photos from prior work with rectiﬁed surface crops and additional annotations. Our approach handles the challenge of producing tileable textures for dominant surfaces such as ﬂoors, walls, and ceilings from a sparse set of unaligned photos that only partially cover the resi-dence. Qualitative and quantitative evaluations show that our system produces realistic 3D interior models, outper-forming baseline approaches on a suite of texture quality metrics and as measured by a holistic user study. 