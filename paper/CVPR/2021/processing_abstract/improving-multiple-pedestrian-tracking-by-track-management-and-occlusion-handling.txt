Multi-pedestrian trackers perform well when targets are clearly visible making the association task quite easy. How-ever, when heavy occlusions are present, a mechanism to re-identify persons is needed. The common approach is to ex-tract visual features from new detections and compare them with the features of previously found tracks. Since those de-tections can have substantial overlaps with nearby targets – especially in crowded scenarios – the extracted features are insufﬁcient for a reliable re-identiﬁcation. In contrast, we propose a novel occlusion handling strategy that explicitly models the relation between occluding and occluded tracks outperforming the feature-based approach, while not de-pending on a separate re-identiﬁcation network. Further-more, we improve the track management of a regression-based method in order to bypass missing detections and to deal with tracks leaving the scene at the border of the image.Finally, we apply our tracker in both temporal directions and merge tracklets belonging to the same target, which fur-ther enhances the performance. We demonstrate the effec-tiveness of our tracking components with ablative experi-ments and surpass the state-of-the-art methods on the three popular pedestrian tracking benchmarks MOT16, MOT17, and MOT20. 