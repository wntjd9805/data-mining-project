Learning low-dimensional latent state space dynam-ics models has proven powerful for enabling vision-based planning and learning for control. We introduce a latent dynamics learning framework that is uniquely designed to induce proportional controlability in the latent space, thus enabling the use of simple and well-known PID controllers. We show that our learned dynamics model enables proportional control from pixels, dramatically simpliÔ¨Åes and accelerates behavioural cloning of vision-based controllers, and provides interpretable goal dis-covery when applied to imitation learning of switching controllers from demonstration. Notably, such propor-tional controlability also allows for robust path following from visual demonstrations using Dynamic MovementPrimitives in the learned latent space. 