Current CNN-based super-resolution (SR) methods pro-cess all locations equally with computational resources be-ing uniformly assigned in space. However, since missing details in low-resolution (LR) images mainly exist in re-gions of edges and textures, less computational resources are required for those ﬂat regions. Therefore, existing CNN-based methods involve redundant computation in ﬂat re-gions, which increases their computational cost and lim-its their applications on mobile devices. In this paper, we explore the sparsity in image SR to improve inference efﬁ-ciency of SR networks. Speciﬁcally, we develop a SparseMask SR (SMSR) network to learn sparse masks to prune redundant computation. Within our SMSR, spatial masks learn to identify “important” regions while channel masks learn to mark redundant channels in those “unimportant” regions. Consequently, redundant computation can be ac-curately localized and skipped while maintaining compa-rable performance.It is demonstrated that our SMSR achieves state-of-the-art performance with 41%/33%/27%FLOPs being reduced for ×2/3/4 SR. Code is available at: https://github.com/LongguangWang/SMSR. 