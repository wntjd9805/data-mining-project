Adversarial robustness corresponds to the susceptibil-ity of deep neural networks to imperceptible perturbations made at test time. In the context of image tasks, many algo-rithms have been proposed to make neural networks robust to adversarial perturbations made to the input pixels. These perturbations are typically measured in an ℓp norm. How-ever, robustness often holds only for the speciﬁc attack used for training. In this work we extend the above setting to con-sider the problem of training of deep neural networks that can be made simultaneously robust to perturbations applied in multiple natural representations spaces. For the case of image data, examples include the standard pixel represen-tation as well as the representation in the discrete cosine transform (DCT) basis. We design a theoretically sound algorithm with formal guarantees for the above problem.Furthermore, our guarantees also hold when the goal is to require robustness with respect to multiple ℓp norm based attacks. We then derive an efﬁcient practical implementa-tion and demonstrate the effectiveness of our approach on standard datasets for image classiﬁcation.1 