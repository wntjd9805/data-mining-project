Sequence label: jump over obstacle=[BABEL, others]Understanding the semantics of human movement – the what, how and why of the movement – is an important prob-lem that requires datasets of human actions with seman-tic labels. Existing datasets take one of two approaches.Large-scale video datasets contain many action labels but do not contain ground-truth 3D human motion. Alterna-tively, motion-capture (mocap) datasets have precise body motions but are limited to a small number of actions. To address this, we present BABEL, a large dataset with lan-guage labels describing the actions being performed in mo-cap sequences. BABEL consists of language labels for over 43 hours of mocap sequences from AMASS, containing over 250 unique actions. Each action label in BABEL is precisely aligned with the duration of the corresponding action in the mocap sequence. BABELalso allows overlap of multiple ac-tions, that may each span different durations. This results in a total of over 66000 action segments. The dense annota-tions can be leveraged for tasks like action recognition, tem-poral localization, motion synthesis, etc. To demonstrate the value of BABEL as a benchmark, we evaluate the per-formance of models on 3D action recognition. We demon-strate that BABEL poses interesting learning challenges that are applicable to real-world scenarios, and can serve as a useful benchmark for progress in 3D action recogni-tion. The dataset, baseline methods, and evaluation code are available and supported for academic research pur-poses at https://babel.is.tue.mpg.de/. 