Domain adaptation (DA) aims to transfer knowledge from a label-rich but heterogeneous domain to a label-scare domain, which alleviates the labeling efforts and attracts considerable attention. Different from previous methods focusing on learning domain-invariant feature representa-tions, some recent methods present generic semi-supervised learning (SSL) techniques and directly apply them to DA tasks, even achieving competitive performance. One of the most popular SSL techniques is pseudo-labeling that as-signs pseudo labels for each unlabeled data via the classiﬁer trained by labeled data. However, it ignores the distribution shift in DA problems and is inevitably biased to source data.To address this issue, we propose a new pseudo-labeling framework called Auxiliary Target Domain-Oriented Clas-siﬁer (ATDOC). ATDOC alleviates the classiﬁer bias by introducing an auxiliary classiﬁer for target data only, to improve the quality of pseudo labels. Speciﬁcally, we em-ploy the memory mechanism and develop two types of non-parametric classiﬁers, i.e. the nearest centroid classiﬁer and neighborhood aggregation, without introducing any addi-tional network parameters. Despite its simplicity in a pseudo classiﬁcation objective, ATDOC with neighborhood aggrega-tion signiﬁcantly outperforms domain alignment techniques and prior SSL techniques on a large variety of DA bench-marks and even scare-labeled SSL tasks. 