Generative adversarial networks (GANs) learn to mapIt is noise latent vectors to high-Ô¨Ådelity image outputs. found that the input latent space shows semantic correla-tions with the output image space. Recent works aim to interpret the latent space and discover meaningful direc-tions that correspond to human interpretable image trans-formations. However, these methods either rely on explicit scores of attributes (e.g., memorability) or are restricted to binary ones (e.g., gender), which largely limits the ap-plicability of editing tasks, especially for free-form artis-In this paper, we pro-tic tasks like style/anime editing. pose an adversarial method, AdvStyle, for discovering in-terpretable directions in the absence of well-labeled scores or binary attributes. In particular, the proposed adversar-ial method simultaneously optimizes the discovered direc-tions and the attribute assessor using the target attribute data as positive samples, while the generated ones being negative.In this way, arbitrary attributes can be edited by collecting positive data only, and the proposed method learns a controllable representation enabling manipulation*Corresponding author (hesfe@scut.edu.cn). of non-binary attributes like anime styles and facial char-acteristics. Moreover, the proposed learning strategy atten-uates the entanglement between attributes, such that multi-attribute manipulation can be easily achieved without any additional constraint. Furthermore, we reveal several in-teresting semantics with the involuntarily learned negative directions. Extensive experiments on 9 anime attributes and 7 human attributes demonstrate the effectiveness of our ad-versarial approach qualitatively and quantitatively. Code is available at https://github.com/BERYLSHEEP/AdvStyle. 