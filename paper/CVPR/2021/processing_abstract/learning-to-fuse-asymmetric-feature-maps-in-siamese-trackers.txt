Recently, Siamese-based trackers have achieved promis-ing performance in visual tracking. Most recent Siamese-based trackers typically employ a depth-wise cross-correlation (DW-XCorr) to obtain multi-channel correla-tion information from the two feature maps (target and search region). However, DW-XCorr has several limitations within Siamese-based tracking: it can easily be fooled by distractors, has fewer activated channels and provides weak discrimination of object boundaries. Further, DW-XCorr is a handcrafted parameter-free module and cannot fully ben-eﬁt from ofﬂine learning on large-scale data.We propose a learnable module, called the asymmetric convolution (ACM), which learns to better capture the se-mantic correlation information in ofﬂine training on large-scale data. Different from DW-XCorr and its predecessor (XCorr), which regard a single feature map as the convo-lution kernel, our ACM decomposes the convolution oper-ation on a concatenated feature map into two mathemati-cally equivalent operations, thereby avoiding the need for the feature maps to be of the same size (width and height) during concatenation. Our ACM can incorporate useful prior information, such as bounding-box size, with stan-dard visual features. Furthermore, ACM can easily be inte-grated into existing Siamese trackers based on DW-XCorr or XCorr. To demonstrate its generalization ability, we in-tegrate ACM into three representative trackers: SiamFC,SiamRPN++ and SiamBAN. Our experiments reveal the beneﬁts of the proposed ACM, which outperforms existing methods on six tracking benchmarks. On the LaSOT test set, our ACM-based tracker obtains a signiﬁcant improve-ment of 5.8% in terms of success (AUC), over the baseline. 