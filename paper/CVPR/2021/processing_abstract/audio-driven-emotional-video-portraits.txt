Despite previous success in generating audio-driven talking heads, most of the previous studies focus on the cor-relation between speech content and the mouth shape. Fa-cial emotion, which is one of the most important features on natural human faces, is always neglected in their methods.∗Corresponding authors.In this work, we present Emotional Video Portraits (EVP), a system for synthesizing high-quality video portraits with vivid emotional dynamics driven by audios. Speciﬁcally, we propose the Cross-Reconstructed Emotion Disentanglement technique to decompose speech into two decoupled spaces, i.e., a duration-independent emotion space and a duration-dependent content space. With the disentangled features, dynamic 2D emotional facial landmarks can be deduced.Then we propose the Target-Adaptive Face Synthesis tech-14080nique to generate the ﬁnal high-quality video portraits, by bridging the gap between the deduced landmarks and the natural head poses of target videos. Extensive experiments demonstrate the effectiveness of our method both qualita-tively and quantitatively.1 