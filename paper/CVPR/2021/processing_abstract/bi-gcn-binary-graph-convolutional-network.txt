Graph Neural Networks (GNNs) have achieved tremen-dous success in graph representation learning. Unfortu-nately, current GNNs usually rely on loading the entire at-tributed graph into network for processing. This implicit assumption may not be satisﬁed with limited memory re-sources, especially when the attributed graph is large. In this paper, we pioneer to propose a Binary Graph Convo-lutional Network (Bi-GCN), which binarizes both the net-work parameters and input node features. Besides, the orig-inal matrix multiplications are revised to binary operations for accelerations. According to the theoretical analysis, ourBi-GCN can reduce the memory consumption by an aver-age of ∼30x for both the network parameters and input data, and accelerate the inference speed by an average of∼47x, on the citation networks. Meanwhile, we also de-sign a new gradient approximation based back-propagation method to train our Bi-GCN well. Extensive experiments have demonstrated that our Bi-GCN can give a compara-ble performance compared to the full-precision baselines.Besides, our binarization approach can be easily applied to other GNNs, which has been veriﬁed in the experiments. 