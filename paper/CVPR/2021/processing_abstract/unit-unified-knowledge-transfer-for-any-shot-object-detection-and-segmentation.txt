Methods for object detection and segmentation rely on large scale instance-level annotations for training, which are difﬁcult and time-consuming to collect. Efforts to allevi-ate this look at varying degrees and quality of supervision.Weakly-supervised approaches draw on image-level labels to build detectors/segmentors, while zero/few-shot methods as-sume abundant instance-level data for a set of base classes, and none to a few examples for novel classes. This taxonomy has largely siloed algorithmic designs. In this work, we aim to bridge this divide by proposing an intuitive and uniﬁed semi-supervised model that is applicable to a range of super-vision: from zero to a few instance-level samples per novel class. For base classes, our model learns a mapping from weakly-supervised to fully-supervised detectors/segmentors.By learning and leveraging visual and lingual similarities be-tween the novel and base classes, we transfer those mappings to obtain detectors/segmentors for novel classes; reﬁning them with a few novel class instance-level annotated sam-ples, if available. The overall model is end-to-end trainable and highly ﬂexible1. Through extensive experiments on MS-COCO [32] and Pascal VOC [14] benchmark datasets we show improved performance in a variety of settings. 