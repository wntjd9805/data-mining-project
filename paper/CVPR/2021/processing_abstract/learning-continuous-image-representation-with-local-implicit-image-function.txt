How to represent an image? While the visual world is presented in a continuous manner, machines store and see the images in a discrete way with 2D arrays of pixels. In this paper, we seek to learn a continuous representation for images. Inspired by the recent progress in 3D reconstruc-tion with implicit neural representation, we propose LocalImplicit Image Function (LIIF), which takes an image co-ordinate and the 2D deep features around the coordinate as inputs, predicts the RGB value at a given coordinate as an output. Since the coordinates are continuous, LIIF can be presented in arbitrary resolution. To generate the contin-uous representation for images, we train an encoder withLIIF representation via a self-supervised task with super-resolution. The learned continuous representation can be presented in arbitrary resolution even extrapolate to ⇥30 higher resolution, where the training tasks are not provided.We further show that LIIF representation builds a bridge between discrete and continuous representation in 2D, it naturally supports the learning tasks with size-varied im-age ground-truths and signiﬁcantly outperforms the method with resizing the ground-truths. Our project page with code is at https://yinboc.github.io/liif/. 