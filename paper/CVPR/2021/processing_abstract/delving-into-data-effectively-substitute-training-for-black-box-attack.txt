Deep models have shown their vulnerability when pro-cessing adversarial samples. As for the black-box attack, without access to the architecture and weights of the at-tacked model, training a substitute model for adversarial attacks has attracted wide attention. Previous substitute training approaches focus on stealing the knowledge of the target model based on real training data or synthetic data, without exploring what kind of data can further improve the transferability between the substitute and target mod-els. In this paper, we propose a novel perspective substitute training that focuses on designing the distribution of data used in the knowledge stealing process. More speciﬁcally, a diverse data generation module is proposed to synthe-size large-scale data with wide distribution. And adversar-ial substitute training strategy is introduced to focus on the data distributed near the decision boundary. The combina-tion of these two modules can further boost the consistency of the substitute model and target model, which greatly im-proves the effectiveness of adversarial attack. Extensive ex-periments demonstrate the efﬁcacy of our method against state-of-the-art competitors under non-target and target at-tack settings. Detailed visualization and analysis are also provided to help understand the advantage of our method. 