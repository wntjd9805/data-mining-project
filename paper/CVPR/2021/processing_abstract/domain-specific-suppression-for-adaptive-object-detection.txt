Domain adaptation methods face performance degrada-tion in object detection, as the complexity of tasks require more about the transferability of the model. We propose a new perspective on how CNN models gain the transfer-ability, viewing the weights of a model as a series of mo-tion patterns. The directions of weights, and the gradients, can be divided into domain-speciﬁc and domain-invariant parts, and the goal of domain adaptation is to concentrate on the domain-invariant direction while eliminating the dis-turbance from domain-speciﬁc one. Current UDA object de-tection methods view the two directions as a whole while op-timizing, which will cause domain-invariant direction mis-match even if the output features are perfectly aligned. In this paper, we propose the domain-speciﬁc suppression, an exemplary and generalizable constraint to the original con-volution gradients in backpropagation to detach the two parts of directions and suppress the domain-speciﬁc one.We further validate our theoretical analysis and methods on several domain adaptive object detection tasks, includ-ing weather, camera conﬁguration, and synthetic to real-world adaptation. Our experiment results show signiﬁcant advance over the state-of-the-art methods in the UDA object detection ﬁeld, performing a promotion of 10.2 12.2% mAP on all these domain adaptation scenarios.∼ 