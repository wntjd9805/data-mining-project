Synthetic training datasetMulti-view crowd counting has been previously proposed to utilize multi-cameras to extend the ﬁeld-of-view of a sin-gle camera, capturing more people in the scene, and im-prove counting performance for occluded people or those in low resolution. However, the current multi-view paradigm trains and tests on the same single scene and camera-views, which limits its practical application.In this paper, we propose a cross-view cross-scene (CVCS) multi-view crowd counting paradigm, where the training and testing occur on different scenes with arbitrary camera layouts. To dynam-ically handle the challenge of optimal view fusion under scene and camera layout change and non-correspondence noise due to camera calibration errors or erroneous fea-tures, we propose a CVCS model that attentively selects and fuses multiple views together using camera layout ge-ometry, and a noise view regularization method to train the model to handle non-correspondence errors. We also gener-ate a large synthetic multi-camera crowd counting dataset with a large number of scenes and camera views to capture many possible variations, which avoids the difﬁculty of col-lecting and annotating such a large real dataset. We then test our trained CVCS model on real multi-view counting datasets, by using unsupervised domain transfer. The pro-posed CVCS model trained on synthetic data outperforms the same model trained only on real data, and achieves promising performance compared to fully supervised meth-ods that train and test on the same single scene. 