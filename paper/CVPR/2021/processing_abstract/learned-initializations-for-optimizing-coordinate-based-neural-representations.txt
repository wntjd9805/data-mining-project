Coordinate-based neural representations have shown signiﬁcant promise as an alternative to discrete, array-based representations for complex low dimensional signals.However, optimizing a coordinate-based network from ran-domly initialized weights for each new signal is inefﬁcient.We propose applying standard meta-learning algorithms to learn the initial weight parameters for these fully-connected networks based on the underlying class of signals being rep-resented (e.g., images of faces or 3D models of chairs). De-spite requiring only a minor change in implementation, us-ing these learned initial weights enables faster convergence during optimization and can serve as a strong prior over the signal class being modeled, resulting in better gener-alization when only partial observations of a given signal are available. We explore these beneﬁts across a variety of tasks, including representing 2D images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D image observations. 