Automatically detecting/segmenting object(s) that blend in with their surroundings is difﬁcult for current mod-els. A major challenge is that the intrinsic similarities be-tween such foreground objects and background surround-ings make the features extracted by deep model indistin-guishable. To overcome this challenge, an ideal model should be able to seek valuable, extra clues from the given scene and incorporate them into a joint learning frame-work for representation co-enhancement. With this inspi-ration, we design a novel Mutual Graph Learning (MGL) model, which generalizes the idea of conventional mutual learning from regular grids to the graph domain. Speciﬁ-cally, MGL decouples an image into two task-speciﬁc fea-ture maps — one for roughly locating the target and the other for accurately capturing its boundary details — and fully exploits the mutual beneﬁts by recurrently reasoningImportantly, their high-order relations through graphs. in contrast to most mutual learning approaches that use a shared function to model all between-task interactions,MGL is equipped with typed functions for handling differ-ent complementary relations to maximize information in-teractions. Experiments on challenging datasets, includingCHAMELEON, CAMO and COD10K, demonstrate the ef-fectiveness of our MGL with superior performance to exist-ing state-of-the-art methods. Code is available at https://github.com/fanyang587/MGL. 