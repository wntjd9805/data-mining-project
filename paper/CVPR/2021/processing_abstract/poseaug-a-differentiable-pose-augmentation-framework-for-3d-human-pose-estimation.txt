Source dataset: H36MCross dataset: 3DHPExisting 3D human pose estimators suffer poor gener-alization performance to new datasets, largely due to the limited diversity of 2D-3D pose pairs in the training data.To address this problem, we present PoseAug, a new auto-augmentation framework that learns to augment the avail-able training poses towards a greater diversity and thus im-prove generalization of the trained 2D-to-3D pose estima-tor. Speciﬁcally, PoseAug introduces a novel pose augmen-tor that learns to adjust various geometry factors (e.g., pos-ture, body size, view point and position) of a pose through differentiable operations. With such differentiable capacity, the augmentor can be jointly optimized with the 3D pose estimator and take the estimation error as feedback to gen-erate more diverse and harder poses in an online manner.Moreover, PoseAug introduces a novel part-aware Kine-matic Chain Space for evaluating local joint-angle plausi-bility and develops a discriminative module accordingly to ensure the plausibility of the augmented poses. These elab-orate designs enable PoseAug to generate more diverse yet plausible poses than existing ofﬂine augmentation methods, and thus yield better generalization of the pose estimator.PoseAug is generic and easy to be applied to various 3D pose estimators. Extensive experiments demonstrate thatPoseAug brings clear improvements on both intra-scenario and cross-scenario datasets. Notably, it achieves 88.6% 3D PCK on MPI-INF-3DHP under cross-dataset evalua-tion setup, improving upon the previous best data augmen-tation based method [22] by 9.1%. Code can be found at: https://github.com/jfzhang95/PoseAug. 