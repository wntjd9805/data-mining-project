Constructing and maintaining a consistent scene model on-the-ﬂy is the core task for online spatial perception, in-terpretation, and action.In this paper, we represent the scene with a Bayesian nonparametric mixture model, seam-lessly describing per-point occupancy status with a contin-uous probability density function. Instead of following the conventional data fusion paradigm, we address the problem of online learning the process how sequential point cloud data are generated from the scene geometry. An incremen-tal and parallel inference is performed to update the pa-rameter space in real-time. We experimentally show that the proposed representation achieves state-of-the-art accu-racy with promising efﬁciency. The consistent probabilistic formulation assures a generative model that is adaptive to different sensor characteristics, and the model complexity can be dynamically adjusted on-the-ﬂy according to differ-ent data scales. 