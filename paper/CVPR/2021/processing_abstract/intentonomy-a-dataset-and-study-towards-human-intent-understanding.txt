An image is worth a thousand words, conveying infor-mation that goes beyond the mere visual content therein. In this paper, we study the intent behind social media images with an aim to analyze how visual information can facil-itate recognition of human intent. Towards this goal, we introduce an intent dataset, Intentonomy, comprising 14K images covering a wide range of everyday scenes. These images are manually annotated with 28 intent categories derived from a social psychology taxonomy. We then sys-tematically study whether, and to what extent, commonly used visual information, i.e., object and context, contribute to human motive understanding. Based on our ﬁndings, we conduct further study to quantify the effect of attending to object and context classes as well as textual information in the form of hashtags when training an intent classiﬁer. Our results quantitatively and qualitatively shed light on how vi-sual and textual information can produce observable effects when predicting intent.1 