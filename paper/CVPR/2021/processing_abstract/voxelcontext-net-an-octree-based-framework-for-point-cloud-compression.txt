In this paper, we propose a two-stage deep learning framework called VoxelContext-Net for both static and dy-namic point cloud compression. Taking advantages of both octree based methods and voxel based schemes, our ap-proach employs the voxel context to compress the octree structured data. Speciﬁcally, we ﬁrst extract the local voxel representation that encodes the spatial neighbouring con-text information for each node in the constructed octree.Then, in the entropy coding stage, we propose a voxel con-text based deep entropy model to compress the symbols of non-leaf nodes in a lossless way. Furthermore, for dynamic point cloud compression, we additionally introduce the lo-cal voxel representations from the temporal neighbouring point clouds to exploit temporal dependency. More impor-tantly, to alleviate the distortion from the octree construc-tion procedure, we propose a voxel context based 3D co-ordinate reﬁnement method to produce more accurate re-constructed point cloud at the decoder side, which is appli-cable to both static and dynamic point cloud compression.The comprehensive experiments on both static and dynamic point cloud benchmark datasets(e.g., ScanNet and SemanticKITTI) clearly demonstrate the effectiveness of our newly proposed method VoxelContext-Net for 3D point cloud ge-ometry compression. 