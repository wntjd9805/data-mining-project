Video deblurring models exploit consecutive frames to remove blurs from camera shakes and object motions. In order to utilize neighboring sharp patches, typical meth-ods rely mainly on homography or optical ﬂows to spatially align neighboring blurry frames. However, such explicit ap-proaches are less effective in the presence of fast motions with large pixel displacements. In this work, we propose a novel implicit method to learn spatial correspondence among blurry frames in the feature space. To construct dis-tant pixel correspondences, our model builds a correlation volume pyramid among all the pixel-pairs between neigh-boring frames. To enhance the features of the reference frame, we design a correlative aggregation module that maximizes the pixel-pair correlations with its neighbors based on the volume pyramid. Finally, we feed the aggre-gated features into a reconstruction module to obtain the re-stored frame. We design a generative adversarial paradigm to optimize the model progressively. Our proposed method is evaluated on the widely-adopted DVD dataset, along with∗ Authors contributed equally.† Corresponding author: kaihao.zhang@anu.edu.au. a newly collected High-Frame-Rate (1000 fps) Dataset forVideo Deblurring (HFR-DVD). Quantitative and qualita-tive experiments show that our model performs favorably on both datasets against previous state-of-the-art methods, conﬁrming the beneﬁt of modeling all-range spatial corre-spondence for video deblurring. 