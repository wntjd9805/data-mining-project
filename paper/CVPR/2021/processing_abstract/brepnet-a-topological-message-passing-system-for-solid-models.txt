Boundary representation (B-rep) models are the stan-dard way 3D shapes are described in Computer-Aided De-sign (CAD) applications. They combine lightweight para-metric curves and surfaces with topological information which connects the geometric entities to describe mani-folds. In this paper we introduce BRepNet, a neural net-work architecture designed to operate directly on B-rep data structures, avoiding the need to approximate the model as meshes or point clouds. BRepNet deﬁnes convolutional kernels with respect to oriented coedges in the data struc-ture.In the neighborhood of each coedge, a small col-lection of faces, edges and coedges can be identiﬁed and patterns in the feature vectors from these entities detected by speciﬁc learnable parameters. In addition, to encour-age further deep learning research with B-reps, we pub-lish the Fusion 360 Gallery segmentation dataset. A col-lection of over 35,000 B-rep models annotated with infor-mation about the modeling operations which created each face. We demonstrate that BRepNet can segment these mod-els with higher accuracy than methods working on meshes, and point clouds.Figure 1: BRepNet convolutional kernels are deﬁned with respect to topological entities called coedges (dashed ar-rows). Feature vectors from a small collection of faces (grey), edges (black) and coedges (blue) adjacent to each coedge (red) are multiplied by the learnable parameters in the kernel. The hidden states arising from the convolution can then be pooled to perform face segmentation. 