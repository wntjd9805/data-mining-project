Sample 1Sample 2Sample 3Generative modeling of set-structured data, such as point clouds, requires reasoning over local and global structures at various scales. However, adopting multi-scale frameworks for ordinary sequential data to a set-structured data is nontrivial as it should be invariant to the permu-tation of its elements. In this paper, we propose SetVAE, a hierarchical variational autoencoder for sets. Motivated by recent progress in set encoding, we build SetVAE upon attentive modules that ﬁrst partition the set and project the partition back to the original cardinality. Exploiting this module, our hierarchical VAE learns latent variables at multiple scales, capturing coarse-to-ﬁne dependency of the set elements while achieving permutation invariance.We evaluate our model on point cloud generation task and achieve competitive performance to the prior arts with sub-stantially smaller model capacity. We qualitatively demon-strate that our model generalizes to unseen set sizes and learns interesting subset relations without supervision. Our implementation is available at https://github.com/ jw9730/setvae. 