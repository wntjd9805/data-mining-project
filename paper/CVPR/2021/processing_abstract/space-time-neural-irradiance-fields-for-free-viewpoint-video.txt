We present a method that learns a spatiotemporal neural ir-radiance ﬁeld for dynamic scenes from a single video. Our learned representation enables free-viewpoint rendering of the input video. Our method builds upon recent advances in implicit representations. Learning a spatiotemporal irradi-ance ﬁeld from a single video poses signiﬁcant challenges because the video contains only one observation of the∗ This work was done while Wenqi was an intern at Facebook. scene at any point in time. The 3D geometry of a scene can be legitimately represented in numerous ways since varying geometry (motion) can be explained with varying appear-ance and vice versa. We address this ambiguity by con-straining the time-varying geometry of our dynamic scene representation using the scene depth estimated from video depth estimation methods, aggregating contents from indi-vidual frames into a single global representation. We pro-vide an extensive quantitative evaluation and demonstrate compelling free-viewpoint rendering results. 9421