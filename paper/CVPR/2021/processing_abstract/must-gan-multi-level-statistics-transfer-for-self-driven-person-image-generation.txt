Pose-guided person image generation usually involves using paired source-target images to supervise the train-ing, which signiﬁcantly increases the data preparation ef-fort and limits the application of the models. To deal with this problem, we propose a novel multi-level statistics trans-fer model, which disentangles and transfers multi-level ap-pearance features from person images and merges them with pose features to reconstruct the source person images themselves. So that the source images can be used as super-vision for self-driven person image generation. Speciﬁcally, our model extracts multi-level features from the appearance encoder and learns the optimal appearance representation through attention mechanism and attributes statistics. Then we transfer them to a pose-guided generator for re-fusion of appearance and pose. Our approach allows for ﬂexible manipulation of person appearance and pose properties to perform pose transfer and clothes style transfer tasks. Ex-perimental results on the DeepFashion dataset demonstrate our method’s superiority compared with state-of-the-art su-pervised and unsupervised methods. In addition, our ap-proach also performs well in the wild. 