In this paper we address multi-target domain adaptation (MTDA), where given one labeled source dataset and mul-tiple unlabeled target datasets that differ in data distribu-tions, the task is to learn a robust predictor for all the tar-get domains. We identify two key aspects that can help to alleviate multiple domain-shifts in the MTDA: feature ag-gregation and curriculum learning. To this end, we pro-pose Curriculum Graph Co-Teaching (CGCT) that uses a dual classiﬁer head, with one of them being a graph con-volutional network (GCN) which aggregates features from similar samples across the domains. To prevent the clas-siﬁers from over-ﬁtting on its own noisy pseudo-labels we develop a co-teaching strategy with the dual classiﬁer head that is assisted by curriculum learning to obtain more re-liable pseudo-labels. Furthermore, when the domain la-bels are available, we propose Domain-aware CurriculumLearning (DCL), a sequential adaptation strategy that ﬁrst adapts on the easier target domains, followed by the harder ones. We experimentally demonstrate the effectiveness of our proposed frameworks on several benchmarks and ad-vance the state-of-the-art in the MTDA by large margins (e.g. +5.6% on the DomainNet). 