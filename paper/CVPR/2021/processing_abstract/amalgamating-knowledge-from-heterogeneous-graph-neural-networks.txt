In this paper, we study a novel knowledge transfer task in the domain of graph neural networks (GNNs). We strive to train a multi-talented student GNN, without accessing hu-man annotations, that “amalgamates” knowledge from a couple of teacher GNNs with heterogeneous architectures and handling distinct tasks. The student derived in this way is expected to integrate the expertise from both teach-ers while maintaining a compact architecture. To this end, we propose an innovative approach to train a slimmableGNN that enables learning from teachers with varying fea-ture dimensions. Meanwhile, to explicitly align topolog-ical semantics between the student and teachers, we in-troduce a topological attribution map (TAM) to highlight the structural saliency in a graph, based on which the stu-dent imitates the teachers’ ways of aggregating informa-tion from neighbors. Experiments on seven datasets across various tasks, including multi-label classiﬁcation and joint segmentation-classiﬁcation, demonstrate that the learned student, with a lightweight architecture, achieves gratifying results on par with and sometimes even superior to those of the teachers in their specializations. Our code is pub-licly available at https://github.com/ycjing/AmalgamateGNN.PyTorch. 