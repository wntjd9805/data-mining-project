OurOnce for AllIn this paper, we propose a feature embedding based video object segmentation (VOS) method which is simple, fast and effective. The current VOS task involves two main challenges: object instance differentiation and cross-frame instance alignment. Most state-of-the-art matching basedVOS methods simplify this task into a binary segmentation task and tackle each instance independently.In contrast, we decompose the VOS task into two subtasks: global em-bedding learning that segments foreground objects of each frame in a pixel-to-pixel manner, and instance feature em-bedding learning that separates instances. The outputs of these two subtasks are fused to obtain the Ô¨Ånal instance masks quickly and accurately. Through using the rela-tion among different instances per-frame as well as tempo-ral relation across different frames, the proposed network learns to differentiate multiple instances and associate them properly in one feed-forward manner. Extensive experi-mental results on the challenging DAVIS [34] and Youtube-VOS [57] datasets show that our method achieves better performances than most counterparts in each case. 