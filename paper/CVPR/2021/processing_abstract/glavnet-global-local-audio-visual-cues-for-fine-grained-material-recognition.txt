In this paper, we aim to recognize materials with com-bined use of auditory and visual perception. To this end, we construct a new dataset named GLAudio that consists of both the geometry of the object being struck and the sound captured from either modal sound synthesis (for vir-tual objects) or real measurements (for real objects). Be-sides global geometries, our dataset also takes local ge-ometries around different hitpoints into consideration. This local information is less explored in existing datasets. We demonstrate that local geometry has a greater impact on the sound than the global geometry and offers more cues in ma-terial recognition. To extract features from different modal-ities and perform proper fusion, we propose a new deep neural network GLAVNet that comprises multiple branches and a well-designed fusion module. Once trained on GLAu-dio, our GLAVNet provides state-of-the-art performance on material identiﬁcation and supports ﬁne-grained material categorization. 