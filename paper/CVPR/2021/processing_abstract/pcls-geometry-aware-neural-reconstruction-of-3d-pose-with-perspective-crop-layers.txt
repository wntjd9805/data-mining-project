Local processing is an essential feature of CNNs and other neural network architectures—it is one of the rea-sons why they work so well on images where relevant in-formation is, to a large extent, local. However, perspec-tive effects stemming from the projection in a conventional camera vary for different global positions in the image.We introduce Perspective Crop Layers (PCLs)—a form of perspective crop of the region of interest based on the camera geometry— and show that accounting for the per-spective consistently improves the accuracy of state-of-the-art 3D pose reconstruction methods. PCLs are modu-lar neural network layers, which, when inserted into ex-isting CNN and MLP architectures, deterministically re-move the location-dependent perspective effects while leav-ing end-to-end training and the number of parameters of the underlying neural network unchanged. We demon-strate that PCL leads to improved 3D human pose recon-struction accuracy for CNN architectures that use cropping operations, such as spatial transformer networks (STN), and, somewhat surprisingly, MLPs used for 2D-to-3D key-point lifting. Our conclusion is that it is important to uti-lize camera calibration information when available, for classical and deep-learning-based computer vision alike.PCL offers an easy way to improve the accuracy of exist-ing 3D reconstruction networks by making them geometry-aware. Our code is publicly available at github.com/yu-frank/PerspectiveCropLayers. 