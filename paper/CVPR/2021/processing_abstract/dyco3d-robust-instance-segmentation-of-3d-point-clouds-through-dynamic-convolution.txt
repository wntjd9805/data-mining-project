Previous top-performing approaches for point cloud in-stance segmentation involve a bottom-up strategy, which often includes inefﬁcient operations or complex pipelines, such as grouping over-segmented components, introducing additional steps for reﬁning, or designing complicated loss functions. The inevitable variation in the instance scales can lead bottom-up methods to become particularly sensi-tive to hyper-parameter values. To this end, we propose in-stead a dynamic, proposal-free, data-driven approach that generates the appropriate convolution kernels to apply in response to the nature of the instances. To make the ker-nels discriminative, we explore a large context by gather-ing homogeneous points that share identical semantic cat-egories and have close votes for the geometric centroids.Instances are then decoded by several simple convolutional layers. Due to the limited receptive ﬁeld introduced by the sparse convolution, a small light-weight transformer is also devised to capture the long-range dependencies and high-level interactions among point samples. The proposed method achieves promising results on both ScanetNetV2 and S3DIS, and this performance is robust to the particular hyper-parameter values chosen. It also improves inference speed by more than 25% over the current state-of-the-art.Code is available at: https://git.io/DyCo3D 