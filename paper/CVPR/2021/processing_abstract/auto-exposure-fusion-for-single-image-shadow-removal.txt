Shadow removal is still a challenging task due to its inher-ent background-dependent1 and spatial-variant properties, leading to unknown and diverse shadow patterns. Even powerful deep neural networks could hardly recover trace-less shadow-removed background. This paper proposes a new solution for this task by formulating it as an exposure fusion problem to address the challenges. Intuitively, weﬁrst estimate multiple over-exposure images w.r.t. the input image to let the shadow regions in these images have the same color with shadow-free areas in the input image. Then, we fuse the original input with the over-exposure images to generate the ﬁnal shadow-free counterpart. Neverthe-less, the spatial-variant property of the shadow requires the fusion to be sufﬁciently ‘smart’, that is, it should auto-matically select proper over-exposure pixels from different images to make the ﬁnal output natural. To address this chal-lenge, we propose the shadow-aware FusionNet that takes the shadow image as input to generate fusion weight maps across all the over-exposure images. Moreover, we propose the boundary-aware ReﬁneNet to eliminate the remaining shadow trace further. We conduct extensive experiments on the ISTD, ISTD+, and SRD datasets to validate our method’s effectiveness and show better performance in shadow re-gions and comparable performance in non-shadow regions over the state-of-the-art methods. We release the code in https://github.com/tsingqguo/exposure-fusion-shadow-removal. 