Learning based video compression attracts increasing attention in the past few years. The previous hybrid coding approaches rely on pixel space operations to reduce spatial and temporal redundancy, which may suffer from inaccu-rate motion estimation or less effective motion compensa-tion. In this work, we propose a feature-space video cod-ing network (FVC) by performing all major operations (i.e., motion estimation, motion compression, motion compensa-tion and residual compression) in the feature space. Specif-ically, in the proposed deformable compensation module, we Ô¨Årst apply motion estimation in the feature space to produce motion information (i.e., the offset maps), which will be compressed by using the auto-encoder style net-work. Then we perform motion compensation by using de-formable convolution and generate the predicted feature.After that, we compress the residual feature between the fea-ture from the current frame and the predicted feature from our deformable compensation module. For better frame reconstruction, the reference features from multiple previ-ous reconstructed frames are also fused by using the non-local attention mechanism in the multi-frame feature fusion module. Comprehensive experimental results demonstrate that the proposed framework achieves the state-of-the-art performance on four benchmark datasets including HEVC,UVG, VTL and MCL-JCV. 