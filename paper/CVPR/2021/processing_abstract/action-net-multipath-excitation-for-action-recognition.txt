Spatial-temporal, channel-wise, and motion patterns are three complementary and crucial types of information for video action recognition. Conventional 2D CNNs are com-putationally cheap but cannot catch temporal relationships; 3D CNNs can achieve good performance but are computa-tionally intensive. In this work, we tackle this dilemma by designing a generic and effective module that can be em-bedded into 2D CNNs. To this end, we propose a spAtio-temporal, Channel and moTion excitatION (ACTION) module consisting of three paths: Spatio-Temporal Excita-tion (STE) path, Channel Excitation (CE) path, and MotionExcitation (ME) path. The STE path employs one chan-nel 3D convolution to characterize spatio-temporal repre-sentation. The CE path adaptively recalibrates channel-wise feature responses by explicitly modeling interdepen-dencies between channels in terms of the temporal aspect.The ME path calculates feature-level temporal differences, which is then utilized to excite motion-sensitive channels.We equip 2D CNNs with the proposed ACTION module to form a simple yet effective ACTION-Net with very limited extra computational cost. ACTION-Net is demonstrated by consistently outperforming 2D CNN counterparts on three backbones (i.e., ResNet-50, MobileNet V2 and BNIncep-tion) employing three datasets (i.e., Something-SomethingV2, Jester, and EgoGesture). Code is provided at https://github.com/V-Sense/ACTION-Net. 