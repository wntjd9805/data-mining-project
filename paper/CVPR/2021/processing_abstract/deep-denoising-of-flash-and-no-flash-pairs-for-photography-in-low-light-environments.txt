We introduce a neural network-based method to denoise pairs of images taken in quick succession, with and with-out a ﬂash, in low-light environments. Our goal is to pro-duce a high-quality rendering of the scene that preserves the color and mood from the ambient illumination of the noisy no-ﬂash image, while recovering surface texture and detail revealed by the ﬂash. Our network outputs a gain map and a ﬁeld of kernels, the latter obtained by linearly mixing elements of a per-image low-rank kernel basis. Weﬁrst apply the kernel ﬁeld to the no-ﬂash image, and then multiply the result with the gain map to create the ﬁnal output. We show our network effectively learns to produce high-quality images by combining a smoothed out estimate of the scene’s ambient appearance from the no-ﬂash image, with high-frequency albedo details extracted from the ﬂash input. Our experiments show signiﬁcant improvements over alternative captures without a ﬂash, and baseline denoisers that use ﬂash no-ﬂash pairs. In particular, our method pro-duces images that are both noise-free and contain accurate ambient colors without the sharp shadows or strong specu-lar highlights visible in the ﬂash image. 