2D_dense correspondence_ 3D image RGB object crd. map  (xyz as RGB) rendered as  point cloudReconstructReprojectObject localization in 3D space is a challenging as-pect in monocular 3D object detection. Recent advances in 6DoF pose estimation have shown that predicting dense 2D-3D correspondence maps between image and object 3D model and then estimating object pose via Perspective-n-Point (PnP) algorithm can achieve remarkable localization accuracy. Yet these methods rely on training with ground truth of object geometry, which is difﬁcult to acquire in real outdoor scenes. To address this issue, we proposeMonoRUn, a novel detection framework that learns dense correspondences and geometry in a self-supervised man-ner, with simple 3D bounding box annotations. To regress the pixel-related 3D object coordinates, we employ a re-gional reconstruction network with uncertainty awareness.For self-supervised training, the predicted 3D coordinates are projected back to the image plane. A Robust KL loss is proposed to minimize the uncertainty-weighted reprojec-tion error. During testing phase, we exploit the network uncertainty by propagating it through all downstream mod-ules. More speciﬁcally, the uncertainty-driven PnP algo-rithm is leveraged to estimate object pose and its covari-ance. Extensive experiments demonstrate that our proposed approach outperforms current state-of-the-art methods onKITTI benchmark.1 