Recent breakthroughs of Neural Architecture Search (NAS) extend the ﬁeld’s research scope towards a broader range of vision tasks and more diversiﬁed search spaces.While existing NAS methods mostly design architectures on a single task, algorithms that look beyond single-task search are surging to pursue a more efﬁcient and universal solution across various tasks. Many of them leverage transfer learn-ing and seek to preserve, reuse, and reﬁne network design knowledge to achieve higher efﬁciency in future tasks. How-ever, the enormous computational cost and experiment com-plexity of cross-task NAS are imposing barriers for valu-able research in this direction. Existing NAS benchmarks all focus on one type of vision task, i.e., classiﬁcation. In this work, we propose TransNAS-Bench-101, a benchmark dataset containing network performance across seven tasks, covering classiﬁcation, regression, pixel-level prediction, and self-supervised tasks. This diversity provides oppor-tunities to transfer NAS methods among tasks and allows for more complex transfer schemes to evolve. We explore two fundamentally different types of search space: cell-level search space and macro-level search space. With 7,352 backbones evaluated on seven tasks, 51,464 trained mod-els with detailed training information are provided. WithTransNAS-Bench-101, we hope to encourage the advent of exceptional NAS algorithms that raise cross-task search ef-ﬁciency and generalizability to the next level. Our dataset and code will be available at Mindspore1 and VEGA2. 