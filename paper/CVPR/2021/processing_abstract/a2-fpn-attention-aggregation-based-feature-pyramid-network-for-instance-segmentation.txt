Learning pyramidal feature representations is crucial for recognizing object instances at different scales. Fea-ture Pyramid Network (FPN) is the classic architecture to build a feature pyramid with high-level semantics through-out. However, intrinsic defects in feature extraction and fu-sion inhibit FPN from further aggregating more discrimi-native features. In this work, we propose Attention Aggre-gation based Feature Pyramid Network (A2-FPN), to im-prove multi-scale feature learning through attention-guided feature aggregation. In feature extraction, it extracts dis-criminative features by collecting-distributing multi-level global context features, and mitigates the semantic infor-mation loss due to drastically reduced channels. In feature fusion, it aggregates complementary information from ad-jacent features to generate location-wise reassembly ker-nels for content-aware sampling, and employs channel-wise reweighting to enhance the semantic consistency be-fore element-wise addition. A2-FPN shows consistent gains on different instance segmentation frameworks. By replac-ing FPN with A2-FPN in Mask R-CNN, our model boosts the performance by 2.1% and 1.6% mask AP when us-ing ResNet-50 and ResNet-101 as backbone, respectively.Moreover, A2-FPN achieves an improvement of 2.0% and 1.4% mask AP when integrated into the strong baselines such as Cascade Mask R-CNN and Hybrid Task Cascade. 