with state-of-the-art methods concerning both attribute and identity ﬁdelity.In this work, we propose a novel two-stage framework named FaceInpainter to implement controllable Identity-Guided Face Inpainting (IGFI) under heterogeneous do-mains. Concretely, by explicitly disentangling foreground and background of the target face, the ﬁrst stage focuses on adaptive face ﬁtting to the ﬁxed background via a StyledFace Inpainting Network (SFI-Net), with 3D priors and tex-ture code of the target, as well as identity factor of the source face.It is challenging to deal with the inconsis-tency between the new identity of the source and the origi-nal background of the target, concerning the face shape and appearance on the fused boundary. The second stage con-sists of a Joint Reﬁnement Network (JR-Net) to reﬁne the swapped face. It leverages AdaIN considering identity and multi-scale texture codes, for feature transformation of the decoded face from SFI-Net with facial occlusions. We adopt the contextual loss to implicitly preserve the attributes, en-couraging face deformation and fewer texture distortions.Experimental results demonstrate that our approach han-dles high-quality identity adaptation to heterogeneous do-mains, exhibiting the competitive performance compared†Corresponding author 