ﬂexibility and interpretability.In this paper, we propose Cluster-wise HierarchicalGenerative Model for deep amortized clustering (CHiGac).It provides an efﬁcient neural clustering architecture by grouping data points in a cluster-wise view rather than point-wise view. CHiGac simultaneously learns what makes a cluster, how to group data points into clusters, and how to adaptively control the number of clusters. The dedicated cluster generative process is able to sufﬁciently exploit pair-wise or higher-order interactions between data points in both inter- and intra-cluster, which is useful to sufﬁciently mine the hidden structure among data. To efﬁciently min-imize the generalized lower bound of CHiGac, we design an Ergodic Amortized Inference (EAI) strategy by consider-ing the average behavior over sequence on an inner varia-tional parameter trajectory, which is theoretically proven to reduce the amortization gap. A series of experiments have been conducted on both synthetic and real-world data.The experimental results demonstrated that CHiGac can ef-ﬁciently and accurately cluster datasets in terms of both in-ternal and external evaluation metrics (DBI and ACC). 