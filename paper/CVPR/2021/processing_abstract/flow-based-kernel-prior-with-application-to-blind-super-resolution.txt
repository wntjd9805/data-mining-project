Kernel estimation is generally one of the key problems for blind image super-resolution (SR). Recently, Double-DIP proposes to model the kernel via a network architec-ture prior, while KernelGAN employs the deep linear net-work and several regularization losses to constrain the ker-nel space. However, they fail to fully exploit the generalSR kernel assumption that anisotropic Gaussian kernels are sufﬁcient for image SR. To address this issue, this paper proposes a normalizing ﬂow-based kernel prior (FKP) for kernel modeling. By learning an invertible mapping be-tween the anisotropic Gaussian kernel distribution and a tractable latent distribution, FKP can be easily used to re-place the kernel modeling modules of Double-DIP and Ker-nelGAN. Speciﬁcally, FKP optimizes the kernel in the la-tent space rather than the network parameter space, which allows it to generate reasonable kernel initialization, tra-verse the learned kernel manifold and improve the optimiza-tion stability. Extensive experiments on synthetic and real-world images demonstrate that the proposed FKP can sig-niﬁcantly improve the kernel estimation accuracy with less parameters, runtime and memory usage, leading to state-of-the-art blind SR results. 