This paper addresses the problem of temporal sen-tence grounding (TSG), which aims to identify the tem-poral boundary of a speciﬁc segment from an untrimmed video by a sentence query. Previous works either compare pre-deﬁned candidate segments with the query and select the best one by ranking, or directly regress the boundary timestamps of the target segment.In this paper, we pro-pose a novel localization framework that scores all pairs of start and end indices within the video simultaneously with a biafﬁne mechanism. In particular, we present a Context-aware Biafﬁne Localizing Network (CBLN) which incorpo-rates both local and global contexts into features of each start/end position for biafﬁne-based localization. The lo-cal contexts from the adjacent frames help distinguish the visually similar appearance, and the global contexts from the entire video contribute to reasoning the temporal rela-tion. Besides, we also develop a multi-modal self-attention module to provide ﬁne-grained query-guided video repre-sentation for this biafﬁne strategy. Extensive experiments show that our CBLN signiﬁcantly outperforms state-of-the-arts on three public datasets (ActivityNet Captions, TACoS, and Charades-STA), demonstrating the effectiveness of the proposed localization framework. The code is available at https://github.com/liudaizong/CBLN. 