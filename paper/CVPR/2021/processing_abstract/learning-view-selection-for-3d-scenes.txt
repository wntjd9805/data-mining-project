EfÔ¨Åcient 3D space sampling to represent an underlying 3D object/scene is essential for 3D vision, robotics, and be-yond. A standard approach is to explicitly sample a dense collection of views and formulate it as a view selection prob-lem, or, more generally, a set cover problem. In this paper, we introduce a novel approach that avoids dense view sam-pling. The key idea is to learn a view prediction network and a trainable aggregation module that takes the predicted views as input and outputs an approximation of their generic scores (e.g., surface coverage, viewing angle from surface normals). This methodology allows us to turn the set cover problem (or multi-view representation optimization) into a continuous optimization problem. We then explain how to effectively solve the induced optimization problem using con-tinuation, i.e., aggregating a hierarchy of smoothed scoring modules. Experimental results show that our approach ar-rives at similar or better solutions with about 10 x speed up in running time, comparing with the standard methods. 