Estimating 3D bounding boxes from monocular images is an essential component in autonomous driving, while ac-curate 3D object detection from this kind of data is very challenging.In this work, by intensive diagnosis experi-ments, we quantify the impact introduced by each sub-task and found the ‘localization error’ is the vital factor in re-stricting monocular 3D detection. Besides, we also investi-gate the underlying reasons behind localization errors, an-alyze the issues they might bring, and propose three strate-gies. First, we revisit the misalignment between the center of the 2D bounding box and the projected center of the 3D object, which is a vital factor leading to low localization ac-curacy. Second, we observe that accurately localizing dis-tant objects with existing technologies is almost impossible, while those samples will mislead the learned network. To this end, we propose to remove such samples from the train-ing set for improving the overall performance of the detec-tor. Lastly, we also propose a novel 3D IoU oriented loss for the size estimation of the object, which is not affected by ‘localization error’. We conduct extensive experiments on the KITTI dataset, where the proposed method achieves real-time detection and outperforms previous methods by a large margin. The code will be made available at: https://github.com/xinzhuma/monodle. 