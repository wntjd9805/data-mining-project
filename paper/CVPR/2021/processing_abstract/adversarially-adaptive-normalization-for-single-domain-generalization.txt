Single domain generalization aims to learn a model that performs well on many unseen domains with only one do-main data for training. Existing works focus on studying the adversarial domain augmentation (ADA) to improve the modelâ€™s generalization capability. The impact on do-main generalization of the statistics of normalization lay-In this paper, we propose ers is still underinvestigated. a generic normalization approach, adaptive standardiza-tion and rescaling normalization (ASR-Norm), to comple-ment the missing part in previous works. ASR-Norm learns both the standardization and rescaling statistics via neural networks. This new form of normalization can be viewed as a generic form of the traditional normalizations. When trained with ADA, the statistics in ASR-Norm are learned to be adaptive to the data coming from different domains, and hence improves the model generalization performance across domains, especially on the target domain with large discrepancy from the source domain. The experimental re-sults show that ASR-Norm can bring consistent improve-ment to the state-of-the-art ADA approaches by 1.6%, 2.7%, and 6.3% averagely on the Digits, CIFAR-10-C, and PACS benchmarks, respectively. As a generic tool, the improve-ment introduced by ASR-Norm is agnostic to the choice ofADA methods. 