Multi-label image classiﬁcation is the task of predicting a set of labels corresponding to objects, attributes or other entities present in an image. In this work we propose theClassiﬁcation Transformer (C-Tran), a general framework for multi-label image classiﬁcation that leverages Trans-formers to exploit the complex dependencies among visual features and labels. Our approach consists of a Trans-former encoder trained to predict a set of target labels given an input set of masked labels, and visual features from a convolutional neural network. A key ingredient of our method is a label mask training objective that uses a ternary encoding scheme to represent the state of the la-bels as positive, negative, or unknown during training. Our model shows state-of-the-art performance on challenging datasets such as COCO and Visual Genome. Moreover, be-cause our model explicitly represents the label state during training, it is more general by allowing us to produce im-proved results for images with partial or extra label anno-tations during inference. We demonstrate this additional ca-pability in the COCO, Visual Genome, News-500, and CUB image datasets. 