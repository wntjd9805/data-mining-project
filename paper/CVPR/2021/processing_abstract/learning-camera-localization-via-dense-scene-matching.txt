Camera localization aims to estimate 6 DoF camera poses from RGB images. Traditional methods detect and match interest points between a query image and a pre-built 3D model. Recent learning-based approaches encode scene structures into a speciﬁc convolutional neural net-work (CNN) and thus are able to predict dense coordi-nates from RGB images. However, most of them require re-training or re-adaption for a new scene and have dif-ﬁculties in handling large-scale scenes due to limited net-work capacity. We present a new method for scene agnos-tic camera localization using dense scene matching (DSM), where a cost volume is constructed between a query image and a scene. The cost volume and the corresponding co-ordinates are processed by a CNN to predict dense coordi-nates. Camera poses can then be solved by PnP algorithms.In addition, our method can be extended to temporal do-main, which leads to extra performance boost during testing time. Our scene-agnostic approach achieves comparable accuracy as the existing scene-speciﬁc approaches, such asKFNet, on the 7scenes and Cambridge benchmark. This ap-proach also remarkably outperforms state-of-the-art scene-agnostic dense coordinate regression network SANet. TheCode is available at https://github.com/Tangshitao/Dense-Scene-Matching. 