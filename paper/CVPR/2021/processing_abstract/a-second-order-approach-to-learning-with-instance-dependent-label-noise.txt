The presence of label noise often misleads the training of deep neural networks. Departing from the recent litera-ture which largely assumes the label noise rate is only deter-mined by the true label class, the errors in human-annotated labels are more likely to be dependent on the difﬁculty lev-els of tasks, resulting in settings with instance-dependent label noise. We ﬁrst provide evidences that the heteroge-neous instance-dependent label noise is effectively down-weighting the examples with higher noise rates in a non-uniform way and thus causes imbalances, rendering the strategy of directly applying methods for class-dependent label noise questionable. Built on a recent work peer loss[24], we then propose and study the potentials of a second-order approach that leverages the estimation of several covariance terms deﬁned between the instance-dependent noise rates and the Bayes optimal label. We show that this set of second-order statistics successfully captures the in-duced imbalances. We further proceed to show that with the help of the estimated second-order statistics, we iden-tify a new loss function whose expected risk of a classiﬁer under instance-dependent label noise is equivalent to a new problem with only class-dependent label noise. This fact allows us to apply existing solutions to handle this better-studied setting. We provide an efﬁcient procedure to es-timate these second-order statistics without accessing ei-ther ground truth labels or prior knowledge of the noise rates. Experiments on CIFAR10 and CIFAR100 with syn-thetic instance-dependent label noise and Clothing1M with real-world human label noise verify our approach. Our im-plementation is available at https://github.com/UCSC-REAL/CAL. 