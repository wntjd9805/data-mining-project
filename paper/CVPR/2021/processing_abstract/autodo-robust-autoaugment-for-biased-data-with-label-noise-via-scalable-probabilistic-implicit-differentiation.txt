AutoAugment [4] has sparked an interest in automated augmentation methods for deep learning models. These methods estimate image transformation policies for train data that improve generalization to test data. While re-cent papers evolved in the direction of decreasing policy search complexity, we show that those methods are not ro-bust when applied to biased and noisy data. To overcome these limitations, we reformulate AutoAugment as a gener-alized automated dataset optimization (AutoDO) task that minimizes the distribution shift between test data and dis-torted train dataset.In our AutoDO model, we explic-itly estimate a set of per-point hyperparameters to ﬂexibly change distribution of train data. In particular, we include hyperparameters for augmentation, loss weights, and soft-labels that are jointly estimated using implicit differentia-tion. We develop a theoretical probabilistic interpretation of this framework using Fisher information and show that its complexity scales linearly with the dataset size. Our exper-iments on SVHN, CIFAR-10/100, and ImageNet classiﬁca-tion show up to 9.3% improvement for biased datasets with label noise compared to prior methods and, importantly, up to 36.6% gain for underrepresented SVHN classes1. 