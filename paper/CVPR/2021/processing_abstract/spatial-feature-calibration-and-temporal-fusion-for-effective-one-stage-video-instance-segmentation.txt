Modern one-stage video instance segmentation networks suffer from two limitations. First, convolutional features are neither aligned with anchor boxes nor with ground-truth bounding boxes, reducing the mask sensitivity to spa-tial location. Second, a video is directly divided into in-dividual frames for frame-level instance segmentation, ig-noring the temporal correlation between adjacent frames.To address these issues, we propose a simple yet effective one-stage video instance segmentation framework by spa-tial calibration and temporal fusion, namely STMask. To ensure spatial feature calibration with ground-truth bound-ing boxes, we Ô¨Årst predict regressed bounding boxes around ground-truth bounding boxes, and extract features from them for frame-level instance segmentation. To further ex-plore temporal correlation among video frames, we aggre-gate a temporal fusion module to infer instance masks from each frame to its adjacent frames, which helps our frame-work to handle challenging videos such as motion blur, partial occlusion and unusual object-to-camera poses. Ex-periments on the YouTube-VIS valid set show that the pro-posed STMask with ResNet-50/-101 backbone obtains 33.5% / 36.8 % mask AP, while achieving 28.6 / 23.4 FPS on video instance segmentation. The code is released online https://github.com/MinghanLi/STMask. 