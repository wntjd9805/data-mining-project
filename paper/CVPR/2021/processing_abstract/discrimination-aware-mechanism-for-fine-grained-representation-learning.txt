Feature EmbeddingOriginal Feature SpaceRecently, with the emergence of retrieval requirements for certain individual in the same superclass, e.g., birds, persons, cars, ﬁne-grained recognition task has attracted a signiﬁcant amount of attention from academia and industry.In ﬁne-grained recognition scenario, the inter-class differ-ences are quite diverse and subtle, which makes it challeng-ing to extract all the discriminative cues. Traditional train-ing mechanism optimizes the overall discriminativeness of the whole feature. It may stop early when some feature ele-ments has been trained to distinguish training samples well, leaving other elements insufﬁciently trained for a feature.This would result in a less generalizable feature extractor that only captures major discriminative cues and ignores subtle ones. Therefore, there is a need for a training mech-anism that enforces the discriminativeness of all the ele-ments in the feature to capture more the subtle visual cues.In this paper, we propose a Discrimination-Aware Mecha-nism (DAM) that iteratively identiﬁes insufﬁciently trained elements and improves them. DAM is able to increase the number of well learned elements, which captures more vi-sual cues by the feature extractor. In this way, a more infor-mative representation is learned, which brings better gen-eralization performance. We show that DAM can be easily applied to both proxy-based and pair-based loss functions, and thus can be used in most existing ﬁne-grained recog-nition paradigms. Comprehensive experiments on CUB-200-2011, Cars196, Market-1501, and MSMT17 datasets demonstrate the advantages of our DAM based loss over the related state-of-the-art approaches. 