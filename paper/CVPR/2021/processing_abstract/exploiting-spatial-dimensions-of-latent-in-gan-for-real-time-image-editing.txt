Generative adversarial networks (GANs) synthesize re-alistic images from random latent vectors. Although ma-nipulating the latent vectors controls the synthesized out-puts, editing real images with GANs suffers from i) time-consuming optimization for projecting real images to the latent vectors, ii) or inaccurate embedding through an en-coder. We propose StyleMapGAN: the intermediate latent space has spatial dimensions, and a spatially variant mod-ulation replaces AdaIN. It makes the embedding through an encoder more accurate than existing optimization-based methods while maintaining the properties of GANs. Exper-imental results demonstrate that our method signiÔ¨Åcantly outperforms state-of-the-art models in various image ma-nipulation tasks such as local editing and image interpo-lation. Last but not least, conventional editing methods onGANs are still valid on our StyleMapGAN. Source code is available at https://github.com/naver-ai/StyleMapGAN . 