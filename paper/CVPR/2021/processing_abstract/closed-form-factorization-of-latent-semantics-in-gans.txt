A rich set of interpretable dimensions has been shown to emerge in the latent space of the Generative AdversarialNetworks (GANs) trained for synthesizing images.In order to identify such latent dimensions for image editing, previous methods typically annotate a collection of syn-thesized samples and train linear classiﬁers in the latent space. However, they require a clear deﬁnition of the target attribute as well as the corresponding manual annotations, limiting their applications in practice.In this work, we examine the internal representation learned by GANs to reveal the underlying variation factors in an unsupervised manner. In particular, we take a closer look into the gen-eration mechanism of GANs and further propose a closed-form factorization algorithm for latent semantic discovery by directly decomposing the pre-trained weights. With a lightning-fast implementation, our approach is capable of not only ﬁnding semantically meaningful dimensions comparably to the state-of-the-art supervised methods, but also resulting in far more versatile concepts across multipleGAN models trained on a wide range of datasets.1 