Deep learning provides a new avenue for light ﬁeld super-resolution (SR). However, the domain gap caused by drastically different light ﬁeld acquisition conditions poses a main obstacle in practice. To ﬁll this gap, we propose a zero-shot learning framework for light ﬁeld SR, which learns a mapping to super-resolve the reference view with examples extracted solely from the input low-resolution light ﬁeld itself. Given highly limited training data under the zero-shot setting, however, we observe that it is difﬁcult to train an end-to-end network successfully.Instead, we divide this challenging task into three sub-tasks, i.e., pre-upsampling, view alignment, and multi-view aggregation, and then conquer them separately with simple yet efﬁcientCNNs. Moreover, the proposed framework can be read-ily extended to ﬁnetune the pre-trained model on a source dataset to better adapt to the target input, which further boosts the performance of light ﬁeld SR in the wild. Exper-imental results validate that our method not only outper-forms classic non-learning-based methods, but also gener-alizes better to unseen light ﬁelds than state-of-the-art deep-learning-based methods when the domain gap is large. 