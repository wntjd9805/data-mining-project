LR input imageSRNTT resultReference-based Super-Resolution (Ref-SR) has recently emerged as a promising paradigm to enhance a low-resolution (LR) input image by introducing an additional high-resolution (HR) reference image. Existing Ref-SR methods mostly rely on implicit correspondence matching to borrow HR textures from reference images to compen-sate for the information loss in input images. However, per-forming local transfer is difﬁcult because of two gaps be-tween input and reference images: the transformation gap (e.g. scale and rotation) and the resolution gap (e.g. HR andLR). To tackle these challenges, we propose C 2-Matching in this work, which produces explicit robust matching cross-ing transformation and resolution. 1) For the transforma-tion gap, we propose a contrastive correspondence network, which learns transformation-robust correspondences using augmented views of the input image. 2) For the resolution gap, we adopt a teacher-student correlation distillation, which distills knowledge from the easier HR-HR matching to guide the more ambiguous LR-HR matching. 3) Finally, we design a dynamic aggregation module to address the po-tential misalignment issue. In addition, to faithfully evalu-ate the performance of Ref-SR under a realistic setting, we contribute the Webly-Referenced SR (WR-SR) dataset, mim-icking the practical usage scenario. Extensive experiments demonstrate that our proposed C 2-Matching signiﬁcantly outperforms state of the arts by over 1dB on the standardCUFED5 benchmark. Notably, it also shows great gener-alizability on WR-SR dataset as well as robustness across large scale and rotation transformations 1. 