BaselineBaseline+AugQBaseline+AugSFew-shot object detection (FSOD) aims to learn detec-tors that can be generalized to novel classes with only a few instances. Unlike previous attempts that exploit meta-learning techniques to facilitate FSOD, this work tackles the problem from the perspective of sample expansion. To this end, we propose a simple yet effective Transforma-tion Invariant Principle (TIP) that can be ﬂexibly applied to various meta-learning models for boosting the detection performance on novel class objects. Speciﬁcally, by intro-ducing consistency regularization on predictions from var-ious transformed images, we augment vanilla FSOD mod-els with the generalization ability to objects perturbed by various transformation, such as occlusion and noise. Im-portantly, our approach can extend supervised FSOD mod-els to naturally cope with unlabeled data, thus addressing a more practical and challenging semi-supervised FSOD problem. Extensive experiments on PASCAL VOC andMSCOCO datasets demonstrate the effectiveness of our TIP under both of the two FSOD settings. 