Akin Caliskan1Adrian Hilton1 2Department of Computer Science, University College LondonLourdes Agapito2We present a new end-to-end learning framework to ob-tain detailed and spatially coherent reconstructions of mul-tiple people from a single image. Existing multi-person methods suffer from two main drawbacks: they are of-ten model-based and therefore cannot capture accurate 3D models of people with loose clothing and hair; or they re-quire manual intervention to resolve occlusions or interac-tions. Our method addresses both limitations by introducing the ﬁrst end-to-end learning approach to perform model-free implicit reconstruction for realistic 3D capture of multi-ple clothed people in arbitrary poses (with occlusions) from a single image. Our network simultaneously estimates the 3D geometry of each person and their 6DOF spatial loca-tions, to obtain a coherent multi-human reconstruction. In addition, we introduce a new synthetic dataset that depicts images with a varying number of inter-occluded humans and a variety of clothing and hair styles. We demonstrate robust, high-resolution reconstructions on images of multi-ple humans with complex occlusions, loose clothing and a large variety of poses and scenes. Our quantitative evalua-tion on both synthetic and real world datasets demonstrates state-of-the-art performance with signiﬁcant improvements in the accuracy and completeness of the reconstructions over competing approaches. 