Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through con-ventional techniques. Secondly, while only normal samples are available at training, the learned features should be dis-criminative of normal and anomalous samples. Here, we propose to use the “distillation” of features at various lay-ers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We de-tect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation val-ues given an input sample. We show that considering mul-tiple intermediate hints in distillation leads to better ex-ploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, compared to utiliz-ing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorpo-rate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve com-petitive or signiﬁcantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization. 