Generative adversarial networks (GANs), e.g., Style-GAN2, play a vital role in various image generation and synthesis tasks, yet their notoriously high computational cost hinders their efﬁcient deployment on edge devices.Directly applying generic compression approaches yields poor results on GANs, which motivates a number of re-cent GAN compression works. While prior works mainly accelerate conditional GANs, e.g., pix2pix and Cycle-GAN, compressing state-of-the-art unconditional GANs has rarely been explored and is more challenging. In this pa-per, we propose novel approaches for unconditional GAN compression. We ﬁrst introduce effective channel pruning and knowledge distillation schemes specialized for uncon-ditional GANs. We then propose a novel content-aware method to guide the processes of both pruning and distil-lation. With content-awareness, we can effectively prune channels that are unimportant to the contents of interest, e.g., human faces, and focus our distillation on these re-gions, which signiﬁcantly enhances the distillation qual-ity. On StyleGAN2 and SN-GAN, we achieve a substantial improvement over the state-of-the-art compression method.Notably, we reduce the FLOPs of StyleGAN2 by 11× with visually negligible image quality loss compared to the full-size model. More interestingly, when applied to various image manipulation tasks, our compressed model forms a smoother and better disentangled latent manifold, making it more effective for image editing. 