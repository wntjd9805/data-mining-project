This paper presents a method for riggable 3D face recon-struction from monocular images, which jointly estimates a personalized face rig and per-image parameters includ-ing expressions, poses, and illuminations. To achieve this goal, we design an end-to-end trainable network embedded with a differentiable in-network optimization. The networkﬁrst parameterizes the face rig as a compact latent code with a neural decoder, and then estimates the latent code as well as per-image parameters via a learnable optimization.By estimating a personalized face rig, our method goes be-yond static reconstructions and enables downstream appli-cations such as video retargeting. In-network optimization explicitly enforces constraints derived from the ﬁrst prin-ciples, thus introduces additional priors than regression-based methods. Finally, data-driven priors from deep learn-ing are utilized to constrain the ill-posed monocular setting and ease the optimization difﬁculty. Experiments demon-strate that our method achieves SOTA reconstruction accu-racy, reasonable robustness and generalization ability, and supports standard face rig applications. 