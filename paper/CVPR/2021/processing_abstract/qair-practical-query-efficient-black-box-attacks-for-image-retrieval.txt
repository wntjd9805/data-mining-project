We study the query-based attack against image retrieval to evaluate its robustness against adversarial examples un-der the black-box setting, where the adversary only has query access to the top-k ranked unlabeled images from the database. Compared with query attacks in image clas-siﬁcation, which produce adversaries according to the re-turned labels or conﬁdence score, the challenge becomes even more prominent due to the difﬁculty in quantifying the attack effectiveness on the partial retrieved list. In this pa-per, we make the ﬁrst attempt in Query-based Attack againstImage Retrieval (QAIR), to completely subvert the top-k re-trieval results. Speciﬁcally, a new relevance-based loss is designed to quantify the attack effects by measuring the set similarity on the top-k retrieval results before and after at-tacks and guide the gradient optimization. To further boost the attack efﬁciency, a recursive model stealing method is proposed to acquire transferable priors on the target model and generate the prior-guided gradients. Comprehensive experiments show that the proposed attack achieves a high attack success rate with few queries against the image re-trieval systems under the black-box setting. The attack eval-uations on the real-world visual search engine show that it successfully deceives a commercial system such as Bing Vi-sual Search with 98% attack success rate by only 33 queries on average. 