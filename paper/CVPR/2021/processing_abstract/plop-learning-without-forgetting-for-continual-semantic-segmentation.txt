Deep learning approaches are nowadays ubiquitously used to tackle computer vision tasks such as semantic seg-mentation, requiring large datasets and substantial com-putational power. Continual learning for semantic seg-mentation (CSS) is an emerging trend that consists in up-dating an old model by sequentially adding new classes.However, continual learning methods are usually prone to catastrophic forgetting. This issue is further aggravated in CSS where, at each step, old classes from previous it-erations are collapsed into the background.In this pa-per, we propose Local POD, a multi-scale pooling distil-lation scheme that preserves long- and short-range spa-tial relationships at feature level. Furthermore, we de-sign an entropy-based pseudo-labelling of the background w.r.t. classes predicted by the old model to deal with back-ground shift and avoid catastrophic forgetting of the old classes. Our approach, called PLOP, signiÔ¨Åcantly outper-forms state-of-the-art methods in existing CSS scenarios, as well as in newly proposed challenging benchmarks1. 