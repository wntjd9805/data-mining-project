In real-world applications, it is common that only a por-tion of data is aligned across views due to spatial, tempo-ral, or spatiotemporal asynchronism, thus leading to the so-called Partially View-aligned Problem (PVP). To solve such a less-touched problem without the help of labels, we propose simultaneously learning representation and align-ing data using a noise-robust contrastive loss. In brief, for each sample from one view, our method aims to identify its within-category counterparts from other views, and thus the cross-view correspondence could be established. As the contrastive learning needs data pairs as input, we construct positive pairs using the known correspondences and nega-tive pairs using random sampling. To alleviate or even elim-inate the inﬂuence of the false negatives caused by random sampling, we propose a noise-robust contrastive loss that could adaptively prevent the false negatives from dominat-ing the network optimization. To the best of our knowledge, this could be the ﬁrst successful attempt of enabling con-trastive learning robust to noisy labels. In fact, this work might remarkably enrich the learning paradigm with noisy labels. More speciﬁcally, the traditional noisy labels are de-ﬁned as incorrect annotations for the supervised tasks such as classiﬁcation. In contrast, this work proposes that the view correspondence might be false, which is remarkably different from the widely-accepted deﬁnition of noisy label.Extensive experiments show the promising performance of our method comparing with 10 state-of-the-art multi-view approaches in the clustering and classiﬁcation tasks. The code will be publicly released at https://pengxi.me. 