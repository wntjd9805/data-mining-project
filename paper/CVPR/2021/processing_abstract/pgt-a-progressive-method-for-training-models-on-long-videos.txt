Convolutional video models have an order of magni-tude larger computational complexity than their counter-part image-level models. Constrained by computational resources, there is no model or training method that can train long video sequences end-to-end. Currently, the main-stream method is to split a raw video into clips, lead-ing to incomplete fragmentary temporal information ﬂow.Inspired by natural language processing techniques deal-ing with long sentences, we propose to treat videos as se-rial fragments satisfying Markov property, and train it as a whole by progressively propagating information through the temporal dimension in multiple steps. This progres-sive training (PGT) method is able to train long videos end-to-end with limited resources and ensures the effec-tive transmission of information. As a general and robust training method, we empirically demonstrate that it yields signiﬁcant performance improvements on different models and datasets. As an illustrative example, the proposed method improves SlowOnly network by 3.7 mAP on Cha-rades and 1.9 top-1 accuracy on Kinetics with negligible parameter and computation overhead. Code is available at: https://github.com/BoPang1996/PGT. 