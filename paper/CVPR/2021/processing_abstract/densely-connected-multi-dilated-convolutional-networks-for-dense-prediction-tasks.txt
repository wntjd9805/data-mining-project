Tasks that involve high-resolution dense prediction re-quire a modeling of both local and global patterns in a large input ﬁeld. Although the local and global structures of-ten depend on each other and their simultaneous modeling is important, many convolutional neural network (CNN)-based approaches interchange representations in different resolutions only a few times. In this paper, we claim the im-portance of a dense simultaneous modeling of multiresolu-tion representation and propose a novel CNN architecture called densely connected multidilated DenseNet (D3Net).D3Net involves a novel multidilated convolution that has different dilation factors in a single layer to model differ-ent resolutions simultaneously. By combining the multidi-lated convolution with the DenseNet architecture, D3Net incorporates multiresolution learning with an exponentially growing receptive ﬁeld in almost all layers, while avoiding the aliasing problem that occurs when we naively incorpo-rate the dilated convolution in DenseNet. Experiments on the image semantic segmentation task using Cityscapes and the audio source separation task using MUSDB18 show that the proposed method has superior performance over state-of-the-art methods. 