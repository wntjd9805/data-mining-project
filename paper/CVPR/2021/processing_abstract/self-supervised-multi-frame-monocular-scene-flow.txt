Estimating 3D scene ﬂow from a sequence of monocu-lar images has been gaining increased attention due to the simple, economical capture setup. Owing to the severe ill-posedness of the problem, the accuracy of current methods has been limited, especially that of efﬁcient, real-time ap-proaches. In this paper, we introduce a multi-frame monoc-ular scene ﬂow network based on self-supervised learning, improving the accuracy over previous networks while re-taining real-time efﬁciency. Based on an advanced two-frame baseline with a split-decoder design, we propose (i) a multi-frame model using a triple frame input and convo-lutional LSTM connections, (ii) an occlusion-aware census loss for better accuracy, and (iii) a gradient detaching strat-egy to improve training stability. On the KITTI dataset, we observe state-of-the-art accuracy among monocular sceneﬂow methods based on self-supervised learning. 