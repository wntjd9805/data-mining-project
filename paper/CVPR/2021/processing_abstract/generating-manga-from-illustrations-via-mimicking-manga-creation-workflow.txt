We present a framework to generate manga from digital illustrations. In professional mange studios, the manga cre-ate workﬂow consists of three key steps: (1) Artists use line drawings to delineate the structural outlines in manga story-boards. (2) Artists apply several types of regular screentones to render the shading, occlusion, and object materials. (3)Artists selectively paste irregular screen textures onto the canvas to achieve various background layouts or special ef-fects. Motivated by this workﬂow, we propose a data-driven framework to convert a digital illustration into three corre-sponding components: manga line drawing, regular screen-tone, and irregular screen texture. These components can be directly composed into manga images and can be further retouched for more plentiful manga creations. To this end, we create a large-scale dataset with these three components annotated by artists in a human-in-the-loop manner. We con-duct both perceptual user study and qualitative evaluation of the generated manga, and observe that our generated image layers for these three components are practically usable in the daily works of manga artists. We provide 60 qualitative results and 15 additional comparisons in the supplemen-tary material. We will make our presented manga dataset publicly available to assist related applications. 