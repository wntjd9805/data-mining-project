With the development of deep learning, neural networks tend to be deeper and larger to achieve good performance.Trained models are more compute-intensive and memory-intensive, which lead to the big challenges on memory band-width, storage, latency, and throughput. In this paper, we propose the neural network compression method named minimally invasive surgery. Different from traditional mod-el compression and knowledge distillation methods, the pro-posed method refers to the minimally invasive surgery prin-ciple. It learns the principal features from a pair of dense and compressed models in a contrastive manner. It also op-timizes the neural networks to meet the speciÔ¨Åc hardware acceleration requirements. Through qualitative, quantita-tive, and ablation experiments, the proposed method shows a compelling performance, acceleration, and generaliza-tion in various tasks. 