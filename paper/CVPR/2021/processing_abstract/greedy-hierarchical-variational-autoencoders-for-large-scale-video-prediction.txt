A video prediction model that generalizes to diverse scenes would enable intelligent agents such as robots to perform a variety of tasks via planning with the model.However, while existing video prediction models have produced promising results on small datasets, they suf-fer from severe underﬁtting when trained on large and diverse datasets. To address this underﬁtting challenge, we ﬁrst observe that the ability to train larger video prediction models is often bottlenecked by the memory constraints of GPUs or TPUs. In parallel, deep hierar-chical latent variable models can produce higher quality predictions by capturing the multi-level stochasticity of future observations, but end-to-end optimization of such models is notably diﬃcult. Our key insight is that greedy and modular optimization of hierarchical autoencoders can simultaneously address both the memory constraints and the optimization challenges of large-scale video pre-diction. We introduce Greedy Hierarchical VariationalAutoencoders (GHVAEs), a method that learns high-ﬁdelity video predictions by greedily training each level of a hierarchical autoencoder. In comparison to state-of-the-art models, GHVAEs provide 17-55% gains in prediction performance on four video datasets, a 35-40% higher success rate on real robot tasks, and can improve performance monotonically by simply adding more modules. Visualization and more details are at https: // sites. google. com/ view/ ghvae . 