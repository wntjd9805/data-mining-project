3D point cloud classiﬁcation has many safety-critical applications such as autonomous driving and robotic grasp-ing. However, several studies showed that it is vulnerable to adversarial attacks. In particular, an attacker can make a classiﬁer predict an incorrect label for a 3D point cloud via carefully modifying, adding, and/or deleting a small num-ber of its points. Randomized smoothing is state-of-the-art technique to build certiﬁably robust 2D image classiﬁers.However, when applied to 3D point cloud classiﬁcation, randomized smoothing can only certify robustness against adversarially modiﬁed points.In this work, we propose PointGuard, the ﬁrst defense that has provable robustness guarantees against adversar-ially modiﬁed, added, and/or deleted points. Speciﬁcally, given a 3D point cloud and an arbitrary point cloud classi-ﬁer, our PointGuard ﬁrst creates multiple subsampled point clouds, each of which contains a random subset of the points in the original point cloud; then our PointGuard pre-dicts the label of the original point cloud as the majority vote among the labels of the subsampled point clouds pre-dicted by the point cloud classiﬁer. Our ﬁrst major theoret-ical contribution is that we show PointGuard provably pre-dicts the same label for a 3D point cloud when the number of adversarially modiﬁed, added, and/or deleted points is bounded. Our second major theoretical contribution is that we prove the tightness of our derived bound when no as-sumptions on the point cloud classiﬁer are made. Moreover, we design an efﬁcient algorithm to compute our certiﬁed robustness guarantees. We also empirically evaluate Point-Guard on ModelNet40 and ScanNet benchmark datasets. 