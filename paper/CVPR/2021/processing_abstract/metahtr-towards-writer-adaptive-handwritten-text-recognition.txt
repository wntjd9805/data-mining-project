Handwritten Text Recognition (HTR) remains a chal-lenging problem to date, largely due to the varying writing styles that exist amongst us. Prior works however generally operate with the assumption that there is a limited number of styles, most of which have already been captured by ex-isting datasets. In this paper, we take a completely different perspective – we work on the assumption that there is al-ways a new style that is drastically different, and that we will only have very limited data during testing to perform adaptation. This creates a commercially viable solution – being exposed to the new style, the model has the best shot at adaptation, and the few-sample nature makes it practi-cal to implement. We achieve this via a novel meta-learning framework which exploits additional new-writer data via a support set, and outputs a writer-adapted model via sin-gle gradient step update, all during inference (see Figure 1). We discover and leverage on the important insight that there exists few key characters per writer that exhibit rel-atively larger style discrepancies. For that, we addition-ally propose to meta-learn instance speciﬁc weights for a character-wise cross-entropy loss, which is speciﬁcally de-signed to work with the sequential nature of text data. Our writer-adaptive MetaHTR framework can be easily imple-mented on the top of most state-of-the-art HTR models. Ex-periments show an average performance gain of 5-7% can be obtained by observing very few new style data (≤ 16). 