Leveraging datasets available to learn a model with high generalization ability to unseen domains is important for computer vision, especially when the unseen domainâ€™s anno-tated data are unavailable. We study a novel and practical problem of Open Domain Generalization (OpenDG), which learns from different source domains to achieve high perfor-mance on an unknown target domain, where the distributions and label sets of each individual source domain and the tar-get domain can be different. The problem can be generally applied to diverse source domains and widely applicable to real-world applications. We propose a Domain-AugmentedMeta-Learning framework to learn open-domain generaliz-able representations. We augment domains on both feature-level by a new Dirichlet mixup and label-level by distilled soft-labeling, which complements each domain with miss-ing classes and other domain knowledge. We conduct meta-learning over domains by designing new meta-learning tasks and losses to preserve domain unique knowledge and gener-alize knowledge across domains simultaneously. Experiment results on various multi-domain datasets demonstrate that the proposed Domain-Augmented Meta-Learning (DAML) outperforms prior methods for unseen domain recognition. 