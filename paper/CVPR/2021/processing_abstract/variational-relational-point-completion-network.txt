Real-scanned point clouds are often incomplete due to viewpoint, occlusion, and noise. Existing point cloud com-pletion methods tend to generate global shape skeletons and hence lack ﬁne local details. Furthermore, they mostly learn a deterministic partial-to-complete mapping, but overlook structural relations in man-made objects. To tackle these challenges, this paper proposes a variational framework,Variational Relational point Completion network (VRC-Net) with two appealing properties: 1) Probabilistic Mod-eling. In particular, we propose a dual-path architecture to enable principled probabilistic modeling across partial and complete clouds. One path consumes complete point clouds for reconstruction by learning a point VAE. The other path generates complete shapes for partial point clouds, whose embedded distribution is guided by distribution obtained from the reconstruction path during training. 2) RelationalEnhancement. Speciﬁcally, we carefully design point self-attention kernel and point selective kernel module to ex-ploit relational point features, which reﬁnes local shape de-tails conditioned on the coarse completion. In addition, we contribute a multi-view partial point cloud dataset (MVP dataset) containing over 100,000 high-quality scans, which renders partial 3D shapes from 26 uniformly distributed camera poses for each 3D CAD model. Extensive exper-iments demonstrate that VRCNet outperforms state-of-the-art methods on all standard point cloud completion bench-marks. Notably, VRCNet shows great generalizability and robustness on real-world point cloud scans. 