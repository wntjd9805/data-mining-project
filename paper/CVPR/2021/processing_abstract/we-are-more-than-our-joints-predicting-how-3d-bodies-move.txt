A key step towards understanding human behavior is the prediction of 3D human motion. Successful solutions have many applications in human tracking, HCI, and graphics.Most previous work focuses on predicting a time series of future 3D joint locations given a sequence 3D joints from the past. This Euclidean formulation generally works bet-ter than predicting pose in terms of joint rotations. Body joint locations, however, do not fully constrain 3D human pose, leaving degrees of freedom (like rotation about a limb) undeﬁned. Note that 3D joints can be viewed as a sparse point cloud. Thus the problem of human motion prediction can be seen as a problem of point cloud pre-diction. With this observation, we instead predict a sparse set of locations on the body surface that correspond to mo-tion capture markers. Given such markers, we ﬁt a para-metric body model to recover the 3D body of the person.These sparse surface markers also carry detailed informa-tion about human movement that is not present in the joints, increasing the naturalness of the predicted motions. Us-ing the AMASS dataset, we train MOJO (More than OurJOints), which is a novel variational autoencoder with a la-tent DCT space that generates motions from latent frequen-cies. MOJO preserves the full temporal resolution of the input motion, and sampling from the latent frequencies ex-plicitly introduces high-frequency components into the gen-erated motion. We note that motion prediction methods ac-cumulate errors over time, resulting in joints or markers that diverge from true human bodies. To address this, weﬁt the SMPL-X body model to the predictions at each time step, projecting the solution back onto the space of valid bodies, before propagating the new markers in time. Quan-titative and qualitative experiments show that our approach produces state-of-the-art results and realistic 3D body an-imations. The code is available for research purposes at https://yz-cnsdqz.github.io/MOJO/MOJO.html. 