Recently, neural architecture search (NAS) has been ex-ploited to design feature pyramid networks (FPNs) and achieved promising results for visual object detection. En-couraged by the success, we propose a novel One-Shot PathAggregation Network Architecture Search (OPANAS) al-gorithm, which signiﬁcantly improves both searching ef-ﬁciency and detection accuracy.Speciﬁcally, we ﬁrst introduce six heterogeneous information paths to build our search space, namely top-down, bottom-up, fusing-splitting, scale-equalizing, skip-connect and none. Sec-ond, we propose a novel search space of FPNs, in which each FPN candidate is represented by a densely-connected directed acyclic graph (each node is a feature pyramid and each edge is one of the six heterogeneous informa-tion paths). Third, we propose an efﬁcient one-shot search method to ﬁnd the optimal path aggregation architecture; speciﬁcally, we ﬁrst train a super-net and then ﬁnd the op-timal candidate with an evolutionary algorithm. Exper-imental results demonstrate the efﬁcacy of the proposedOPANAS for object detection: (1) OPANAS is more ef-ﬁcient than state-of-the-art methods (e.g., NAS-FPN andAuto-FPN) at signiﬁcantly smaller searching cost (e.g., only 4 GPU days on MS-COCO); (2) the optimal architecture found by OPANAS signiﬁcantly improves main-stream de-tectors including RetinaNet, Faster R-CNN and Cascade R-CNN, by 2.3∼3.2 % mAP compared to their FPN counter-parts; and (3) a new state-of-the-art accuracy-speed trade-off (52.2 % mAP at 7.6 FPS) is achieved at smaller training costs than comparable recent arts. Code will be released at https://github.com/VDIGPKU/OPANAS. 