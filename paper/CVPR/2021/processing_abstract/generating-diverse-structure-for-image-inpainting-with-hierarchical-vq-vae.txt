Given an incomplete image without additional con-straint, image inpainting natively allows for multiple solu-tions as long as they appear plausible. Recently, multiple-solution inpainting methods have been proposed and shown the potential of generating diverse results. However, these methods have difﬁculty in ensuring the quality of each so-lution, e.g. they produce distorted structure and/or blurry texture. We propose a two-stage model for diverse inpaint-ing, where the ﬁrst stage generates multiple coarse results each of which has a different structure, and the second stage reﬁnes each coarse result separately by augmenting texture.The proposed model is inspired by the hierarchical vector quantized variational auto-encoder (VQ-VAE), whose hi-erarchical architecture disentangles structural and textural information.In addition, the vector quantization in VQ-VAE enables autoregressive modeling of the discrete distri-bution over the structural information. Sampling from the distribution can easily generate diverse and high-quality structures, making up the ﬁrst stage of our model.In the second stage, we propose a structural attention mod-ule inside the texture generation network, where the mod-ule utilizes the structural information to capture distant correlations. We further reuse the VQ-VAE to calculate two feature losses, which help improve structure coherence and texture realism, respectively. Experimental results onCelebA-HQ, Places2, and ImageNet datasets show that our method not only enhances the diversity of the inpainting solutions but also improves the visual quality of the gen-erated multiple images. Code and models are available at: https://github.com/USTC- JialunPeng/Diverse-Structure-Inpainting. 