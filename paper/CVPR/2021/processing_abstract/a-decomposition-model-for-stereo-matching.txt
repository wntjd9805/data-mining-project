In this paper, we present a decomposition model for stereo matching to solve the problem of excessive growth in computational cost (time and memory cost) as the reso-lution increases. In order to reduce the huge cost of stereo matching at the original resolution, our model only runs dense matching at a very low resolution and uses sparse matching at different higher resolutions to recover the dis-parity of lost details scale-by-scale. After the decompo-sition of stereo matching, our model iteratively fuses the sparse and dense disparity maps from adjacent scales with an occlusion-aware mask. A reﬁnement network is also ap-plied to improving the fusion result. Compared with high-performance methods like PSMNet and GANet, our method achieves 10 − 100× speed increase while obtaining compa-rable disparity estimation results. 