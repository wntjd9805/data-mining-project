2D image representations are in regular grids and can be processed efﬁciently, whereas 3D point clouds are unordered and scattered in 3D space. The information inside these two visual domains is well complementary, e.g., 2D images haveﬁne-grained texture while 3D point clouds contain plentiful geometry information. However, most current visual recog-nition systems process them individually. In this paper, we present a bidirectional projection network (BPNet) for joint 2D and 3D reasoning in an end-to-end manner. It contains 2D and 3D sub-networks with symmetric architectures, that are connected by our proposed bidirectional projection mod-ule (BPM). Via the BPM, complementary 2D and 3D infor-mation can interact with each other in multiple architectural levels, such that advantages in these two visual domains can be combined for better scene recognition. Extensive quan-titative and qualitative experimental evaluations show that joint reasoning over 2D and 3D visual domains can beneﬁt both 2D and 3D scene understanding simultaneously. OurBPNet achieves top performance on the ScanNetV2 bench-mark for both 2D and 3D semantic segmentation. Code is available at https://github.com/wbhu/BPNet. 