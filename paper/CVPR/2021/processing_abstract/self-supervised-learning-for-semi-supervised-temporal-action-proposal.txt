i.e.,Self-supervised learning presents a remarkable perfor-mance to utilize unlabeled data for various video tasks.In this paper, we focus on applying the power of self-supervised methods to improve semi-supervised action pro-posal generation. Particularly, we design an effective Self-supervised Semi-supervised Temporal Action ProposalThe SSTAP contains two crucial (SSTAP) framework. branches, temporal-aware semi-supervised branchThe semi-and relation-aware self-supervised branch. supervised branch improves the proposal model by intro-ducing two temporal perturbations, i.e., temporal feature shift and temporal feature ﬂip, in the mean teacher frame-work. The self-supervised branch deﬁnes two pretext tasks, including masked feature reconstruction and clip-order pre-diction, to learn the relation of temporal clues. By this means, SSTAP can better explore unlabeled videos, and improve the discriminative abilities of learned action fea-tures. We extensively evaluate the proposed SSTAP onTHUMOS14 and ActivityNet v1.3 datasets. The experi-mental results demonstrate that SSTAP signiﬁcantly out-performs state-of-the-art semi-supervised methods and even matches fully-supervised methods. Code is available at https://github.com/wangxiang1230/SSTAP. 