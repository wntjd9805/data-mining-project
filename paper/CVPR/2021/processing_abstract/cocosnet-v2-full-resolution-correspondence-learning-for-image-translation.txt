We present the full-resolution correspondence learning for cross-domain images, which aids image translation. We adopt a hierarchical strategy that uses the correspondence from coarse level to guide the ﬁne levels. At each hier-archy, the correspondence can be efﬁciently computed viaPatchMatch that iteratively leverages the matchings from the neighborhood. Within each PatchMatch iteration, theConvGRU module is employed to reﬁne the current cor-respondence considering not only the matchings of larger context but also the historic estimates. The proposed Co-CosNet v2, a GRU-assisted PatchMatch approach, is fully differentiable and highly efﬁcient. When jointly trained with image translation, full-resolution semantic correspondence can be established in an unsupervised manner, which in turn facilitates the exemplar-based image translation. Experi-ments on diverse translation tasks show that CoCosNet v2 performs considerably better than state-of-the-art literature on producing high-resolution images. 