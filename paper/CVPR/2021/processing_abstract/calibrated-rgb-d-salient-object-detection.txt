Complex backgrounds and similar appearances between objects and their surroundings are generally recognized as challenging scenarios in Salient Object Detection (SOD).This naturally leads to the incorporation of depth infor-mation in addition to the conventional RGB image as in-put, known as RGB-D SOD or depth-aware SOD. Mean-while, this emerging line of research has been consider-ably hindered by the noise and ambiguity that prevail in raw depth images. To address the aforementioned issues, we propose a Depth Calibration and Fusion (DCF) frame-work that contains two novel components: 1) a learning strategy to calibrate the latent bias in the original depth maps towards boosting the SOD performance; 2) a simple yet effective cross reference module to fuse features from both RGB and depth modalities. Extensive empirical ex-periments demonstrate that the proposed approach achieves superior performance against 27 state-of-the-art methods.Moreover, our depth calibration strategy alone can work as a preprocessing step; empirically it results in notice-able improvements when being applied to existing cutting-edge RGB-D SOD models. Source code is available at https://github.com/jiwei0921/DCF. 