For learned image compression, the autoregressive con-text model is proved effective in improving the rate-distortion (RD) performance. Because it helps remove spa-tial redundancies among latent representations. However, the decoding process must be done in a strict scan order, which breaks the parallelization. We propose a paralleliz-able checkerboard context model (CCM) to solve the prob-lem. Our two-pass checkerboard context calculation elimi-nates such limitations on spatial locations by re-organizing the decoding order. Speeding up the decoding process more than 40 times in our experiments, it achieves signiﬁcantly improved computational efﬁciency with almost the same rate-distortion performance. To the best of our knowledge, this is the ﬁrst exploration on parallelization-friendly spa-tial context model for learned image compression. 