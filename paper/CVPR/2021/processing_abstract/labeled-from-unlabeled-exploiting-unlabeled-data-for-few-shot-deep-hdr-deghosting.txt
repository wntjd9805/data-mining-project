High Dynamic Range (HDR) deghosting is an indispens-able tool in capturing wide dynamic range scenes without ghosting artifacts. Recently, convolutional neural networks (CNNs) have shown tremendous success in HDR deghost-ing. However, CNN-based HDR deghosting methods re-quire collecting large datasets with ground truth, which is a tedious and time-consuming process. This paper proposes a pioneering work by introducing zero and few-shot learn-ing strategies for data-efﬁcient HDR deghosting. Our ap-proach consists of two stages of training. In stage one, we train the model with few labeled (5 or less) dynamic sam-ples and a pool of unlabeled samples with a self-supervised loss. We use the trained model to predict HDRs for the un-labeled samples. To derive data for the next stage of train-ing, we propose a novel method for generating correspond-ing dynamic inputs from the predicted HDRs of unlabeled data. The generated artiﬁcial dynamic inputs and predictedHDRs are used as paired labeled data. In stage two, weﬁnetune the model with the original few labeled data and artiﬁcially generated labeled data. Our few-shot approach outperforms many fully-supervised methods in two publicly available datasets, using as little as ﬁve labeled dynamic samples. 