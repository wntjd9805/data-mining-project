We propose DeepMetaHandles, a 3D conditional gen-erative model based on mesh deformation. Given a col-lection of 3D meshes of a category and their deformation handles (control points), our method learns a set of meta-handles for each shape, which are represented as combina-tions of the given handles. The disentangled meta-handles factorize all the plausible deformations of the shape, while each of them corresponds to an intuitive deformation. A new deformation can then be generated by sampling the co-efﬁcients of the meta-handles in a speciﬁc range. We em-ploy biharmonic coordinates as the deformation function, which can smoothly propagate the control points’ transla-tions to the entire mesh. To avoid learning zero deforma-tion as meta-handles, we incorporate a target-ﬁtting mod-ule which deforms the input mesh to match a random tar-get. To enhance deformations’ plausibility, we employ a soft-rasterizer-based discriminator that projects the meshes to a 2D space. Our experiments demonstrate the superiority of the generated deformations as well as the interpretabil-ity and consistency of the learned meta-handles. The code is available at https://github.com/Colin97/DeepMetaHandles. 