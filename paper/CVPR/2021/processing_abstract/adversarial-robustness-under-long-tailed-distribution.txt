Balanced CIFAR-10Long-tailed CIFAR-10Adversarial robustness has attracted extensive studies recently by revealing the vulnerability and intrinsic char-acteristics of deep networks. However, existing works on adversarial robustness mainly focus on balanced datasets, while real-world data usually exhibits a long-tailed distri-bution. To push adversarial robustness towards more real-istic scenarios, in this work we investigate the adversarial vulnerability as well as defense under long-tailed distribu-tions.In particular, we ﬁrst reveal the negative impacts induced by imbalanced data on both recognition perfor-mance and adversarial robustness, uncovering the intrinsic challenges of this problem. We then perform a systematic study on existing long-tailed recognition methods in con-junction with the adversarial training framework. Several valuable observations are obtained: 1) natural accuracy is relatively easy to improve, 2) fake gain of robust accuracy exists under unreliable evaluation, and 3) boundary error limits the promotion of robustness. Inspired by these obser-vations, we propose a clean yet effective framework, RoBal, which consists of two dedicated modules, a scale-invariant classiﬁer and data re-balancing via both margin engineer-ing at training stage and boundary adjustment during in-ference. Extensive experiments demonstrate the superiority of our approach over other state-of-the-art defense meth-ods. To our best knowledge, we are the ﬁrst to tackle adver-sarial robustness under long-tailed distributions, which we believe would be a signiﬁcant step towards real-world ro-bustness. Our code is available at: https://github. com/wutong16/Adversarial_Long-Tail. 