As airborne vehicles are becoming more autonomous and ubiquitous, it has become vital to develop the capa-bility to detect the objects in their surroundings. This paper attempts to address the problem of drones detection from other ﬂying drones. The erratic movement of the source and target drones, small size, arbitrary shape, large inten-sity variations, and occlusion make this problem quite chal-lenging. In this scenario, region-proposal based methods are not able to capture sufﬁcient discriminative foreground-background information. Also, due to the extremely small size and complex motion of the source and target drones, feature aggregation based methods are unable to perform well. To handle this, instead of using region-proposal based methods, we propose to use a two-stage segmentation-based approach employing spatio-temporal attention cues. Dur-ing the ﬁrst stage, given the overlapping frame regions, de-tailed contextual information is captured over convolution feature maps using pyramid pooling. After that pixel and channel-wise attention is enforced on the feature maps toIn the second stage, ensure accurate drone localization.ﬁrst stage detections are veriﬁed and new probable drone locations are explored. To discover new drone locations, motion boundaries are used. This is followed by track-ing candidate drone detections for a few frames, cuboid formation, extraction of the 3D convolution feature map, and drones detection within each cuboid. The proposed approach is evaluated on two publicly available drone de-tection datasets and outperforms several competitive base-lines. 