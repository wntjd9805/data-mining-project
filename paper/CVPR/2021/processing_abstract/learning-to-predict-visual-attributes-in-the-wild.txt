Visual attributes constitute a large portion of informa-tion contained in a scene. Objects can be described using a wide variety of attributes which portray their visual ap-pearance (color, texture), geometry (shape, size, posture), and other intrinsic properties (state, action). Existing work is mostly limited to study of attribute prediction in speciﬁc domains. In this paper, we introduce a large-scale in-the-wild visual attribute prediction dataset consisting of over 927K attribute annotations for over 260K object instances.Formally, object attribute prediction is a multi-label clas-siﬁcation problem where all attributes that apply to an ob-ject must be predicted. Our dataset poses signiﬁcant chal-lenges to existing methods due to large number of attributes, label sparsity, data imbalance, and object occlusion. To this end, we propose several techniques that systematically tackle these challenges, including a base model that uti-lizes both low- and high-level CNN features with multi-hop attention, reweighting and resampling techniques, a novel negative label expansion scheme, and a novel super-vised attribute-aware contrastive learning algorithm. Us-ing these techniques, we achieve near 3.7 mAP and 5.7 overall F1 points improvement over the current state of the art. Further details about the VAW dataset can be found at https://vawdataset.com/ 