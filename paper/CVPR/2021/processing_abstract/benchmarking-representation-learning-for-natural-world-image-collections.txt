Recent progress in self-supervised learning has resulted in models that are capable of extracting rich representations from image collections without requiring any explicit label supervision. However, to date the vast majority of these approaches have restricted themselves to training on stan-dard benchmark datasets such as ImageNet. We argue thatﬁne-grained visual categorization problems, such as plant and animal species classiﬁcation, provide an informative testbed for self-supervised learning. In order to facilitate progress in this area we present two new natural world vi-sual classiﬁcation datasets, iNat2021 and NeWT. The for-mer consists of 2.7M images from 10k different species up-loaded by users of the citizen science application iNatural-ist. We designed the latter, NeWT, in collaboration with domain experts with the aim of benchmarking the perfor-mance of representation learning algorithms on a suite of challenging natural world binary classiﬁcation tasks that go beyond standard species classiﬁcation. These two new datasets allow us to explore questions related to large-scale representation and transfer learning in the context of ﬁne-grained categories. We provide a comprehensive analysis of feature extractors trained with and without supervision on ImageNet and iNat2021, shedding light on the strengths and weaknesses of different learned features across a di-verse set of tasks. We ﬁnd that features produced by stan-dard supervised methods still outperform those produced by self-supervised approaches such as SimCLR. However, im-proved self-supervised learning methods are constantly be-ing released and the iNat2021 and NeWT datasets are a valuable resource for tracking their progress. 