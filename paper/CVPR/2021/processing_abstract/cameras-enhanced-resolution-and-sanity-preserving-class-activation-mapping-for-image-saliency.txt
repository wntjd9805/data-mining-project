Backpropagation image saliency aims at explaining model predictions by estimating model-centric impor-tance of individual pixels in the input. However, class-insensitivity of the earlier layers in a network only allows saliency computation with low resolution activation maps of the deeper layers, resulting in compromised image saliency.Remedifying this can lead to sanity failures. We proposeCAMERAS, a technique to compute high-ﬁdelity backprop-agation saliency maps without requiring any external priors and preserving the map sanity. Our method systematically performs multi-scale accumulation and fusion of the acti-vation maps and backpropagated gradients to compute pre-cise saliency maps. From accurate image saliency to artic-ulation of relative importance of input features for different models, and precise discrimination between model percep-tion of visually similar objects, our high-resolution map-ping offers multiple novel insights into the black-box deep visual models, which are presented in the paper. We also demonstrate the utility of our saliency maps in adversarial setup by drastically reducing the norm of attack signals by focusing them on the precise regions identiﬁed by our maps.Our method also inspires new evaluation metrics and a san-ity check for this developing research direction. 