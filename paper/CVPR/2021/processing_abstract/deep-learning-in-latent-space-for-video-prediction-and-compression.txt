Learning-based video compression has achieved substan-tial progress during recent years. The most inﬂuential ap-proaches adopt deep neural networks (DNNs) to remove spatial and temporal redundancies by ﬁnding the appropri-ate lower-dimensional representations of frames in the video.We propose a novel DNN based framework that predicts and compresses video sequences in the latent vector space. The proposed method ﬁrst learns the efﬁcient lower-dimensional latent space representation of each video frame and then performs inter-frame prediction in that latent domain. The proposed latent domain compression of individual frames is obtained by a deep autoencoder trained with a generative ad-versarial network (GAN). To exploit the temporal correlation within the video frame sequence, we employ a convolutional long short-term memory (ConvLSTM) network to predict the latent vector representation of the future frame. We demon-strate our method with two applications; video compression and abnormal event detection that share the identical latent frame prediction network. The proposed method exhibits superior or competitive performance compared to the state-of-the-art algorithms speciﬁcally designed for either video compression or anomaly detection. 1 