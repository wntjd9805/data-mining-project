This paper presents an uncalibrated deep neural network framework for the photometric stereo problem. For training models to solve the problem, existing neural network-based methods either require exact light directions or ground-truth surface normals of the object or both. However, in practice, it is challenging to procure both of this informa-tion precisely, which restricts the broader adoption of pho-tometric stereo algorithms for vision application. To bypass this difﬁculty, we propose an uncalibrated neural inverse rendering approach to this problem. Our method ﬁrst es-timates the light directions from the input images and then optimizes an image reconstruction loss to calculate the sur-face normals, bidirectional reﬂectance distribution function value, and depth. Additionally, our formulation explicitly models the concave and convex parts of a complex surface to consider the effects of interreﬂections in the image forma-tion process. Extensive evaluation of the proposed method on the challenging subjects generally shows comparable or better results than the supervised and classical approaches. 