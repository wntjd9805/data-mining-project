Image restoration tasks demand a complex balance be-tween spatial details and high-level contextualized informa-tion while recovering images. In this paper, we propose a novel synergistic design that can optimally balance these competing goals. Our main proposal is a multi-stage ar-chitecture, that progressively learns restoration functions for the degraded inputs, thereby breaking down the over-all recovery process into more manageable steps. Speciﬁ-cally, our model ﬁrst learns the contextualized features us-ing encoder-decoder architectures and later combines them with a high-resolution branch that retains local informa-tion. At each stage, we introduce a novel per-pixel adap-tive design that leverages in-situ supervised attention to reweight the local features. A key ingredient in such a multi-stage architecture is the information exchange be-tween different stages. To this end, we propose a two-faceted approach where the information is not only ex-changed sequentially from early to late stages, but lateral connections between feature processing blocks also exist to avoid any loss of information. The resulting tightly inter-linked multi-stage architecture, named as MPRNet, delivers strong performance gains on ten datasets across a range of tasks including image deraining, deblurring, and denois-ing. The source code and pre-trained models are available at https://github.com/swz30/MPRNet. 