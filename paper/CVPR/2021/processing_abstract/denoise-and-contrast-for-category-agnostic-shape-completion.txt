In this paper, we present a deep learning model that ex-ploits the power of self-supervision to perform 3D point cloud completion, estimating the missing part and a context region around it. Local and global information are encoded in a combined embedding. A denoising pretext task provides the network with the needed local cues, decoupled from the high-level semantics and naturally shared over multi-ple classes. On the other hand, contrastive learning max-imizes the agreement between variants of the same shape with different missing portions, thus producing a represen-tation which captures the global appearance of the shape.The combined embedding inherits category-agnostic prop-erties from the chosen pretext tasks. Differently from exist-ing approaches, this allows to better generalize the comple-tion properties to new categories unseen at training time.Moreover, while decoding the obtained joint representa-tion, we better blend the reconstructed missing part with the partial shape by paying attention to its known surround-ing region and reconstructing this frame as auxiliary objec-tive. Our extensive experiments and detailed ablation on theShapeNet dataset show the effectiveness of each part of the method with new state of the art results. Our quantitative and qualitative analysis conﬁrms how our approach is able to work on novel categories without relying neither on clas-siﬁcation and shape symmetry priors, nor on adversarial training procedures. 