more diverse and realistic images than previous methods.Training generative models, such as GANs, on a tar-get domain containing limited examples (e.g., 10) can eas-ily result in overﬁtting. In this work, we seek to utilize a large source domain for pretraining and transfer the di-versity information from source to target. We propose to preserve the relative similarities and differences between instances in the source via a novel cross-domain distance consistency loss. To further reduce overﬁtting, we present an anchor-based strategy to encourage different levels of realism over different regions in the latent space. With ex-tensive results in both photorealistic and non-photorealistic domains, we demonstrate qualitatively and quantitatively that our few-shot model automatically discovers correspon-dences between source and target domains and generates 