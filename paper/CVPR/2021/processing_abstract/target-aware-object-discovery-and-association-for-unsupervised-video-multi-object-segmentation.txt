This paper addresses the task of unsupervised video multi-object segmentation. Current approaches follow a two-stage paradigm: 1) detect object proposals using pre-trained Mask R-CNN, and 2) conduct generic feature matching for temporal association using re-identiﬁcation techniques. However, the generic features, widely used in both stages, are not reliable for characterizing unseen ob-jects, leading to poor generalization. To address this, we introduce a novel approach for more accurate and efﬁcient spatio-temporal segmentation. In particular, to address in-stance discrimination, we propose to combine foreground region estimation and instance grouping together in one network, and additionally introduce temporal guidance for segmenting each frame, enabling more accurate object dis-covery. For temporal association, we complement current video object segmentation architectures with a discrimina-tive appearance model, capable of capturing more ﬁne-grained target-speciﬁc information. Given object propos-als from the instance discrimination network, three essen-tial strategies are adopted to achieve accurate segmenta-tion: 1) target-speciﬁc tracking using a memory-augmented appearance model; 2) target-agnostic veriﬁcation to trace possible tracklets for the proposal; 3) adaptive memory up-dating using the veriﬁed segments. We evaluate the pro-posed approach on DAVIS17 and YouTube-VIS, and the re-sults demonstrate that it outperforms state-of-the-art meth-ods both in segmentation accuracy and inference speed. 