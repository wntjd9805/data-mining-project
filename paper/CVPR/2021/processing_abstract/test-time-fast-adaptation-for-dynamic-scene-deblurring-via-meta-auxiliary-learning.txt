In this paper, we tackle the problem of dynamic scene deblurring. Most existing deep end-to-end learning ap-proaches adopt the same generic model for all unseen test images. These solutions are sub-optimal, as they fail to utilize the internal information within a speciÔ¨Åc image.On the other hand, a self-supervised approach, SelfDe-blur, enables internal training within a test image from scratch, but it does not fully take advantage of large ex-ternal datasets.In this work, we propose a novel self-supervised meta-auxiliary learning to improve the perfor-mance of deblurring by integrating both external and inter-nal learning. Concretely, we build a self-supervised auxil-iary reconstruction task that shares a portion of the network with the primary deblurring task. The two tasks are jointly trained on an external dataset. Furthermore, we propose a meta-auxiliary training scheme to further optimize the pre-trained model as a base learner, which is applicable for fast adaptation at test time. During training, the performance of both tasks is coupled. Therefore, we are able to exploit the internal information at test time via the auxiliary task to en-hance the performance of deblurring. Extensive experimen-tal results across evaluation datasets demonstrate the effec-tiveness of test-time adaptation of the proposed method. 