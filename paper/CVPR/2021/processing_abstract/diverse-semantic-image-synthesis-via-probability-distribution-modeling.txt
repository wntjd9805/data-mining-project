Semantic image synthesis, translating semantic lay-outs to photo-realistic images, is a one-to-many mapping problem. Though impressive progress has been recently made, diverse semantic synthesis that can efÔ¨Åciently pro-duce semantic-level multimodal results, still remains a chal-lenge.In this paper, we propose a novel diverse seman-tic image synthesis framework from the perspective of se-mantic class distributions, which naturally supports diverse generation at semantic or even instance level. We achieve this by modeling class-level conditional modulation param-eters as continuous probability distributions instead of dis-crete values, and sampling per-instance modulation param-eters through instance-adaptive stochastic sampling that is consistent across the network. Moreover, we propose prior noise remapping, through linear perturbation param-eters encoded from paired references, to facilitate super-vised training and exemplar-based instance style control at test time. Extensive experiments on multiple datasets show that our method can achieve superior diversity and compa-rable quality compared to state-of-the-art methods. Code will be available at https://github.com/tzt101/INADE.git 