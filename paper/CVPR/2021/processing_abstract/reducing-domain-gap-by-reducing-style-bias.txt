Convolutional Neural Networks (CNNs) often fail to main-tain their performance when they confront new test domains, which is known as the problem of domain shift. Recent stud-ies suggest that one of the main causes of this problem isCNNsâ€™ strong inductive bias towards image styles (i.e. tex-tures) which are sensitive to domain changes, rather than contents (i.e. shapes). Inspired by this, we propose to reduce the intrinsic style bias of CNNs to close the gap between do-mains. Our Style-Agnostic Networks (SagNets) disentangle style encodings from class categories to prevent style biased predictions and focus more on the contents. Extensive ex-periments show that our method effectively reduces the style bias and makes the model more robust under domain shift.It achieves remarkable performance improvements in a wide range of cross-domain tasks including domain generaliza-tion, unsupervised domain adaptation, and semi-supervised domain adaptation on multiple datasets.1 