Semantic segmentation of nighttime images plays an equally important role as that of daytime images in au-tonomous driving, but the former is much more challenging due to poor illuminations and arduous human annotations.In this paper, we propose a novel domain adaptation net-work (DANNet) for nighttime semantic segmentation with-out using labeled nighttime image data. It employs an ad-versarial training with a labeled daytime dataset and an unlabeled dataset that contains coarsely aligned day-night image pairs. Speciﬁcally, for the unlabeled day-night im-age pairs, we use the pixel-level predictions of static object categories on a daytime image as a pseudo supervision to segment its counterpart nighttime image. We further design a re-weighting strategy to handle the inaccuracy caused by misalignment between day-night image pairs and wrong predictions of daytime images, as well as boost the predic-tion accuracy of small objects. The proposed DANNet is theﬁrst one-stage adaptation framework for nighttime seman-tic segmentation, which does not train additional day-night image transfer models as a separate pre-processing stage.Extensive experiments on Dark Zurich and Nighttime Driv-ing datasets show that our method achieves state-of-the-art performance for nighttime semantic segmentation. 