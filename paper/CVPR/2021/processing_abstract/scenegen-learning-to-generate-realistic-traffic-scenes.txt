We consider the problem of generating realistic trafﬁc scenes automatically. Existing methods typically insert ac-tors into the scene according to a set of hand-crafted heuris-tics and are limited in their ability to model the true com-plexity and diversity of real trafﬁc scenes, thus inducing a content gap between synthesized trafﬁc scenes versus real ones. As a result, existing simulators lack the ﬁdelity neces-sary to train and test self-driving vehicles. To address this limitation, we present SceneGen—a neural autoregressive model of trafﬁc scenes that eschews the need for rules and heuristics. In particular, given the ego-vehicle state and a high deﬁnition map of surrounding area, SceneGen inserts actors of various classes into the scene and synthesizes their sizes, orientations, and velocities. We demonstrate on two large-scale datasets SceneGen’s ability to faithfully model distributions of real trafﬁc scenes. Moreover, we show thatSceneGen coupled with sensor simulation can be used to train perception models that generalize to the real world. 