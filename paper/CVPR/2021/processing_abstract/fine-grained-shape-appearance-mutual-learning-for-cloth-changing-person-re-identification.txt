(cid:28636)(cid:28631)(cid:28595)(cid:28612) (cid:28660)(cid:28675)(cid:28675)(cid:28664)(cid:28660)(cid:28677)(cid:28660)(cid:28673)(cid:28662)(cid:28664) (cid:28636)(cid:28631)(cid:28595)(cid:28612) (cid:28636)(cid:28631)(cid:28595)(cid:28612) (cid:28672)(cid:28660)(cid:28678)(cid:28670) (cid:28636)(cid:28631)(cid:28595)(cid:28612)Recently, person re-identiﬁcation (Re-ID) has achieved great progress. However, current methods largely depend on color appearance, which is not reliable when a person changes the clothes. Cloth-changing Re-ID is challenging since pedestrian images with clothes change exhibit large intra-class variation and small inter-class variation. Some signiﬁcant features for identiﬁcation are embedded in unob-vious body shape differences across pedestrians. To explore such body shape cues for cloth-changing Re-ID, we propose a Fine-grained Shape-Appearance Mutual learning frame-work (FSAM), a two-stream framework that learns ﬁne-grained discriminative body shape knowledge in a shape stream and transfers it to an appearance stream to com-plement the cloth-unrelated knowledge in the appearance features. Speciﬁcally, in the shape stream, FSAM learnsﬁne-grained discriminative mask with the guidance of iden-tities and extracts ﬁne-grained body shape features by a pose-speciﬁc multi-branch network. To complement cloth-unrelated shape knowledge in the appearance stream, dense interactive mutual learning is performed across low-level and high-level features to transfer knowledge from shape stream to appearance stream, which enables the appear-ance stream to be deployed independently without extra computation for mask estimation. We evaluated our method on benchmark cloth-changing Re-ID datasets and achieved the start-of-the-art performance. 