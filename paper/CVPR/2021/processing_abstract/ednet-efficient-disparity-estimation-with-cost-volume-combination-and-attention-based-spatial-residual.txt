Existing state-of-the-art disparity estimation works mostly leverage the 4D concatenation volume and construct a very deep 3D convolution neural network (CNN) for dis-parity regression, which is inefﬁcient due to the high mem-ory consumption and slow inference speed. In this paper, we propose a network named EDNet for efﬁcient disparity estimation. Firstly, we construct a combined volume which incorporates contextual information from the squeezed con-catenation volume and feature similarity measurement from the correlation volume. The combined volume can be next aggregated by 2D convolutions which are faster and re-quire less memory than 3D convolutions. Secondly, we pro-pose an attention-based spatial residual module to generate attention-aware residual features. The attention mechanism is applied to provide intuitive spatial evidence about inac-curate regions with the help of error maps at multiple scales and thus improve the residual learning efﬁciency. Extensive experiments on the Scene Flow and KITTI datasets show that EDNet outperforms the previous 3D CNN based works and achieves state-of-the-art performance with signiﬁcantly faster speed and less memory consumption. 