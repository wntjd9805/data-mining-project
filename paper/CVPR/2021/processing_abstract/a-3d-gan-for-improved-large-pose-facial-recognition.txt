Facial recognition using deep convolutional neural net-works relies on the availability of large datasets of face im-ages. Many examples of identities are needed, and for each identity, a large variety of images are needed in order for the network to learn robustness to intra-class variation. In practice, such datasets are difÔ¨Åcult to obtain, particularly those containing adequate variation of pose. GenerativeAdversarial Networks (GANs) provide a potential solution to this problem due to their ability to generate realistic, syn-thetic images. However, recent studies have shown that cur-rent methods of disentangling pose from identity are inade-quate. In this work we incorporate a 3D morphable model into the generator of a GAN in order to learn a nonlinear texture model from in-the-wild images. This allows genera-tion of new, synthetic identities, and manipulation of pose, illumination and expression without compromising the iden-tity. Our synthesised data is used to augment training of facial recognition networks with performance evaluated on the challenging CFP and CPLFW datasets. 