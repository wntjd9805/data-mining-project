Panoptic segmentation presents a new challenge in ex-ploiting the merits of both detection and segmentation, with the aim of unifying instance segmentation and semantic seg-mentation in a single framework. However, an efﬁcient so-lution for panoptic segmentation in the emerging domain ofLiDAR point cloud is still an open research problem and is very much under-explored. In this paper, we present a fast and robust LiDAR point cloud panoptic segmentation framework, referred to as Panoptic-PolarNet. We learn both semantic segmentation and class-agnostic instance clustering in a single inference network using a polar Bird’sEye View (BEV) representation, enabling us to circum-vent the issue of occlusion among instances in urban street scenes. To improve our network’s learnability, we also pro-pose an adapted instance augmentation technique and a novel adversarial point cloud pruning method. Our exper-iments show that Panoptic-PolarNet outperforms the base-line methods on SemanticKITTI and nuScenes datasets with an almost real-time inference speed. Panoptic-PolarNet achieved 54.1% PQ in the public SemanticKITTI panoptic segmentation leaderboard and leading performance for the validation set of nuScenes. 