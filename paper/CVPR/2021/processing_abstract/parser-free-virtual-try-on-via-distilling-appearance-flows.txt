Image virtual try-on aims to ﬁt a garment image (tar-get clothes) to a person image. Prior methods are heavily based on human parsing. However, slightly-wrong segmen-tation results would lead to unrealistic try-on images with large artifacts. A recent pioneering work employed knowl-edge distillation to reduce the dependency of human pars-ing, where the try-on images produced by a parser-based method are used as supervisions to train a “student” net-work without relying on segmentation, making the student mimic the try-on ability of the parser-based model. How-ever, the image quality of the student is bounded by the*Y. Song is the corresponding author. This work is done when Y. Ge is an intern in Tencent AI Lab. The code is available at https://github. com/geyuying/PF-AFN. parser-based model. To address this problem, we propose a novel approach, “teacher-tutor-student” knowledge dis-tillation, which is able to produce highly photo-realistic images without human parsing, possessing several appeal-ing advantages compared to prior arts. (1) Unlike existing work, our approach treats the fake images produced by the parser-based method as “tutor knowledge”, where the arti-facts can be corrected by real “teacher knowledge”, which is extracted from the real person images in a self-supervised way. (2) Other than using real images as supervisions, we formulate knowledge distillation in the try-on problem as distilling the appearance ﬂows between the person image and the garment image, enabling us to ﬁnd accurate dense correspondences between them to produce high-quality re-sults. (3) Extensive evaluations show large superiority of our method (see Fig. 1). 8485