Substantial progress has been made on modeling rigid 3D objects using deep implicit representations. Yet, extend-ing these methods to learn neural models of human shape is still in its infancy. Human bodies are complex and the key challenge is to learn a representation that generalizes such that it can express body shape deformations for un-seen subjects in unseen, highly-articulated, poses. To ad-dress this challenge, we introduce LEAP (LEarning Articu-lated occupancy of People), a novel neural occupancy rep-resentation of the human body. Given a set of bone trans-formations (i.e. joint locations and rotations) and a query point in space, LEAP ﬁrst maps the query point to a canoni-cal space via learned linear blend skinning (LBS) functions and then efﬁciently queries the occupancy value via an oc-cupancy network that models accurate identity- and pose-dependent deformations in the canonical space. Experi-ments show that our canonicalized occupancy estimation with the learned LBS functions greatly improves the gen-eralization capability of the learned occupancy representa-tion across various human shapes and poses, outperforming existing solutions in all settings. 