Quantization-based methods are widely used in LiDAR points 3D object detection for its efﬁciency in extracting context information. Unlike image where the context infor-mation is distributed evenly over the object, most LiDAR points are distributed along the object boundary, which means the boundary features are more critical in LiDAR points 3D detection. However, quantization inevitably in-troduces ambiguity during both the training and inference stages. To alleviate this problem, we propose a one-stage and voting-based 3D detector, named Point-Voxel-Grid Net-work (PVGNet). In particular, PVGNet extracts point, voxel and grid-level features in a uniﬁed backbone architecture and produces point-wise fusion features.It segments Li-DAR points into foreground and background, predicts a 3D bounding box for each foreground point, and performs group voting to get the ﬁnal detection results. Moreover, we observe that instance-level point imbalance due to oc-clusion and observation distance also degrades the detec-tion performance. A novel instance-aware focal loss is pro-posed to alleviate this problem and further improve the de-tection ability. We conduct experiments on the KITTI andWaymo datasets. Our proposed PVGNet outperforms previ-ous state-of-the-art methods and ranks at the top of KITTI 3D/BEV detection leaderboards. 