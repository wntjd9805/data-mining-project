Most existing CNN-based super-resolution (SR) methods are developed based on an assumption that the degradation is ﬁxed and known (e.g., bicubic downsampling). However, these methods suffer a severe performance drop when the real degradation is different from their assumption. To han-dle various unknown degradations in real-world applica-tions, previous methods rely on degradation estimation to reconstruct the SR image. Nevertheless, degradation esti-mation methods are usually time-consuming and may lead to SR failure due to large estimation errors.In this pa-per, we propose an unsupervised degradation representa-tion learning scheme for blind SR without explicit degrada-tion estimation. Speciﬁcally, we learn abstract representa-tions to distinguish various degradations in the representa-tion space rather than explicit estimation in the pixel space.Moreover, we introduce a Degradation-Aware SR (DASR) network with ﬂexible adaption to various degradations based on the learned representations.It is demonstrated that our degradation representation learning scheme can extract discriminative representations to obtain accurate degradation information. Experiments on both synthetic and real images show that our network achieves state-of-the-art performance for the blind SR task. Code is avail-able at: https://github.com/LongguangWang/DASR. 