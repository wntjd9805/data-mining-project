We deﬁne the concept of CompositeTasking as the fusion of multiple, spatially distributed tasks, for various aspects of image understanding. Learning to perform spatially dis-tributed tasks is motivated by the frequent availability of only sparse labels across tasks, and the desire for a com-pact multi-tasking network. To facilitate CompositeTask-ing, we introduce a novel task conditioning model – a sin-gle encoder-decoder network that performs multiple, spa-tially varying tasks at once. The proposed network takes an image and a set of pixel-wise dense task requests as in-puts, and performs the requested prediction task for each pixel. Moreover, we also learn the composition of tasks that needs to be performed according to some CompositeTasking rules, which includes the decision of where to apply whichIt not only offers us a compact network for multi-task. tasking, but also allows for task-editing. Another strength of the proposed method is demonstrated by only having to supply sparse supervision per task. The obtained results are on par with our baselines that use dense supervision and a multi-headed multi-tasking design. The source code will be made publicly available at www.github.com/ nikola3794/composite-tasking. 