Current face forgery detection methods achieve high ac-curacy under the within-database scenario where training and testing forgeries are synthesized by the same algorithm.However, few of them gain satisfying performance under the cross-database scenario where training and testing forg-eries are synthesized by different algorithms. In this paper, we ﬁnd that current CNN-based detectors tend to overﬁt to method-speciﬁc color textures and thus fail to general-ize. Observing that image noises remove color textures and expose discrepancies between authentic and tampered re-gions, we propose to utilize the high-frequency noises for face forgery detection. We carefully devise three functional modules to take full advantage of the high-frequency fea-tures. The ﬁrst is the multi-scale high-frequency feature ex-traction module that extracts high-frequency noises at mul-tiple scales and composes a novel modality. The second is the residual-guided spatial attention module that guides the low-level RGB feature extractor to concentrate more on forgery traces from a new perspective. The last is the cross-modality attention module that leverages the correlation be-tween the two complementary modalities to promote feature learning for each other. Comprehensive evaluations on sev-eral benchmark databases corroborate the superior gener-alization performance of our proposed method. 