Neural image compression leverages deep neural net-works to outperform traditional image codecs in rate-distortion performance. However, the resulting models are also heavy, computationally demanding and generally opti-mized for a single rate, limiting their practical use. Focus-ing on practical image compression, we propose slimmable compressive autoencoders (SlimCAEs), where rate (R) and distortion (D) are jointly optimized for different capacities.Once trained, encoders and decoders can be executed at different capacities, leading to different rates and complex-ities. We show that a successful implementation of Slim-CAEs requires suitable capacity-speciﬁc RD tradeoffs. Our experiments show that SlimCAEs are highly ﬂexible models that provide excellent rate-distortion performance, variable rate, and dynamic adjustment of memory, computational cost and latency, thus addressing the main requirements of practical image compression. 