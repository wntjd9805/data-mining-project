Person image synthesis, e.g., pose transfer, is a challeng-ing problem due to large variation and occlusion. Existing methods have difﬁculties predicting reasonable invisible re-gions and fail to decouple the shape and style of clothing, which limits their applications on person image editing. In this paper, we propose PISE, a novel two-stage generative model for Person Image Synthesis and Editing, which is able to generate realistic person images with desired poses, textures, or semantic layouts. For human pose transfer, weﬁrst synthesize a human parsing map aligned with the target pose to represent the shape of clothing by a parsing gener-ator, and then generate the ﬁnal image by an image genera-tor. To decouple the shape and style of clothing, we propose joint global and local per-region encoding and normaliza-tion to predict the reasonable style of clothing for invisi-ble regions. We also propose spatial-aware normalization to retain the spatial context relationship in the source im-age. The results of qualitative and quantitative experiments demonstrate the superiority of our model on human pose transfer. Besides, the results of texture transfer and region editing show that our model can be applied to person im-age editing. The code is available for research purposes at https://github.com/Zhangjinso/PISE. 