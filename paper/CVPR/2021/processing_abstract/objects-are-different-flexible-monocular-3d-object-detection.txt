The precise localization of 3D objects from a single im-age without depth information is a highly challenging prob-lem. Most existing methods adopt the same approach for all objects regardless of their diverse distributions, leading to limited performance for truncated objects.In this pa-per, we propose a ﬂexible framework for monocular 3D ob-ject detection which explicitly decouples the truncated ob-jects and adaptively combines multiple approaches for ob-ject depth estimation. Speciﬁcally, we decouple the edge of the feature map for predicting long-tail truncated ob-jects so that the optimization of normal objects is not inﬂu-enced. Furthermore, we formulate the object depth estima-tion as an uncertainty-guided ensemble of directly regressed object depth and solved depths from different groups of keypoints. Experiments demonstrate that our method out-performs the state-of-the-art method by relatively 27% for the moderate level and 30% for the hard level in the test set of KITTI benchmark while maintaining real-time efﬁ-ciency. Code will be available at https://github. com/zhangyp15/MonoFlex. 