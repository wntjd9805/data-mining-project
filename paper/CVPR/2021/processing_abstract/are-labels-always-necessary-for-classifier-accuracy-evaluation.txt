To calculate the model accuracy on a computer vision task, e.g., object recognition, we usually require a test set composing of test samples and their ground truth labels.Whilst standard usage cases satisfy this requirement, many real-world scenarios involve unlabeled test data, render-ing common model evaluation methods infeasible. We in-vestigate this important and under-explored problem, Au-tomatic model Evaluation (AutoEval). Speciﬁcally, given a labeled training set and a classiﬁer, we aim to estimate the classiﬁcation accuracy on unlabeled test datasets. We construct a meta-dataset: a dataset comprised of datasets generated from the original images via various transforma-tions such as rotation, background substitution, foreground scaling, etc. As the classiﬁcation accuracy of the model on each sample (dataset) is known from the original dataset labels, our task can be solved via regression. Using the feature statistics to represent the distribution of a sample dataset, we can train regression models (e.g., a regression neural network) to predict model performance. Using syn-thetic meta-dataset and real-world datasets in training and testing, respectively, we report a reasonable and promising prediction of the model accuracy. We also provide insights into the application scope, limitation, and potential future direction of AutoEval. 