A crucial component for the scene text based reasoning re-quired for TextVQA and TextCaps datasets involve detecting and recognizing text present in the images using an optical character recognition (OCR) system. The current systems are crippled by the unavailability of ground truth text an-notations for these datasets as well as lack of scene text detection and recognition datasets on real images disallow-ing the progress in the Ô¨Åeld of OCR and evaluation of scene text based reasoning in isolation from OCR systems. In this work, we propose TextOCR, an arbitrary-shaped scene text detection and recognition with 900k annotated words col-lected on real images from TextVQA dataset. We show that current state-of-the-art text-recognition (OCR) models fail to perform well on TextOCR and that training on TextOCR helps achieve state-of-the-art performance on multiple otherOCR datasets as well. We use a TextOCR trained OCR model to create PixelM4C model which can do scene text based rea-soning on an image in an end-to-end fashion, allowing us to revisit several design choices to achieve new state-of-the-art performance on TextVQA dataset. 