CompositorsExisting EnsemblesIn this paper, we propose a deep compositional met-ric learning (DCML) framework for effective and gener-alizable similarity measurement between images. Conven-tional deep metric learning methods minimize a discrimi-native loss to enlarge interclass distances while suppress-ing intraclass variations, which might lead to inferior gen-eralization performance since samples even from the same class may present diverse characteristics. This motivates the adoption of the ensemble technique to learn a number of sub-embeddings using different and diverse subtasks. How-ever, most subtasks impose weaker or contradictory con-straints, which essentially sacriÔ¨Åces the discrimination abil-ity of each sub-embedding to improve the generalization ability of their combination. To achieve a better general-ization ability without compromising, we propose to sepa-rate the sub-embeddings from direct supervisions from the subtasks and apply the losses on different composites of the sub-embeddings. We employ a set of learnable compositors to combine the sub-embeddings and use a self-reinforced loss to train the compositors, which serve as relays to dis-tribute the diverse training signals to avoid destroying the discrimination ability. Experimental results on the CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the superior performance of our framework. 1 