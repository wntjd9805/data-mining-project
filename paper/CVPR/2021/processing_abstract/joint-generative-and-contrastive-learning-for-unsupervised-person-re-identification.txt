Recent self-supervised contrastive learning provides an effective approach for unsupervised person re-identiﬁcation (ReID) by learning invariance from different views (trans-formed versions) of an input. In this paper, we incorporate a Generative Adversarial Network (GAN) and a contrastive learning module into one joint training framework. While the GAN provides online data augmentation for contrastive learning, the contrastive module learns view-invariant fea-tures for generation. In this context, we propose a mesh-based view generator. Speciﬁcally, mesh projections serve as references towards generating novel views of a per-son. In addition, we propose a view-invariant loss to fa-cilitate contrastive learning between original and gener-ated views. Deviating from previous GAN-based unsuper-vised ReID methods involving domain adaptation, we do not rely on a labeled source dataset, which makes our method more ﬂexible. Extensive experimental results show that our method signiﬁcantly outperforms state-of-the-art methods under both, fully unsupervised and unsupervised domain adaptive settings on several large scale ReID dat-sets. Source code and models are available under https://github.com/chenhao2345/GCL. 