TLong-term actions involve many important visual con-cepts, e.g., objects, motions, and sub-actions, and there are various relations among these concepts, which we call ba-sic relations. These basic relations will jointly affect each other during the temporal evolution of long-term actions, which forms the high-order relations that are essential for long-term action recognition. In this paper, we propose aGraph-based High-order Relation Modeling (GHRM) mod-ule to exploit the high-order relations in the long-term ac-tions for long-term action recognition. In GHRM, each ba-sic relation in the long-term actions will be modeled by a graph, where each node represents a segment in a long video. Moreover, when modeling each basic relation, the information from all the other basic relations will be in-corporated by GHRM, and thus the high-order relations in the long-term actions can be well exploited. To bet-ter exploit the high-order relations along the time dimen-sion, we design a GHRM-layer consisting of a Temporal-GHRM branch and a Semantic-GHRM branch, which aims to model the local temporal high-order relations and global semantic high-order relations. The experimental results on three long-term action recognition datasets, namely, Break-fast, Charades, and MultiThumos, demonstrate the effec-tiveness of our model. 