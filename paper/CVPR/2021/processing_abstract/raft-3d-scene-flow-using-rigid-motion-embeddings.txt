We address the problem of scene ﬂow: given a pair of stereo or RGB-D video frames, estimate pixelwise 3D mo-tion. We introduce RAFT-3D, a new deep architecture for scene ﬂow. RAFT-3D is based on the RAFT model devel-oped for optical ﬂow but iteratively updates a dense ﬁeld of pixelwise SE3 motion instead of 2D motion. A key inno-vation of RAFT-3D is rigid-motion embeddings, which rep-resent a soft grouping of pixels into rigid objects. Integral to rigid-motion embeddings is Dense-SE3, a differentiable layer that enforces geometric consistency of the embed-dings. Experiments show that RAFT-3D achieves state-of-the-art performance. On FlyingThings3D, under the two-view evaluation, we improved the best published accuracy (δ < 0.05) from 34.3% to 83.7%. On KITTI, we achieve an error of 5.77, outperforming the best published method (6.31), despite using no object instance supervision. 