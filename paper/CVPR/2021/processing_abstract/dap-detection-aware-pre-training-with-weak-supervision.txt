ImageNet)In contrastThis paper presents a detection-aware pre-training (DAP) approach, which leverages only weakly-labeled for pre-classiﬁcation-style datasets (e.g., training, but is speciﬁcally tailored to beneﬁt object de-tection tasks. to the widely used image classiﬁcation-based pre-training (e.g., on ImageNet), which does not include any location-related training tasks, we transform a classiﬁcation dataset into a detection dataset through a weakly supervised object localization method based on Class Activation Maps to directly pre-train a de-tector, making the pre-trained model location-aware and capable of predicting bounding boxes. We show that DAP can outperform the traditional classiﬁcation pre-training in terms of both sample efﬁciency and convergence speed in downstream detection tasks including VOC and COCO. In particular, DAP boosts the detection accuracy by a large margin when the number of examples in the downstream task is small. 