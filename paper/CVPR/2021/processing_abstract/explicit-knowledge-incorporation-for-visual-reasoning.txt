Existing explainable and explicit visual reasoning meth-ods only perform reasoning based on visual evidence but do not take into account knowledge beyond what is in the vi-sual scene. To addresses the knowledge gap between visual reasoning methods and the semantic complexity of real-world images, we present the ﬁrst explicit visual reasoning method that incorporates external knowledge and models high-order relational attention for improved generalizabil-ity and explainability. Speciﬁcally, we propose a knowledge incorporation network that explicitly creates and includes new graph nodes for entities and predicates from external knowledge bases to enrich the semantics of the scene graph used in explicit reasoning. We then create a novel Graph-Relate module to perform high-order relational attention on the enriched scene graph. By explicitly introducing struc-tured external knowledge and high-order relational atten-tion, our method demonstrates signiﬁcant generalizability and explainability over the state-of-the-art visual reasoning approaches on the GQA and VQAv2 datasets. 