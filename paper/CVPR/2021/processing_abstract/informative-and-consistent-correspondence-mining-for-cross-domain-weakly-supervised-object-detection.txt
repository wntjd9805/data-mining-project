Cross-domain weakly supervised object detection aims to adapt object-level knowledge from a fully labeled source domain dataset (i.e., with object bounding boxes) to train object detectors for target domains that are weakly labeled (i.e., with image-level tags). Instead of domain-level distri-bution matching, as popularly adopted in the literature, we propose to learn pixel-wise cross-domain correspondences for more precise knowledge transfer. It is realized through a novel cross-domain co-attention scheme trained as region competition. In this scheme, the cross-domain correspon-dence module seeks for informative features on the target domain image, which if warped to the source domain im-age, could best explain its annotations. Meanwhile, a col-laborative mask generator competes to mask out the rel-evant target image region to make the remaining features uninformative. Such competitive learning strives to corre-late the full foreground in cross-domain image pairs, reveal-ing the accurate object extent in target domain. To allevi-ate the ambiguity of inter-domain correspondence learning, a domain-cycle consistency regularizer is further proposed to leverage the more reliable intra-domain correspondence.The proposed approach achieves consistent improvements over existing approaches by a considerable margin, demon-strated by the experiments on various datasets. 