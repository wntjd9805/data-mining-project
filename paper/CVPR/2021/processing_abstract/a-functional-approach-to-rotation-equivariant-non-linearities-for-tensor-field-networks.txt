Learning pose invariant representation is a fundamental problem in shape analysis. Most existing deep learning al-gorithms for 3D shape analysis are not robust to rotations and are often trained on synthetic datasets consisting of pre-aligned shapes, yielding poor generalization to unseen poses. This observation motivates a growing interest in ro-tation invariant and equivariant methods. The ﬁeld of rota-tion equivariant deep learning is developing in recent years thanks to a well established theory of Lie group representa-tions and convolutions. A fundamental problem in equivari-ant deep learning is to design activation functions which are both informative and preserve equivariance. The recently introduced Tensor Field Network (TFN) framework pro-vides a rotation equivariant network design for point cloud analysis. TFN features undergo a rotation in feature space given a rotation of the input pointcloud. TFN and similar designs consider nonlinearities which operate only over ro-tation invariant features such as the norm of equivariant features to preserve equivariance, making them unable to capture the directional information. In a recent work en-titled ”Gauge Equivariant Mesh CNNs: Anisotropic Con-volutions on Geometric Graphs” Hann et al. interpret 2D rotation equivariant features as Fourier coefﬁcients of func-tions on the circle. In this work we transpose the idea ofHann et al. to 3D by interpreting TFN features as spher-ical harmonics coefﬁcients of functions on the sphere. We introduce a new equivariant nonlinearity and pooling forTFN. We show improvments over the original TFN design and other equivariant nonlinearities in classiﬁcation and segmentation tasks. Furthermore our method is competi-tive with state of the art rotation invariant methods in some instances. 