We present a simple but powerful architecture of convo-lutional neural network, which has a VGG-like inference-time body composed of nothing but a stack of 3 × 3 con-volution and ReLU, while the training-time model has a multi-branch topology. Such decoupling of the training-time and inference-time architecture is realized by a struc-tural re-parameterization technique so that the model is named RepVGG. On ImageNet, RepVGG reaches over 80% top-1 accuracy, which is the ﬁrst time for a plain model, to the best of our knowledge. On NVIDIA 1080Ti GPU,RepVGG models run 83% faster than ResNet-50 or 101% faster than ResNet-101 with higher accuracy and show fa-vorable accuracy-speed trade-off compared to the state-of-the-art models like EfﬁcientNet and RegNet. The code and trained models are available at https://github. com/megvii-model/RepVGG. 