Search spaceS a m p l e  Super-netWeight sharing has become a de facto standard in neu-ral architecture search because it enables the search to be done on commodity hardware. However, recent works have empirically shown a ranking disorder between the perfor-mance of stand-alone architectures and that of the corre-sponding shared-weight networks. This violates the main assumption of weight-sharing NAS algorithms, thus limit-ing their effectiveness. We tackle this issue by proposing a regularization term that aims to maximize the correla-tion between the performance rankings of the shared-weight network and that of the standalone architectures using a small set of landmark architectures. We incorporate our regularization term into three different NAS algorithms and show that it consistently improves performance across al-gorithms, search-spaces, and tasks. 