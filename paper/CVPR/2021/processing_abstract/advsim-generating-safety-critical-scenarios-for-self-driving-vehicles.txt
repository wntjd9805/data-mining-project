Original ScenarioAdvSim ScenarioAs self-driving systems become better, simulating sce-narios where the autonomy stack may fail becomes more important. Traditionally, those scenarios are generated for a few scenes with respect to the planning module that takes ground-truth actor states as input. This does not scale and cannot identify all possible autonomy failures, such as per-ception failures due to occlusion.In this paper, we pro-pose AdvSim, an adversarial framework to generate safety-critical scenarios for any LiDAR-based autonomy system.Given an initial trafﬁc scenario, AdvSim modiﬁes the ac-tors’ trajectories in a physically plausible manner and up-dates the LiDAR sensor data to match the perturbed world.Importantly, by simulating directly from sensor data, we ob-tain adversarial scenarios that are safety-critical for the full autonomy stack. Our experiments show that our approach is general and can identify thousands of semantically mean-ingful safety-critical scenarios for a wide range of modern self-driving systems. Furthermore, we show that the robust-ness and safety of these systems can be further improved by training them with scenarios generated by AdvSim. 