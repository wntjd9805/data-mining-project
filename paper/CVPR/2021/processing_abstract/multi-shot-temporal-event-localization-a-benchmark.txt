Current developments in temporal event or action lo-calization usually target actions captured by a single cam-era. However, extensive events or actions in the wild may be captured as a sequence of shots by multiple cameras at different positions.In this paper, we propose a new and challenging task called multi-shot temporal event lo-calization, and accordingly, collect a large-scale dataset called MUlti-Shot EventS (MUSES). MUSES has 31,477 event instances for a total of 716 video hours. The core nature of MUSES is the frequent shot cuts, for an average of 19 shots per instance and 176 shots per video, which in-duces large intra-instance variations. Our comprehensive evaluations show that the state-of-the-art method in tem-poral action localization only achieves an mAP of 13.1% at IoU=0.5. As a minor contribution, we present a sim-ple baseline approach for handling the intra-instance vari-ations, which reports an mAP of 18.9% on MUSES and 56.9% on THUMOS14 at IoU=0.5. To facilitate research in this direction, we release the dataset and the project code at https://songbai.site/muses/. 