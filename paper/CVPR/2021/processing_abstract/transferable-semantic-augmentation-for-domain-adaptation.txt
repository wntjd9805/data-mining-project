Source-onlySource-only+TSADADA+TSADomain adaptation has been widely explored by trans-ferring the knowledge from a label-rich source domain to a related but unlabeled target domain. Most existing domain adaptation algorithms attend to adapting feature represen-tations across two domains with the guidance of a shared source-supervised classiﬁer. However, such classiﬁer limits the generalization ability towards unlabeled target recog-nition. To remedy this, we propose a Transferable Seman-tic Augmentation (TSA) approach to enhance the classiﬁer adaptation ability through implicitly generating source fea-tures towards target semantics. Speciﬁcally, TSA is inspired by the fact that deep feature transformation towards a cer-tain direction can be represented as meaningful semantic altering in the original input space. Thus, source features can be augmented to effectively equip with target semantics to train a more transferable classiﬁer. To achieve this, for each class, we ﬁrst use the inter-domain feature mean differ-ence and target intra-class feature covariance to construct a multivariate normal distribution. Then we augment source features with random directions sampled from the distribu-tion class-wisely. Interestingly, such source augmentation is implicitly implemented through an expected transferable cross-entropy loss over the augmented source distribution, where an upper bound of the expected loss is derived and minimized, introducing negligible computational overhead.As a light-weight and general technique, TSA can be easily plugged into various domain adaptation methods, bringing remarkable improvements. Comprehensive experiments on cross-domain benchmarks validate the efﬁcacy of TSA. 