We propose a novel method for privacy-preserving train-ing of deep neural networks leveraging public, out-domain data. While differential privacy (DP) has emerged as a mechanism to protect sensitive data in training datasets, its application to complex visual recognition tasks re-mains challenging.Traditional DP methods, such asDifferentially-Private Stochastic Gradient Descent (DP-SGD), perform well only on simple datasets and shallow networks, while recent transfer learning-based DP meth-ods often make unrealistic assumptions about the availabil-ity and distribution of public data. In this work, we argue that minimizing the number of trainable parameters is the key to improving the privacy-performance tradeoff of DP on complex visual recognition tasks. Inspired by this argu-ment, we also propose a novel transfer learning paradigm that Ô¨Ånetunes a very sparse subnetwork with DP. We con-duct extensive experiments and ablation studies on two vi-sual recognition tasks: CIFAR-100 ! CIFAR-10 (standardDP setting) and the CD-FSL challenge (few-shot, multiple levels of domain shifts) and demonstrate competitive exper-imental performance. 