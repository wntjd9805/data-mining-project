We present a novel method for predicting accurate depths from monocular images with high efﬁciency. This optimal efﬁciency is achieved by exploiting wavelet de-composition, which is integrated in a fully differentiable encoder-decoder architecture. We demonstrate that we can reconstruct high-ﬁdelity depth maps by predicting sparse wavelet coefﬁcients.In contrast with previous works, we show that wavelet coefﬁcients can be learned without direct supervision on coefﬁcients. Instead we supervise only the ﬁnal depth im-age that is reconstructed through the inverse wavelet trans-form. We additionally show that wavelet coefﬁcients can be learned in fully self-supervised scenarios, without access to ground-truth depth. Finally, we apply our method to differ-ent state-of-the-art monocular depth estimation models, in each case giving similar or better results compared to the original model, while requiring less than half the multiply-adds in the decoder network. 