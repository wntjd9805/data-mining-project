In this paper, we focus on category-level 6D pose and size estimation from a monocular RGB-D image. Previ-ous methods suffer from inefﬁcient category-level pose fea-ture extraction, which leads to low accuracy and inference speed. To tackle this problem, we propose a fast shape-based network (FS-Net) with efﬁcient category-level fea-ture extraction for 6D pose estimation. First, we design an orientation aware autoencoder with 3D graph convolution for latent feature extraction. Thanks to the shift and scale-invariance properties of 3D graph convolution, the learned latent feature is insensitive to point shift and object size.Then, to efﬁciently decode category-level rotation informa-tion from the latent feature, we propose a novel decoupled rotation mechanism that employs two decoders to comple-mentarily access the rotation information. For translation and size, we estimate them by two residuals: the difference between the mean of object points and ground truth trans-lation, and the difference between the mean size of the cate-gory and ground truth size, respectively. Finally, to increase the generalization ability of the FS-Net, we propose an on-line box-cage based 3D deformation mechanism to augment the training data. Extensive experiments on two benchmark datasets show that the proposed method achieves state-of-the-art performance in both category- and instance-level 6D object pose estimation. Especially in category-level pose estimation, without extra synthetic data, our method outperforms existing methods by 6.3% on the NOCS-REAL dataset 1. 