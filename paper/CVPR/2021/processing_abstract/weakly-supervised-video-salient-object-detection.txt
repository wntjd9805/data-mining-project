Signiﬁcant performance improvement has been achieved for fully-supervised video salient object detection with the pixel-wise labeled training datasets, which are time-consuming and expensive to obtain. To relieve the bur-den of data annotation, we present the ﬁrst weakly super-vised video salient object detection model based on rela-beled “ﬁxation guided scribble annotations”. Speciﬁcally, an “Appearance-motion fusion module” and bidirectionalConvLSTM based framework are proposed to achieve ef-fective multi-modal learning and long-term temporal con-text modeling based on our new weak annotations. Fur-ther, we design a novel foreground-background similarity loss to further explore the labeling similarity across frames.A weak annotation boosting strategy is also introduced to boost our model performance with a new pseudo-label gen-eration technique. Extensive experimental results on six benchmark video saliency detection datasets illustrate the effectiveness of our solution1. 