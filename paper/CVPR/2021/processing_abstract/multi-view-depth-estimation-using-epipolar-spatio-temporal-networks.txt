We present a novel method for multi-view depth estima-tion from a single video, which is a critical task in var-ious applications, such as perception, reconstruction and robot navigation. Although previous learning-based meth-ods have demonstrated compelling results, most works esti-mate depth maps of individual video frames independently, without taking into consideration the strong geometric and temporal coherence among the frames. Moreover, current state-of-the-art (SOTA) models mostly adopt a fully 3D con-volution network for cost regularization and therefore re-quire high computational cost, thus limiting their deploy-ment in real-world applications. Our method achieves tem-porally coherent depth estimation results by using a novelEpipolar Spatio-Temporal (EST) transformer to explicitly associate geometric and temporal correlation with multiple estimated depth maps. Furthermore, to reduce the compu-tational cost, inspired by recent Mixture-of-Experts mod-els, we design a compact hybrid network consisting of a 2D context-aware network and a 3D matching network which learn 2D context information and 3D disparity cues sepa-rately. Extensive experiments demonstrate that our method achieves higher accuracy in depth estimation and signiÔ¨Å-cant speedup than the SOTA methods. 