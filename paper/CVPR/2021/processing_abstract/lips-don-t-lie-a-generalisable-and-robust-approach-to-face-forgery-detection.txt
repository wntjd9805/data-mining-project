Although current deep learning-based face forgery de-tectors achieve impressive performance in constrained sce-narios, they are vulnerable to samples created by unseen manipulation methods. Some recent works show improve-ments in generalisation but rely on cues that are easily cor-rupted by common post-processing operations such as com-pression. In this paper, we propose LipForensics, a detec-tion approach capable of both generalising to novel manip-ulations and withstanding various distortions. LipForensics targets high-level semantic irregularities in mouth move-ments, which are common in many generated videos. It con-sists in ﬁrst pretraining a spatio-temporal network to per-form visual speech recognition (lipreading), thus learning rich internal representations related to natural mouth mo-tion. A temporal network is subsequently ﬁnetuned on ﬁxed mouth embeddings of real and forged data in order to detect fake videos based on mouth movements without overﬁtting to low-level, manipulation-speciﬁc artefacts. Extensive ex-periments show that this simple approach signiﬁcantly sur-passes the state-of-the-art in terms of generalisation to un-seen manipulations and robustness to perturbations, as well as shed light on the factors responsible for its performance. 