We present a novel, real-time, semantic segmentation network in which the encoder both encodes and generates the parameters (weights) of the decoder. Furthermore, to allow maximal adaptivity, the weights at each decoder block vary spatially. For this purpose, we design a new type of hypernetwork, composed of a nested U-Net for drawing higher level context features, a multi-headed weight gen-erating module which generates the weights of each block in the decoder immediately before they are consumed, for efÔ¨Åcient memory utilization, and a primary network that is composed of novel dynamic patch-wise convolutions. De-spite the usage of less-conventional blocks, our architec-ture obtains real-time performance.In terms of the run-time vs. accuracy trade-off, we surpass state of the art (SotA) results on popular semantic segmentation bench-marks: PASCAL VOC 2012 (val. set) and real-time seman-tic segmentation on Cityscapes, and CamVid. The code is available: https://nirkin.com/hyperseg. 