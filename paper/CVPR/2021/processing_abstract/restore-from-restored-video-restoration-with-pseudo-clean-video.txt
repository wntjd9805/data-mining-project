In this study, we propose a self-supervised video denois-ing method called “restore-from-restored.” This methodﬁne-tunes a pre-trained network by using a pseudo clean video during the test phase. The pseudo clean video is ob-tained by applying a noisy video to the baseline network.By adopting a fully convolutional neural network (FCN) as the baseline, we can improve video denoising performance without accurate optical ﬂow estimation and registration steps, in contrast to many conventional video restoration methods, due to the translation equivariant property of theFCN. Speciﬁcally, the proposed method can take advantage of plentiful similar patches existing across multiple con-secutive frames (i.e., patch-recurrence); these patches can boost the performance of the baseline network by a large margin. We analyze the restoration performance of theﬁne-tuned video denoising networks with the proposed self-supervision-based learning algorithm, and demonstrate that the FCN can utilize recurring patches without requir-ing accurate registration among adjacent frames.In our experiments, we apply the proposed method to state-of-the-art denoisers and show that our ﬁne-tuned networks achieve a considerable improvement in denoising performance. 