We aim at constructing a high performance model for de-fect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors us-ing normal training data only. We ﬁrst learn self-supervised deep representations and then build a generative one-class classiﬁer on learned representations. We learn representa-tions by classifying normal data from the CutPaste, a sim-ple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect vari-ous types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representa-tions from scratch. By transfer learning on pretrained rep-resentations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing de-fective areas without annotations during training. 