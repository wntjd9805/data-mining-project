Monocular 3D object detection is a key problem for autonomous vehicles, as it provides a solution with sim-ple conﬁguration compared to typical multi-sensor systems.The main challenge in monocular 3D detection lies in accu-rately predicting object depth, which must be inferred from object and scene cues due to the lack of direct range mea-surement. Many methods attempt to directly estimate depth to assist in 3D detection, but show limited performance as a result of depth inaccuracy. Our proposed solution, Categor-ical Depth Distribution Network (CaDDN), uses a predicted categorical depth distribution for each pixel to project rich contextual feature information to the appropriate depth in-terval in 3D space. We then use the computationally efﬁ-cient bird’s-eye-view projection and single-stage detector to produce the ﬁnal output detections. We design CaDDN as a fully differentiable end-to-end approach for joint depth es-timation and object detection. We validate our approach on the KITTI 3D object detection benchmark, where we rank 1st among published monocular methods. We also provide the ﬁrst monocular 3D detection results on the newly re-leased Waymo Open Dataset. We provide a code release forCaDDN which is made available. 