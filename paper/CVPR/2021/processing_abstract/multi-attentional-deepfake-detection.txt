Face forgery by deepfake is widely spread over the in-ternet and has raised severe societal concerns. Recently, how to detect such forgery contents has become a hot re-search topic and many deepfake detection methods have been proposed. Most of them model deepfake detection as a vanilla binary classiﬁcation problem, i.e, ﬁrst use a backbone network to extract a global feature and then feed it into a binary classiﬁer (real/fake). But since the differ-ence between the real and fake images in this task is often subtle and local, we argue this vanilla solution is not op-timal. In this paper, we instead formulate deepfake detec-tion as a ﬁne-grained classiﬁcation problem and propose a new multi-attentional deepfake detection network. Speciﬁ-cally, it consists of three key components: 1) multiple spa-tial attention heads to make the network attend to differ-ent local parts; 2) textural feature enhancement block to zoom in the subtle artifacts in shallow features; 3) aggre-gate the low-level textural feature and high-level semantic features guided by the attention maps. Moreover, to address the learning difﬁculty of this network, we further introduce a new regional independence loss and an attention guided data augmentation strategy. Through extensive experiments on different datasets, we demonstrate the superiority of our method over the vanilla binary classiﬁer counterparts, and achieve state-of-the-art performance. The models will be released recently at https://github.com/yoctta/ multiple-attention. 