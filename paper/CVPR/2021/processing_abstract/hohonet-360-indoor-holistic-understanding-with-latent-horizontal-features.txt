We present HoHoNet, a versatile and efﬁcient frame-work for holistic understanding of an indoor 360-degree panorama using a Latent Horizontal Feature (LHFeat). The compact LHFeat ﬂattens the features along the vertical direc-tion and has shown success in modeling per-column modal-ity for room layout reconstruction. HoHoNet advances in two important aspects. First, the deep architecture is re-designed to run faster with improved accuracy. Second, we propose a novel horizon-to-dense module, which relaxes the per-column output shape constraint, allowing per-pixel dense prediction from LHFeat. HoHoNet is fast: It runs at 52 FPS and 110 FPS with ResNet-50 and ResNet-34 back-bones respectively, for modeling dense modalities from a high-resolution 512 × 1024 panorama. HoHoNet is also accurate. On the tasks of layout estimation and semantic segmentation, HoHoNet achieves results on par with cur-rent state-of-the-art. On dense depth estimation, HoHoNet outperforms all the prior arts by a large margin. Code is available at https:// github.com/ sunset1995/ HoHoNet. 