Monocular 3D reconstruction of articulated object cat-egories is challenging due to the lack of training data and the inherent ill-posedness of the problem. In this work we use video self-supervision, forcing the consistency of con-secutive 3D reconstructions by a motion-based cycle loss.This largely improves both optimization-based and learning-based 3D mesh reconstruction. We further introduce an in-terpretable model of 3D template deformations that controls a 3D surface through the displacement of a small number of local, learnable handles. We formulate this operation as a structured layer relying on mesh-laplacian regularization and show that it can be trained in an end-to-end manner.We Ô¨Ånally introduce a per-sample numerical optimisation approach that jointly optimises over mesh displacements and cameras within a video, boosting accuracy both for training and also as test time post-processing.While relying exclusively on a small set of videos col-lected per category for supervision, we obtain state-of-the-art reconstructions with diverse shapes, viewpoints and textures for multiple articulated object categories. Sup-plementary materials, code, and videos are provided on the project page: https://fkokkinos.github.io/ video_3d_reconstruction/. 