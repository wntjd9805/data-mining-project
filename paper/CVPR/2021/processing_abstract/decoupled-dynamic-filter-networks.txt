Convolution is one of the basic building blocks of CNN architectures. Despite its common use, standard convo-lution has two main shortcomings: Content-agnostic andComputation-heavy. Dynamic ﬁlters are content-adaptive, while further increasing the computational overhead.Depth-wise convolution is a lightweight variant, but it usu-ally leads to a drop in CNN performance or requires a larger number of channels. In this work, we propose theDecoupled Dynamic Filter (DDF) that can simultaneously tackle both of these shortcomings. Inspired by recent ad-vances in attention, DDF decouples a depth-wise dynamicﬁlter into spatial and channel dynamic ﬁlters. This decom-position considerably reduces the number of parameters and limits computational costs to the same level as depth-wise convolution. Meanwhile, we observe a signiﬁcant boost in performance when replacing standard convolution with DDF in classiﬁcation networks. ResNet50 / 101 get improved by 1.9% and 1.3% on the top-1 accuracy, while their computational costs are reduced by nearly half. Ex-periments on the detection and joint upsampling networks also demonstrate the superior performance of the DDF up-sampling variant (DDF-Up) in comparison with standard convolution and specialized content-adaptive layers. The project page with code is available1. 