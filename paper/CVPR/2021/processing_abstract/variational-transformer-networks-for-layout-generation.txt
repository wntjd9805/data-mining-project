Generative models able to synthesize layouts of different kinds (e.g. documents, user interfaces or furniture arrange-ments) are a useful tool to aid design processes and as a Ô¨Årst step in the generation of synthetic data, among other tasks.We exploit the properties of self-attention layers to capture high level relationships between elements in a layout, and use these as the building blocks of the well-known Varia-tional Autoencoder (VAE) formulation. Our proposed Vari-ational Transformer Network (VTN) is capable of learning margins, alignments and other global design rules without explicit supervision. Layouts sampled from our model have a high degree of resemblance to the training data, while demonstrating appealing diversity. In an extensive evalua-tion on publicly available benchmarks for different layout types VTNs achieve state-of-the-art diversity and percep-tual quality. Additionally, we show the capabilities of this method as part of a document layout detection pipeline. 