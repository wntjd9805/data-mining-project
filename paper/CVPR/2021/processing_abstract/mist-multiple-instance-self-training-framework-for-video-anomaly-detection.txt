Weakly supervised video anomaly detection (WS-VAD) is to distinguish anomalies from normal events based on dis-criminative representations. Most existing works are lim-ited in insufﬁcient video representations. In this work, we develop a multiple instance self-training framework (MIST) to efﬁciently reﬁne task-speciﬁc discriminative representa-tions with only video-level annotations. In particular, MIST is composed of 1) a multiple instance pseudo label gener-ator, which adapts a sparse continuous sampling strategy to produce more reliable clip-level pseudo labels, and 2) a self-guided attention boosted feature encoder that aims to automatically focus on anomalous regions in frames while extracting task-speciﬁc representations. Moreover, we adopt a self-training scheme to optimize both compo-nents and ﬁnally obtain a task-speciﬁc feature encoder. Ex-tensive experiments on two public datasets demonstrate the efﬁcacy of our method, and our method performs compara-bly to or even better than existing supervised and weakly su-pervised methods, speciﬁcally obtaining a frame-level AUC 94.83% on ShanghaiTech. 