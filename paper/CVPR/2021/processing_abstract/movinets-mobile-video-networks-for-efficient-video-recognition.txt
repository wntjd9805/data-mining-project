We present Mobile Video Networks (MoViNets), a fam-ily of computation and memory efﬁcient video networks that can operate on streaming video for online inference. 3D convolutional neural networks (CNNs) are accurate at video recognition but require large computation and mem-ory budgets and do not support online inference, making them difﬁcult to work on mobile devices. We propose a three-step approach to improve computational efﬁciency while substantially reducing the peak memory usage of 3DCNNs. First, we design a video network search space and employ neural architecture search to generate efﬁcient and diverse 3D CNN architectures. Second, we introduce theStream Buffer technique that decouples memory from video clip duration, allowing 3D CNNs to embed arbitrary-length streaming video sequences for both training and inference with a small constant memory footprint. Third, we pro-pose a simple ensembling technique to improve accuracy further without sacriﬁcing efﬁciency. These three progres-sive techniques allow MoViNets to achieve state-of-the-art accuracy and efﬁciency on the Kinetics, Moments in Time, and Charades video action recognition datasets. For in-stance, MoViNet-A5-Stream achieves the same accuracy asX3D-XL on Kinetics 600 while requiring 80% fewer FLOPs and 65% less memory. Code is available at https://github.com/google-research/movinet. 