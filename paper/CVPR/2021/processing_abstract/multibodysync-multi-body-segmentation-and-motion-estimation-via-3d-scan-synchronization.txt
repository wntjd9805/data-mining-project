We present MultiBodySync, a novel, end-to-end train-able multi-body motion segmentation and rigid registra-tion framework for multiple input 3D point clouds. The two non-trivial challenges posed by this multi-scan multi-body setting that we investigate are: (i) guaranteeing cor-respondence and segmentation consistency across multi-ple input point clouds capturing different spatial arrange-ments of bodies or body parts; and (ii) obtaining ro-bust motion-based rigid body segmentation applicable to novel object categories. We propose an approach to ad-dress these issues that incorporates spectral synchroniza-tion into an iterative deep declarative network, so as to si-multaneously recover consistent correspondences as well as motion segmentation. At the same time, by explicitly disentangling the correspondence and motion segmenta-tion estimation modules, we achieve strong generalizabil-ity across different object categories. Our extensive evalu-ations demonstrate that our method is effective on various datasets ranging from rigid parts in articulated objects to individually moving objects in a 3D scene, be it single-view or full point clouds. Code at https://github.com/ huangjh-pub/multibody-sync. 