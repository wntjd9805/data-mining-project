With the maturing of deep learning systems, trustworthiness is becoming increasingly important for model assessment.We understand trustworthiness as the combination of ex-plainability and robustness. Generative classiﬁers (GCs) are a promising class of models that are said to naturally accomplish these qualities. However, this has mostly been demonstrated on simple datasets such as MNIST and CIFAR in the past. In this work, we ﬁrstly develop an architecture and training scheme that allows GCs to operate on a more relevant level of complexity for practical computer vision, namely the ImageNet challenge. Secondly, we demonstrate the immense potential of GCs for trustworthy image clas-siﬁcation. Explainability and some aspects of robustness are vastly improved compared to feed-forward models, even when the GCs are just applied naively. While not all trust-worthiness problems are solved completely, we observe thatGCs are a highly promising basis for further algorithms and modiﬁcations. We release our trained model for download in the hope that it serves as a starting point for other gen-erative classiﬁcation tasks, in much the same way as pre-trained ResNet architectures do for discriminative classiﬁ-cation.Code: github.com/VLL-HD/trustworthy GCs 