We present Sparse R-CNN, a purely sparse method for object detection in images. Existing works on object de-tection heavily rely on dense object candidates, such as k anchor boxes pre-deﬁned on all grids of image feature map of size H × W .In our method, however, a ﬁxed sparse set of learned object proposals, total length of N , are provided to object recognition head to perform classiﬁ-cation and location. By eliminating HW k (up to hundreds of thousands) hand-designed object candidates to N (e.g. 100) learnable proposals, Sparse R-CNN completely avoids all efforts related to object candidates design and many-to-one label assignment. More importantly, ﬁnal predictions are directly output without non-maximum suppression post-procedure. Sparse R-CNN demonstrates accuracy, run-time and training convergence performance on par with the well-established detector baselines on the challenging COCO dataset, e.g., achieving 45.0 AP in standard 3× train-ing schedule and running at 22 fps using ResNet-50 FPN model. We hope our work could inspire re-thinking the con-vention of dense prior in object detectors. The code is avail-able at: https://github.com/PeizeSun/SparseR-CNN.* Equal contribution.PAOCOC 50 45 40 35 30 25 20 15 500 epochsRetinaNetFaster R-CNNDETRSparse R-CNN 120 140 3x schedule 0 20 40 80 60Training Epochs 100Figure 2 – Convergence curves of RetinaNet, Faster R-CNN,DETR and Sparse R-CNN on COCO val2017 [24]. SparseR-CNN achieves competitive performance in terms of training efﬁciency and detection quality. 