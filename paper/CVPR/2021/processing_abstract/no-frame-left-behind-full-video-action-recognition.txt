Not all video frames are equally informative for recog-nizing an action. It is computationally infeasible to train deep networks on all video frames when actions develop over hundreds of frames. A common heuristic is uniformly sampling a small number of video frames and using these to recognize the action. Instead, here we propose full video action recognition and consider all video frames. To make this computational tractable, we ﬁrst cluster all frame acti-vations along the temporal dimension based on their simi-larity with respect to the classiﬁcation task, and then tem-porally aggregate the frames in the clusters into a smaller number of representations. Our method is end-to-end train-able and computationally efﬁcient as it relies on tempo-rally localized clustering in combination with fast Ham-ming distances in feature space. We evaluate on UCF101,HMDB51, Breakfast, and Something-Something V1 and V2, where we compare favorably to existing heuristic frame sampling methods. 