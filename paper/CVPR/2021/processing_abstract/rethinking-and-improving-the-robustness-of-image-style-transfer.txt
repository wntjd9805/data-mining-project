On pre-trained modelsOn random modelsExtensive research in neural style transfer methods has shown that the correlation between features extracted by a pre-trained VGG network has a remarkable ability to cap-ture the visual style of an image. Surprisingly, however, this stylization quality is not robust and often degrades signif-icantly when applied to features from more advanced and lightweight networks, such as those in the ResNet family.By performing extensive experiments with different network architectures, we Ô¨Ånd that residual connections, which rep-resent the main architectural difference between VGG andResNet, produce feature maps of small entropy, which are not suitable for style transfer. To improve the robustness of theResNet architecture, we then propose a simple yet effective solution based on a softmax transformation of the feature activations that enhances their entropy. Experimental results demonstrate that this small magic can greatly improve the quality of stylization results, even for networks with random weights. This suggests that the architecture used for feature extraction is more important than the use of learned weights for the task of style transfer. 