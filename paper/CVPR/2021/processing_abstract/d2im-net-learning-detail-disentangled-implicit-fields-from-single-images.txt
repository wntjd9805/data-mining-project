We present the ﬁrst single-view 3D reconstruction net-work aimed at recovering geometric details from an input image which encompass both topological shape structures and surface features. Our key idea is to train the network to learn a detail disentangled reconstruction consisting of two functions, one implicit ﬁeld representing the coarse 3D shape and the other capturing the details. Given an in-put image, our network, coined D2IM-Net, encodes it into global and local features which are respectively fed into two decoders. The base decoder uses the global features to re-construct a coarse implicit ﬁeld, while the detail decoder re-constructs, from the local features, two displacement maps, deﬁned over the front and back sides of the captured ob-ject. The ﬁnal 3D reconstruction is a fusion between the base shape and the displacement maps, with three losses enforcing the recovery of coarse shape, overall structure, and surface details via a novel Laplacian term. 