Active Learning for discriminative models has largely been studied with the focus on individual samples, with less emphasis on how classes are distributed or which classes are hard to deal with. In this work, we show that this is harmful. We propose a method based on the Bayes’ rule, that can naturally incorporate class imbalance into the Ac-tive Learning framework. We derive that three terms should be considered together when estimating the probability of a classiﬁer making a mistake for a given sample; i) probability of mislabelling a class, ii) likelihood of the data given a pre-dicted class, and iii) the prior probability on the abundance of a predicted class. Implementing these terms requires a generative model and an intractable likelihood estimation.Therefore, we train a Variational Auto Encoder (VAE) for this purpose. To further tie the VAE with the classiﬁer and facilitate VAE training, we use the classiﬁers’ deep feature representations as input to the VAE. By considering all three probabilities, among them, especially the data imbalance, we can substantially improve the potential of existing meth-ods under limited data budget. We show that our method can be applied to classiﬁcation tasks on multiple different datasets – including one that is a real-world dataset with heavy data imbalance – signiﬁcantly outperforming the state of the art.Figure 1. Class matters – We show an example where existing methods fail to identify important samples to put into the updated training set. We show the importance metrics given by various methods – DBAL [10], CoreSet [38], Max. Entropy [45], and our method – for selected images when the dataset is dominated by plane images. We further show below each image, the ground-truth class y and the predicted class y. Because of the data imbalance, b existing methods heavily favour the plane class, even when the results are correct, as seen on the left. And for rare classes in the right column, they fail to recognise that the samples are important, which leads to the improved performance. On the other hand, our method correctly identiﬁes them as important, by considering also the class difﬁculty and the class prior. 