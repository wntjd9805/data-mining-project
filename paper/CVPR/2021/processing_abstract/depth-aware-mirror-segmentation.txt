We present a novel mirror segmentation method that leverages depth estimates from ToF-based cameras as an additional cue to disambiguate challenging cases where the contrast or relation in RGB colors between the mirror re-ﬂection and the surrounding scene is subtle. A key observa-tion is that ToF depth estimates do not report the true depth of the mirror surface, but instead return the total length of the reﬂected light paths, thereby creating obvious depth dis-continuities at the mirror boundaries. To exploit depth in-formation in mirror segmentation, we ﬁrst construct a large-scale RGB-D mirror segmentation dataset, which we subse-quently employ to train a novel depth-aware mirror segmen-tation framework. Our mirror segmentation framework ﬁrst locates the mirrors based on color and depth discontinuities and correlations. Next, our model further reﬁnes the mirror boundaries through contextual contrast taking into account both color and depth information. We extensively validate our depth-aware mirror segmentation method and demon-strate that our model outperforms state-of-the-art RGB andRGB-D based methods for mirror segmentation. Experi-mental results also show that depth is a powerful cue for mirror segmentation. 