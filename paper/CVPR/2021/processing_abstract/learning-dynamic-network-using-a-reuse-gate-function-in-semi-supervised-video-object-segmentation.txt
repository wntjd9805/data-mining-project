Current state-of-the-art approaches for Semi-supervisedVideo Object Segmentation (Semi-VOS) propagates infor-mation from previous frames to generate segmentation mask for the current frame. This results in high-quality seg-mentation across challenging scenarios such as changes in appearance and occlusion. But it also leads to un-necessary computations for stationary or slow-moving ob-jects where the change across frames is minimal. In this work, we exploit this observation by using temporal in-formation to quickly identify frames with minimal change and skip the heavyweight mask generation step. To re-alize this efﬁciency, we propose a novel dynamic net-work that estimates change across frames and decides which path – computing a full network or reusing pre-vious frame’s feature – to choose depending on the ex-pected similarity. Experimental results show that our ap-proach signiﬁcantly improves inference speed without much accuracy degradation on challenging Semi-VOS datasets – DAVIS 16, DAVIS 17, and YouTube-VOS. Furthermore, our approach can be applied to multiple Semi-VOS meth-ods demonstrating its generality. The code is available in https://github.com/HYOJINPARK/Reuse VOS . 