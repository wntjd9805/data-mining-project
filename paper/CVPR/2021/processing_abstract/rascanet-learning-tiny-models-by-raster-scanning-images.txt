Deploying deep convolutional neural networks on ultra-low power systems is challenging due to the extremely lim-ited resources. Especially, the memory becomes a bottle-neck as the systems put a hard limit on the size of on-chip memory. Because peak memory explosion in the lower lay-ers is critical even in tiny models, the size of an input im-age should be reduced with sacriﬁce in accuracy. To over-come this drawback, we propose a novel Raster-ScanningNetwork, named RaScaNet, inspired by raster-scanning in image sensors. RaScaNet reads only a few rows of pixels at a time using a convolutional neural network and then se-quentially learns the representation of the whole image us-ing a recurrent neural network. The proposed method oper-ates on an ultra-low power system without input size reduc-tion; it requires 15.9–24.3× smaller peak memory and 5.3– 12.9× smaller weight memory than the state-of-the-art tiny models. Moreover, RaScaNet fully exploits on-chip SRAM and cache memory of the system as the sum of the peak memory and the weight memory does not exceed 60 KB, improving the power efﬁciency of the system.In our ex-periments, we demonstrate the binary classiﬁcation perfor-mance of RaScaNet on Visual Wake Words and Pascal VOC datasets. 