Pre-trained models play an important role in deep learn-ing based text detectors. However, most methods ignore the gap between natural images and scene text images and di-rectly apply ImageNet for pre-training. To address such a problem, some of them ﬁrstly pre-train the model using a large amount of synthetic data and then ﬁne-tune it on tar-get datasets, which is task-speciﬁc and has limited general-ization capability. In this paper, we focus on providing gen-eral pre-trained models for text detectors. Considering the importance of exploring text contents for text detection, we propose STKM (Self-attention based Text Knowledge Min-ing), which consists of a CNN Encoder and a Self-attentionDecoder, to learn general prior knowledge for text detec-tion from SynthText. Given only image level text labels,Self-attention Decoder directly decodes features extracted from CNN Encoder to texts without requirement of detec-tion, which guides the CNN backbone to explicitly learn discriminative semantic representations ignored by previ-ous approaches. After that, the text knowledge learned by the backbone can be transferred to various text detectors to signiﬁcantly improve their detection performance (e.g., 5.89% higher F-measure for EAST on ICDAR15 dataset) without bells and whistles. Pre-trained model is available at: https://github.com/CVI-SZU/STKM 