One-shot talking face generation should synthesize high visual quality facial videos with reasonable animations of expression and head pose, and just utilize arbitrary driv-ing audio and arbitrary single face image as the source.Current works fail to generate over 256×256 resolution realistic-looking videos due to the lack of an appropriate high-resolution audio-visual dataset, and the limitation of the sparse facial landmarks in providing poor expression details. To synthesize high-deﬁnition videos, we build a large in-the-wild high-resolution audio-visual dataset and propose a novel ﬂow-guided talking face generation frame-work. The new dataset is collected from youtube and con-sists of about 16 hours 720P or 1080P videos. We leverage the facial 3D morphable model (3DMM) to split the frame-work into two cascaded modules instead of learning a di-rect mapping from audio to video. In the ﬁrst module, we propose a novel animation generator to produce the move-ments of mouth, eyebrow and head pose simultaneously. In the second module, we transform animation into dense ﬂow to provide more expression details and carefully design a novel ﬂow-guided video generator to synthesize videos. Our method is able to produce high-deﬁnition videos and out-performs state-of-the-art works in objective and subjective comparisons*. 