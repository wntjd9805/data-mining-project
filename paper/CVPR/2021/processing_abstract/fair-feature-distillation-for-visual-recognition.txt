Fairness is becoming an increasingly crucial issue for computer vision, especially in the human-related decision systems. However, achieving algorithmic fairness, which makes a model produce indiscriminative outcomes against protected groups, is still an unresolved problem.In this paper, we devise a systematic approach which reduces al-gorithmic biases via feature distillation for visual recogni-tion tasks, dubbed as MMD-based Fair Distillation (MFD).While the distillation technique has been widely used in general to improve the prediction accuracy, to the best of our knowledge, there has been no explicit work that also tries to improve fairness via distillation. Furthermore, We give a theoretical justiﬁcation of our MFD on the effect of knowledge distillation and fairness. Throughout the exten-sive experiments, we show our MFD signiﬁcantly mitigates the bias against speciﬁc minorities without any loss of the accuracy on both synthetic and real-world face datasets. 