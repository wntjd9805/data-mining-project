We propose a framework for sequence-to-sequence con-trastive learning (SeqCLR) of visual representations, which we apply to text recognition. To account for the sequence-to-sequence structure, each feature map is divided into dif-ferent instances over which the contrastive loss is com-puted. This operation enables us to contrast in a sub-word level, where from each image we extract several positive pairs and multiple negative examples. To yield effective vi-sual representations for text recognition, we further suggest novel augmentation heuristics, different encoder architec-tures and custom projection heads. Experiments on hand-written text and on scene text show that when a text decoder is trained on the learned representations, our method out-performs non-sequential contrastive methods. In addition, when the amount of supervision is reduced, SeqCLR sig-niﬁcantly improves performance compared with supervised training, and when ﬁne-tuned with 100% of the labels, our method achieves state-of-the-art results on standard hand-written text recognition benchmarks. 