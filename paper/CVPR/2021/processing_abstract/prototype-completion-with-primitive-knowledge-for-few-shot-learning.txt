Few-shot learning is a challenging task, which aims to learn a classiﬁer for novel classes with few examples. Pre-training based meta-learning methods effectively tackle the problem by pre-training a feature extractor and then ﬁne-tuning it through the nearest centroid based meta-learning.However, results show that the ﬁne-tuning step makes veryIn this paper, 1) we ﬁgure out marginal improvements. the key reason, i.e., in the pre-trained feature space, the base classes already form compact clusters while novel classes spread as groups with large variances, which im-plies that ﬁne-tuning the feature extractor is less meaning-ful; 2) instead of ﬁne-tuning the feature extractor, we focus on estimating more representative prototypes during meta-learning. Consequently, we propose a novel prototype com-pletion based meta-learning framework. This frameworkﬁrst introduces primitive knowledge (i.e., class-level part or attribute annotations) and extracts representative attribute features as priors. Then, we design a prototype completion network to learn to complete prototypes with these priors.To avoid the prototype completion error caused by primitive knowledge noises or class differences, we further develop a Gaussian based prototype fusion strategy that combines the mean-based and completed prototypes by exploiting the unlabeled samples. Extensive experiments show that our method: (i) can obtain more accurate prototypes; (ii) out-performs state-of-the-art techniques by 2% 9% in terms of classiﬁcation accuracy. Our code is available online 1.∼ 