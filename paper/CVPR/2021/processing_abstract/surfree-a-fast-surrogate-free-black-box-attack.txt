Machine learning classiﬁers are critically prone to eva-sion attacks. Adversarial examples are slightly modiﬁed inputs that are then misclassiﬁed, while remaining percep-tively close to their originals. Last couple of years have witnessed a striking decrease in the amount of queries a black box attack submits to the target classiﬁer, in order to forge adversarials. This particularly concerns the black box score-based setup, where the attacker has access to top predicted probabilites: the amount of queries went from to millions of to less than a thousand.This paper presents SurFree, a geometrical approach that achieves a drastic reduction in the amount of queries in the hardest setup: black box decision-based attacks (only the top-1 label is available). We ﬁrst highlight that the most recent attacks in that setup, HSJA [3], QEBA [14] and GeoDA [23] all perform costly gradient surrogate es-timations. SurFree proposes to bypass these, by instead focusing on careful trials along diverse directions, guided by precise indications of geometrical properties of the clas-siﬁer decision boundaries. We motivate this geometric ap-proach before performing a head-to-head comparison with previous attacks with the amount of queries as a ﬁrst class citizen. We exhibit a faster distortion decay under low query amounts (few hundreds to a thousand), while remaining competitive at higher query budgets.1 