This paper addresses the problem of learning to esti-mate the depth of detected objects given some measure-ment of camera motion (e.g., from robot kinematics or ve-hicle odometry). We achieve this by 1) designing a recur-rent neural network (DBox) that estimates the depth of ob-jects using a generalized representation of bounding boxes and uncalibrated camera movement and 2) introducing theObject Depth via Motion and Detection Dataset (ODMD).ODMD training data are extensible and conÔ¨Ågurable, and the ODMD benchmark includes 21,600 examples across four validation and test sets. These sets include mobile robot experiments using an end-effector camera to locate objects from the YCB dataset and examples with perturba-tions added to camera motion or bounding box data. In ad-dition to the ODMD benchmark, we evaluate DBox in other monocular application domains, achieving state-of-the-art results on existing driving and robotics benchmarks and es-timating the depth of objects using a camera phone. 