Domain adaptation deals with training models using large scale labeled data from a speciﬁc source domain and then adapting the knowledge to certain target domains that have few or no labels. Many prior works learn do-main agnostic feature representations for this purpose us-ing a global distribution alignment objective which does not take into account the ﬁner class speciﬁc structure in the source and target domains. We address this issue in our work and propose an instance afﬁnity based criterion for source to target transfer during adaptation, called ILA-DA. We ﬁrst propose a reliable and efﬁcient method to ex-tract similar and dissimilar samples across source and tar-get, and utilize a multi-sample contrastive loss to drive the domain alignment process. ILA-DA simultaneously ac-counts for intra-class clustering as well as inter-class sepa-ration among the categories, resulting in less noisy clas-siﬁer boundaries, improved transferability and increased accuracy. We verify the effectiveness of ILA-DA by ob-serving consistent improvements in accuracy over popu-lar domain adaptation approaches on a variety of bench-mark datasets and provide insights into the proposed align-ment approach. Code will be made publicly available at https://github.com/astuti/ILA-DA. 