Action segmentation refers to inferring boundaries of se-mantically consistent visual concepts in videos and is an important requirement for many video understanding tasks.For this and other video understanding tasks, supervised approaches have achieved encouraging performance but re-quire a high volume of detailed frame-level annotations.We present a fully automatic and unsupervised approach for segmenting actions in a video that does not require any training. Our proposal is an effective temporally-weighted hierarchical clustering algorithm that can group semanti-cally consistent frames of the video. Our main ﬁnding is that representing a video with a 1-nearest neighbor graph by taking into account the time progression is sufﬁcient to form semantically and temporally consistent clusters of frames where each cluster may represent some action in the video. Additionally, we establish strong unsupervised base-lines for action segmentation and show signiﬁcant perfor-mance improvements over published unsupervised methods on ﬁve challenging action segmentation datasets. Our code is available.1 