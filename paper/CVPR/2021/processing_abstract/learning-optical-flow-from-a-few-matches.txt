State-of-the-art neural network models for optical ﬂow estimation require a dense correlation volume at high reso-lutions for representing per-pixel displacement. Although the dense correlation volume is informative for accurate estimation, its heavy computation and memory usage hin-ders the efﬁcient training and deployment of the models. In this paper, we show that the dense correlation volume rep-resentation is redundant and accurate ﬂow estimation can be achieved with only a fraction of elements in it. Based on this observation, we propose an alternative displacement representation, named Sparse Correlation Volume, which is constructed directly by computing the k closest matches in one feature map for each feature vector in the other fea-ture map and stored in a sparse data structure. Experi-ments show that our method can reduce computational cost and memory use signiﬁcantly, while maintaining high accu-racy compared to previous approaches with dense correla-tion volumes. 