This paper presents a novel method, termed Bridge toAnswer, to infer correct answers for questions about a given video by leveraging adequate graph interactions of hetero-geneous crossmodal graphs. To realize this, we learn ques-tion conditioned visual graphs by exploiting the relation be-tween video and question to enable each visual node using question-to-visual interactions to encompass both visual and linguistic cues. In addition, we propose bridged visual-to-visual interactions to incorporate two complementary vi-sual information on appearance and motion by placing the question graph as an intermediate bridge. This bridged ar-chitecture allows reliable message passing through compo-sitional semantics of the question to generate an appropri-ate answer. As a result, our method can learn the question conditioned visual representations attributed to appearance and motion that show powerful capability for video question answering. Extensive experiments prove that the proposed method provides effective and superior performance than state-of-the-art methods on several benchmarks. 