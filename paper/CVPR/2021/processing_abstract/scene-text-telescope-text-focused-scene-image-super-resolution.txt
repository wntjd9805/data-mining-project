Image super-resolution, which is often regarded as a pre-processing procedure of scene text recognition, aims to re-cover the realistic features from a low-resolution text im-age. It has always been challenging due to large variations in text shapes, fonts, backgrounds, etc. However, most exist-ing methods employ generic super-resolution frameworks to handle scene text images while ignoring text-speciÔ¨Åc prop-erties such as text-level layouts and character-level details.In this paper, we establish a text-focused super-resolution framework, called Scene Text Telescope (STT). In terms of text-level layouts, we propose a Transformer-Based Super-Resolution Network (TBSRN) containing a Self-AttentionModule to extract sequential information, which is robust to tackle the texts in arbitrary orientations.In terms of character-level details, we propose a Position-Aware Mod-ule and a Content-Aware Module to highlight the position and the content of each character. By observing that some characters look indistinguishable in low-resolution condi-tions, we use a weighted cross-entropy loss to tackle this problem. We conduct extensive experiments, including text recognition with pre-trained recognizers and image qual-ity evaluation, on TextZoom and several scene text recog-nition benchmarks to assess the super-resolution images.The experimental results show that our STT can indeed gen-erate text-focused super-resolution images and outperform the existing methods in terms of recognition accuracy. 