We introduce DatasetGAN: an automatic procedure to generate massive datasets of high-quality semantically seg-mented images requiring minimal human effort. Current deep networks are extremely data-hungry, beneﬁting from training on large-scale datasets, which are time consuming to annotate. Our method relies on the power of recent GANs to generate realistic images. We show how the GAN latent code can be decoded to produce a semantic segmentation of the image. Training the decoder only needs a few labeled examples to generalize to the rest of the latent space, result-ing in an inﬁnite annotated dataset generator! These gen-erated datasets can then be used for training any computer vision architecture just as real datasets are. As only a few images need to be manually segmented, it becomes possible to annotate images in extreme detail and generate datasets with rich object and part segmentations. To showcase the power of our approach, we generated datasets for 7 image segmentation tasks which include pixel-level labels for 34 human face parts, and 32 car parts. Our approach outper-forms all semi-supervised baselines signiﬁcantly and is on par with fully supervised methods, which in some cases re-quire as much as 100x more annotated data as our method. 