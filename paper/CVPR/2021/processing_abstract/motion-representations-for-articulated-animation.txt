SourceAnimatedWe propose novel motion representations for animating articulated objects consisting of distinct parts. In a com-pletely unsupervised manner, our method identiﬁes object parts, tracks them in a driving video, and infers their motions by considering their principal axes. In contrast to the previ-ous keypoint-based works, our method extracts meaningful and consistent regions, describing locations, shape, and pose. The regions correspond to semantically relevant and distinct object parts, that are more easily detected in frames of the driving video. To force decoupling of foreground from background, we model non-object related global motion with an additional afﬁne transformation. To facilitate animation and prevent the leakage of the shape of the driving object, we disentangle shape and pose of objects in the region space.Our model1 can animate a variety of objects, surpassing pre-vious methods by a large margin on existing benchmarks. We present a challenging new benchmark with high-resolution videos and show that the improvement is particularly pro-nounced when articulated objects are considered, reaching 96.6% user preference vs. the state of the art. 