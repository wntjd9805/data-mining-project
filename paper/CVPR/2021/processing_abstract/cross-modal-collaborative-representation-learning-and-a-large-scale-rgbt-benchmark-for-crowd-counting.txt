Crowd counting is a fundamental yet challenging task, which desires rich information to generate pixel-wise crowd density maps. However, most previous methods only used the limited information of RGB images and cannot well discover potential pedestrians in unconstrained scenarios.In this work, we ﬁnd that incorporating optical and ther-mal information can greatly help to recognize pedestrians.To promote future researches in this ﬁeld, we introduce a large-scale RGBT Crowd Counting (RGBT-CC) bench-mark, which contains 2,030 pairs of RGB-thermal images with 138,389 annotated people. Furthermore, to facili-tate the multimodal crowd counting, we propose a cross-modal collaborative representation learning framework, which consists of multiple modality-speciﬁc branches, a modality-shared branch, and an Information Aggregation-Distribution Module (IADM) to capture the complementary information of different modalities fully. Speciﬁcally, ourIADM incorporates two collaborative information transfers to dynamically enhance the modality-shared and modality-speciﬁc representations with a dual information propaga-tion mechanism. Extensive experiments conducted on theRGBT-CC benchmark demonstrate the effectiveness of our framework for RGBT crowd counting. Moreover, the pro-posed approach is universal for multimodal crowd count-ing and is also capable to achieve superior performance on the ShanghaiTechRGBD [22] dataset. Finally, our source code and benchmark have been released at http:// lingboliu.com/RGBT_Crowd_Counting.html. 