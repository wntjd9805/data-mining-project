Weakly supervised object localization (WSOL) aims at learning to localize objects of interest by only using the image-level labels as the supervision. While numerous ef-forts have been made in this ﬁeld, recent approaches still suffer from two challenges: one is the part domination is-sue while the other is the learning robustness issue. Specif-ically, the former makes the localizer prone to the local dis-criminative object regions rather than the desired whole ob-ject, and the latter makes the localizer over-sensitive to the variations of the input images so that one can hardly ob-tain localization results robust to the arbitrary visual stim-ulus. To solve these issues, we propose a novel framework to strengthen the learning tolerance, referred to as SLT-Net, for WSOL. Speciﬁcally, we consider two-fold learning toler-ance strengthening mechanisms. One is the semantic toler-ance strengthening mechanism, which allows the localizer to make mistakes for classifying similar semantics so that it will not concentrate too much on the discriminative local regions. The other is the visual stimuli tolerance strengthen-ing mechanism, which enforces the localizer to be robust to different image transformations so that the prediction qual-ity will not be sensitive to each speciﬁc input image. Fi-nally, we implement comprehensive experimental compar-isons on two widely-used datasets CUB and ILSVRC2012, which demonstrate the effectiveness of our proposed ap-proach. 