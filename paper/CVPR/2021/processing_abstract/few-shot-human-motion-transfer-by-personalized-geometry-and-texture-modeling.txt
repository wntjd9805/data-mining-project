Geometry GeneratorWe present a new method for few-shot human motion transfer that achieves realistic human image generation with only a small number of appearance inputs. Despite re-cent advances in single person motion transfer, prior meth-ods often require a large number of training images and take long training time. One promising direction is to per-form few-shot human motion transfer, which only needs a few of source images for appearance transfer. However, it is particularly challenging to obtain satisfactory transfer re-sults. In this paper, we address this issue by rendering a human texture map to a surface geometry (represented as aUV map), which is personalized to the source person. Our geometry generator combines the shape information from source images, and the pose information from 2D keypoints to synthesize the personalized UV map. A texture genera-tor then generates the texture map conditioned on the tex-ture of source images to ﬁll out invisible parts. Further-more, we may ﬁne-tune the texture map on the manifold of the texture generator from a few source images at the test time, which improves the quality of the texture map with-out over-ﬁtting or artifacts. Extensive experiments show the proposed method outperforms state-of-the-art methods both qualitatively and quantitatively. Our code is avail-able at https://github.com/HuangZhiChao95/FewShotMotionTransfer. 