We introduce a meta-regularization framework for learning-based image registration. Current learning-based image registration methods use high-resolution architec-tures such as U-Nets to produce spatial transformations, and impose simple and explicit regularization on the output of the network to ensure that the estimated displacements are smooth. While this approach works well on small de-formations, it has been known to struggle when the defor-mations are large. Our method uses a more advanced form of meta-regularization to increase the generalization ability of learned registration models. We motivate our approach based on Reproducing Kernel Hilbert Space (RKHS) theory, and approximate that framework via a meta-regularization convolutional layer with radially symmetric, positive semi-deﬁnite ﬁlters that inherent its regularization properties. We then provide a method to learn such regularization ﬁlters while also learning to register. Our experiments on syn-thetic and real datasets as well as ablation analysis show that our method can improve anatomical correspondence compared to competing methods, and reduce the percentage of folding and tear in the large deformation setting, reﬂect-ing better regularization and model generalization. 