Video-based person re-identiﬁcation (Re-ID) aims to au-tomatically retrieve video sequences of the same person under non-overlapping cameras. To achieve this goal, it is the key to fully utilize abundant spatial and temporal cues in videos. Existing methods usually focus on the most conspicuous image regions, thus they may easily miss outﬁne-grained clues due to the person varieties in image se-quences. To address above issues, in this paper, we propose a novel Global-guided Reciprocal Learning (GRL) frame-work for video-based person Re-ID. Speciﬁcally, we ﬁrst propose a Global-guided Correlation Estimation (GCE) to generate feature correlation maps of local features and global features, which help to localize the high- and low-correlation regions for identifying the same person. Af-ter that, the discriminative features are disentangled into high-correlation features and low-correlation features un-der the guidance of the global representations. Moreover, a novel Temporal Reciprocal Learning (TRL) mechanism is designed to sequentially enhance the high-correlation semantic information and accumulate the low-correlation sub-critical clues. Extensive experiments are conducted on three public benchmarks. The experimental results indi-cate that our approach can achieve better performance than other state-of-the-art approaches. The code is released at https://github.com/ﬂysnowtiger/GRL. 