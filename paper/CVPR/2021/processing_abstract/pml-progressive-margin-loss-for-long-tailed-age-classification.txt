In this paper, we propose a progressive margin loss (PM-L) approach for unconstrained facial age classiﬁcation.Conventional methods make strong assumption on that each class owns adequate instances to outline its data distribu-tion, likely leading to bias prediction where the training samples are sparse across age classes. Instead, our PML aims to adaptively reﬁne the age label pattern by enforc-ing a couple of margins, which fully takes in the in-between discrepancy of the intra-class variance, inter-class vari-ance and class center. Our PML typically incorporates with the ordinal margin and the variational margin, simultane-ously plugging in the globally-tuned deep neural network paradigm. More speciﬁcally, the ordinal margin learns to exploit the correlated relationship of the real-world age la-bels. Accordingly, the variational margin is leveraged to minimize the inﬂuence of head classes that misleads the pre-diction of tailed samples. Moreover, our optimization care-fully seeks a series of indicator curricula to achieve robust and efﬁcient model training. Extensive experimental result-s on three face aging datasets demonstrate that our PML achieves compelling performance compared to state of the art. Code will be made publicly. 