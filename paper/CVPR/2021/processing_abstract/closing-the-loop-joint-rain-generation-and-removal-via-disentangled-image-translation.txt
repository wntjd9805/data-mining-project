Existing deep learning-based image deraining methods have achieved promising performance for synthetic rainy images, typically rely on the pairs of sharp images and simulated rainy counterparts. However, these methods suf-fer from signiﬁcant performance drop when facing the real rain, because of the huge gap between the simpliﬁed syn-thetic rain and the complex real rain. In this work, we ar-gue that the rain generation and removal are the two sides of the same coin and should be tightly coupled. To close the loop, we propose to jointly learn real rain generation and removal procedure within a uniﬁed disentangled image translation framework. Speciﬁcally, we propose a bidirec-tional disentangled translation network, in which each uni-directional network contains two loops of joint rain genera-tion and removal for both the real and synthetic rain image, respectively. Meanwhile, we enforce the disentanglement strategy by decomposing the rainy image into a clean back-ground and rain layer (rain removal), in order to better pre-serve the identity background via both the cycle-consistency loss and adversarial loss, and ease the rain layer translat-ing between the real and synthetic rainy image. A counter-part composition with the entanglement strategy is symmet-rically applied for rain generation. Extensive experiments on synthetic and real-world rain datasets show the superi-ority of proposed method compared to state-of-the-arts. 