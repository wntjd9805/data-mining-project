Reasoning the human-object interactions (HOI) is es-sential for deeper scene understanding, while object affor-dances (or functionalities) are of great importance for hu-man to discover unseen HOIs with novel objects. Inspired by this, we introduce an affordance transfer learning ap-proach to jointly detect HOIs with novel object and rec-ognize affordances. Speciﬁcally, HOI representations can be decoupled into a combination of affordance and object representations, making it possible to compose novel inter-actions by combining affordance representations and novel object representations from additional images, i.e. transfer-ring the affordance to novel objects. With the proposed affordance transfer learning, the model is also capable of inferring the affordances of novel objects from known af-fordance representations. The proposed method can thus be used to 1) improve the performance of HOI detection, especially for the HOIs with unseen objects; and 2) infer the affordances of novel objects. Experimental results on two datasets, HICO-DET and HOI-COCO (from V-COCO), demonstrate signiﬁcant improvements over recent state-of-the-art methods for HOI detection and object affordance de-tection. Code is available at https://github.com/ zhihou7/HOI-CL.Figure 1. An intuitive example to demonstrate affordance trans-fer learning for jointly exploring human interactions with novel objects (e.g., “tiger”), and recognizing the affordance of novel ob-jects. The proposed method is able to learn from the unseen in-teraction samples (e.g., “ride tiger”) that are composed from af-fordance representations and novel object representations, which meanwhile transfers the affordance to novel objects and enables the object affordance recognition. 