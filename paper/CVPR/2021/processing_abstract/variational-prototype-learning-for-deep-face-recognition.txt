Deep face recognition has achieved remarkable im-provements due to the introduction of margin-based soft-max loss, in which the prototype stored in the last linear layer represents the center of each class. In these methods, training samples are enforced to be close to positive pro-totypes and far apart from negative prototypes by a clear margin. However, we argue that prototype learning only employs sample-to-prototype comparisons without consid-ering sample-to-sample comparisons during training and the low loss value gives us an illusion of perfect feature embedding, impeding the further exploration of SGD. To this end, we propose Variational Prototype Learning (VPL), which represents every class as a distribution instead of a point in the latent space. By identifying the slow feature drift phenomenon, we directly inject memorized features into prototypes to approximate variational prototype sam-pling. The proposed VPL can simulate sample-to-sample comparisons within the classiﬁcation framework, encour-aging the SGD solver to be more exploratory, while boost-ing performance. Moreover, VPL is conceptually simple, easy to implement, computationally efﬁcient and memory saving. We present extensive experimental results on pop-ular benchmarks, which demonstrate the superiority of the proposed VPL method over the state-of-the-art competitors. 