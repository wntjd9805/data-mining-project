Visual and audio signals often coexist in natural environ-ments, forming audio-visual events (AVEs). Given a video, we aim to localize video segments containing an AVE and identify its category. In order to learn discriminative fea-tures for a classiﬁer, it is pivotal to identify the helpful (or positive) audio-visual segment pairs while ﬁltering out the irrelevant ones, regardless whether they are synchronized or not. To this end, we propose a new positive sample prop-agation (PSP) module to discover and exploit the closely related audio-visual pairs by evaluating the relationship within every possible pair.It can be done by construct-ing an all-pair similarity map between each audio and vi-sual segment, and only aggregating the features from the pairs with high similarity scores. To encourage the net-work to extract high correlated features for positive sam-ples, a new audio-visual pair similarity loss is proposed.We also propose a new weighting branch to better exploit the temporal correlations in weakly supervised setting. We perform extensive experiments on the public AVE dataset and achieve new state-of-the-art accuracy in both fully and weakly supervised settings, thus verifying the effectiveness of our method. 