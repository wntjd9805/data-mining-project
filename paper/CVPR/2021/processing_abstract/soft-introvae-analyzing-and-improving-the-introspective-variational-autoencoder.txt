The recently introduced introspective variational au-toencoder (IntroVAE) exhibits outstanding image genera-tions, and allows for amortized inference using an image encoder. The main idea in IntroVAE is to train a VAE ad-versarially, using the VAE encoder to discriminate between generated and real data samples. However, the original In-troVAE loss function relied on a particular hinge-loss for-mulation that is very hard to stabilize in practice, and its theoretical convergence analysis ignored important terms in the loss. In this work, we take a step towards better under-standing of the IntroVAE model, its practical implementa-tion, and its applications. We propose the Soft-IntroVAE, a modiﬁed IntroVAE that replaces the hinge-loss terms with a smooth exponential loss on generated samples. This change signiﬁcantly improves training stability, and also enables theoretical analysis of the complete algorithm.Interest-ingly, we show that the IntroVAE converges to a distribution that minimizes a sum of KL distance from the data distribu-tion and an entropy term. We discuss the implications of this result, and demonstrate that it induces competitive im-age generation and reconstruction. Finally, we describe an application of Soft-IntroVAE to unsupervised image trans-lation, and demonstrate compelling results. Code and ad-ditional information is available on the project website -taldatech.github.io/soft-intro-vae-web. 