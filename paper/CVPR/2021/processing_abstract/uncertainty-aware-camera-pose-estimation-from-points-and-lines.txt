Perspective-n-Point-and-Line (PnPL) algorithms aim at fast, accurate, and robust camera localization with respect to a 3D model from 2D-3D feature correspondences, being a major part of modern robotic and AR/VR systems. Current point-based pose estimation methods use only 2D feature detection uncertainties, and the line-based methods do not take uncertainties into account. In our setup, both 3D co-ordinates and 2D projections of the features are considered uncertain. We propose PnP(L) solvers based on EPnP [20] and DLS [14] for the uncertainty-aware pose estimation.We also modify motion-only bundle adjustment to take 3D uncertainties into account. We perform exhaustive syn-thetic and real experiments on two different visual odometry datasets. The new PnP(L) methods outperform the state-of-the-art on real data in isolation, showing an increase in mean translation accuracy by 18% on a representative sub-set of KITTI, while the new uncertain reﬁnement improves pose accuracy for most of the solvers, e.g. decreasing mean translation error for the EPnP by 16% compared to the standard reﬁnement on the same dataset. The code is avail-able at https://alexandervakhitov.github.io/uncertain-pnp/. 