SourceTargetEasy to TransferHard to TransferDomain adaptation (DA) enables knowledge transfer from a labeled source domain to an unlabeled target do-main by reducing the cross-domain distribution discrep-ancy. Most prior DA approaches leverage complicated and powerful deep neural networks to improve the adaptation capacity and have shown remarkable success. However, they may have a lack of applicability to real-world situa-tions such as real-time interaction, where low target infer-ence latency is an essential requirement under limited com-putational budget. In this paper, we tackle the problem by proposing a dynamic domain adaptation (DDA) framework, which can simultaneously achieve efﬁcient target inference in low-resource scenarios and inherit the favorable cross-domain generalization brought by DA. In contrast to static models, as a simple yet generic method, DDA can integrate various domain confusion constraints into any typical adap-tive network, where multiple intermediate classiﬁers can be equipped to infer “easier” and “harder” target data dy-namically. Moreover, we present two novel strategies to fur-ther boost the adaptation performance of multiple predic-tion exits: 1) a conﬁdence score learning strategy to derive accurate target pseudo labels by fully exploring the predic-tion consistency of different classiﬁers; 2) a class-balanced self-training strategy to explicitly adapt multi-stage clas-siﬁers from source to target without losing prediction di-versity. Extensive experiments on multiple benchmarks are conducted to verify that DDA can consistently improve the adaptation performance and accelerate target inference un-der domain shift and limited resources scenarios. 