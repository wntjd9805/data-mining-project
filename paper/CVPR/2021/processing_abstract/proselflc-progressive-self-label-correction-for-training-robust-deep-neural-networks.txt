To train robust deep neural networks (DNNs), we system-atically study several target modiﬁcation approaches, which include output regularisation, self and non-self label cor-rection (LC). Two key issues are discovered: (1) Self LC is the most appealing as it exploits its own knowledge and requires no extra models. However, how to automatically decide the trust degree of a learner as training goes is not well answered in the literature? (2) Some methods penalise while the others reward low-entropy predictions, prompting us to ask which one is better? issue,To resolve the ﬁrst taking two well-accepted propositions–deep neural networks learn meaningful pat-terns before ﬁtting noise [3] and minimum entropy regu-larisation principle [10]–we propose a novel end-to-end method named ProSelfLC, which is designed according to learning time and entropy. Speciﬁcally, given a data point, we progressively increase trust in its predicted label distri-bution versus its annotated one if a model has been trained for enough time and the prediction is of low entropy (high conﬁdence). For the second issue, according to ProSelfLC, we empirically prove that it is better to redeﬁne a meaning-ful low-entropy status and optimise the learner toward it.This serves as a defence of entropy minimisation.We demonstrate the effectiveness of ProSelfLC through extensive experiments in both clean and noisy settings. The source code is available at https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021. 