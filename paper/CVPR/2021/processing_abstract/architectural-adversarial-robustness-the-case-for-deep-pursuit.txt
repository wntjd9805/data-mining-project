Despite their unmatched performance, deep neural net-works remain susceptible to targeted attacks by nearly im-perceptible levels of adversarial noise. While the underly-ing cause of this sensitivity is not well understood, theo-retical analyses can be simpliÔ¨Åed by reframing each layer of a feed-forward network as an approximate solution to a sparse coding problem. Iterative solutions using basis pur-suit are theoretically more stable and have improved adver-sarial robustness. However, cascading layer-wise pursuit implementations suffer from error accumulation in deeper networks. In contrast, our new method of deep pursuit ap-proximates the activations of all layers as a single global optimization problem, allowing us to consider deeper, real-world architectures with skip connections such as residual networks. Experimentally, our approach demonstrates im-proved robustness to adversarial noise. 