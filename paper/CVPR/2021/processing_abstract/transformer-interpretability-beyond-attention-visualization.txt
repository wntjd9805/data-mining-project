Self-attention techniques, and speciﬁcally Transformers, are dominating the ﬁeld of text processing and are becom-ing increasingly popular in computer vision classiﬁcationIn order to visualize the parts of the image that tasks. led to a certain classiﬁcation, existing methods either rely on the obtained attention maps or employ heuristic prop-agation along the attention graph.In this work, we pro-pose a novel way to compute relevancy for Transformer networks. The method assigns local relevance based on the Deep Taylor Decomposition principle and then prop-agates these relevancy scores through the layers. This propagation involves attention layers and skip connections, which challenge existing methods. Our solution is based on a speciﬁc formulation that is shown to maintain the to-tal relevancy across layers. We benchmark our method on very recent visual Transformer networks, as well as on a text classiﬁcation problem, and demonstrate a clear advantage over the existing explainability methods. Our code is available at: https://github.com/hila-chefer/Transformer-Explainability. 