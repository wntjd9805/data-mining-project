The problem of novelty detection in ﬁne-grained visual classiﬁcation (FGVC) is considered. An integrated un-derstanding of the probabilistic and distance-based ap-proaches to novelty detection is developed within the frame-work of convolutional neural networks (CNNs). It is shown that softmax CNN classiﬁers are inconsistent with novelty detection, because their learned class-conditional distribu-tions and associated distance metrics are unidentiﬁable. A new regularization constraint, the class-conditional Gaus-sianity loss, is then proposed to eliminate this unidentiﬁa-bility, and enforce Gaussian class-conditional distributions.This enables training Novelty Detection Consistent Classi-ﬁers (NDCCs) that are jointly optimal for classiﬁcation and novelty detection. Empirical evaluations show that NDCCs achieve signiﬁcant improvements over the state-of-the-art on both small- and large-scale FGVC datasets. 