Rotation detection serves as a fundamental building block in many visual applications involving aerial im-age, scene text, and face etc. Differing from the domi-nant regression-based approaches for orientation estima-tion, this paper explores a relatively less-studied method-ology based on classiﬁcation. The hope is to inherently dismiss the boundary discontinuity issue as encountered by the regression-based detectors. We propose new tech-niques to push its frontier in two aspects: i) new encoding mechanism: the design of two Densely Coded Labels (DCL) for angle classiﬁcation, to replace the Sparsely Coded La-bel (SCL) in existing classiﬁcation-based detectors, leading to three times training speed increase as empirically ob-served across benchmarks, further with notable improve-ment in detection accuracy; ii) loss re-weighting: we pro-pose Angle Distance and Aspect Ratio Sensitive Weighting (ADARSW), which improves the detection accuracy espe-cially for square-like objects, by making DCL-based detec-tors sensitive to angular distance and object’s aspect ratio.Extensive experiments and visual analysis on large-scale public datasets for aerial images i.e. DOTA, UCAS-AOD,HRSC2016, as well as scene text dataset ICDAR2015 andMLT, show the effectiveness of our approach. The source code is available at DCL and is also integrated in our open source rotation detection benchmark: RotationDetection. 