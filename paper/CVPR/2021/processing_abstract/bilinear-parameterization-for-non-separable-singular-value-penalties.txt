Low rank inducing penalties have been proven to suc-cessfully uncover fundamental structures considered in computer vision and machine learning; however, such methods generally lead to non-convex optimization prob-lems. Since the resulting objective is non-convex one of-ten resorts to using standard splitting schemes such as Al-ternating Direction Methods of Multipliers (ADMM), or other subgradient methods, which exhibit slow convergence in the neighbourhood of a local minimum. We propose a method using second order methods, in particular the variable projection method (VarPro), by replacing the non-convex penalties with a surrogate capable of converting the original objectives to differentiable equivalents. In this way we beneﬁt from faster convergence.The bilinear framework is compatible with a large fam-ily of regularizers, and we demonstrate the beneﬁts of our approach on real datasets for rigid and non-rigid structure from motion. The qualitative difference in reconstructions show that many popular non-convex objectives enjoy an ad-vantage in transitioning to the proposed framework.1 