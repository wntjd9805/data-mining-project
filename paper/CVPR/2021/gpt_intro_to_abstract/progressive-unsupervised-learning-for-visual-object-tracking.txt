Visual object tracking (VOT) is an important task in computer vision with various practical applications. Despite significant progress, VOT remains challenging due to real-world complexities. Existing deep trackers rely on supervised learning from large annotated datasets, but collecting such datasets is expensive and time-consuming. Unlabeled videos offer a potential solution for unsupervised learning, but constructing a supervisory signal is challenging. This paper proposes a progressive unsupervised learning (PUL) framework for visual tracking that incorporates both background discrimination and temporal correspondence learning. The PUL framework utilizes contrastive learning with anchor-based hard negative mining to learn a background discrimination model. It also introduces a noise-robust loss function to effectively learn temporal correspondences from noisy patch-pairs. Experimental results demonstrate that the proposed PUL framework outperforms state-of-the-art unsupervised trackers on multiple benchmarks without the need for online fine-tuning or adaptation. Overall, this paper contributes a novel approach for unsupervised learning in visual tracking, offering potential improvements in performance and reducing the reliance on expensive annotated datasets.