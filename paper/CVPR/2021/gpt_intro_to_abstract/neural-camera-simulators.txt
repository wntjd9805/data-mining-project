Controllable photo-realistic image generation is a new research topic in computer science. Previous works have focused on learning scene representation based on different viewpoints or lighting. However, the camera settings, such as exposure time, ISO, and aperture size, have not been thoroughly investigated. These settings play an important role in the physical image formulation pipeline. In this paper, we aim to explore the problem of controllable exposure synthesis with different camera settings. We propose a simulator that maps from old camera settings to new settings using raw image data. Our simulator takes into account factors such as luminance changes, noise, and defocus blur introduced by different exposure settings. We leverage the physical information captured in raw sensor data and propose a model with three modules: exposure correction, noise-level-function analysis, and an attention module for aperture enhancement. We collect a large dataset of raw data sequences captured with different camera settings to evaluate our proposed model. The experiments demonstrate that our model can generate visually and statistically similar results at new exposure settings, making it useful for generating HDR images, enhancing defocus blur, training auto-exposure algorithms, and data augmentation for local feature detectors. Contributions of this paper include being the first to systematically study controllable image generation with camera exposure settings, demonstrating multiple applications using the proposed simulator, and providing a large dataset for further research in computer vision tasks.