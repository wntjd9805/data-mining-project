Scene flow estimation is a crucial task in computer vision, aiming to provide dense or semi-dense 3D vectors representing per-point 3D motion in consecutive frames. While significant progress has been made in 2D optical flow estimation, the 3D counterpart is more challenging due to the irregularity and sparsity of point cloud data, as well as the diversity of scenes. Most structures in the visual world are rigid or nearly rigid, making the estimation of 3D point cloud motion a regression problem. However, existing approaches often ignore the potential rigid motion constraints in local regions, leading to distorted results that fail to maintain local geometric smoothness. To address this issue, we propose HCRF-Flow, a novel framework consisting of a position-aware flow estimation module (PAFE) and a continuous high-order Conditional Random Fields (CRFs) module (Con-HCRFs). The PAFE module leverages position-aware flow embedding to encode knowledge into the matching costs for aggregation. As for the Con-HCRFs module, it incorporates pairwise regularization to encourage neighboring points with similar local structure to have similar motions and a high order term to enforce region-level consistency based on shared rigid motion parameters. Our proposed HCRF-Flow outperforms state-of-the-art methods on FlyingThing3D and KITTI Scene Flow 2015 datasets, achieving high accuracy scores. These contributions advance the field of scene flow estimation by combining the strengths of deep neural networks and CRFs, effectively modeling rigid motion constraints and producing more accurate per-point motion predictions.