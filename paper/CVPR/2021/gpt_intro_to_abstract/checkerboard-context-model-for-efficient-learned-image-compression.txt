Image compression is an important research area in multimedia signal processing, with various algorithms designed to reduce redundancies and create more compact image representations. Traditional image compression methods, such as JPEG and JPEG2000, rely on non-learned algorithms and mainly involve transformations and quantization. In recent years, deep learning and computer vision techniques have been introduced to develop powerful learned image compression methods. These methods aim to establish novel compression pipelines using recurrent neural networks, convolutional autoencoders, or generative adversarial networks. Some of these methods have shown superior performance compared to traditional compression techniques, even surpassing upcoming video coding standards. The success of these approaches lies in entropy modeling and optimization, as well as the introduction of hyper-latent representations that capture spatial correlations. Context modeling is another important component, which predicts unknown codes based on decoded latents. However, existing context models suffer from low computational efficiency, limiting their practical deployment. To address this issue, this paper proposes a parallelizable checkerboard context model and a two-pass decoding method to achieve a better balance between rate-distortion performance and running efficiency.