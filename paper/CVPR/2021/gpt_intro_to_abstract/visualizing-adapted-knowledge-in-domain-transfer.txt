Domain transfer or domain adaptation is a crucial task in machine learning, aiming to bridge the distribution gap between source and target domains. While many existing works focus on unsupervised domain adaptation (UDA) where the target domain is unlabeled, this paper explores the knowledge difference between models trained on source and target domains. The authors propose a novel approach called source-free image translation (SFIT) to visualize the knowledge difference without relying on source images. Instead, the SFIT approach generates source-style images from target images and feeds them to the source and target models, respectively. By ensuring that the outputs from the two branches are similar, the SFIT approach represents the knowledge difference between the models. The paper introduces a knowledge distillation loss and a relationship preserving loss to train the generator network in SFIT. Experimental results on various benchmarks demonstrate that SFIT significantly decreases the performance gap between the two models, suggesting successful knowledge distillation. Additionally, SFIT transfers image style at varying degrees when different UDA methods are used on the same dataset, indicating its faithfulness to the models. The generated images can serve as an additional cue for further tuning of target models, which is particularly valuable in source-free domain adaptation (SFDA) settings where source images are not available. Overall, the SFIT approach introduces a new perspective on visualizing knowledge differences in UDA, contributing to the field of transfer learning.