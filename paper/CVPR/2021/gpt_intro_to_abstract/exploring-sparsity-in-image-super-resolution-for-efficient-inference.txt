The goal of single image super-resolution (SR) is to recover a high-resolution (HR) image from a single low-resolution (LR) observation. Traditional SR methods have been outperformed by CNN-based SR methods that utilize powerful feature representation and model fitting capabilities of deep neural networks. Efforts have been made towards real-world applications of SR, including few-shot SR, blind SR, and scale-arbitrary SR. Efficient SR on intelligent edge devices such as smartphones and VR glasses is highly demanded due to their limited resources. While deep networks have been extensively studied for image SR, they often come with high computational costs that limit their applications on mobile devices. To address this issue, previous works have focused on reducing model size, but they still involve redundant computation. In this paper, the authors propose a sparse mask SR (SMSR) network that dynamically skips redundant computation to improve inference efficiency. They exploit the sparsity in image SR and investigate feature sparsity in existing SR networks. The SMSR network learns spatial masks to identify important regions and uses channel masks to mark redundant channels in unimportant regions. These masks work together to accurately localize redundant computation. Gumbel softmax trick is used to make the binary masks differentiable during training, and sparse convolution is employed during inference to skip redundant computation. Experimental results demonstrate that the SMSR network achieves state-of-the-art performance in image SR with better inference efficiency, outperforming previous methods on mobile devices.