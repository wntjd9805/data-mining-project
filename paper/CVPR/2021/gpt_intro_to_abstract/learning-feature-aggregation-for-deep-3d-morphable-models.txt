This paper focuses on 3D morphable models and their important role in various applications, such as identity recognition, shape retrieval, animation, and reconstructing 3D shapes from 2D images. Specifically, the study aims to enhance the representation power of 3D mesh shapes that share a common template and are already aligned to it. Previous encoding approaches used linear methods like Principal Component Analysis or manually defined blendshape, as well as non-linear approaches like deep learning-based models. While deep learning models offer the ability to capture detailed deformations, they have limitations in terms of feature aggregation across hierarchical levels. To address this limitation, the authors propose an attention-based feature aggregation strategy for constructing hierarchical representations of 3D meshes with a fixed topology. Instead of using precomputed matrices for feature aggregation, the authors introduce trainable variables called keys and queries that are shared across the dataset. These keys and queries are used to derive mapping matrices through a compatibility function, allowing for simultaneous learning of receptive fields and aggregation weights. The proposed approach can be used for either downsampling or upsampling by varying the number of keys and queries. Importantly, the attention-based mapping module can be detached once training is complete to reduce inference costs. The authors evaluate their method on the reconstruction task using three 3D human shape datasets (faces, bodies, and hands) and demonstrate quantitative and qualitative improvements over existing models. This attention-based feature aggregation approach enhances the performance of existing models when combined with isotropic or anisotropic convolution operators. Overall, the proposed method provides a more effective and efficient way to represent and reconstruct 3D mesh shapes.