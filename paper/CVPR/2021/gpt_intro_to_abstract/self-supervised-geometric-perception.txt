Geometric perception is a crucial task in computer vision, involving the estimation of geometric models from visual measurements such as images or point clouds. It has diverse applications in object detection, pose estimation, motion estimation, 3D reconstruction, simultaneous localization and mapping (SLAM), structure from motion (SfM), as well as virtual and augmented reality.Traditionally, geometric perception consists of a front-end that detects and represents keypoints, and a back-end that performs estimation of geometric models while being robust to outliers. Hand-crafted features, like SIFT and FPFH, have been used for feature matching but tend to result in a large number of outliers, making accurate estimation challenging. As a result, there has been growing interest in learning feature descriptors, particularly through deep neural networks, which have shown superior performance across various applications.However, existing feature learning approaches have limitations. They often require a large number of ground-truth geometric model labels for training, making them applicable only to datasets with such annotations. Additionally, obtaining these labels can be challenging and require specific reconstruction pipelines, parameter tuning, and human supervision.In this paper, we propose a general framework for feature learning in geometric perception that does not rely on ground-truth geometric labels or sophisticated reconstruction pipelines. We formulate geometric perception as an optimization problem that jointly searches for the best feature descriptor and the best geometric models. The framework combines robust model fitting and deep feature learning as two subproblems, incorporating iterative optimization based on alternating minimization, which we refer to as self-supervised geometric perception (SGP). SGP involves two meta-algorithms: a teacher that generates pseudo-labels using correspondences established from learned features, and a student that refines the features under the supervision of updated geometric models. SGP can be initialized with a bootstrap descriptor before iteratively improving the descriptors.We apply SGP to two perception problems: relative camera pose estimation and 3D point cloud registration. Our experiments demonstrate that SGP achieves comparable or superior performance compared to supervised approaches and sets the new state-of-the-art on benchmark datasets such as MegaDepth and 3DMatch.Overall, our work introduces a promising method for feature learning in geometric perception that does not rely on ground-truth labels or complex reconstruction pipelines, expanding the applicability of feature learning to a wider range of datasets and scenarios.