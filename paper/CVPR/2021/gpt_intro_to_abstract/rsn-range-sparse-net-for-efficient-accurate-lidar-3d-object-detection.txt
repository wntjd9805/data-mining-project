This paper presents a novel 3D object detection model called Range Sparse Net (RSN) that combines the advantages of dense range images and grids to enhance accuracy and efficiency. RSN utilizes a lightweight 2D convolutional network to extract semantic features from high-resolution range images and then applies sparse convolutions on predicted foreground voxels to accurately regress 3D boxes. Unlike existing methods, RSN focuses on high recall foreground segmentation instead of regressing boxes directly from underlying features. The model achieves end-to-end, efficient, and accurate object detection without non-maximum suppression. Additionally, RSN incorporates a multi-view fusion approach that transfers information from the perspective view to the 3D view, resulting in improved feature quality and efficiency. The paper presents experiments on the Waymo Open Dataset (WOD) and an internal dataset, demonstrating state-of-the-art accuracy and efficiency for vehicle and pedestrian detection. Ablation studies are conducted to analyze the effectiveness of range image features and the impact of various aspects on latency and accuracy. The proposed RSN model offers a simple, efficient, and accurate solution for 3D LiDAR object detection.