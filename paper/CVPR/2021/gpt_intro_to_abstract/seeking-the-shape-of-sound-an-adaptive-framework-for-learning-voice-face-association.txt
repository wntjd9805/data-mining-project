This paper focuses on the problem of learning voice-face associations in machine learning systems. Previous studies have shown that humans are able to match the corresponding voice and face of an unknown person with higher accuracy than chance. The goal is to investigate whether machines can achieve the same ability. This technology has potential applications in criminal investigation, synthesis or retrieval of human faces from voices, and more. While previous methods have achieved comparable performance to humans, there are still challenges in learning voice-face associations. This paper addresses two problems: the slow convergence of previous methods due to the use of local information in a mini-batch, and the diversity of difficulty across identities. The authors propose an adaptive framework that includes implicit and explicit modality alignment to overcome these challenges. The framework also includes an adaptive identity re-weighting strategy to better explore difficult identities and exclude personalized identities for better generalization. Experimental results demonstrate the effectiveness of the proposed framework. Overall, this paper contributes to the understanding and development of machine learning algorithms for voice-face associations.