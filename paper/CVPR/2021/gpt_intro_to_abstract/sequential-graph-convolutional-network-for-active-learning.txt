Deep learning has made significant advancements in computer vision tasks such as image classification and 3D Hand Pose Estimation (HPE). However, data annotation for these tasks is time-consuming, costly, and requires domain expertise. Active learning has been used to select meaningful samples to overcome these challenges. Active learning frameworks consist of a learner, sampler, and annotator. Existing active learning approaches are either task-dependent or task-agnostic, with task-dependent approaches limiting scalability. Recent works have introduced mechanisms to improve discrimination between labeled and unlabeled data, but lack the ability to exploit correlation between these data. In this paper, we propose a sequential Graph Convolutional Network-based active learning approach in a task-agnostic manner. Our approach uses a learner to minimize the objective of the downstream task and a graph constructed from learner features to select representative unlabeled examples. We leverage Graph Convolutional Networks to induce higher-order representations and pass messages between nodes in the graph. We introduce two sampling techniques, UncertainGCN and CoreGCN, that exploit uncertainties in the graph and employ risk minimization for labeled examples. Our proposed method is evaluated on image classification benchmarks, 3D HPE datasets, and synthetic image classification benchmarks, outperforming existing methods in both quantitative and qualitative comparisons.