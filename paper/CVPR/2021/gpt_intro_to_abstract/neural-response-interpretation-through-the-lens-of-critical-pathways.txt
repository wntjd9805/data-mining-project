Understanding the rationale behind the response of a neural network is crucial for its adoption and safe deployment in critical domains. Interpreting neural network responses not only helps in debugging and designing networks, but also satisfies intellectual curiosity about their functioning. This paper aims to explore the underpinnings of neural network responses by analyzing neurons and pathways. Pathways refer to the connections between the input and output of a network. Previous research has shown that analyzing pathways can reveal human interpretable concepts encoded in neurons, such as curve and circle detectors. This work focuses on identifying pathways responsible for a network's response given a specific input. It is known that deep rectified neural networks encode information using a sparse set of active neurons, similar to how biological neurons encode information in the brain. It has been observed that the pathways of active neurons in artificial neural networks overlap significantly for inputs of the same class. Additionally, pruning objectives and knowledge distillation techniques have been used to achieve higher levels of sparsity in neural networks while maintaining prediction accuracy. These highly sparse pathways, known as critical paths, differ for inputs of different classes and adversarial inputs. However, it is unclear whether these highly sparse pathways actually encode critical input features. This paper investigates this question and shows that the pruning objective can result in pathways that are not critical, despite having the same response as the original network. The authors propose selecting pathways based on neuron contributions instead of the pruning objective, as it is intuitive that selected sparse pathways should encompass important neurons for the corresponding response. To compute the importance of neurons, the authors use notions of marginal contribution and the Shapley value. The paper also introduces an input feature attribution methodology called "pathway gradient" based on the local linearity of critical pathways in rectified neural networks. The methodology is evaluated on various datasets using input degradation, sanity checks, and Remove-and-Retrain techniques. The paper's main contributions include demonstrating that the pruning objective may not extract critical pathways and proposing a pathway selection method based on neuron contributions. It also proves that critical pathways selected by neuron contributions are locally linear and introduces the pathway gradient method for input feature attribution. The empirical results show that computing the contribution of neurons improves input feature attribution compared to considering input pixels alone.