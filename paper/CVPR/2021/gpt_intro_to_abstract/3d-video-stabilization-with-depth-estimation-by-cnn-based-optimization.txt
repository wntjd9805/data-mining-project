Video stabilization is a critical module in video acquisition and pre-processing. Traditional methods use 2D or 3D motion models to estimate the inter-frame motion and apply a smoothing algorithm to stabilize the video. However, 2D-based methods suffer from spatially variant motion, while 3D-based methods are expensive. Feature tracking for motion estimation is challenging in shaky videos, limiting the performance of earlier approaches. CNN-based methods extract frame motion in CNN parameter space but still suffer from parallax effect and introduce distortions. In this paper, we propose a novel 3D-based learning method called Deep3D Stabilizer. Our method is the first to handle video stabilization with learned 3D information. It jointly learns scene depth and camera motion during test time without training data. We employ a 3D geometry optimization stage and a frame rectification stage to perform stabilization, resulting in low distortion and improved handling of parallax effect. Furthermore, our method allows users to manipulate the stability of the stabilized video in real-time. Our contributions include introducing the first 3D-based deep CNN method for video stabilization, improved handling of parallax effect, and real-time stability manipulation.