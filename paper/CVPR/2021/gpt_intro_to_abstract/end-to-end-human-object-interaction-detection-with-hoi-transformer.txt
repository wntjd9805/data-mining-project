This paper focuses on the problem of Human-Object Interaction (HOI) detection, which is vital for human-centric scene understanding. HOI detection involves localizing humans and objects in an image, as well as recognizing the interactions between them. Previous studies have achieved promising results by decoupling HOI detection into object detection and interaction classification. However, these methods suffer from limitations such as sub-optimal solutions due to separate optimization, low-quality human-object proposals, and high computation cost.Recent approaches have introduced a surrogate interaction detection problem to optimize HOI detection indirectly. These methods define interaction proposals based on human priors and detect human, object, and interaction proposals in parallel. However, these proposals are not always valid in different scenarios, making the pipeline complex and computationally expensive.The main problem in HOI detection is capturing long-range dependencies between humans and objects in the image space. Current methods use complex strategies or introduce surrogate proposals to address this problem. Inspired by the transformer network's ability to capture long-range dependencies, this paper proposes a new architecture for end-to-end HOI instance prediction. The proposed method utilizes a transformer encoder-decoder architecture and a quintuple HOI matching loss. It leverages a CNN backbone for feature extraction, an encoder to generate global memory features, and a decoder to generate output embeddings. HOI instances are predicted using a multi-layer perception. The quintuple HOI matching loss supervises the learning process. The proposed method achieves state-of-the-art results on various challenging HOI benchmarks.