This paper introduces a joint generative and contrastive learning framework for unsupervised person re-identification (ReID). ReID systems aim to identify individuals across different camera views, and traditional supervised methods require human-annotated labels, which can be time-consuming and cumbersome. This paper focuses on unsupervised ReID algorithms that learn directly from unlabeled images, allowing for scalability in real-world deployments. The authors propose a novel view generator based on 3D meshes to enhance view diversity for contrastive learning under the fully unsupervised setting. They disentangle person images into identity features (color distribution and body shape) and structure features (pose and view-point) and estimate 3D meshes from unlabeled training images. These meshes are then rotated to simulate new structures, allowing for the generation of novel views by combining identity features with new structures. The authors also design a pseudo-label-based contrastive learning module that maximizes representation similarity between original and generated views of the same person, while minimizing representation similarity between other persons. The proposed method incorporates generative and contrastive modules into one framework, with both modules sharing the same identity feature encoder. The generative module enhances the capacity of the shared encoder by generating diversified novel views, leading to improved generation quality. The paper's contributions include:1. Proposing a joint generative and contrastive learning framework for unsupervised person ReID, where the generative and contrastive modules mutually promote each other's performance.2. Introducing a 3D mesh-based novel view generator that effectively preserves body shape, surpassing the performance of skeleton-guided generators.3. Introducing a view-invariant loss in the contrastive module to reduce intra-class variation between original and generated images, leading to view-invariant representations under the fully unsupervised ReID setting.4. Overcoming the limitations of previous GAN-based unsupervised ReID methods by significantly improving performance without relying on a labeled source dataset.Overall, the proposed framework achieves state-of-the-art results in both fully unsupervised and unsupervised domain adaptation settings for person ReID.