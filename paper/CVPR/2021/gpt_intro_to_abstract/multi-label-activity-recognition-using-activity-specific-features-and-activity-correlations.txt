Activity recognition has gained significant attention in recent years due to its potential in real-world applications. However, most existing research focuses on single-activity recognition, overlooking the multi-label problem where a video can contain multiple activities concurrently or sequentially. This paper proposes a new approach to multi-label activity recognition by generating independent feature descriptors called "activity-specific features" for different activities. The proposed mechanism involves two stages: the first stage generates independent feature snippets using spatio-temporal attention, while the second stage learns activity-specific features by combining different combinations of observations. Unlike previous approaches that use shared feature vectors, this network produces specific feature descriptors for each activity. The paper also introduces an activity label-wise correlation map to model co-existing and exclusive patterns, as well as a speed-invariant tuning method to address variations in activity duration. The proposed model is evaluated on large-scale multi-label activity datasets and real-world sports datasets, outperforming state-of-the-art networks without the need for additional information. The paper concludes with a summary of the contributions, which include the network structure for activity-specific feature generation, the activity correlation map, and the speed-invariant tuning method.