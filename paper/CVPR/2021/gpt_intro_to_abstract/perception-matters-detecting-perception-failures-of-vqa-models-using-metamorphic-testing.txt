This paper introduces MetaVQA, a model-agnostic approach to testing the perception ability of visual question answering (VQA) models. The authors propose using metamorphic testing (MT) principles to assess the accuracy of VQA models in answering perception questions. MetaVQA synthesizes transformed questions and images based on the objects and properties detected in the original inputs, and checks whether the answers to the transformed inputs satisfy metamorphic relations (MRs) denoting perception consistency. The paper presents empirical results showing that MetaVQA detects millions of erroneous answers produced by popular VQA models, including the state-of-the-art model that won the VQA 2020 challenge. The authors advocate for evaluating VQA models' perception ability, as it is the foundation for high-level logic reasoning tasks. They also release MetaVQA for results verification and benchmarking of VQA models. Overall, this work contributes to the assessment and improvement of VQA models' perception capabilities.