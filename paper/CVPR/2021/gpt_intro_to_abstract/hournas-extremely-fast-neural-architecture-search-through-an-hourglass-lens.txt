In recent years, advancements in deep neural networks have significantly improved various computer vision tasks. These improvements have been achieved through the design of well-structured cells and sophisticated architectures. While extensive experiments are required to determine the weights and hyperparameters of these networks, researchers have also explored the use of Neural Architecture Search (NAS) algorithms to automatically and efficiently find networks with desired properties.Different NAS algorithms have been proposed, including Evolutionary Algorithm (EA) based methods, Reinforcement Learning (RL) based methods, and differentiable based methods. These approaches aim to accelerate the search process by maintaining a set of architectures and optimizing their weights and parameters. However, due to the high computation cost, most methods perform NAS on smaller datasets and then fine-tune the selected architecture on larger datasets.In this paper, we present HourNAS, a novel approach for accurate and efficient architecture search on the large-scale ImageNet dataset. Our method focuses on identifying the vital blocks in the network, which play a crucial role in its accuracy. We propose a two-stage search scheme that speeds up the architecture search process and efficiently allocates computational resources to the vital blocks. This approach allows us to achieve high accuracy while minimizing the number of parameters in the network.To demonstrate the effectiveness of HourNAS, we conduct experiments on residual networks. The results show the significant impact of vital and non-vital blocks on network accuracy. By treating the architecture search through an hourglass lens, we allocate computation resources more effectively and achieve promising results. In particular, HourNAS achieves a Top-1 accuracy of 77.0% on the entire ImageNet dataset, outperforming state-of-the-art methods.