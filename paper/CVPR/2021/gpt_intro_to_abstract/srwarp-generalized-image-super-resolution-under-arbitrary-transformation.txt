Image super-resolution (SR) is a crucial problem in computer vision, aiming to reconstruct high-resolution (HR) images from low-resolution (LR) inputs. SR methods find wide applications in image enhancement, editing, and digital zooming. Recent advancements in convolutional neural networks (CNNs) have significantly improved SR performance by employing large-scale datasets, efficient structures, and optimization techniques. State-of-the-art SR methods can achieve sharp edges and detailed textures at various scaling factors on different types of input data. However, existing SR models are not optimized for general image editing tasks, and they are limited to rectangular grids, making them inadequate for handling irregular grids. Additionally, conventional warping methods tend to generate blurry results when local regions of an image are stretched. To address these limitations, this paper proposes an end-to-end learnable framework called SRWarp. SRWarp introduces an adaptive warping layer (AWL) to predict appropriate resampling kernels for local distortions. It also utilizes a multi-scale blending strategy to combine features of different resolutions based on local deformations and image contents. Experimental analysis demonstrates the effectiveness of SRWarp in reconstructing image structures, even under complex and spatially-varying deformations. The contributions of this paper include a generalized SRWarp model, an adaptive warping layer, and a multi-scale blending strategy. Compared to existing methods, SRWarp produces high-quality transformed images with improved details and edges.