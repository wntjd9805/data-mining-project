3D object recognition, including segmentation and detection, plays a crucial role in scene understanding. However, existing methods for 3D recognition often rely on strong supervision, such as detailed annotations or semantic labels, which are time-consuming and expensive to obtain. This limitation hinders the scalability of 3D recognition systems. In this paper, we propose a novel weakly-supervised learning framework, called WyPR, that leverages scene-level class tags as supervision for training semantic segmentation and object detection models. Scene-level tags are highly efficient to annotate, allowing for easier scaling compared to box-level supervision. WyPR jointly learns segmentation and detection, benefiting from the mutually beneficial relationship between these two tasks. Additionally, the tasks naturally constrain each other, leading to effective self-supervised objectives that further enhance performance. To address the limitations of weak labels, WyPR incorporates a two-stage detection framework using weakly-supervised segmentation. We introduce Geometric Selective Search (GSS), an unsupervised proposal generation algorithm that utilizes local geometric structures for bottom-up proposal generation. Experimental results on standard 3D datasets demonstrate the superiority of WyPR compared to single task baselines, achieving state-of-the-art performance in weakly-supervised semantic segmentation and establishing new benchmarks for weakly-supervised proposal generation and object detection. Our contributions include the WyPR framework, the GSS algorithm, and the improved performance in weakly-supervised 3D recognition tasks.