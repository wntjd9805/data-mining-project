Modern deep convolutional neural networks (CNNs) have achieved remarkable success in various computer vision tasks, primarily due to the availability of large annotated datasets. However, these networks are data-hungry and require a substantial amount of labeled images for training. This limitation makes them less applicable to practical scenarios such as autonomous driving, where annotating examples is costly or when dealing with never-before-seen concepts.Humans, on the other hand, have the remarkable ability to quickly understand new concepts and make meaningful generalizations, even from a single example. This ability to learn from few examples has sparked the emergence of few-shot or low-shot learning approaches, which aim to train models that can learn novel concepts from only a few labeled examples.While there have been notable successes in few-shot classification, most of the existing work focuses on simple classification tasks with artificial settings and small-scale datasets. Few-shot object detection, which involves learning an object detector from a few annotated bounding box examples, is much less explored. Few-shot detection is more challenging than classification as it requires not only determining where an object is but also what it is, handling distracting background regions, and other complexities.In this paper, we address the problem of few-shot object detection by proposing a novel approach. Our approach aims to effectively deal with the lack of variation in training data, which is crucial for accurate object detection. We introduce a hallucinator network into the object detection model, which performs data hallucination for the box classifier in the learned region of interest (RoI) feature space. The hallucinator is trained on data-abundant base classes, encoding the rich structure of their shared modes of variation. We then use the hallucinator to generate additional examples for the novel classes, creating an augmented training set to improve the classifier's performance.We demonstrate the effectiveness of our approach on extremely few-shot detection tasks, where there are very limited examples (less than 3) for novel classes. Our approach outperforms the state-of-the-art few-shot detectors in this regime, such as the two-stage fine-tuning approach and cooperating region proposal networks. Our contributions include addressing the lack of variation issue in extremely few-shot detection, proposing a novel data hallucination-based approach, and achieving significant performance improvements over existing methods.Overall, our approach shows promise in bridging the gap between data-hungry deep CNNs and the human ability to learn from few examples. The code for our approach is publicly available.