Semantic segmentation is a critical component of scene understanding across various domains, including microscopic and telescopic scenes, as well as those captured by moving vehicles or viewed through augmented reality devices. The demand for real-time processing in mobile applications has driven research into real-time semantic segmentation. This area has become a test-bed for new architectural designs and training methods aimed at improving accuracy and speed. Previous work has focused on increasing capacity and incorporating attention mechanisms to enhance performance. In this paper, we propose a different approach to improving performance by introducing adaptivity to the network through the use of meta-learning techniques known as dynamic networks or hypernetworks. While hypernetworks have been utilized in various tasks such as text analysis and 3D modeling, their application in generating image-like maps has been limited due to the inability to capture signals from high-resolution images. We address this limitation by presenting a novel encoder-decoder architecture, where the encoder backbone incorporates recent advancements in the field, and the encoded signal is mapped to dynamic network weights using an internal U-Net. The decoder incorporates dynamic blocks with spatially varying weights. Our proposed architecture achieves state-of-the-art accuracy versus runtime trade-off on widely used benchmarks such as PASCAL VOC 2012, CityScapes, and CamVid. Despite utilizing an unconventional architecture with locally connected layers and dynamic weights, our approach is highly efficient. In conclusion, the key contributions of this work include a novel hypernetwork architecture incorporating a U-Net within a U-Net, dynamic patch-wise convolution with varying weights per input and spatial location, and state-of-the-art accuracy versus runtime trade-off on major benchmarks in the field.