The detection of human-object interactions (HOIs) in images is a challenging task due to the diverse range of rare or unseen interactions with novel objects. HOIs can be captured using either a human-centric (actions) or object-centric (affordance) approach, where each HOI can be disentangled into a verb and an object, indicating the possible actions that can be applied to a specific object. In this paper, we propose an affordance transfer learning (ATL) framework that learns object affordances from HOI samples, allowing for the detection of HOIs with novel objects. By composing new HOIs through the combination of affordances and novel object representations, the proposed framework generalizes and improves the detection of HOIs with additional unseen objects. Furthermore, the ATL framework enables weakly supervised learning of object affordances by leveraging the HOI detection model and transferring shared affordance representations from existing HOIs to novel objects. Experimental results demonstrate that our approach not only improves state-of-the-art HOI detection methods but also facilitates the recognition of object affordance. Overall, our contributions lie in introducing the affordance transfer learning framework for broader HOI detection and incorporating decomposed affordances to infer the affordance of novel objects.