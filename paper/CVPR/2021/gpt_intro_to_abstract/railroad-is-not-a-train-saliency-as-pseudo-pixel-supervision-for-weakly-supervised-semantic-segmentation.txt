Weakly-supervised semantic segmentation (WSSS) aims to achieve competitive performance to fully-supervised models while using weaker forms of supervision. Most existing WSSS approaches utilize image-level labels as weak supervision. However, WSSS faces challenges such as limited object localization, boundary mismatch, and difficulty in separating co-occurring pixels. Existing studies address these challenges through three approaches: expanding object coverage, improving object boundaries, and mitigating co-occurrence using extra groundtruth masks or saliency maps. However, these approaches have limitations and fail to fully address the challenges. In this paper, we propose a novel framework called Explicit Pseudo-pixel Supervision (EPS) to overcome these challenges. Our approach fully utilizes both the localization map and the saliency map by exploiting their complementary relationship. We design a classifier to predict C+1 classes, including C target classes and the background class, and use C localization maps and the background localization map to estimate a saliency map. We introduce the saliency loss, which penalizes boundary mismatches, and train the classifier to optimize both the saliency loss and the multi-label classification loss. Experimental results on PASCAL VOC 2012 and MS COCO 2014 datasets demonstrate that EPS achieves remarkable segmentation performance, surpassing state-of-the-art accuracies.