This paper introduces the ReLabel strategy, a re-labeling method that aims to obtain pixel-wise labeling on the ImageNet training set. The ImageNet dataset plays a crucial role in the advancement of computer vision, and improving model performance on ImageNet is considered a benchmark for model applicability and transfer learning. However, recent studies have revealed that a significant portion of the ImageNet dataset consists of images with multiple possible labels, contradicting the assumption of a single object class per image. This poses problems for evaluation and training, as the supervision becomes noisy, especially with the widespread adoption of random crop augmentation. Even for images with a single class, random crops often lack foreground objects, resulting in potentially incorrect supervision signals during training. To overcome these challenges, the proposed ReLabel strategy generates location-wise multi-labels, providing cleaner supervision per random crop. This strategy involves using strong classifiers trained on external data to generate pixel-wise labels, both for multi-labels and localized labels. The paper also introduces a novel training scheme called LabelPooling, which allows training classifiers based on the dense labels. LabelPooling computes the multi-label ground truth for each random crop sample by pooling the label scores from the crop region. Notably, ReLabel incurs a one-time cost for generating the label maps per dataset, unlike other approaches like Knowledge Distillation that require one forward pass per training iteration. The LabelPooling supervision adds only a small additional computational cost to the usual single-label cross-entropy supervision.The paper presents extensive evaluations of various model architectures trained with ReLabel on multiple datasets and tasks. On ImageNet classification, ResNet-50 with ImageNet ReLabel achieves a top-1 accuracy of 78.9%, a significant improvement over the baseline model trained with the original labels. By employing the CutMix regularization on top of ReLabel, the accuracy of ResNet-50 reaches 80.2%, setting a new state-of-the-art performance on ImageNet. Models trained with ReLabel also consistently improve accuracies on ImageNet multi-label evaluation metrics proposed by previous studies. ReLabel and LabelPooling show consistent improvements for transfer learning experiments, including object detection, instance segmentation tasks on COCO, and fine-grained classification tasks. Additionally, LabelPooling is tested on the multi-label classification task on COCO, and models trained with ReLabel demonstrate greater resilience to test-time perturbations, as evidenced by experiments on various robustness benchmarks.