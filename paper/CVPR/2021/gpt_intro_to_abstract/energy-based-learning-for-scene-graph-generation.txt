This paper introduces a novel energy-based framework for scene graph generation, which incorporates the structure of scene graphs into the learning process. The authors address the limitations of conventional cross-entropy based training, which ignores the rich structure and biases in the scene graph output space. By using energy computation and a graph message passing algorithm, the proposed framework maximizes the joint likelihood of objects and relations, leading to improved performance and generalization capabilities. The authors experiment with state-of-the-art models and demonstrate significant improvements in performance compared to traditional cross-entropy based models. They also showcase the ability of the energy-based framework to learn from less training data and achieve better performance on few-shot relation triplets. The proposed approach generates more granular and accurate scene graphs, while precluding improbable relations. This paper contributes a novel energy-based framework for scene graph generation, along with a generic message passing algorithm that can be used for other applications as well. The proposed framework outperforms cross-entropy based models on benchmark datasets Visual Genome and GQA by up to 21% and 27% respectively.