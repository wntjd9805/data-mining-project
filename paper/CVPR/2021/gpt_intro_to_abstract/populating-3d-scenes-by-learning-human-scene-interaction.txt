This paper introduces a novel model, POSA (Pose with Proximities and Contacts), which incorporates human-scene interaction (HSI) into the body representation. The existing representations of the human body in computer vision and computer graphics do not explicitly represent or capture physical interactions. By extending the SMPL-X model, POSA encodes HSI as an ego-centric representation in the body model. It defines a probabilistic feature map that encodes the probability of contact between body vertices and the world, along with semantic labels associated with that contact. POSA is trained using the PROX dataset and PROX-E dataset, which contain 20 subjects interacting with 12 real 3D scenes. The paper demonstrates the value of POSA through two applications - automatic scene population and monocular 3D human pose estimation in a scene. For scene population, POSA generates a target feature map based on a given body pose and searches for the most likely position in the scene. Compared to a state-of-the-art approach, POSA achieves higher perceptual realism. In pose estimation, POSA's learned feature map replaces the hand-coded contact points in the PROX method, resulting in lower pose estimation errors. This paper presents a novel approach that intertwines pose and scene semantics with contact, allowing for various applications in computer vision and computer graphics. The model and code are available for research purposes.