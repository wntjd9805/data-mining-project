This paper introduces the problem of video deraining, which involves removing rain from videos to improve visual quality and enhance the performance of subsequent video processing algorithms. Traditional methods rely on manually-designed prior knowledge and have limited effectiveness. Recent deep learning-based approaches have shown promising results, but they still struggle with real-world applications and the modeling of rain layers. This paper proposes a semi-supervised video deraining method that utilizes a dynamical rain generator to capture the intrinsic properties of rain layers in videos. The method incorporates both synthetic and real rainy videos to improve generalization. The proposed method includes a probabilistic framework with a transition model and an emission model, both parameterized by deep neural networks. A semi-supervised learning mechanism is designed to leverage labeled synthetic data and unlabeled real data. An EM algorithm is used for model learning. The proposed method aims to overcome the limitations of traditional and deep learning-based approaches by better modeling rain layers and utilizing both synthetic and real data for improved performance.