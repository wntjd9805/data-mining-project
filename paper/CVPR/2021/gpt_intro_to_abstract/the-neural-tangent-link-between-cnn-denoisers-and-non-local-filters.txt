Convolutional neural networks (CNNs) have become widely used in deep learning solutions for computational imaging and computer vision tasks such as image restoration and reconstruction. Despite their empirical success, there is a lack of theoretical understanding of the implicit assumptions imposed by CNNs on the set of plausible signals. Ulyanov et al. discovered the "deep image prior" (DIP), where training a CNN with only a single corrupted image can achieve competitive reconstructions. This challenges the traditional belief that networks should be trained with large amounts of data and highlights the bias of CNN architectures towards natural images. However, these methods still provide comparable or slightly worse denoising results compared to classical non-local filtering techniques. Therefore, the questions arise of whether the neural network is performing a similar filtering process and if it is possible to avoid slow training and apply the filter more directly. Understanding the bias of CNNs towards clean images is crucial for building better frameworks for optimizing and designing new denoisers and other low-level computer vision algorithms. Additionally, recent research on overparameterized neural networks trained with gradient descent has shown convergence to a Gaussian process known as the neural tangent kernel (NTK). While the properties of the NTK have been analyzed for image classification, little is known in the context of high-dimensional image restoration with no clean data. This paper studies overparameterized CNNs and their associated NTK in the context of image denoising, establishing links with classical non-local filtering techniques but also uncovering limitations in explaining the results obtained by the DIP. The main contributions include showing that CNN denoisers trained with a single corrupted image in the overparameterized regime correspond to an existing iterative non-local filtering technique, as well as analyzing the impact of the optimization algorithm on the DIP's performance. The findings are evaluated through denoising experiments, showcasing the advantages of both fixed non-local filters and adaptive filters during training.