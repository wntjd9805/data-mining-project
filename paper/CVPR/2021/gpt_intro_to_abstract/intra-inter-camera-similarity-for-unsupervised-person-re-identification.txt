Person Re-Identification (ReID) is a task that involves matching a query person in an image gallery collected from non-overlapping camera networks. While deep Convolutional Neural Networks (CNNs) have enabled great progress in supervised person ReID, there is a growing interest in unsupervised approaches that can alleviate the need for expensive person ID annotation. Existing unsupervised person ReID works can be categorized into domain adaptation, generative adversarial networks (GANs), and pseudo-label generation. However, generating high-quality pseudo-labels in unsupervised person ReID remains challenging, particularly due to feature distribution discrepancies among cameras.To address this challenge, this paper proposes a two-stage approach for generating reliable pseudo-labels in unsupervised person ReID. In the first stage, sample similarity is computed within each camera using CNN features, guiding pseudo-label generation within each camera. Independent pseudo-labels in multiple cameras are used to train a ReID model with a C-branch network. The shared backbone is optimized by multiple tasks, and each branch is optimized by a specific classification task within the same camera. This simplifies pseudo-label generation and ensures high-quality pseudo-labels and efficient backbone optimization.In the second stage, sample similarities are computed across cameras, considering the domain gap that affects the similarity among samples of the same identity. By classifying each sample with multiple classifiers trained on different cameras, the classification scores are used as a new feature vector that is robust to the domain gap. The proposed Adaptive Instance and Batch Normalization (AIBN) enhances the generalization ability of classifiers without reducing their discriminative ability. The classification scores produced by these classifiers are then used to calculate the "inter-camera" similarity for generating pseudo-labels across cameras.Experimental results on several ReID datasets demonstrate the effectiveness of the proposed approach. The complete approach, combining intra-camera and inter-camera similarities, achieves the best performance, outperforming recent unsupervised works by a significant margin. It also outperforms transfer learning approaches that leverage extra annotations. The proposed method effectively alleviates the domain gap between cameras and improves the ReID model optimization process. This work contributes original research on better similarity computation strategies in unsupervised person ReID.