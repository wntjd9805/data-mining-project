Estimating point correspondences between 3D models is a crucial step in various computer vision tasks, including 3D registration, tracking, and scene flow estimation. To facilitate this process, 3D descriptors are used to extract discriminative and consistent geometric features for estimating correspondences. While learning-based descriptors have shown superior performance on common point cloud registration benchmarks, they typically assume that the point density or resolution of different point clouds is the same. However, in real-world scenarios, resolution mismatch often occurs, such as in reconstructions from monocular videos and stereo camera setups affected by calibration errors and hardware discretization. Existing methods for normalization, based on convolutional neural networks (CNNs), struggle to handle resolution mismatch, particularly when global scales of samples are unknown. To address this problem, we propose a novel normalization technique called Batch-Neighborhood Normalization (B-NHN) that incorporates local point cloud statistics into internal normalization layers. Inspired by contrast normalization in the human vision system, B-NHN aims to increase the robustness of the network across resolutions. We demonstrate the effectiveness of our approach on benchmark datasets and introduce a dataset of nasal cavities to evaluate geometric feature extraction methods on a medical video-CT registration task with resolution mismatch. Our results show that B-NHN outperforms state-of-the-art methods, highlighting its potential for addressing resolution mismatch in 3D geometric feature learning.