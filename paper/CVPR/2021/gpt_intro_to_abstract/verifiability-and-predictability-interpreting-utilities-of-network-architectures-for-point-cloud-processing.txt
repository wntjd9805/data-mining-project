Recently, deep neural networks (DNNs) have been widely used for 3D point cloud processing and have shown superior performance in various tasks. However, traditional approaches to designing intermediate-layer architectures in DNNs have relied on empirical methods, which makes it challenging to explore and verify the utilities of each specific architecture.In this study, we aim to bridge the gap between intermediate-layer architecture and its utilities. We consider three specific utilities: rotation robustness, adversarial robustness, and neighborhood inconsistency. While there have been some heuristic insights into the utilities of existing architectures, there has been a lack of rigorous and quantitative verification.To quantitatively diagnose the utilities of intermediate-layer network architectures, we propose a method that provides new insights into architectural design. We focus on two terms: verifiability and predictability. Verifiability involves designing new metrics to quantify the utilities of existing architectures and prove intuitive insights. Predictability, on the other hand, involves using the verified insights to revise other networks and improve their utilities.To verify the hypotheses about the utilities of specific intermediate-layer architectures, we conducted comparative studies using five evaluation metrics. These metrics include information discarding and information concentration, rotation robustness, adversarial robustness, and neighborhood inconsistency. We analyzed several intermediate-layer architectures with strong connections to human intuitions and quantified their utilities through comparative experiments.The verified hypotheses were then used to guide the architectural revision of existing DNNs to improve their utilities. The revised architectures were evaluated, and their classification accuracy was reported.Overall, the contributions of this study include proposing hypotheses on the utilities of specific intermediate-layer architectures, designing metrics for comparative studies to verify these hypotheses, and demonstrating that the verified insights can be used to improve the utilities of existing DNNs.