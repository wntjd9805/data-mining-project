Image-to-image translation (I2IT) has become a popular research area in computer science, with a focus on translating images from one domain to another. Photorealistic I2IT, in particular, has gained increasing attention due to its practical applications, such as transferring images between different daytimes or retouching images to improve their aesthetic quality. However, the key challenge in practical photorealistic I2IT is maintaining efficiency and avoiding content distortions when dealing with high-resolution images.Traditional methods for achieving faithful translations employ an encoding-decoding paradigm, which maps the input image into a low-dimensional latent space and reconstructs the output from a translated latent code. However, these methods are often limited to low-resolution applications or have time-consuming inference models, making them impractical. The main reason for this limitation is the need to globally manipulate high-resolution images using deep networks, which comes with a heavy computational cost.Recent research has explored disentangling the contents and attributes of both domains for photorealistic translation, but the irreversible down- and up-sampling operations involved in these models still require heavy convolutions on high-resolution feature maps, sacrificing efficiency.Inspired by the reversible and closed-form frequency-band decomposition framework of a Laplacian pyramid, this paper proposes a fast and effective method called the Laplacian Pyramid Translation Network (LPTN) to improve efficiency while maintaining transformation performance for photorealistic I2IT tasks.The LPTN approach leverages the observation that the domain-specific attributes of a photorealistic I2IT task, such as illuminations or colors, are primarily exhibited in the low-frequency component, while content details are related to higher-frequency components. By refining the high-frequency components adaptively and avoiding heavy convolutions on high-resolution feature maps, LPTN achieves efficient manipulation of the low-frequency component and faithful reconstruction of the image from a Laplacian pyramid.Experimental results show that LPTN enables real-time photorealistic I2IT on 4K resolution images while still achieving comparable or superior performance in terms of transformation capacity and photorealism compared to state-of-the-art methods. The proposed method is trained in an unsupervised manner using an adversarial training strategy. Overall, LPTN offers a lightweight and efficient solution for photorealistic image translation.