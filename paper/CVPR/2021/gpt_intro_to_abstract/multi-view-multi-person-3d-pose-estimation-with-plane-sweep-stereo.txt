3D human pose estimation for multiple persons from monocular images is a challenging and ill-posed problem in computer vision. The loss of depth information and severe occlusions under a single camera viewpoint further complicate the task. Utilizing multi-view images captured by multiple cameras can provide complementary information to alleviate projective ambiguities. Previous methods address this problem through a three-step process of estimating 2D poses for each camera view independently, identifying and grouping corresponding poses, and estimating the 3D pose using triangulation or optimization-based models. However, establishing cross-view correspondences remains critical for accurate multi-view multi-person 3D pose estimation. Traditional methods employ greedy matching or optimization-based approaches, but recently, Voxel-Pose has proposed a voxel-based object detection paradigm that avoids explicit cross-view matching. However, Voxel-Pose has limitations such as requiring prior knowledge of the 3D space dimension, scalability issues with large scenes, and heavy computations with 3D convolutions. In this work, we propose a plane-sweep-based approach for multi-view multi-person 3D pose estimation. Our framework utilizes plane sweep stereo to estimate depth for each joint and person in the target camera view. We measure cross-view consistency at each depth level and regress depths using convolutional neural networks. Our depth regression employs a two-stage coarse-to-fine scheme. During inference, 3D poses are obtained by back-projecting 2D poses with estimated depths, and multiple poses of the same person from different views can be easily merged using distance-based clustering. We evaluate our approach on benchmark datasets and outperform existing state-of-the-art methods. Additionally, our method is more efficient than Voxel-Pose, as it leverages the plane sweep algorithm and utilizes faster 1D convolutions instead of 3D convolutions. Our method is also more generalizable to various camera settings. In summary, our contributions include a plane-sweep-based approach that performs multi-view multi-person 3D pose estimation without explicit cross-view matching, achieving superior performance and efficiency compared to existing methods.