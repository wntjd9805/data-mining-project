Instance segmentation is a fundamental task in computer vision that requires predicting pixel-wise masks and categories for instances of interest. Recent methods have significantly advanced the performance of instance segmentation, making it as simple and fast as bounding-box object detection. However, instance segmentation still requires heavier pixel-wise mask annotations compared to bounding box detection, which is time-consuming. In this paper, we propose a box-supervised instance segmentation method called BoxInst, which eliminates the need for pixel-level mask annotations. We replace the original pixel-wise mask losses with a carefully designed mask loss consisting of two terms. The first term minimizes the discrepancy between the projections of the predicted mask and the ground-truth box, ensuring that the predicted mask matches the ground-truth box. The second term supervises the pairwise label consistency in proximal pixels, using color similarity as a threshold to eliminate supervision noises. Through these two loss terms, we achieve impressive instance segmentation results without using any mask annotations. BoxInst outperforms fully supervised methods on large-scale benchmarks such as COCO, achieving 33.2% mask AP without mask annotations. Additionally, BoxInst has the potential to improve the performance of downstream tasks without the need for annotating ground-truth masks. This work challenges the belief that instance segmentation is significantly more challenging than bounding box detection, highlighting the potential for solving instance segmentation with only box supervision.