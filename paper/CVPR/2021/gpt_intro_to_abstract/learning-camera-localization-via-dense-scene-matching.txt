Camera Localization involves estimating the 6-DoF camera pose of an image in a known environment, and it is crucial for various applications such as mobile navigation, SLAM, and AR. There are two main categories of camera localization methods: regression-based and structure-based. Regression-based methods directly predict camera poses but tend to be less accurate. Structure-based methods, on the other hand, establish correspondences between 2D query image pixels and 3D scene points before estimating the camera pose. These methods can be further categorized into sparse feature matching and scene coordinate map regression approaches. Sparse feature matching methods detect and match feature points, while coordinate map regression methods predict dense 3D coordinates at all image pixels.This paper focuses on the coordinate map regression approach, specifically, the dense coordinate regression network SANet. However, SANet randomly selects coordinates within a region, which leads to pose accuracy issues and computational heaviness. To address this problem, the paper proposes a new camera localization network that utilizes dense scene matching via a cost volume. The cost volume ensures more accurate scene points by enforcing a higher correlation with the query image pixel. To handle the irregular scene structure, the paper suggests a solution to unify the size of all cost volumes by selecting the best candidates and feeding them to a neural network for dense coordinate regression. The cost volume can also be fused with temporal correlations for video localization.The proposed method is evaluated on benchmark datasets for indoor and outdoor scenes, and it outperforms both scene-specific and scene-agnostic methods in terms of pose accuracy and coordinate accuracy.