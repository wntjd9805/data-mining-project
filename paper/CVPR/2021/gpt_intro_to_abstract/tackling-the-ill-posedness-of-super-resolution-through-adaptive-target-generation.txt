Image super-resolution (SR) aims to generate a high-resolution (HR) image from a low-resolution (LR) counterpart. Previous SR methods have focused on finding the relationship between LR and HR patch pairs in natural images, either within a single image or through external example-based approaches. In these learning-based approaches, training example pairs are simulated from a collection of HR images in a self-supervised manner. However, the SR problem becomes under-determined as different HR images can be mapped to the same LR image. This issue is exacerbated in blind SR, where the blur kernel is unknown and diverse. To address this, previous blind SR methods estimate the blur kernel and use it as an additional input for the SR network, but they are sensitive to inaccurate predictions. In this paper, we propose a different approach that allows more flexibility in SR network outputs. Instead of comparing directly to the original target, our method computes the loss for an adaptive target that relaxes the typical pixel reconstruction loss and allows various HR predictions given an LR input. This adaptive target is created on-the-fly during training and encourages the generation of sharper outputs. Unlike previous blind SR methods, our approach does not rely on additional kernel information. We demonstrate the effectiveness of our method in terms of peak signal-to-noise ratio (PSNR) and visual quality, outperforming previous blind SR models. Additionally, our method is effective for non-blind SR when combined with adversarial training (GAN) for realistic SR. Overall, our contributions include introducing a simple and effective way to encourage sharp output generation using an adaptive target, demonstrating applicability to any training dataset, and achieving superior performance in blind and non-blind SR scenarios.