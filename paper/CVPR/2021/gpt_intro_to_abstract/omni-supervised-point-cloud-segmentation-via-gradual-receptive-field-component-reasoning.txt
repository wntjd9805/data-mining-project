Semantic segmentation of point cloud is a challenging task in 3D vision with applications in robotics, autonomous driving, and virtual/augmented reality. Previous works have used encoder-decoder architectures to extract global context features and achieve point-wise labeling. However, these approaches lack direct supervision in intermediate layers, leading to a need for multi-scale/omni-scale supervision. While multi-scale supervision has been explored in 2D vision, it has not been successfully applied to 3D semantic segmentation due to the irregularity of point cloud data. In this paper, we propose an omni-scale supervision method using Receptive Field Component Reasoning. Instead of up-sampling hidden features, we design a Receptive Field Component Code (RFCC) to trace the encoding relationship and represent categories within receptive fields. Target RFCCs are generated at different layers to supervise the network at all scales. We demonstrate the effectiveness of our method on multiple point cloud datasets, outperforming state-of-the-art methods and pushing the performance on challenging datasets.