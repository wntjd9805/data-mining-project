Deep Neural Networks (DNNs) have found widespread applications in many computer vision tasks. However, executing DNNs on edge devices poses challenges due to the large sizes of state-of-the-art models. Model compression approaches, such as pruning and quantization, have been proposed to reduce the sizes of DNN models without significant loss in accuracy. Tensor decomposition, a mathematical tool that explores the low tensor rank characteristics of large-scale tensor data, has emerged as an attractive DNN model compression technique. It offers ultra-high compression ratios, especially for recurrent neural network (RNN) models. Prior research works have explored tensor decomposition-based DNN models and developed TT-format DNN hardware accelerators. However, the performance of tensor decomposition in compressing convolutional neural network (CNN) models for image classification tasks is limited, with significant accuracy loss. This limitation is mainly attributed to the challenges involved in training tensor decomposed DNN models. This paper proposes a systematic framework for tensor decomposition-based model compression using the alternating direction method of multipliers (ADMM). The framework leverages ADMM to solve the tensor decomposition optimization problem iteratively, gradually restricting the DNN model to the target tensor ranks without explicitly training on the TT format. Experimental results demonstrate that the proposed ADMM-based TT-format models achieve high compression performance with high accuracy in image classification and video recognition tasks. For example, on CIFAR-100, the models achieve higher top-1 accuracy compared to the original ResNet models at compression ratios of 2.3x and 2.4x.