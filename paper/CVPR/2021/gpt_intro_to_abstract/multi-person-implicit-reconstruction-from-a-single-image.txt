This paper introduces a model-free approach for multi-person human reconstruction from a single image. This technique has applications in various fields such as surveillance, film production, AR/VR content generation, and sports broadcasting. Compared to multi-view reconstruction methods, single-camera reconstruction is more practical and cost-effective. Recent advancements have been made in estimating 3D human pose and shape from a single image or video, with methods classified as model-based or model-free. Model-based methods use parametric body shape models, such as SMPL, to reconstruct people, while model-free methods provide more realistic reconstructions of people with loose clothing and hair details. However, existing methods require fully visible individuals without occlusions for accurate reconstruction. This paper presents the first model-free end-to-end approach that can reconstruct multiple clothed people from a single image, even in crowded scenes with inter-person occlusions. The proposed approach produces a spatially coherent reconstruction of each person, along with their spatial locations and orientations, without manual intervention. Additionally, the authors introduce a multiple people synthetic dataset and benchmark that allows for quantitative evaluation of the reconstruction. The contributions of this paper include the novel approach for model-free multi-person reconstruction, an end-to-end framework using multitask networks for 3D reconstruction and location/orientation estimation, a synthetic dataset with complex scenes, and a method that leverages volumetric and implicit 3D shape representations for detailed reconstructions from a single image.