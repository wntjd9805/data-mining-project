Instance-aware human parsing, which involves partitioning humans into semantic parts and associating each part with the corresponding human instance, has only recently been explored in the literature. This paper introduces a new approach for tackling this task by jointly estimating human poses and segmenting human parts in an end-to-end trainable, bottom-up fashion. The proposed model incorporates category-level human semantic parsing, body-to-joint projection, and bottom-up keypoint detection and association in a differentiable framework. By leveraging both sparse human joints and dense part semantics, the model enhances human understanding in unconstrained environments. The framework offers a new paradigm for bottom-up, instance-aware human part parsing and demonstrates promising performance with high efficiency. It avoids sophisticated inference and heavy network designs by regressing semantic-rich human joints as pixel embeddings and efficiently grouping fine-grained human semantics through body joint association. The model also introduces three crucial techniques: differentiable body-to-joint projection, multi-step projection field estimation, and an end-to-end trainable framework. These techniques contribute to the compact and powerful nature of the proposed instance-aware human parsing solution. The model's practical utility extends to various human-centric applications, and it generates instance-level parsing results at a high speed, surpassing alternative methods in terms of efficiency. Extensive experiments on three instance-aware human parsing datasets confirm the favorable performance of the proposed model.