Instance segmentation plays a crucial role in various computer vision applications, such as autonomous driving and robotics. The Mask R-CNN framework has gained popularity for its ability to detect objects and perform binary segmentation to generate instance masks. However, the quality of the predicted instance masks is often subpar, particularly around object boundaries. This is due to the low spatial resolution of the output and the difficulty in classifying pixels near boundaries. Existing methods have attempted to address these challenges but have not fully solved the issues. In this paper, we propose a post-processing framework called BPR (Boundary Patch Refinement) that improves boundary quality through a crop-then-refine strategy. This approach leverages the behavior of human annotators who first localize and categorize objects, provide coarse instance masks, and then zoom into boundary regions to achieve higher-resolution segmentation. BPR extracts small image patches along predicted boundaries, refines them through a refinement network, and reassembles them into high-quality instance masks. The proposed framework significantly improves mask quality without requiring modifications or fine-tuning of segmentation models. It retains low-level details by processing patches at higher resolution and increases the fraction of boundary pixels, thus alleviating optimization bias. BPR outperforms existing boundary refinement methods and can be applied to other segmentation models as well. In fact, it achieved state-of-the-art results on the Cityscapes test set and secured the top position on the Cityscapes leaderboard at the time of submission.