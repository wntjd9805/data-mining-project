3D human pose estimation is a crucial task with various applications such as sport analysis, human-computer interaction, and fitness and dance teaching. Although significant progress has been made in 3D pose estimation, challenges like depth ambiguity and self-occlusion still remain unsolved. In scenarios where people are in front of a mirror, the mirror image provides an additional virtual view that can resolve depth ambiguity and alleviate occlusion problems. This paper explores the use of mirror images to enhance the accuracy of 3D human pose estimation. We propose an optimization-based framework with mirror symmetry constraints that does not require prior knowledge of mirror geometry or camera parameters. Additionally, we introduce a method to leverage vanishing points to recover the mirror normal and camera parameters, enabling the imposition of an additional mirror normal constraint for improved pose estimation accuracy. Our framework is validated on a newly created dataset with ground-truth 3D pose provided by a multi-view camera system. Furthermore, we demonstrate that our approach can generate pseudo ground-truth annotations to train existing 3D pose estimation models. We curate a large-scale dataset called Mirrored-Human, comprising internet images containing people and mirrors, and use our optimization method to generate 3D pose annotations. Experiments show that incorporating Mirrored-Human into training data significantly enhances the accuracy and generalizability of existing 3D pose estimation methods for both single-person and multi-person cases. In summary, this paper introduces the task of reconstructing human pose from a single image containing the person and their mirror image. We propose a novel optimization-based framework and present the Mirrored-Human dataset, which improves the performance of existing 3D pose estimation models.