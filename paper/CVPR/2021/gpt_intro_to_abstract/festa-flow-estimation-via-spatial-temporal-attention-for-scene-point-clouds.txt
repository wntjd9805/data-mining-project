This paper introduces a novel approach called Flow Estimation via Spatial-Temporal Attention (FESTA) for accurately estimating scene flow from point cloud data. Scene flow, which represents the 3D vector field of the scene dynamics, is important for various computer vision applications such as self-driving cars and robots. Existing methods for scene flow estimation from point clouds encounter challenges due to the inconsistent down-sampling of points using the Farthest Point Sampling (FPS) technique. To address this issue, the authors propose a Spatial Abstraction with Attention (SA2) layer that utilizes a trainable Aggregate Pooling (AP) module to generate stable down-sampled points. These points define attended regions for further processing. Additionally, a Temporal Abstraction with Attention (TA2) layer is introduced to handle both large-scale and small-scale motion estimation. The TA2 layer refines the initial scene flow by shifting temporal attended regions to more correspondent areas. The proposed FESTA architecture achieves state-of-the-art performance in 3D point cloud scene flow estimation on synthetic and real-world benchmarks. Overall, this work presents contributions in stable point cloud abstraction, motion coverage, and performance improvement in scene flow estimation.