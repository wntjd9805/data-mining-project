Semi-VOS is a challenging task in computer vision that involves tracking an object of interest across all frames in a video. This task has wide applicability to various real-world scenarios such as autonomous driving, surveillance, video editing, and augmented reality devices. The main challenge in VOS is distinguishing the target object from other similar objects in the scene, even as the target's appearance changes over time and through occlusions.Previous methods for video object segmentation have utilized information from previous frames to produce high-quality segmentation masks. However, in this work, we propose a different question: Can we use temporal information to identify when the object's appearance and position have not changed across frames? This motivation is to skip computationally expensive operations for frames that have masks similar to the previous frame's masks.To address this question, we construct a cheap temporal matching module that quantifies the similarity between the current frame and the previous frame. We use this similarity to determine whether to reuse previous features with minor refinements or perform the expensive mask generation step. By doing so, we can significantly reduce the computation required for the current frame without sacrificing accuracy.Our approach complements existing video object segmentation models and can be integrated into prior models such as FRTM and TTVOS. We believe this is a significant contribution that enables high-quality video object segmentation on mobile devices in real-time with minimal battery impact.In this paper, we present the following contributions:1. We propose exploiting temporal information to skip mask generation for frames with little or no movement.2. We develop a general framework consisting of sub-networks to estimate movement across frames, dynamic selection between processing the full network or reusing previous frame's features, and a novel loss function to train this dynamic architecture.3. We evaluate our approach on multiple video object segmentation models and challenging datasets, demonstrating up to a 47.5% computation reduction and a 1.45x FPS speedup with minimal accuracy impact.Overall, our proposed method shows promising results in improving the efficiency of video object segmentation algorithms, making them suitable for real-time applications on resource-constrained devices.