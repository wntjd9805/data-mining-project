Video prediction is an important task in computer vision, as it involves estimating future frames at the pixel-level based on previous frames. This has applications in various fields such as weather forecasting, traffic prediction, and autonomous driving. However, pixel-level video prediction is challenging due to the complexities involved in capturing high-dimensional and long-term motion dynamics. Previous studies have proposed deep neural network approaches to tackle these challenges, but they have not adequately addressed the long-term motion context issues.In this paper, we propose a novel motion context-aware video prediction method to overcome these challenges. We introduce a long-term motion context memory (LMC-Memory) with memory alignment learning, which allows us to store and recall various long-term motion contexts that are not limited to the current input. This memory alignment learning consists of two phases: storing long-term motion context and matching short-term sequences with the stored contexts. This enables us to predict the long-term motion context from a short-term input sequence alone.Additionally, to handle the high-dimensionality of motions, we propose the decomposition of memory query. This allows us to store and recall local motion contexts with low-dimensional dynamics, thereby improving the alignment between the input and the stored long-term motion context in the LMC-Memory.The contributions of this paper are three-fold. Firstly, we introduce a novel motion context-aware video prediction method that addresses the long-term motion context issues not effectively tackled by previous RNN-based methods. Secondly, we propose the LMC-Memory with memory alignment learning to address the storage and recall of long-term motion contexts. Finally, we propose the decomposition of memory query to handle the high-dimensionality of motions and improve the alignment between the input and the stored motion contexts.Overall, our work aims to improve the accuracy of video prediction by leveraging long-term motion context and addressing the challenges posed by high-dimensional motions.