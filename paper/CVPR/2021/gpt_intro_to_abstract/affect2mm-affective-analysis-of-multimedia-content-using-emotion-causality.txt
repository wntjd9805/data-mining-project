This paper introduces the problem of affective analysis of movies, focusing on understanding the emotions invoked in the audience. The authors explore the use of time-series emotion recognition models to dynamically model emotions over time, using temporally continuous data from multimedia content. They propose Affect2MM, a learning model that aligns with the theory of emotional causality and incorporates temporal causality through attention methods and Granger causality. The authors also discuss the use of emotion datasets, theories of emotion causation, and the representation of emotions using the Valence-Arousal-Dominance (VAD) model. The paper presents the novel contributions of Affect2MM and evaluates its performance on multiple movie datasets, showcasing its generalizability.