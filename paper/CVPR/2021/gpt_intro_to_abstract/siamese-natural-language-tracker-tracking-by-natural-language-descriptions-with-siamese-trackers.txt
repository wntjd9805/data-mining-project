This paper presents a novel approach to tracking objects using natural language descriptions in real-time. The authors observe that the fields of visual and language recognition evolve concurrently in children, but in computer vision, these two areas have been developed independently. The authors propose a Siamese Natural Language Tracker (SNLT) that leverages predictions from both visual and language modalities. They introduce a Siamese Natural Language Region Proposal Network (SNL-RPN) that transforms NL descriptions into convolutional kernels and shares feature extraction layers with Siamese trackers. The SNL-RPN is dynamically aggregated to create the SNLT, which outperforms all prior NL trackers and achieves state-of-the-art performance. The proposed SNLT improves Siamese trackers by 3 to 7 percentage points and runs at over 50 frames per second. Overall, this paper provides a practical and general solution to the challenge of tracking objects with NL descriptions in real-time.