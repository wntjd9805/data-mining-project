Pre-training has become a common approach in computer vision tasks, where models are trained on large-scale datasets and then fine-tuned on target tasks with limited training data. The dominant pre-training method is supervised ImageNet pre-training, where models are trained to solve image classification and then transferred to downstream tasks. However, there is a gap between image classification pre-training and target dense prediction tasks, such as object detection and semantic segmentation. Annotation for these tasks is time-consuming, making it difficult to collect enough data for universal feature representation pre-training.Unsupervised visual pre-training has gained attention as a way to learn visual representations from unlabeled images. Some methods have shown effectiveness in downstream tasks, achieving comparable or better results than supervised ImageNet pre-training. However, there is still a gap between image classification pre-training and dense prediction tasks. Existing self-supervised learning methods focus on global image-level prediction using instance discrimination, but better image classification does not guarantee better object detection. There is a need for self-supervised learning customized for dense prediction tasks, removing the gap between pre-training and target tasks.Inspired by supervised dense prediction tasks like semantic segmentation, which performs dense per-pixel classification, we propose dense contrastive learning (DenseCL) for self-supervised visual pre-training. DenseCL treats the learning task as dense pairwise contrastive learning rather than global image classification. It introduces a dense projection head that preserves spatial information and generates dense feature vectors. The positive sample of each local feature vector is defined by extracting correspondence across views. A dense contrastive loss is designed as an unsupervised objective function, extending the conventional InfoNCE loss to a dense paradigm. DenseCL performs contrastive learning densely using a fully convolutional network (FCN), similar to target dense prediction tasks.The main contributions of this paper are: the proposal of dense contrastive learning as a new paradigm for self-supervised visual pre-training, the design of DenseCL as a simple and effective self-supervised learning method tailored for dense prediction tasks, and the demonstration that DenseCL significantly outperforms the state-of-the-art MoCo-v2 when transferring pre-trained models to downstream dense prediction tasks, surpassing supervised ImageNet pre-training in object detection, instance segmentation, and semantic segmentation.