Outdoor vision systems, often used in intelligent vehicles and surveillance, can be affected by rain pollution, leading to undesirable image quality. To tackle this issue, researchers have explored methods for image deraining, which involves removing rain streaks from images. Previous approaches have utilized specific prior knowledge, such as the dark channel or maximizing contrast among different regions. However, these methods struggle to effectively remove sparse rain streaks. Other techniques based on physical properties aim to separate the rain layer from the background layer using sparse coding, dictionary learning, and Gaussian mixture models. However, these methods are limited by their dependence on specific prior knowledge and their inability to handle complex and diverse scenarios. In recent years, deep learning-based approaches for image deraining have gained popularity. These methods employ deraining networks as conditional generators, generating high-quality output images by embedding target image information into the model. Existing deep learning methods focus on network structure design and guided features, resulting in potential loss of details and halo artifacts. To address these limitations, we propose a robust representation learning approach for image deraining that incorporates feedback mechanisms to handle uncertainty-induced model errors. By finding a functional relationship between basic and optimal embedding features, our approach aims to improve deraining performance by replacing low-quality features with latent high-quality features. The contributions of this paper include an analysis of uncertainty impact and model error remapping, the design of error detection and feature compensation mechanisms, and the introduction of latent high-quality features to enhance image deraining.