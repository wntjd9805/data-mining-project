Image compression is a widely used technique in computer vision, with lossless image compression being the preferred choice for applications requiring high image fidelity. However, the compression ratio of lossless compression is limited by Shannon's source coding theorem and typically ranges from 2:1 to 3:1 for practical codecs. To improve compression performance while maintaining reliability, ℓ∞-constrained near-lossless image compression has been developed and standardized in traditional codecs like JPEG-LS and CALIC. Unlike lossy image compression, near-lossless compression requires the maximum reconstruction error of each pixel to be within a specified tight numerical bound.Recent advancements in deep neural networks have led to significant progress in learning-based lossy image compression methods. These approaches, based on variational auto-encoder (VAE) architecture, achieve competitive performance with the latest compression standards by optimizing rate-distortion trade-offs. However, these methods cannot be directly applied to near-lossless compression as DNN-based transforms struggle to meet the tight error bounds required.In this paper, a novel joint lossy image and residual compression framework for learning near-lossless image compression is proposed. Inspired by the traditional "lossy plus residual" coding scheme, the framework obtains a lossy reconstruction of the raw image and uniformly quantizes the residual to meet the given ℓ∞ error bound. The optimization problem of compressing both the lossy image and original residual is formulated using VAEs, and an end-to-end training approach is employed. Additionally, to achieve scalable near-lossless compression, the probability model of the quantized residual is derived from the learned probability model of the original residual, instead of training multiple networks. A bias correction scheme is introduced to address the context mismatch between training and inference. The compression is achieved using an arithmetic coder, and the resulting compressed image includes the bitstreams of the encoded lossy image and quantized residual.The main contributions of this paper include the proposal of a joint lossy image and residual compression framework that enables learning-based lossless and near-lossless image compression. The framework, interpreted as a VAE model, can be optimized end-to-end. Scalable compression is achieved by deriving the probability model of the quantized residual, and a bias correction scheme further improves the compression performance. The proposed codec achieves state-of-the-art performance for lossless and near-lossless image compression, with competitive PSNR and smaller ℓ∞ error compared to lossy image codecs at high bit rates.