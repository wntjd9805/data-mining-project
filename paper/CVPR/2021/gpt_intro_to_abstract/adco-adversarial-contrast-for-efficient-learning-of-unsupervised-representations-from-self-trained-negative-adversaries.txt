Learning visual representations in an unsupervised fashion has gained significant attention in the field of computer science. This approach reduces the need for labeled data and has shown progress in reducing the performance gap with fully supervised models. One family of methods, known as contrastive learning, trains deep networks by distinguishing the representation of positive queries from their negative counterparts. Two types of contrastive learning approaches have been proposed: one type maintains a queue of negative examples from past minibatches, while the other type uses all negative examples from the current minibatch. However, both approaches have limitations. The queue-based approach struggles to track the rapid change of feature representations and incurs inefficiencies in training the network. The minibatch-based approach requires a larger minibatch size, which leads to memory and computing burdens. To overcome these drawbacks, this paper introduces an Adversarial Contrast (AdCo) model that consists of a backbone representation network and a collection of negative adversaries. The backbone network encodes input samples while the negative adversaries discriminate against positive queries. The model alternately updates these two components, training the backbone network to minimize the contrastive loss and updating the negative adversaries to closely track the positive queries. The paper demonstrates that the AdCo model outperforms existing methods on downstream tasks and is capable of training unsupervised networks with fewer epochs. For example, AdCo achieves a higher top-1 accuracy than other models with the same or less GPU time. Additionally, AdCo achieves a record top-1 accuracy compared to state-of-the-art models while maintaining computational efficiency. The paper concludes with a review of related works, an explanation of how AdCo focuses on low-density queries, experimental results, and final remarks.