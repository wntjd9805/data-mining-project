Whole slide scanning is a widely used tool in medical diagnosis and research, allowing tissue sections to be visualized digitally. However, automated disease detection in these digital whole slide images (WSIs) has been a challenge for computer aided diagnostic systems. Patch-based processing, where WSIs are divided into small patches and examined by a classifier, is commonly used for WSI classification. However, labeling patches by expert pathologists is time-consuming and difficult. Weakly supervised WSI classification, which uses slide-level labels for training, has shown promise in addressing this challenge. Most previous approaches for weakly supervised WSI classification follow a multiple instance learning (MIL) formulation, where each WSI is treated as a bag containing patches. However, there are challenges in developing deep MIL models for this task, particularly when the patches in positive images are highly unbalanced and when fixed patch features or only a few high score patches are used. To address these challenges, we propose a novel deep MIL model called DSMIL, which jointly learns a patch and an image classifier using a two-stream architecture. DSMIL incorporates a soft selection of instances based on attention scores, resulting in a better decision boundary. It also incorporates self-supervised contrastive learning for training the feature extractor and utilizes a multiscale feature fusion mechanism. We evaluate DSMIL on two public WSI datasets and demonstrate its superior performance in both classification accuracy and localization accuracy compared to other MIL models. Furthermore, DSMIL also achieves state-of-the-art performance on general MIL problems beyond weakly supervised WSI classification.