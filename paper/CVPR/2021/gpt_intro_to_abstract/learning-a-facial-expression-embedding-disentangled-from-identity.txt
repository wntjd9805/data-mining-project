Facial expression plays a crucial role in human social communication. However, accurately perceiving facial expressions remains a challenge for computers. In order to develop effective human-computer interaction, it is important to have a reliable representation of facial expressions. Previous methods, such as the Facial Action Coding System (FACS) and categorical expression models, have attempted to build discrete expression representations. However, these methods fail to capture the large variance within emotional classes and struggle with the identity-entangled problem. As a result, existing expression representations lack the capacity to extract fine-grained and identity-invariant expression information from faces, hindering downstream tasks such as expression recognition, image retrieval, and face manipulation.This paper introduces a novel expression embedding framework called the Deviation Learning Network (DLN) that learns a continuous and smooth space for expressions from face images. The framework adopts the idea of contrastive comparison to learn the expression distribution, aiming to map similar expressions within a triplet close to each other while keeping a distance from the third one. Additionally, the paper proposes modeling facial expression as a deviation from facial identity representation, effectively disentangling the two attributes. This disentanglement allows for the explicit resolution of the expression embedding problem.The DLN framework consists of three modules: a deviation module, a high-order module, and a crowd layer. The deviation module extracts identity-invariant deviation features by subtracting the identity attribute from the face representation. The high-order module maps the high-dimensional features to a low-dimensional manifold using the high-order polynomial of the deviation for nonlinear mapping. To alleviate label noise, the crowd layer accounts for different annotators' label bias, ensuring a more robust expression embedding.In summary, the main contributions of this paper are threefold. Firstly, it addresses the challenge of learning an identity-invariant facial expression embedding through the innovative DLN framework. Secondly, it introduces the high-order module to improve the fitting performance from high-dimensional expression space to a low-dimensional manifold. Lastly, it enhances expression embedding in terms of robustness with the crowd layer and in terms of fine-grained property with hierarchical-annotated triplets. Extensive experiments demonstrate the potential of the proposed method in various tasks such as emotion recognition, image retrieval, and face manipulation.