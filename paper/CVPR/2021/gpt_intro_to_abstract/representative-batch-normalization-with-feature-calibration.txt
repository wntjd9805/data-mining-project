Convolutional Neural Networks (CNNs) have significantly improved the performance of computer vision tasks. However, as CNNs become more complex with increased model parameters, training difficulties arise. Batch normalization (BatchNorm) has been effective in alleviating these difficulties by constraining intermediate features within a normalized distribution. However, this assumption that features generated from different instances fit into the same distribution within a channel does not always hold true. This inconsistency can affect the training performance of CNNs.To address this issue, previous works have proposed utilizing instance-specific statistics to normalize intermediate features. However, these approaches often have inferior performance compared to BatchNorm due to the lack of batch information and training instability.Other methods combine multiple normalization techniques or introduce attention mechanisms, but these approaches introduce additional overhead and may not be practical for real-world usage.In this paper, we propose a simple yet effective feature calibration scheme to enhance the instance-specific representations while maintaining the batch benefits of BatchNorm. We focus on calibrating the feature standardization operation of BatchNorm by adjusting the centering and scaling operations. We address the inconsistencies introduced by inappropriate running statistics during testing by utilizing instance-specific statistics to calibrate the centering and scaling operations. This calibration process only introduces three weights per channel and has a negligible computational cost.We introduce Representative Batch Normalization (RBN) by adding the centering and scaling calibrations to BatchNorm. Our experiments show that the model equipped with RBN achieves smaller training loss and testing error compared to using BatchNorm alone. We demonstrate that RBN can be used as a replacement for BatchNorm in existing methods to enhance the performance of various computer vision tasks, such as classification, detection, and segmentation, with minimal additional cost and parameters.