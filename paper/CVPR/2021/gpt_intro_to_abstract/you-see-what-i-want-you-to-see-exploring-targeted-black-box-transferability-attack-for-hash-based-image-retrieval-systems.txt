Abstract:This paper addresses the vulnerability of deep hashing, a leading technique in content-based image retrieval, to adversarial attacks. Adversarial examples, crafted with minimal perceptual difference, can cause misclassification in deep hashing systems, leading to incorrect search results or the inclusion of inappropriate content in the database. Previous works have shown success in untargeted attacks, but targeted attacks, which strategically mislead search results into specific categories, are yet to be fully explored. This paper explores and improves targeted transferable attacks in deep hashing, focusing on the existence of vulnerable pairs that transfer more easily than others. The authors design algorithms to estimate the generated adversarial region and propose a new attack that is both adversarial and robust to random noise. Extensive experiments demonstrate the effectiveness of the proposed attack in boosting black-box transferability compared to existing techniques. This work not only bridges the areas of adversarial attacks and image retrieval but also opens up new possibilities for realistic attacks in image retrieval systems.