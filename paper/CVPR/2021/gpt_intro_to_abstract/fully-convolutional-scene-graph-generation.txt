This paper addresses the problem of semantic content representation and reasoning in computer vision systems. The authors propose a novel fully convolutional scene graph generation model, called FCSGG, which represents objects as points and relationships as vectors. The relationships are encoded as a segment in a 2D vector field called relation affinity fields (RAF). The proposed model allows for the explicit representation and reasoning of detailed semantics, enabling downstream tasks such as image captioning, image retrieval, visual question answering, and image generation. The authors make several contributions, including a more compact and computationally efficient scene graph generation model, the introduction of relation affinity fields as a novel relationship representation, strong results on zero-shot recall, and near real-time inference. The proposed model outperforms visual-only scene graph generation methods and achieves competitive results compared to methods utilizing external knowledge. Comprehensive experiments and benchmarks are conducted to evaluate the proposed method. Overall, this paper presents a promising approach to scene graph generation and provides insights into improving the efficiency and scalability of computer vision systems.