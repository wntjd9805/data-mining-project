This paper focuses on the task of estimating the 7 Degrees-of-Freedom (location, dimension, and orientation) state of surrounding objects in complex real-world environments for autonomous vehicles and robots. LiDAR-based 3D object detection has gained attention due to its ability to provide direct 3D measurements; however, it still faces challenges such as point sparsity and large search space in 3D. Existing methods often transform irregular point cloud data into regular 3D voxel grids or 2D projections for feature extraction, but quantization errors in these methods limit performance. Point-based methods can learn features from raw point cloud data, but require complicated operations for information aggregation and are often combined with other representations for object detection. In this paper, the authors propose a method called LiDAR R-CNN, inspired by the R-CNN approach, which aims to refine a set of proposals in 3D space. The authors choose PointNet as their preferred method due to its ability to process points from a single object in a small region. However, they discover a size ambiguity problem with PointNet, which disregards the spacing in 3D space, leading to subpar results. To address this issue, the authors propose several solutions and demonstrate their effectiveness through extensive experiments on the Waymo Open Dataset. Their proposed LiDAR R-CNN significantly improves the performance of existing detectors, even outperforming state-of-the-art models. The contributions of this paper are the introduction of an R-CNN style detector based on PointNet, the identification and resolution of the size ambiguity problem, and the consistent performance improvements demonstrated on various datasets and base detectors.