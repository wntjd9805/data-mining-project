Deep neural networks have shown significant progress in visual recognition tasks using large-scale datasets such as ImageNet, COCO, and Places. However, real-world data often exhibit a long-tailed distribution, where head classes dominate the data and tail classes have very few samples. This poses a challenge to state-of-the-art classification models, as they tend to perform poorly on datasets with long-tailed distributions. Many methods have been proposed to address this issue by training on the source label distribution (ps) and evaluating on the target label distribution (pt). However, this evaluation protocol may not be practical, as the target label distribution can be arbitrary. To overcome this limitation, this paper proposes a new method called LADE (Label Distribution DisEntangling) that disentangles the source label distribution from the model prediction. The proposed Post-Compensated Softmax (PC Softmax) baseline method shows promising results in disentangling the label distribution during the inference phase. Building upon this, LADE uses the Donsker-Varadhan representation to directly disentangle the source label distribution during training. Experimental results demonstrate that LADE achieves state-of-the-art performance on benchmark datasets and can effectively adapt to arbitrary target label distributions. Additionally, LADE also improves confidence calibration in the classification model. Overall, this paper introduces PC Softmax as a strong baseline and proposes LADE as a novel method for long-tailed visual recognition tasks.