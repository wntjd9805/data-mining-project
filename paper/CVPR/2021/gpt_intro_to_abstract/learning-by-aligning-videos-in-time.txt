In this paper, we address the problem of spatio-temporal registration in computer vision and its application in deep learning. We focus on the task of learning perfect alignment of two videos, which requires disentangling phases of activity in time and associating visually similar frames in different videos. We propose a self-supervised method called Learning by Aligning Videos (LAV) that utilizes temporal alignment as a means of learning video representations. We adopt Dynamic Time Warping (DTW) as the alignment metric and introduce a regularization term to optimize for temporally disentangled representations. Our approach achieves comparable or better performance than state-of-the-art methods on various temporal understanding tasks and offers significant accuracy gain when labeled data is lacking. We have also released a dataset of dense per-frame labels for the Penn Action dataset. Overall, our work contributes to the revival of temporal alignment in video representation learning and demonstrates its effectiveness in downstream tasks.