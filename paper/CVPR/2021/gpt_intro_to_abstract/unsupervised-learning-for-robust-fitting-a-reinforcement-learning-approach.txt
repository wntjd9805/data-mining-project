This paper introduces a novel unsupervised learning framework for robust estimation in computer vision. The presence of outliers in data can significantly affect the performance of algorithms, making the use of robust estimators essential. While supervised learning methods have shown superior performance, they require a large amount of labeled data. The paper proposes a solution to this bottleneck by formulating robust fitting as a goal-oriented reinforcement learning problem. The authors leverage the consensus maximization formulation and develop a state embedding scheme based on a graph convolutional network. They also introduce an efficient backbone network that allows the agent to explore the action space and achieve the goal state. The proposed method is compared to a globally optimal algorithm, demonstrating its ability to effectively explore the environment and identify the shortest path to remove outliers. This work is the first to apply deep architecture models within a reinforcement learning paradigm for consensus maximization in computer vision. The contributions of the paper include the unsupervised learning framework, the state embedding scheme, and the efficient backbone network.