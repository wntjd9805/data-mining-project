Abstract: Estimating 3D human body shape and pose from RGB images has various applications in augmented and virtual reality, healthcare, fitness technology, and virtual retail. Previous solutions have focused on single images, video with temporal constraints, and multi-view images. In contrast, our approach aims to estimate 3D body shape and pose from a group of unconstrained images of the same subject. We present a probabilistic method that predicts a proxy representation from each image, then uses a distribution prediction network to output a probability distribution over body shape and pose parameters. These distributions are then combined to yield a final shape prediction. Our method improves accuracy over current single-image estimators and considers uncertainty in pose parameter estimates. Training accurate body shape predictors is challenging due to the lack of suitable training datasets, so we adopt a synthetic training approach and extend data augmentations to better model occlusion and missing body parts. We propose a novel task, provide a solution, output uncertainties alongside predictions, and demonstrate improved metrics compared to previous methods.