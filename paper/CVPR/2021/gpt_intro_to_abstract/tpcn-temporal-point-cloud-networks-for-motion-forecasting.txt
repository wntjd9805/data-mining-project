Motion forecasting in autonomous driving plays a crucial role in predicting the future trajectories of surrounding traffic participants, such as vehicles and pedestrians. Traditional methods for motion forecasting have relied on kinematic constraints and handcrafted rules, which often fail to capture the complex behavior and interaction in urban scenarios. To overcome these limitations, recent advancements have explored the use of data-driven methods with deep learning. However, existing approaches still face challenges in efficiently representing environment and agent history, requiring significant computation and data. In this paper, we propose a novel architecture called Temporal Point Cloud Networks (TPCN) for motion forecasting. TPCN combines spatial and temporal learning in a unified framework, leveraging the joint spatial-temporal space representation of agents' history observations and map data. By employing a spatial module based on point cloud learning and a temporal module for sequential feature extraction, TPCN effectively predicts future trajectory points. We introduce several components in our approach, including Dual-representation Spatial Learning for feature extraction and Dynamic Temporal Learning for handling variant time lengths of different agents. Our method addresses the problem of multi-modal trajectory selection through displacement regression, providing a more flexible approach compared to classification-based methods. We conduct extensive experiments on the Argoverse motion forecasting benchmark, demonstrating the effectiveness of our proposed approach.