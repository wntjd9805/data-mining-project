We are surrounded by dynamic environments that require the reconstruction of time-varying surfaces for various applications such as robotics, autonomous driving, and virtual/augmented reality. Previous works in 4D reconstruction have faced limitations such as the need for expensive template meshes or clean input data. To address these issues, OccFlow proposed a learning-based framework for 4D reconstruction that establishes dense correspondences between occupancy fields. However, this framework has limitations in spatial and temporal encoding and suffers from accumulated prediction errors and low computational efficiency. In this paper, we present a novel framework for 4D shape reconstruction from spatio-temporally sampled point clouds. Our approach focuses on improving computational efficiency, geometry accuracy, and temporal continuity. We achieve this by parallelly establishing dense correspondences among different time-step occupancy fields predicted from a spatio-temporal encoder. Our approach combines static implicit field learning with dynamic cross-frame correspondence predicting, enabling improved geometry reconstructions and accurate correspondences. To reduce convergence time in network training, we propose a strategy of simultaneously learning occupancy field transformations from the first time step to others, bypassing the expensive computation of solving ordinary differential equations. Additionally, our approach provides a significant speed-up in inference time through parallel isosurface deformations for different time steps. Our contributions include a learning framework for modeling the temporal evolution of the occupancy field, a strategy for establishing cross-frame shape correspondences, and a novel 4D point cloud encoder design that improves the robustness of reconstructed geometries. Extensive ablation studies validate the effectiveness of our proposed module designs, and comparisons against previous state-of-the-art methods on the D-FAUST dataset demonstrate the superior accuracy and efficiency of our approach in 4D shape auto-encoding and completion.