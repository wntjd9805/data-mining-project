This paper addresses the problem of estimating the relative pose between two cameras. This problem is important in various computer vision applications such as structure-from-motion, visual localization, and SLAM. The standard approach for relative pose estimation is to use the RANSAC algorithm, but recent variants like locally optimized RANSAC (LO-RANSAC) have shown improved accuracy and convergence.The LO-RANSAC variants apply a local optimization step to refine the best model using non-minimal samples, which helps in averaging out observational noise and speeding up the estimation process. Minimal solutions for relative pose estimation with different camera configurations have been well-studied, but the non-minimal case, also known as the N-point problem, is more challenging.The most commonly used non-minimal solver is the direct linear transformation (DLT) method, but it does not minimize the error in the 5D space of essential matrices for calibrated cameras. Several recent approaches attempt to directly minimize an energy function in the 5D space of relative poses, but they either do not guarantee global optimality or are computationally slow.The paper presents a novel real-time globally optimal solver that minimizes the algebraic error in the least squares sense for relative pose estimation. It assumes that the cameras share a common reference direction, reducing the relative rotation to 1 degree of freedom. The main contributions of the paper are (1) proposing an efficient solution to the system of two polynomials with two unknowns, (2) considering the linearized rotation for mobile robots and autonomous driving cars, and (3) demonstrating improvements in accuracy and speed compared to state-of-the-art solvers through real and synthetic experiments. Additionally, a novel dataset with image pairs and ground truth 3D reconstructions is presented.