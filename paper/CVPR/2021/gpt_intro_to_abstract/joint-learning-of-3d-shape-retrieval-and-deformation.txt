This paper introduces a joint learning approach for 3D shape synthesis, specifically focusing on the retrieval and deformation of 3D models. Existing methods either retrieve a mesh from a database or train a neural network to deform a source to a target, but fail to achieve high-quality results. This paper proposes a joint learning method where retrieval and deformation are treated as equal components. The goal is to learn how to retrieve a shape from a database and predict optimal deformation parameters for the best match to a given target. The proposed method includes a learnable deformation module that is optimized for fitting retrieved shapes to target shapes. The deformation function is designed to deform individual parts of the model while respecting the connectivity of the original structure. This approach accommodates varying numbers of parts and structural relationships without requiring manual labeling or consistent segmentations. The proposed method is evaluated using 2D image and 3D point cloud targets and outperforms various baselines. The experiments also demonstrate that the method works with imperfect and inconsistent segmentations and can be combined with different deformation modules. Overall, the joint learning approach improves the fidelity and detail of generated 3D models.