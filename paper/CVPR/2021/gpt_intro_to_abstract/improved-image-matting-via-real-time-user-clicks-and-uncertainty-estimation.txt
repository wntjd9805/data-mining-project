Image matting is a fundamental problem in computer vision that involves separating the foreground object from the background and estimating the opacity of each pixel near the boundary. This task is essential for applications such as image editing, film production, and virtual background for video conferencing. Traditional matting algorithms often rely on trimaps, which require users to manually define the foreground, background, and transition regions in the image. However, drawing a suitable trimap can be tedious and time-consuming, especially for non-professional users. Recent approaches using deep learning techniques have attempted to eliminate the need for trimaps but often struggle with ambiguity when multiple foreground objects are present or when processing images of unseen categories.To address these limitations, we propose a novel matting approach that combines the performance of trimap-based methods with the user-friendliness of trimap-free methods. Our method integrates user clicks as hints into a matting network, making it adaptable to any user input. During training, we simulate user clicks by adding random points into the foreground and background regions. Compared to trimap-based approaches, our method only requires a few user clicks to indicate foreground and background but achieves comparable performance. In cases without foreground ambiguity, it may not require any user clicks at all. Additionally, our method can easily extend to unseen categories by adding a few user clicks.Furthermore, we introduce an uncertainty estimation module and an uncertainty-guided local refinement network. This allows the network to predict areas that require further refinement and enables users to choose which local parts to improve based on their computation budget. Compared to existing methods that use an extra network for global refinement, our approach is more flexible and efficient as it avoids redundant computations for well-predicted regions. To the best of our knowledge, this is the first approach to introduce uncertainty in deep image matting.We conduct extensive experiments on synthetic and real datasets to demonstrate the effectiveness of our method. The results show superior performance compared to trimap-free approaches and comparable results to state-of-the-art trimap-based methods. Ablation analysis confirms the flexibility and adaptability of our approach to new categories unseen in the training set. Additionally, we provide a real-time user interactive system for better application.In summary, our contributions include introducing user click interaction into image matting, proposing an uncertainty estimation module, and developing an uncertainty-guided local refinement network. Experimental results demonstrate the effectiveness and flexibility of our method, making it a promising approach for image matting tasks.