This paper addresses the issue of catastrophic forgetting in deep-neural-network-based AI systems that learn incrementally over time. These systems often experience forgetting problems when updated with new data, resulting in the overriding of previously acquired knowledge. Additionally, the inability to replay all previous data further exacerbates this problem. To combat these issues, the authors propose the Code: https://class-il.mpi-inf.mpg.de/class-incremental learning (CIL) protocol, which introduces a memory constraint forcing the system to store only a small set of exemplars from old classes. However, this constraint leads to a data imbalance between old and new classes, presenting a stability-plasticity dilemma. Existing CIL approaches utilize various data strategies to address this dilemma but remain limited in effectiveness. To tackle these challenges, the authors present a novel network architecture called Adaptive Aggregation Networks (AANets) that explicitly maintains the knowledge of old classes while allowing for the learning of new ones. AANets achieve this through two residual blocks with different levels of learnability, with one block focusing on stability and the other on plasticity. By dynamically balancing the usage of these blocks using aggregation weights, AANets effectively address the stability-plasticity dilemma. The authors formulate the optimization of AANets as a bilevel optimization problem and conduct experiments on three CIL benchmarks to validate the effectiveness of their approach. The contributions of this paper include the AANets architecture, the bilevel optimization formulation, and extensive experiments comparing AANets with baseline methods.