A typical problem in machine learning is estimating a function Fθ that maps from a set of training examples {xi, yi} to a target variable y. The parameters of the function θ are often determined by minimizing a loss function. The choice of loss function can greatly affect the performance of the model. One widely used loss function is the Huber loss, which is quadratic for small residuals and linear for large residuals. Despite its popularity, selecting an appropriate transition point for the Huber loss can be challenging. In this paper, we propose a probabilistic interpretation of the Huber loss that assumes the observed target values yi are noisy estimates of the true values y∗i. We show that minimizing the Huber loss is equivalent to minimizing an upper-bound on the Kullback-Leibler (KL) divergence between the distributions of y∗i and q(y∗i|xi,θ), where q(y∗i|xi,θ) is a Laplace distribution with its scale determined by the transition point of the Huber loss. We argue that approximating the noise in the ground-truth values provides a more intuitive way to determine the transition point compared to reasoning about the Huber density. We present an analysis of the relationship between the optimal transition point of the Huber loss and the noise distribution using a toy problem and demonstrate how our interpretation can lead to better hyper-parameter selection. Additionally, we analyze the loss functions used by modern object detectors in light of our interpretation.