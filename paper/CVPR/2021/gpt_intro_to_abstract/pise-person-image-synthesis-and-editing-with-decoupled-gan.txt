Person image synthesis is a challenging problem in computer vision and computer graphics with applications in image editing, video generation, and virtual try-on. Specifically, human pose transfer, which involves synthesizing a new image of the same person in a target pose, is an active topic in person image synthesis. Generative Adversarial Networks (GANs) have achieved success in this area, with methods utilizing neural networks to learn the mapping from source image and pose to the target image. However, existing methods face challenges in predicting sharp and reasonable images when there are large pose differences between the source and target. To address this, flow-based methods estimate an appearance flow to obtain denser correspondences, warping the source image or its features to align with the target pose.While these methods preserve details of the source image, they struggle to recover the invisible regions due to occlusion. To tackle this, some methods introduce human parsing maps to provide semantic correspondence in the synthesis process. However, these methods fail to disentangle the shape and style information of the clothing and struggle to preserve spatial context relationships. To overcome these challenges, the authors propose a novel Decoupled GAN for person image synthesis and editing. Instead of directly learning the mapping, they use the human parsing map as an intermediate result to guide semantic guidance for predicting clothing shape. They also introduce per-region encoding and normalization to better control texture style in visible and invisible regions. To preserve spatial context relationships, they propose spatial-aware normalization. Experimental results demonstrate the flexibility and superior performance of their method in human pose transfer, texture transfer, and region editing.The contributions of this work include the two-stage model with per-region control for decoupling clothing shape and style, the joint global and local per-region encoding and normalization for predicting reasonable styles in invisible regions, and the spatial-aware normalization for preserving spatial context relationships. Overall, this paper presents a comprehensive approach for person image synthesis and editing, showing promising results in various applications.