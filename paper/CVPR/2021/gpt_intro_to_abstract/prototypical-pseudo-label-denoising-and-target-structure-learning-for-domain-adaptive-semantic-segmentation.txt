This paper addresses the problem of unsupervised domain adaptation (UDA) in semantic segmentation tasks. UDA is challenging because it involves transferring knowledge learned from synthetic images to real ones without accessible labels. Previous approaches for UDA have focused on aligning the distributions of the source and target domains, but they still lag behind supervised and semi-supervised learning.To improve UDA performance, this paper proposes two key contributions. First, it introduces the concept of prototypes, which are class-wise feature centroids, to rectify the pseudo labels generated in self-training. The network progressively corrects the pseudo labels throughout the training by estimating class-wise likelihoods based on the relative feature distances to the prototypes. This allows the network to focus on reliable knowledge in the target domain.Second, inspired by Deepcluster, the paper aligns soft prototypical assignments for different views of the same target to learn the intrinsic structure of the target domain. By drawing on the compact target feature space produced by this alignment, the proposed method, called ProDA, achieves superior performance compared to previous works.Furthermore, the paper explores the benefits of task-agnostic pretraining, where knowledge is distilled to a self-supervised pretrained model. This further improves the performance of ProDA, demonstrating its record-high effectiveness in UDA.Experimental results using the Deeplabv2 network show that ProDA outperforms state-of-the-art approaches in semantic segmentation. When adapting from the GTA5 and SYNTHIA datasets to the Cityscapes dataset, ProDA improves the adaptation gain by 52.6% and 58.5% respectively compared to the leading prior approach.