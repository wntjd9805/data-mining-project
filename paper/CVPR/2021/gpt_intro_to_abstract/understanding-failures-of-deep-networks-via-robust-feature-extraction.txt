Understanding the failure modes of machine learning (ML) systems is crucial in high-stakes applications. While aggregate metrics provide overall performance information, it is essential to delve into specific instances of failure in ML systems and components. This understanding guides the iterative process of model development and debugging. However, standard metrics like AUC or accuracy fail to capture the non-uniformity of model performance across different clusters of instances. This paper proposes a method called Barlow that leverages the internal representation of a robust model to generate metadata for identifying natural clusters with high failure rates. The method employs fault tree analysis techniques and visualization of robust representations to reveal two types of failures: spurious correlations and overemphasized features. Barlow assists practitioners by efficiently identifying failure modes and providing visualizations, enabling interventions for improvement. The contributions of this study include an error analysis framework, a feature extraction and visualization method, a crowdsourcing study to evaluate the visualization technique, and a user study with experienced engineers to evaluate the methodology for model debugging.