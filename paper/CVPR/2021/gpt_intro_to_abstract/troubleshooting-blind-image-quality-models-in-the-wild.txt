This paper discusses the importance of blind image quality assessment and the limitations of existing models in terms of generalization in the open visual world. The authors propose a troubleshooting approach for improving the generalizability of blind image quality assessment models. They introduce the concept of network pruning, which can effectively expose weaknesses in trained models by identifying samples that are not well learned or represented. The authors leverage network pruning to reveal superficial shortcuts in blind image quality assessment models and create ensembles of pruned models to compete with the target model in a maximum differentiation competition procedure. The authors then fine-tune the target and pruned models based on both human-rated images and previously trained data to enable learning from failures. The proposed method is the first of its kind to troubleshoot blind image quality assessment models in real-world scenarios, and the results show improved performance and resistance in the maximum differentiation competition. The code for the proposed method is publicly available for reference.