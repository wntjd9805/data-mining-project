Deep models have made significant advancements in computer vision and other fields. Language-queried video actor segmentation is a novel task that aims to predict pixel-level masks for actors performing specific actions in a video based on a natural language query. This task requires fine-grained spatial-temporal modeling and visual-linguistic interaction, making it more challenging than previous language-queried video localization tasks. This task has applications in language-driven video editing, intelligent surveillance video processing, and human-robot interaction.To tackle this task, both temporal modeling over the video clip and spatial modeling over the target frame are crucial. Spatial modeling alone cannot accurately identify the correct actor due to the presence of similar-looking actors, leading to false-positive predictions. Temporal modeling is needed to recognize the queried action and distinguish it from other similar actions. However, existing approaches only focus on temporal modeling, leading to inaccurate segmentation. This paper proposes a collaborative spatial-temporal framework with two encoders - a temporal encoder and a spatial encoder. The temporal encoder uses a 3D CNN to identify the actor performing the queried action, while the spatial encoder uses a 2D CNN to extract precise spatial features of the target frame. These features are effectively integrated using a Language-Guided Feature Selection (LGFS) module in the decoder that generates flexible channel selection weights based on the linguistic feature. Additionally, a Cross-Modal Adaptive Modulation (CMAM) module dynamically recombines linguistic features and visual features to highlight spatial or temporal relevant information.The contributions of this paper include the proposed collaborative spatial-temporal framework, the LGFS module for feature integration, and the CMAM module for multimodal interaction. Extensive experiments on popular benchmarks show that the proposed method outperforms previous state-of-the-art approaches with significantly less computational overhead.