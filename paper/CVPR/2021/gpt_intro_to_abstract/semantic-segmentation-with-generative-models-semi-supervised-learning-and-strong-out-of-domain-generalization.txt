Deep learning has become a dominant force in computer vision applications, such as autonomous driving, medical imaging, and image editing. However, deep neural networks require large-scale datasets for training and struggle to generalize to out-of-distribution data. This issue is particularly challenging in tasks like semantic segmentation, where pixel-level annotations are time-consuming and expensive to obtain. In this paper, we aim to reduce the amount of training data needed while achieving strong out-of-domain generalization.Semi-supervised learning (SSL) is a technique that leverages both labeled and unlabeled data to improve model performance. Various SSL approaches, including pseudo-labeling, consistency regularization, and data augmentation, have been proposed. Contrastive learning has emerged as a leading SSL technique, focusing on training powerful feature extractors using unsupervised contrastive losses.While SSL has been extensively explored for classification tasks, its application to pixel-wise tasks like semantic segmentation is relatively new. However, traditional SSL techniques often overlook the distribution of input data and can still overfit to the training data, limiting their generalization capabilities, particularly in tasks with limited labeled data.To address this issue, we propose a fully generative approach based on a generative adversarial network (GAN) that models the joint image-label distribution and synthesizes images and their semantic segmentation masks. Our model builds upon the StyleGAN2 architecture and incorporates a label generation branch. By training on a large unlabeled image collection and a small labeled subset with adversarial objectives, we achieve competitive or better performance in the medical and human face domains while demonstrating significantly higher generalization ability in out-of-domain tests.In summary, our contributions include a novel generative model for semantic segmentation that allows for semi-supervised training and explicitly models the joint image-label distribution. We extensively validate our model in the medical and face image domains, showing results that match or surpass competitive baselines in the semi-supervised setting and exhibit strong generalization capabilities. Additionally, we demonstrate the model's ability to perform well on extreme out-of-domain examples.