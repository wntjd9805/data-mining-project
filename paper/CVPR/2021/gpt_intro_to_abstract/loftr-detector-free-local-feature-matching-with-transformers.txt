Local feature matching is a crucial task in 3D computer vision applications such as structure from motion (SfM), simultaneous localization and mapping (SLAM), and visual localization. Existing methods typically consist of three phases: feature detection, feature description, and feature matching. However, feature detectors can fail to extract enough interest points that are repeatable between images due to factors like poor texture, repetitive patterns, viewpoint change, illumination variation, and motion blur.Recent works have attempted to address this issue through pixel-wise dense matches, but these methods have limited receptive fields that may not distinguish indistinctive regions. Humans, on the other hand, rely on a larger global context to find correspondences in such regions. This observation highlights the importance of a large receptive field in feature extraction.Motivated by this, we propose LoFTR (Local Feature TRansformer), a detector-free approach to local feature matching. Inspired by SuperGlue, we employ Transformer with self and cross attention layers to transform dense local features extracted from the convolutional backbone. We extract dense matches between the transformed features, select matches with high confidence, and refine them to a sub-pixel level. The global receptive field and positional encoding of Transformer enable context- and position-dependent feature representations. By interleaving self and cross attention layers, LoFTR learns densely-arranged globally-consented matching priors. A linear transformer is also used to reduce computational complexity.We evaluate LoFTR on various image matching and camera pose estimation tasks with indoor and outdoor datasets. The experiments demonstrate that LoFTR outperforms both detector-based and detector-free feature matching baselines. It achieves state-of-the-art performance and ranks first on two public benchmarks of visual localization. Compared to detector-based methods, LoFTR excels in indistinctive regions with low-textures, motion blur, or repetitive patterns.