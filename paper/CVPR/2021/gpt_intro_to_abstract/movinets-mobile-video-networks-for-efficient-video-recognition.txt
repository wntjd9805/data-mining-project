Efficient video recognition models are in high demand for mobile camera, IoT, and self-driving applications. However, finding models that are both efficient and accurate for on-device processing is challenging. While 3D convolutional neural networks (CNNs) offer state-of-the-art accuracy, they consume a lot of memory and computation. On the other hand, 2D CNNs are more suitable for mobile devices but lack accuracy. This paper introduces Mobile Video Networks (MoViNets), a family of memory and computation efficient 3D CNNs, to address these challenges. Three steps are taken: (1) defining a MoViNet search space to efficiently trade-off spatiotemporal feature representations, (2) introducing stream buffers to reduce memory usage and enable online inference while maintaining long temporal dependencies, and (3) creating temporal ensembles of streaming MoViNets to regain the slight loss in accuracy introduced by the stream buffers. These techniques result in MoViNets that are accurate, memory-efficient, computationally efficient, and support online inference. Extensive testing is done on various datasets to validate the effectiveness of MoViNets.