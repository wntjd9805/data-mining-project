This paper addresses the joint optimization of video downscaling and upscaling, known as video rescaling. The goal is to optimize the reconstruction quality of high-resolution (HR) videos while providing comparable visual quality to the downscaled videos for human perception. Existing solutions for video rescaling involve independent operations of downscaling and upscaling, resulting in a loss of high-frequency information and an ill-posed reconstruction problem. Jointly optimizing downscaling and upscaling has been proposed for image rescaling, but the approaches are not suitable for video rescaling as they do not consider temporal information. This paper presents two joint optimization approaches for video rescaling: LSTM-VRN and MIMO-VRN. LSTM-VRN uses a coupling architecture combined with a Long Short-Term Memory (LSTM) network to estimate the missing high-frequency component for upscaling. MIMO-VRN introduces a new paradigm by simultaneously downscaling and upscaling multiple HR video frames, utilizing a group-of-frames-based coupling architecture. Both approaches outperform existing image-based solutions and achieve state-of-the-art performance in video rescaling.