High-speed imaging is crucial for capturing fast-changing processes in various fields such as physics experiments, chemical reactions, and sports events. Traditional digital cameras, with their constant shutter speed, often result in motion blur and a loss of visual information. High-speed cameras, on the other hand, can capture images at significantly higher time sampling frequencies, but they require expensive specialized sensors and consume enormous amounts of memory.Neuromorphic vision sensors, inspired by the biological mechanisms of the retina, have gained attention for their bio-inspired visual recording capabilities. These sensors, such as dynamic vision sensors (DVS) or event cameras, generate asynchronous binary outputs for each pixel based on changes in scene radiance. Event cameras offer advantages over traditional frame cameras, including low-latency, sparse output, low power consumption, and high dynamic range. However, they struggle with reconstructing textures in static scenes due to the loss of visual information.To address this limitation, spiking cameras, inspired by the primate fovea's sampling mechanism, have been developed. Each pixel in a spiking camera continuously captures photons and generates spikes when the accumulated intensity reaches a threshold. This allows the camera to retain high-speed spatio-temporal information for both moving and static objects, making it suitable for scene reconstruction.Existing scene reconstruction methods for event cameras rely on estimating the firing frequency of each pixel, but they often suffer from motion blur, low image contrast, and complex optimization algorithms. Additionally, these methods require a predefined time window, hindering real-time reconstruction.This paper presents a new approach to high-speed image reconstruction using the short-term plasticity (STP) mechanism of the brain. By leveraging spiking neural networks with STP and the output spiking streams as input, the relationship between the time-varying firing frequency of each pixel and the dynamics of the postsynaptic neuron is derived. This allows for the inference of scene radiance and pixel values in the reconstructed images. Furthermore, a motion extraction method with STP is introduced to enhance the reconstruction results, ensuring high image quality and low latency.Experimental results demonstrate that the proposed methods can reconstruct high-speed motion scenes in real-time with superior image quality compared to existing approaches. The contributions of this paper include the proposal of bio-inspired image reconstruction methods that estimate each pixel's firing frequency without using time windows, as well as a novel motion extraction method based on STP dynamics. These methods leverage the low latency of spiking cameras to achieve high-speed image reconstruction.