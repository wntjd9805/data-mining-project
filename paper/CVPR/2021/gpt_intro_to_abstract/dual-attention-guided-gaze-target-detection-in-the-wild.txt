Gaze cues are important for evaluating intentions and predicting human behaviors. Gaze analysis has been widely used in neurophysiology studies, saliency prediction, and social awareness tracking. However, most existing works require specialized equipment or settings. In this paper, we focus on gaze target detection from a single image in daily life. Our goal is to predict where people are looking, including out-of-frame targets and inside-frame targets. Existing methods reason about salient objects in the scene based on gaze orientation, but they fail to capture depth-channel gaze information and lack scene depth understanding. They also struggle with fixation inconsistency between the eyes and the head. To address these problems, we propose a three-stage scheme that simulates human gaze inference behavior in 3D space. We introduce a Dual Attention Module (DAM) to model depth-aware perspective in the scene. We also employ a coarse-to-fine strategy to estimate 3D gaze orientation. Our method achieves accurate detection results and outperforms state-of-the-art methods on benchmark datasets. Our contributions include the design of DAM, the development of a coarse-to-fine strategy for 3D gaze estimation, and the demonstration of superior performance compared to existing methods.