Deep learning based object detection has shown significant advancements in outperforming traditional approaches. However, these methods heavily rely on large amounts of labeled training data, which can be time-consuming and labor-intensive to annotate. This paper focuses on Few-Shot Object Detection (FSOD), where the object detector is trained to detect novel classes with limited samples, leveraging data from base classes. Existing FSOD approaches are primarily built on Faster-RCNN and have shown promise but still struggle to achieve satisfactory performance on challenging benchmarks like MS-COCO. This paper aims to understand the major causes of performance degradation in novel classes and addresses the limitations of the classification branch in FSOD. The paper introduces a novel Few-Shot Classification Refinement mechanism that enhances the original classification results by injecting additional category-discriminative information. The proposed framework consists of an IOU-aware classification branch and a discriminability enhancement branch, which separately focus on objectness estimation and alleviating category confusion. To preserve classification-preferred translation-invariant features, the enhancement branch is designed as a decoupled classifier called Few-Shot Correction Network (FSCN). Additionally, the paper addresses the issue of distractor samples, where unlabelled novel-class objects in the base set introduce destructive noise during the few-shot adaptation process. The paper proposes strategies to filter out distractors and utilizes them in a semi-supervised manner to improve detection performance. The proposed FSOD framework achieves state-of-the-art results with remarkable few-shot performance and knowledge retention ability in various datasets.