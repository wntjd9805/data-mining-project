Introduction:Deep learning models often struggle to generalize well in real-world applications due to domain-shift, which refers to the difference in distributions between training and test data. Unsupervised Domain Adaptation (UDA) has emerged as a research area focused on leveraging source data to create robust predictors for target domains. Initially, UDA methods primarily targeted single source to single target domain adaptation (STDA). However, with the increasing availability of unlabeled data, the need for adapting to multiple target domains has become more prevalent. This has led to the emergence of Multi-target Domain Adaptation (MTDA) as a more practical scenario. MTDA aims to learn compact representations that perform well across all target domains. Applying STDA methods directly to MTDA can be suboptimal due to multiple domain-shifts, leading to negative transfer. In this paper, we present a framework for MTDA that focuses on feature aggregation and curriculum learning. We propose representing source and target samples as a graph and leveraging Graph Convolutional Networks (GCN) to aggregate semantic information across domains. Additionally, we introduce a co-teaching framework with two classifiers - a MLP classifier and a GCN classifier - to provide pseudo-labels to each other. We argue that learning robust features in a unified space is essential for achieving minimum risk across multiple target domains. To address the challenge of noisy pseudo-labels, we propose obtaining pseudo-labels episodically and employing curriculum learning. We introduce Curriculum Graph Co-Teaching (CGCT) that combines co-teaching and curriculum learning, as well as Domain-aware Curriculum Learning (DCL) to make the feature alignment process smoother. Our frameworks outperform state-of-the-art methods on UDA benchmarks, including a significant improvement of +5.6% on the DomainNet dataset.