This paper addresses the limitations of previous reporting practices in membership inference (MI) attacks on deep learning models. While many papers report accuracy, precision, and recall, they often fail to provide important information such as train and test accuracy of the target victim models, which are useful for evaluating the generalization gap. Furthermore, the reporting of MI attacks usually overlooks the performance on negative samples, particularly the false positive rate (FAR). The authors show that the common metrics do not accurately reflect how MI attacks perform in practice and can be misleading. The paper provides a comprehensive evaluation of MI attacks on deep learning models, highlighting the difficulty of achieving a reliable attack with high accuracy and low FAR. The authors also analyze different types of information available from the target models, but find that deep models often behave similarly on train and non-train samples across these metrics. The paper concludes that membership inference of correctly classified samples, which make up the majority of training samples, is a challenging task. The authors call for further research and caution against generalizing the results to all scenarios.