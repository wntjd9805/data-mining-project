Abstract:This paper presents a novel approach called "heterogeneous grid convolution" for adaptive and efficient feature representation in image understanding tasks. The existing regular grid feature representation lacks adaptability and contains redundant information. To address this, our method allocates node features adaptively based on information density, reducing redundant computations and enabling focus on regions of interest. We propose a differentiable clustering-based graph pooling and a direction-aware extension of graph convolution to tackle the technical challenges of adaptive node allocation and convolution on a heterogeneous grid structure. Our resulting neural model, named heterogeneous grid convolution, can be seamlessly integrated into existing CNN architectures. We evaluate our approach on four image understanding tasks and demonstrate its effectiveness in semantic segmentation, object localization, road extraction, and salient object detection. The proposed HG-CNNs outperform strong baselines with significantly fewer floating-point operations, achieving state-of-the-art results in road extraction and salient object detection. While the computational efficiency of our approach may not be superior on current neural processors, it opens up new research possibilities and potential impacts in specialized hardware for embedded devices. Code and data are made available for further research.