Person re-identification (ReID) is a critical task in intelligent video surveillance systems, aiming to match individuals across different camera views. Existing ReID methods primarily focus on visible image-based cross-view matching tasks, which do not perform well in scenarios with illumination variations. To address this challenge, the field of RGB-IR ReID, which involves matching RGB and infrared pedestrian images captured by dual-mode cameras, has gained significant attention. However, RGB-IR ReID faces difficulties due to visual discrepancies between visible and infrared images, making it challenging to align images of the same identity. Previous approaches have attempted to minimize the modality gap through cross-modality image synthesis or shared feature learning. In this paper, we propose an automated machine learning (AutoML)-powered approach called Neural Feature Search (NFS) for RGB-IR ReID. NFS formulates feature selection as a bilevel optimization problem and introduces a novel feature search space that allows for both pixel and channel-level feature selection. Additionally, a cross-modality contrastive optimization scheme is introduced to tackle modality discrepancies. Experimental results on two benchmark datasets demonstrate the effectiveness of NFS compared to state-of-the-art methods. This paper contributes by introducing an AutoML-powered feature selection approach for RGB-IR ReID, proposing a novel search space for feature selection, and demonstrating the superior performance of NFS in comparison to previous methods.