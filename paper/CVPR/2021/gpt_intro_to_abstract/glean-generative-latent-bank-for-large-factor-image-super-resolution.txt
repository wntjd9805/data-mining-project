This study explores a new approach for image super-resolution using Generative Adversarial Networks (GANs). The focus is on high magnification factors (8× to 64×), where traditional super-resolution methods struggle due to loss of details and textures during downsampling. Informative priors are necessary in this setting to restore textural details. The use of GANs in super-resolution has two main approaches: training a generator to upscale images and using GAN inversion to map images back to the latent space. However, both methods have limitations, including artifacts, unnatural textures, and low fidelity. This study proposes leveraging pre-trained GANs, such as StyleGAN, to provide diverse priors for the task. Unlike other GAN inversion methods, this approach does not require image-specific optimization at runtime, making it more practical for real-time applications. The proposed method utilizes a novel encoder-bank-decoder architecture, where the pre-trained GAN acts as a latent bank. By conditioning and retrieving from this latent bank, the burden of learning both fidelity and texture generation simultaneously is alleviated. Additionally, passing multi-resolution cues between the encoder, bank, and decoder further improves the results. The effectiveness of the proposed method is demonstrated in handling challenging pose and structure variations, as well as different image categories, by switching pre-trained GAN latent banks.