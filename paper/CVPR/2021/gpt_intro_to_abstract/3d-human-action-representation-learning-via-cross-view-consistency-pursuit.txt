Human action recognition is a challenging task in computer vision research. With the popularity of 3D skeleton as a feature representation for studying action dynamics, fully-supervised methods have been used in many action recognition works, but they require large amounts of labeled 3D skeleton data, which is expensive and time-consuming to annotate. This has led researchers to explore unsupervised methods on skeleton data. However, existing unsupervised methods have limitations in their approach. Traditional contrastive learning methods consider similar samples as negative pairs, which can lead to unreasonable clustering. Additionally, these methods have not fully utilized the rich intra-supervision information provided by different skeleton modalities. To address these limitations, this paper proposes a Cross-view Contrastive Learning framework for Skeleton-based action Representation (CrosSCLR), which leverages multi-view information to mine positive samples and pursue cross-view consistency in unsupervised contrastive learning. CrosSCLR first applies parallel Contrastive Learning to each single-view Skeleton action Representation (SkeletonCLR) to obtain multiple single-view embedding features. Then, a Cross-View Consistent Knowledge Mining (CVC-KM) module is developed to assess the similarity of samples and select the most similar pairs as positive ones, boosting the positive set in complementary views. This process promotes information sharing among views and leads to the extraction of more comprehensive cross-view features. The proposed CrosSCLR framework is evaluated on 3D skeleton datasets, such as NTU-RGB+D 60/120, and achieves remarkable results in unsupervised settings.