With the rapid increase in video content, there is a growing need for efficient and scalable action recognition in videos. Deep neural networks have shown impressive performance in this area, but their high data volumes, compute demands, and latency requirements make them challenging to implement on resource-constrained devices. To address this issue, researchers have been designing efficient and lightweight architectures that treat all videos equally, regardless of their complexity. However, current methods for frame selection and computation adjustment either rely on assumptions about saliency or require carefully selected reward functions. In this paper, we propose FrameExit, a conditional early exiting framework for efficient video recognition. This framework uses a cascade of gating modules to determine when to stop further processing of the video, thus reducing computational costs. The gates learn to adapt the amount of computation based on the difficulty of the input video. We also introduce a simple, deterministic frame sampling strategy and an accumulated feature pooling module to improve recognition performance. Our method outperforms existing approaches and achieves state-of-the-art performance on three large-scale datasets. We demonstrate a significant reduction in computation costs while maintaining or improving recognition accuracy. Specifically, on the HVU dataset, we report a 5Ã— reduction in computation costs compared to state-of-the-art methods.