3D reconstruction from multi-view images is a fundamental problem in computer vision. Traditional methods, such as SFM, rely on distinctive view-independent features to establish correspondences and reconstruct objects or scenes. However, these methods fail when dealing with real-world objects or surfaces that lack distinctive features or exhibit non-Lambertian reflectance. Moreover, if the surface reflectance is unknown, it becomes even more challenging to model the object's appearance changes with different viewpoints. To address these challenges, previous works have combined photometric stereo with multi-view methods, but they often depend on external initialization and require a large number of input images. Additionally, they make restrictive assumptions about the setup, objects, or scenes. Direct multi-view reconstruction of textureless, glossy objects remains an open challenge.In this paper, we propose a simple and practical solution to jointly recover high-fidelity surface geometry and unknown generic reflectance of purely texture-less objects. We introduce a co-located camera and light-source configuration, easily accessible with commodity hardware. Unlike existing methods, we allow the camera to freely move and leverage multi-view constraints. We do not rely on explicit cross-view correspondences or shape initialization, which are challenging for texture-less surfaces with arbitrary BRDF. Instead, we utilize a physically-based image formation model to constrain shape and reflectance estimation, formulating the reconstruction as an energy minimization problem. We propose an effective optimization-based approach that robustly reconstructs complex geometry and general reflectance without initial shape information.The code and data for our method will be made available at https://github.com/za-cheng/PM-PMVS/.