High-quality image inpainting involves filling in missing regions with synthetic content, requiring semantically meaningful structures and visually pleasing textures. Deep learning-based methods have been used, but they often struggle with complex holes involving multiple sub-regions with different semantic classes. This is due to the difficulty in modeling the prior distributions of a mixture of semantic regions, resulting in blurry boundaries and unrealistic textures. To address this, we propose a two-step approach that utilizes structural information, such as edges and contours, as guidance for completing missing structures and textures. However, the correspondence between structural information and textures is not always clear, leading to filled textures that rely heavily on local correlation. We argue that high-level semantic information can provide more vital clues for inferring object textures and propose to use coherence priors between semantics and textures in our inpainting method. We introduce a framework that extracts a shared feature to optimize semantic segmentation and image inpainting jointly, utilizing a Semantic-Wise Attention Propagation (SWAP) module to capture semantic relevance and loss terms to supervise coherence relationships. Our approach outperforms existing state-of-the-art methods in completing complex holes with multiple semantic regions, achieving sharper boundaries and more coherent and visually plausible textures.