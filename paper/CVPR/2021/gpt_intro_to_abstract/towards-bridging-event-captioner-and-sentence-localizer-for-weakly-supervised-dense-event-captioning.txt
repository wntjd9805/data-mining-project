In recent years, there has been extensive research on conventional video captioning, which involves generating a single sentence description for a trimmed video. However, natural videos often contain multiple events, prompting the introduction of the Dense Event Captioning (DEC) task. DEC aims to generate multiple event descriptions localized in time for untrimmed videos. While some methods rely on temporal boundary annotations, Weakly Supervised Dense Event Captioning (WS-DEC) poses a more challenging scenario without this additional information. Existing WS-DEC methods use an iterative approach, where the event captioner and sentence localizer communicate through input-output connections and the optimization of reconstruction losses. In this paper, we propose a new WS-DEC method that introduces additional information communication between these subtasks to bridge them more closely. Our method utilizes a multiple instance concept learner for sentence localization, enabling alignment with sentence features at a frame-to-word level. The localizer provides word importances and concept features to guide caption generation and enhance video features. Our proposed method, abbreviated as EC-SL, allows for the integration of temporal localization and event description in untrimmed videos without temporal boundary annotations. This paper's main contribution lies in exploring an effective information communication pathway to unify the localization and description subtasks, a problem not extensively investigated in literature.