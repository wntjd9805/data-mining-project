Recently, computer vision researchers have shown a growing interest in using deep learning models for understanding 3D data. These models have been successfully applied to tasks such as object shape reconstruction, shape and pose estimation, point cloud completion, and brain cortical surface reconstruction. A common component of these models is the computation of distances between predicted and ground-truth meshes, either for loss computation during training or for evaluation purposes. The mainstream approach involves sampling point clouds from meshes to compute point-based distances like the Chamfer distance or earth mover's distance. While there has been extensive discussion on these distance metrics, the mesh sampling technique itself has received less attention, and the widely adopted uniform sampling approach produces inaccuracies and artifacts in the resulting point cloud. This paper addresses this problem by proposing a novel algorithm, called MongeNet, for sampling point clouds from triangular meshes. The algorithm formulates the problem as an optimal transport problem and employs a neural network to efficiently predict the optimal solution. The proposed approach provides a better representation of the underlying mesh, resulting in more accurate approximation and reduced artifacts. Experimental evaluations demonstrate the superiority of the proposed sampling technique compared to existing methods, particularly in approximating triangles with fewer sampled points. Additionally, MongeNet is shown to be useful for 3D deep learning tasks as a mesh approximator using the Point2Mesh model. The proposed approach outperforms the uniform mesh sampling technique in terms of robustness, reliability, and approximation accuracy, as evidenced by a significant reduction in approximation error on the ShapeNet dataset.