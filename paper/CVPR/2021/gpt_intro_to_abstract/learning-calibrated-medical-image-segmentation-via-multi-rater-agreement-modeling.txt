Accurate segmentation of anatomy and lesions is essential in clinical assessment for various diseases. In recent years, automated segmentation systems have been developed using deep convolutional neural networks (CNNs) to provide reliable references for disease progression quantification. However, medical images are often independently annotated by multiple experts or raters, leading to inter-observer variability and challenges in segmenting uncertain regions. Existing approaches typically use unique ground-truth annotations or label fusion strategies, which may ignore the underlying uncertainty information among multiple raters. This paper proposes a multi-rater agreement modeling framework, called MR-Net, to address this issue. MR-Net introduces the notion of expertise levels of the raters and incorporates it into the network architecture. It also uses a multi-rater reconstruction module to estimate an uncertainty map reflecting inter-rater variability. Additionally, a multi-rater perception module is incorporated to further utilize the rich cues from multi-rater disagreements. Extensive experiments on various medical imaging tasks show that MR-Net consistently outperforms state-of-the-art methods and existing multi-rater strategies. Moreover, MR-Net achieves real-time performance at the inference stage, making it practical for real-world applications.