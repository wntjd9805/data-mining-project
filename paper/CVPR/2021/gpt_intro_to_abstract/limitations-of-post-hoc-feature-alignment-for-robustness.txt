A foundational assumption in machine learning is that the training distribution is the same as the test distribution. However, this assumption is often violated in practice, leading to decreased model performance. Unsupervised Domain Adaptation (UDA) is a process that aims to improve robustness by utilizing unlabeled test data to adapt the model to the new distribution. One common approach in UDA is feature alignment, which involves aligning the feature activations between the source and target distributions. This alignment can be achieved through various methods, such as normalizing the features or making them indistinguishable to an adversarial discriminator. This paper focuses on a specific feature alignment method called Adaptive Batch Normalization (AdaBN). AdaBN is a normalization-based method that matches the first and second order statistics of the feature distributions. It is a post-hoc method, meaning it aligns features for an already trained model, making it simple and applicable for unforeseen distribution shifts. AdaBN achieves this alignment by re-estimating the Batch Normalization (BN) statistics of the model using target data, aligning the mean and variance of each channel in the network.Recent work has shown that aligning batch norm statistics between train and test distributions can lead to state-of-the-art accuracy on the robustness benchmark ImageNet-C. However, the reasons behind the effectiveness of this method on ImageNet-C and its limited effectiveness on other distribution shifts have not been adequately explained. This paper seeks to investigate when and why methods like AdaBN help with robustness. The findings include the discovery that aligning BN statistics can actually degrade accuracy on certain distribution shifts, the identification of implicit symmetry assumptions made by these methods, and the demonstration of how aligning BN statistics primarily helps with distribution shifts involving changes in local image statistics.These findings have several implications. While aligning BN statistics is effective in some settings, it only significantly helps with a narrow set of distribution shifts and can even degrade performance in other cases. The limitations of this method may hinder its practical usefulness. Additionally, existing justifications for feature alignment are insufficient in explaining the conditions under which these methods work. Future research in UDA should focus on explicitly identifying the relevant properties of data distributions and neural networks. Furthermore, the efficacy of UDA in improving the robustness of machine learning systems is in question, calling for more work to make UDA practical in this regard.