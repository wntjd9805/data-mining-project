Recently, deep neural networks have shown remarkable performance in computer vision tasks, largely due to the availability of high-quality datasets. However, in real-world scenarios, obtaining a large amount of high-quality data is often challenging and costly. Few-shot learning (FSL) methods have been proposed to address this issue, by reducing the dependence on data. These methods aim to train models with only a few labeled examples for each class. While FSL methods have been successful in closed-set problems, where training and testing samples share the same class pool, they are limited in their ability to handle open-set recognition tasks, where unseen class samples need to be identified. In this paper, we introduce the concept of few-shot open-set recognition (FSOSR) and propose a novel method called SnaTCHer for detecting unseen class samples. Our method leverages transformation consistency to distinguish unseen samples from seen samples without requiring additional pseudo-unseen data. We evaluate our method on various benchmarks and demonstrate its superior performance in unseen sample detection without compromising classification accuracy. Additionally, we highlight the limitations of pseudo-unseen class sample-based methods for FSOSR tasks. Our work contributes to the field by addressing the challenges of few-shot learning in open-set scenarios and providing a more effective approach for detecting unseen class samples.