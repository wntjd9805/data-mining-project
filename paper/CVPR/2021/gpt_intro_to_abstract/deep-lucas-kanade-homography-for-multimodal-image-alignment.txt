This paper addresses the problem of pixel-wise alignment of multimodal image pairs in various computer vision applications, such as medical imaging, remote sensing, and robotics. The alignment of these images is challenging due to differences in color representations and appearance changes. The proposed solution is a generic pipeline that extends the traditional Lucas-Kanade (LK) algorithm with neural networks. The key component of this pipeline is the extraction of a feature map called the deep Lucas-Kanade feature map (DLKFM), which is able to recognize invariant features in different multimodal cases. The DLKFM helps the LK algorithm converge successfully by shaping the landscape of the objective function. The paper also discusses the use of homography or perspective transform as a general 2D image transformation and the challenge of aligning 2D images in 3D computer vision. The traditional feature-based methods and direct methods, such as the Lucas-Kanade algorithm, are explored as potential solutions. However, both methods face limitations in handling multimodal images and achieving accurate alignment. To overcome these limitations, the paper introduces a feature constructor based on classical feature extractors and a special loss function that ensures brightness consistency and aids in the convergence of the Lucas-Kanade algorithm. The paper concludes with the contributions of the proposed method, including a generic pipeline for aligning multimodal images and two specific technologies: the feature constructor on multi-channel tensors and the special loss function for the convergence of Lucas-Kanade. The effectiveness of these contributions is demonstrated through an ablation study.