Face forgery detection is an important task in computer vision, but improving performance is challenging due to the lack of high-quality Deepfake data. This paper focuses on improving face-swapping methods to help develop more powerful forgery detection algorithms. Previous works have made significant contributions in this area by introducing GAN-based methods and addressing the occlusion problem. However, disentangling the identity and perception in face swapping remains a challenge. Existing works attempt to constrain the identity and perception of generated faces, but without explicit supervision, learning well-disentangled representations is difficult. In this paper, the authors propose a novel information disentanglement network called InfoSwap to improve disentangled representation learning in subject-agnostic face swap. The main idea is to learn the optimal representations for both identity and identity-irrelevant perceptual information from the latent features of a pre-trained model. By modeling the learning process as an optimization problem of the Information Bottleneck trade-off, the authors provide explicit supervision for disentangled representation learning. They also introduce an Identity Contrastive Loss as additional regularization to further facilitate representation disentangling. Experimental results show that InfoSwap can generate more identity-discriminative swapped faces with higher fidelity. The contributions of this paper include adopting the Information Bottleneck principle for disentangled representation learning, extending the objectives with an identity contrastive loss, providing a novel metric for evaluating the discriminative identity, and demonstrating the robustness and effectiveness of the proposed method through extensive experiments. Overall, this work addresses the need for better face-swapping methods to improve forgery detection algorithms.