Neuromorphic events are a new type of visual signals that offer advantages such as low power consumption, low latency, and high dynamic range. These events are captured by sensors that compare current and previous intensity states and generate binary-signed events when the intensity variation exceeds a threshold. However, event cameras have limitations in capturing static scenes and produce spatio-temporal point clouds instead of 2D image sequences. The restoration and enhancement of event signals require modifications from traditional image-based approaches. Previous research has focused on event-to-image reconstruction and demonstrated that image-based algorithms perform well on reconstructed event images. Some studies have explored the use of events in low-level vision tasks, such as HDR imaging, video synthesis, motion deblur, and super resolution. However, these approaches require heavy computational power and time for event-to-image conversion. State-of-the-art solutions for event restoration and enhancement rely on intensity signals and exhibit limitations in capturing missed events and achieving high-quality results. In this paper, we propose EventZoom, an end-to-end neural network approach for event denoising and super resolution. EventZoom utilizes a 3D U-Net as a backbone for event-to-event transformation and incorporates an event-to-image module to leverage image signals. We contribute by introducing EventZoom as the first network approach to solve event denoising and super resolution, developing a multi-resolution event dataset, and demonstrating the performance improvement achieved by EventZoom in event-based visual object tracking and image reconstruction.