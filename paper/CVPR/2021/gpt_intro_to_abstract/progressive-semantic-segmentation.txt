This paper introduces a novel multi-scale segmentation and refinement framework called MagNet. The current state-of-the-art semantic image segmentation techniques are based on deep learning, but they struggle to handle high-resolution input images due to memory and computational constraints. Downsampling and patch processing approaches have limitations in terms of losing fine details and lacking global context. The Global-Local Network (GLNet) successfully combines global and local segmentation processes, but it struggles with ultra-high resolution images. To address this, MagNet proposes considering multiple scales in between and using a refinement module to progressively refine the output segmentation map. This framework integrates global contextual cues and can output high-resolution detailed segmentation maps while operating under memory constraints. Experimental results demonstrate the effectiveness of MagNet compared to other segmentation methods.