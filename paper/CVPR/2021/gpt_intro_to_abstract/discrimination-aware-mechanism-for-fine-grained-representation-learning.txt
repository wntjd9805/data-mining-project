Fine-grained recognition aims to distinguish between subclasses within a superclass dataset, such as birds, persons, and cars. However, there are limited cues that can effectively differentiate between different classes within a superclass. Additionally, images captured at different times and places may exhibit visual differences within the same subclass. This makes fine-grained recognition extremely challenging. Recent research has focused on retrieving examples of specific subclasses from a superclass database to address this issue.In current representation learning methods, three main directions have been explored: (1) designing powerful loss functions to extract robust feature embeddings, such as proxy-based loss and pair-based loss; (2) constructing attention modules to resolve local regions; and (3) randomly erasing parameters or feature values during training for better generalization performance. These methods leverage powerful deep networks and large-scale labeled benchmarks to obtain relevant feature representations for images.Despite significant progress in fine-grained recognition, most existing methods optimize the overall discriminativeness of the entire feature space to distinguish it from other classes. However, in fine-grained recognition scenarios, the inter-class differences are often subtle and diverse. Traditional optimization mechanisms may focus only on major discriminative cues and ignore these subtle ones, leading to a less generalizable feature extractor. To address this limitation, we propose a Discrimination-Aware Mechanism (DAM) that iteratively learns more discriminative feature elements.DAM encourages the model to keep learning by mapping low-discriminative features to a harder space and then optimizing the new features. Specifically, by leveraging differences between specific inter-classes, we retain elements of features with fewer differences to other classes and erase the rest for the harder features. In DAM feature space, inter-class samples are pushed closer together, and intra-class samples are pushed further apart, thus increasing the discriminativeness of the overall feature representation. We achieve this by selectively retaining feature elements based on the difference of their values between different classes.The main contributions of our work are as follows: (1) We propose a discrimination-aware mechanism that extracts more discriminative visual cues without modifying the network architecture. (2) We design two feature mapping mechanisms for proxy-based loss and pair-based loss, selectively retaining low-discriminative elements for each feature. (3) We achieve better performance on fine-grained recognition tasks compared to state-of-the-art methods, such as CUB-200-2011, Cars196, Market-1501, and MSMT17.