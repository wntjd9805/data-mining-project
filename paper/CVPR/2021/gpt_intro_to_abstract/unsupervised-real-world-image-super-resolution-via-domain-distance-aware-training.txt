Single image super-resolution (SR) is a highly practical research topic in computer science, aiming to reconstruct high-resolution (HR) images from low-resolution (LR) observations. Various models have been proposed to address the SR problem, but their generalization capacity for real scenarios is limited. Training SR networks on simulated datasets often leads to undesired artifacts in real image SR results. Although attempts have been made to prepare real image SR datasets, they are laborious and costly to collect. Another approach assumes a parameterized degradation model and proposes blind SR algorithms, but these assumptions limit their performance on real data. Recently, unsupervised SR approaches leveraging unpaired training data have been proposed, but they ignore the domain-gap between generated and real LR images. In this paper, we propose a Domain-distance Aware Super-resolution (DASR) framework for real-world image SR. DASR addresses the domain gap by training the SR network with both generated pseudo pairs and real LR images, incorporating adversarial constraints on real-world data. Additionally, a domain-distance weighted supervision strategy is proposed to exploit the generated pseudo pairs effectively. Our contributions include the DASR framework, improved architecture of the down-sampling network, and better adversarial loss in the wavelet domain. Experimental results on synthetic and real datasets demonstrate the superiority of DASR over competing approaches.