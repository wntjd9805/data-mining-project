Deep convolutional neural networks (CNNs) have shown remarkable progress in various fields, including image classification and semantic segmentation. However, their reliance on annotated in-domain data limits their application to cross-domain tasks. Unsupervised domain adaptation (UDA) has emerged as a solution to transfer knowledge from an annotated domain to an unlabeled domain. Most UDA methods assume that the two domains share the same label set, which is often not the case in real-world scenarios.To address this, different approaches have been proposed, such as open set domain adaptation (OSDA), partial domain adaptation (PDA), and universal domain adaptation (UniDA). OSDA deals with target domains that have private classes unknown to the source domain, while PDA focuses on source domains with private classes. However, both OSDA and PDA require prior knowledge about the location of private classes and fail to generalize to different scenarios. UniDA offers a more general setting where both domains can have private classes.The challenge in transferring over unaligned label spaces is effectively separating common samples from private samples in both domains. Previous methods primarily focus on identifying common samples but treat private samples as a single unknown class. This approach does not fully exploit the intrinsic structure of private samples, resulting in lower compactness and less discriminative target representations.In this paper, we propose Domain Consensus Clustering (DCC) to better exploit the intrinsic structure of the target domain. DCC leverages domain consensus knowledge to form discriminative clusters on both common and private samples. We propose a cycle-consistent matching (CCM) approach to identify common clusters by mining semantic consensus among cluster centers. Additionally, we introduce a domain consensus score to quantify cross-domain classification agreements and determine the number of target clusters.For common clusters with high domain consensus scores, we employ a class-aware alignment technique to mitigate the distribution shift. We also enhance the cluster-based consistency of centers that do not find consensus counterparts using a prototypical regularizer. By differentiating private samples into different clusters, we improve the UniDA problem and achieve better representations.Our contributions include tackling the UniDA problem by differentiating private samples into clusters, proposing DCC to mine domain consensus knowledge at semantic and sample levels, and conducting extensive experiments that demonstrate the superior performance of our method compared to previous approaches.