Recent advancements in Generative Adversarial Networks (GANs) have led to the synthesis of photo-realistic images utilizing latent codes. However, the interpretability of the generation process remains a challenge. In particular, achieving well-disentangled semantics that are linear-encoded in the latent space is crucial for practical interpretability. StyleGAN proposes an architecture that supports disentanglement for face generation by introducing an intermediate latent space. This enables linear-encoded representations of facial semantics. Recent works demonstrate that manipulating the face generations to meet specific requirements is possible by sampling along the linear-encoded representation vector. However, existing frameworks rely on training offline classifiers with manually labeled datasets for mapping facial semantics to latent representation vectors. This approach has several disadvantages, including the need for human annotations and limited scope of semantics. In this work, we propose an unsupervised framework for disentangling and manipulating facial semantics under the StyleGAN environment, while still maintaining interpretability. We introduce decorrelation regularization to enhance disentanglement, mutual reconstruction to stabilize training of a 3D deformable face reconstruction method, and linear regression and localized representation learning algorithms for capturing perturbations of univariate and pixel-level semantics, respectively. Our methods are based on label-free training and drastically reduce human involvement in facial representation learning. Additionally, our framework provides an unconstrained environment for disentanglement algorithms to explore and shed light on how interpretable representations are learned in neural network models.