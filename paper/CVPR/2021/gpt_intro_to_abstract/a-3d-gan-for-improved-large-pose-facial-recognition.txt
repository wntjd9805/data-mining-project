Facial recognition algorithms have made significant progress in recent years due to the availability of large image datasets. However, these datasets often have an unbalanced distribution of facial poses, with frontal portraits being more prevalent than images with large poses. The robustness of facial recognition to pose variation is currently a major challenge. Some researchers have attempted to address this issue by frontalizing probe images or by augmenting training datasets with synthetic poses. We support the use of synthetic augmentation, as it does not require additional resources during inference. Traditionally, synthetic pose augmentation involves fitting a 3D face model to input images, extracting textures, and re-projecting them at modified poses. However, recent advancements in Generative Adversarial Networks (GANs) provide an alternative approach. GANs are capable of generating realistic images of new identities, eliminating the need for existing identities in data augmentation. To generate fully synthetic training data, the disentanglement of identity from other characteristics, such as pose, is essential. Although 2D GAN methods struggle with this disentanglement, our work incorporates a 3D morphable model into a GAN to generate images of synthetic identities with fully disentangled pose. Our contributions include the introduction of a method for learning a nonlinear texture model from in-the-wild images, which can be used to generate images of synthetic identities with disentangled pose, without the need for specially captured scans of facial texture. Additionally, we demonstrate improved large-pose facial recognition by augmenting datasets with synthetic 3D GAN images, achieving state-of-the-art accuracy for the CPLFW dataset.