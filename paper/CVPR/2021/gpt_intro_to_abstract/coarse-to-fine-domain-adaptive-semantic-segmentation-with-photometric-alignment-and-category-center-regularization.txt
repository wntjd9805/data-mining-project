Semantic segmentation is a crucial computer vision task that involves labeling every pixel in an image with a semantic category. It is widely used in applications such as autonomous driving and medical image analysis. Deep learning methods have shown impressive results in semantic segmentation, but they require large amounts of annotated ground-truth data, which is often difficult to obtain in practical scenarios. Unsupervised domain adaptation is an alternative approach that aims to transfer knowledge from a source domain (composed of synthetic images) to a target domain (composed of real-world images). However, the differences between the source and target domains, also known as domain shifts, pose a challenge for achieving good performance on the target domain. In this paper, we identify two primary causes of domain shifts: image-level shifts and category-level shifts. We propose a novel pipeline that addresses both levels of domain shifts in a coarse-to-fine manner. Our approach includes a global photometric alignment module for image-level alignment and a category-oriented triplet loss and target domain consistency regularization for category-level feature distribution regularization. Experimental results demonstrate the effectiveness of our method, outperforming previous approaches and achieving state-of-the-art performance on benchmarks.