Temporal data is a common form of data in various domains, such as finance, industrial processes, and video sequences. Analyzing temporal sequences is a crucial task, but comparing two sequences can be challenging due to misalignment. Sequences can vary in temporal length and observation speed, requiring alignment before comparisons. Current alignment methods, such as interpolation and downsampling, either modify the data distribution or suffer from data loss and fail to handle variations in speed. Dynamic Time Warping (DTW) addresses misalignment issues by providing optimal alignments between input sequences using a dynamic programming procedure. DTW is robust to varying temporal lengths and observation speeds, allowing for the computation of discrepancy values between sequences. The DTW barycenter averaging (DBA) technique can obtain a prototype by averaging a set of sequences, enabling tasks like clustering and classification. However, DBA only considers intra-class samples and neglects inter-class samples in learning class-specific prototypes for time series classification (TSC), leading to a negative impact on classification performance. This paper proposes a novel DTW method called Discriminative Prototype DTW (DP-DTW) for temporal recognition problems. DP-DTW computes discrepancies between an input and prototypes of different classes, supervised by discriminative loss, resulting in class-specific prototype sequences that capture distinctive temporal dynamics. DP-DTW can handle temporal recognition of sequences with multiple classes, as in the weakly supervised action segmentation problem in video data. By concatenating prototypes according to the action order indicated in the transcript, each transcript has its ordering sequence representation in DP-DTW. Discriminative losses are applied to DTW discrepancies between the deep representation of the input video and the ordering sequences during training, allowing for the learning of discriminative action prototypes. Action segmentation is obtained by aligning the input with the ordering sequences using DTW alignment, and action-based key frames can be selected as a video summary. The proposed DP-DTW method has three contributions: learning discriminative class-specific prototypes for TSC, unifying the training and inference of DTW for weakly supervised action segmentation, and enabling action-based video summarization. DP-DTW outperforms competitive DTW baselines on TSC benchmarks and achieves state-of-the-art results on challenging datasets for weakly supervised action segmentation. Detailed analysis, such as action-based summarization, is enabled by DP-DTW.