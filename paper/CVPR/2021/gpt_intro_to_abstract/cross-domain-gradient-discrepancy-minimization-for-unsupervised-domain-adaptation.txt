Conventional deep learning methods often rely on large-scale labeled data, which can be expensive and time-consuming to obtain, especially in domains such as medical image analysis. To address this issue, unsupervised domain adaptation (UDA) methods aim to transfer models trained on labeled data from a source domain to similar target domains with unlabeled data. One popular approach in UDA is to reduce the distribution divergence between domains by minimizing a specific metric. Another approach is to learn domain-invariant feature representations using adversarial learning. However, existing adversarial domain adaptation methods have limitations, such as neglecting the category information of target samples and focusing solely on the discrepancy between classifiers. This can result in inaccurate classification and loss of discriminability.In this paper, we propose a novel approach called Cross-Domain Gradient Discrepancy Minimization (CGDM) to address these limitations. CGDM minimizes the discrepancy of gradient vectors between source and target samples as a form of surrogate supervision, ensuring not only accurate alignment but also a similar optimization path between the two domains. Additionally, we leverage a clustering-based self-supervised method to obtain more reliable pseudo labels for target samples, reducing the number of ambiguous samples. The main contributions of this work are as follows:1. We introduce a novel method for minimizing the discrepancy of gradient vectors between source and target samples, addressing the issue of inaccurate alignment in previous bi-classifier adversarial learning approaches.2. We propose a clustering-based strategy to compute the gradients of target samples and obtain more reliable pseudo labels, followed by self-supervised learning to fine-tune the model with both source and target data.3. We reformulate the vanilla bi-classifier adversarial framework with our proposed methods and conduct extensive experiments on three large-scale datasets. The results demonstrate the effectiveness of our approach.Overall, our CGDM method shows promising performance in addressing the limitations of existing UDA methods and improving the accuracy and discriminability of classification on target samples.