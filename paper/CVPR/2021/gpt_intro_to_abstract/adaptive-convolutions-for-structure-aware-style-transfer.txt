In recent years, convolutional neural networks (CNNs) have been used to explore and manipulate the style of images. However, current methods such as adaptive instance normalization (AdaIN) have limitations in capturing and transferring localized spatial structure in the style. To address this, we propose an extension to AdaIN called Adaptive Convolutions (AdaConv) that simultaneously adapts both statistical and structural style. Instead of simply transferring global statistics, our approach estimates full convolution kernels and bias values from the style image, which are then convolved on the content image features. This allows for a more faithful transfer of structural elements from the style image to the content image. We demonstrate the effectiveness of AdaConv in both style transfer and style-based generative face modeling. This extension can replace AdaIN in various applications, providing a new, generic building block in CNN-based image generation and style manipulation.