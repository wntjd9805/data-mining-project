Event cameras have gained attention in computer vision due to their unique ability to detect pixel-wise intensity changes asynchronously. Compared to conventional frame-based cameras, event cameras offer advantages such as low latency, low power consumption, high temporal resolution, and high dynamic range. While event cameras have been successfully used for various vision tasks, they cannot be directly used for existing image-based vision algorithms due to their lack of absolute intensity information. Recent research has focused on reconstructing high-speed and HDR intensity images/videos from events, but the visual quality of the reconstructed videos remains unsatisfactory. This paper aims to address this limitation by proposing a convolutional recurrent neural network for high-speed HDR video reconstruction from events. A temporal consistency constraint is also introduced to reduce temporal discontinuity along frame sequences. To overcome the shortage of high-quality learning data, the authors designed a special imaging system to capture paired high-speed HDR videos and event streams in real scenes. A publicly available dataset, containing paired real-world data, is collected and used to validate the proposed method's performance. Experimental results demonstrate that the proposed approach achieves state-of-the-art reconstruction performance and can effectively handle real HDR scenes. The contributions of this work include the neural network architecture, the temporal consistency constraint, and the collection of a high-quality real dataset for high-speed HDR video reconstruction from events.