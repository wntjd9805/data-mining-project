3D shape generation is a crucial problem in computer vision and computer graphics, with the goal of creating new, diverse, and plausible shapes while minimizing manual intervention. Previous efforts have focused on synthesizing shapes using probabilistic models and geometric constraints. Recently, deep generative methods such as adversarial networks and variational auto-encoders have shown promising results. However, existing works mainly consider geometric and structural plausibility, overlooking physical and functional constraints. This paper introduces a physically-aware generative modeling method that addresses this limitation. By incorporating geometric, structural, and physical information in a latent representation, the proposed method enables applications such as generating realistic shapes and performing physical shape optimization. The approach utilizes a novel loss function that endows existing deep generative models with physical reasoning. Specifically, the method addresses issues of disconnected components and lack of stability by combining new loss functions with a carefully designed training framework. Importantly, the approach requires no additional data or manual annotation. Key components of the method include an implicit function representation of 3D shapes and a topological energy based on persistent homology for promoting connectivity. Additionally, a neural stability predictor is integrated into the generative framework to enhance the stability of generated shapes under gravity. The proposed physical loss is fully differentiable and can be used in various end-to-end learning applications. Extensive experiments demonstrate that the approach improves overall generative performance and physical plausibility metrics compared to state-of-the-art methods. The contributions of this work include enhancing the physical validity of generated content by incorporating physical reasoning, introducing two novel physical losses, and demonstrating the generalizability of the framework to different networks and 3D shape representations. Overall, this paper presents the first end-to-end physically-aware deep generative framework that jointly encodes geometry, structure, and physics in deep generative neural networks.