This paper introduces a novel weakly-supervised framework for remote 3D gaze estimation from monocular images. While previous methods are limited to frontal faces viewed by close-range cameras, this work focuses on the more challenging problem of physically unconstrained gaze estimation with larger camera-to-subject distances and greater variations in head pose and eye gaze angles. The main challenge in this context is acquiring 3D gaze training data, particularly in outdoor settings. To address this, the authors propose a weakly-supervised approach that leverages videos of people "looking at each other" (LAEO) without explicit 3D gaze labels. They introduce several training objectives, including predicting aleatoric uncertainty, deriving pseudo-3D gaze labels, and incorporating geometric LAEO 3D and 2D constraints. The proposed approach is evaluated on the Gaze360 benchmark dataset, demonstrating its effectiveness in learning 3D gaze information from weak LAEO labels. Additionally, when combined with limited 3D gaze-labeled data, the approach shows improved accuracy and cross-domain generalization. Overall, this work presents a promising approach to reduce the burden of acquiring data and labels for physically unconstrained gaze estimation.