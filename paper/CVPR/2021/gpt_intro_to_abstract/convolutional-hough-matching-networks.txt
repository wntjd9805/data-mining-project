Visual correspondence is a crucial aspect of image understanding and is used in various tasks like object recognition, image retrieval, motion estimation, object tracking, and reconstruction. While deep neural networks have made significant progress in learning robust feature representation for establishing correspondences, spatial matching with a geometric constraint remains important for handling image pairs with large variations such as changes in viewpoint, illumination, blur, occlusion, lack of texture, etc. In particular, addressing intra-class variations, where images depict different instances of the same category, is a critical challenge. Geometric matching, which relies on exploiting a geometric consensus of candidate matches, is commonly used to handle this challenge. Traditional methods like RANSAC and Hough transform have been used for geometric verification, but recent work has shown that incorporating the Hough voting process into neural networks is effective for challenging correspondence problems. However, existing methods have limitations as their matching modules are not fully differentiable or learnable, and they are weak to background clutter due to the position-invariant global Hough space. In this work, we propose Convolutional Hough Matching (CHM), a learnable layer that distributes similarities of candidate matches over a geometric transformation space and evaluates them in a convolutional manner. CHM is designed to be compatible with any neural network that uses correlation computation, enabling flexible non-rigid matching and even multiple matching surfaces or objects. Our method outperforms state-of-the-art methods on standard benchmarks for semantic correspondence, demonstrating its strong robustness to challenging intra-class variations.