This paper introduces the concept of video moment localization, which aims to identify and analyze specific moments within untrimmed videos based on natural language descriptions. Existing approaches that interact vision and language either focus on frame-level or proposal-level interactions, neglecting the inherent structure of moments. Moreover, these methods lack the ability to comprehensively understand the content and boundaries of moments, resulting in inaccurate localization. To address these challenges, this paper proposes a Structured Multi-level Interaction Network (SMIN) that incorporates multiple levels of vision-language interaction and moment structured interaction. SMIN utilizes a coarse-to-fine cross-modal interaction to fuse video frames and queries, and incorporates structured moment interaction to capture the relationships between content, boundary, and the moment. Experimental results demonstrate that SMIN outperforms state-of-the-art methods in accurately localizing moments in videos.