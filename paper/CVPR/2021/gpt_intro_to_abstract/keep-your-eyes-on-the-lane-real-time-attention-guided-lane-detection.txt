Deep learning has played a crucial role in advancing various fields, particularly in the domain of autonomous driving. In the context of self-driving cars, deep learning applications primarily focus on perception systems, aiming to ensure the safety of passengers and pedestrians by accurately perceiving the vehicle's surroundings. Lane detection systems have emerged as a critical component in this regard, as they enable autonomous vehicles to determine the exact position of each lane.However, lane detection models face several challenges in real-world scenarios. These challenges include robustness in adverse conditions such as extreme lighting and weather, as well as the occlusion of lane markings by other objects, like cars. Additionally, the long-tail effect can cause data imbalance problems, particularly for approaches like polynomial regression models which struggle to handle sharper curves due to their rarity. Moreover, the efficiency of lane detection systems is a crucial consideration as they need to operate in real-time or faster to optimize processing power for other tasks.Various methodologies have been explored in the literature to address these challenges. Traditional computer vision techniques, such as Hough lines, were commonly used before the emergence of deep learning models. More recently, the focus has shifted towards deep learning approaches, specifically convolutional neural networks (CNNs). These CNN-based models typically approach the lane detection problem as a segmentation task, wherein an input image is processed to generate a segmentation map with per-pixel predictions. While advancements in deep learning have facilitated the use of segmentation networks in real-time, many models struggle to achieve the necessary performance. Consequently, the range of backbone options for segmentation-based methods remains limited. To overcome these limitations, some recent works have explored alternative directions. However, several common challenges persist, including the need for post-processing steps, long training times, and a lack of publicly available source code, hindering comparison and reproducibility.In this paper, we propose a novel method called LaneATT for real-time lane detection, which surpasses the accuracy and speed of most existing state-of-the-art methods. LaneATT is an anchor-based single-stage lane detection model that utilizes a unique anchor-based feature pooling technique. This approach allows for the usage of a lightweight backbone CNN while maintaining high accuracy, in contrast to a previous method. Additionally, we introduce an innovative anchor-based attention mechanism for aggregating global information. Extensive experimental results on three benchmark datasets demonstrate the superiority of our method compared to state-of-the-art models. We also discuss efficiency trade-offs and conduct an ablation study to analyze the effectiveness of our design choices.