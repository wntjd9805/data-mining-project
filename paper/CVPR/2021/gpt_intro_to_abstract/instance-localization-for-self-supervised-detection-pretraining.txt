The paper introduces a novel approach called Instance Localization (InsLoc) for transfer learning in computer vision. While pretraining and finetuning is a popular paradigm in deep network training, the existence of generic and universal representations for transfer learning is questioned. The assumption that ImageNet classification accuracy and object detection performance are positively correlated is challenged. The proposed InsLoc approach sacrifices ImageNet classification accuracy but demonstrates better generalization ability for object detection. The paper identifies two issues contributing to task misalignment in transfer learning: re-purposing the pretrained network for target architectures and the lack of explicit spatial modeling for spatial reasoning tasks. The InsLoc approach includes bounding box information and explicit alignment between convolutional features and foreground regions, enhancing feature responses and sensitivity to translations for detection tasks. The approach is implemented using the momentum contrast framework and evaluated on popular detection backbone networks, demonstrating significant improvements in performance. The proposed InsLoc approach is particularly advantageous for object detection under the small data regime.