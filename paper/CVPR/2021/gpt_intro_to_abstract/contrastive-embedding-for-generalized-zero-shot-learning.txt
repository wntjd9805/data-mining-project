Object recognition is a core problem in computer vision, and significant progress has been made in recognizing objects from a fixed set of categories with ample training samples using deep convolutional neural networks. However, recognizing object categories that follow a long-tail distribution, where some categories have abundant training samples while others have few or no samples, remains challenging due to imbalanced training sets. Zero-shot learning (ZSL) holds promise for addressing this challenge by classifying objects from unseen categories without access to data from those categories. ZSL typically relies on category-level semantic descriptors to transfer the recognition model from seen to unseen categories.In conventional ZSL, the test set only contains samples from unseen classes, while in generalized zero-shot learning (GZSL), the test set includes samples from both seen and unseen classes. Conventional ZSL methods learn a semantic embedding function to map visual features into the semantic descriptor space, enabling classification by comparing embedded data points with class-level semantic descriptors. However, these methods suffer from bias towards seen classes in the more challenging GZSL scenario, misclassifying testing images from unseen classes.To mitigate bias in GZSL, feature generation-based methods have been proposed to synthesize training samples for unseen classes, effectively compensating for the lack of data. While these methods merge real seen training features with synthetic unseen features to create a fully-observed training set, they still operate in the original feature space, which lacks discriminative ability.To address these limitations, this paper proposes a hybrid GZSL framework that combines a feature generation model with an embedding model. Both real seen features and synthetic unseen features are mapped to a new embedding space, where GZSL classification is performed. Instead of using traditional semantic embedding, a contrastive embedding method is proposed in this framework to leverage both class-wise and instance-wise supervision. The contrastive embedding learns to discriminate between positive and negative samples from different classes using a contrastive loss.The proposed method is evaluated on five benchmark datasets and achieves state-of-the-art performance on three datasets and competitive results on the other two. The contributions of this work are three-fold: (1) presenting a hybrid GZSL framework that combines embedding and feature generation models, (2) proposing a contrastive embedding method that utilizes both class-wise and instance-wise supervision, and (3) demonstrating the effectiveness of the GZSL model through comprehensive benchmark evaluations.