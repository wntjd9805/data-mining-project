Visual localization is a fundamental challenge in computer vision, with applications in autonomous robotics, augmented reality, and virtual reality systems. State-of-the-art techniques typically rely on 2D-3D correspondences obtained through local image feature matching and use a Perspective-n-Point solver inside a RANSAC loop. Recent approaches leverage deep neural networks to learn features, match correspondences, and filter outliers. However, training such pipelines end-to-end is challenging due to the complexity and instability of gradient propagation. Alternative approaches aim to regress geometric quantities, such as camera poses or 3D scene coordinates, but suffer from limited scene-specific accuracy and poor generalization to new viewing conditions. In this paper, we propose PixLoc, a trainable algorithm that localizes an image by aligning it to an explicit 3D model using dense features extracted by a CNN. By relying on classical geometric optimization, PixLoc does not need to learn pose regression, making it accurate and able to generalize to new scenes. We train PixLoc end-to-end, supervising only the pose, and demonstrate competitive performance compared to state-of-the-art approaches. Our method also shows robustness to appearance and structural changes, making it suitable for a wide range of applications. Experimental results demonstrate the effectiveness of PixLoc in handling new scenes and challenging viewing conditions.