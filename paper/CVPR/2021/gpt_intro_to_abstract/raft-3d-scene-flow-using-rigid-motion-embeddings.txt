This paper introduces RAFT-3D, an end-to-end differentiable architecture for estimating pixelwise 3D motion from stereo or RGB-D video. The goal of scene flow estimation is to estimate detailed 3D motion between a pair of video frames, which is essential for various applications such as path planning, collision avoidance, virtual reality, and motion modeling. The paper focuses on stereo scene flow and RGB-D scene flow, which deal with stereo video and RGB-D video, respectively.Many scenes can be approximated as collections of rigidly moving objects, and previous scene flow approaches have successfully exploited this structure by decomposing a scene into its rigidly moving components. However, integrating deep learning into scene flow estimation pipelines has proven challenging due to non-differentiable components introduced by object detection and instance segmentation networks.In this paper, the authors propose RAFT-3D, which builds upon the state-of-the-art optical flow architecture RAFT. The main innovation of RAFT-3D is the introduction of rigid-motion embeddings, which are per-pixel vectors representing a soft grouping of pixels into rigid objects. These embeddings are updated iteratively during inference, ensuring that pixels with similar embeddings belong to the same rigid object and follow the same 3D motion.Integral to rigid-motion embeddings is the Dense-SE3 layer, which iteratively updates a dense field of per-pixel SE3 motion. This layer uses unrolled Gauss-Newton iterations to ensure that the SE3 motion is geometrically consistent with the current estimates of rigid-motion embeddings and pixel correspondence. By leveraging Dense-SE3, the rigid-motion embeddings can be indirectly supervised using only ground truth 3D scene flow, eliminating the need for object boxes or masks as supervision.The paper provides an overview of the RAFT-3D approach, highlighting its feature extraction, correlation volume construction, and the iterative update process for pixelwise SE3 motion estimation. Experimental results show that RAFT-3D achieves state-of-the-art accuracy on FlyingThings3D and KITTI datasets, outperforming previous methods in terms of scene flow estimation.