The paper proposes GeoSim, a framework for realistic image manipulation that inserts dynamic objects into existing videos. It combines data-driven approaches and computer graphics to generate assets inexpensively while maintaining high visual quality through physically grounded simulation. GeoSim leverages low-cost bounding box annotations and sensor data from a self-driving fleet to build a fully-textured large-scale 3D assets bank. It addresses challenges such as sparsity of 3D observations, occlusions, shadows, limited viewpoints, and lighting changes to reconstruct assets robustly. The 3D scene layout is used to add vehicles in plausible locations and make them behave realistically. GeoSim performs image-based rendering and neural network-based image in-painting to seamlessly blend the inserted objects. The resulting synthetic images and video footages are realistic, dynamically plausible, and geometrically consistent. The paper demonstrates applications in long-range realistic video simulation and synthetic labeled data generation for training self-driving perception algorithms, outperforming prior work in realism metrics. GeoSim has potential applications in safety verification, data augmentation, Sim2Real, augmented reality, and automatic video editing.