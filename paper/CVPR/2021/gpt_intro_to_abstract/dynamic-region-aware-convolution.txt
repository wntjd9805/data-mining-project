Convolutional neural networks (CNNs) have demonstrated great success in various computer vision tasks. However, traditional CNNs perform convolution operations in a filter sharing manner across the entire spatial domain, limiting their ability to effectively extract fine-grained information. To address this limitation, some studies have proposed local convolutions, where each spatial position is assigned individual filters. Although local convolutions have shown promise, they suffer from two significant drawbacks: a large number of parameters and the loss of translation-invariance. In this paper, we propose a new convolutional operation called Dynamic Region-Aware Convolution (DRConv) to overcome these limitations. DRConv automatically assigns filters to spatial regions using a learnable guided mask module, allowing for powerful semantic representation and maintaining translation-invariance. We validate the effectiveness of DRConv through experiments on image classification, face recognition, object detection, and segmentation tasks. The results demonstrate that DRConv achieves excellent performance while significantly reducing the number of parameters compared to local convolutions, without increasing computational complexity. This work contributes a novel convolutional operation with improved representation ability and end-to-end optimization, making it a valuable addition to convolutional neural networks in various computer vision applications.