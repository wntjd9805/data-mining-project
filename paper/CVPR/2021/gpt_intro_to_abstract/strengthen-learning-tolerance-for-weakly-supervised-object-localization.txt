Object detection has seen significant advancements in recent years, thanks to convolutional neural networks (CNNs). However, traditional methods still require bounding box annotations, which can be time-consuming and costly. As a result, weakly supervised object localization (WSOL) has gained attention as it only relies on image-level annotations. WSOL methods can be categorized into unified localization-classification frameworks and separated localization-classification frameworks. While the former predicts localization and classification in the same network, the latter separates the tasks into two networks. In this paper, we propose a novel weakly supervised object localization framework called SLT-Net. SLT-Net consists of a localizer, a regressor, and a classifier, and it focuses on strengthening the model's tolerance to semantic mistakes and image transformations. Specifically, we introduce a class-tolerant classification module to mitigate the part domination effect, and we enhance the tolerance to image diversity by matching the visual response maps of transformed and original images. Experimental results on the CUB and ILSVRC2012 datasets demonstrate the effectiveness of the proposed method.