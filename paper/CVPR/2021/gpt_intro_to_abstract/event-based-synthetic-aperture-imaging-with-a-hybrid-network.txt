In this paper, we introduce a novel synthetic aperture imaging (SAI) method using event cameras to address the challenges of imaging in harsh environments with dense occlusions and extreme lighting conditions. Conventional frame-based SAI often fails in these cases, leading to degraded image quality or even reconstruction failure. Event-based SAI (E-SAI) overcomes these limitations by utilizing event streams that capture the pixel-wise brightness changes of scenes in an asynchronous manner. E-SAI collects light information from occluded targets via event streams, representing the brightness difference between foreground occlusions and the occluded targets. The high dynamic range and low latency of event cameras enable the collection of confident light information even under extreme lighting conditions. To effectively process the event stream and reconstruct high-quality visual images, we propose a hybrid neural network architecture that combines a spiking neural network (SNN) encoder and a convolutional neural network (CNN) decoder. This architecture integrates and encodes the spatio-temporal information of events efficiently, mitigates the influence of noise events, and ensures the overall performance of reconstruction. The contributions of this paper are three-fold: 1. We present a novel event-based SAI algorithm that overcomes the limitations of conventional frame-based SAI under dense occlusions and extreme lighting conditions. 2. We propose a hybrid SNN-CNN encoder-decoder network that effectively reconstructs high-quality visual images for E-SAI by leveraging the advantages of SNN and CNN. 3. We construct an event-based SAI dataset to evaluate the proposed method and make it available to the research community.