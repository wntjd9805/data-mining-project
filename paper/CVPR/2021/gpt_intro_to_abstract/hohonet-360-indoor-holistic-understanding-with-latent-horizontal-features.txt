This paper introduces HoHoNet, a framework for holistic scene modeling from a single high-resolution equirectangular projection (ERP) image that captures a 360° panorama. With the increasing accessibility of omnidirectional cameras and the release of large-scale panorama datasets, there is a growing need for techniques to model panoramic scenes. HoHoNet addresses this problem by efficiently and effectively encoding ERP images into a Latent Horizontal Feature representation (LHFeat). The framework includes a horizon-to-dense (h2d) module that recovers per-pixel modalities while maintaining efficiency. This is achieved by utilizing the strong regularity between human-made structures and the gravity aligned y-axis of ERP images. By replacing linear interpolation with IDCT, HoHoNet improves dense prediction results. The key merits of HoHoNet are its speed, versatility, and accuracy. It can yield dense modalities for a high-resolution 512 × 1024 panorama at 52 FPS and 110 FPS with ResNet-50 and ResNet-34 respectively. It can model layout, dense depth, and semantic segmentation, and achieves state-of-the-art performance in these tasks.