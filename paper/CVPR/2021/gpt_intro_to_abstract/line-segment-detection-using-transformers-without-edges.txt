Line segment detection is a crucial step in various computer vision tasks but remains an unsolved problem. While edge detection has shown impressive results, accurately extracting line segments with semantic significance remains a challenge due to the complexity and occlusion in natural scenes. Existing methods often rely on heuristics and intermediate stages, limiting their performance and development. In this paper, we propose a Transformer-based end-to-end line segment detection algorithm called LinE segment TRansformers (LETR). Inspired by the power of Transformers in modeling complex structures, LETR eliminates the need for explicit edge detection and heuristics-guided processes. We achieve state-of-the-art results on benchmark datasets by leveraging tokenized queries, self-attention mechanism, and bipartite matching. Additionally, we introduce multi-scale encoding/decoding strategy and a direct endpoint distance loss term to overcome the limitations of bounding box representations. Our contributions include a joint end-to-end line segment detection approach, the use of Transformers for entity modeling and perceptual grouping, and the enhancement of DETR with new algorithmic aspects.