Convolutional neural networks (CNNs) have made significant advancements in computer vision tasks such as image classification, semantic segmentation, object detection, and image restoration. However, CNNs require large amounts of weights and operations, resulting in high memory and computational costs. Network quantization, which reduces the bit-precision of weights and/or activations in a network, offers a potential solution to implement CNNs with limited hardware resources. For example, binarized neural networks use 32 times less memory compared to full-precision counterparts and rely on binarization techniques that replace multiplication and addition with XNOR and bit-count operations. Quantized networks involve weight and/or activation quantizers that convert full-precision values into low-precision ones. The main challenge in training quantized networks arises from the discretization step, where gradients become zero or explode due to the derivative of the discretizer being either zero or infinite. Most quantization methods overcome this issue by using the straight-through estimator (STE), which assumes the derivative of the discretizer is equal to 1. However, the use of STE can lead to a gradient mismatch problem as the forward pass discretizer does not match the backward pass discretizer. In this paper, we propose a different approach called element-wise gradient scaling (EWGS) that improves the training of quantized networks compared to STE in terms of stability and accuracy. We interpret the full-precision input of the discretizer as a "latent value" moving in a continuous space, and the discretizer output as a "discrete value" determined by projecting the latent value to the nearest discrete level. EWGS scales up or down each gradient element of the discrete value during backpropagation, considering the sign and discretization errors between the latent and discrete values. We also propose an adaptive method to adjust the scaling factors during training based on the second-order derivatives of the loss function with respect to the discrete values. This estimation is performed efficiently using Hutchinson's method. Our experimental results demonstrate that CNN architectures trained with EWGS achieve state-of-the-art performance on ImageNet, without the need for extensive hyperparameter search, training schedules, or additional modules. We also show that our approach enhances the performance of other quantization methods such as DoReFa-Net and PROFIT. Code and models are made available online for reproducibility.