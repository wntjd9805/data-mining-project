Supervised deep learning approaches have made significant progress in video action recognition but require large annotated datasets. This motivates the exploration of semi-supervised learning approaches, which use structural invariance as a source of supervision. While semi-supervised representation learning models have performed well in image recognition, their application to video action recognition has received little attention. This paper proposes a Temporal Contrastive Learning (TCL) framework for semi-supervised action recognition in videos. TCL leverages the temporal information in videos by learning representations from both slow and fast versions of the same videos. A two-pathway model is used to process unlabeled videos at different speeds, maximizing similarity between representations of the same video and minimizing similarity between representations of different videos. To achieve this, a modified NT-Xent contrastive loss is employed, considering both individual instances and groups of videos with high class consistency. Extensive experiments demonstrate that TCL outperforms state-of-the-art semi-supervised approaches in image recognition, requiring only a fraction of labeled data to reach the performance of fully supervised approaches. The framework is also shown to be robust to domain shifts when training with unlabeled videos from a different domain. Overall, TCL offers a novel approach to semi-supervised action recognition in videos, achieving superior performance and demonstrating versatility in different scenarios.