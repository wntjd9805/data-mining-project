This paper addresses the problem of unsupervised action segmentation in untrimmed videos. The actions in the videos are considered both salient and latent, as they may not have a distinct semantic meaning and no supervision about the actions is available. The goal is to localize the salient actions in the videos. The paper focuses on a specific setting where all videos show the same activity that can be decomposed into a sequence of simpler actions. Previous work in this setting made restrictive assumptions about the fixed temporal ordering of actions in the videos. This paper relaxes those assumptions and proposes a Hidden Markov Model (HMM) to infer the temporal ordering of actions. A new self-supervised learning (SSL) approach is also introduced for action-level temporal feature embedding. The SSL approach uses positive and negative sequences of actions generated from the videos. The paper then formulates a joint training of the HMM, MLP, and Action Shuffle SSL within the Generalized EM framework. The paper provides an overview of the unsupervised learning process and presents results demonstrating superior performance compared to state-of-the-art methods on challenging datasets. The remaining sections of the paper discuss related work, present the SSL approach, specify the HMM and its inference, formalize the joint training, extend the approach to a more general setting, and present experimental results.