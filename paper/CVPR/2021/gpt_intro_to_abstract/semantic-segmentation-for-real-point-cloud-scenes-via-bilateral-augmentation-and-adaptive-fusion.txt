This paper focuses on the semantic segmentation of real point cloud scenes, which is a challenging task due to the scattered, irregular, unordered, and uneven distribution of point clouds in 3D space. Although various data-driven models using deep learning have been proposed, they often require time-consuming pre/post-processing steps and may lose the context of the surroundings. To address these issues, this paper introduces a point-based network that directly processes points for fine-grained analysis.The paper aims to overcome two major drawbacks of existing works. Firstly, the ambiguity in close points is addressed by augmenting the local context with a dense region and using a robust aggregation process to extract useful neighboring information. Secondly, the problem of redundant features is tackled by characterizing the input information as geometric and semantic clues and utilizing them through a bilateral structure, thereby avoiding complexity in processing large-scale point clouds.Additionally, the paper addresses the inadequacy of global representations by integrating information from different resolutions and adaptively fusing multi-resolutional features for each point. This ensures a comprehensive representation for fine-grained semantic prediction.The contributions of this paper include the introduction of a bilateral block to augment local context, the adaptive fusion of multi-resolutional features for comprehensive knowledge about point clouds, and a novel semantic segmentation network for real point cloud scenes. The proposed network is evaluated on three large-scale benchmarks, demonstrating competitive performances compared to state-of-the-art methods. Overall, this paper provides insights and advancements in the field of point cloud analysis and semantic segmentation.