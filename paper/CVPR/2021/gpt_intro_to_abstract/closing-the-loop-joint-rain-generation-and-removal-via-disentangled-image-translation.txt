Rain is a common weather phenomenon that impacts the quality of images and computer vision tasks. The current approach to rain generation simplifies the process and is formulated as an inverse problem of rain removal. Recent deep learning-based deraining methods have shown promise in removing rain streaks, but they struggle to generalize well to real rain due to the gap between synthetic and real rain. Different approaches have been proposed to improve real rain removal, including incorporating more complex rain models and enforcing constraints between real and simulated deraining results. However, these methods often neglect the importance of coupling rain generation and removal. In this work, we propose a bidirectional disentangled translation network that learns rain generation and removal in a unified framework. We focus on learning from real rainy images to approximate the complex degradation implicitly. Our algorithm preserves the consistency of the image background while transforming the rain layer between real and simulated rain. We evaluate our method on both synthetic and real-world datasets and achieve superior performance compared to state-of-the-art methods, especially on real-world rainy images.