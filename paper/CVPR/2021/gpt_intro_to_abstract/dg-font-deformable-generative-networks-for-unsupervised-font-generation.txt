Font generation is an important task in various applications such as font library creation and data augmentation for optical character recognition. Traditional methods rely on expert designers, making the process expensive and labor-intensive, especially for logographic languages like Chinese and Korean. Recent advancements in convolutional neural networks have enabled automatic font generation without human expertise. However, existing methods either require large amounts of paired training samples or rely on auxiliary annotations. In this paper, we propose a novel deformable generative model for unsupervised font generation (DG-Font). Our method separates style and content representations and leverages a feature deformation skip connection (FDSC) to preserve the geometric transformation, stroke thickness, and other important characteristics of fonts. We train our model with a multi-task discriminator and utilize reconstruction losses to ensure domain-invariant characteristics between generated and content images. Experimental results demonstrate that our model achieves comparable results to state-of-the-art methods and can generate unseen style characters.