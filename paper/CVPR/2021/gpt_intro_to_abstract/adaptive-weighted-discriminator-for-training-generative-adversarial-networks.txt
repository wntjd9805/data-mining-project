Generative Adversarial Networks (GANs) have emerged as a key model for unsupervised machine learning. GANs consist of a generator and a discriminator network, with the generator generating samples and the discriminator distinguishing between real and fake data. However, GAN training faces challenges such as instability, mode collapse, diminishing gradients, and sensitivity to hyperparameters. This paper focuses on addressing instability and mode collapse by modifying the discriminator model. The modified discriminator loss function introduces adaptive weights to control the gradient direction, avoiding situations where training benefits one loss but harms the other. The proposed method is applicable to various GAN models and has been demonstrated to yield significant improvements in image generation tasks on CIFAR-10, STL-10, and CIFAR-100 datasets. The code for the proposed method is available on GitHub.