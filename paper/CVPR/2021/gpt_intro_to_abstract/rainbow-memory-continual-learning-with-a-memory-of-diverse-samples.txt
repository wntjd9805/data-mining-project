Continual learning (CL) or class incremental learning (CIL) is a challenging task in artificial intelligence (AI) due to the changing data distribution and the inability to access previous task data. This leads to catastrophic forgetting and poor model generalization. Various approaches have been proposed to address this issue, such as momentum matching, sample generation, regularization, and sampling-based memory management. However, these approaches are mostly evaluated in disjoint task setups where tasks do not share classes. In real-world applications, blurry-CIL setups are more common, where tasks share classes and a model can only use a small portion of data from previous tasks. To tackle the challenges of blurry-CIL, this paper proposes a new method called Rainbow Memory (RM). RM introduces a diversity-aware sampling method that selects samples for the memory based on perturbation-induced uncertainty. The memory slots are filled with samples drawn from a distribution that approximates the robustness of the samples. This diversity-induced memory helps models preserve discriminative boundaries for each class. Additionally, RM explores the use of data augmentation techniques, such as label mixing-based augmentation, to further enhance the diversity of the stored samples in the memory. The proposed method is evaluated on MNIST, CIFAR10, CIFAR100, and ImageNet datasets using the blurry-CIL setup. Experimental results show that RM outperforms state-of-the-art baselines with significant improvements in accuracy (over 14%p and 9% on all datasets evaluated). Furthermore, RM performs comparably to other methods in the disjoint-CIL setup despite being designed for blurry-CIL. The contributions of this paper include the proposal of a diversity-aware sampling method, the exploration of data augmentation for memory enhancement, and the release of the source code and evaluation protocol for future research in this area.