This paper introduces the concept of transformation driven visual reasoning (TVR), which aims to test machines' ability to reason about the dynamics between different states. The authors argue that existing visual reasoning tasks, such as visual question answering (VQA) and visual commonsense reasoning, focus on reasoning within states and fail to capture the ability to reason about transformations between states. To address this, the authors define a new TVR task and construct a dataset called TRANCE (Transformation on CLEVR) based on the CLEVR dataset. TRANCE consists of three settings: Basic, Event, and View, which test single-step and multi-step transformations. To evaluate existing reasoning techniques on this new task, the authors propose a new encoder-decoder framework called TranceNet. Experimental results show that deep models perform well on the Basic setting but struggle with the more complex Event and View settings, highlighting the challenges and research potential in transformation-based reasoning. The contributions of this work include the definition of the TVR paradigm, the creation of the TRANCE dataset, and insights for future model designs.