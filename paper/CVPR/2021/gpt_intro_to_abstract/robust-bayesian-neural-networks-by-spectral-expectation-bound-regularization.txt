Bayesian neural networks (BNNs) are a powerful framework that treats model weights as random variables, allowing for the estimation of both aleatoric and epistemic uncertainty. This probabilistic representation makes BNNs suitable for building reliable and robust systems in various domains, including computer vision and natural language processing. However, BNNs face challenges in defending against adversarial attacks, as traditional defenses based on constraining the Lipschitz constant cannot be directly applied to probabilistic models. Nonetheless, BNNs have shown promising results in detecting adversarial samples and have been found to exhibit inherent adversarial robustness under certain idealized conditions. Unfortunately, these idealized conditions are rarely met in practical scenarios, and the need for improved robustness persists. This paper proposes a novel method called Spectral Expectation Bound Regularization (SEBR) to enhance the robustness of BNNs. SEBR leverages the Lipschitz constraint by reducing the expectation of the spectral norm of the training parameter matrices. Theoretical analysis confirms the effectiveness of SEBR in improving the adversarial robustness of BNNs, and its impact on the epistemic uncertainty of the model is also studied. Experimental results on multiple BNN structures validate the theoretical findings and demonstrate the effectiveness of SEBR in real-world scenarios. The code for implementing SEBR is publicly available on Github.