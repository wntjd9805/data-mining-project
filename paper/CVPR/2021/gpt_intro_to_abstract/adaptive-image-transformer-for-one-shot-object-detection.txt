Object detection is a fundamental technique in computer vision, but it often requires a large amount of labeled training data for reliable performance. Existing object detectors perform well in localizing objects that have been seen in training, but struggle with objects from unseen classes. To address this issue, the task of One-Shot Object Detection (OSD) is introduced, which aims to detect objects of arbitrary unseen classes based on a given inference query. However, OSD presents challenges as online model fine-tuning is not feasible and objects can vary significantly in size, shape, color, texture, and appearance. To overcome these challenges, a neural network approach is proposed that employs a multi-head attention mechanism to adaptively represent each potential region, evaluating its relatedness to the query patch. The proposed method consists of three key components: Multi-head Co-Attention (MCA), Adaptive Image Transformer (AIT), and Selective Channel Attention (SCA). MCA correlates the target image and query patch to generate more relevant region proposals, while AIT translates the feature of each proposal to match the query feature. SCA enhances the importance of high similarity channels before evaluating a proposal-query pair. The proposed method achieves state-of-the-art results on two benchmark datasets, showcasing its effectiveness in one-shot object detection.