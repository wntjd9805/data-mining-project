Abstract:We propose a new method, called deep pursuit, for designing deep neural networks that are robust to adversarial noise. Unlike previous methods that accumulate error in layered basis pursuit, our approach synchronously optimizes all network activations through a global basis pursuit. This method accounts for skip connections commonly found in modern network architectures and avoids error accumulation as the network grows deeper. By reframing the network as a single structured sparse coding problem, our method achieves improved robustness to adversarial attacks. We provide connections to sparse approximation theory, extend the layered basis pursuit method to our global view, and demonstrate the superiority of deep pursuit over layered basis pursuit through experimental results on the CIFAR-10 dataset. Our method has implications for domains such as security systems and autonomous vehicles where robustness to adversarial attacks is critical.