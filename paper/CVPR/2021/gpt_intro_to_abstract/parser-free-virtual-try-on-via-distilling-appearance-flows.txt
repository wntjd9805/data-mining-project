Virtual try-on of fashion image has become an important task in the field of e-commerce and fashion image editing. State-of-the-art methods rely on human segmentation of body parts to enable the learning procedure of virtual try-on. However, slight errors in segmentation can lead to unrealistic try-on images. To address this issue, a recent work called WU-TON proposed a parser-free network that does not require human segmentation for virtual try-on. However, the generated images of the parser-based teacher in WU-TON have large artifacts, resulting in unsatisfactory results when used as teacher knowledge. In this paper, we propose a new approach called Parser Free Appearance Flow Network (PF-AFN) that produces highly photo-realistic try-on images without human parsing. PF-AFN employs a "teacher-tutor-student" knowledge distillation scheme, where the fake person image is treated as input for the parser-free student model and supervised by the original real person image. We also formulate knowledge distillation as distilling appearance flows between the person image and the garment image, facilitating accurate dense correspondences for high-quality image generation. Our method outperforms previous approaches both qualitatively and quantitatively, demonstrating its superiority.