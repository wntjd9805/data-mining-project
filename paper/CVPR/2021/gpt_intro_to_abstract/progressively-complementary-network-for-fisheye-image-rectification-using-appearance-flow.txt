The use of fisheye cameras has become prevalent in various applications such as video surveillance, autonomous driving, and mobile applications. However, the images captured by these cameras are not suitable for traditional computer vision techniques designed for perspective images. Distortion rectification has been a focus of attention for many years to address this issue. Traditional algorithms extract features to calculate corresponding model parameters, but the number of detected features is unstable, affecting the accuracy of the model. To overcome this problem, deep learning approaches have been explored, specifically regression-based and generation-based methods. Regression-based methods utilize convolutional neural networks to predict model parameters, but they trade-off the number of parameters in the nonlinear model. On the other hand, generation-based methods directly generate corrected images using an encoder-decoder structure. However, the effects of this structure have not been fully explored, as the skip-connection in the structure introduces redundant information that confounds the decoder. This paper aims to investigate the effects of different approaches to image rectification and propose a complementary architecture that addresses the limitations of the existing methods.