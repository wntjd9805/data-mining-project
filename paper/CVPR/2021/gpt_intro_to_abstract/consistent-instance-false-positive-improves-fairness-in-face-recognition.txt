Abstract:Fairness in face recognition systems has gained significant attention due to the widespread deployment of such systems in our daily lives. Unfair predictions by these systems can result in unfair treatment, especially across different demographic groups. Previous studies have focused on improving fairness in face recognition through dataset and algorithm enhancements. However, constructing balanced datasets that eliminate racial biases remains challenging. Additionally, existing algorithms designed to mitigate demographic biases have limited transferability and rely on accurate demographic attribute annotations. In this paper, we propose a novel approach to address these challenges by evaluating bias in face recognition based on false positive rate (FPR) and false negative rate (FNR). We introduce a false positive rate penalty loss that promotes consistency in FPR across demographic groups, mitigating bias in face recognition. Our method does not require demographic annotations and can be easily integrated into commonly used face recognition loss functions. Through extensive experiments on popular facial benchmarks, we demonstrate the effectiveness of our approach in improving fairness across demographic groups divided by various attributes. The contributions of our work include providing a new perspective on improving face recognition fairness, developing a method that can improve fairness across different attributes without demographic annotations, and achieving superior performance compared to state-of-the-art competitors.