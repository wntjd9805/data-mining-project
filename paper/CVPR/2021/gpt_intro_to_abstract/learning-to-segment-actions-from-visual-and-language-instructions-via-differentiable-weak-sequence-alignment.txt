This paper focuses on the task of learning procedural tasks from instructional videos. The aim is to localize the key steps required to complete a task by analyzing the visual demonstrations and accompanying narrations in the videos. While previous works have made progress in learning from weakly annotated videos, there is a need for unsupervised learning approaches that do not require costly annotations. The authors address this challenge by leveraging both visual and language instructions in the videos. However, there are challenges, such as the misalignment between the two modalities and the presence of irrelevant background information. To overcome these challenges, the authors propose a method that recovers the sequences of key steps and performs weak alignment. They design an ordered prototype learning module to extract visual and linguistic prototypes and develop a differentiable weak sequence alignment (DWSA) method for finding one-to-one matching between sequences. The proposed method outperforms existing approaches in terms of F1 score, as demonstrated in experiments on instructional video datasets.