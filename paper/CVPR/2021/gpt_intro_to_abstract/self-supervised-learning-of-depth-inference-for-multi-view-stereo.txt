Multi-view Stereo (MVS) aims to reconstruct a 3D model from multiple images. Cost-volume based deep neural networks have achieved the best performance in MVS, but they require large amounts of ground truth depth data, which is expensive and time-consuming to acquire. Synthetic data has been proposed as an alternative by generating multiple view images with ground truth depths from 3D scene models. However, fine-tuning the model using real scene data is still necessary for practical use. Unsupervised learning strategies have also been explored, but they are less effective compared to supervised methods. In this paper, we propose a self-supervised learning framework for depth inference from multi-view images. Our approach generates pseudo labels for network training solely from multiple view images. We use an image reconstruction loss to supervise the training of a cost-volume based depth inference network, and then use this network to infer pseudo depth labels for self-supervision. We refine the pseudo labels by inferring depth from higher resolution images, filtering out depth with large errors, and using multi-view depth fusion and rendering to complete the labels. Our experiments show that our self-supervised framework outperforms existing unsupervised MVS networks and performs on par with supervised methods.