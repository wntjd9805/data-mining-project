Estimating relative pose between a pair of RGB images is an important task in computer vision with various applications. Existing methods heavily rely on accurate correspondence between images, which becomes challenging when there is little or no image overlap. In this paper, we propose a technique for estimating relative 3D rotation for image pairs with extreme relative motion and little or no overlap. Our approach leverages cues such as illumination and geometric properties, which can provide evidence for the geometric relationship between images. We use correlation volumes to compare local properties between image pairs, allowing us to find explicit correspondence for overlapping pairs and implicit cues for non-overlapping pairs. We then process the correlation volume with a network to estimate probabilities over a fine-grained discretization of 3D rotations. Our framework is end-to-end trainable and achieves state-of-the-art results for overlapping pairs. We evaluate our method on a variety of extreme RGB image pairs and demonstrate its generalization capabilities to new data.