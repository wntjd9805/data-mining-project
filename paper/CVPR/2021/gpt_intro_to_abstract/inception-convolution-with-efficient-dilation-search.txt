The concept of receptive fields in convolution neural networks (CNNs) has been extensively studied, with previous works proposing optimal receptive fields (ORFs) for different tasks. The need for ORFs arises from variations in image sizes and object scales across different tasks. The dilation value of dilated convolution kernels has been shown to be an effective hyper-parameter for controlling receptive fields. However, previous methods for optimizing receptive fields neglect the fine-grained inner structure of dilated convolution. In this work, we propose a new type of dilated convolution called Inception Convolution that considers a dense range of possible receptive fields. We also introduce a statistical optimization-based network architecture search algorithm called EDO, which efficiently learns the optimal receptive field. EDO supports efficient channel-wise dilation pattern selection over the complete dilation pattern search space, and has lower computation cost and higher GPU utilization compared to previous methods. Our contributions include the proposal of Inception Convolution, the development of the EDO algorithm, and comprehensive experiments demonstrating improved performance for various visual tasks without additional computational costs.