The introduction of this computer science paper discusses the importance of modeling affinity, or similarity among different positions, in deep networks. Two existing solutions for affinity learning in deep networks are discussed: learning an affinity map before a non-deep backend, and using a learnable affinity-based module to propagate information. However, these approaches have limitations and may not be effective for downstream tasks. The paper proposes a novel learnable upsampling operator called affinity-aware upsampling (A2U) that models affinity into upsampling. A2U is shown to be a generalization of first-order upsampling operators and can be implemented efficiently with few extra parameters. The effectiveness of A2U is demonstrated through experiments on detail-sensitive tasks, including image reconstruction and image matting. The results show that A2U achieves significant improvement in performance with negligible increase in parameters, offering a lightweight and high-performing image matting architecture. The paper concludes by discussing alternative design choices for A2U and comparing their similarities and differences.