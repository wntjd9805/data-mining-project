This paper introduces the concept of representing images as continuous functions rather than 2D arrays of pixels in the field of deep learning. The authors propose the use of implicit neural representations (INRs) as approximations of the underlying function that maps pixel coordinates to RGB values. To overcome the challenges of training and evaluating INRs for high-resolution images, the authors propose two architectural techniques: factorized multiplicative modulation (FMM) layer for hypernetworks and multi-scale INRs. These techniques are used to build INR-GAN, a state-of-the-art continuous image generator that achieves impressive results on large real-world datasets. The paper also investigates various interesting properties of INR-based decoders, including extrapolation, geometric encoding, low-resolution inference, image space interpolation, and out-of-the-box superresolution. Overall, the contributions of this paper include the development of the FMM layer, the multi-scale INR architecture, the INR-GAN model, and the exploration of unique properties of INR-based decoders.