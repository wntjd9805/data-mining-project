Predicting the future trajectories of nearby vehicles is crucial for Autonomous Vehicle systems to understand their surroundings and make informed decisions. Multi-modal prediction, which aims to generate multiple plausible trajectories for the target vehicle, plays a vital role in handling the uncertainty in motion prediction and improving motion planning safety. However, this prediction is challenging due to the uncertainties and variations in vehicle behaviors. Existing methods for multi-modal prediction mainly use probabilistic or proposal-based approaches. Probabilistic methods model the uncertainty of the trajectory by defining possible underlying models as latent variables. Proposal-based approaches define candidate points or trajectories as proposals and then regress or classify these proposals to the ground truth. While these methods have achieved good performance, they still have limitations such as optimization instability, mode collapse, reliance on pre-defined anchors, and the inability to capture the multi-modal nature of trajectory prediction. In this paper, we propose a novel end-to-end multimodal motion prediction framework called MultiModal Transformer (mmTransformer) for addressing these limitations. mmTransformer is based on the transformer architecture, which has been proven effective in modeling sequential data. The framework incorporates contextual information by randomly initializing and refining trajectory proposals. These proposals are treated as queries in the decoders of mmTransformer, aggregating multiple channels of contextual information from encoders and enabling independent predictions. Additionally, we introduce a region-based training strategy (RTS) to explicitly ensure multimodality. RTS divides the surrounding space into regions and assigns trajectory proposals to different sets based on their regions. During training, only the set of proposals assigned to the region where the ground truth is located is utilized to optimize the framework. This strategy allows each individual proposal to focus on capturing a specific mode without compromising the latent features learned by other proposals.The contributions of this paper are: (1) mmTransformer is the first model to use stacked transformers for trajectory proposals, effectively aggregating contextual information and achieving multimodal prediction; (2) The novel region-based training strategy preserves the multimodal nature of motion forecasting by ensuring that each individual proposal captures a specific mode; (3) Extensive experiments demonstrate the substantial improvement brought by the proposed model architecture and region-based training strategy. Our model achieved the top rank on the Leaderboard of Argoverse benchmark and remains competitive.