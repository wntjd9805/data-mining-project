Obtaining dense 3D information is crucial for applications such as autonomous vehicle navigation, mixed reality, 3D modeling, and industrial control. Camera-based passive sensing offers energy and cost efficiency, compact size, and versatility compared to active depth sensing methods. Monocular systems provide mobile, low-maintenance solutions, while stereo devices often have impractical baseline sizes for mobile devices. This paper focuses on dense depth recovery for video streams with known camera poses. The availability of camera poses allows triangulation-based metric reconstructions, differentiating from learning-based depth prediction methods extended to video. The goal is to develop a lightweight online multi-view stereo (MVS) system for real-time applications. The framework presented enhances existing MVS methods by incorporating partial scene geometry information from past frames to improve depth predictions in the current frame. This is achieved through convolutional long short-term memory (ConvLSTM) and a hidden state propagation scheme. The proposed approach demonstrates improved depth estimation accuracy with minimal computational overhead. The system sets a new state-of-the-art performance on several benchmark datasets while maintaining low runtime and memory usage.