This paper introduces a novel unsupervised deep learning-based framework for building dense correspondence between 3D point clouds. With the increasing popularity of point clouds in various applications, the lack of correspondence between point clouds poses challenges for downstream processing and analysis. Existing methods either require large amounts of annotated data or assume connectivity information is available in the input data. This paper addresses these limitations by proposing an unsupervised approach that learns dense correspondence between non-rigid 3D shapes in the form of point clouds, but can also be applied to rigid shapes. The proposed framework includes a correspondence indicator module and a deformation-like reconstruction module, which work together to generate a permutation matrix that encodes the point-to-point correspondence. Experimental results demonstrate the superiority of the proposed method over state-of-the-art methods, even outperforming methods that use 3D meshes as input. This paper contributes to the advancement of building dense correspondence in point clouds and opens up new possibilities for unsupervised learning in computer vision and digital geometry processing.