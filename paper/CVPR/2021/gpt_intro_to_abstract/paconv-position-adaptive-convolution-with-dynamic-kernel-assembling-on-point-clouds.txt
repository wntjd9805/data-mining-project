The rise of 3D scanning technologies has led to the increased use of 3D point cloud data in various applications such as autonomous driving, robotic manipulation, and virtual reality. However, the processing of 3D point clouds is challenging due to their sparse, irregular, and unordered structure. While deep learning methods have shown promising results in processing 3D point clouds, the current approaches still struggle with these challenges. Existing research can be categorized into two main approaches. The first approach involves voxelizing the point clouds to form regular grids and applying 3D grid convolutions. However, this method often results in the loss of important geometric information and incurs additional memory and computational costs. The second approach focuses on directly processing the point cloud data. The pioneering work utilizes Multi-Layer Perceptron (MLP) and global aggregation to learn spatial encodings of points. Subsequent works have improved on this by incorporating local aggregation schemes. However, these methods are limited in representing spatial-variant relationships as they process all the points with the same MLP.To address these limitations, this paper introduces Position Adaptive Convolution (PAConv), a plug-and-play convolutional operation for deep representation learning on 3D point clouds. PAConv dynamically assembles convolutional kernels using basic weight matrices in a Weight Bank. The assembly coefficients are learned from the relative point positions using MLPs. PAConv is capable of modeling the spatial variations and geometric structures of 3D point clouds while remaining efficient. It bypasses the memory and computational burden of inferring kernels from point positions and provides flexibility in modeling spatial variations in a data-driven manner.Extensive experiments are conducted on three benchmark datasets using three generic network backbones, namely PointNet, PointNet++, and DGCNN. PAConv is shown to achieve state-of-the-art performance on ModelNet40 and significantly improve the baseline results on ShapeNet Part and S3DIS. It is worth noting that the evaluation of recent point convolution methods often involves complex architectures and tailored data augmentations, making it difficult to assess the progress made by the convolutional operator. This paper adopts simple baselines to better evaluate the performance gain from PAConv.