Learning a discriminative and generalizable metric for computing distances between images is a fundamental problem in computer vision. This metric serves as the foundation for various tasks, including face clustering, person re-identification, and image retrieval. The objective of metric learning is to compress samples from the same class while maintaining a margin between different classes in the learned metric space. However, existing ensemble-based deep metric learning methods compromise metric discriminativeness to improve generalization ability. In this paper, we propose a Deep Compositional Metric Learning (DCML) framework that addresses this issue. Instead of imposing contradictory constraints on sub-embeddings, we propose applying losses on different composites constructed from these sub-embeddings. We learn adaptive compositors that effectively re-weight the sub-embeddings and guide them towards better generalization. The discriminative constraints are imposed on the concatenation of sub-embeddings to maintain discrimination ability. Our DCML framework can be trained efficiently in an end-to-end manner and requires no additional resources for testing. Experimental results on the CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the competitive performance of our proposed framework.