Predicting the future motion of a dynamic agent is crucial for self-driving robots and vehicles to conduct path planning and collision avoidance. However, this prediction task is challenging due to the uncertainties involved, including the agent's intention, the static environment, and interaction with other agents. These uncertainties result in multiple plausible trajectories that the agent can take. To address this, a prediction model should suggest more than one plausible trajectory samples that follow the distribution for the given situation. Deep neural networks (DNN) are well-suited for this task, but their intermediate logic is often not interpretable, limiting human intervention. This can lead to inefficient sampling of trajectories. This paper aims to address these limitations by proposing a model that extracts and represents multiple cues efficiently. The proposed model combines previous work in interaction modeling, static scene processing, and multi-modal trajectory modeling. The model's interpretability allows for explicit conditioning on specific factors, enhancing prediction accuracy. The effectiveness of the proposed model is evaluated through experimental results. Overall, this paper contributes to the development of more accurate and interpretable prediction models for self-driving robots.