This paper introduces Soft-IntroVAE (S-IntroVAE), a modified version of the original IntroVAE that utilizes the evidence lower bound (ELBO) as a discriminatory signal and does not require a hard-margin threshold. The goal is to improve the stability of the introspective training paradigm. The theoretical analysis shows that S-IntroVAE converges to the true posterior, maintaining the inference capabilities of the VAE framework. It also reveals that the S-IntroVAE model converges to a generative distribution that minimizes a sum of KL divergence from the data distribution and an entropy term, unlike GANs. The practical implications of this result are analyzed, and it is shown that S-IntroVAE produces high-quality generations from a distribution with a sharp support. Additionally, S-IntroVAE is more stable than IntroVAE and is rigorously validated through experiments. The paper also demonstrates the application of S-IntroVAE to unsupervised image translation, showing its capability of transferring content between images without supervision. Overall, the contributions of this paper include proposing S-IntroVAE, providing a deeper theoretical understanding of introspective VAEs, demonstrating robust training, showcasing high-quality image synthesis, and applying the model to unsupervised image translation.