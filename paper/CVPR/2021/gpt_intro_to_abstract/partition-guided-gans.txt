Generative adversarial networks (GANs) have experienced great success in learning the distribution of observed samples. However, GAN training remains unstable, particularly when dealing with multimodal data distributions. This is problematic because real data is known to conform to such distributions. The development of improved GAN models, capable of stable training and generating high-quality images, has attracted significant interest in machine learning research. Two specific challenges in GAN training are mode collapse, where the generator fails to capture the full diversity of the data, and the mode connecting problem. The mode connecting problem occurs when the GAN generates samples from regions where the true data does not exist, due to the use of a continuous generator to approximate a distribution with disconnected support. Additionally, GANs are difficult to train because the discriminator often provides unreliable gradients. To address these challenges, this paper introduces an unsupervised space partitioner and trains a different generator for each partition. This approach reduces the risk of missing modes in the data distribution and mitigates mode connecting by allowing a mixture of generators to focus on different parts of the distribution. The space partitioner is designed to place disconnected data manifolds in separate partitions, achieved by learning semantic representations of images using contrastive learning methods. The partitioner also defines a distance metric between points in the data space and partitions, which is then used to guide each generator to its designated region. The effectiveness of the proposed method, called Partition-Guided Mixture of GANs (PGMGAN), is demonstrated through extensive experiments on various datasets. The results show that PGMGAN successfully recovers all modes and achieves higher scores in terms of Inception Score and Frechet Inception Distance than both supervised and unsupervised methods. The contributions of this paper include improvements over relevant baselines, an explanation of the loss and architecture design, a solution to the mode connecting problem, and practical guidance for each generator to produce samples from their designated regions. The paper also provides theoretical analysis, lower bounds, and guarantees on the effectiveness of the proposed approach. These findings have significant implications for improving GAN training and generating diverse and high-quality samples.