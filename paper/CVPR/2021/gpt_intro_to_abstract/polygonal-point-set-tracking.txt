Object mask tracking is a crucial task in visual effects (VFX), but it is time-consuming and labor-intensive. This paper addresses the problem of propagating object mask information through frames to reduce the need for manual rotoscoping. Existing propagation methods use different object representations, such as point, region, contour, and polygonal point set. However, each representation has limitations in describing the target object and its pixel correspondences. This paper focuses on polygonal point set tracking, which combines the object's position and shape information. The proposed method trains a network to learn progressive alignment of the point set between frames. It incorporates a local alignment module that uses recurrent neural networks (RNN) and multi-head attention (MHA) for accurate tracking. Additionally, the proposed method introduces a novel learning strategy using unsupervised learning and synthesized data to train the model without fully annotated data. The paper also presents a new evaluation dataset for polygonal point set tracking, named PoST, which includes annotations for point correspondences. Experimental results demonstrate the effectiveness of the proposed method compared to existing approaches. The contributions of this paper include the introduction of a learning-based point set tracking method with point correspondence, the design of a local alignment module, a novel learning strategy using unsupervised learning and synthesized data, and the creation of the PoST dataset for performance evaluation.