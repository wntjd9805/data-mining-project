In recent years, video processing has made significant advancements with the emergence of complex deep learning architectures based on 3D Convolutional Neural Networks (CNNs). These networks are trained using a specific number of input frames, typically ranging from 16 to 64 frames. However, these networks are expensive to train and deploy for inference tasks. To reduce inference time, previous works have proposed processing only certain parts of a video with a 3D CNN, either by training a second network or using a fixed scheme.While these approaches reduce the computational cost during inference, they increase training time and do not address the computational cost of the 3D CNNs themselves. This paper proposes an approach to make 3D CNNs more efficient for training and inference by dynamically adapting their computational resources. The researchers observed that the computational cost of a 3D CNN depends on the temporal resolution at each stage of the network. However, existing schemes that define how the temporal resolution is reduced are hard-coded and the same for all videos.To address this limitation, the paper proposes exploiting redundancy within temporal features to selectively process and select the most valuable and informative features for action classification. The proposed Similarity Guided Sampling (SGS) mechanism measures the similarity of temporal feature maps, groups similar maps together, and aggregates them into a single output feature map. This process dynamically adapts the temporal feature resolution of the network based on the redundancy of the input frames.The SGS mechanism is incorporated as an additional module within any 3D CNN and effectively converts it into a more efficient dynamic 3D CNN with adaptive temporal feature resolutions (ATFR). The approach is complementary to previous works and can replace the static 3D CNNs used in those approaches. The paper demonstrates the efficiency of 3D CNNs with adaptive temporal feature resolutions by integrating the SGS mechanism into state-of-the-art 3D CNNs such as R(2+1)D, I3D, and X3D.The results show that the proposed approach significantly reduces the computational cost of off-the-shelf 3D CNNs, decreasing GFLOPs by about half on average while maintaining or improving accuracy. The Similarity Guided Sampler plays a crucial role in real-world video-based applications where computational cost is a significant factor.