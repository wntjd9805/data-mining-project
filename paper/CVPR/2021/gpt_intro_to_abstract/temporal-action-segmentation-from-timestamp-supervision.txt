Analyzing and understanding video content is crucial for various applications, such as surveillance and intelligent advertisement. Previous approaches to video analysis rely on fully annotated videos, which require extensive time and effort to obtain. Additionally, inconsistencies between annotations from different annotators can arise due to the ambiguous boundaries between action segments. To address these challenges, weaker levels of supervision, such as transcripts or sets of actions, have been explored. However, the performance of these weakly supervised approaches is not satisfactory compared to fully supervised methods. This paper proposes the use of timestamp supervision for action segmentation, inspired by its success in action recognition. Timestamp annotations, which only require annotating one frame per action segment, provide more supervision than transcripts while still reducing annotation effort. The paper introduces an approach to train a segmentation model using all frames of the videos and identifies action changes by minimizing feature variations. A loss function is also introduced to ensure the model effectively uses all frames. The contributions of this work include the use of timestamp supervision for temporal action segmentation, a training approach based on timestamp supervision, and a novel confidence loss. The proposed approach is evaluated on four datasets, demonstrating its feasibility and comparable performance to fully supervised learning at a fraction of the annotation costs.