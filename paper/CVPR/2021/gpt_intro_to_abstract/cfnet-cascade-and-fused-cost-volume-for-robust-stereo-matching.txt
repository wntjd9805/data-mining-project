Stereo matching is used to estimate the disparity/depth map from a pair of stereo images, and it is crucial for various applications such as autonomous driving, robot navigation, and SLAM. Deep learning-based stereo methods have achieved impressive performance on standard benchmarks. However, these methods are often limited to specific datasets due to significant domain shifts. For real-world applications, it is necessary for stereo methods to generalize well across different scenarios without adaptation. The challenges in designing a robust stereo matching system stem from the large domain differences and unbalanced disparity distribution between datasets. In this paper, we propose a cascade and fused cost volume representation to address these challenges. We fuse multiple low-resolution dense cost volumes to capture global and structural representations, allowing the network to learn scene information that is invariant across datasets. Additionally, we employ a cascade cost volume representation and uncertainty estimation to adaptively adjust the disparity search range, effectively covering the disparity distribution of multiple datasets. Experimental results show that our method achieves state-of-the-art overall performance on three real-world datasets without adaptation. Our contributions include the fused cost volume representation and the cascade cost volume representation with uncertainty estimation. Our method demonstrates strong generalization ability and performs well in the Robust Vision Challenge 2020 stereo task. Furthermore, our method achieves excellent finetuning performance with low latency and ranks first on the popular KITTI 2015 and KITTI 2012 benchmarks among published methods with less than 200ms inference time.