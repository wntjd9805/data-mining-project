Visual recognition in computer science is currently based on empirical risk minimization (ERM), which assumes that the training and testing distributions are the same. However, in real-world scenarios, it is challenging to collect a representative and balanced dataset that covers all variations in factors such as background context or camera viewpoints. This leads to the learning of unstable spurious correlations that do not align with the underlying causal structure.This paper presents a method for learning causal visual features that improve the robustness of visual recognition models. The approach involves learning causal representations that can identify the causal mechanism between image features and category labels, enabling more accurate generalization. Traditional approaches to establish causality, such as randomized control trials or interventions, are not possible with passive collection of natural images.The proposed framework utilizes generative models to quantify nuisance variables, such as viewpoint and background, and constructs a causal graph that models both robust and spurious features in image recognition. The key aspect of the methodology is the ability to steer generative models to perform interventions on realistic images, simulating manipulations that remove spurious correlations caused by confounding factors. This approach is applicable to any state-of-the-art computer vision model, making it model-agnostic.Empirical and theoretical results demonstrate the effectiveness of the proposed approach in learning robust causal features. The method outperforms existing approaches by overcoming the limitations posed by spurious correlations. The contribution of this research is significant for improving visual recognition systems and enhancing their performance in real-world scenarios.