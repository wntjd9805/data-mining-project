Recently, Siamese networks have gained attention in the field of visual tracking due to their high speed and tracking performance. One popular method, SiamFC, uses Siamese networks and cross-correlation layers to compute similarity between a template and instances in video frames. Another method, SiamRPN, formulates the tracking problem as one-shot detection using a region proposal network (RPN) and up-channel cross-correlation. However, SiamRPN suffers from imbalanced parameter distribution, making training optimization difficult. To address these issues, SiamRPN++ introduces a depth-wise correlation (DW-XCorr) method to efficiently generate a multi-channel correlation feature map. Despite the success of DW-XCorr and its predecessor XCorr in Siamese trackers, both methods have limitations in terms of producing similar responses for target and distractors of homogeneous appearance, only activating a few channels, and often producing responses at irrelevant background. In this paper, we propose a new module called asymmetric convolution (ACM) that overcomes these limitations. The ACM allows feature maps of different sizes to be concatenated efficiently, produces more discriminative features, and suppresses background, leading to more robust predictions. We validate the effectiveness of ACM through extensive experiments on tracking benchmarks, showing significant improvements in performance compared to existing methods.