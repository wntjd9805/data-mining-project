Recently, zero-shot learning (ZSL) has gained attention in machine learning and computer vision. ZSL aims to recognize unseen-class samples using labeled seen-class samples and semantic features of both seen and unseen classes. An important aspect of ZSL is learning the mapping between visual and semantic features for the unseen-class domain.Existing ZSL methods can be categorized into inductive ZSL (I-ZSL) and transductive ZSL (T-ZSL) methods. I-ZSL methods only use labeled seen-class samples for training, while T-ZSL methods also incorporate unlabeled unseen-class samples. However, I-ZSL methods often suffer from the domain shift problem, where the model learned from the seen-class domain may not generalize well to the unseen-class domain. On the other hand, T-ZSL methods partially alleviate the domain shift problem but still face challenges in effectively utilizing the unlabeled unseen-class samples.To address this problem, this paper investigates the prediction accuracies of unseen classes using popular I-ZSL methods on a public dataset. The authors find an uneven prediction phenomenon, where some unseen classes are harder to classify compared to others. This observation leads to three key findings: (1) samples from "hard" classes are more effective in improving the performance of a ZSL method compared to "easy" classes, when unseen-class samples are available for training; (2) the predicted pseudo labels of hard classes are less noisy than those of easy classes; (3) the diversity of hard classes benefits the overall performance of a ZSL method.These findings provide insights into the roles of unseen-class samples with varying levels of classification hardness in the training process of ZSL methods. By understanding the impact of different unseen-class samples, this research aims to improve the effectiveness of utilizing unlabeled unseen-class samples for training in T-ZSL methods.