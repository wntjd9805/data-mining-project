Stereo-based 3D reconstruction is a popular technique but is limited by the trade-off between imaging volume and noise. To maintain a large imaging volume with sharp texture features, a narrow aperture is required, leading to a decrease in the total light level reaching the sensor. This makes it challenging to achieve large volume, high-quality, and high-resolution 3D reconstruction in light-limited environments. Increasing exposure duration or aperture size to increase light throughput can result in motion blur or a smaller depth of field, respectively. To address this, we propose CodedStereo, a technique that uses optimized phase masks in the aperture of stereo cameras. These masks allow for a larger aperture size while maintaining a depth-dependent focal blur. Our learned phase masks not only enable more accurate depth estimation but also produce sharper RGB images with extended depth of field for downstream applications. We optimize the reconstruction algorithms and phase masks using an end-to-end learning framework. Our contributions include the introduction of CodedStereo, the development of an end-to-end learning framework, and the demonstration of its performance benefits through simulation and a prototype system.