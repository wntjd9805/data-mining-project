Abstract:Semantic segmentation is a key problem in computer vision, involving the assignment of labels to pixels in an image. While traditional convolutional neural networks (CNNs) have been used for semantic segmentation, they are limited in practical applications where the model needs to continuously learn new classes without retraining from scratch. This scenario, referred to as Continual Semantic Segmentation (CSS), presents challenges in terms of catastrophic forgetting and background shift. Catastrophic forgetting refers to the tendency of neural networks to forget previously learned knowledge when trained on new information, while background shift occurs when the background class contains pixels belonging to both future and old classes. In this paper, we propose a deep learning strategy called PLOP (Pseudo-label and LOcal POD) to address these challenges in CSS. PLOP leverages the old model by using a feature-based multi-scale distillation scheme to alleviate catastrophic forgetting and a confidence-based pseudo-labeling strategy to distinguish old class pixels within the background. We evaluate PLOP on multiple datasets and demonstrate significant performance improvements compared to state-of-the-art CSS methods. Additionally, we propose new scenarios to further assess the performance of CSS methods in terms of long-term learning, class presentation order, and domain shift, and show that PLOP outperforms other approaches in these scenarios. Overall, our contributions include the introduction of a multi-scale spatial distillation loss to preserve knowledge during continual learning, a confidence-based pseudo-labeling strategy to handle background shift, and the demonstration of PLOP's superior performance in both existing and new CSS scenarios.