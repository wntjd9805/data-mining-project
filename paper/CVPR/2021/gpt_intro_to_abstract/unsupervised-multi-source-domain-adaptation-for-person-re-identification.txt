Person re-identification (re-ID) is the task of identifying a specific person across different cameras. While supervised methods have shown impressive results, they suffer from performance degradation when tested on unseen datasets. Unsupervised domain adaptation (UDA) for person re-ID has gained attention as a solution to this problem. Pseudo-label-based methods have dominated the state-of-the-art UDA person re-ID methods but often only use limited data from a single-source domain, which wastes abundant labeled data resources. To address this, we introduce the concept of multi-source UDA person re-ID, utilizing multiple source datasets in both model pre-training and fine-tuning stages. However, combining different datasets brings limited improvement due to domain gaps caused by differences in color, illumination, camera views, etc. In this paper, we propose addressing the domain gap problem from two perspectives: domain-specific view and domain-fusion view. We introduce a rectification domain-specific batch normalization (RDSBN) module that captures and reduces domain-specific information to enhance feature distinctiveness. We also develop a GCN-based multi-domain information fusion (MDIF) module to reduce domain distances by fusing feature distributions. Unlike previous GCN-based methods, our MDIF module focuses on reducing domain gaps and incorporates a domain-agent-node concept for information propagation and fusion. The contributions of this work are three-fold: 1) Introducing the multi-source concept to UDA person re-ID, pioneering research in the community. 2) Proposing the RDSBN module to simultaneously reduce domain-specific information and improve the distinctiveness of person features. 3) Developing the MDIF module to pull different domains closer in feature space and shedding new light on the use of GCN for reducing domain gaps.