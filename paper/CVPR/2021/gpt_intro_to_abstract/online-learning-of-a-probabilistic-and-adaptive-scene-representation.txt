Simultaneous Localization and Mapping (SLAM) has become important in the field of Spatial AI, as it allows mobile devices to perceive their surroundings and estimate sensor states. As SLAM systems evolve to offer spatial perception, there is a growing need for a more expressive map that can distill information from various data types into a compact parameter space. This paper aims to address this need by proposing a continuous probability field as a map representation using a Bayesian nonparametric mixture model. The proposed representation can be applied to different spatial representations like point clouds, occupancy grids, and meshes. It offers probabilistic quantification of uncertainties and allows for the incorporation of information from different sensor inputs in a unified manner. The nonparametric property of the model guarantees adaptive complexity with respect to acquired data scale, while maintaining a compact and expressive representation. The mapping problem is formulated as an online Bayesian learning problem, where the map is a generative process of observations and acquired streaming data is used for incremental learning. The incremental inference is performed in a parallel and incremental manner, allowing for efficient inference of accurate scene geometry. The contributions of this paper include the novel scene representation using the Bayesian nonparametric mixture model and a principled approach to online Bayesian learning for efficient map updating. The proposed method achieves high-quality scene representation incrementally and demonstrates state-of-the-art results in qualitative and quantitative experiments.