Diabetic retinopathy (DR) is a serious complication of diabetes that can result in vision impairment and blindness. Currently, DR severity is assessed by ophthalmologists based on the type and number of associated lesions in fundus images. Deep learning models have been proposed for automatic DR diagnosis, but they require manual annotation of images by experts. Additionally, most existing methods treat DR grading and lesion discovery as separate tasks, and rely on lesion annotations for learning. In this paper, we present a novel lesion-aware transformer (LAT) model that simultaneously performs DR grading and lesion discovery. The LAT model incorporates a pixel relation based encoder and a lesion filter based decoder. The encoder uses a self-attention mechanism to capture pixel correlations, while the decoder learns lesion-aware filters through cross-attention and self-attention modules. To overcome the challenges of weak supervision, we introduce mechanisms for lesion region importance learning and lesion region diversity learning. Experimental results on benchmark datasets demonstrate that the LAT model achieves superior performance compared to existing methods for DR grading. This work contributes to the advancement of automatic DR diagnosis and lesion discovery, offering a unified deep learning framework for accurate assessment of DR severity.