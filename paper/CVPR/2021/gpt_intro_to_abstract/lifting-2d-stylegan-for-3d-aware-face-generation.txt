In this paper, we introduce a framework called LiftedGAN for 3D-aware face image generation. While existing generative models have been successful in generating high-quality 2D images, they lack direct manipulation control over semantic attributes such as pose and expression. Our approach leverages a pre-trained StyleGAN2 model and distills the 3D-awareness into the generator. This not only allows us to generate realistic face images but also provides control over parameters such as view points, light direction, and 3D information like surface normal map. We demonstrate the superiority of our approach in preserving identity and generating high-quality images through qualitative and quantitative evaluations. The main contributions of this paper include the LiftedGAN framework, a self-supervised method for disentangling and distilling 3D information, and a generator that enables explicit control over pose and lighting.