Drones equipped with cameras are increasingly used for video surveillance in various applications, including crowd control and public safety. Automatic density map estimation, counting, and tracking in crowds captured by drones have become important tasks, but they face challenges such as view point and scale variations, background clutter, and small scales. However, the development and evaluation of these algorithms for drones are hindered by the lack of publicly available large-scale benchmarks specifically designed for drone-based crowd counting and tracking.To address this gap, we introduce the DroneCrowd dataset, a large-scale collection of drone-captured video clips across different cities in China. This dataset includes over 4.8 million head annotations and various video-level attributes, making it the largest and most thoroughly annotated dataset for density map estimation, localization, and tracking to date.To handle this challenging dataset, we propose the Space-Time Neighbor-Aware Network (STNNet), which simultaneously solves density map estimation, localization, and tracking tasks. STNNet consists of four modules: a feature extraction subnetwork, density map estimation heads, a localization subnet, and an association subnet. The feature extraction subnetwork extracts multi-scale features using two-branch CNNs and computes correlations between consecutive frames to exploit temporal relations. The density map estimation heads estimate object density in video frames for crowd counting, while the localization subnet accurately outputs target locations. The association subnet predicts motion offsets for tracking by considering the temporal consistency of targets.To exploit spatial-temporal context, we introduce the neighboring context loss, which penalizes large displacements of relative positions of adjacent objects in the temporal domain. This loss guides the association subnet to generate accurate motion offsets. The entire network is trained end-to-end using a multi-task loss and Adam optimizer. Additionally, we evaluate the effectiveness of the proposed STNNet method using state-of-the-art algorithms on the DroneCrowd dataset, demonstrating its performance in density map estimation, crowd localization, and tracking tasks.In summary, our contributions include the collection of a large-scale drone-based dataset and the proposal of an advanced network architecture for density map estimation, localization, and tracking. We also introduce the neighboring context loss to leverage spatial-temporal context for network training. Through extensive experiments, we validate the effectiveness of the proposed method on the DroneCrowd dataset.