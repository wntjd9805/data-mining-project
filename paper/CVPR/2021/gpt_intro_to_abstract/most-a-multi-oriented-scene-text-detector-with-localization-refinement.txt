Scene text reading has gained significant attention in the computer vision community due to its wide range of applications. Deep neural networks and large datasets have led to advancements in scene text reading techniques. However, challenges such as diverse shapes, orientations, scales, illumination, blur, and perspective distortion still exist, calling for improved methods. In this work, we focus on scene text detection and address the weaknesses of existing algorithms, particularly in detecting text instances with extreme aspect ratios. We propose a Multi-Oriented Scene Text detector (MOST) with localization refinement, incorporating a Text Feature Alignment Module (TFAM) and a Position-Aware Non-Maximum Suppression (PA-NMS) module. TFAM dynamically adjusts the receptive field for localization prediction, while PA-NMS merges detections based on positions to improve accuracy. Additionally, we introduce an Instance-wise IoU loss to enhance the detection of small text instances. Experimental results demonstrate the effectiveness of these strategies, with significant performance gains on various datasets. Our proposed method achieves state-of-the-art or competitive performance while maintaining a fast inference speed. The contributions of this paper include TFAM for receptive field adjustment, PA-NMS for refined detections, Instance-wise IoU loss for balanced training, and the development of MOST as a performant text detection system.