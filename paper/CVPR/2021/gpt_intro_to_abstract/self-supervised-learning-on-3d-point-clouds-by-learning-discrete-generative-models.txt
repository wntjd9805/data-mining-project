In recent years, self-supervised learning methods have emerged as effective alternatives to traditional supervised learning methods. These methods involve designing pretext tasks that generate their own supervisory signal, such as predicting or discriminating data augmentations that preserve input semantics. While self-supervised learning has shown success in domains like NLP and 2D computer vision, it remains relatively nascent in the field of 3D perception. This is partly due to the lack of a common representation for 3D data. Unlike NLP with word embeddings or 2D computer vision with images, 3D data lacks a universal and obvious data structure. Additionally, the lack of standardization in basic 3D data processing further compounds these challenges.This paper aims to address the need for self-supervised learning methods for 3D data by proposing a 3D representation learning method that is agnostic to specific data representations and neural network architectures. The method leverages the geometric nature of 3D point cloud data and can be applied to any off-the-shelf network architecture that outputs point-wise classification scores. The proposed method re-interprets these classification scores in the context of probabilistic geometric spatial partition assignments, effectively connecting the network architecture to the geometric nature of 3D point clouds.Instead of relying on per-point class labels for ground truth partition assignments, the proposed method generates "pseudo-labels" automatically from the data itself. This is achieved by learning the partitioning function itself to softly assign point clouds into geometrically coherent overlapping clusters. Unlike jigsaw tasks that destroy global geometry by randomly permuting voxels, the proposed pretext task maintains the original global geometry of the point cloud, thus preserving semantic information.Inspired by deep learning for point cloud registration, the proposed method utilizes a point cloud segmentation network to implicitly infer a latent generative mixture model. By calculating the data likelihood of the input point cloud with respect to the spatial density defined by the mixture model, the self-supervision becomes the likelihood of the discrete generative model.Overall, the proposed method offers a novel approach to self-supervised 3D representation learning that addresses the challenges posed by the lack of standardization in 3D data processing. It achieves this by leveraging the geometric nature of 3D point clouds and generating pseudo-labels based on probabilistic geometric spatial partition assignments. The effectiveness of the method is demonstrated through experiments and comparisons with existing approaches.