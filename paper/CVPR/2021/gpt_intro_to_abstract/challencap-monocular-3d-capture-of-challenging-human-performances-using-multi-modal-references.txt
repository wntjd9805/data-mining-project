Markerless human motion capture has made significant advancements in the past decade, benefiting applications like VR/AR experiences, sports analysis, and interactive entertainment. While multi-view solutions provide high-fidelity results, they require expensive studio setups and are not suitable for everyday use. Learning-based techniques allow for robust human attribute prediction from monocular RGB video. However, existing monocular human motion capture approaches struggle to capture challenging motions such as yoga or rolling on the floor, which involve extreme poses, complex motion patterns, and self-occlusion.Optical marker-based solutions like Vicon are widely used for capturing challenging professional motions, but directly integrating them into markerless capture is difficult due to temporal unsynchronization. Some data-driven human pose estimation approaches utilize unpaired references in an adversarial manner, but they fail to capture the characteristics of specific challenging motions. Previous work has proposed using markerless multi-view references to provide more robust 3D prior for monocular capture, but it is weakly supervised and lacks attention to combining references from both marker-based and multi-view systems.In this paper, we propose ChallenCap, a template-based monocular 3D capture approach for challenging human motions. Our approach outperforms existing state-of-the-art methods and embraces multi-modal references from both marker-based and markerless systems. We introduce a novel learning-and-optimization framework consisting of a hybrid motion inference stage and a robust motion optimization stage. The hybrid motion inference utilizes marker-based reference for accurate spatial characteristics and sparse multi-view reference for pairwise 3D motion priors. We also introduce a new challenging human motion dataset with unsynchronized marker-based and multi-image references.Overall, our contributions include the proposal of a monocular 3D capture approach for challenging human motions, a hybrid motion inference module for learning challenging motion characteristics, a robust motion optimization module for accurate tracking, and a new challenging human motion dataset.