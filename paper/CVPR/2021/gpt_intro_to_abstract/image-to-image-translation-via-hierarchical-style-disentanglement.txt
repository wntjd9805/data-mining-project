Abstract:Deep learning has shown promising results in image-to-image translation. Previous methods have focused on learning deterministic mappings between domains, which have led to challenges in translating inputs conditioned on multiple labels and generating diverse outputs with multiple styles. In this paper, we propose a novel framework called Hierarchical Style Disentanglement (HiSD) to address these challenges. We organize the labels into a hierarchical structure that includes independent tags and exclusive attributes. Specifically, we introduce different modules to generate, extract, and manipulate disentangled tag-relevant styles. We also employ cycle consistency and style consistency to guarantee realistic and accurate image manipulations. To ensure disentanglement, we use a local translator and a tag-irrelevant conditional discriminator. Our experimental results demonstrate the effectiveness of the proposed model. Our contributions include the establishment of HiSD, the design of modules and objectives to identify styles with tags, and extensive evaluation of our model.