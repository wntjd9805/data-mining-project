This paper introduces the concept of dynamic transfer for multi-source domain adaptation in computer science. The existing approach, known as static transfer, aims to learn a domain agnostic model that works well for all source and target domains. However, this approach can lead to a performance drop on each source domain due to domain conflicts. To address this issue, dynamic transfer utilizes a parameter predictor that changes the model parameters on a per-sample basis. By adapting the model's parameters statistically per sample, dynamic transfer simplifies the alignment between source domains and the target domain. This paradigm shift allows for a more elastic mapping and eliminates the need to pull all source domains together. The proposed dynamic residual transfer technique is shown to enhance domain adaptation performance significantly. Experimental results demonstrate that it outperforms state-of-the-art methods with a simpler loss function and training algorithm. Overall, dynamic transfer offers an effective solution for multi-source domain adaptation in computer science.