Deep learning has revolutionized computer vision tasks with its state-of-the-art performance. However, deep learning heavily relies on large labeled datasets, which are expensive and often not feasible to obtain, especially in domains requiring specialized expertise. Semi-supervised learning (SSL) offers a solution by leveraging partially labeled data, which is more readily available. This paper focuses on two critical problems in SSL: generalizing information from limited label data and directly learning from large amounts of unlabeled data. Several approaches have been developed, including Label Propagation and consistency regularization. The recently proposed MixMatch combines these techniques, introducing a unified loss function and the mix-up technique for increased generalization. Building upon MixMatch, ReMixMatch further improves SSL by introducing Distribution Alignment and Augmentation Anchoring techniques. This paper proposes the SimPLE algorithm, leveraging the relationship between different unlabeled samples through a novel Pair Loss. SimPLE generates pseudo labels for unlabeled samples, computes both supervised and unsupervised losses, and encourages consistency among variations of the same samples. Experimental results demonstrate the effectiveness of the proposed Pair Loss and SimPLE algorithm, outperforming state-of-the-art methods on standard benchmarks such as CIFAR100 and Mini-ImageNet. The algorithm also performs well on CIFAR10 and SVHN when applied to pre-trained models. Overall, this paper makes significant contributions by introducing a novel unsupervised loss term, developing the SimPLE algorithm, and demonstrating its effectiveness in various settings.