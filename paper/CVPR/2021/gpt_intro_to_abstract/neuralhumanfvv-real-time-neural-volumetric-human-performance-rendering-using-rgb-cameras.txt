The demand for 4D (3D spatial plus 1D time) content generation has increased with the rise of virtual and augmented reality (VR and AR). Reconstructing human activities and providing photo-realistic rendering from a free viewpoint has become an important technique. Early solutions required pre-scanned templates or significantly more time than is available for daily usage. Volumetric approaches have enabled real-time human performance reconstruction by leveraging RGBD sensors and modern GPUs. However, high-end solutions rely on expensive multi-view studio setups, while low-end approaches suffer from self-occlusion constraints and rely on depth cameras. Recent learning-based techniques have enabled robust human attribute reconstruction using only RGB input. However, these methods fail to generate compelling photo-realistic texture. Existing neural rendering techniques have the potential for photo-realistic novel view synthesis but rely on per-scene training or have difficulty achieving real-time performance. Few researchers have explored combining volumetric geometry modeling and photo-realistic novel view synthesis of human performance in a data-driven manner. This paper presents NeuralHumanFVV, a real-time human neural volumetric rendering system that uses only light-weight and sparse RGB cameras. The approach generates high-quality geometry and photo-realistic texture of human activities in arbitrary novel views while maintaining real-time computation and a light-weight setup. A neural geometry generation scheme is introduced to reason about the underlying geometry, and a neural blending scheme maps the input adjacent images into a photo-realistic texture output in the target view. The paper presents a hierarchical sampling strategy, an efficient occlusion analysis, and blending weight learning. The approach also recovers the normal information in the target view and combines neural geometry generation and texturing blending into a multi-task learning framework. The contributions include presenting a real-time human performance rendering approach, proposing an efficient neural implicit generation scheme for fine geometry details, and introducing a novel neural blending scheme for high-resolution and photo-realistic texture results.