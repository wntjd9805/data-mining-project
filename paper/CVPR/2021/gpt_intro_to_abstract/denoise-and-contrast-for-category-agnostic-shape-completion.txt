Cameras that capture and render objects in 3D are increasingly common in smartphones, drones, robots, and cars. However, these 3D sensing technologies often produce incomplete point cloud data due to occlusions, transparency, reflections, or limitations in resolution and viewing angle. This incompleteness hinders the direct use of the object shape in various tasks such as robotic manipulation, scene understanding, autonomous driving, and augmented reality. Point cloud completion addresses this problem by estimating the complete geometry of the missing regions from partial observations. Previous approaches have focused on inferring new points from a latent representation of the partial input, resulting in reconstructions that tend to resemble generic average objects instead of the specific input instance. To improve the fusion of local and global features, researchers have explored various techniques such as surface modeling, skeleton representation, new pooling operations, and local refinement through point upsampling or adversarial training. However, these techniques have not been extensively tested with point clouds corrupted with multiple holes or with object categories unseen during training. In this paper, we propose a novel point cloud completion method called DeCo that combines local information from denoising and global information from contrastive learning. DeCo avoids the risks of genus-wise distortions and blends the predicted missing part with the incomplete input effectively. The architecture of DeCo utilizes graph convolutions, which is a novel approach in point cloud completion. We conduct extensive experiments on ShapeNet dataset, demonstrating the effectiveness of DeCo in both single and multiple hole configurations, as well as on novel categories. Our results show that DeCo outperforms existing methods, establishing a new state-of-the-art in point cloud completion.