With the advance of deep convolutional neural networks (CNN), computer vision tasks such as image classification and object detection have seen significant improvement. However, directly applying these trained models to a new domain often results in performance degradation due to differences in data characteristics or distributions, known as domain shift. Unsupervised domain adaptation (UDA) aims to adapt the model trained on a source domain to a target domain without the need for annotation on target samples. Existing UDA methods focus on aligning the distributions of the source and target domains by minimizing the discrepancy between feature distributions or by adversarially learning to enforce indistinguishable feature representations. However, these methods lack efficient coordination between the optimizations of domain alignment and object classification tasks, resulting in inferior object classification performance. In this work, we propose a meta-learning based method called MetaAlign to address this optimization inconsistency. MetaAlign treats the domain alignment objective and the classification objective as two tasks in a meta-learning scheme, enforcing optimization coordination between them. Through theoretical analysis and extensive experiments, we demonstrate the effectiveness and applicability of MetaAlign in image classification and object detection tasks, achieving state-of-the-art performance.