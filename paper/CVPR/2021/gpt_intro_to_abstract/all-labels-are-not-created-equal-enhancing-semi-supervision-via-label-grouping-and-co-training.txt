Deep neural models require large amounts of labeled data for high performance, but labeling data is often expensive and impractical. Semi-supervised learning (SSL) has emerged as a way to leverage unlabeled data to learn from a smaller set of labeled data. In image classification, recent methods use unlabeled data for consistency regularization or pseudo-labeling. Combining these approaches has shown state-of-the-art results. However, pseudo-labeling often suffers from confirmation bias, where the model reaffirms wrong predictions, leading to accumulation of errors. Previous methods mitigate this bias through warm-up phases or limiting pseudo-labeled samples, but they do not consider prior knowledge about similarities among classes. In this paper, we propose exploiting class label semantics to account for class similarities. We use distributed embeddings based on knowledge graph embeddings or visual attribute annotation to group visually similar class labels. These embeddings improve pseudo-labeling quality and enable better SSL performance. Our co-training-based SSL method involves two classifiers, one using label grouping during pseudo-labeling and the other without. The classifiers learn from their disagreements through shared consistency regularization on unlabeled data. We demonstrate that our method outperforms state-of-the-art SSL approaches on five different datasets with smaller batch sizes and fewer training iterations. Our contributions include improving pseudo-labeling quality, introducing a co-training-based SSL method, and achieving significantly better results on five datasets, including a 5.6% improvement on Mini-Imagenet with limited labeled data.