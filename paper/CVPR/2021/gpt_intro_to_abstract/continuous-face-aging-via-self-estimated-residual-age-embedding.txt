Face aging, also known as age progression, involves rendering face images with natural aging effects while preserving identity information. Recent advancements in deep learning have improved image fidelity and age precision in simulated face images. However, challenges remain, such as the lack of data for continuous aging and maintaining individual aging patterns. Traditional face aging approaches include physical model-based and prototype-based methods, but these are limited in terms of data and personalization. Generative models like VAEs and GANs have been adapted for face synthesis, but continuous aging has not been explored extensively. Linear interpolation methods have been proposed, but they may result in a shift of target age and imperfect disentanglement of personal traits. To address these issues, we propose a novel approach that integrates a simple age estimator into an encoder-decoder architecture to achieve continuous aging. This allows for self-estimated age embeddings and personalized age embeddings without manual selection of anchor age groups. Our method considers both personalized residual age embedding and exemplar-face aging basis to generate images with better preservation of personalized information, accurate aging control, and fine-grained aging details. Extensive experiments on FFHQ and CACD2000 datasets demonstrate significant improvements over the state-of-the-art. The proposed approach can also be applied to other conditional image-to-image translation tasks.