In image classification, it is important for the output of a classifier to be invariant to small shifts in the image. Convolutional neural networks (CNNs) have traditionally been assumed to possess this property due to the use of convolutional layers that are shift equivariant, and non-linearities and pooling layers that progressively enhance stability to deformations. However, recent studies have demonstrated that CNNs are not actually shift-invariant. Azulay and Weiss have shown that a one-pixel shift in input images can result in a 30% probability of the output of a CNN trained for classification changing. This revelation challenges previous assumptions about the shift invariance of CNNs and highlights the need for further investigation and improvement in this area.