Abstract:Pedestrian detection is a crucial task in computer vision, with applications in various domains such as autonomous driving, video surveillance, action recognition, and tracking. Convolutional neural networks (CNNs) have shown significant progress in pedestrian detection, but current methods suffer from overfitting to source datasets, particularly in the context of autonomous driving. These detectors do not generalize well to target datasets, even when trained on relatively large-scale datasets closer to the target domain. This limitation hinders the scalability of pedestrian detection in real-world applications.Despite the importance of generalizable pedestrian detection, it has not received much attention in prior research. Moreover, the reasons for poor performance in cross-dataset evaluation have not been properly investigated. In this paper, we argue that the lack of generalization is mainly due to the bias of current detectors towards target datasets, as well as the sparse and non-diverse nature of the training sources.Since state-of-the-art methods rely on deep learning, their performance heavily depends on the quantity and quality of data. Existing autonomous driving datasets have limitations in terms of the number of unique pedestrians, low pedestrian density, and limited diversity. Recently, larger and more diverse datasets have been created by crawling the web and surveillance cameras, but they do not sufficiently cover autonomous driving scenarios.In this paper, we demonstrate that existing pedestrian detection methods underperform compared to general object detectors when provided with larger and more diverse datasets. We show that carefully trained general object detectors can significantly outperform pedestrian-specific detection methods on pedestrian detection tasks without any specific adaptation to the target data. We propose a progressive training pipeline that leverages general pedestrian datasets to improve the performance of pedestrian detection, particularly in the context of autonomous driving.We evaluate our approach on benchmark datasets such as Caltech and CityPersons, and demonstrate significant performance gains without fine-tuning on the target domain. These improvements hold true for different pedestrian detection families, including Cascade R-CNN, Faster RCNN, and embedded vision-based backbones like MobileNet.The rest of the paper is organized as follows: Section 2 reviews the relevant literature, Section 3 introduces the datasets and evaluation protocol, Section 4 presents our baseline benchmarking, and Section 5 tests the generalization capabilities of pedestrian-specific and general object detectors. We conclude the paper in Section 6.