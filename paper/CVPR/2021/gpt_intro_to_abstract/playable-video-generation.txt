This paper introduces the task of Playable Video Generation (PVG), which aims to learn distinct actions from real-world video clips in an unsupervised manner in order to allow users to interactively generate new videos. The proposed framework, named Clustering for Action Decomposition and DiscoverY (CADDY), utilizes an encoder-decoder architecture with a discrete bottleneck layer to obtain a discrete representation of transitions between frames. A reconstruction loss is used as the driving loss, eliminating the need for action label supervision or the precise number of actions. To address the challenge of capturing the stochasticity of real-world videos, an action network is introduced to estimate the posterior distribution of the action labels by decomposing them into discrete and continuous components. Experiments on various datasets demonstrate that CADDY can generate high-quality videos and provide a better playability experience compared to existing future frame prediction methods.