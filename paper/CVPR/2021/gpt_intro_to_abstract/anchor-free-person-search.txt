Person search has become a practical task in computer vision with applications in real-world scenarios. It involves localizing and identifying a target person from a gallery of scene images. To address this task, two fundamental tasks in computer vision need to be addressed: pedestrian detection and person re-identification (re-id). Previous efforts in this research area can be divided into two categories: two-step approaches that handle detection and re-id separately, and one-step approaches that unify detection and re-id in an end-to-end manner. Although one-step models can achieve satisfactory results, they inherit the limitations of two-stage detectors. In this paper, the authors propose an anchor-free framework called the Feature-Aligned Person Search Network (AlignPS) for efficient person search. The model employs an aligned feature aggregation (AFA) module to address issues of scale, region, and task misalignment in re-id feature learning. Experimental results show that the proposed model outperforms state-of-the-art one-step two-stage models on benchmark datasets while running at a higher speed. This work contributes to the development of an anchor-free solution for efficient person search, opening up avenues for future research in this direction.