Deep face recognition has greatly benefited from loss functions and large-scale labeled datasets. However, obtaining labeled data is time-consuming, while there is an abundance of unlabeled face data available. Several methods have been proposed to enhance face recognition performance using unlabeled data. However, in real-world scenarios, the unlabeled data often contains a large number of identities with very few images per identity, known as shallow face data. Existing semi-supervised learning methods do not work well in this situation. Clustering-based methods struggle to cluster shallow data, leading to errors such as samples from different identities being assigned to the same category or samples from the same identity being assigned to different categories. Another approach, Unknown Identity Rejection (UIR) loss, may converge into a trivial solution and learn identity-irrelevant features. Self-learning methods, which show promise in representation learning for object classification, cannot be effectively applied to aligned face data. In this paper, we propose VirFace, consisting of two components, VirClass and VirInstance, to address these challenges. VirClass enlarges the inter-class distance by incorporating unlabeled data as new identities, while VirInstance generates virtual instances sampled from the learned distribution of each identity. Our proposed VirFace method effectively utilizes unlabeled shallow data to learn a discriminative feature representation, improving the performance over supervised baselines. The main contributions of this paper are: (1) the introduction of a novel face recognition approach, VirFace, specifically designed for unlabeled shallow data, (2) the incorporation of VirClass and VirInstance to enlarge the inter-class distance and learn discriminative features, and (3) extensive experiments demonstrating significant performance improvement over supervised baselines in the unlabeled shallow situation compared to other unlabeled approaches.