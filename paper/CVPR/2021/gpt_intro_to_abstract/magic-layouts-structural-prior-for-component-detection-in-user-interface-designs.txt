This paper introduces Magic Layouts, a technique for parsing UI layouts into their individual components. The authors propose a deep learning method that leverages the spatial relationships between UI components to improve detection accuracy. By exploiting co-occurrence information, such as the relationship between a text input field and a button, the authors create a knowledge graph to boost the performance of detection algorithms. The proposed approach is tested on two publicly available datasets and shows improvements in detection for different modalities. The authors also develop an interactive tool called "Magic Layouts" that can parse UI layouts from sketches or screenshots, and incorporate sketch-based image search to replace sketched graphics with higher fidelity artwork.