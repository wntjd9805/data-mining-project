Instance segmentation is a crucial technique in the field of autonomous driving, and recent advancements have greatly improved its performance in both image and video processing. However, existing approaches heavily rely on dense annotations of instance segmentation masks and instance associations, which poses a significant challenge due to the labor-intensive nature of video annotation. To address this issue, self-supervised tracking methods have been developed that learn pixel-level video correspondences from large-scale unlabeled videos. While these methods are effective in tracking fine-grained attributes, such as segmentation masks, they do not discriminate between object instances. In this paper, we propose a novel semi-supervised setting where instance tracking is learned using only a labeled image dataset, along with optionally leveraging unlabeled video sequences. Our approach strikes a balance between fully-supervised and self-supervised learning, with the potential to significantly reduce the effort required for large-scale video dataset annotation. We introduce an Instance Contrastive (IC) objective that encourages the consistency of pixel-level feature embeddings within the same instance, while being less consistent for different instances. Additionally, we optimize a Maximum Entropy (ME) regularization to enforce a uniform distribution when instances are matched to each other. We demonstrate that our proposed method outperforms state-of-the-art approaches in both video instance segmentation and pose tracking tasks. Overall, our contributions include a novel semi-supervised setting, a feature embedding learning approach using only labeled images, a self-supervised video correspondence learning method using unlabeled videos, and an integrated framework for tracking masks of multiple instances.