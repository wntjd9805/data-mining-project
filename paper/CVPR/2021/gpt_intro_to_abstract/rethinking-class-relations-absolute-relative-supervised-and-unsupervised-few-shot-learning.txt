This paper introduces the concept of Absolute-relative Learning (ArL) for few-shot learning in computer vision tasks. While deep learning models have achieved high performance on various computer vision tasks, they heavily rely on large amounts of labeled training data. In contrast, humans are able to learn new visual concepts from only a few examples. The researchers propose ArL as a solution to train networks using only a few labeled training instances.ArL consists of two separate learning modules: Absolute Learning (AL) and Relative Learning (RL). AL focuses on learning to predict the actual object categories or class concepts, providing additional knowledge for the feature extracting network. RL, on the other hand, aims to learn similarity between image pairs using semantic annotations to capture realistic relations beyond binary similarity labels. Unlike existing few-shot learning approaches that use only binary similarity labels and pair-wise relation labels, the proposed ArL addresses two major problems. First, binary labels may not accurately represent the similarity between image pairs in real-world scenarios. Second, existing models discard explicit object classes despite their availability during training. ArL addresses these inconsistencies by exposing few-shot learners to both similarity and class labels.The paper also explores the use of attributes or word2vec embeddings for obtaining semantic relation labels. These labels are used as supervisory cues in relation learning to promote realistic soft relations between objects. By combining AL and RL, the proposed ArL simultaneously teaches the network class/object concepts and realistic class/object relations, resulting in improved accuracy.The approach also leverages interpretable features from the absolute and relative learners to promote original relation learning through feedback connections. The researchers note that their approach is different from multi-modal learning as it models semantic annotations in the label space, rather than combining multiple streams of data on network inputs.Furthermore, the proposed ArL can be extended to unsupervised few-shot learning by relying on augmentation labeling for training samples. This eliminates the need for additional labeling at the testing stage, making the approach more realistic than existing approaches.The contributions of this paper include the introduction of ArL for few-shot learning, the extension of ArL to unsupervised few-shot learning, an investigation of different similarity measures on attributes in real-world relation learning, and an analysis of the influence of different branches of absolute learning on classification performance. This comprehensive analysis of object and class relation modeling in the context of supervised and unsupervised few-shot learning using ArL is novel in the field.