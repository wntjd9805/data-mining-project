Generative adversarial networks (GANs) are widely used for image and video generation in both unconditional and conditional setups. However, the literature on transfer learning for generative adversarial models is limited compared to discriminative setups. Existing works have focused primarily on unconditional GANs, while the approach for conditional GANs remains unexplored. In this paper, we propose a method for efficient GAN transfer to new classes in pre-trained conditional GANs by learning the similarity between old and new classes using batch normalization statistics. Our method does not require access to the old data and achieves superior results in terms of generated image quality and convergence speed on benchmark datasets. These contributions fill the gap in knowledge transfer for conditional GANs and provide insights for future research in this area.