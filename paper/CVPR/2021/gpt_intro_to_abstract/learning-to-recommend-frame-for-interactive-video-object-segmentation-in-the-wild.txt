Video object segmentation is an important task in computer vision with various applications such as video editing and object tracking. However, collecting densely-annotated datasets for this task is expensive and time-consuming. To address this issue, a human-in-the-loop interactive video object segmentation (VOS) setting has been proposed, where users provide initial scribbles and gradually refine the segmentation masks. The current approach selects the frame with the worst segmentation quality for user annotation. However, this paper argues that the frame with the worst segmentation quality may not be the most valuable one for the refinement process. To determine the worthiness of a frame, this paper formulates the frame recommendation problem as a Markov Decision Process (MDP) and trains a recommendation agent using Deep Reinforcement Learning (DRL). The state space is narrowed down to the segmentation quality of each frame and the recommendation history. A segmentation quality assessment module is utilized to estimate the segmentation quality. Without any ground-truth information, the learned agent can recommend frames for annotation. To evaluate the generalization ability of the agent, a subset of the YouTube-VOS dataset is extended with initial scribbles. Experimental results demonstrate that the proposed recommendation agent outperforms baseline strategies on both the DAVIS dataset and YouTube-VOS dataset, regardless of the availability of ground-truth information. In summary, this paper shows that the frame with the worst segmentation quality is not necessarily the best choice for user annotation in interactive VOS. A deep reinforcement recommendation agent is proposed, which does not require ground-truth information and proves to be effective in various datasets.