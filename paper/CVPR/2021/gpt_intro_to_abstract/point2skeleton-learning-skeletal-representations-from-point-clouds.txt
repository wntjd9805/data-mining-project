Generating skeleton-based representations to capture shape structures is a common problem in computer vision and computer graphics. Skeletonization has been utilized in various applications including shape recognition, 3D reconstruction, segmentation, shape matching, and animation. Traditional methods for extracting shape skeletons have relied on hand-crafted rules or deep learning networks. However, these methods are limited to specific types of shapes with tubular parts and require watertight surface meshes. This restricts their applicability and effectiveness. In this paper, we propose an unsupervised method called Point2Skeleton for learning skeletal meshes from 3D point clouds. Our method overcomes the limitations of existing skeletonization methods by utilizing the medial axis transform (MAT) and deep neural networks. The MAT, unlike curve skeletons, provides a mathematical definition for arbitrary shapes and is more resilient to surface noise. By learning a generalized skeletal representation, we enhance the expressive capacity for the geometry and topology of 3D shapes. Our contributions include the development of Point2Skeleton as the first unsupervised learning method for point cloud skeletonization, novel formulations for geometric learning of 3D point clouds, and the introduction of the skeletal mesh representation which provides insights into unsupervised tasks for point clouds.