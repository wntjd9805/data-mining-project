Video super-resolution (VSR) is the task of generating a high-resolution (HR) video from a low-resolution (LR) observation. Deep learning networks have shown promising results in super-resolution, but they require significant computational resources which limits their deployment on resource-limited devices. On the other hand, compact VSR networks are easily deployable but lack the ability to model spatial-temporal correlations effectively. In this paper, we propose a new approach to VSR using knowledge distillation (KD) for the first time. By leveraging the knowledge of a more powerful teacher network, we train a compact student network to achieve performance similar to its teacher without increasing its inference time. Our method focuses on narrowing the performance gap between compact and complex models by introducing a space-time distillation (STD) scheme. We use space distillation (SD) to imitate the spatial attention maps of the teacher network and time distillation (TD) to enhance the temporal correlation and consistency. Through comprehensive experiments on benchmark datasets, we demonstrate that our proposed STD scheme improves the reconstruction quality and temporal consistency of VSR results without sacrificing inference efficiency. Our method shows promise in enabling effective and efficient VSR on resource-limited devices.