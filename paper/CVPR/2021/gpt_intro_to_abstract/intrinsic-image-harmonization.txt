In this paper, we address the problem of image harmonization in compositing tasks, where the visual appearance of the foreground and background images may be distinct due to different lighting and scene conditions. This often leads to inharmony between the two images, degrading the quality of the composite result. The inharmony problem is not only relevant to compositing tasks, but also affects various computer vision tasks such as image editing, inpainting, and stitching. Additionally, human visual system is highly sensitive to inharmonies in appearance, making image harmonization a challenging task.We propose a novel approach to image harmonization based on intrinsic image theory. The appearance of a natural image is dependent on various factors in the scene, such as illumination, material, and shape. Humans have the ability to estimate intrinsic characteristics of a scene, such as color, size, shape, and illumination, which allows them to distinguish composite images. We leverage the Retinex theory to separate the intrinsic characteristics of illumination and reﬂectance in the composite image, enabling separate harmonization.Our method formulates image harmonization as an autoencoder that internally disentangles the composite image into reﬂectance and illumination intrinsic images. For reﬂectance harmonization, we use material-consistency as a penalty cue to ensure harmonious foreground boundaries. For illumination harmonization, we design a lighting strategy to address the incompatibility between foreground and background illuminations. Moreover, we incorporate patch relations between foreground and background images to guide intrinsic image harmonization and ensure visually plausible composites.Our contributions include the proposal of a novel method that leverages intrinsic image theory for image harmonization. We introduce a lighting strategy and an inharmony-free learning approach to effectively address the inharmony problem in composite images. Our method achieves state-of-the-art performance on both synthesized and real composite datasets, and we also provide a new benchmark dataset, HVIDIT, for evaluating illumination harmonization.