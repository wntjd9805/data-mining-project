Object tracking is a challenging task in computer vision, and Siamese network based architectures have achieved state-of-the-art performance in recent years. These architectures use a Siamese network for feature extraction and a tracking-head network for object information decoding. However, current cross-correlation based trackers have some important drawbacks, such as pre-fixed convolution kernel size and global information matching that is not robust to rotation, pose variation, and occlusion. To address these issues, we propose a graph attention module (GAM) that enables part-to-part information embedding. The GAM facilitates adaptive information propagation and eliminates the drawbacks of traditional cross-correlation based methods. We also introduce a target-aware template computing mechanism to handle size and aspect-ratio variations. Our proposed Siamese Graph Attention Tracking (SiamGAT) network achieves leading performance on multiple challenging benchmarks, including GOT-10k, UAV123, OTB-100, and LaSOT. Our contributions include the GAM for effective part-to-part matching, the SiamGAT network for general object tracking that is adaptive to different objects, and the demonstrated superior performance compared to state-of-the-art trackers.