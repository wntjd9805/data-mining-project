Single image super-resolution (SR) involves recovering a high-resolution (HR) image from a low-resolution (LR) observation. Recent advancements in deep neural networks, specifically CNN-based methods, have made significant contributions to SR research due to their powerful feature representation capability. However, most existing CNN-based methods assume a known and fixed degradation model, which limits their performance when faced with real-world degradations that differ from the assumed model.To address the limitations of known degradations, several non-blind SR methods have been proposed. These methods assume a set of known degradations for training and rely on this prior knowledge during inference. While non-blind methods have shown promising results, they are sensitive to degradation estimation and often introduce artifacts due to estimation errors.In this paper, we present a novel approach to tackle the unknown degradation problem in SR. Instead of explicitly estimating the degradation from an LR image, we propose a degradation representation learning scheme based on contrastive loss. This unsupervised learning approach aims to distinguish the latent degradation from others, providing accurate degradation information for blind SR. The benefits of degradation representation learning are twofold: it facilitates the learning of abstract representations to distinguish different degradations, and it can be conducted in an unsupervised manner, making it suitable for real-world applications with unknown degradations.Our proposed method introduces an unsupervised degradation representation learning scheme for blind SR. We assume that the degradation is consistent within an image but can vary across different images, aligning with the general case in related literature. We leverage the similarity between patches within an image and dissimilarity between patches from different images in the degradation representation space. Additionally, we develop a degradation-aware SR network (DASR) that adapts to different degradations based on the learned representations. Our DASR incorporates degradation information by predicting convolutional kernels and channel-wise modulation coefficients. Experimental results demonstrate the effectiveness of our approach in handling various degradations and producing promising results for synthetic and real-world images under blind settings.