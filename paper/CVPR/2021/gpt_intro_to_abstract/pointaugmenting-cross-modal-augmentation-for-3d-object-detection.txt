This paper introduces a novel approach to advancing 3D object detection for autonomous driving by effectively fusing LiDAR and camera data. The challenge of 3D object detection lies in the misalignment between the two modalities. Previous approaches have explored different fusion schemes but are limited in performance or computationally expensive. In this work, the authors propose a cross-modal fusion method that directly augments LiDAR points with CNN features from images. They also address the issue of cross-modal data augmentation by proposing a simple yet effective method that maintains consistency between LiDAR points and camera images. The proposed method achieves remarkable improvements in performance compared to existing methods. The paper's contributions include exploring effective CNN features for fusion, proposing a cross-modal data augmentation method, and demonstrating the effectiveness of these approaches on large-scale datasets.