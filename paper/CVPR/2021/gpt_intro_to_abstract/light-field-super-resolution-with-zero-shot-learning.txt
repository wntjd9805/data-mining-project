The introduction of this paper discusses the importance of light field super-resolution (SR) in computer vision and the limitations of current light field cameras. The emergence of deep learning techniques has shown promising results for light field SR, but these methods face the challenge of domain shift, where the network trained on one dataset may not perform well on unseen light fields. This paper proposes a zero-shot learning framework for light field SR, inspired by a similar method in single image SR. The framework consists of three sub-tasks: pre-upsampling, view alignment, and multi-view aggregation. Through a divide-and-conquer strategy, the proposed framework can train an input-specific SR model without external light field datasets, and achieve impressive high-resolution results even with limited training data. The framework can also be further extended to finetune the pre-trained model on a source dataset. Overall, this work presents a novel approach for light field SR, which can address the domain gap and generate state-of-the-art results. Additionally, the zero-shot framework has the potential to inspire other inverse problems involving high-dimensional data acquisition with customized hardware.