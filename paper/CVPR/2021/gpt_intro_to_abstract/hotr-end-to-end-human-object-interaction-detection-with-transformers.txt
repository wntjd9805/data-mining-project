Human-Object Interaction (HOI) detection is the task of predicting a set of human, object, interaction triplets within an image. Previous methods have approached this task indirectly by first performing object detection and then associating human-object pairs. However, these sequential methods are time-consuming and computationally expensive. To address these limitations, recent research has proposed parallel HOI detectors that explicitly localize interactions using interaction or union boxes. These parallel detectors replace the neural network inference with simple matching based on heuristics. However, existing HOI detectors still suffer from the need for additional post-processing steps and limited exploration of high-level dependency between interactions. In this paper, we introduce HOTR (Human-Object interaction TRansformer), a fast and accurate HOI algorithm that predicts a set of human-object interactions in a scene using a direct set prediction approach. HOTR leverages an encoder-decoder architecture based on transformers to predict HOI triplets, eliminating the need for hand-crafted post-processing. The self-attention mechanisms of transformers allow the model to capture contextual relationships between humans, objects, and their interactions, enabling high-level scene understanding. We evaluate HOTR on two benchmark datasets, V-COCO and HICO-DET, and achieve state-of-the-art performance compared to both sequential and parallel HOI detectors. Additionally, HOTR significantly reduces inference time, making it much faster than previous parallel HOI detectors. Overall, HOTR contributes to the field by introducing a transformer-based set prediction approach in HOI detection, exploring the correlations between interactions, and proposing various training and inference techniques.