Motion planning in dynamic environments requires forecasting the imminent evolution of the scene. Traditional approaches use object-centric representations, obtained through object detection, tracking, and prediction modules. However, training these modules requires large amounts of manually annotated data, which is costly and time-consuming. To address this challenge, we propose an alternative freespace-centric representation for motion planning. Freespace is a natural cue for safe planning and can be easily obtained from LiDAR scans recorded by autonomous vehicles without the need for manual annotation. We present two approaches based on freespace-centric representation. First, we explore self-supervised learning for freespace forecasting, highlighting the key modeling choices for effective prediction. Second, we show that self-supervised future freespace predictions can be used to identify candidate plans that are likely to result in collision with objects. Additionally, we propose using future freespace as an additional source of supervision for learning to plan, which leads to safer and collision-free plans. Our contributions include the exploration of a self-supervised freespace-centric representation, the integration of self-supervised freespace predictions with existing planners, modifications to learning approaches for incorporating future freespace as self-supervision, and promising results on planning benchmarks.