Boundary representation (B-rep) models are widely used in commercial Computer Aided Design (CAD) software for describing 3D objects. However, the complexity of the data structures and the limited availability of labeled datasets have posed challenges for researchers. The segmentation of B-rep models based on learned patterns is of particular interest as it allows for the automation of laborious manual tasks in CAD, Computer Aided Engineering (CAE), and Computer Aided Process Planning (CAPP). This includes tasks such as model simplification and segmenting models based on manufacturing processes. Additionally, the loss of parametric feature history when exchanging models between CAD applications is an issue addressed by segmentation algorithms.While attempts were made in the 90s to apply neural networks to B-rep segmentation, progress was stalled due to the absence of machine learning frameworks and large labeled datasets. In this paper, we introduce BRepNet, a neural network architecture designed specifically for operating directly on the faces and edges of B-rep data structures, taking advantage of their topological relationships. We also introduce the Fusion 360 Gallery segmentation dataset, consisting of over 35,000 3D models in different representations with segmentation labels revealing the modeling operations used.The BRepNet approach leverages the observation that convolutional neural networks for image processing operate on pixels with known locations within the filter window. A similar arrangement can be achieved with B-reps, where neighboring entities can be identified at well-defined locations relative to each coedge. Feature vectors can be extracted from these entities and concatenated, allowing convolution to be performed as matrix/vector multiplication. Specific entities relative to each coedge map to learnable parameters in the convolutional kernels, enabling the recognition of patterns in the input data.The key contributions of this paper are the introduction of BRepNet, the publication of the Fusion 360 Gallery segmentation dataset, and experimental results demonstrating the effectiveness and efficiency of B-rep data in solving the segmentation problem compared to point cloud and mesh representations.