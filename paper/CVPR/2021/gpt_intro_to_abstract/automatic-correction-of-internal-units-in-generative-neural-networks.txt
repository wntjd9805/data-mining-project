Generative Adversarial Networks (GANs) have shown remarkable progress in generating high-quality images that are difficult to distinguish from real samples. Despite their success, GANs still suffer from the production of unrealistic regions, known as artifacts, which hinder their applicability in mission-critical domains. This paper aims to address this issue by investigating the cause of artifact generation and proposing solutions to improve overall quality.Previous methods have attempted to remove artifact areas by perturbing latent codes or identifying defective units based on human annotation. In this work, we propose a new approach that employs a classifier trained on annotated samples to identify defective units. Additionally, we utilize an explanation map to devise a global multi-layer artifact unit ablation scheme, which enhances the quality of defective generations while preserving plausible ones.Our approach involves annotating randomly sampled generations as normal or artifact, training a classifier on these annotated images and real images, and generating an estimated mask for defective regions using an explanation method. Defective units are identified by measuring the alignment between the activation of individual internal units and the segmentation mask of defective regions. To correct artifact areas, we ablate units with the highest overlap score. The contributions of our work include the compilation of a large dataset of flawed generations, an analysis of artifact generations, the identification of defective units using intersection-over-union (IoU), and a proposed artifact removal method through global unit ablation. We further enhance our approach by sequentially ablating defective units across consecutive layers.In conclusion, this paper presents a comprehensive study on artifact generations in GANs and offers a novel approach for identifying and correcting defective units. Our proposed method improves the quality of artifact samples while maintaining normal samples without the need for retraining.