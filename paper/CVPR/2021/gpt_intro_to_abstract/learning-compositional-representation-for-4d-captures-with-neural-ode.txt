This paper introduces a novel deep compositional representation for 4D object dynamics in the field of shape representation in 3D computer vision. The representation disentangles input point cloud sequences into semantically meaningful representations in three latent spaces: geometry template, initial state, and temporal deformation. The deep representation for deforming 3D objects over time is missing in the literature, making this work a pioneer in the field. The paper proposes an encoder that takes a 4D capture as input and produces latent codes representing the three key factors: identity, initial body pose, and motion. A novel architecture is designed to reconstruct 4D captures by using the latent codes as inputs. The geometry template code remains unchanged over time, while the initial state code is updated conditioned on the deformation code using a conditional latent Neural ODE. The reconstructed implicit occupancy field recovers the 3D shape over time. The paper proposes a training strategy that swaps geometry template codes from two different subjects to enable the encoder to decouple the geometry template and deformation. The training is fully supervised by synthetic data generated using a parametric model. The paper demonstrates the effectiveness of the proposed representation and decoder in 4D reconstruction, motion transfer, and 4D completion. The results show an improvement over state-of-the-art methods. The contributions of this paper include the design of the deep representation, the novel decoder, and the training strategy, as well as the demonstration of the performance in various applications.