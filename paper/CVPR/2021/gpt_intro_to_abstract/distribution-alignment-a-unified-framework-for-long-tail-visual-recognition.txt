Deep convolutional networks have achieved remarkable success in various vision tasks but typically require a large number of training examples for each visual category. Previous research has primarily focused on learning from balanced datasets where object classes are evenly distributed. However, many large-scale vision recognition tasks involve datasets with long-tail class label distributions, where the number of training instances per class varies significantly. This poses challenges for recognition in the wild, as the performance of naive models is often dominated by head classes while being degraded for tail classes.Early attempts to address imbalanced data distribution focused on one-stage learning models with limited success. More recent efforts have explored a two-stage strategy, separating representation learning and classifier head learning, to improve long-tail prediction. However, such approaches often rely on heuristic design and necessitate tedious hyper-parameter tuning, limiting their ability to handle imbalanced training data and balanced evaluation metrics mismatch.In this paper, we perform an ablative analysis of the two-stage learning strategy to identify its performance bottleneck. We discover a substantial performance gap between this strategy and an 'ideal' classification accuracy achieved by training the classifier head on a balanced dataset while keeping the representation fixed. Based on these findings, we propose a simple yet effective two-stage learning scheme for long-tail visual recognition problems.Our approach focuses on improving second-stage training of the classifier by developing a unified distribution alignment strategy. This strategy calibrates the classifier output by matching it to a reference distribution of classes that favors balanced prediction. We leverage class prior and data input in a principled manner to learn the class decision boundary, eliminating the need for extensive hyper-parameter tuning. Our approach includes a lightweight distribution alignment module comprising an adaptive calibration function for flexible and confidence-aware alignment and a generalized re-weight design for incorporating a balanced class prior.We extensively validate our model on four typical visual recognition tasks, including image classification, semantic segmentation, object detection, and instance segmentation. Experimental results demonstrate the superiority of our method over state-of-the-art approaches on all benchmarks. In summary, our contributions include an empirical study on the performance bottleneck of long-tail recognition, a simple and effective distribution alignment strategy, and state-of-the-art performance on various long-tail recognition tasks.