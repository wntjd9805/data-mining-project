Deep neural networks (DNN) have achieved significant advancements in computer vision tasks such as classification, object detection, and segmentation. However, these achievements rely on the assumption of identical distributions between the training dataset and application scenarios, which is often impractical to satisfy in real-world situations. Unsupervised domain adaptation (UDA) provides an alternative solution to the performance degradation caused by domain distribution mismatch without the need for annotations on the target domain. In this paper, we investigate the transferability of a model from a model-level explanation perspective in the training process. We divide the weights and gradients of a model into two separate directions: domain-invariant and domain-specific. The former emphasizes consistency between different domains for high-level tasks and plays a crucial role in the transferability of a model, while the latter hinders transferability as it represents unique features within a specific domain. Our goal is to promote transferability by learning the domain-invariant weights while eliminating the domain-specific ones.Current research in UDA aims to align the distribution of features extracted by the model through auxiliary objective functions that measure the discrepancy between domains. However, aligning the combinations of domain-specific and domain-invariant parts does not guarantee consistency in the domain-invariant parts themselves. This misalignment between domain-invariant parts and the presence of domain-specific parts leads to inefficiency or ineffectiveness, especially in complex tasks such as object detection.To address this issue, we propose a novel domain-specific suppression (DSS) method for domain-invariant alignment. We estimate the domain-specific part of the gradients by projecting it onto the direction of weights and impose constraints on the gradients in that corresponding direction. This estimation is based on the observation that the overall proportion of the domain-specific direction in weights is generally higher than that in gradients. By introducing constraints on the domain-specific direction, the gradients gradually converge to the domain-invariant optima. We also provide a simplified version of domain-specific suppression by normalizing weights with their 2-Norm, which reduces implementation complexity and allows for easy integration into any architecture. With domain-specific suppression, we remove a key barrier to domain adaptation tasks.We evaluate our method on the Faster RCNN framework with a ResNet-50 backbone on various datasets involving weather variance, camera configuration changes, and synthetically generated to real-world adaptations. We also conduct experiments using a model pre-trained on COCO2017 to highlight the importance of improving the model's discriminability through pre-training on large datasets in UDA detection tasks.