This paper focuses on the task of 3D object detection in real-world scenes using point cloud data. Traditional approaches either reorder point clouds into regular forms or rely on pre-defined shape templates, but recent methods such as VoteNet have achieved success by designing end-to-end 3D object detection networks based on raw point clouds. However, the quality of the regressed votes determines the reliability of the generated object proposals. This paper introduces a new approach called Back-tracing Representative Point Network (BRNet) that incorporates end-to-end learnable back-tracing and revisiting operations into the voting-based framework. BRNet generates representative points based on vote cluster centers and uses these points to revisit seed points, resulting in more accurate object proposals. Experimental results show that BRNet achieves state-of-the-art performance on benchmark datasets while maintaining a lightweight model size and high efficiency. The contributions of this work include the adaptation of Hough voting's back-tracing step to 3D object detection, an end-to-end learnable network for generative back-tracing and refining object proposals, and improved 3D object detection performance.