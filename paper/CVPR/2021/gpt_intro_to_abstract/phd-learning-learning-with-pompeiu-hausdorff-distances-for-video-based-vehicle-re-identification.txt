Vehicle re-identification (re-ID) is a critical task in urban operation, management, and security. It involves locating and recognizing a specific vehicle across multiple cameras in traffic intersections. While visual appearance-based vehicle re-ID has been extensively studied using still images, it is limited by visual ambiguities and the lack of spatial-temporal information. Video sequences, on the other hand, provide richer clues and are beneficial for identifying vehicles under complex surveillance conditions.However, there are two main challenges in video-based vehicle re-ID. Firstly, there is a lack of adequate quantity and high-quality video-based vehicle re-ID datasets. Existing datasets are constructed from sampled static images, leading to insufficient consecutive spatial-temporal information and oversimplified variations in viewpoint, occlusion, illumination, and resolution. This restricts the construction of reliable and robust appearance-based models. Secondly, an effective video-based vehicle re-ID method is needed to extract discriminative features from videos. While video-based re-ID benefits from rich spatial-temporal data, it also introduces difficulties in accurately matching video sequences, especially when dealing with occlusion.To overcome these limitations, this paper presents two key contributions. Firstly, a new video-based vehicle re-ID benchmark named VVeRI-901 is created. This benchmark captures vehicles in unconstrained real-world traffic intersections, providing diverse visual information in terms of viewpoint, resolution, and illumination. It also includes successive spatial-temporal information to enhance the robustness of appearance-based models and facilitate related research areas. Secondly, a set-to-set Pompeiu-Hausdorff Distance (PhD) learning method is proposed for video-to-video matching in re-ID tasks. This method automatically eliminates occlusion samples during the optimization process, improving recognition performance significantly.The main contributions of this paper include the creation of the VVeRI-901 benchmark, the proposal of the PhD learning method for video-based re-ID, and the verification of the method's superiority on video-based re-ID tasks. The proposed approach not only addresses the limitations of existing methods but also demonstrates promising results in both video-based vehicle re-ID and video-based person re-ID tasks.