Learning from labeled data has been a widely studied topic in the field of machine learning, and more recently in deep learning. However, supervised learning techniques heavily rely on the availability of massive amounts of annotated data. To overcome the difficulty and expensive cost of annotating data, research has focused on techniques that can learn with limited or completely non-annotated data. This has led to the proposal of semi-supervised and unsupervised learning methods, which have shown promising results compared to supervised learning methods. Despite these advancements, not much effort has been made to exploit prior knowledge from existing labeled datasets and use it to discover unknown classes that are not present in the labeled data.This paper addresses the problem of Novel Class Discovery (NCD), where a labeled dataset and an unlabeled dataset with different class label spaces are given. The goal of NCD is to learn a model that can cluster the unlabeled data by leveraging the latent commonalities from the labeled data. This task is different from semi-supervised learning, where the label space is shared between labeled and unlabeled data, and presents additional challenges.To tackle this problem, the paper proposes a holistic learning framework that utilizes contrastive loss formulation to learn discriminative features from both the labeled and unlabeled data. The framework introduces two key ideas: Neighborhood Contrastive Learning (NCL) and Hard Negative Generation (HNG). NCL exploits the fact that the local neighborhood of a sample in the embedding space will contain samples belonging to the same semantic category as the query, and brings the query closer to its pseudo-positives. HNG addresses the selection of negatives by generating synthetic samples in the feature space using a mixing strategy, effectively improving the contrastive learning.The contributions of this work are threefold: 1. The proposal of NCL for NCD, which significantly improves the clustering accuracy by recruiting more positive samples for the contrastive loss formulation.2. The introduction of HNG to aid contrastive learning by leveraging labeled samples to generate hard negative samples, resulting in consistent improvement.3. Extensive experiments on three NCD benchmarks demonstrate the effectiveness of the proposed method, surpassing state-of-the-art approaches by large margins.Overall, this paper presents a novel approach to address the problem of NCD and provides insights on how to leverage labeled data and improve clustering accuracy in the absence of annotated data.