This paper introduces a holistic scene understanding method that jointly optimizes the reconstruction of 3D human body meshes and static scene elements from single-view RGB images. The approach incorporates physical constraints and priors to obtain robust and physically plausible predictions. The proposed model outperforms state-of-the-art methods in 3D scene understanding and human pose estimation. The contributions include the development of a trainable model for joint reconstruction at the mesh level, the ability to produce high-quality mesh reconstructions without requiring ground truth annotations, and improved performance compared to previous methods. Experimental evaluation on PiGraphs and PROX datasets validates the effectiveness of the proposed approach.