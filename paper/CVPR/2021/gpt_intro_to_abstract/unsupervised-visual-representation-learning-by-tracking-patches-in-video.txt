This paper focuses on addressing the visual representation learning problem in computer vision by leveraging the way developing eyes learn in childhood. The authors propose a proxy task of tracking a moving target to guide a computer vision system in learning feature representations of visual signals in videos. This self-supervised video representation learning approach aims to make use of the large amount of video data available on the internet without requiring human annotation. The authors compare this approach to existing proxy tasks and demonstrate its effectiveness in capturing fine-grained information. They introduce a game called Catch-the-Patch (CtP) inspired by the training of human vision system, where a patch is cut from a video and its location and size in all input frames need to be predicted. The authors use the CtP game to pretrain two neural network models and evaluate their performance on action recognition and video clip retrieval tasks. Experimental results show that the CtP-pretrained models outperform existing methods and achieve high classification accuracy. The contributions of this work include the design of the CtP game, the introduction of the masked region model (MRM), and comprehensive evaluation of the proposed method, which bridges the performance gap between unsupervised and supervised video representation learning.