This paper focuses on the REVERIE task, which involves high-level natural language instructions for object grounding and navigation in visual environments. The current approach of integrating state-of-the-art navigation and object grounding models has limitations, as it does not consider the role of high-level natural language interpretation and common sense knowledge in navigation. To address this, the paper proposes a new agent that mimics human behaviors by first extracting high-level what and where information from the instruction and forming an overview of the target location. The agent is trained using a two-stage pipeline. In the first stage, two pre-training tasks, namely the Scene Grounding task and Object Grounding task, are introduced to recognize the best viewpoint and object that align with the instruction. Experimental results show improved performance compared to previous models.In the second stage, a memory-augmented attentive action decoder is proposed, leveraging a scene memory structure to enhance navigation capability under high-level instructions. Experimental results demonstrate the effectiveness of this approach, achieving state-of-the-art performance on the REVERIE task.Overall, the contributions of this paper include a new framework that integrates navigation and visual grounding by borrowing human intuitions, the introduction of novel pre-training tasks and a memory-augmented action decoder, and achieving improved performance on the REVERIE task.