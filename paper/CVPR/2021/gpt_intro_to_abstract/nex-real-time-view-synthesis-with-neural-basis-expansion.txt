Novel view synthesis is a challenging problem in computer vision and graphics that aims to construct visual scenes from sparse sets of images and render them from unseen perspectives. Current approaches, such as multiplane image (MPI), have limitations in accurately capturing complex scenes and view-dependent effects. Additionally, recent research on implicit scene representation has shown promise but lacks real-time rendering capabilities and struggles with high-fidelity surface reflectance. To address these limitations, we propose NeX, a new scene representation based on MPI that models view-dependent effects through basis expansion. Instead of storing static color values, NeX represents colors as functions of the viewing angle using a linear combination of spherical basis functions learned from a neural network. We also introduce a hybrid parameter modeling strategy for capturing high-frequency detail within an implicit MPI framework, resulting in sharper results in fewer training iterations.We evaluate our algorithm on benchmark datasets and compare it against state-of-the-art approaches such as NeRF and DeepView. However, these datasets primarily consist of diffuse scenes and simple view-dependent effects, limiting their ability to assess the full potential of our algorithm. Hence, we introduce the Shiny dataset, which features more challenging view-dependent effects like rainbow reflections and refraction through non-planar glassware. Our method achieves superior performance in terms of overall scores across all major metrics on these datasets, capturing accurate view-dependent effects and producing sharper results in real-time.Through quantitative and qualitative analysis, along with ablation studies, we validate the technical contributions of our method. Compared to the current state-of-the-art approach, NeRF, our method excels in capturing view-dependent effects and produces superior results in real time.