Generative Adversarial Networks (GANs) have achieved significant success in image synthesis. It has been observed that GANs can represent multiple interpretable attributes in the latent space, such as gender for face synthesis and lighting condition for scene synthesis. This discovery opens up possibilities for controlling the image generation process and enables various editing applications, like face manipulation and scene editing. However, interpreting the latent space of GANs is challenging due to its high dimensionality and diverse image semantics.Existing supervised approaches for interpreting the latent space rely on sampling latent codes and synthesizing images, which are then annotated with pre-defined labels to train a classifier. This process has several limitations, including the reliance on pre-trained classifiers and the time-consuming and unstable nature of sampling. Some recent studies explore unsupervised discovery of interpretable GAN semantics but require model training or data sampling.In this work, we propose SeFa (Semantic Factorization), a novel algorithm to discover latent semantic directions in GANs without the need for training or sampling. SeFa examines the relation between image variation and internal representations by analyzing the generation mechanism of GANs, specifically focusing on the initial projection step in the latent space. We develop a closed-form method that identifies versatile semantics using pre-trained generator weights. The discovered variation factors by SeFa are more accurate and cover a wider range compared to supervised approaches. Manipulation results using the discovered semantics demonstrate the effectiveness of our approach. We validate the efficiency and applicability of SeFa on popular GAN models trained on different datasets.