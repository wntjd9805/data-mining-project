In this paper, we propose a pre-trained model for image processing called Image Processing Transformer (IPT). The IPT model is designed using the transformer architecture and aims to be compatible with various image processing tasks, including super-resolution, denoising, and deraining. The network consists of multiple pairs of task-specific heads and tails, along with a shared body. To train the IPT model, we use the ImageNet benchmark dataset, which contains a diverse range of high-resolution images with 1,000 categories. We generate multiple corrupted versions of the ImageNet images to serve different tasks during training. For example, for the super-resolution task, we generate training samples by downsampling the original images. The IPT model is trained in an end-to-end manner, where the heads predict the original images with different output sizes according to the specific tasks. Additionally, we introduce a contrastive loss to capture the relationship between patches of different inputs, enabling the IPT model to adapt well to various image processing tasks. Experimental results on several benchmarks demonstrate that the pre-trained IPT model outperforms existing methods on their respective tasks after fine-tuning. Our work addresses the challenge of pre-training models for image processing tasks and offers a promising solution for improving the performance of low-level vision tasks.