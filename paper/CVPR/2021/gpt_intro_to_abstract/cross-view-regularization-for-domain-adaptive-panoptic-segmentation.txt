Panoptic segmentation is a task in computer vision that aims to assign both a semantic class and an instance ID to each pixel in an image. Traditionally, this task requires a large amount of annotated training images, which is costly and time-consuming. To address this constraint, synthetic images annotated by graphic software have been used, but they do not align well with natural images and result in performance drop when applied to real-world scenarios. In this paper, we propose a novel approach called Cross-View Regularization Network (CVRN) for domain adaptive panoptic segmentation. Unlike previous methods that treat semantic segmentation and instance segmentation as independent tasks, our CVRN design incorporates an inter-task regularizer that leverages the complementary relationship between the two tasks to improve performance. We also introduce an inter-style regularizer that leverages different styles of the same image as supervision to align features across domains. To handle the lack of annotations in the target domain, we predict pseudo labels using self-training ideas. Our contributions include the development of an effective cross-view regularization network for domain adaptive panoptic segmentation, the introduction of an inter-task regularizer and an inter-style regularizer, and extensive experiments demonstrating superior segmentation performance compared to state-of-the-art methods.