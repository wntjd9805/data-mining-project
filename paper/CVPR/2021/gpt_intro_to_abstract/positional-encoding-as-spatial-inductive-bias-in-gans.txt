This paper investigates the phenomenon of structured outputs in Generative Adversarial Networks (GANs) despite the expectation of position-agnostic outputs. The study reveals that the presence of zero padding in the generators of GANs leads to a spatial bias in feature maps, acting as an implicit positional encoding. This bias is unbalanced across the image space, resulting in inferior results at the center of the image. To address this issue, the paper explores two explicit positional encodings: the normalized Cartesian spatial grid and 2D sinusoidal positional encoding. These encodings provide a balanced spatial inductive bias and enable the generation of images with stable structures. The paper also introduces a multi-scale training strategy, called Multi-Scale training with PositIon Encodings (MS-PIE), which allows for high-quality multi-scale synthesis using a single generator. The contributions of this study include the revelation of the unintentional positional encoding caused by zero padding, the investigation of explicit positional encodings, and the development of a multi-scale training strategy for improved image generation.