Abstract:Person re-identification (ReID) has gained significant attention in academia and industry due to its potential applications. ReID aims to identify a person across different camera views. However, existing ReID models trained under the same domain often fail to perform well on new unseen target domains due to domain biases. To address this issue, unsupervised domain adaptation (UDA) and domain generalizable (DG) ReID methods have been proposed. UDA methods utilize unlabeled target data to fine-tune the model, while DG ReID methods learn a generalizable model from multiple source domains without using any target domain data. In this paper, we propose a novel approach called Relevance-aware Mixture of Experts (RaMoE) to improve the performance of DG ReID. RaMoE trains a domain-specific network for each source domain to leverage their discriminative characteristics. An adaptive voting network is then used to integrate these domain experts' features based on the relevance of the unseen target domain to the source domains. We introduce a decorrelation loss to encourage diversity among the domain experts and a relation alignment loss to ensure the aggregated features are as discriminative as the features extracted by the domain experts. Experimental results demonstrate that RaMoE outperforms state-of-the-art DG ReID methods. This work presents a novel mixture-of-experts paradigm for DG ReID, utilizing a voting-based mixture mechanism.