Datasets play a crucial role in the development of AI algorithms, especially in the field of computer vision. Convolutional neural networks (CNNs) have revolutionized vision tasks since the introduction of AlexNet in the early 2010s, which relied on a large dataset of manually labeled images from ImageNet. However, for low-level vision tasks like optical flow and stereo, manual labeling is difficult or impossible to obtain. Synthetic data have become essential for enabling deep models to perform well on such tasks. FlyingChairs, a large synthetic dataset, has shown impressive results in pre-training CNN models for optical flow. Despite the availability of more realistic datasets, none have outperformed FlyingChairs. This raises questions about the importance of realism in rendering training data. It remains unclear what principles make an effective optical flow dataset.To address these questions, this paper proposes a joint optimization framework that couples data rendering with model training. By formulating the generation of training data as an optimization problem, the rendering pipeline can be simplified to a 2D layered approach without manual labeling or 3D models. The motion and shape of each layer are randomly generated based on hyperparameters, which are optimized to improve model performance on a target dataset.Surprisingly, this simplified rendering pipeline proves to be effective in generating training datasets for optical flow. The recent RAFT model and the widely-used PWC-Net model, trained on the rendered data from scratch, consistently outperform models trained on FlyingChairs. By using only a few examples from the AutoFlow dataset with augmentation, lower errors are achieved on the Sintel dataset compared to using a large number of examples from FlyingChairs.An analysis of the rendered data reveals interesting properties, such as the motion statistics of AutoFlow not resembling those of the Sintel dataset and an underrepresentation of small motions. However, this abnormal distribution may be attributed to tiny motion having little impact on the overall error.The contributions of this paper include the introduction of a learning approach to render training data for optical flow, the superiority of the AutoFlow dataset over FlyingChairs in pre-training the RAFT model, significant performance gains for the PWC-Net model using AutoFlow, and a detailed analysis of important features for dataset generation in optical flow.