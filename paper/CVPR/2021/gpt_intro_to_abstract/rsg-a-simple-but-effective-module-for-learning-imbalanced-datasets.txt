Computer vision research has advanced significantly with the use of deep convolutional neural networks (CNNs) and high-quality datasets. However, many real-world scenarios involve imbalanced data distributions, where certain categories have a limited number of instances. To address this issue, generating new samples for rare classes during training has been proposed as a solution. However, existing methods have limitations, such as incomplete training or the introduction of class-relevant information from frequent classes. In this paper, we propose a fully parameterized generator called rare-class sample generator (RSG) that can be trained end-to-end with any backbone CNN. RSG directly uses variation information from samples of the same frequent class to generate new samples, resulting in more stable and reasonable outputs. Furthermore, RSG includes a module to eliminate frequent-class-relevant information, mitigating the aliasing problem. The effectiveness of RSG is demonstrated in a simple CNN architecture; however, it can be integrated into various network architectures. The proposed method offers a promising approach to address the challenges of imbalanced datasets in computer vision tasks.