Temporal localization is a crucial task in video analysis for computer vision. While there has been significant research on temporal action localization, the recent focus has shifted towards temporal language localization. This task involves localizing the moment in an untrimmed video that corresponds to a language query. However, there are still critical challenges that need to be addressed, including effectively modeling the visual-language alignment and accurately localizing the moment in the original video length. Existing approaches often process video and language sequences separately, leading to a loss of detailed semantics and limited interaction and alignment. Additionally, the representations used for moment candidates, such as full convolution, mean pooling, or RoI pooling, fail to capture the different stages within the moment accurately. Furthermore, convolution operations using all the elements in the moment candidate are unable to identify key elements for localization, and the fixed structure of the convolution kernel restricts adaptability to various dynamics. To overcome these problems, this paper proposes a multi-stage aggregated transformer network for temporal language localization. The network consists of a visual-language transformer backbone and a multi-stage aggregation module. The transformer backbone simultaneously processes video and language sequences, effectively modeling their fine-grained interactions and alignments. The multi-stage aggregation module computes stage-specific representations corresponding to different temporal stages, allowing for more accurate moment localization. The proposed network achieves superior localization performance and high efficiency in terms of speed. The main contributions of this work include the introduction of a visual-language transformer backbone that processes modality-specific contents and the development of a multi-stage aggregation module for accurate language localization. Extensive experiments on ActivityNet Captions and TACoS datasets validate the effectiveness of the proposed network. This research opens up new possibilities for future studies in temporal language localization using this novel architecture.