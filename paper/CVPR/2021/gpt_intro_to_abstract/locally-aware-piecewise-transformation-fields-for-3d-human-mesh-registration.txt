Human pose and shape registration from sensor inputs is a challenging problem in computer vision. Despite the availability of unstructured 3D point clouds, accurately registering these point clouds to parametric human shape models remains challenging, especially for clothed humans with arbitrary poses. Traditional approaches rely on temporal sequences of dense scans or manually enforced constraints, which limits their applicability to static point clouds. Recent advances in neural implicit functions have improved the accuracy of reconstructing human shapes from point clouds. However, most existing methods treat reconstructed human shapes as static objects and do not provide a way to register these shapes to parametric body models. This paper introduces a novel approach that estimates the pose parameters of parametric human models based on implicit representations and local point cloud features. The approach uses transformation functions, called Piecewise Transformation Fields (PTF), to transform query points from posed space to rest-pose space. Each body part is assigned a transformation function to calculate rigid bone transformations. By transforming query points into a canonical space, the occupancy learning/inference task is made easier. The proposed occupancy networks estimate the occupancy value, body part label, and corresponding position in rest-pose space for each point. Mesh surfaces of the human body, along with semantic part labels and corresponding positions in rest-pose, can then be extracted. The PTF approach also employs optimization-based registration, using point correspondences to initialize pose parameters accurately and improve the stability and accuracy of the registration process.The contributions of this work are three-fold: (1) the proposal of Piecewise Transformation Fields (PTF) for transforming arbitrary points from posed space to rest-pose space, (2) the combination of PTF modules with occupancy networks, achieving state-of-the-art results in clothed human reconstruction from point clouds while reducing the number of parameters, and (3) an alternative learning-based method for estimating joint rotations of the parametric SMPL model from point clouds, which produces more accurate and robust estimations compared to direct regression from global features. Experimental results show a significant reduction in registration error when fitting parametric models to implicit reconstructions using the estimated poses as initialization.The paper presents an overview of related works, reviews the fundamentals of the SMPL and NASA models, introduces the proposed PTF method and its application to joint rotation estimation, benchmarks the PTF model for registration and reconstruction, and concludes with discussions on possible future works. The code for the proposed approach is available online.