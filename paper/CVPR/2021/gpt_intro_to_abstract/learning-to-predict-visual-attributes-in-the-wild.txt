This paper introduces the problem of predicting visual attributes of objects in computer vision and image understanding. The correct grounding of objects with their visual attributes is crucial for various computer vision tasks such as image retrieval, tagging, visual question answering, and image captioning. Existing works on attribute prediction are limited in many ways, such as focusing on domain-specific attributes or small-scale datasets with label noise. This paper proposes a new large-scale dataset called Visual Attributes in the Wild (VAW), which includes positive and negative annotations for over 927K attribute-object pairs. The dataset addresses the challenges of large-scale attribute prediction and provides segmentation masks for 92% of the instances. The paper explores state-of-the-art methods and proposes a strong baseline model that considers low- and high-level features using multi-hop attention and partially available segmentation masks. Additionally, the paper describes techniques to address label imbalance and expand the number of negative labels using linguistic knowledge. A supervised contrastive learning approach called SCoNE is proposed, achieving significant improvements over state-of-the-art models in terms of mean average precision (mAP) and overall F1 score. The paper contributes by creating the VAW dataset, designing a strong baseline model, and demonstrating the effectiveness of the proposed techniques through extensive experimentation.