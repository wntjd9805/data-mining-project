In recent years, significant advancements have been made in object detection through improvements in feature representations, learning architectures, and large-scale datasets. However, the challenge of generalizing detection models to unseen domains remains, as these models often become biased towards dataset-specific patterns rather than data-invariant "common knowledge." While unsupervised domain adaptation methods have been proposed to transfer task knowledge from a source to a target domain, aligning knowledge transfer to the desired task objective is nontrivial due to variations in frequency patterns, visual styles, and class distributions between domains. To address this issue, a relaxed setting called cross-domain weakly supervised object detection has been explored, where the target domain images are assumed to be tagged with semantic labels. However, existing approaches still conduct knowledge adaptation globally at the domain level, neglecting the potential for local feature alignment and knowledge transfer. In this paper, we propose a novel approach for cross-domain object detection that embraces the weakly supervised setting and explicitly establishes pixel-wise semantic correspondences between each pair of cross-domain images for accurate local knowledge transfer. Our approach involves dividing each image into semantic clusters in a weakly supervised manner to explain the region annotations of the source domain image, under the cross-domain warping indicated by their correspondences. We train a cross-domain co-attention module to identify informative features on the target domain image for reconstructing the annotations of the corresponding source domain image. Simultaneously, a jointly trained mask generator competes to mask out the relevant target image region, discouraging informative correspondences. This competitive process encourages the correlation of underlying objects across domains. Additionally, to reduce the ambiguity of cross-domain matching, we propose a domain-cycle consistency regularizer that leverages intra-domain correspondence as robust self-supervision.The proposed approach achieves state-of-the-art results with consistent improvements over previous works, with 4% to 6% higher mean average precision on three datasets. Our contributions include the formulation of a novel approach that establishes explicit pixel-wise semantic correspondences across domains for accurate local knowledge transfer, the introduction of a domain-cycle consistency regularizer that provides robust self-supervision, and extensive experimental evaluations demonstrating significantly improved results on three benchmark datasets.