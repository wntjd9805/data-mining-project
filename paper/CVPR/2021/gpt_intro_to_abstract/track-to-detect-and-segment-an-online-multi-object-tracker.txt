Advanced online multi-object tracking methods can be categorized into two paradigms: tracking-by-detection (TBD) and joint detection and tracking (JDT). TBD treats detection and tracking as separate tasks, while JDT performs detection and tracking simultaneously in a single forward-pass. However, JDT methods often neglect the use of tracking cues in detection, and the common re-ID tracking loss is not compatible with detection loss in jointly training a single backbone network. In this paper, we propose a new online joint detection and tracking model called TraDeS (TRAck to DEtect and Segment). TraDeS tightly integrates tracking into detection within an end-to-end and unified framework. Two modules, the cost volume based association (CVA) module and the motion-guided feature warper (MFW) module, are introduced to achieve this. The CVA module constructs a cost volume to extract re-ID embedding features and infer tracking offsets for data association. The MFW module utilizes tracking offsets as motion cues to propagate object features between frames. By incorporating tracking cues into detection and implementing a dedicated re-ID learning scheme, TraDeS improves detection performance and tracking accuracy. Experimental results on multiple datasets demonstrate the effectiveness and efficiency of TraDeS, outperforming existing methods in 2D object tracking, 3D object tracking, and instance segmentation tracking tasks. Ablation studies further validate the effectiveness of the proposed approach.