Recently, deep face recognition with Convolutional Neural Networks (CNNs) has made significant progress due to the availability of large-scale training datasets. However, training models with millions of identities present challenges in terms of computational resources, specifically the need to train a fully-connected (FC) layer as the category classifier. This layer requires substantial computational consumption and can cause out-of-memory errors. Another paradigm, metric learning, addresses these drawbacks but suffers from inferior performance. This paper proposes a Virtual fully-connected (Virtual FC) layer to reduce the number of parameters by more than 100 times compared to the FC layer and achieve competitive performance. The Virtual FC layer splits training identities into groups and shares anchors between group members, significantly reducing parameters and memory requirements. Two novel anchor types, the corresponding anchor and the free anchor, are used to estimate the anchors adaptively. A re-grouping strategy is also introduced to eliminate anchor conflicts. Experimental results demonstrate the effectiveness of the Virtual FC layer in reducing parameters and achieving competitive performance in face recognition evaluation datasets. The contributions of this paper include proposing a solution to reduce parameters in the classification paradigm for training large-scale face recognition datasets with limited computational resources, introducing the Virtual FC layer, and demonstrating its compatibility with multiple GPUs and superiority over the metric learning paradigm in terms of performance.