This paper introduces a new type of adversarial attack called adversarial laser beam (AdvLB) in the context of deep neural networks (DNNs). The authors explore the idea of using a laser beam as a weapon to perform attacks on DNNs with the goal of causing misclassification. The proposed attack leverages the properties of light and does not require physically changing the target object, providing high flexibility for attackers to perform the attack from a distance. The authors conduct experiments to demonstrate the effectiveness of AdvLB in both digital and physical settings. They also analyze the prediction errors caused by the laser beam and identify two key factors: the laser beam's color feature altering the image and introducing dominant features of specific classes. The findings of this research open up new avenues for both attackers and defenders to better understand and manipulate this new type of attack. The contributions of this study include the proposal and evaluation of AdvLB, the demonstration of real-world threats with a simple laser pointer, and the analysis of prediction errors caused by the attack.