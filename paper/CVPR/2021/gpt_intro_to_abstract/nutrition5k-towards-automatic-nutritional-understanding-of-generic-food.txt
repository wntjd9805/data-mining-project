The introduction of this computer science paper discusses the importance of understanding and tracking the nutritional breakdown of the food we eat in order to make better dietary choices and improve overall health. It highlights the limitations of current tools for tracking nutritional content, such as tracking apps, which require manual entry of each ingredient and portion size. It also mentions the potential of using camera-based food logging to streamline the process. The paper addresses the challenge of estimating portion sizes and recognizing ingredients in generic food dishes, which are not part of a pre-determined set with known nutritional content. The scarcity and inaccuracy of available data for training computer vision models in this domain is also acknowledged. The paper proposes an alternative approach to dataset construction, involving incremental weighing, scanning, and logging of each item as it's added to a plate in real-world cafeterias. This approach enables the creation of the Nutrition5k dataset, which consists of real-world generic food dishes along with video captures, depth images, component weights, and high-accuracy nutritional information. The paper showcases the utility of this dataset by training deep convolutional neural networks (CNNs) to predict nutritional content from RGB images, achieving higher accuracy than a trained nutritionist's visual estimation. Additionally, the use of depth sensor data is shown to improve portion size predictions and nutrition regression accuracy.