Object detection is a crucial task in 3D scene understanding, providing meaningful representations of sensor measurements through 3D bounding boxes. Although state-of-the-art object detection methods have shown impressive performance, their success relies heavily on large annotated datasets. Annotating these datasets remains a bottleneck, necessitating the development of detection methods that can leverage both labeled and unlabeled data. In this work, we propose a novel semi-supervised 3D object detection method called 3DIoUMatch. Our method is applicable to both indoor and outdoor scenes and utilizes point-based object detectors as backbone networks. To provide supervision to unlabeled scenes, we adopt a teacher-student mutual learning framework and use the teacher network's bounding box predictions as pseudo-labels. However, we observe significant noise in these pseudo-labels, which complicates their direct usage. Inspired by FixMatch, a state-of-the-art semi-supervised learning method for 2D image classification, we adopt a confidence-based filtering mechanism to improve the quality of pseudo-labels. Additionally, we leverage estimated Intersection over Union (IoU) as a measure of localization quality for pseudo-label filtering. By equipping our detectors with a 3D IoU estimation module, we can filter out poorly localized pseudo-labels. We propose a two-stage filtering process to strike a balance between quality and coverage. Our experiments demonstrate that our method consistently outperforms the previous state-of-the-art method on both indoor and outdoor benchmarks. We achieve significant improvements in performance under various label ratios, and our method surpasses fully supervised baselines on the KITTI benchmark for the first time. Our contributions include a novel semi-supervised method for 3D object detection, leveraging predicted 3D IoU as a localization confidence score, and achieving improved performance on major indoor and outdoor benchmarks.