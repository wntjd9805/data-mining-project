Deep learning has achieved impressive results in various computer vision tasks, but obtaining good annotations for training datasets is challenging and expensive. Active learning (AL) is an approach that aims to overcome the limited labeling budget by selecting the most informative data instances to label. Existing AL approaches can be classified into two groups: task-agnostic and task-aware methods. Task-agnostic approaches select instances based on the input distribution, while task-aware approaches consider the relationship between inputs and outputs. However, task-aware approaches often rely on estimating the conditional distribution, which may be inaccurate at the early stage of AL. A recent attempt called SRAAL combined task-agnostic and task-aware approaches but did not use the information about the loss directly related to the task. In this paper, we propose a novel AL scheme, called Task-Aware Variational Adversarial Active Learning (TA-VAAL), which combines the benefits of both groups of approaches. We relax the goal of the loss prediction module, leading to altered loss and introducing ranking loss. Our TA-VAAL embeds the normalized ranking loss information from any given task learner and reshapes the latent space using a ranking conditional generative adversarial network. We demonstrate the superior performance of TA-VAAL compared to state-of-the-art approaches on various classification and semantic segmentation benchmark datasets. Our codes are available online.