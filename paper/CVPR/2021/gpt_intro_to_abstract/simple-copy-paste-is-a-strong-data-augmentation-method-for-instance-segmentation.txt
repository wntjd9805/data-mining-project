Instance segmentation is a crucial task in computer vision with various real-world applications. However, state-of-the-art convolutional network-based instance segmentation models are data-hungry, and annotating large datasets for this task is expensive and time-consuming. In this paper, we propose data augmentation as a simple solution to enhance the data efficiency of instance segmentation models. While general-purpose augmentation methods have been widely used, we focus on the object-aware and category-specific Copy-Paste augmentation. By pasting diverse objects of different scales onto new background images, Copy-Paste generates novel and challenging training data. The augmentation procedure offers multiple options for selecting source images, object instances to copy, and paste locations, providing flexibility for effectively utilizing this technique. We demonstrate that the combination of Copy-Paste augmentation and large scale jittering significantly improves data efficiency, outperforming the commonly used standard scale jittering technique on the COCO benchmark. We also show that the Copy-Paste strategy can be combined with self-training, achieving state-of-the-art performance on the COCO test-dev dataset for both box and mask average precisions. Furthermore, Copy-Paste augmentation improves the features for the two-stage training procedure used in the LVIS benchmark. This strategy is easy to implement and does not introduce additional training or inference overheads. Overall, our results highlight the effectiveness of the Copy-Paste augmentation in improving the data efficiency and performance of instance segmentation models.