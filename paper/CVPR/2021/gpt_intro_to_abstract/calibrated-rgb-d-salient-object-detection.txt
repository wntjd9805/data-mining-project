Salient Object Detection (SOD) is a significant computer vision problem that aims to identify and segment the most prominent object in a scene. It has found successful applications in various tasks such as object recognition, image retrieval, SLAM, and video analysis. Incorporating depth information as a complementary input source has been explored to address challenging scenes with low texture contrast or cluttered backgrounds. However, there are two main challenges in utilizing depth maps for SOD: noisy depth boundaries and limited difference between foreground and background object depths. To address these challenges, we propose a Depth Calibration and Fusion (DCF) framework. The DCF framework includes a two-step calibration and fusion pipeline, which involves calibrating the depth image to correct bias and fusing feature representations from RGB and calibrated depth streams using a Cross Reference Module (CRM). Extensive experimental evaluations, comparing our approach with 27 state-of-the-art RGB-D SOD methods, demonstrate the effectiveness of the proposed framework. Additionally, our depth calibration module can be applied as a preprocessing step to existing RGB-D SOD methods, resulting in decreased Mean Absolute Error (MAE) metrics for two representative models.