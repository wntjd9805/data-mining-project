Face detection is a crucial task in computer vision, with various practical applications such as intelligent surveillance, face unlock, and beauty filters. However, face detection under adverse illumination conditions remains challenging. Insufficiently illuminated images suffer from low visibility, noise, and color cast, which not only affect human visual quality but also degrade the performance of machine vision tasks. This can lead to potential risks in surveillance video analysis and nighttime autonomous driving. To address this issue, we propose a novel framework called High-Low Adaptation Face detection (HLA-Face). Our framework aims to adapt normal light face detection models to low light scenarios without the need for annotated dark face data. We identify two levels of gaps between normal light and low light: pixel-level appearance and object-level semantic differences. Traditional low light enhancement methods fail to bridge the semantic gap, while typical adaptation methods are inadequate due to the significant domain gap. To overcome these challenges, HLA-Face incorporates joint low-level and high-level adaptation. In the low-level adaptation, we utilize a bidirectional scheme that involves brightening low light images and distorting normal light images. This approach allows us to build intermediate states between the normal and low light domains. For high-level adaptation, we employ multi-task self-supervised learning to close the feature distance between the intermediate states. By combining both levels of adaptation, our framework outperforms state-of-the-art face detection methods, even without using labels of dark faces. The contributions of this work include the proposal of a framework for dark face detection without annotated dark data, the design of a bidirectional scheme for low-level adaptation, and the introduction of cross-domain self-supervised learning for feature adaptation in the high-level adaptation.