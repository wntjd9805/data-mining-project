Face recognition using deep neural networks has shown promising outcomes on evaluation benchmarks. However, existing methods often assume that the training and testing data have similar distributions, leading to poor generalization in real-world scenarios with unknown statistics. Collecting more data along underrepresented attributes is costly, necessitating the development of learning algorithms that can yield universal face representations. Domain generalization has emerged as an approach to address this challenge, but it is mainly applicable to object classification with a limited number of classes. In this paper, we propose an approach to improve face recognition from unseen domains by learning semantically meaningful representations. Inspired by previous works in few-shot learning, domain generalization, and face recognition, we introduce the Cross-Domain Triplet (CDT) loss. This loss function considers two domains, leveraging the similarity metrics provided by one domain to learn compact feature clusters in another domain. Through the use of covariance matrices, our CDT loss aligns distributions of two domains in a discriminative manner. Additionally, we utilize a meta-learning framework to further enforce the learning of generalized features under domain shift. Experimental evaluations demonstrate the effectiveness of our approach on face recognition for unknown ethnicity and other variations. Our proposed method achieves state-of-the-art results on standard face recognition from unseen domain datasets.