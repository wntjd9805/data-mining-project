Visual search systems in an "open universe" setting often consist of a gallery model and a query model, both mapping input images to vector embeddings. Existing approaches typically use the same model architecture for both the gallery and query models, creating a trade-off between accuracy and efficiency. In this paper, we propose a heterogeneous visual search (HVS) approach that uses different model architectures for the gallery and query models, mitigating the accuracy-efficiency trade-off. We introduce a compatibility-aware neural architecture search (CMP-NAS) strategy that searches for an efficient query model while ensuring compatibility with the gallery model. We demonstrate that CMP-NAS outperforms state-of-the-art architectures designed for resource-constrained mobile platforms and achieves significant reductions in model complexity with minimal loss in accuracy. Our contributions include demonstrating the benefits of HVS, proposing CMP-NAS for compatibility-aware architecture search, and achieving substantial reductions in complexity with marginal accuracy loss.