Generative adversarial networks (GANs) have made significant advancements in synthesizing high-quality images and videos. In conditional settings, additional input signals control the generation process. However, the computational complexity and large size of generative models make them less practical for resource-constrained platforms. Previous works have proposed compression techniques for discriminative models, but compressing generative models has been less explored. Existing compression methods for image-to-image translation networks lead to degraded image quality compared to the original model. This paper focuses on compressing these networks and introduces a new network design that serves as both the teacher network design and the architecture search space for the student. The trained teacher network is pruned using an efficient technique to achieve a target computation budget, and a knowledge distillation technique based on global kernel alignment is introduced. The proposed method, named CAT (Compression And Teaching), achieves better performance than the original models with significantly reduced computational resources.