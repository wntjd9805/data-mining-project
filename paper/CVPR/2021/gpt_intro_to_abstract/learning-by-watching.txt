Modern autonomous driving systems heavily rely on large amounts of data to train imitation and machine learning algorithms. However, this data is often captured by a few organizations, limiting accessibility and hindering progress in autonomous driving technologies. This paper proposes a Learning by Watching (LbW) framework, which learns robust and data-efficient driving policies by leveraging data from multiple demonstration sources. Unlike existing approaches that rely on ego-vehicle perspective data, LbW allows the use of data from non-instrumented vehicles, enabling the learning of safe driving in diverse scenarios. The paper addresses the challenges of inferring states and actions of surrounding vehicles without direct access to observations and presents a two-step behavior cloning approach. The effectiveness of the proposed framework is validated through experiments on CARLA and NoCrash benchmarks. The paper emphasizes the benefits of LbW in terms of scalability and adaptability to novel driving scenarios, even with limited data availability.