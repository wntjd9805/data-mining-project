Generative adversarial networks (GANs) have made significant advancements in the field of high-fidelity image synthesis directly from data. While GANs have shown the ability to encode rich semantics within the latent space, manipulating real images by changing the latent code remains a challenge. Existing approaches such as image-to-image translation and direct optimization of latent code have limitations in terms of user controllability and computation time. To address these issues, we propose StyleMap-GAN, a novel approach that utilizes a tensor with spatial dimensions as a representation of the latent space. By incorporating spatial dimensions, our method enables GANs to encode local semantics of images more effectively, allowing for high-fidelity and real-time image projection. Additionally, our approach offers the capability to edit specific regions of an image by manipulating the matching positions of the stylemap. Experimental results demonstrate that our stylemap representation significantly improves projection quality compared to traditional vector-based representations. Furthermore, our method outperforms state-of-the-art approaches in image projection, interpolation, and local editing tasks. Lastly, we showcase the ability of our method to transplant regions even when they are not aligned between images.