Dense pixel-wise prediction tasks in computer vision, such as denoising, super-resolution, and semantic/instance segmentation, are structured output learning problems. These tasks often rely on dependencies between prediction variables. The pixel-wise loss is commonly used for these tasks, but the perceptual loss, which captures perceptual information by measuring discrepancies in high-level convolutional features extracted from pre-trained CNNs, has also been successful in tasks like style transfer and super-resolution. However, previous works assume that the success of the perceptual loss depends on the ability of a pre-trained CNN to extract high-level perceptual features. In this paper, we challenge this assumption and show that the structure of a multi-layered CNN itself is sufficient to capture interaction statistics for different output forms. We conduct a pilot experiment on image super-resolution using a randomly-weighted network instead of a pre-trained VGG network for the perceptual loss. The results show that the randomly-weighted network performs on par with the pre-trained VGG network, indicating that the success of the perceptual loss is more dependent on the deep network architecture rather than the pre-trained weights. Based on this finding, we propose a generic perceptual loss for structured output learning that can be computed by comparing discrepancies in hierarchical dependencies between variables in multiple layers of a deep network. We demonstrate the effectiveness of this perceptual loss in various structured output learning tasks, such as semantic segmentation, depth estimation, and instance segmentation. The proposed perceptual loss consistently improves performance compared to baselines that use pixel-wise loss alone. We also analyze the impact of initialization schemes and network architectures on the performance of the perceptual loss. Overall, our contributions include revealing the independence of the success of perceptual loss from pre-trained weights, applying the generic perceptual loss to multiple structured output learning tasks, investigating initialization and network structure effects, and proposing a simple and generic perceptual loss for computer vision tasks.