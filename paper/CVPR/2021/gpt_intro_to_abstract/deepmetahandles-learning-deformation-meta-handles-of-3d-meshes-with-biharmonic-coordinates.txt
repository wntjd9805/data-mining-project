Learning to generate 3D meshes is challenging due to the irregularity of mesh data structures and the difficulty in designing loss functions to measure geometrical and topological properties. Previous methods restrict the creation space to changing the geometry of a known connectivity structure. In this paper, we propose a 3D conditional generative model that can take any existing mesh as input and produce plausible variants. Our approach integrates a target-driven fitting component and a conditional generative model, allowing both deformations to fit a given target shape and exploration of plausible variants without a target. We aim to improve the plausibility of output shapes and the interpretability of learned latent spaces. To achieve these goals, we leverage classical deformation handles to parameterize deformations with a low degree of freedom. We learn a low-dimensional deformation subspace for each shape, explicitly factorizing all plausible deformations with interpretable deformation functions. We introduce meta-handles that correspond to intuitive deformation directions and enforce disentanglement to allow independent deformation of part groups. We address the challenge of examining plausibility using a differentiable 2D renderer and discriminator. Our DeepMetaHandles model is trained with random pairs of source and target shapes, utilizing MetaHandleNet and DeformNet modules for prediction and deformation. We demonstrate the effectiveness of our approach by producing superior fitting results compared to other techniques. Our key contributions include the proposal of DeepMetaHandles, the use of deformation handles and meta-handles for parameterizing deformations, and improved plausibility using a differentiable renderer and discriminator.