Image extrapolation is a valuable technique in computational photography that extends pixels beyond image borders. Unlike image interpolation, which infers missing pixels based on known information, extrapolation requires inferring both textures and structures in a convincing manner with limited information available. Classical methods for image extrapolation often rely on guide images or reference images found on the Internet to expand the input image. However, these methods have limitations and are only applicable to specific scenarios.Recently, learning-based approaches using generative adversarial networks (GANs) have emerged for image extrapolation. These methods, such as Boundless, Wide-Context, Panorama Synthesis, and Pluralistic Image Completion, leverage the success of GANs to tackle the challenges of extrapolation. Despite progress in textural images, the problem of extrapolating objects in images with salient objects remains unsolved.To address this challenge, we introduce OCONet (Object Completion Networks), which specifically targets the image extrapolation problem for a broad range of images with different object classes. By leveraging advances in high-quality instance segmentation, we can obtain accurate object class and foreground object shape masks, even with only a small portion of the object visible within the image boundary. OCONet utilizes this information to train a class-conditioned object model that infers the shape and pixels of foreground objects, as well as a background model that extrapolates the background. The completed object is then composited with the extrapolated background to produce the final result.Extensive quantitative and qualitative experiments demonstrate that OCONet significantly outperforms previous state-of-the-art methods. We showcase our method on various object categories, including cars, trains, dogs, and apples, and compare the results with other approaches. Our contributions include the introduction of object completion networks, the effective use of sign-distance field (SDF) as an internal representation for 2D shape completion, and substantially improved extrapolation results for important object classes.In summary, our work addresses the challenges of image extrapolation and demonstrates the effectiveness of OCONet in producing high-quality results for a broad range of object classes.