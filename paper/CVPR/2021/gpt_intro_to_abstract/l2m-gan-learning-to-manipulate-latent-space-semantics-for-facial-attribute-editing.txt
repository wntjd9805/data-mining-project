Facial attribute editing has various real-world applications such as entertainment, psychiatric treatment, and data augmentation. The challenge lies in meeting the requirements of attribute correctness and irrelevance preservation simultaneously. Existing approaches use spatial attention or factorization of the latent space, but they have limitations. To address these limitations, we propose a novel end-to-end model called L2M-GAN. L2M-GAN factorizes the latent space into attribute-relevant and -irrelevant codes and incorporates a style transformer for attribute editing. The transformed code satisfies the orthogonality constraint with the attribute-irrelevant code, ensuring attribute correctness and irrelevance preservation. L2M-GAN outperforms existing methods in facial attribute editing tasks and can be used for attribute manipulation without re-training. Experimental results on CelebA-HQ dataset demonstrate the superior performance of L2M-GAN.