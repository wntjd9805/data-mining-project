The paper explores the technique of style transfer in computer-generated art. It discusses the historical background of automated texture synthesis and introduces the concept of Neural Style Transfer (NST). NST utilizes deep layers of a pre-trained Convolutional Neural Network (CNN) to encode high-level semantic information and align feature distributions, similar to Domain Adaptation (DA). The paper focuses on the interpretation of style transfer as distribution matching and examines the limitations of existing methods. It introduces the concept of Central Moment Discrepancies (CMDs) as a solution to these limitations, providing a computationally efficient and theoretically grounded approach to aligning style distributions. The paper categorizes existing NST methods, highlights underlying approximations, and presents a novel NST algorithm based on CMDs. This algorithm achieves a clearer separation between artistic style and semantic content, resulting in visually compelling style transfer. The approach is empirically evaluated through a user study with over 50 participants.