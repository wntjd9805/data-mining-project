Unsupervised video object segmentation is a crucial task in computer vision, with applications in video compression, autonomous driving, and human-centric understanding. However, it is challenging due to the lack of prior knowledge about the objects and the various factors present in video data. Early studies used saliency cues or objectness priors to identify foreground objects. With the advent of deep neural networks, learning-based models have been proposed, but they mainly focus on foreground/background separation and are not suitable for multi-object scenarios. Unsupervised video multi-object segmentation is even more challenging as it requires discovering instance-agnostic foreground regions and discriminating different object instances. Existing methods typically follow a top-down tracking-by-detection approach, but they have limitations in terms of using static images for segmentation, separate consideration of instance segmentation and foreground estimation, and the lack of distinctive features for specific targets. In this paper, we propose a novel approach for unsupervised multi-object segmentation in videos. Our approach includes an instance discrimination network that leverages temporal information for better segmentation accuracy and efficiency, and a target-aware tracking network that learns target-specific appearance features for robust object association. We achieve state-of-the-art results on benchmark datasets and demonstrate a better trade-off between segmentation accuracy and inference efficiency. Our approach has the potential for practical applications with its high inference speed.