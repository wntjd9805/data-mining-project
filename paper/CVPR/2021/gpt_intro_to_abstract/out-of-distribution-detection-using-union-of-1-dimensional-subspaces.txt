Abstract:Out-of-distribution (OOD) sample detection is crucial in classification tasks, where training data may not encompass all possible classes encountered during testing. Various OOD detection techniques rely on class membership probabilities or similarity measures in a feature space. However, conventional class-conditional Gaussian embeddings often fail to distinguish outliers effectively. In this work, we propose constraining the representation of in-distribution (ID) samples in the feature space to enhance OOD detection performance. Our approach embeds training samples, ensuring that feature vectors of each known class lie on a 1-dimensional subspace. This representation offers two advantages: it reduces the likelihood of OOD samples occupying the same region as known classes, and it leverages the robustness of the first singular vector of a 1-dimensional subspace. We reject samples as OOD if their region corresponds to the training samples with a probability of 0, determined using Monte Carlo sampling techniques. Inspired by spectral methods in signal processing and prior OOD detection methods, we engineer the distribution of ID feature vectors without requiring knowledge of OOD sample distributions or additional OOD example subsets for hyperparameter tuning. Our technique can be easily deployed in various frameworks and modalities. This paper presents our contributions, which include demonstrating the effectiveness of embedding feature vectors onto a union of 1-dimensional subspaces for robust OOD detection, proposing a new OOD detection test utilizing the first singular vector and Monte Carlo sampling, and providing a hyperparameter-free framework that can be applied across different domains. We also introduce a new baseline for OOD detection in human action classification in videos.