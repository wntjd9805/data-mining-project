Convolutional Networks (ConvNets) have shown remarkable performance in semantic segmentation, a task that aims to classify individual pixels in an image into their respective semantic regions. In particular, segmenting road scenes automatically is crucial for scene understanding in autonomous driving systems. While most segmentation algorithms are designed for narrow field-of-view (FoV) pinhole camera images, the increasing use of omnidirectional cameras in autonomous driving systems calls for models that can handle the broader FoV provided by these cameras.However, due to the lack of labeled data for omnidirectional images, narrow FoV-trained models are often applied to omnidirectional images, resulting in significant performance degradation. The difference in FoV and structural distribution between imaging domains leads to unreliable segmentation results. To address this challenge, this paper introduces Efficient Concurrent Attention Networks (ECANets) that leverage the long-range contextual priors unique to omnidirectional images. ECANets utilize non-local operations that capture pixel-to-pixel correlations and model correlations of each position to omni-range regions, effectively aggregating associations from highly correlated positions.In addition to architectural considerations, training efficient models for omnidirectional semantic segmentation is also challenging due to the lack of annotated panoramic images. To overcome this limitation, the paper proposes a multi-source omni-supervised learning approach that combines training on unlabeled panoramic images and densely labeled pinhole images. This approach utilizes data distillation and a novel multi-source prediction fusion method to increase prediction certainty and incorporate long-range contextual priors.To evaluate the proposed ECANet model and training strategy, the paper introduces the Wild PAnoramic Semantic Segmentation (WildPASS) dataset, which features diverse road scenes collected from around the world. Extensive experiments demonstrate that the proposed methods outperform state-of-the-art approaches on both the public PASS dataset and the WildPASS dataset.In summary, this paper presents novel ECANets and a multi-source omni-supervised learning approach for efficient panoramic semantic segmentation. The proposed methods leverage long-range contextual priors unique to omnidirectional images and achieve state-of-the-art results on the PASS and WildPASS datasets. The WildPASS dataset, collected from diverse locations, provides a valuable resource for evaluating panoramic semantic segmentation algorithms in real-world environments.