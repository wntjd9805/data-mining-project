Finding image correspondences is crucial for various computer vision tasks such as Structure-from-Motion (SfM) and Simultaneous Localization and Mapping (SLAM). The traditional approach involves using hand-crafted local features, but they are vulnerable to challenging conditions. Recent studies have proposed learning-based methods to detect and describe local features using neural networks, which have shown robustness in matching under challenging conditions. Additionally, some methods focus on learning a filtering function to reject outlier matches. The combination of learned features and matchers has achieved state-of-the-art results.While previous research has explored learning the entire matching pipeline, the main challenge lies in achieving pixel-level accuracy while maintaining computational efficiency. Some studies have resorted to matching at lower resolutions, which compromises accuracy. Other approaches have used correspondence networks that are weakly supervised, achieving pixel-level matching. However, these methods may introduce biases due to ground truth supervisions.In this paper, we propose Patch2Pix, a novel approach for correspondence networks inspired by detect-to-refine practices in object detection. Our method first generates patch-level match proposals and then refines them to pixel-level matches using a refinement network supervised by epipolar geometry computed from relative camera poses. We optimize directly on match locations and achieve state-of-the-art results in various geometry tasks, including image matching, homography estimation, and visual localization. Our model generalizes well to fully supervised methods without retraining and achieves promising results in indoor and outdoor long-term localization.