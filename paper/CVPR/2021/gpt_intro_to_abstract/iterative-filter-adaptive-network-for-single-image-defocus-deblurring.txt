Defocus deblurring aims to restore sharp, all-in-focus images from defocused images, which is crucial for photographers to remove unwanted blur. Additionally, restored all-in-focus images can greatly enhance high-level vision tasks such as semantic segmentation and object detection. However, defocus deblurring remains challenging due to the spatially varying size and shape of defocus blur. Conventional approaches model defocus blur using predefined kernels and estimate per-pixel blur kernels based on the blur model, followed by non-blind deconvolution. Unfortunately, this approach often fails due to the restrictive blur model, which ignores the nonlinearity of real-world blur and confines defocus blur to specific shapes. Recently, an end-to-end learning-based method called DPDNet was proposed, which outperformed previous approaches for real-world defocused images. However, it suffered from ringing artifacts and remaining blur due to its limited flexibility in handling spatially varying and large blur. In this paper, we propose an end-to-end network embedded with the Iterative Filter Adaptive Network (IFAN) for single image defocus deblurring. IFAN is specifically designed to handle spatially varying and large defocus blur. It adopts an adaptive filter prediction scheme to handle spatially varying defocus blur and predicts stacks of small-sized separable filters to efficiently handle large defocus blur. To apply these filters to features, we introduce a novel Iterative Adaptive Convolution (IAC) layer. Furthermore, we train our network with novel defocus-specific tasks such as defocus disparity estimation and reblurring to improve the deblurring quality. We extensively evaluate our method on diverse real-world images from different cameras, demonstrating its effectiveness in terms of deblurring accuracy and computational cost. In summary, our contributions include the IFAN, a novel training scheme, and state-of-the-art performance in defocus deblurring.