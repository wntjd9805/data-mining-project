This paper focuses on the evaluation of image captioning, which involves translating visual information into natural language. Previous evaluation methods for image captioning have relied on reference-based metrics that measure the similarity between candidate captions and human-labeled reference captions. However, these metrics have limitations in terms of robustness to text ambiguity and coverage of all image contents. To address these limitations, this paper proposes a Fidelity and Adequacy ensured Image Caption Evaluation metric (FAIEr) that takes into account both the image and reference captions. FAIEr uses scene graphs to align and dissect visual and textual information, and calculates multi-modal similarity by fusing and matching scene graphs. The evaluation of fidelity relies on matching between the image and candidate caption, while adequacy is measured by comparing the candidate and reference captions. Experimental results show the consistency of FAIEr with human judgement and the advantages of scene graph representations. Additionally, FAIEr has the capability for reference-free evaluation.