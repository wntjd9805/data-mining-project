Temporal action proposal is an essential task in computer vision, as it entails localizing action instances in untrimmed videos by predicting action-ness probabilities and temporal boundaries. While several approaches have been proposed to address this task, utilizing the advancements in spatio-temporal feature learning, most of them heavily rely on dense temporal annotations during the training phase. However, the process of annotating these videos is both tedious and time-consuming. This paper aims to overcome these challenges by proposing a novel method that reduces the need for dense temporal annotations, yet achieves competitive performance. Our approach leverages the advancements in spatio-temporal feature learning and employs X technique to predict both action-ness probabilities and temporal boundaries accurately. We evaluate the proposed method on various benchmark datasets and demonstrate its effectiveness in reducing annotation efforts while achieving state-of-the-art performance.