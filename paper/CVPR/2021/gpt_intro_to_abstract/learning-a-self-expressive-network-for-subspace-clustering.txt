This paper introduces the Self-Expressive Network (SENet), a method for subspace clustering that addresses the limitations of existing self-expressive models. The self-expressive model expresses data points as linear combinations of other data points, with coefficients representing the similarity between points. However, the computational cost of solving for the coefficients becomes prohibitive for large-scale data. SENet overcomes this limitation by learning a neural network function that approximates the self-expressive coefficients. The number of network parameters does not scale with the dataset size, making it suitable for large-scale data. Moreover, a trained SENet can be used to handle out-of-sample data effectively. The authors propose a network architecture and a training algorithm to learn the desired subspace-preserving properties. The experiments demonstrate the effectiveness of SENet in approximating the self-expressive coefficients, handling out-of-sample data, and achieving state-of-the-art clustering performance on datasets like MNIST, Fashion MNIST, Extended MNIST, and CIFAR-10.