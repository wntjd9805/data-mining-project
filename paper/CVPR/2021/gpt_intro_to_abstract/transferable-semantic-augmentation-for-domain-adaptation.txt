In recent years, deep learning has achieved impressive results in various computer vision tasks such as image recognition and semantic segmentation. However, the success of deep learning methods heavily relies on having access to large amounts of labeled data, which can be expensive to collect. Additionally, each domain has its own specific factors that can cause a shift in the data distribution, resulting in poor generalization of deep models trained on a large dataset when applied to a new domain.To address this issue, domain adaptation (DA) methods have been proposed, aiming to leverage knowledge from a labeled source domain to assist learning in an unlabeled target domain. Previous deep DA methods can be categorized into statistical discrepancy minimization based methods and adversarial learning based methods. However, most of these methods assume a shared classifier with domain-invariant representations, overlooking the importance of explicitly enhancing the adaptation ability of the source-supervised classifier.To tackle this problem, this paper introduces a Transferable Semantic Augmentation (TSA) approach, which implicitly augments source features with target semantic guidance in the deep feature space to facilitate classifier adaptation. TSA exploits the disentangling and linearizing properties of deep networks to explore different semantic transformation directions. It estimates the inter-domain feature mean difference and target intra-class feature covariance to effectively capture the semantic variations between domains.To obtain accurate estimations, TSA incorporates a memory module to calculate feature mean and covariance, and samples semantic transformation directions from a multivariate normal distribution. The overall semantic difference between domains and target intra-class semantic variations guide the source augmented features towards the target. The proposed method also introduces an expected transferable cross-entropy loss over the augmented source distribution to perform source semantic augmentation efficiently, without explicitly generating augmented features.The contributions of this work are as follows: first, the TSA method enables classifier adaptation through implicit source feature augmentation, without introducing additional network modules. Second, the novel expected transferable cross-entropy loss enhances the classifier adaptation ability and can be easily integrated into various DA methods. Finally, extensive experiments on several cross-domain benchmarks demonstrate the consistent and significant performance improvements achieved by TSA.Overall, this paper presents a novel approach for domain adaptation that effectively enhances the adaptation ability of source-supervised classifiers without introducing complexity or computational overhead. The proposed TSA method shows promising results in improving performance on various cross-domain datasets.