This paper proposes a method for estimating the number of repetitions of unknown activities in videos using both sight and sound signals. Existing solutions in computer vision focus solely on the visual modality, which can fail in poor sight conditions. By analyzing sound, which has proven advantageous in various computer vision challenges, the paper introduces a new perspective for repetitive activity counting. The paper presents an audiovisual model with sight and sound streams, allowing each modality to contribute to the prediction of repetitions. A temporal stride decision module is also proposed to select the best sample rate based on visual and audio features. The paper further introduces two datasets, one for supervised learning and evaluation and another for assessing audiovisual counting in challenging vision conditions. Experimental results show that incorporating sound improves the accuracy of repetition counting, especially in harsh vision conditions. The proposed model outperforms the state-of-the-art in sight-only counting.