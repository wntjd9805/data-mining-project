Deep neural networks (DNNs) have achieved remarkable performance in various computer vision tasks. However, the complexity of these networks, with a large number of model parameters, hinders their deployment on cloud and edge devices. Model quantization, the conversion of high-precision parameters to low-precision ones, has emerged as a paradigm for model compression and acceleration. Quantization-aware fine-tuning approaches have been studied to optimize quantized models, but they are not applicable in situations where the original training data is inaccessible due to privacy and security concerns. Post-training quantization methods have been proposed to quantize weights and activations in DNNs without fine-tuning, but these methods often suffer from performance degradation due to a gap between the strategies used and the goals of the target tasks. Recent methods have leveraged batch normalization statistics (BNS) to guide data generation and fine-tuning of quantized models. While these methods improve the performance to some extent, the generated data still fails to fully recover the peculiarities of the training data, and the generation process is time-consuming due to data redundancy. To address these issues, this paper presents a novel learning framework called Zero-shot Adversarial Quantization (ZAQ) for data-free model quantization. ZAQ utilizes a two-level discrepancy modeling strategy to measure the gap between a quantized model and its corresponding full-precision model. It considers both output discrepancy and intermediate inter-channel discrepancy based on feature maps. The ZAQ framework includes a generator that generates informative and diverse data examples using adversarial learning techniques. Additionally, activation regularization is employed to facilitate the generator in obtaining examples more sensitive to the network. The contributions of this paper include the proposal of ZAQ as the first adversarial learning-based approach for data-free model quantization, the development of a novel two-level discrepancy modeling strategy, and extensive experiments demonstrating the effectiveness and efficiency of ZAQ compared to existing methods. The experiments cover image classification, segmentation, and object detection tasks, and show that ZAQ achieves state-of-the-art results in data-free scenarios, particularly ultra-low precision situations. Overall, ZAQ offers a promising approach for data-free model quantization in computer vision tasks.