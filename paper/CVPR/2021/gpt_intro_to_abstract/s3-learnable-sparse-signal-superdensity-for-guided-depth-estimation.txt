Dense depth estimation is crucial in the field of 3D reconstruction, object detection, and robotic vision. Previous methods for depth estimation have relied on either RGB images or stereo pairs, but these approaches have limitations in terms of reliability and accuracy. Monocular depth estimation is inherently ambiguous and unreliable, while stereo estimation can be unreliable in certain scenarios. To address these challenges, recent solutions have leveraged raw sparse signals, such as LiDAR and Radar, to improve depth estimation results. However, there are still two key problems with sparse signal guidance: (1) the low density of sparse signal data and (2) the imbalanced distribution of these signals. In this paper, we propose a novel framework called Sparse Signal Superdensity (S3) to enhance the density and mitigate the imbalanced distribution of sparse signals for guided depth estimation. S3 consists of two components: sparse signal expansion and confidence weighting. The sparse signal expansion module estimates the expanded area for each sparse signal based on the RGB image and assigns appropriate depth values to the expanded region. The confidence weighting module measures the confidence of the assigned depth values to control their influence on the sparse-guidance methods. Our experimental results demonstrate the effectiveness of the S3 framework in enhancing the density and mitigating the imbalanced distribution of sparse signals, leading to improvements in depth estimation accuracy and robustness. The proposed S3 framework can be integrated into existing sparse-guidance depth estimation methods and trained in an end-to-end fashion. Our contributions include identifying the defective properties of sparse signals and their impact on depth estimation, introducing the S3 framework for enhancing the density and mitigating the imbalanced distribution of sparse signals, and demonstrating the improved performance of S3 in depth estimation tasks using sparse signals like LiDAR and Radar.