Crowd counting is a vital computer vision task with applications in traffic management, video surveillance, and social distancing monitoring during the COVID-19 pandemic. Various models have been proposed, but accurately estimating crowd density maps remains challenging. Previous methods primarily rely on optical information from RGB images, which can be limited in unconstrained scenarios with poor illumination and similar appearances of non-human objects. Thermal images have been shown to complement RGB images in distinguishing pedestrians from cluttered backgrounds. To promote further research in this field, a large-scale benchmark called "RGBT Crowd Counting (RGBT-CC)" is proposed, consisting of 2,030 pairs of RGB-thermal images and 138,389 annotated pedestrians captured in diverse and challenging environments. A cross-modal collaborative representation learning framework is introduced, incorporating modality-specific branches, a modality-shared branch, and an Information Aggregation-Distribution Module (IADM) to fully exploit the complementarities of RGB and thermal images. The IADM dynamically aggregates contextual information and propagates shared information to enhance representation learning. The proposed framework demonstrates effectiveness and universality for multimodal crowd counting, as validated through experiments on the RGBT-CC and ShanghaiTechRGBD benchmarks.