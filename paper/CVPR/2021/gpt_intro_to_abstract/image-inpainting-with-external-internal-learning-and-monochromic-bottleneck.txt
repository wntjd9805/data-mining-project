Image inpainting is a task that aims to complete missing regions of an image with visually realistic and semantically consistent content. While significant progress has been made in image inpainting, existing methods still suffer from color artifacts, especially for large missing regions. This paper analyzes the weaknesses of state-of-the-art inpainting approaches and presents a novel framework to improve existing methods. The existing methods can be roughly categorized into patch matching and deep learning models, each with their own advantages and disadvantages. PatchMatch is a learning-free method that generates smooth patterns but fails to fill in semantic-aware content. Deep learning-based approaches can learn semantic-aware models but still suffer from color and texture artifacts. One of the most common artifacts is color bleeding. To address these issues, the proposed method combines the best of both worlds. It adopts an external-internal inpainting scheme with a monochromic bottleneck, completing the monochromic image externally and then internally colorizing it. This method reduces the dimension of the optimization space and ensures structure preservation and color consistency. It also shows stronger generalization ability on cross-dataset evaluation. Extensive experiments are conducted to evaluate the performance on four public datasets, and meaningful improvements are observed in terms of structure preservation and color harmonization. The proposed method is the first to introduce an external-internal learning approach for deep image inpainting and achieves outstanding colorization performance. It is also generalized to several deep inpainting models, showing clear improvements in visual quality and model generalization ability.