Deep learning models have achieved remarkable performance in image recognition tasks, surpassing even human-level performance. However, these models typically assume high-quality or clean images for training and testing, while in practice, images of various qualities can be encountered. Additionally, deep models are known to be vulnerable to image distortions such as noise, blur, JPEG compression, contrast changes, weather conditions, and low resolution. In contrast, the human visual system robustly extracts semantic information from such distorted images due to its generalization ability.Data augmentation is a common method used to build robust models against different data domains or corruptions. This involves synthesizing low-quality (LQ) images through degradation procedures like blur, noise, and low resolution, and then training models using both high-quality (HQ) and LQ images. However, training with diverse data characteristics may result in an underfitted model for a specific type of data.To address these challenges, quality-aware deep models have been proposed, which introduce additional network modules to handle different corruption types. These models have shown promising results for both HQ and LQ images. However, as the number of corruption types increases, these approaches may require substantial resources for training and evaluation.In this paper, we propose a novel training scheme to build a quality-agnostic model that performs well on images of any quality. Our approach encourages LQ images to have HQ-like features by using an auxiliary decoder to reconstruct HQ images using features of LQ images. We train the classification model with a multi-task learning strategy on the classification task and the reconstruction task. To effectively train the classification model with the reconstruction decoder, we propose a two-stage training scheme where we first train a decoder with HQ images only and freeze it. Then, we train a classifier-decoder architecture with both HQ and LQ images using classification and reconstruction losses.Under our scheme, the classifier is encouraged to produce features of LQ input images that are similar to those of HQ images by performing the reconstruction task effectively. We suggest training an invertible network under the classification objective in the first stage and using its inversion as a decoder in the second stage. This helps mitigate potential conflicts between the two tasks in the multi-task learning stage.Experimental results demonstrate the effectiveness of our method for various tasks such as image classification and face recognition on benchmarks like ImageNet, ImageNet-C, CFP-FP, and AgeDB-30. Our proposed training scheme outperforms existing approaches and achieves high accuracy on images of any quality.