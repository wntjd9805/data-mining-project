In this paper, we introduce a method for automatic image editing guided by user's voice input. We propose a Text-to-Operation Network (T2ONet) that selects editing operations from a predefined set to progressively edit the image based on language comprehension and visual editing feedback. Our method ensures the resolution independence of the edited images. We address the challenge of training our model with the lack of supervision information for editing sequences by devising a weakly-supervised method to generate pseudo operation supervision. Inspired by forward search planning, we propose an operation-planning algorithm to recover the editing procedure from the input and edited images. We demonstrate the effectiveness of our method through experiments on a large-scale language-guided global image editing dataset. Our method outperforms reinforcement learning and GAN-based methods in terms of both quantitative and qualitative results.