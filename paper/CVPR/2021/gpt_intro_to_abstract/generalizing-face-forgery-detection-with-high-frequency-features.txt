Face forgery detection has become an important research topic due to the emergence of face manipulation techniques and deep generators. While existing methods mainly focus on detecting forgeries within a database, the generalization problem poses a significant challenge. Different manipulation techniques generate diversified data distributions, resulting in a performance drop when applying within-database detection methods to cross-database scenarios. Previous works have attempted to address the generalization problem through assumptions, transfer learning, domain adaptation, and frequency domain analysis, but these approaches have limitations or are expensive to implement. To overcome these challenges, this paper proposes a generalizable model for face forgery detection. The model leverages image noises to tackle overfitting and enhance generalization. Three novel modules are developed: a multi-scale high-frequency feature extraction module that extracts high-frequency noises and low-frequency textures, a residual guided spatial attention module to focus on forgery traces, and a dual cross-modality attention module to capture the correlation and interaction between the high-frequency modality and the regular modality. The contributions of this paper include an analysis of CNN-based detectors, which reveals their bias towards method-specific textures and the proposal of utilizing image noises to enhance generalization. The proposed model demonstrates superior generalization ability through comprehensive evaluations on multiple benchmarks.