Instance segmentation is a challenging problem in computer vision that involves assigning instance labels to pixels to separate objects in a complex scene. Existing methods often rely on complex graphical models with deep neural networks, but still require additional post-processing steps to predict the labeling map. Some approaches use bounding boxes to represent instances, but the coarse representation of object shape has been criticized. Sequential object detection and segmentation methods have shown promising results, but are limited to images with a small number of objects.This paper proposes a novel end-to-end instance segmentation method using reinforcement learning, motivated by the slow and time-consuming nature of conventional segmentation methods for separating individual cells in microscopy images. Unlike previous sequential approaches, this method leverages multiple pixel-wise agents working concurrently to differentiate multiple objects. The segmentation problem is formulated as an iterative binary graph coloring problem, and the asynchronous advantage actor-critic (A3C) algorithm is employed to train the agents.The proposed method demonstrates efficient handling of images with numerous objects of various shapes, while maintaining a high-quality segmentation comparable to state-of-the-art methods. This is the first reinforcement learning-based end-to-end instance segmentation method that runs in parallel, offering a new approach to tackle the instance segmentation problem.