This paper presents TesseTrack, a novel approach for tracking and reconstructing 3D articulated poses of multiple individuals captured in arbitrary camera feeds. The proposed method tackles challenges such as occlusions, fast motions, and person-person interactions in real-world scenarios. Unlike existing multi-view strategies that rely on multi-stage inference, TesseTrack simultaneously addresses 3D body joint reconstructions and associations using a spatio-temporal formulation. This formulation leverages a voxelized feature space obtained from deep learning features and employs a 3D CNN and a 4D CNN for localization and short-term representations. The linked representations are used to predict 3D body joints consistently over time. The entire approach is implemented as layers in a single feed-forward neural network and is trained end-to-end. Experimental evaluation on the Panoptic dataset demonstrates that TesseTrack outperforms baselines in per-joint tracking accuracy. Furthermore, an ablation study and comparisons with current methods on standard benchmarks highlight the effectiveness and state-of-the-art performance of TesseTrack.