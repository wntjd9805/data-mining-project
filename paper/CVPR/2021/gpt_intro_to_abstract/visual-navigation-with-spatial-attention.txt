This paper introduces the problem of object goal visual navigation and proposes a novel approach using reinforcement learning. The goal of the navigation task is to find an instance of a target object class, and the proposed approach combines both semantic and spatial information to improve the agent's policy. The authors utilize a convolutional net to encode semantic information about observed objects and an attention probability model to incorporate spatial information about their place. The attention mechanism consists of target attention, action attention, and memory attention, which allows the agent to effectively navigate towards the sought objects. The authors validate their approach using the AI2-THOR environment and show that it outperforms state-of-the-art methods. Additionally, the attention model carries spatial information about the objects and has the potential to explain the agent's actions in visual navigation tasks. The paper makes three contributions: the proposed attention mechanism, the end-to-end reinforcement learning framework, and the ability to visualize and explain the agent's actions.