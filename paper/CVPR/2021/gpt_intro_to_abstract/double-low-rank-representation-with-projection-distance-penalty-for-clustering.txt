Clustering is a fundamental problem in computer science that involves grouping samples into categories based on their similarity. Graph-based clustering methods, which classify samples using a similarity graph, have gained attention for their good performance and mathematical foundation. Self-representation models are effective in constructing similarity graphs by exploiting the subspace structure of data. Sparse subspace clustering (SSC) and low-rank representation (LRR) are self-representation methods, but they have limitations in capturing global structure and non-negativity. To address these issues, various approaches such as Laplacian regularized LRR and non-negative low-rank learning have been proposed. However, using nuclear norm can result in the loss of local intrinsic structure. Therefore, Laplacian regularized LRR methods have been proposed to preserve local information. Adaptive weighted nonnegative low-rank representation improves these methods by reducing the influence of noise and redundancy. Latent low-rank representation and double low-rank representation with projection distance penalty are also introduced to address insufficiency in observed data and to consider the structure of features. However, double low-rank representation ignores local structure and optimal projection. In this paper, a novel double low-rank representation model with projection distance penalty (DLRRPD) is proposed to improve the discrimination and robustness of the similarity graph for clustering tasks. DLRRPD introduces a projection distance penalty to capture global and local geometrical structures. A Laplacian rank constraint ensures robustness to noise, and the use of Frobenius norm improves clustering performance.