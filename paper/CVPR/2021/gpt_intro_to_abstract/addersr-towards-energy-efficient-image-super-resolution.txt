Single image super-resolution (SISR) is a popular computer vision task that aims to reconstruct a high-resolution (HR) image from a low-resolution (LR) image. With the increasing usage of smartphones and mobile cameras, there is a need to develop SISR models with low computational cost and high visual quality. Deep convolutional neural networks (CNNs) have significantly improved the performance of SISR, but they come with increased computational complexity and energy consumption. In order to address this problem, various approaches have been proposed to compress and accelerate deep CNNs, such as filter pruning and knowledge distillation. However, these methods may compromise the accuracy of the network. Binarization techniques reduce energy and memory consumption, but they are not suitable for the super-resolution task. Recently, AdderNet was introduced, which replaces multiplication operations with additions, significantly reducing complexity. This work proposes utilizing AdderNet to construct energy-efficient SISR models. By analyzing the theoretical difficulties of applying additions to SISR tasks and incorporating self-shortcuts and a learnable power activation, AdderSR models are established. The effectiveness of these models is verified on benchmark datasets, showing comparable performance to CNN baselines while reducing overall energy consumption by more than 50%. The paper concludes with a brief investigation of related works on neural network compression and energy-efficient approaches.