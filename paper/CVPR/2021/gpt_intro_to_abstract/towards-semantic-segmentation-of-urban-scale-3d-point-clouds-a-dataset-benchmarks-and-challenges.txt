The ability to accurately segment and label objects in the three-dimensional world is crucial for enabling machines to interact effectively in our physical environment. This has applications in various fields such as robotics, autonomous driving, and urban planning. Recent advancements in data-driven deep networks have greatly improved the performance of 3D point cloud segmentation. Several neural pipelines have been proposed, including voxel-based, projection-based, and point-based methods. Benchmark datasets have played a significant role in driving the development of these techniques. However, there are still open questions regarding the capability of these techniques to learn accurate semantics over large-scale urban 3D point clouds. Challenges include efficiently preprocessing massive point clouds, addressing extreme class imbalance in urban-scale datasets, leveraging color information for semantic segmentation, and generalizing existing networks to novel urban areas. To address these challenges, the authors propose a new paradigm for urban-scale 3D semantic segmentation using UAV photogrammetry. They introduce a new dataset, called SensatUrban, consisting of billions of 3D points covering several square kilometers of urban areas in three UK cities. The dataset provides unique perspectives and distinct geometric patterns, textures, and colors. The authors identify key challenges and conduct empirical investigations to explore various aspects of large-scale urban point cloud segmentation. Their contributions include the dataset and an in-depth study of generalizing existing algorithms to large-scale urban point clouds. The paper aims to inspire innovation in applications such as smart cities, autonomous vehicles, and intelligent construction sites.