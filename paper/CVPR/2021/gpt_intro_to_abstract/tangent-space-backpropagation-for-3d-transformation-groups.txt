This paper introduces the problem of integrating 3D transformation groups into the computation graphs of deep learning models. 3D transformation groups, such as SO(3), SE(3), and Sim(3), are commonly used in computer vision and robotics applications. However, existing deep learning libraries make the assumption that computation graphs consist only of mappings between Euclidean spaces, which breaks down when dealing with 3D transformations.To address this issue, the authors propose a new approach called tangent space backpropagation. Instead of embedding 3D transformation groups in Euclidean spaces, the authors perform backpropagation directly in the tangent space of each group element. This approach avoids numerical instabilities and allows for stable gradients, even for groups like Sim(3) that do not provide stable gradients using conventional automatic differentiation.The authors highlight several advantages of their approach, including improved numerical stability, representation agnosticism, reduced computation graphs, and support for manifold optimization. They demonstrate the effectiveness of their approach in various vision and robotics tasks such as pose graph optimization, inverse kinematics, RGB-D scan registration, and RGB-D SLAM.The authors have implemented their approach as an easy-to-use PyTorch library called LieTorch, which provides transparent backpropagation for 3D transformations. This library supports insertion of 3D transformations into computation graphs and offers familiar tensor-like operations.The contributions of this paper are twofold. Firstly, it introduces the concept of performing backpropagation in the tangent space of 3D transformation groups, which is novel in training neural networks. Secondly, it presents LieTorch as an open-source library for tangent space backpropagation, which is expected to be a valuable tool for researchers in 3D vision and robotics.