Tracking multiple objects in videos is a challenging problem with various applications in fields such as surveillance, business analytics, robotics, and autonomous driving. The goal of multiple object tracking (MOT) is to accurately estimate the trajectory of each individual person in a scene, without any contamination by other objects. While significant research has been done to develop robust MOT algorithms, the problem remains unsolved, as indicated by the latest benchmark results. The main challenges in MOT are occlusion and scene clutter, which make it difficult to accurately track objects and distinguish between similar targets. Traditional approaches to MOT rely on heuristics and hand-defined mechanisms to handle occlusions, but these methods are often not optimal and have limited computational efficiency. In this paper, we propose a data-driven approach to MOT that utilizes two key modules: proposal generation and proposal scoring with a graph convolutional network (GCN). The proposal generation module generates a set of proposals that cover each individual person while allowing for some contamination. The proposal scoring module uses a trainable GCN to score the proposals and rank them based on their quality. Finally, an inference algorithm is used to generate the final tracking output. Our approach offers several contributions, including a novel learnable framework for MOT, an iterative graph clustering strategy for proposal generation, the use of a trainable GCN for proposal scoring, and improved state-of-the-art results on MOTChallenge benchmarks.