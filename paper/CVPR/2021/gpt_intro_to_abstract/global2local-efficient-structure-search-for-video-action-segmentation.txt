Action recognition is a crucial task in computer vision applications such as video tagging, surveillance, and anomaly detection. While short trimmed videos with single activities have been extensively studied, segmenting each frame densely in long untrimmed videos is challenging due to the presence of multiple activities with varying temporal lengths. Temporal convolutional networks (TCN) have shown promise in action segmentation tasks by capturing both long-term and short-term information. However, designing appropriate receptive fields in TCN layers to balance long-term dependencies and local details remains a challenge. In this paper, we propose a global-to-local search scheme to explore effective receptive field combinations in TCN. Our approach includes a genetic-based global search to find coarse receptive field combinations and an expectation guided iterative local search to refine the combinations. The global search identifies various combinations that outperform human-designed patterns, while the local search determines fine-grained dilation rates to improve performance. Our proposed scheme achieves impressive performance gain compared to human-designed structures and provides a low-cost solution for searching fine-grained receptive field combinations in the dense search space. Overall, our contributions include the expectation guided iterative local search scheme and the discovery of effective receptive field combinations through the global-to-local search approach.