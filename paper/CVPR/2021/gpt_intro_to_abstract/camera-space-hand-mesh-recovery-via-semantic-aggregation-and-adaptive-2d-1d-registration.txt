Monocular 3D mesh recovery from a single RGB image is a challenging task with wide-ranging applications in areas such as augmented reality, virtual reality, and human-machine interaction. Existing methods for 2D-to-3D reconstruction have limitations in accurately estimating the 3D locations of mesh vertices, particularly for highly articulated structures, 2D-to-3D ambiguity, and self-occlusion. This paper proposes a camera-space mesh recovery (CMR) framework that integrates the tasks of 3D hand mesh and root recovery into a unified framework. The CMR framework comprises three phases: 2D cue extraction, 3D mesh recovery, and global mesh registration. The authors introduce an Inception Spiral Module for robust 3D decoding and design an aggregation method to collect effective 2D cues by exploiting high-level semantic relations. They also present an adaptive 2D-1D registration method that leverages joint landmarks and silhouette in different dimensions for robust root recovery. Experimental results demonstrate that the CMR framework surpasses state-of-the-art methods in both mesh and root recovery tasks on datasets such as FreiHAND, RHD, and Human3.6M. Overall, this paper contributes a novel approach for monocular 3D mesh recovery and presents a unified pipeline for camera-space mesh recovery with promising results.