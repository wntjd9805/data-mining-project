The traditional approach for learning visual representations involves pretraining a convolutional network on annotated images from ImageNet and then transferring the learned features to other computer vision tasks. However, this method is expensive and relies on human workers for image annotation. As a result, there has been growing interest in unsupervised pretraining methods that use unlabeled images to learn visual representations.In this paper, we propose an alternative approach called VirTex, which learns visual representations from textual annotations. Our method involves joint training of a ConvNet and Transformer to generate natural language captions for images. We then transfer the learned features to downstream visual recognition tasks.We believe that using language supervision is advantageous due to its semantic density, as captions provide a richer learning signal compared to unsupervised contrastive methods and supervised classification. By leveraging textual features, we hypothesize that we can achieve high-quality visual representations with fewer images.Another benefit of using textual annotations is the simplified data collection process. Unlike the complex pipelines involved in eliciting labels for classification tasks, natural language descriptions can be easily obtained from non-expert workers without the need for an explicit ontology.Our main contribution is demonstrating that natural language can serve as effective supervision for learning transferable visual representations in a data-efficient manner. We train our models from scratch on the COCO Captions dataset and evaluate the learned features on various downstream tasks. Remarkably, our VirTex approach outperforms existing methods for supervised or unsupervised pretraining on ImageNet, while using significantly fewer images. Our code and pretrained models are available for public use.In summary, our work introduces VirTex, an approach for learning visual representations from textual annotations. By leveraging the semantic density and simplified data collection process of language supervision, we demonstrate improved data efficiency compared to traditional methods.