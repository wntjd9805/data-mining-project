This paper introduces the concept of Dynamic Slimmable Network (DS-Net), a new dynamic network routing regime for improving hardware efficiency in deep neural networks. Unlike existing dynamic pruning methods, DS-Net uses a technique called dynamic slicing to adjust the network width without introducing extra computation costs. The authors propose a double-headed dynamic gate that predictsively adjusts the filter numbers of networks at test time. To train the dynamic networks, a two-stage training scheme with In-place Ensemble Bootstrapping (IEB) and Sandwich Gate Sparsification (SGS) techniques is proposed. Experimental results demonstrate that DS-Net outperforms static and dynamic model compression methods, achieving significant computation reduction and real-world acceleration with minimal accuracy drops.