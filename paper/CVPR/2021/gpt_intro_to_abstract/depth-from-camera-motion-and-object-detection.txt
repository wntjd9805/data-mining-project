This paper addresses the problem of estimating the depth of objects using uncalibrated camera motion and bounding boxes from object detection. The authors previously developed a method of video object segmentation-based visual servo control, object depth estimation, and mobile robot grasping using a single RGB camera. To improve accuracy and bridge the gap between 3D applications and video object segmentation, the authors introduced a learning-based method for estimating object depth via motion and segmentation. Motivated by these developments, this paper focuses on estimating object depth using uncalibrated camera motion and bounding boxes from object detection. The authors derive an analytical model and solution for this problem, achieving the best analytical result on the benchmark dataset. They also develop a recurrent neural network (RNN) for depth prediction and introduce the Object Depth via Motion and Detection (ODMD) dataset for training and evaluation. The ODMD dataset consists of bounding boxes, camera movement distances, and ground truth object depth. Training with perturbations improves performance in real applications, and the dataset is designed to be simple and generalizable to various domains. The authors demonstrate the effectiveness of their approach through experiments and achieve state-of-the-art results on the benchmark dataset.