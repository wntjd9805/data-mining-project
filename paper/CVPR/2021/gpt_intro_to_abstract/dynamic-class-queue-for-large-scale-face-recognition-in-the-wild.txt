Face recognition has made significant advancements with the emergence of deep neural networks and large-scale datasets. The size of public training datasets has been steadily increasing, leading to improved performance. However, the growing training data poses challenges in terms of computing resources and long-tailed class distribution. To address these challenges, various methods have been proposed, such as pairwise-based methods and dynamic class selection. However, these methods still require storing all class weights in memory. In this paper, we propose a computationally efficient and memory-friendly method called Dynamic Class Queue (DCQ). DCQ dynamically selects a subset of classes for classification and generates class weights on-the-fly instead of learning them via SGD. The class weights are stored in a queue, reducing memory consumption significantly. We empirically demonstrate the effectiveness and efficiency of DCQ, achieving comparable performance to baseline methods while using only a fraction of classes. Our method is particularly useful in real-world long-tailed datasets, as demonstrated on the MF2 dataset, where we achieve improved results with only 10% of the classes.