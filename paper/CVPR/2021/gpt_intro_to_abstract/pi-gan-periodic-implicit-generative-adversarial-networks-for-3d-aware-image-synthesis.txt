Generative Adversarial Networks (GANs) have shown great potential in generating photorealistic images in 2D [24, 25, 26], but their application in 3D image synthesis has been limited due to a lack of realistic 3D training data. In this paper, we propose a novel approach called Periodic Implicit Generative Adversarial Networks (π-GAN) for unsupervised 3D representation learning from 2D images. Our method utilizes a SIREN network to condition an implicit radiance field, which maps 3D locations and 2D viewing directions to view-dependent radiance and view-independent volume density. By using differentiable volume rendering techniques, the radiance field can be rendered from arbitrary camera poses, enabling the synthesis of view-consistent images from multiple perspectives. π-GAN significantly improves image quality and view-consistency compared to existing 3D-aware image synthesis methods. We also introduce two technical contributions: conditioning layers in the SIREN network using feature-wise linear modulation (FiLM), and a progressive growing strategy to accelerate training. Our experimental results demonstrate that π-GAN achieves state-of-the-art results on real-world and synthetic datasets, with applications to novel view synthesis. The 5D spatio-angular radiance field representation used by π-GAN also allows for the extraction of interpretable 3D proxy shapes. Our contributions include introducing SIREN-based implicit GANs as an alternative to convolutional GAN architectures, proposing FiLM conditioning and progressive growing for improved results, and demonstrating the advantages of using neural radiance fields for view consistency and camera control.