This paper focuses on the subproblems involved in self-driving systems and their sequential approach of solving them in the classical formulation. These subproblems include localization, perception, prediction, motion planning, and control. However, the assumption of accurate localization is made in most cases, neglecting the potential impact of localization errors on the overall system performance. The authors observe that localization errors can lead to missed detections, prediction errors, inaccurate planning, larger discrepancies with human trajectories, and increased collision rates. Recent systems have started to address multiple autonomy tasks jointly, utilizing a shared neural backbone to decrease complexity and produce interpretable outputs. However, these joint formulations have mainly focused on specific combinations such as perception and prediction or perception, prediction, and motion planning. In this paper, the authors propose a joint design philosophy for the tasks of localization, perception, and prediction, referred to as LP2. They develop an LP2 system that shares computation between the tasks, allowing for efficient localization with minimal computational overhead. The proposed system is evaluated on a large-scale dataset and compared to traditional systems with separate localization and perception components. The results show that the LP2 approach matches the performance of the traditional system while correcting localization errors online and reducing runtime and engineering complexity. An example scenario is presented to highlight the impact of localization errors, where a small error leads to a collision. The significance of addressing localization errors in autonomous systems is emphasized, particularly in the context of achieving accurate perception, prediction, and motion planning.