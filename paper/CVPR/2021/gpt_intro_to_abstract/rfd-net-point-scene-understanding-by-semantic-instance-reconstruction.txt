Semantic scene reconstruction is a crucial task in various applications such as robot navigation and interior design. This process involves recovering object labels, poses, and geometries from partial observations of a 3D scene. While instance reconstruction from images using 2D CNNs has shown promising results, the depth ambiguity still hinders accurate object location. Point clouds, on the other hand, provide surface geometry that can alleviate this issue, but their sparse and irregular nature poses challenges for direct grid-based CNN usage.In the context of 3D scene scanning, missing geometries are common due to occlusions, view constraints, and weak illumination. Previous works have explored different strategies to recover missing shapes, including depth inpainting, voxel/TSDF prediction, and shape retrieval. Depth inpainting aims to complete depth maps in single views using 2D CNNs, while extending these methods to 3D through voxel/TSDF grids enables scene completion and semantic/instance-level reconstruction. Additionally, shape retrieval approaches search for CAD models that resemble the incomplete object, with accuracy and computation efficiency reliant on dataset scale. In this paper, we propose RfD-Net, a reconstruction-from-detection framework that enables end-to-end semantic instance reconstruction directly from raw point clouds. Our approach leverages object detections for spatial alignment and local shape reconstruction. By decoupling the scene reconstruction problem into global localization and local shape prediction, we embed a shape reconstruction head with a 3D detector backbone. This design exploits the sparsity of point clouds and enables higher-resolution surface reconstruction through implicit function learning. Experimental results demonstrate the complementary effects of joint shape reconstruction and 3D detection, consistently outperforming prior methods in 3D detection and instance reconstruction. In summary, our contributions include introducing a novel learning modality for semantic instance reconstruction, proposing the RfD-Net architecture for learning object semantics and shapes from sparse point clouds, and showcasing the complementary benefits of joint learning object poses and shapes. Our method achieves state-of-the-art results in instance detection and completion, as well as significant improvements in object reconstruction.