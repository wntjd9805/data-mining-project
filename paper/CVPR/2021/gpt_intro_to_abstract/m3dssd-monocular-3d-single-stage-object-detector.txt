Three-dimensional (3D) object detection is crucial for machines to sense their environment and interact with the real world. It plays a significant role in systems such as autonomous vehicles and robots. While existing methods rely heavily on expensive LiDAR or binocular camera-based approaches, we propose a cost-effective monocular camera-based approach for 3D object detection. Monocular 3D object detection is challenging due to the lack of depth information. Previous methods either rely on depth estimation using CAD models or pre-trained models, which indirectly use 3D depth ground-truth data. We introduce a novel Asymmetric Non-local Attention Block (ANAB) that computes the response at a position as a weighted sum of features from all positions. We also utilize multi-scale features to learn depth-wise features and propose a two-step feature alignment method to address feature mismatching between 2D and 3D bounding box predictions. Our proposed method achieves state-of-the-art performance on the KITTI benchmark. We contribute a simple and efficient monocular 3D single-stage object detection method (M3DSSD), a novel attention block for depth-wise feature extraction, and a two-step feature alignment module to improve the accuracy of object detection.