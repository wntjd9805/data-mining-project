Model pre-training is essential in person Re-identification (Re-ID) due to the difficulty and expense of data collection and annotation. However, existing public datasets for Re-ID have limited scale, leading to a shortage of training data. Previous research has attempted to use models pre-trained on ImageNet for Re-ID tasks, but the domain gap between ImageNet and Re-ID data poses challenges. In this paper, we propose large-scale unsupervised pre-training for person Re-ID feature representation learning. We introduce a new dataset called LUPerson, which consists of 4 million person images from over 200,000 identities extracted from YouTube videos. This dataset is 30 times larger than the largest existing Re-ID dataset and covers various capturing environments, providing a diverse set of data for learning generic representations. We find that directly applying contrastive learning methods does not work well for unsupervised Re-ID feature learning due to unique factors in the Re-ID task. We investigate factors such as color distortion, task-specific augmentation, and temperature parameter usage in the contrastive loss. Our pre-trained model demonstrates significant improvements in performance on various person Re-ID datasets, outperforming state-of-the-art methods. Additionally, our unsupervised representation learning benefits both supervised and unsupervised Re-ID methods. The contributions of this research include the creation of the LUPerson dataset, the feasibility of generic unsupervised pre-training for Re-ID tasks, and the improvement of performance for both supervised and unsupervised Re-ID methods.