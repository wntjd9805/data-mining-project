Inferring the geometric structure from a single image has been extensively studied, and convolutional neural networks have emerged as a powerful tool in these tasks. With the increasing popularity of consumer-level 360◦ cameras, the estimation of room layouts from single 360◦ panoramas has become crucial for applications such as virtual and augmented reality (VR/AR) and robotic vision. However, existing methods for room layout estimation often fall short in accurately reconstructing the 3D layout of a room from a 2D panorama.One of the main issues is that these methods are trained using a loss function based on the pixel coordinates of the 2D panorama, rather than the coordinates of the 3D reconstruction. This approach fails to capture the fact that pixels with different depths from the camera should contribute differently to the loss in the 3D coordinate. Additionally, existing methods tend to focus on the correctness of the majority of the segment rather than the boundary of the segment when using additional losses such as binary segmentation.In this paper, we propose a novel approach for room layout estimation from single 360◦ panoramas. We reformulate the layout estimation problem into a unique depth estimation problem by estimating the depth values on the horizon line of the panorama. We introduce a differentiable procedure called L2D (Layout-to-Depth) to transform the layout into a "layout-depth" representation, which enables us to leverage widely-used objective functions in depth estimation.Our proposed method, LED2-Net, takes advantage of a ray-casting technique to recover the depth values for the corner points in the room layout. To balance efficiency and accuracy, we propose a "Grid Re-sample" strategy that approximates the horizon-depth map with a flexible number of casting rays. We demonstrate the effectiveness of our model on four benchmark datasets and show that it outperforms state-of-the-art approaches in both within-dataset and cross-dataset evaluations.Furthermore, we leverage the property of our depth estimation objective to enable depth pre-training using a synthetic dataset, which further improves the generalizability of our model. Our experiments and evaluation results illustrate the benefits of our proposed framework for 360◦ layout estimation.In summary, our contributions include the reformulation of the 360◦ layout estimation problem into a 360◦ depth estimation problem, the proposal of a differentiable layout-to-depth procedure that enables end-to-end training, and the demonstration of the improved generalizability through depth pre-training.