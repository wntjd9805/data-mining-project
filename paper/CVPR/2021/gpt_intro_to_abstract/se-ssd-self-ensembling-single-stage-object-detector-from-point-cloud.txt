This paper introduces the Self-Ensembling Single-Stage object Detector (SE-SSD) for efficient and precise 3D object detection in autonomous driving using LiDAR point clouds. The SE-SSD framework consists of a teacher SSD and a student SSD, where the teacher produces more precise bounding boxes and confidence as soft targets to supervise the student. A novel IoU-based matching strategy and consistency loss are designed to align the student's predictions with the soft targets. Additionally, a shape-aware augmentation scheme is employed to encourage the model to infer complete object shapes from incomplete information. The SE-SSD is trained in a fully-supervised manner, utilizing both soft and hard targets, achieving state-of-the-art performance on 3D and bird's eye view car detection benchmarks. The proposed framework demonstrates ultra-high inference speed on CPU-GPU and outperforms prior works.