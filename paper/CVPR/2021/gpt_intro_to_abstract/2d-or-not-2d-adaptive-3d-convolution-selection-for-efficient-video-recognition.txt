Videos are expected to dominate Internet traffic in the near future, highlighting the need for efficient and accurate approaches for understanding video content. Temporal modeling, specifically through 3D convolutional networks, has been extensively studied to capture relationships among frames. However, these models are computationally expensive, requiring costly convolution operations on a large number of frames. This paper introduces Ada3D, a framework that learns adaptive usage of 3D convolutions and frames for efficient video recognition. By dynamically determining the number of frames and 3D convolutional layers to use based on the content of each clip, Ada3D allocates more resources to videos with complex motion patterns while performing economical inference for static videos. This framework is built upon a reinforcement learning framework and is optimized using policy gradient methods. Experimental evaluations on multiple datasets demonstrate that Ada3D can save significant computation while maintaining similar recognition performance compared to baselines. The learned policies can also be transferred to larger datasets and are compatible with different 3D models, making Ada3D a versatile and efficient approach for video recognition.