Deep neural networks have revolutionized computer vision capabilities, but they often require large amounts of labeled training data. To address this limitation, self-supervised methods have been explored, where proxy tasks guide network training. One common approach is to predict one part of the data from another, such as colorization or inpainting. Another class of approaches involves unsupervised learning within a generative modeling context, using techniques like GANs or VAEs. Inspired by these approaches, this paper focuses on the unsupervised segmentation task, specifically the segmentation of images into meaningful regions without relying on labeled data. The paper introduces the Inpainting Error Maximization (IEM) method, which relies on the intuition that segmentation into objects minimizes mutual information between pixels in the segments. The paper describes how IEM is implemented through a gradient descent on the segmentation and shows example results of foreground-background segmentation. The paper demonstrates that IEM segmentations can be used as noisy training labels to train a deep segmentation network, further improving segmentation quality. The paper compares IEM to other unsupervised segmentation approaches, showing competitive performance in terms of intersection-over-union. Additionally, the paper proposes a refinement phase for IEM, where a neural segmentation network is trained on high-error IEM segmentations to outperform competing methods. Overall, the paper challenges dominant approaches to unsupervised segmentation and highlights the potential of IEM as a new direction for unsupervised methods.