Active depth cameras, along with RGB cameras, have facilitated high-fidelity scene reconstructions and enabled research on computer vision problems. However, challenges remain in depth imaging under strong ambient light and for dynamic scenes. Various active depth sensing approaches have been explored, such as structure light and time-of-flight cameras. While time-of-flight sensors provide accurate depth, their low fill factor limits the acquisition of dense depth maps. Correlation time-of-flight sensors suffer from ambient illumination and multi-path interference. Active stereo cameras have emerged as a low-cost depth sensing modality, but they struggle with extreme ambient illumination and complex scenes. These limitations arise from hand-engineered pipeline designs for illumination patterns and reconstruction algorithms. In this work, we propose an end-to-end learning method that jointly optimizes illumination patterns and reconstruction algorithms. Our method, called Polka Lines, achieves high-quality scene reconstructions and allows for the learning of environment-specific illumination patterns. We introduce a differentiable image formation model that accurately simulates illumination and capture. Additionally, we devise a trinocular active stereo network that leverages the known illumination pattern to reduce reconstruction errors near occlusion boundaries. We validate our method through simulations and an experimental prototype, demonstrating robust depth acquisition across diverse scenarios. This paper makes contributions in the form of the proposed differentiable image formation model, the trinocular active stereo network, the learning of optimal illumination patterns, and the validation of the method in various imaging conditions.