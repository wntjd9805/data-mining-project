In this paper, we address the problem of 3D object detection using only monocular images. Most existing methods for 3D object detection rely on LiDAR sensors or stereo cameras, which can be costly to implement in practical systems. Therefore, monocular 3D object detection has gained attention as a more promising and cost-effective solution.One common approach in 3D object detection is to handle different objects using a unified approach. However, we observe that this can lead to unsatisfactory performance, particularly in detecting heavily truncated objects that are crucial for the safety of autonomous vehicles. We also find that these hard samples can increase the learning burden and impact the prediction of general objects. Therefore, we propose a flexible detector that considers the differences among objects and estimates their 3D locations in an adaptive manner.To localize the projected 3D center of objects, we divide them into two groups: "inside" objects and "outside" objects. Inside objects are represented by their projected centers, while outside objects are represented by carefully chosen edge points. This allows us to handle the inner and edge regions of the feature map differently. Additionally, we introduce an edge fusion module to decouple the feature learning and prediction of outside objects.In terms of estimating object depth, we combine different depth estimators with uncertainty estimation. These estimators include direct regression and geometric solutions from keypoints. We address the challenge of computing depth from keypoints by splitting them into multiple groups and formulating the final estimation as an uncertainty-weighted average. This allows the model to choose the most suitable estimators for robust and accurate predictions.We evaluate our approach on the KITTI dataset and demonstrate its superior performance compared to existing methods, especially for moderate and hard samples. The contributions of this paper can be summarized as follows: (1) We emphasize the importance of considering the differences among objects in monocular 3D object detection and propose a method to handle truncated objects separately, and (2) We propose a new formulation for object depth estimation that leverages uncertainties to flexibly combine independent estimators.