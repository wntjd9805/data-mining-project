Motion understanding plays a crucial role in various fields including human-computer interaction, robotics, and autonomous driving. In the past, computer vision techniques focused on estimating motion between two images, but the introduction of 3D geometry allows for a more comprehensive understanding of scene flow. However, incorporating non-rigid movements or piece-wise movements into the scene flow estimation problem has made it challenging to solve. With advancements in artificial intelligence, there has been progress in learning-based methods for 3D flow estimation, outperforming traditional optimization approaches. Scene flow estimation is particularly important in autonomous driving, where LiDAR data is used for environment perception. However, sparse LiDAR data poses difficulties for deep-learning flow algorithms, which rely on knowledge of the spatio-temporal neighborhood of objects. To address this limitation, all-to-all mechanisms have been proposed, but they consume large amounts of memory and may produce inconsistencies. This work focuses on scene flow estimation with large deviations, utilizing a small set of points for alignment and employing a recurrent refinement block that learns movement differentiators. The network is trained to predict one step at a time and iteratively converge towards the final flow solution. Trained solely on synthetic data, the proposed method achieves significant improvements over existing self-supervised methods on benchmark datasets. The key contributions of this work include the introduction of a recurrent architecture for non-rigid scene flow, a memory-efficient all-to-all correlation pipeline, and improved results in a fully-supervised framework.