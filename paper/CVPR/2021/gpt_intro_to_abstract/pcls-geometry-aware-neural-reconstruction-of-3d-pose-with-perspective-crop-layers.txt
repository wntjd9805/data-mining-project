Convolutional neural networks (CNNs) have achieved great success in image-based prediction tasks due to their translation invariance and ability to focus on informative image locations. However, CNNs ignore perspective effects that result from projecting a 3D scene onto a 2D image plane. This can lead to different features being extracted for the same pose at different image locations. Increasing the size of the network can partially address this issue, but it relies on large amounts of training data. Existing two-stage approaches also face limitations in accounting for perspective distortion. To address these challenges, this paper introduces Perspective Crop Layers (PCLs) to explicitly account for perspective distortion in CNNs and other neural networks. PCLs use a homography to map the input image to a virtual camera with predefined intrinsic parameters, focusing on the region of interest (RoI). This synthetic view compensates for location-dependent perspective deformations. The 3D pose inferred from this view can then be projected back into the original image. PCLs are robust to calibration inaccuracies and all their operations are differentiable, facilitating end-to-end learning.The contributions of this research can be summarized as follows: 1. Showcasing the influence of perspective effects on 3D pose estimates, which are often ignored by state-of-the-art algorithms. 2. Deriving equations to compensate for perspective effects in a location-dependent manner across the entire image. 3. Encapsulating the proposed formalism into PCLs, which can be easily integrated into existing deep learning frameworks. 4. Demonstrating the benefits of PCLs in 3D human pose estimation for both rigid objects and articulated people. PCLs consistently improve performance, with an average boost of 2-10% and up to 25% at the image boundary where perspective effects are strongest. This improvement is observed across various baseline methods, validating the claim that existing deep networks fail to learn perspective effects in current datasets. In addition, a variant of PCLs that addresses perspective effects on 2D keypoints demonstrates the benefits of the approach for state-of-the-art 3D pose estimation methods. The code for PCLs is publicly available.