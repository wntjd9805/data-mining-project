This paper presents a novel object-centric long-term video recognition model called Object Transformers. Unlike existing top-performing recognition models that focus on short video clips and lack long-term temporal reasoning, Object Transformers capture complex synergies among objects across time. This model takes advantage of current image-based recognition architectures to detect and track objects throughout a video and utilizes a transformer-based architecture to model interactions between these objects. Additionally, a large-scale benchmark comprising 9 diverse tasks on over 1,000 hours of video is introduced. Experimental results demonstrate that Object Transformers outperform existing state-of-the-art methods on long-form video understanding tasks and significantly outperform current methods on existing datasets.