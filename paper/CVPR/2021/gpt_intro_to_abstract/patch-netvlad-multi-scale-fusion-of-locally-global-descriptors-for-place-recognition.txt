Visual Place Recognition (VPR) is essential for numerous applications in robotics and autonomous systems. However, it is a challenging task due to changes in appearance, illumination, and viewpoint. This paper introduces Patch-NetVLAD, a novel visual place recognition system that combines the strengths of global and local approaches while minimizing their weaknesses. Patch-NetVLAD generates a similarity score between two images through local matching of locally-global descriptors extracted from patches in the feature space. Additionally, a multi-scale fusion technique is proposed to improve performance. The paper provides various system configurations with different performance and computational balances, achieving state-of-the-art recall performance, faster processing speeds, and flexibility based on task requirements. Extensive evaluations on well-known datasets demonstrate the superiority of Patch-NetVLAD over state-of-the-art global feature descriptor methods and local descriptor baselines. The system's properties are analyzed through ablation studies, and the code is made available for future research.