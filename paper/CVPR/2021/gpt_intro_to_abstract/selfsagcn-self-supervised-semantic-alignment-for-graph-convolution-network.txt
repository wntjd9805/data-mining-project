Graph convolution networks (GCNs) have been widely used in various applications, such as social networks, knowledge graphs, and molecular structures. Recent developments in deep learning for graph structure data have led to the rapid advancement of GCNs. GCNs apply linear transformations and graph aggregation to obtain low-dimensional features for graph nodes. There are two main categories of GCNs, spatial and spectral convolution methods. Spatial methods define the graph convolution layer using operations on node neighbor groups, while spectral methods define the graph convolution operation based on the spectral representation of graphs. Although GCNs have achieved significant success, their performance declines when there is a limited number of labeled nodes per class. This is due to overfitting and over-smoothing problems. Overfitting occurs when an algorithm performs well on the training data but fails to generalize to new, unseen data. Over-smoothing refers to the degradation of performance that occurs when more layers are stacked with nonlinearity activations in GCNs. To address these issues, this paper proposes a Self-Supervised Semantic Alignment Graph Convolution Network (SelfSAGCN) that integrates semantic extraction and alignment into traditional GCNs. SelfSAGCN consists of two crux techniques, Identity Aggregation and Semantic Alignment. Identity Aggregation extracts semantic information from labeled nodes, while Semantic Alignment transfers this information to unlabeled nodes for improved feature alignment. Experimental results demonstrate the effectiveness of SelfSAGCN, outperforming state-of-the-art methods on various classification tasks. This paper contributes to mitigating the overfitting and over-smoothing problems in GCNs and improving the discriminative power of node features.