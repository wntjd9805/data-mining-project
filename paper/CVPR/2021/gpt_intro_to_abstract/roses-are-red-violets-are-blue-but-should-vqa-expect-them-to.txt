Visual Question Answering (VQA) is a challenging task that requires learning-based systems to perform high-level reasoning by answering questions about images. However, VQA models are faced with the diversity and complexity of the physical world, and must learn various high-level representations of concepts and interactions. To learn these reasoning capabilities, large-scale datasets are used, but it is important to ensure that the data is free from biases that could lead to unwanted shortcuts in learning.In this paper, we address the issue of bias exploitation in VQA and propose a new benchmark for Out-Of-Distribution (OOD) evaluation. This benchmark includes distribution shifts tailored to different question groups with highly imbalanced distributions. We introduce a new evaluation metric based on the rarity of concepts within each question group, which is shown to be less prone to bias exploitation.We demonstrate that state-of-the-art (SOTA) VQA models and bias reduction methods reproduce biases present in the training data, leading to limited generalization capabilities. Despite the recognition of this problem, there is a lack of systematic evaluations of error distributions in VQA models. This paper aims to fill this gap by providing insights into how errors are distributed, whether true positives are a result of reasoning or bias exploitation, and the prediction accuracy on infrequent versus frequent concepts.To achieve this, we propose a new benchmark based on the GQA dataset, which allows for a fine-grained analysis of biases and distribution shifts. We reorganize the dataset to create distribution shifts in both the validation and test sets, and introduce new evaluation metrics and plots to analyze the generalization behavior of VQA models. Our benchmark complements existing evaluation protocols and provides a better diagnostic tool for assessing VQA performance.Our contributions include the release of the reorganized GQA dataset and associated evaluation metrics, enabling precise evaluation of reasoning behavior and characterization of generalization. Compared to other benchmarks, our dataset includes distribution shifts in both the validation and test sets, providing the ability to validate models in OOD conditions. We experimentally evaluate the proposed metric and demonstrate its efficacy in distinguishing models that exploit biases. Furthermore, we perform a comprehensive study of several recent VQA models and show their limited generalization capabilities in OOD conditions. We also evaluate SOTA bias reduction methods and identify opportunities for further improvement in addressing bias in VQA.