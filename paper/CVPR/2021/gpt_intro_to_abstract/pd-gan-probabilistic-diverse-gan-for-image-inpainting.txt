In recent years, there has been increasing attention on the development of advanced image inpainting methods for content removal and image restoration. These methods typically use deep Convolutional Neural Networks (CNNs) to generate meaningful image content for hole filling. While deep encoder-decoder networks have improved image inpainting performance, they tend to produce a single restored result for each input image.In practice, image inpainting may produce multiple results due to the uncertain content generation within the hole region. However, existing methods have limited effectiveness in generating both diverse and realistic contents. One reason is that these methods still rely on the encoder-decoder structure, which models the current masked image to a Gaussian distribution and decodes it into a completed image. This limits the diversity of content generation, particularly for free-form hole regions. Additionally, these methods heavily rely on image reconstruction loss during training, which restricts the diverse content generation.To address these limitations, we propose PD-GAN, a diverse image inpainting network built upon a vanilla GAN. Instead of using input images, PD-GAN starts from a random noise vector and decodes it to generate content. We introduce the SPDNorm module to inject prior information and the region mask into all decoder layers. This module learns a spatial transformation with hard and soft probabilistic diversity maps for feature fusion, enhancing diversity towards the hole center and reducing it towards the hole boundary.We also propose a perceptual diversity loss to empower the diverse generation ability of PD-GAN. This loss forces two output images generated with the same prior information but different input noise vectors to be farther in feature space. By training PD-GAN with the perceptual diversity loss, we can effectively generate diverse and visually realistic contents for image inpainting.Our contributions include the modulation of deep features of the random noise vector using the SPDNorm module to incorporate context constraint, the introduction of a perceptual diversity loss to enhance network diversity, and the demonstration of the effectiveness of PD-GAN in generating diverse and visually realistic contents for image inpainting through experiments on benchmark datasets.