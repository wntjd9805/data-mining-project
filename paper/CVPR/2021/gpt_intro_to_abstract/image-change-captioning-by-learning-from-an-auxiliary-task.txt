This paper introduces the task of change captioning, which aims to generate detailed sentences describing the differences between two images at the object level. While previous works have focused on localizing changes, change captioning provides a more meaningful understanding of image differences for users. The paper addresses the limitation of assuming object changes in all image pairs by proposing robust change captioning, which can handle distractors with similar scenes. The proposed method utilizes multi-task learning, with the primary task being change captioning and the auxiliary task being composed query image retrieval. The paper proposes a joint learning scheme that sequentially performs these tasks, reinforcing each other during training. The contributions of the paper include the proposed learning scheme, a new strategy for selecting hard negative samples, and empirical experiments demonstrating improved performance on the CLEVR-Change and Spot-the-diff datasets.