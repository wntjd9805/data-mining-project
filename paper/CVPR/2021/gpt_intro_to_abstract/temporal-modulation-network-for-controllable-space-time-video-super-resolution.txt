This paper introduces the concept of Space-Time Video Super-Resolution (STVSR) in the context of broadcasting videos on Ultra High Definition Televisions (UHD TVs). While current videos are commonly in Full High Definition (FHD) with a resolution of 2K at 30 frames per second (FPS), UHD TVs can display videos with resolutions of 4K or 8K at higher frame rates. To broadcast FHD videos on UHD TVs, it is necessary to increase both the spatial and temporal resolutions of the videos. However, previous model-based STVSR methods rely heavily on precise spatial and temporal registration, leading to inferior results when the registration is inaccurate. Additionally, these methods involve solving complex optimization problems, resulting in low inference efficiency. To overcome these limitations, recent developments in deep convolutional neural networks have been applied to video restoration tasks such as STVSR. However, current STVSR networks are restricted to highly-controlled application scenarios with fixed frame rates. In this paper, the authors propose a Temporal Modulation Network (TMNet) that can interpolate an arbitrary number of intermediate frames for STVSR. The TMNet incorporates motion cues through a Temporal Modulation Block (TMB), enabling controllable interpolation at any moment defined by a temporal parameter. The authors also introduce a two-stage temporal feature fusion scheme that accurately interpolates the intermediate frames for STVSR. Experimental results on three benchmarks demonstrate that the TMNet achieves state-of-the-art performance on STVSR, making it a flexible and effective solution for frame interpolation in broadcasting scenarios.