Deep visual models have achieved impressive performance in various vision tasks, but they lack transparency, making them difficult to deploy in high-risk applications where explanation is crucial. This paper addresses this issue by proposing CAMERAS, a technique for precise backpropagation image saliency that preserves sanity. CAMERAS accumulates and fuses multi-scale activation maps and backpropagated gradients to construct high-resolution saliency maps without the need for external factors or heuristics. The proposed method outperforms state-of-the-art saliency methods and enables visualization of differences in model performance and discrimination of input features. Furthermore, CAMERAS improves the efficacy of adversarial attacks and calls for new evaluation metrics and sanity checks in the field of saliency computation.