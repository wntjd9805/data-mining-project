Abstract:This paper presents a new approach to video compression using a feature-space video coding network (FVC) that reduces spatial-temporal redundancy in videos. Unlike traditional video codecs that rely on pixel-level operations, FVC performs all operations, including motion estimation, motion compensation, and residual compression, in the feature space. The proposed approach incorporates deformable convolution, which uses dynamic kernels to align consecutive frames in the feature space, allowing for improved motion compensation and reduced artifacts introduced by pixel-level operations. Additionally, a multi-frame feature fusion module is introduced to combine features from multiple previous frames for better frame reconstruction. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed framework, achieving state-of-the-art performance compared to existing learning-based video compression methods. Overall, the FVC framework offers a promising solution for the next generation of video compression technologies.