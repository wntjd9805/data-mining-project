In this paper, the authors address the problem of localizing visual objects that emit characteristic sounds in videos. They propose a new training scheme that explicitly seeks to spatially localize sounds by incorporating a background mining technique and introducing the concept of a Tri-map. This allows for the inclusion of uncertain regions and improves sound localization performance. The authors also introduce a new benchmark dataset, VGG-Sound Source, which provides high-quality bounding box annotations for sounding objects in over 5,000 videos spanning 200 categories. The proposed algorithm is evaluated on this dataset and shows significant improvements compared to existing methods. The authors believe that this work will be useful for further research in the field of sound localization in computer vision.