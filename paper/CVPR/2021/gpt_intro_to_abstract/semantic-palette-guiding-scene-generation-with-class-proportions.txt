Generative Adversarial Networks (GANs) have shown promise in generating photo-realistic images based on a collection of examples. However, for complex structured images like urban scenes, GANs struggle to produce satisfactory results. In this paper, we focus on the task of generating semantic layouts for urban scenes, which is important for applications such as image segmentation. Existing approaches decouple the synthesis process into two phases: generating semantic layouts and then translating them into realistic images. We propose a "Semantic Palette" approach that allows for tight control of class proportions when generating semantic layouts. This approach offers benefits in various applications, including real image editing and data augmentation for improved model training. We introduce a conditional layout GAN that takes a class histogram as input and propose novel architecture designs and learning objectives to achieve our goal. We conduct experiments on different urban scene datasets and assess the quality of the generated layouts and images, as well as the performance of segmentation models trained on synthesized data. Our approach outperforms baselines and improves the distribution of real scenes. Our contributions include a novel layout generative model, a variant for partial editing of semantic layouts, and extensive evaluations on driving benchmarks.