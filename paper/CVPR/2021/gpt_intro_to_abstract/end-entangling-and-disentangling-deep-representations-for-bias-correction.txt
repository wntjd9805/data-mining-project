In the past two decades, there has been a significant interest and research focus on artificial neural network models (ANNs). These models have proven effective in tackling complex and even ill-posed problems when trained with large datasets. Additionally, ANNs are increasingly being used to assist in decision-making processes, such as scouting and hiring individuals. However, concerns about the trustworthiness of AI systems have emerged, with calls for AI to be lawful, ethical, and robust. Ensuring robustness in AI models is particularly crucial, as these models may exhibit high confidence in their predictions while processing information in unintended ways.The problem of identifying "unknown unknowns" in data, where deep models generate predictions confidently but in unintended ways, has been discussed. This issue has affected AI-based solutions for COVID detection from radiographic images, as early datasets were heavily biased. Biases, such as the detection of catheters or medical devices for positive patients, the age of patients, or the origin of data, led to models predicting COVID diagnosis with high confidence. As a result, there is a need to address bias propagation in deep models.In this paper, we propose a regularization strategy called EnD (Entangle and Disentangle) to mitigate bias propagation in deep models. EnD aims to create an "information bottleneck" by entangling the deep features extracted from data belonging to the same target class and disentangling the features with biased labels. By minimizing the loss and applying EnD during training, biased features are discouraged in favor of unbiased ones. Importantly, EnD operates directly on the target model and can be minimized using standard backpropagation, eliminating the need for additional models or data manipulation.Addressing the problem of minimizing mutual information is challenging due to non-differentiability and computational complexity. However, previous studies have demonstrated the effectiveness of adding constraints to the learning problem. Our experimental results show that EnD successfully favors the selection of unbiased features during training, leading to comparable generalization capabilities compared to models trained with other debiasing techniques.The remainder of the paper is structured as follows: Section 2 reviews related works, Section 3 provides a detailed explanation of EnD, Section 4 presents empirical results, and Section 5 concludes the paper.