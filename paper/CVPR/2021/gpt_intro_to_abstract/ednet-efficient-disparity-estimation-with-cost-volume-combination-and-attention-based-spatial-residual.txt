Accurate and fast depth estimation is crucial for various applications such as robot navigation, 3D reconstruction, and autonomous driving. Stereo matching, which involves analyzing correspondence between pixels in stereo images, is a commonly used approach for depth estimation. Convolutional neural networks (CNNs) have been adopted to address the difficulties encountered in stereo matching, particularly in dealing with textureless and repetitive regions. Previous methods have achieved state-of-the-art performance by constructing a 4D concatenation volume followed by 3D convolution blocks for aggregation. However, this approach significantly increases computation cost and lacks feature similarity measurement. Another method utilizes a low-cost correlation layer with 2D convolutions, striking a good balance between speed and accuracy. However, performance is compromised as each disparity level has only one single feature channel. This raises the question of how to effectively leverage the advantages of both concatenation and correlation volumes. Inspired by the residual convolution block in ResNet, we propose EDNet, which combines a combined volume for robust feature representations and an attention-based residual module for disparity refinement. The combined volume consists of a squeezed concatenation volume and a correlation volume, preserving both contextual information and feature similarities. Further aggregation is achieved using 2D convolutions, reducing memory consumption and computational complexity. The attention-based residual module leverages spatial attention to generate attention-aware residuals, allowing for more efficient learning of disparity correction. By following a coarse-to-fine strategy and considering error maps at multiple scales, EDNet produces accurate and continuous disparity maps, even in low-texture regions. Our contributions include:- A low-cost method for aggregating 3D correlation features and 4D concatenation volume using a combined volume, which can be efficiently processed with 2D convolutions while preserving contextual information and feature similarities.- An Attention-based Residual (AR) module that utilizes the attention mechanism to improve learning efficiency for disparity refinement at each scale.- EDNet achieves state-of-the-art accuracy on public datasets, such as Scene Flow and KITTI, with significantly less memory requirement and faster speed compared to existing methods based on 3D CNNs.The remainder of the paper is organized as follows: Section 2 presents related studies on stereo matching based on CNNs. Section 3 explains the methodology and implementation of EDNet. Experimental results are provided in Section 4. Finally, Section 5 concludes the paper.