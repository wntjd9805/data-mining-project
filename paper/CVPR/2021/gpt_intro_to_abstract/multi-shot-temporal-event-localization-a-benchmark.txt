The paper introduces the research topic of multi-shot temporal event localization in TV shows and movies. This task aims to predict the semantic label of an action and locate its start and end times in a long video. The authors highlight the commercial applications of this research, such as generating trailers, video summaries, and mashups. They emphasize the unique characteristic of TV shows and movies, which is the frequent use of shot cuts. The authors explain the challenges of localizing events in these videos, including large intra-instance variation caused by shot cuts and side effects like scene changes and occlusions. To address these challenges, the authors present a large-scale dataset called MUlti-Shot EventS (MUSES) that contains drama videos processed by professional editing techniques. They also evaluate state-of-the-art methods on MUSES and provide a simple baseline approach for multi-shot temporal event localization. The paper concludes by making the dataset and project code publicly available for researchers.