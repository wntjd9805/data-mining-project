In recent years, deep learning methods have become popular for inferring 3D surface representations from 2D images. Traditional approaches involve using volumetric representations and marching-cube algorithms to create meshes, but these methods introduce artifacts and are not end-to-end differentiable. Direct methods that go from 2D images to 3D meshes have been proposed but suffer from generating unwanted artifacts. State-of-the-art methods try to handle these artifacts by introducing additional regularizing loss terms during training. However, effectively weighting these terms is challenging.In this paper, we propose a solution to this problem by introducing a special-purpose layer into the surface generating architecture. This layer uses a semi-implicit scheme to recursively solve sparse linear systems of equations, effectively propagating smoothness constraints and generating smoother meshes. The proposed scheme allows for local modulation of regularization, preserving accuracy only where needed. Additionally, it enables the use of meshes consisting of vertices with arbitrary degrees, which is important for modeling complex 3D objects with varying levels of smoothness.Our approach draws inspiration from Active Surface Models (ASMs) but extends them to handle irregular 3D surface meshes. Unlike existing ASM methods, we embed the models within contour deforming graph convolution networks. We also propose an original method to compute derivatives required for back-propagation on irregular meshes.Our contribution, known as Deep Active Surface Models (DASMs), outperforms equivalent architectures that use traditional loss functions to impose smoothness constraints. We demonstrate the effectiveness of DASMs in 3D surface reconstruction from 2D images and 3D volume segmentation.