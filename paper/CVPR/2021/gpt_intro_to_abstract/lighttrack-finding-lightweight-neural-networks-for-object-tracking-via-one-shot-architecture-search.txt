Object tracking is a challenging task in computer vision, with recent advancements achieved through the use of deep neural networks. However, these tracking models have become increasingly complex and resource-intensive, hindering their deployment in real-world applications where efficiency is crucial. This paper introduces a solution to address these issues by automating the design of lightweight models using neural architecture search (NAS). The proposed algorithm, called LightTrack, encodes all possible architectures into backbone and head supernets, trained on ImageNet and tracking data, respectively. Architecture search is performed using tracking accuracy and model complexity as guidance. To further reduce complexity, a search space consisting of lightweight building blocks is designed. Experiments demonstrate that LightTrack can efficiently search for lightweight object trackers that outperform existing methods while significantly reducing model complexity. When deployed on resource-limited chipsets, the discovered tracker runs much faster and requires fewer parameters and computations compared to state-of-the-art methods. This work contributes to the automation of neural architecture design for object tracking and enables the deployment of efficient trackers on various hardware platforms.