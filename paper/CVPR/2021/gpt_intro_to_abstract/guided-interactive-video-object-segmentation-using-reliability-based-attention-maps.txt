Video object segmentation (VOS) is a challenging task that involves cutting out objects of interest in a video. It is widely applicable in fields such as video editing, video summarization, video inpainting, and self-driving cars. Semi-supervised VOS, which requires a fully annotated segmentation mask in the first frame, has been extensively studied to improve segmentation performance. However, this approach is time-consuming and lacks a fallback mechanism for unsatisfactory results. To address these limitations, interactive VOS allows users to provide user-friendly annotations, such as scribbles, to refine segmentation results. This paper introduces a guided interactive segmentation (GIS) algorithm that guides users to quickly and effectively identify poorly segmented regions. The proposed algorithm utilizes reliability-based attention (R-attention) maps to transfer object information from annotated frames to the target frame. Intersection-aware propagation is then performed to propagate segmentation results to neighboring frames. Additionally, a guidance score called R-score is computed to optimize the annotation selection process. Experimental results demonstrate that the GIS algorithm outperforms existing methods in both simulation and real-world applications, in terms of both accuracy and speed. The contributions of this paper include the development of novel operators for VOS, the introduction of the concept of guidance in interactive VOS, and the significant improvement in speed and accuracy achieved by the proposed GIS algorithm.