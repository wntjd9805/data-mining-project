Abstract:The task of detecting anomalous events in video has garnered increasing interest in recent years. An anomalous event refers to an unfamiliar or unexpected event in a given context. However, the reliance on context and the difficulty of collecting anomalous events for training make the problem challenging. This paper presents a novel approach that jointly learns multiple proxy tasks through a single object-centric architecture for anomaly detection in video. The proposed approach includes predicting the arrow of time, predicting the irregularity of motion, reconstructing the appearance of objects, and estimating normality-specific class probabilities through knowledge distillation. Experimental results on three benchmark datasets demonstrate that the proposed approach outperforms state-of-the-art methods in terms of frame-level AUC scores. The findings also highlight the superiority of the jointly optimized model on the proposed proxy tasks compared to single models optimized on individual tasks. Overall, this paper introduces new proxy tasks, proposes a multi-task learning framework, and achieves superior anomaly detection results.