In this paper, we introduce a Multi-Source Meta-Learning framework for person re-identification (ReID) in order to improve the generalization ability of models to unseen domains. We focus on the domain generalization (DG) setting, where the goal is to learn models that can perform well on unseen domains without access to target domains. We propose a meta-learning strategy that simulates the train-test process of DG during model optimization. Our method dynamically divides the source domains into meta-train and meta-test sets at each iteration and encourages the loss of meta-train samples to optimize the model towards a direction that improves the accuracy of meta-test samples. To address the issue of unstable optimization caused by traditional parametric-based identification loss in the presence of multiple domains, we propose a memory-based identification loss that utilizes a non-parametric memory. We also introduce a meta batch normalization layer (MetaBN) to simulate the feature variations in different domains. We conduct experiments on four large-scale ReID datasets and demonstrate that our Memory-based Multi-Source Meta-Learning (M3L) framework achieves state-of-the-art results when testing on unseen domains. Overall, our contributions include proposing a framework for multi-source DG, introducing a memory-based module for stable optimization, and presenting MetaBN for generating diverse meta-test features.