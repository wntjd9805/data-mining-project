Optical flow, depth estimation, and camera motion estimation are core tasks in computer vision. Recent advancements in deep learning have significantly improved the state-of-the-art in optical flow and stereo depth estimation, as well as camera ego-motion prediction. Jointly estimating these three tasks has numerous applications, such as autonomous navigation, 3D scene reconstruction, and robot control. Many unsupervised frameworks have been proposed to optimize multiple tasks concurrently, demonstrating the positive impact of joint estimation. Previous approaches often estimate each task separately using individual networks and employ geometric consistency constraint losses. While some works have attempted to share the same network for stereo depth and optical flow estimation, they treat these tasks as identical, disregarding the opportunity to leverage the advantages of feature-level collaboration. In this paper, we propose that effective feature-level collaboration can significantly improve the performance of all three tasks compared to loss-level joint optimization. By sharing features between stereo depth and optical flow estimation, we introduce a single network that integrates these tasks and incorporates camera motion estimation. We demonstrate that this feature-level collaboration enhances the training process and achieves better performance in all three tasks. Additionally, we address the challenge of occlusion in optical flow estimation by leveraging the cost volume of stereo images to complement the cost volume of consecutive frames. Our method represents the first feature-level collaboration for optical flow, stereo depth, and camera motion estimation. Experimental results show that our approach outperforms existing unsupervised joint methods and even surpasses some classic supervised methods in optical flow estimation.