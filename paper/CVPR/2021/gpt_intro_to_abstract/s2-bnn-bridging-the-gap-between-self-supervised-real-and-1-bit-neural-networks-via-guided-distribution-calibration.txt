Recent advances in 1-bit convolutional neural networks (1-bit CNNs), also known as binary neural networks (BNNs), have primarily focused on supervised learning. BNNs have gained recognition for their efficiency and potential for deep compression in resource-limited devices. However, the self-supervised learning methods commonly used for real-valued networks may not be optimal for BNNs due to their binary nature and limited representation capability. In this paper, we aim to study the mechanisms and properties of BNNs under the self-supervised learning scenario and provide practical guidelines for establishing a strong self-supervised framework. We first explore the suitability of contrastive learning, a popular self-supervised technique, for BNNs. We investigate optimizers, learning rate schedulers, and data augmentation strategies to determine optimal designs for self-supervised BNNs. We then address the performance gap between BNNs and real-valued networks in self-supervised learning. We observe that the distributions of predictions from BNNs and real-valued networks differ significantly but can be calibrated using a simple teacher-student paradigm, resulting in improved performance for BNNs. To further enhance the representation ability of self-supervised BNNs, we propose a guided learning paradigm that leverages a self-supervised real-valued network branch as a teacher. We show that combining guided learning with contrastive learning can significantly boost the performance of BNNs, while guided learning alone can also achieve substantial improvements. We analyze the learning mechanisms behind contrastive and guided learning and conclude that recovering knowledge from a well-learned real-valued network is more effective for self-supervised BNNs. Our proposed framework improves the na¨ıve contrastive learning by 5.5% to 15% on ImageNet, and we demonstrate the effectiveness of our learned models on downstream datasets through transfer learning. This paper contributes to the understanding of self-supervised learning in BNNs and provides practical insights and guidelines for their implementation.