Abstract:Novel view synthesis, also known as view translation, is a challenging task in computer science that aims to render the same object under arbitrary poses. This requires the model to accurately understand the image content and the relationship between object poses and appearances in the image. Learning-based methods, such as autoencoders and variational autoencoders, have been widely used for view synthesis. However, these methods have limitations in representing the content and translating images into target domains. In this paper, we propose a novel iterative view translation framework that deforms the encoder features in a coarse-to-fine fashion to align them with corresponding parts in the decoder. We introduce Soft and Hard Conditional Deformation Modules (SCDM and HCDM) to compute the initial flow and subsequent residuals for better alignment. Our experiments on two different datasets demonstrate the effectiveness of the proposed framework and modules in improving synthesis quality. This research contributes to the advancement of view synthesis in computer science.