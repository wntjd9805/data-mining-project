This paper introduces the concept of CompositeTasking, a technique for performing multiple visual tasks on the same image using a single convolutional neural network. The paper addresses the question of determining where in the image it is necessary to perform a task, and proposes an algorithm that efficiently executes multiple task instructions based on spatially distributed task requests. The paper also discusses the challenge of sparse task annotations in image datasets and presents a method for efficient learning from sparse multi-task labels. The proposed network architecture uses task-specific batch normalization and conditional image-to-image translation to perform multiple tasks in a compact and efficient manner. The paper demonstrates the benefits of CompositeTasking in various applications, including task editing and rule transfer. Overall, the proposed CompositeTasking method offers a promising approach for achieving scene understanding and reasoning in computer vision tasks.