Unsupervised representation learning from unlabeled images has proven effective in improving neural network performances for unknown downstream tasks, particularly with limited labeled data. However, conventional generative modeling algorithms struggle to produce semantically meaningful representations from high-resolution natural images. Recent self-supervised learning algorithms have shown promise in obtaining semantic representations through proxy tasks on unsupervised data. Among these methods, contrastive learning with discriminative models has achieved remarkable success in image classification tasks. Contrastive self-supervised learning aims to obtain discriminative representations based on semantically positive and negative image pairs. However, existing contrastive methods often generate inconsistent local representations with respect to the same spatial regions after image transformations. Additionally, these methods rely heavily on heavily cropped views from an image, which can induce matching between semantically different regions. To address these issues, we propose SCRL, a spatially consistent representation learning algorithm for multi-object and location-specific downstream tasks such as object detection and instance segmentation. Our approach leverages unlabeled images and develops a self-supervised objective to achieve invariant spatial representations for the same cropped region under image augmentations. We utilize RoIAlign and optimize the encoding network to minimize the distance between local representations. Inspired by BYOL, which does not require negative pairs, we adapt its learning framework to produce spatially coherent representations.We conduct extensive experiments on benchmark datasets to demonstrate the effectiveness of SCRL. We consistently outperform random initialization, previous supervised pretraining, and state-of-the-art self-supervised methods in object detection and instance segmentation tasks using datasets such as PASCAL VOC, COCO, and Cityscapes. SCRL enables more precise object boundary regression and exhibits superior performance even with a small number of epochs during upstream training on unlabeled images. The improvements in fine-tuned downstream performance are maintained under longer schedules and small data regimes, validating the benefits of transferred spatial representations. In summary, our contributions include considering spatial consistency in image representations, proposing the SCRL algorithm for multi-object and location-aware tasks, generating diverse pairs of semantically-consistent cropped spatial feature maps, and demonstrating superior performance compared to existing methods in obtaining better localization task performances.