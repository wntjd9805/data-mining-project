This paper introduces the concept of style-agnostic sketch-based image retrieval (SBIR) to address the issue of user style diversity in SBIR models. Existing models focus on bridging the gap between photo and sketch modalities, but largely ignore the style variations that exist amongst users. This can lead to inconsistent results for different sketches of the same object instance. To overcome this, a novel style-agnostic SBIR framework is proposed that explicitly accounts for style diversity and can adapt dynamically to unseen user styles without retraining the model. The framework uses a disentanglement model to separate the shared semantic content and the user's drawing style in a sketch or photo image. The disentanglement is challenging due to the large variability in sketching styles, but a meta-learning approach is employed to make the disentanglement dynamically adaptable and generalizable. Experimental results demonstrate the effectiveness of the style-agnostic design in achieving state-of-the-art performances in SBIR.