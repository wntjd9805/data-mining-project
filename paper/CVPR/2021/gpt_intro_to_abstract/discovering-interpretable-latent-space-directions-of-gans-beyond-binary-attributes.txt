Generative adversarial networks (GANs) have shown promise in generating high-resolution photorealistic images by training with diverse data. GANs learn a nonlinear mapping function from input noise to output images that conform to real data distributions. Previous studies have demonstrated vector arithmetic properties in the latent space of GANs, such as modifying image semantics by adding vectors or combining latent codes. However, the structure of semantics in the latent space remains uncertain. Recent works have attempted to discover meaningful directions in the latent space corresponding to interpretable image transformations. Unsupervised methods can uncover simple image transformations but struggle to locate specific target attributes. Supervised approaches leverage target attribute accessors to trace back the corresponding directions. However, obtaining well-scored attributes or 3D data is expensive and limits practicability. Previous work extends the accessor to a binary classifier to edit binary attributes but fails to handle non-binary attributes correctly. To address this, we propose AdvStyle, an adversarial method that focuses on finding positive directions by training the attribute assessor to distinguish between target positive samples and generated negative samples. This approach enables the disentangling of various semantics and allows for multi-attribute editing without orthogonal constraints. We dynamically update the attribute assessor to bridge the domain gap between generated images and training data. Our method also captures interesting and unexpected semantics through involuntarily learned negative directions. We demonstrate the effectiveness of our method in both synthetic and real image editing scenarios. Our contributions include: the proposal of an adversarial method for discovering arbitrary attribute directions in the latent space, disentangled directions for multi-attribute manipulation, a study on interesting and unexpected semantics captured by negative directions, and an extension of our method to real image editing using GAN inversion methods. Ultimately, our method offers a flexible and practical editing tool for users.