Deep neural networks have achieved significant success in classification tasks, but they are vulnerable to overfitting and adversarial attacks. To address these issues, data augmentation and regularization methods have been studied. Mixup, CutMix, and Manifold Mixup have improved classification performance and robustness but do not consider the content and style of images separately. In this work, we propose StyleMix, a mixup method that carefully combines the content and style of two input images to enhance model training. We also introduce StyleCutMix, which allows sub-image level manipulation. We develop a scheme to automatically decide the degree of style mixing based on the class distance between image pairs. Our experiments on CIFAR-10, CIFAR-100, and ImageNet datasets show that our methods improve classification performance and outperform state-of-the-art mixup methods. We also demonstrate that our methods enhance the robustness of classifiers to adversarial attacks.