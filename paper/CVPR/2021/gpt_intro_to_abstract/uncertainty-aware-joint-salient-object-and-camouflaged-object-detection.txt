Visual salient object detection (SOD) aims to identify the most visually distinctive regions in images that attract human attention. These salient objects should have high contrast compared to their global and local context. Conversely, camouflaged objects often blend in with their surroundings by sharing similar structure or texture information. Existing SOD models focus on global and local contrast, while camouflaged object detection (COD) models avoid searching for camouflaged objects in salient regions. However, there are objects that exhibit both saliency and camouflage characteristics. In this study, we propose a joint learning framework that combines SOD and COD and augments the training dataset to include lower contrast samples. We argue that effective data augmentation techniques should be context-aware for saliency detection. We introduce a similarity measure module and employ a third dataset to achieve separate focus for the two tasks. Additionally, we explore the use of adversarial training to model prediction uncertainty and estimate model confidence for both tasks. Our contributions include the introduction of a joint SOD and COD network within an adversarial learning framework, the design of a similarity measure module to capture the contradicting attributes of the tasks, and the presentation of a data interaction strategy for robust saliency detection.