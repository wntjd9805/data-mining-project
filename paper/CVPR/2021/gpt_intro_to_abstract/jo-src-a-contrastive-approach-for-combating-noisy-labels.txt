Deep neural networks (DNNs) have contributed to significant advancements in computer vision tasks, but their success heavily relies on large-scale datasets with reliable annotations. However, collecting such datasets is time-consuming and labor-intensive, especially in domains requiring expert knowledge. This issue poses a bottleneck for the use of DNNs in real-world scenarios. As an alternative, training DNNs with web images has gained attention due to their cheaper and easier accessibility. However, web images often come with noisy labels, which can lead to overfitting and reduced performance. To address this, various methods have been proposed for learning with noisy labels, including correcting losses during training and selecting or reweighting training samples. However, existing sample selection methods tend to assume constant noise ratios across all mini-batches, which may not hold true in real-world cases. Additionally, most methods focus on closed-set scenarios, neglecting the presence of both in-distribution (ID) and out-of-distribution (OOD) noisy samples in open-set cases. To overcome these limitations, we propose Jo-SRC (Joint Sample Selection and Model Regularization based on Consistency), which leverages self-supervised contrastive learning to select clean samples globally. We measure the likelihood of a sample being clean using the Jensen-Shannon divergence and distinguish ID and OOD noisy samples based on prediction consistency. Clean samples are trained conventionally, while ID and OOD noisy samples are relabeled before updating the network. Our joint loss, including a classification term and a consistency regularization term, further improves model performance. Experimental results demonstrate the superiority of Jo-SRC over state-of-the-art methods on synthetic and real-world noisy datasets. Ablation studies confirm the effectiveness of our approach. Overall, Jo-SRC provides a simple yet effective solution for mitigating the negative effects of noisy labels in training DNNs.