Abstract:Deep-learning-based point cloud understanding has gained popularity in recent years, with various architectures proposed to handle the sparse nature of point clouds and achieve successful applications in object recognition, scene understanding, and autonomous driving. However, traditional methods that project points into a dense 3D grid suffer from scalability issues as the operating range of sensors improves. In this paper, we propose a new point cloud representation, called perspective point cloud (PPC), that directly operates on the perspective 2D range image without the need for 3D projection. We introduce alternative kernels inspired by recent advances in graph operations to inject 3D information into the PPC model, addressing the deficiency of traditional 2D convolution layers. Our proposed model sets a new state-of-the-art for pedestrian detection on the Waymo Open Dataset and matches the state-of-the-art for vehicle detection. We demonstrate that our model maintains efficiency benefits from operating on the 2D range image and outperforms larger models in terms of accuracy. The proposed perspective point cloud representation and improved kernels offer a promising approach for deep-learning-based point cloud understanding.