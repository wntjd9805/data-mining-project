Object detection is a critical task in computer vision, and recent advancements have been dominated by deep convolutional neural networks (CNNs). However, CNN models often have millions of parameters and require large computational resources, limiting their deployment on resource-limited platforms. To address this issue, various methods have been proposed to compress and accelerate CNNs for efficient online inference, such as network design, pruning, low-rank decomposition, quantization, and knowledge distillation. In particular, quantization, especially binarization, has shown promise in reducing the bit-width of network parameters and activations for efficient inference. Binarized detectors, which compress weights and activations into a single bit, have contributed to speeding up the CNN feature extraction process for real-time object detection. Despite their energy-efficiency and potential for deployment on embedded devices, the performance of 1-bit detectors often falls short compared to their real-valued counterparts. This degradation in performance is primarily attributed to the layer-wise binarization error that significantly impacts 1-bit detector learning. In this paper, we propose a layer-wise search method called LWS-Det to optimize 1-bit detectors and narrow the performance gap. We employ the student-teacher framework, minimizing the binarization error by decoupling it into angular and amplitude errors. The binarized weight is searched by well-designed losses under the differentiable binarization search (DBS) framework, and the problem is formulated as a combination of -1 and 1. This differentiable search significantly enhances the capacity of 1-bit detectors. Additionally, we incorporate two losses to supervise the 1-bit convolution layer from angular and amplitude perspectives, further improving the representation ability of LWS-Det. Our contributions include introducing a differentiable search method for 1-bit detectors that minimizes angular error and the use of a scale factor to minimize amplitude loss based on the student-teacher framework. We evaluate LWS-Det on the PASCAL VOC and COCO datasets and compare it with state-of-the-art 1-bit detectors. The results demonstrate that our approach outperforms other BNN-based detectors by a significant margin. For instance, on the COCO dataset, the 1-bit Faster-RCNN with ResNet-50 backbone obtained by LWS-Det achieves 31.7% mAP, surpassing all current 1-bit detectors.