Person image generation has gained significant attention in recent years for its potential applications in various fields such as virtual try-on, clothing texture editing, and person manipulation. Most of the existing research in this area focuses on pose-guided person image generation, utilizing paired source-target images for supervised training. However, the collection of paired images is time-consuming and requires significant workforce, limiting the usability of these models. In this paper, we propose a self-driven approach for person image generation that does not rely on paired source-target images during training. Our approach utilizes a novel multi-level statistics transfer model to disentangle and transfer multi-level appearance features for person images. By using the source image as supervision information, our method enables flexible manipulation of pose and appearance properties to achieve pose transfer and clothes style transfer.To prevent the model from learning trivial solutions and to ensure effective feature extraction, we introduce a multi-level statistics transfer model that leverages attention mechanism and attributes statistics. This model extracts features from the appearance encoder and the pose encoder and applies a multi-layer fully connected network to learn the corresponding relationship between the transferred statistics and the generator branch, which reconstructs the source person image.Our self-driven approach eliminates the need for paired data during training and achieves superior performance compared to state-of-the-art supervised and unsupervised methods. We demonstrate the effectiveness of our model through quantitative and qualitative comparisons. Furthermore, our model allows for flexible manipulation of person appearance and pose properties, showcasing its potential for pose transfer and clothes style transfer tasks. Our approach also performs well in real-world scenarios, highlighting its applicability in practice.Overall, this paper presents a fully self-driven person image generation method that transfers multi-level appearance features without paired source-target images. The proposed multi-level statistics transfer model enables flexible manipulation of person appearance and pose properties, demonstrating superior performance in pose transfer and clothes style transfer tasks.