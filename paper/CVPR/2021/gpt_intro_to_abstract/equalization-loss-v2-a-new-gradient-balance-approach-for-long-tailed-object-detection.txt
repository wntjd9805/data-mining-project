Object detection is a crucial task in computer vision that aims to identify and locate objects within an image. While modern object detectors have achieved promising results on conventional benchmarks, such as COCO and PASCAL VOC, these datasets have balanced quantities of each category. However, in real-world scenarios, the distribution of object categories follows a long-tailed Zipfian distribution, resulting in extreme imbalances in different categories. Training object detectors on long-tailed datasets poses challenges, including insufficient annotations for tail classes and model biases towards head classes. Current state-of-the-art approaches employ decoupled training, but they require additional fine-tuning and may result in suboptimal representations. To address these limitations, this paper proposes a new version of the equalization loss, called EQL v2, for long-tailed object detection. EQL v2 balances the positive to negative gradient ratio through a gradient-guided re-weighing mechanism, treating each category as an independent sub-task. Experimental results on two long-tailed object detection datasets, LVIS and OpenImages, demonstrate the effectiveness of EQL v2 in achieving more balanced training and outperforming existing methods in terms of average precision.