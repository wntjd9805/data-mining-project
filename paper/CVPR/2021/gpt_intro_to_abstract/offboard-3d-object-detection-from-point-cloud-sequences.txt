This paper introduces a novel pipeline for offboard 3D object detection in computer vision. The pipeline makes use of the whole sensor sequence input, such as video data commonly found in autonomous driving applications. The authors propose a modular design and a series of tailored deep network models to achieve high-quality object detection. The pipeline also incorporates a 4D object-centric design, leveraging multi-object tracking to link objects detected at different frames. The proposed pipeline, named "3D Auto Labeling," improves perception quality compared to existing real-time, onboard detectors. The paper presents experimental results on the Waymo Open Dataset, demonstrating state-of-the-art performance. Additionally, a human label study is conducted to validate the accuracy of auto labels compared to human labels. The effectiveness of auto labels for semi-supervised learning is also demonstrated. Overall, the contributions of this work include the formulation of the offboard 3D object detection problem, the proposed pipeline, state-of-the-art performance, and the evaluation of auto labels.