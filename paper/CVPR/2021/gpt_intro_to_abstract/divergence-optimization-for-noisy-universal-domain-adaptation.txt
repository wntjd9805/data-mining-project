Deep neural networks (DNNs) have shown remarkable performance in tasks requiring large-scale annotated training data. However, the performance of these networks tends to decline when the test data differs from the training data. To address this issue, unsupervised domain adaptation (UDA) techniques have been proposed, which aim to learn a discriminative classifier even when there is a shift between the source domain (training data) and the target domain (test data). Existing UDA methods typically assume that the source and target domains share the same class distribution, but in real-world scenarios, this assumption may not hold. To overcome this limitation, Universal Domain Adaptation (UniDA) has been introduced, which relaxes the constraints on label sets, allowing for unknown classes to exist in the target domain and some classes from the source domain to be absent in the target domain. However, existing UniDA methods require source data with correct annotations, limiting their applicability to real domain adaptation problems where clean and high-quality datasets are difficult to obtain. In this paper, we propose a new realistic setting called "Noisy Universal Domain Adaptation" (Noisy UniDA). This setting considers the presence of noisy labels in the source domain, source private classes that do not appear in the target domain, and target private classes that are not shared by the source domain. We review existing methods that aim to address certain parts of Noisy UniDA but do not solve all the problems simultaneously. Instead of tackling each problem separately, we propose a divergence-based approach that leverages multiple models with different parameters to detect unwanted samples in Noisy UniDA. Specifically, we use a two-head network architecture with two independent classifiers to identify noisy source samples and target private samples. By aligning the distributions of clean samples from common classes shared by both domains, we effectively mitigate the influence of incorrect source labels, source private classes, and target private classes. Our method outperforms existing approaches on various domain adaptation tasks, making the following contributions: (1) we propose a novel setting and training methodology for Noisy UniDA, (2) we introduce a divergence optimization framework to detect and handle noisy source samples and target private samples, and (3) we provide experimental results demonstrating the effectiveness of our method in real-world domain adaptation tasks.