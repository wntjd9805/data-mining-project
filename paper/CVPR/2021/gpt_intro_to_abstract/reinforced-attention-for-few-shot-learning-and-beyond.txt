The success of deep learning models in computer vision tasks relies heavily on large amounts of labeled data. However, the availability of such datasets is limited due to the labor-intensive process of data preparation. This limitation has sparked interest in the field of few-shot learning, which aims to enable models to classify unlabeled examples of unseen classes using only a small number of labeled support examples. One approach to few-shot learning is model-initialization based, which updates the model parameter using support examples and seeks a representation that generalizes well in the testing phase. Another approach is metric-learning based, which manipulates global embeddings learned by the backbone network. However, these traditional approaches often ignore the spatial information encoded within feature maps, making the model sensitive to background clutter in image examples. To address this, attention-oriented designs have been developed, utilizing word embeddings and semantics-guided attention modules to capture relevant visual features among query samples. In addition, sample-guided attention designs explore feature relevance between support and query samples. However, these attention models often focus on designing complex meta-learners. In this work, we propose a reinforced-attention policy (RAP) learning model for few-shot learning, which trains an attention mechanism using reinforcement learning. RAP uses an auxiliary agent to compute a series of attention maps that decide where to enforce or ignore over feature maps. This enables the backbone network to identify informative parts of the feature maps and make the generated embeddings more discriminative for the few-shot meta-learner. We formulate the feature extraction process as a Markov Decision Process (MDP) and optimize RAP in a reinforcement learning setting. The agent, guided by the computed reward, progressively refines the attention upon feature maps over time. Our contributions include a flexible extension to the backbone network that attends to informative regions of feature maps without a complex meta-learner design, and a novel solution for training the attention mechanism using reinforcement learning. Experimental results on benchmark datasets demonstrate the effectiveness of our approach, not only in few-shot learning but also in image classification tasks.