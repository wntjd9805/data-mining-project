Visual attention is a crucial component of everyday tasks. While previous studies have focused on stimulus-driven attention during free-viewing behavior, task-driven attention is another important form of attention that selects task-relevant information for decision-making and task completion. Additionally, temporal sequences of eye fixations can provide a more comprehensive and natural representation of attention compared to static saliency maps. Understanding and predicting visual scanpaths in general tasks can not only provide insights into the decision-making process but also have practical applications in computer vision. This paper introduces a novel deep reinforcement learning method that leverages task guidance to predict human visual exploration behaviors in general tasks. The proposed method includes a task guidance map to specify task-relevant image regions and addresses the exposure bias between training and test contexts through reinforcement learning. A novel loss function is also introduced to differentiate between correct and incorrect scanpaths. This work differs from previous scanpath prediction studies by focusing on complex scanpath patterns in general decision-making tasks and investigating the correlation between scanpaths and performance. Additionally, the proposed method demonstrates improved performance compared to humans and can be adapted to various tasks with different levels of complexity. The paper presents a deep reinforcement learning model that considers task performance in predicting scanpaths and integrates attention maps from task-specific neural network models. The method is shown to outperform existing approaches and achieve human-level performance on three tasks: visual question answering, free-viewing, and visual search.