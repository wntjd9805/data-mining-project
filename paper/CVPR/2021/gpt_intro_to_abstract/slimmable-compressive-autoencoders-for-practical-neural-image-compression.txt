Visual information, such as images and videos, is essential in human content creation, communication, and interaction. However, efficient storage and transmission of visual content require compression techniques. The basic image compression problem aims to achieve the shortest binary representation of an input image while maintaining a certain level of fidelity. This tradeoff between rate (compression level) and distortion is known as the rate-distortion tradeoff.Practical image compression also takes into account real-world constraints, such as memory, computation, and latency, which are particularly important for resource-constrained devices and networks. Video compression, which deals with sequences of images, further exacerbates the complexity and latency requirements. Many applications also require dynamic control of the rate-distortion tradeoff to adapt to specific requirements.Traditional compression methods, such as JPEG and JPEG2000, follow the transform coding paradigm, using linear transforms and coding tools. These methods optimize the rate-distortion tradeoff by searching for optimal block partitions and coding/prediction modes. In contrast, neural image compression (NIC) approaches exploit flexible nonlinear transforms and entropy models represented as deep neural networks. NIC methods have shown better rate-distortion performance but are typically designed for a single target rate and require specialized hardware.To address these challenges, this paper presents the slimmable compressive autoencoder (SlimCAE) framework. SlimCAE allows for variable rate and adaptive complexity in image compression. It introduces slimmable modules, such as generalized divisive normalization (GDN) layers and probability models, which enable control over computation, memory, and rate. The paper also proposes a training algorithm that adjusts the rate-distortion tradeoff parameters and demonstrates the effectiveness of SlimCAE in achieving practical neural image compression.The contributions of this work include the novel rate and complexity control mechanism based on layer widths, the SlimCAE framework for practical neural image compression, an efficient training algorithm, and novel slimmable modules. Additionally, SlimCAEs can easily generate scalable bitstreams, expanding their applicability.