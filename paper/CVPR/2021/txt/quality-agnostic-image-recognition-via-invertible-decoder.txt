Abstract
Despite the remarkable performance of deep models on image recognition tasks, they are known to be suscepti-ble to common corruptions such as blur, noise, and low-resolution. Data augmentation is a conventional way to build a robust model by considering these common corrup-tions during the training. However, a naive data augmenta-tion scheme may result in a non-specialized model for par-ticular corruptions, as the model tends to learn the aver-aged distribution among corruptions. To mitigate the issue, we propose a new paradigm of training deep image recog-nition networks that produce clean-like features from any quality image via an invertible neural architecture. The pro-posed method consists of two stages. In the ﬁrst stage, we train an invertible network with only clean images under the recognition objective. In the second stage, its inversion, i.e., the invertible decoder, is attached to a new recognition net-work and we train this encoder-decoder network using both clean and corrupted images by considering recognition and reconstruction objectives. Our two-stage scheme allows the network to produce clean-like and robust features from any quality images, by reconstructing their clean images via the invertible decoder. We demonstrate the effectiveness of our method on image classiﬁcation and face recognition tasks. 1.

Introduction
Deep learning models have shown remarkable perfor-mance for image recognition (or classiﬁcation) tasks, even surpassing human-level performance [30, 41, 42, 17, 23, 4, 48, 22]. They typically assume high-quality (HQ) or clean images for their training/testing, while such an assumption may not hold in practice, e.g., images of various qualities can be encountered in their applications [9]. Moreover, deep models are known to be vulnerable to image distor-tions such as noise, blur, JPEG, contrast, weather, and low-resolution. On the other hand, the human visual system ro-bustly extracts semantic information from such images due to its generalization ability [14].
*Corresponding authors
Figure 1. Quality-agnostic learning scheme based on classiﬁer-decoder structure. We train an invertible classiﬁer using a clas-siﬁcation objective at the ﬁrst stage. We use it as an invertible decoder of the second stage by its inversion and freezing the pa-rameters. A new classiﬁer is trained with this frozen decoder using
HQ and LQ images at the second stage. As a result, the decoder evokes HQ features from both HQ and LQ input images.
In practice, data augmentation is a conventional and prin-cipled way to build models robust against various domains or corruptions of data.1 For example, one can synthesize
LQ images by using degradation procedures, such as blur, noise, and low-resolution, and then train a model using both
HQ and LQ images. One can also train a model using HQ images, and then ﬁne-tune it using both HQ and LQ im-ages. However, training (or ﬁne-tuning) with such diverse characteristics of data may generate the averaged distribu-tion among corruptions [47], such that it results in an under-ﬁtted (or poor) model for a particular type of data, e.g., HQ images [14] or LQ images [44, 51, 10]. Indeed, learning a better single neural network handling such various types is a challenge to overcome.
To process various types of corruptions better, several quality-aware deep models have been studied [11, 2, 50].
They introduce an additional network module per quality type in order to handle multiple corruption types, and show 1In this paper, we primarily assume that types of corruption or LQ im-ages in test data are known at training time. Hence, our work is orthogonal to prior works building robust models without the assumption [20, 38, 19]. 12257
promising results with respect to both HQ and LQ images.
However, as the number of corruption types increases, these approaches may require a large number of resources during the training and evaluation phases. Instead, we are inter-ested in a more fundamental question: how to learn a single and uniﬁed model with high HQ and LQ accuracy, without using such additional quality-related modules?
To address the question, we propose a novel training scheme to build such a quality-agnostic model, i.e., having high performance on any input quality images. At a high level, the proposed training scheme encourages any quality images (even LQ) to have HQ-like features for the desired quality-agnostic performance. To this end, we suggest an additional training loss to reconstruct HQ images by using features of LQ images via an auxiliary decoder. Namely, we train the classiﬁcation model using a multi-task learning strategy on the original (e.g., classiﬁcation) task and the re-construction task. However, in our early experiments, we found that training the classiﬁer and the decoder in an end-to-end manner from scratch is not that effective for our pur-pose. This is because the additional reconstruction task may obstruct the original classiﬁcation learning as their effective features may be different.
To effectively learn a classiﬁcation model with the recon-struction decoder, we propose a two-stage training scheme.
We ﬁrst train a decoder with HQ images only, i.e., it takes some features as input and reconstructs the original HQ im-age as output. Then, we freeze the decoder and train a classiﬁer-decoder architecture with both HQ and LQ im-ages using two losses for classiﬁcation and reconstruction.
Under our scheme, LQ images are never fed to train the de-coder. Hence, at the second stage, the classiﬁer is encour-aged to produce the features of LQ input images to be simi-lar to those of HQ images by performing the reconstruction task well. To design a beneﬁcial decoder for our two-stage strategy, we suggest training an invertible network under the classiﬁcation objective at the ﬁrst stage and use its inversion as a decoder of the second stage as shown in Fig. 1. As the decoder is trained for the classiﬁcation objective at the ﬁrst stage and is not updated at the second stage, the reconstruc-tion task via the decoder can be regarded as a classiﬁcation task in a backward perspective. Therefore, it can mitigate a potential conﬂict on our second multi-task learning stage.
Furthermore, the decoder can reconstruct HQ images only from class-aware HQ features. Hence, under our training scheme, the classiﬁer can be penalized by the reconstruc-tion loss if the classiﬁer does not output class-aware HQ features even in the case of LQ input images (see Fig. 2).
We demonstrate the superiority of our method under var-ious tasks such as image classiﬁcation and face recogni-tion. Our extensive experiments show the effectiveness of our method on various benchmarks such as ImageNet [5],
ImageNet-C [19], CFP-FP [39] and AgeDB-30 [34]. 2.