Abstract
Graph Edit Distance (GED) is a popular similarity mea-surement for pairwise graphs and it also refers to the re-covery of the edit path from the source graph to the target graph. Traditional A* algorithm suffers scalability issues due to its exhaustive nature, whose search heuristics heavily rely on human prior knowledge. This paper presents a hy-brid approach by combing the interpretability of traditional search-based techniques for producing the edit path, as well as the efï¬ciency and adaptivity of deep embedding models to achieve a cost-effective GED solver. Inspired by dynamic programming, node-level embedding is designated in a dy-namic reuse fashion and suboptimal branches are encour-aged to be pruned. To this end, our method can be read-ily integrated into A* procedure in a dynamic fashion, as well as signiï¬cantly reduce the computational burden with a learned heuristic. Experimental results on different graph datasets show that our approach can remarkably ease the search process of A* without sacriï¬cing much accuracy. To our best knowledge, this work is also the ï¬rst deep learning-based GED method for recovering the edit path. 1.

Introduction
Graph edit distance (GED) is a popular similarity mea-sure for graphs, which lies in the core of many vision and pattern recognition tasks including image matching [12], signature veriï¬cation [29], scene-graph edition [11], drug discovery [32], and case-based reasoning [47].
In gen-eral, GED algorithms aim to ï¬nd an optimal edit path from source graph to target graph with minimum edit cost, which is inherently an NP-complete combinatorial problem [2]:
GED(G1, G2) = min (e1,...,el)âˆˆÎ³(G1,G2) l
X i=1 c(ei) (1) where Î³(G1, G2) denote the set of all possible â€œedit pathsâ€ transforming source graph G1 to target graph G2. c(ei) mea-âˆ—Junchi Yan is the corresponding author. edge deletion edge deletion node deletion
ğ“–ğŸ
ğ’„ ğ’†ğŸ = ğŸ
ğ’„ ğ’†ğŸ = ğŸ
GED
= 3
ğ’„ ğ’†ğŸ‘ = ğŸ
ğ“–ğŸ (ğ“–ğŸ, ğ“–ğŸ)
Figure 1. Top: an edit path between two simple graphs G1, G2.
Bottom: an example of querying images via GED, where only ge-ometric information is involved. The last image shows an â€œunsim-ilarâ€ image based on GED measurement. sures the cost of edit operation ei.
Exact GED solvers [2, 34] guarantee to ï¬nd the optimal solution under dynamic condition, at the cost of poor scal-ability on large graphs, and these exact solvers heavily rely on heuristics to estimate the corresponding graph similarity based on the current partial solution. Recent efforts in deep graph similarity learning [3, 4, 28] adopt graph neural net-works [24, 36] to directly regress graph similarity scores, without explicitly incorporating the intrinsic combinatorial nature of GED, hence fail to recover the edit path. However, the edit path is often of the central interest in many applica-tions [11, 12] and most GED works [2, 33, 15, 46, 34] still are more focused on ï¬nding the edit path itself.
As the growth of graph size, it calls for more scalable
GED solvers which are meanwhile expected to recover the exact edit path. However, these two merits cannot both hold by existing methods. As discussed above, deep learning-based solvers have difï¬culty in recovering the edit path while the learning-free methods suffer scalability issue. In this paper, we are aimed to design a hybrid solver by com-bining the best of the two worlds.
Speciï¬cally, we resort to A* algorithm [34] which is a popular solution among open source GED softwares [10, 22], and we adopt neural networks to predict similarity scores which are used to guide A* search, in replacement of manually designed heuristics in traditional A*. We want to highlight our proposed Graph Edit Neural Net-work (GENN) in two aspects regarding the dynamic pro-5241
gramming concepts: Firstly, we propose to reuse the previ-ous embedding information given a graph modiï¬cation (e.g. node deletion) where among the states of A* search tree the graph nodes are deleted progressively1; Secondly, we pro-pose to learn more effective heuristic to avoid unnecessary exploration over suboptimal branches to achieve signiï¬cant speed-up. It is worth noting that our learning method is no longer an exact GED solver compared to the original A* algorithm, and we signiï¬cantly reduces the running time of
A* while preserving most of the accuracy, as shown in ex-periments. The contributions made in this paper are: 1) We propose the ï¬rst (to our best knowledge) deep net-work solver for GED, where a search tree state selection heuristic is learned by dynamic graph embedding. It out-performs traditional heuristics in efï¬cacy. 2) Speciï¬cally, we devise a speciï¬c graph embedding method in the spirit of dynamic programming to reuse the previous computation to the utmost extent. In this sense, our method can be naturally integrated with the A* procedure where a dynamical graph similarity prediction is involved after each graph modiï¬cation, achieving much lower com-plexity compared to vanilla graph embeddings. 3) Experiments on real-world graphs show that our learning-based approach is more accurate than manually de-signed inexact solvers [15, 33]. It also runs much faster than
A* exact GED solvers [6, 34] that ensures global optimum by exhaustive search, with comparable accuracy. 2.