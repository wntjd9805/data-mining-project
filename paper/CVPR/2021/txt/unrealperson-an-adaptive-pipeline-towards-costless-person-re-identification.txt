Abstract
The main difﬁculty of person re-identiﬁcation (ReID) lies in collecting annotated data and transferring the model across different domains. This paper presents UnrealPer-son, a novel pipeline that makes full use of unreal image data to decrease the costs in both the training and deploy-ment stages. Its fundamental part is a system that can gen-erate synthesized images of high-quality and from control-lable distributions. Instance-level annotation goes with the synthesized data and is almost free. We point out some de-tails in image synthesis that largely impact the data quality.
With 3,000 IDs and 120,000 instances, our method achieves a 38.5% rank-1 accuracy when being directly transferred to
MSMT17. It almost doubles the former record using syn-thesized data and even surpasses previous direct transfer records using real data. This offers a good basis for un-supervised domain adaption, where our pre-trained model is easily plugged into the state-of-the-art algorithms to-wards higher accuracy. In addition, the data distribution can be ﬂexibly adjusted to ﬁt some corner ReID scenarios, which widens the application of our pipeline. We publish our data synthesis toolkit and synthesized data in https:
//github.com/FlyHighest/UnrealPerson. 1.

Introduction
Person re-identiﬁcation aims to retrieve the same pedes-trian (i.e., an identity) from the images captured by a cam-era network. As a fundamental task of intelligent surveil-lance, ReID has attracted increasing attention in the com-This work was partially supported by the National Key R&D Program of China (Grant No.2020AAA0130200), the National Natural Science
Foundation of China (No.61772054, 62072022), the NSFC Key Project (No.61632001) and the Fundamental Research Funds for the Central Uni-versities. We thank Dr. Weichao Qiu for instructive discussions.
* Corresponding author puter vision community. Recently, with the emergence of large-scale ReID datasets [59, 60, 46], effective algorithms have been proposed and achieved satisfying performance in these benchmarks. However, there is still a signiﬁcant gap in deploying the ReID algorithms to real-world scenarios, arguably because (i) the trained models are often vulnera-ble to domain changes, yet (ii) annotating identities in new scenarios requires exhausting human labors. We attribute such an application gap to the fact that the current pipeline is hindered by the data limitation and thus not optimized for generalizing across different scenarios.
To alleviate this problem and pave a new path for the community, we propose UnrealPerson, a new pipeline that makes full use of unreal (synthesized) image data towards a powerful ReID algorithm that easily and costlessly de-ploys to a wide range of scenarios. The key observation is that the synthesized pedestrian data sampled from a virtual world comes naturally with free and perfect annotations.
From the perspective of the generalization ability, the syn-thesized data enjoys two-fold beneﬁts. First, compared to the manually collected data from restricted real scenarios, the synthesized data from inﬁnite virtual scenes is more di-verse, making it less prone to domain-speciﬁc patterns. Sec-ond, the parameters of data synthesis can be freely adjusted to ﬁt the domains in which collecting real data is difﬁcult (e.g., the low-illumination scenario). To fully utilize these characteristics, our entire pipeline consists of pre-training the model using abundant synthesized data and then ﬁne-tuning it with off-the-shelf domain adaptation algorithms.
This pipeline has broad applications since it ﬁts both the fully-supervised and unsupervised setting and transfers well to a few corner scenarios.
The quality and richness of our synthesized pedestrian data is the cornerstone of our UnrealPerson pipeline. To synthesize abundant and authentic samples, we ﬁrst create a set of scenarios (e.g., street, plaza, etc.) in the virtual 3D world with changeable environmental parameters (e.g., illu-mination, lighting, etc.). Then, we place an arbitrary num-11506
ber of pedestrians with conﬁgurable appearance (e.g., gen-der, height, clothing, etc.) into the scenarios, and they move according to the pre-deﬁned paths. Finally, the images are captured by the virtual cameras in the scenes. With this data synthesis system, UnrealPerson is ﬂexible to assemble suit-able training data and learning approaches to achieve the best performance for different ReID tasks. We verify its ef-fectiveness through two groups of experiments. First, we verify the effectiveness of the synthesized data on improv-ing the generalization ability. We train the ReID model only on the synthesized data and test it directly on conventional
ReID benchmarks. Quantitatively, our vanilla baseline [62] achieves a rank-1 accuracy of 38.5% on the MSMT17 dataset, which almost doubles the previous synthesis-based record: 20.0% by RandPerson [45]. Second, we adapt our pipeline for specialized ReID scenarios, e.g., all pedestrians are in black, or the illumination is very low. In these tough scenarios, UnrealPerson achieves competitive performance, even surpassing the models that are pre-trained in manually labeled datasets with real-world images. Our major contri-bution is summarized as follows.
• We propose a novel pipeline that largely reduces the deployment costs of ReID. For the ﬁrst time, the model pre-trained purely on synthesized data outperforms that pre-trained on real, annotated data.
• We verify the usefulness of our pipeline in a wide range of downstream tasks, including direct transfer, supervised domain adaptation, and unsupervised do-main adaptation settings.
• We provide a detailed analysis of the factors in data synthesis, which offers practical guidelines for reusing our toolkit for future research. 2.