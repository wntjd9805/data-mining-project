Abstract
We propose HOI Transformer to tackle human object in-teraction (HOI) detection in an end-to-end manner. Cur-rent approaches either decouple HOI task into separated stages of object detection and interaction classiﬁcation or introduce surrogate interaction problem.
In contrast, our method, named HOI Transformer, streamlines the HOI pipeline by eliminating the need for many hand-designed components. HOI Transformer reasons about the rela-tions of objects and humans from global image context and directly predicts HOI instances in parallel. A quintuple matching loss is introduced to force HOI predictions in a uniﬁed way. Our method is conceptually much simpler and demonstrates improved accuracy. Without bells and whistles, HOI Transformer achieves 26.61% AP on HICO-DET and 52.9% AProle on V-COCO, surpassing previous methods with the advantage of being much simpler. We hope our approach will serve as a simple and effective al-ternative for HOI tasks. Code is available at https:
//github.com/bbepoch/HoiTransformer. 1.

Introduction
Human-Object Interaction (HOI) detection plays an im-portant role in the high level human-centric scene under-standing, and has attracted considerable research interest re-cently. The HOI research can also contribute to other tasks, such as action analysis, weakly-supervised object detection, and visual question answering, etc.
The goal of HOI detection aims at localizing human and object, as well as recognizing the interaction between them.
Previous studies [7, 6, 9, 22, 19, 3] present promising results on HOI detection by decouple this task into object detec-tion and interaction classiﬁcation (Fig. 1(a)). More speciﬁ-cally, human and object detection results is ﬁrst obtained by pre-trained object detector, then interaction classiﬁcation is
*Equal contribution.
Feature  
Extraction
Human   
Stream
Object 
Stream
Pairwise   
Stream
HOI
Category
Object  
Detection
Pairs  
Enumerate
Two-stage(a)
Interaction(Point)
Detection
Matching
Object  
Detection
Pairs  Enumerate
One-stage(b)
Feature  
Extraction
HOI 
Transformer 
End-to-End(c)
Figure 1: Comparison of recent approaches on HOI detec-tion. (a) two-stage methods, typically use pre-trained detec-tors to generate human, object proposal and enumerate all (human, object) pairs, followed by a multi-stream architec-ture to classify interactions. (b) one-stage methods, detect interaction point/box and object proposals simultaneously, followed by complex matching process to assign interac-tions to object pairs. (c) our end-to-end method, input an image and predict HOI instances directly. conducted on the pair-wisely combined human-object pro-posals. The limitations of these methods are mainly caused by the separated two stages. The independent optimization on two sub-problems may lead to sub-optimal solution. The generated human-object proposals have relatively low qual-ity for interaction classiﬁcation [19], because only object-level conﬁdence has been taken into account. Moreover, all pair-wise proposals need to be processed, which brings 11825
large redundant computation cost.
More recent approaches [35, 3, 19] have introduced a surrogate interaction detection problem to optimize HOI de-tection indirectly (Fig. 1(b)). Firstly, the interaction pro-posal has been pre-deﬁned based on human priors. For example, UnionDet [3] deﬁnes the interaction proposal as union box of the human and object box. PPDM [19] uses the center point between human and object as interaction point. Secondly, the human, object and interaction propos-als are detected in parallel. Finally, each interaction result is assigned to one (human, object) pair based on pre-deﬁned matching strategy in post processing. However, such deﬁni-tion of interaction proposal are not always valid under dif-ferent circumstance and make the pipeline more complex and costly in computation.
For HOI detection, how to capture the dependencies, es-pecially long range, between human and object in the im-age space is the main problem. The above methods used complex but sub-optimal strategies, i.e. decouple into two-stages or introduce surrogate proposals to empower models the ability of capturing dependencies. However, the trans-former network [32] is designed to exhaustively capture the long range dependencies, which inspire us to address the problem with transformer.
In this paper, we propose a new architecture to directly predict the HOI instance, i.e. (human, object, interaction), in an end-to-end manner. Our method consists of two parts, a transformer encoder-decoder architecture and a quintuple
HOI matching loss. The architecture ﬁrst use CNN back-bone to extract high-level image features, then the encoder is leveraged to generate global memory feature, which mod-els the relation between the image feature explicitly. Next the global memory from encoder and the HOI queries are send to decoder to generate the output embeddings. Finally, a multi-layer perception is used to predict HOI instances based on the output embeddings of decoder. Meanwhile, a quintuple HOI matching loss is proposed to supervise the learning of HOI instance prediction. Our method achieves state-of-the-art results on different challenging HOI bench-marks. 2.