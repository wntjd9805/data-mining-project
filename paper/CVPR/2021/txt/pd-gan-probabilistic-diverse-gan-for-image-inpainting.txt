Abstract
We propose PD-GAN, a probabilistic diverse GAN for image inpainting. Given an input image with arbitrary hole regions, PD-GAN produces multiple inpainting results with diverse and visually realistic content. Our PD-GAN is built upon a vanilla GAN which generates images based on ran-dom noise. During image generation, we modulate deep features of input random noise from coarse-to-ﬁne by in-jecting an initially restored image and the hole regions in multiple scales. We argue that during hole ﬁlling, the pix-els near the hole boundary should be more deterministic (i.e., with higher probability trusting the context and ini-tially restored image to create natural inpainting bound-ary), while those pixels lie in the center of the hole should enjoy more degrees of freedom (i.e., more likely to depend on the random noise for enhancing diversity). To this end, we propose spatially probabilistic diversity normalization (SPDNorm) inside the modulation to model the probability of generating a pixel conditioned on the context informa-tion. SPDNorm dynamically balances the realism and di-versity inside the hole region, making the generated con-tent more diverse towards the hole center and resemble neighboring image content more towards the hole bound-ary. Meanwhile, we propose a perceptual diversity loss to further empower PD-GAN for diverse content generation.
Experiments on benchmark datasets including CelebA-HQ,
Places2 and Paris Street View indicate that PD-GAN is ef-fective for diverse and visually realistic image restoration. 1.

Introduction
*X. Han is the corresponding author. The results and code are available at https://github.com/KumapowerLIU/PD-GAN.
There is a growing attention on developing advanced image inpainting methods for content removal [34, 3] and 9371
image restoration [39, 42, 45, 43]. Based on deep CNNs, image inpainting methods [31, 26, 54, 27] typically utilize an encoder-decoder network to generate meaningful image content for hole ﬁlling. Meanwhile, the content across the hole boundary is enforced consistent during visually realis-tic generation. By taking the input image with hole regions, the encoder captures deep image representations hierarchi-cally, which are decoded to produce the output result.
While deep encoder-decoders improve the image in-painting performance, they target for single image gener-ation that each input image corresponds to one restored result.
In practice, image inpainting may produce mul-tiple results because of the uncertain content generation within the hole region. This diverse image inpainting is less touched by existing inpainting methods. Recently, in-vestigations [58, 57, 11] on diverse image inpainting fol-low the encoder-decoder structure. They are not effective to generate both diverse and realistic contents. One rea-son is that these methods still utilize the encoder to model the current masked image to Gaussian distribution and de-code to a completed image, the variation of distribution is greatly limited by the masked image itself which leads to a decline in diversity, especially when the hole regions are free-form. On the other hand, these encoder-decoder net-works utilize image reconstruction loss [18] during training.
The generated content is thus enforced to be similar to the ground truth across both low-level and semantic representa-tions. Heavily relying on such reconstruction loss limits the diverse content generation.
In this work, we propose PD-GAN, a diverse image in-painting network built upon a vanilla GAN. We notice that
GAN is powerful to generate diverse image content based on different random noise inputs. Thus, instead of send-ing input images to the CNN, our PD-GAN starts from a random noise vector and then decodes this noise vector for content generation. In all the decoder layers, we inject prior information (coarse reconstruction result from a pre-trained partial convolution model [25]) and the region mask. The injection is fulﬁlled by the proposed SPDNorm (spatially probabilistic diversity normalization) module. SPDNorm gradually modulates deep features of the noise vector with input image representations. Speciﬁcally, the SPDNorm module learns a spatial transformation containing both hard and soft probabilistic diversity maps for feature fusion. The diversity is enhanced towards the hole center while is re-duced towards the hole boundary.
Moreover, we propose a perceptual diversity loss to em-power the diverse generation ability of PD-GAN. For two output images generated by the same prior information but input noise vectors, the perceptual diversity loss forces these two images to be farther in feature space. By training
PD-GAN with the perceptual diversity loss, we can effec-tively generate both diverse and visually realistic contents for image inpainting. Some results can be found in Fig 1.
Our contributions are summarized as follows:
• Based on a vanilla GAN, the proposed PD-GAN mod-ulates deep features of random noise vector via the pro-posed SPDNorm to incorporate context constraint.
• We propose a perceptual diversity loss to empower the network diversity.
• Experiments on the benchmark datasets indicate that our PD-GAN is effective to generate diverse and visu-ally realistic contents for image inpainting. 2.