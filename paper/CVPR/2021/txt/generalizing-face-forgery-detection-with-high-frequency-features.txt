Abstract
Current face forgery detection methods achieve high ac-curacy under the within-database scenario where training and testing forgeries are synthesized by the same algorithm.
However, few of them gain satisfying performance under the cross-database scenario where training and testing forg-eries are synthesized by different algorithms. In this paper, we ﬁnd that current CNN-based detectors tend to overﬁt to method-speciﬁc color textures and thus fail to general-ize. Observing that image noises remove color textures and expose discrepancies between authentic and tampered re-gions, we propose to utilize the high-frequency noises for face forgery detection. We carefully devise three functional modules to take full advantage of the high-frequency fea-tures. The ﬁrst is the multi-scale high-frequency feature ex-traction module that extracts high-frequency noises at mul-tiple scales and composes a novel modality. The second is the residual-guided spatial attention module that guides the low-level RGB feature extractor to concentrate more on forgery traces from a new perspective. The last is the cross-modality attention module that leverages the correlation be-tween the two complementary modalities to promote feature learning for each other. Comprehensive evaluations on sev-eral benchmark databases corroborate the superior gener-alization performance of our proposed method. 1.

Introduction
As face manipulation techniques [4, 24, 59] spring up along with the breakthrough of deep generators [27, 20], face forgery detection becomes an arousing research topic.
Most existing methods focus on within-database detec-tion [7, 29, 9], where forged images in the training set and testing set are manipulated by the same algorithm. How-ever, the biggest challenge hampering face forgery detec-∗Equal contribution
†Work done during an internship at Tencent AI Lab
‡Corresponding Author
Figure 1: Training and testing forgeries of within-database detection are synthesized by the same algorithm while those of cross-database detection are synthesized by different al-gorithms. We focus on the latter which is more challenging. tion is the generalization problem. Due to the diversiﬁed data distributions generated by different manipulation tech-niques, methods with high within-database detection accu-racy always experience a severe performance drop in the cross-database scenario, thus limiting broader applications.
Recently, several works are devoted to addressing the generalizing problem. [30, 28] assume that some artifacts are shared in forged faces and customize databases special-ized on those artifacts. However, these assumptions do not always hold. Besides, transfer learning [13], domain adap-tation [54], and multi-task learning [14, 35, 45] are utilized to improve model’s performance in unseen domains. Nev-ertheless, the acquisition of target samples and annotations is expensive. Meanwhile, some attempt to obtain informa-tion from frequency domains, such as Fourier transforma-tion [11], DCT [38], and steganalysis features [52, 57]. But they rarely consider the relation and interaction between the additional information and regular color textures.
In this paper, we aim at learning a more generalizable face forgery detector (See Fig. 1). To facilitate understand-ing why current CNN-based works fail on unseen forgeries, we analyze CNN-based classiﬁers’ behaviors and ﬁnd that 16317
the model is biased to method-speciﬁc color textures. Ob-serving that high-frequency noises can suppress image tex-tures and expose statistical discrepancies between tampered and authentic regions, we propose to utilize noises to tackle the overﬁtting problem.
We propose a generalizable model for face forgery de-tection. To take full advantage of image noises, we care-fully devise three novel modules. The ﬁrst is the multi-scale high-frequency feature extraction module. We adopt the widely used high-pass ﬁlters from SRM [18] to extract high-frequency noises from images. Unlike [11, 52, 57] that only consider extracting noises from an input image, we further apply these ﬁlters to low-level features at multi-ple scales to compose more abundant and informative fea-tures. Employing both the high-frequency noises and the low-frequency textures, we build a two-stream network to process the two modalities, respectively. Secondly, we ap-ply the residual guided spatial attention in the entry part to guide the RGB modality from the residual perspective to attach more importance to forgery traces. Thirdly, we de-sign a dual cross-modality attention module to formulate the interaction between the two modalities instead of keeping them independent [11, 52]. In this way, the two modalities provide complementary information based on their correla-tion and mutually promote representation learning.
Our contributions are summarized as follows:
• We perform an analysis on CNN-based detectors and
ﬁnd that they are biased to method-speciﬁc textures, leading to the generalization problem. Given that the image’s high-frequency noises can remove color tex-tures and reveal forgery traces, we propose to utilize image noises to boost the generalization ability.
• We devise a generalizable model by exploiting high-frequency features and modeling the correlation and interaction between the high-frequency modality and the regular one. We design three functional modules for learning an adequate representation, i.e., the multi-scale high-frequency feature extraction module, the residual guided spatial attention module, and the dual cross-modality attention module.
• We conduct comprehensive evaluations on several benchmarks and demonstrate the superior generaliza-tion ability of the proposed model. 2.