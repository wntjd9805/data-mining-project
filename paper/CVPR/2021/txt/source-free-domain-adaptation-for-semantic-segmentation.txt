Abstract
Unsupervised Domain Adaptation (UDA) can tackle the challenge that convolutional neural network (CNN)-based approaches for semantic segmentation heavily rely on the pixel-level annotated data, which is labor-intensive. How-ever, existing UDA approaches in this regard inevitably re-quire the full access to source datasets to reduce the gap between the source and target domains during model adap-tation, which are impractical in the real scenarios where the source datasets are private, and thus cannot be released along with the well-trained source models. To cope with this issue, we propose a source-free domain adaptation frame-work for semantic segmentation, namely SFDA, in which only a well-trained source model and an unlabeled target domain dataset are available for adaptation. SFDA not only enables to recover and preserve the source domain knowl-edge from the source model via knowledge transfer during model adaptation, but also distills valuable information from the target domain for self-supervised learning. The pixel-and patch-level optimization objectives tailored for semantic segmentation are seamlessly integrated in the framework.
The extensive experimental results on numerous benchmark datasets highlight the effectiveness of our framework against the existing UDA approaches relying on source data. 1.

Introduction
Semantic segmentation has been a critical computer vi-sion task, which aims to segment and parse a scene im-age into different image regions associated with semantic categories. It is critical for precisely understanding the vi-sual scene and can be applied to numerous potential ap-plications, such as autonomous driving [7], visual ground-ing [20, 45, 39], and image editing [31]. But the success of current segmentation techniques depends on large-scale densely-labeled datasets that are prohibitively expensive to be collected in reality. For instance, it takes about 90 min-utes to manually annotate a Cityscapes image. An intuitive method to address this issue is transferring knowledge from
*Corresponding author.
Figure 1. Overview of source-free UDA for segmentation. existing models trained on source datasets to the unlabeled target domain. However, it tends to be hindered by the issue of domain shift which is caused by various data distributions in source and target domains.
Unsupervised domain adaptation (UDA) [13, 54, 19, 6] for semantic segmentation has been proposed to address this issue and generalize the well-trained models on an unlabeled target domain, avoiding expensive data annotation. All the methods suppose that both the well-trained source models and labeled source datasets are available. This is because source data plays a vital role in retaining valuable source knowledge during adaptation training and reducing the cross-domain discrepancy iteratively. However, in some crucial areas like autonomous driving, the source datasets may be private and commercial, making only the source models and unlabeled target datasets available. Due to the lack of supervision of the source domain and the uncertainty of target pseudo-labels, none of these UDA methods can work in such source-free scenarios.
With these insights, we formulate a new but important problem — source-free domain adaptation for semantic seg-mentation, in which only a well-trained source model and an unlabeled target domain dataset are available for adap-tation. Recently, a tiny number of source-free UDA meth-ods [25, 24, 27, 38, 22, 26] have been developed to tackle a similar issue on image classiﬁcation. However, the image-level computer vision task just associates the label with a whole image, which is fundamentally different from image 1215
segmentation that belongs to a pixel-level task with each pixel associated with a semantic label. As shown in Fig-ure 1, the pseudo-labels of one target image contains mul-tiple classes shifting on diverse distributions. As such, it is nontrivial for the above methods to leverage clustering for each class adaptation. Since considering that the source domain knowledge cannot be preserved and utilized without source data, so we attempt to recover and transfer the source domain knowledge by introduced data-free knowledge distil-lation approaches [29, 3, 30, 11, 48] that are originally for model compression.
In this work, we propose a novel source-free unsupervised domain adaptation framework for segmentation, namely
SFDA. Our framework alternatively works in two stages: knowledge transfer and model adaptation. Due to unavail-able source data and uncertain target pseudo-labels, recover-ing and preserving the source knowledge learned by a source model is vital during adaptation training. This is because the uncertain supervision information in target pseudo-labels will tend to deviate the target model from the working do-main. As such, in the knowledge transfer stage, we leverage a generator to estimate the source domain (working domain) and synthesize fake samples similar to the real source data in distribution, which can be used to transfer the domain knowl-edge from a well-trained source model to a target model.
The key to semantic segmentation networks lies in captur-ing contextual feature relationships. With this intuition, a dual attention distillation (DAD) mechanism is introduced to help the generator synthesize samples with meaningful semantic context, which is beneﬁcial to efﬁcient pixel-level domain knowledge transfer. Moreover, the source model could work well on partial target domain and predict correct labels. Therefore we propose an entropy-based intra-domain patch-level self-supervision module (IPSM) to leverage the correctly segmented patches as self-supervision during the model adaptation stage.
Our main contributions can be summarized as follows:
• We propose the novel SFDA framework that combines knowledge transfer and model adaptation without re-quiring any source data and target labels. To our best knowledge, this is the ﬁrst attempt to address the prob-lem of source-free UDA for semantic segmentation.
• A novel dual attention distillation mechanism is de-signed speciﬁcally for segmentation to transfer and re-tain the contextual information, and the intra-domain patch-level self-supervision module is introduced to exploit patch-level knowledge in target domain.
• We demonstrate the effectiveness of our framework on synthetic-to-real and cross-city segmentation scenarios.
In particular, it can even achieve competitive results with the state-of-the-art source-driven UDA approaches under the source-free setting. 2.