Abstract 1.

Introduction
We propose real-time, six degrees of freedom (6DoF), 3D face pose estimation without face detection or landmark localization. We observe that estimating the 6DoF rigid transformation of a face is a simpler problem than facial landmark detection, often used for 3D face alignment. In addition, 6DoF offers more information than face bounding box labels. We leverage these observations to make multiple contributions: (a) We describe an easily trained, efﬁcient,
Faster R-CNN–based model which regresses 6DoF pose for all faces in the photo, without preliminary face detection. (b) We explain how pose is converted and kept consistent between the input photo and arbitrary crops created while (c) Finally, we show training and evaluating our model. how face poses can replace detection bounding box train-ing labels. Tests on AFLW2000-3D and BIWI show that our method runs at real-time and outperforms state of the art (SotA) face pose estimators. Remarkably, our method also surpasses SotA models of comparable complexity on the WIDER FACE detection benchmark, despite not been optimized on bounding box labels.
∗ Joint ﬁrst authorship.
All experiments reported in this paper were performed at the Univer-sity of Notre Dame.
Face detection is the problem of positioning a box to bound each face in a photo. Facial landmark detection seeks to localize speciﬁc facial features: e.g., eye centers, tip of the nose. Together, these two steps are the corner-stones of many face-based reasoning tasks, most notably recognition [18, 47, 48, 49, 74, 76] and 3D reconstruc-tion [20, 30, 71, 72]. Processing typically begins with face detection followed by landmark detection in each de-tected face box. Detected landmarks are matched with cor-responding ideal locations on a reference 2D image or a 3D model, and then an alignment transformation is resolved us-ing standard means [16, 39]. The terms face alignment and landmark detection are thus sometimes used interchange-ably [3, 15, 38].
Although this approach was historically successful, it has drawbacks. Landmark detectors are often optimized to the particular nature of the bounding boxes produced by speciﬁc face detectors. Updating the face detector therefore requires re-optimizing the landmark detector [4, 21, 50, 79].
More generally, having two successive components implies separately optimizing two steps of the pipeline for accuracy and – crucially for faces – fairness [1, 2, 35]. In addition,
SotA detection and pose estimation models can be compu-tationally expensive (e.g., ResNet-152 used by the full Reti-7617
naFace [17] detector). This computation accumulates when these steps are applied serially. Finally, localizing the stan-dard 68 face landmarks can be difﬁcult for tiny faces such as those in Fig. 1, making it hard to estimate their poses and align them. To address these concerns, we make the following key observations:
Observation 1: 6DoF pose is easier to estimate than de-tecting landmarks. Estimating 6DoF pose is a 6D regres-sion problem, obviously smaller than even 5-point landmark detection (5×2D landmarks = 10D), let alone standard 68 landmark detection (=136D). Importantly, pose captures the rigid transformation of the face. By comparison, land-marks entangle this rigid transformation with non-rigid fa-cial deformations and subject-speciﬁc face shapes.
This observation inspired many to recently propose skip-ping landmark detection in favor of direct pose estima-tion [8, 9, 10, 36, 51, 64, 81]. These methods, however, estimate poses for detected faces. By comparison, we aim to estimate poses without assuming that faces were already detected.
Observation 2: 6DoF pose labels capture more than just bounding box locations. Unlike angular, 3DoF pose esti-mated by some [31, 32, 64, 81], 6DoF pose can be converted to a 3D-to-2D projection matrix. Assuming a known intrin-sic camera parameters, pose can therefore align a 3D face with its location in the photo [27]. Hence, pose already cap-tures the location of the face in the photo. Yet, for the price of two additional scalars (6D pose vs. four values per box), 6DoF pose also provides information on the 3D position and orientation of the face. This observation was recently used by some, most notably, RetinaFace [17], to improve detec-tion accuracy by proposing multi-task learning of bounding box and facial landmarks. We, instead, combine the two in the single goal of directly regressing 6DoF face pose.
We offer a novel, easy to train, real-time solution to 6DoF, 3D face pose estimation, without requiring face de-tection (Fig. 1). We further show that predicted 3D face poses can be converted to obtain accurate 2D face bound-ing boxes with only negligible overhead, thereby providing face detection as a byproduct. Our method regresses 6DoF pose in a Faster R-CNN–based framework [63]. We explain how poses are estimated for ad-hoc proposals. To this end, we offer an efﬁcient means of converting poses across dif-ferent image crops (proposals) and the input photo, keeping ground truth and estimated poses consistent. In summary, we offer the following contributions.
• We propose a novel approach which estimates 6DoF, 3D face pose for all faces in an image directly, and without a preceding face detection step.
• We introduce an efﬁcient pose conversion method to maintain consistency of estimates and ground-truth poses, between an image and its ad-hoc proposals.
• We show how generated 3D pose estimates can be con-verted to accurate 2D bounding boxes as a byproduct with minimal computational overhead.
Importantly, all the contributions above are agnostic to the underlying Faster R-CNN–based architecture. The same techniques can be applied with other detection architectures to directly extract 6DoF, 3D face pose estimation, without requiring face detection.
Our model uses a small, fast, ResNet-18 [28] back-bone and is trained on the WIDER FACE [80] training set with a mixture of weakly supervised and human anno-tated ground-truth pose labels. We report SotA accuracy with real-time inference on both AFLW2000-3D [89] and
BIWI [19]. We further report face detection accuracy on
WIDER FACE [80], which outperforms models of compa-rable complexity by a wide margin. Our implementation and data are publicly available from: http://github. com/vitoralbiero/img2pose. 2.