Abstract
Standard UDA
Source data-free UDA
DT = {xi
T }NT i=1
DT = {xi
T }NT i=1
Unsupervised Domain Adaptation (UDA) aims to learn a predictor model for an unlabeled domain by transferring knowledge from a separate labeled source domain. However, most of these conventional UDA approaches make the strong assumption of having access to the source data during train-ing, which may not be very practical due to privacy, security and storage concerns. A recent line of work addressed this problem and proposed an algorithm that transfers knowl-edge to the unlabeled target domain from a single source model without requiring access to the source data. How-ever, for adaptation purposes, if there are multiple trained source models available to choose from, this method has to go through adapting each and every model individually, to check for the best source. Thus, we ask the question: can we ﬁnd the optimal combination of source models, with no source data and without target labels, whose performance is no worse than the single best source? To answer this, we propose a novel and efﬁcient algorithm which automatically combines the source models with suitable weights in such a way that it performs at least as good as the best source model. We provide intuitive theoretical insights to justify our claim. Furthermore, extensive experiments are conducted on several benchmark datasets to show the effectiveness of our algorithm, where in most cases, our method not only reaches best source accuracy but also outperforms it. 1.

Introduction
Deep neural networks have achieved proﬁciency in a multiple array of vision tasks [11, 25, 18, 35], however, these models have consistently fallen short in adapting to visual distributional shifts [27]. Human recognition, on the other hand, is robust to such shifts, such as reading text in a new font or recognizing objects in unseen environments.
Imparting such robustness towards distributional shifts to deep models is fundamental in applying these models to practical scenarios.
*Equal Contribution
†Work done while SP was a PhD student at UC Riverside.
D1
S = {xi
S1 , yi
S1 }N1 i=1
D2
S = {xi
S2 , yi
S2 }N2 i=1
Dn
S = {xi
Sn, yi
Sn}Nn i=1
θ1
S
θ2
S
>θn
S
>θT
Adaptation
D1
S = {xi
S1 , yi
S1 }N1 i=1
D2
S = {xi
S2 , yi
S2 }N2 i=1
Dn
S = {xi
Sn, yi
Sn}Nn i=1
θ1
S
θ2
S
>θn
S
>θT
Adaptation
Figure 1. Problem setup. Standard unsupervised multi-source domain adaptation (UDA) utilizes the source data, along with the models trained on the source, to perform adaptation on a target domain. In contrast, we introduce a setting which adapts multiple models without requiring access to the source data.
Unsupervised domain adaptation (UDA) [2, 37] seeks to bridge this performance gap due to domain shift via adap-tation of the model on small amounts of unsupervised data from the target domain. The majority of current approaches
[7, 14] optimize a two-fold objective: (i) minimize the em-pirical risk on the source data, (ii) make the target and source features indistinguishable from each other. Minimizing dis-tribution divergence between domains by matching the distri-bution statistical moments at different orders have also been explored extensively [42, 33].
A shortcoming of all the above approaches is the trans-ductive scenario in which they operate, i.e., the source data is required for adaptation purposes. In a real-world setting, source data may not be available for a variety of reasons.
Privacy and security are the primary concern, with the data possibly containing sensitive information. Another crucial reason is storage issues, i.e., source datasets may contain videos or high-resolution images and it might not be practical to transfer or store on different platforms. Consequently, it is imperative to develop unsupervised adaptation approaches which can adapt the source models to the target domain without access to the source data.
Recent works [21, 23] attempt this by adapting a single source model to a target domain without accessing the source data. However, an underlying assumption of these methods is that the most correlated source model is provided by an oracle for adaptation purposes. A more challenging and 10103
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" n
C 9 4
K
N
J 5 x
V
K u i k
S
E 1
B x
T x
W
/
A e
I 0
=
"
>
A
A
A
B 8
X i c b
V
B
N
S 8
N
A
E
N 3 4
W e t
X 1 a
O
X x
S
J 4
K o k o e i x 6 8
V j
R f m
A b y 2
Y 7 a
Z d u
N m
F 3
I p
T
Q f
+
H
F g y
J e
/
T f e
/
D d u 2 x y 0 9 c
H
A 4 7 0
Z
Z u
Y
F i
R
Q
G
X f f b
W
V p e
W
V 1 b
L 2 w
U
N 7 e 2 d 3
Z
L e
/ s
N
E 6 e a
Q 5 3
H
M t a t g
B m
Q
Q k
E d
B
U p o
J
R p
Y
F
E h o
B s
P r i d 9 8
A m 1
E r
O 5 x l
I
A f s b 4
S o e
A
M r f
T
Q w
Q
E g 6 9 4 9 e t 1
S 2 a 2 4
U 9
B
F 4 u
W k
T
H
L
U u q
W v
T i
/ m a
Q
Q
K u
W
T
G t
D 0 3
Q
T 9 j
G g
W
X
M
C 5 2
U g
M
J 4 0
P
W h 7 a l i k
V g
/
G x 6 8
Z g e
W 6
V
H w 1 j b
U k i n 6 u
+
J j
E
X
G j
K
L
A d k
Y
M
B 2 b e m 4 j
/ e e 0
U w 0 s
/
E y p
J
E
R
S f
L
Q p
T
S
T
G m k
/ d p
T 2 j g
K
E e
W
M
K 6
F v
Z
X y
A d
O
M o w 2 p a
E
P w 5 l 9 e
J
I 3
T i n d e c
W
/
P y t
W r
P
I 4
C
O
S
R
H 5
I
R 4 5
I
J
U y
Q 2 p k
T r h
R
J
F n 8 k r e
H
O
O 8
O
O
/
O x 6 x 1 y c l n
D s g f
O
J 8
/
K 6 e
Q l
Q
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" c
P 7
Y w
S w y l
S
X 5 n
/
H
G
A p
T f 4 e
L k x 4 o
=
"
>
A
A
A
B 8
X i c b
V
D
L
T g
J
B
E
J z
F
F
+
I
L 9 e h l
I j
H x
R
H a
J
R o 9
E
L x 4 x y i
P
C
S m a
H
B i b
M z m 5 m e k 3
I h r
/ w 4 k
F j v
P o 3 3 v w b
B 9 i
D g p
V 0
U q n q
T n d
X
E
E t h 0
H
W
/ n d z
K 6 t r 6
R n 6 z s
L
W 9 s 7 t
X 3
D 9 o m
C j
R
H
O o 8 k p
F u
B c y
A
F
A r q
K
F
B
C
K 9 b
A w k
B
C
M x h d
T
/ 3 m
E 2 g j
I n
W
P 4 x j 8 k
A 2
U 6
A v
O 0
E o
P
H
R w
C s u 7 d
Y 6
V b
L
L l l d w a 6
T
L y
M l
E i
G
W r f 4 1 e l
F
P
A l
B
I
Z f
M m
L b n x u i n
T
K
P g
E i a
F
T m
I g
Z n z
E
B t
C 2
V
L
E
Q j
J
/
O
L p 7
Q
E 6 v 0 a
D
/
S t h
T
S m f p 7
I m
W h
M e
M w s
J 0 h w 6
F
Z 9
K b i f 1 4 7 w f 6 l n w o
V
J w i
K z x f 1
E 0 k x o t
P 3 a
U 9 o 4
C j
H l j
C u h b 2
V 8 i
H
T j
K
M
N q
W
B
D 8
B
Z f
X i a
N
S t k 7
L 7 u 3
Z 6
X q
V
R
Z
H n h y
R
Y 3
J
K
P
H
J
B q u
S
G 1
E i d c
K
L
I
M 3 k l b 4 5 x
X p x 3 5 2
P e m n
O y m
U
P y
B 8 7 n
D y 0 r k
J
Y
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" q s
Y
L 8 t 7
P
B
F g k
C 0 k e 4
/ d g 3 o 2 t o
R
U
=
"
>
A
A
A
B 8
X i c b
V
B
N
S 8
N
A
E
N 3 4
W e t
X 1 a
O
X x
S
J 4
K o k o e i x 6 8
V j
R f m
A b y 2
Y 7 a
Z d u
N m
F 3
I p
T
Q f
+
H
F g y
J e
/
T f e
/
D d u 2 x y 0 9 c
H
A 4 7 0
Z
Z u
Y
F i
R
Q
G
X f f b
W
V p e
W
V 1 b
L 2 w
U
N 7 e 2 d 3
Z
L e
/ s
N
E 6 e a
Q 5 3
H
M t a t g
B m
Q
Q k
E d
B
U p o
J
R p
Y
F
E h o
B s
P r i d 9 8
A m 1
E r
O 5 x l
I
A f s b 4
S o e
A
M r f
T
Q w
Q
E g 6 9 4 9 q m 6 p 7
F b c
K e g i 8
X
J
S
J j l q 3 d
J
X p x f z
N
A
K
F
X
D
J j 2 p 6 b o
J 8 x j
Y
J
L
G
B c 7 q
Y
G
E 8
S
H r
Q 9 t
S x
S
I w f j a 9 e
E y
P r d
K j
Y a x t
K a
R
T 9 f d
E x i
J j
R l
F g
O y
O
G
A z
P v
T c
T
/ v
H a
K 4 a
W f
C
Z
W k
C
I r
P
F o
W p p
B j
T y f u 0
J z
R w l
C
N
L
G
N f
C 3 k r 5 g
G n
G 0
Y
Z
U t
C
F 4 8 y 8 v k s
Z p x
T u v u
L d n 5 e p
V
H k e
B
H
J
I j c k
I 8 c k
G q 5
I b
U
S
J 1 w o s g z e
S
V v j n
F e n
H f n
Y 9 a 6 5
O
Q z
B
+
Q
P n
M 8 f i
B u
Q 0 g
=
=
<
/ l a t e x i t
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
Q
U
X
U 7
E
D 6
O
O c
T h h f 3
K
A 6 q g z
D
H
M g k
=
"
>
A
A
A
B 7 3 i c b
V
B
N
S 8
N
A
E
J 3
U r 1 q
/ q h 6 9
L
B b
B
U 0 l
E 0
W
P
R i 8 c
K
/
Y
I 2 l
M 1 2 0 y 7 d b
O
L u
R
C i h f 8
K
L
B 0
W 8
+ n e 8
+
W
/ c t j l o 6 4
O
B x 3 s z z
M w
L
E i k
M u u 6 3
U 1 h b 3 9 j c
K m 6
X d n b 3 9 g
/
K h 0 c t
E 6 e a 8
S a
L
Z a w 7
A
T
V c
C s
W b
K
F
D y
T q
I 5 j
Q
L
J 2 8
H 4 b u a 3 n 7 g 2
I l
Y
N n
C
T c j
+ h
Q i
V
A w i l b q 9
H
D
E k f
Y b
/
X
L
F r b p z k
F
X i 5 a
Q
C
O e r 9 8 l d v
E
L
M 0 4 g q
Z p
M
Z 0
P
T d
B
P 6
M a
B
Z
N 8
W u q l h i e
U j e m
Q d y 1
V
N
O
L
G z
+ b 3
T s m
Z
V
Q
Y k j
L
U t h
W
S u
/ p 7
I a
G
T
M
J
A p s
Z 0
R x
Z
J a 9 m f i f 1 0 0 x v
P
E z o
Z
I
U u
W
K
L
R
W
E q
C c
Z k 9 j w
Z
C
M 0
Z y o k l l
G l h b y
V s
R
D
V l a
C
M q 2
R
C 8 5
Z d
X
S e u i 6 l 1
V 3
Y f
L
S u 0 2 j 6
M
I
J 3
A
K 5
+
D
B
N d
T g
H u r
Q
B
A
Y
S n u
E
V 3 p x
H 5 8
V 5 d z 4
W r
Q
U n n z m
G
P 3
A
+ f w
A
D 1
I
/ z
<
/ l a t e x i t
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
L j v
C
/
H 4 a 8
P 9
M s o
/
P
H
O
S 4
X i p 8
F
Y
I
=
"
>
A
A
A
C
D
H i c b
V
D
L
S g
M x
F
M 3
U
V 6 2 v q k s 3 w
S
K 4
K j
O i 6
K
Z
Q 1
I
U r q
T
B 9
Q
G c 6
Z
N
J
M
G 5 p 5 k
G
T
E
E u
Y
D 3
P g r b l w o 4 t
Y
P c
O f f m
G m 7 0
N
Y
D g c
M 5 5 5
J 7 j 5 8 w
K q
R p f h u
F p e
W
V 1 b
X i e m l j c 2 t 7 p 7 y 7 1 x
J x y j
F p 4 p j
F v
O
M j
Q
R i
N
S
F
N
S y
U g n 4
Q
S
F
P i
N t f 3
S
V
+
+ 1 7 w g
W
N
I 1 u
O
E
+
K
G a
B
D
R g
G
I k t e
S
V
K 0 6
I 5
B
A j p q 4 z z 6 4 5 6 q
F
H
P d v
J
P
E
V r
V t
Z
T t 5 6 d 6
Z
R
Z
N
S e
A i 8
S a k
Q q
Y o e
G
V v 5 x
+ j
N
O
Q
R
B
I z
J
E
T
X
M h
P p
K s
Q l x
Y x k
J
S c
V
J
E
F 4 h
A a k q 2 m
E
Q i
J c
N
T k m g 0 d a 6 c
M g 5 v p
F
E k 7
U 3 x
M
K h
U
K
M
Q 1 8 n 8 9
X
F v
J e
L
/ 3 n d
V
A
Y
X r q
J
R k k o
S 4 e l
H
Q c q g j
G
H e
D
O x
T
T r
B k
Y 0 0
Q 5 l
T v
C v
E
Q c
Y
S l 7 q
+ k
S 7
D m
T 1 4 k r
Z
O q d
V
Y 1 7 0 4 r 9 c t
Z
H
U
V w
A
A 7
B
M b
D
A
O a i
D
G 9
A
A
T
Y
D
B
I 3 g
G r
+
D
N e
D
J e j
H f j
Y x o t
G
L
O
Z f f
A
H x u c
P
A
+
K b l g
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" n
C 9 4
K
N
J 5 x
V
K u i k
S
E 1
B x
T x
W
/
A e
I 0
=
"
>
A
A
A
B 8
X i c b
V
B
N
S 8
N
A
E
N 3 4
W e t
X 1 a
O
X x
S
J 4
K o k o e i x 6 8
V j
R f m
A b y 2
Y 7 a
Z d u
N m
F 3
I p
T
Q f
+
H
F g y
J e
/
T f e
/
D d u 2 x y 0 9 c
H
A 4 7 0
Z
Z u
Y
F i
R
Q
G
X f f b
W
V p e
W
V 1 b
L 2 w
U
N 7 e 2 d 3
Z
L e
/ s
N
E 6 e a
Q 5 3
H
M t a t g
B m
Q
Q k
E d
B
U p o
J
R p
Y
F
E h o
B s
P r i d 9 8
A m 1
E r
O 5 x l
I
A f s b 4
S o e
A
M r f
T
Q w
Q
E g 6 9 4 9 e t 1
S 2 a 2 4
U 9
B
F 4 u
W k
T
H
L
U u q
W v
T i
/ m a
Q
Q
K u
W
T
G t
D 0 3
Q
T 9 j
G g
W
X
M
C 5 2
U g
M
J 4 0
P
W h 7 a l i k
V g
/
G x 6 8
Z g e
W 6
V
H w 1 j b
U k i n 6 u
+
J j
E
X
G j
K
L
A d k
Y
M
B 2 b e m 4 j
/ e e 0
U w 0 s
/
E y p
J
E
R
S f
L
Q p
T
S
T
G m k
/ d p
T 2 j g
K
E e
W
M
K 6
F v
Z
X y
A d
O
M o w 2 p a
E
P w 5 l 9 e
J
I 3
T i n d e c
W
/
P y t
W r
P
I 4
C
O
S
R
H 5
I
R 4 5
I
J
U y
Q 2 p k
T r h
R
J
F n 8 k r e
H
O
O 8
O
O
/
O x 6 x 1 y c l n
D s g f
O
J 8
/
K 6 e
Q l
Q
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" c
P 7
Y w
S w y l
S
X 5 n
/
H
G
A p
T f 4 e
L k x 4 o
=
"
>
A
A
A
B 8
X i c b
V
D
L
T g
J
B
E
J z
F
F
+
I
L 9 e h l
I j
H x
R
H a
J
R o 9
E
L x 4 x y i
P
C
S m a
H
B i b
M z m 5 m e k 3
I h r
/ w 4 k
F j v
P o 3 3 v w b
B 9 i
D g p
V 0
U q n q
T n d
X
E
E t h 0
H
W
/ n d z
K 6 t r 6
R n 6 z s
L
W 9 s 7 t
X 3
D 9 o m
C j
R
H
O o 8 k p
F u
B c y
A
F
A r q
K
F
B
C
K 9 b
A w k
B
C
M x h d
T
/ 3 m
E 2 g j
I n
W
P 4 x j 8 k
A 2
U 6
A v
O 0
E o
P
H
R w
C s u 7 d
Y 6
V b
L
L l l d w a 6
T
L y
M l
E i
G
W r f 4 1 e l
F
P
A l
B
I
Z f
M m
L b n x u i n
T
K
P g
E i a
F
T m
I g
Z n z
E
B t
C 2
V
L
E
Q j
J
/
O
L p 7
Q
E 6 v 0 a
D
/
S t h
T
S m f p 7
I m
W h
M e
M w s
J 0 h w 6
F
Z 9
K b i f 1 4 7 w f 6 l n w o
V
J w i
K z x f 1
E 0 k x o t
P 3 a
U 9 o 4
C j
H l j
C u h b 2
V 8 i
H
T j
K
M
N q
W
B
D 8
B
Z f
X i a
N
S t k 7
L 7 u 3
Z 6
X q
V
R
Z
H n h y
R
Y 3
J
K
P
H
J
B q u
S
G 1
E i d c
K
L
I
M 3 k l b 4 5 x
X p x 3 5 2
P e m n
O y m
U
P y
B 8 7 n
D y 0 r k
J
Y
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" q s
Y
L 8 t 7
P
B
F g k
C 0 k e 4
/ d g 3 o 2 t o
R
U
=
"
>
A
A
A
B 8
X i c b
V
B
N
S 8
N
A
E
N 3 4
W e t
X 1 a
O
X x
S
J 4
K o k o e i x 6 8
V j
R f m
A b y 2
Y 7 a
Z d u
N m
F 3
I p
T
Q f
+
H
F g y
J e
/
T f e
/
D d u 2 x y 0 9 c
H
A 4 7 0
Z
Z u
Y
F i
R
Q
G
X f f b
W
V p e
W
V 1 b
L 2 w
U
N 7 e 2 d 3
Z
L e
/ s
N
E 6 e a
Q 5 3
H
M t a t g
B m
Q
Q k
E d
B
U p o
J
R p
Y
F
E h o
B s
P r i d 9 8
A m 1
E r
O 5 x l
I
A f s b 4
S o e
A
M r f
T
Q w
Q
E g 6 9 4 9 q m 6 p 7
F b c
K e g i 8
X
J
S
J j l q 3 d
J
X p x f z
N
A
K
F
X
D
J j 2 p 6 b o
J 8 x j
Y
J
L
G
B c 7 q
Y
G
E 8
S
H r
Q 9 t
S x
S
I w f j a 9 e
E y
P r d
K j
Y a x t
K a
R
T 9 f d
E x i
J j
R l
F g
O y
O
G
A z
P v
T c
T
/ v
H a
K 4 a
W f
C
Z
W k
C
I r
P
F o
W p p
B j
T y f u 0
J z
R w l
C
N
L
G
N f
C 3 k r 5 g
G n
G 0
Y
Z
U t
C
F 4 8 y 8 v k s
Z p x
T u v u
L d n 5 e p
V
H k e
B
H
J
I j c k
I 8 c k
G q 5
I b
U
S
J 1 w o s g z e
S
V v j n
F e n
H f n
Y 9 a 6 5
O
Q z
B
+
Q
P n
M 8 f i
B u
Q 0 g
=
=
<
/ l a t e x i t
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
Q
U
X
U 7
E
D 6
O
O c
T h h f 3
K
A 6 q g z
D
H
M g k
=
"
>
A
A
A
B 7 3 i c b
V
B
N
S 8
N
A
E
J 3
U r 1 q
/ q h 6 9
L
B b
B
U 0 l
E 0
W
P
R i 8 c
K
/
Y
I 2 l
M 1 2 0 y 7 d b
O
L u
R
C i h f 8
K
L
B 0
W 8
+ n e 8
+
W
/ c t j l o 6 4
O
B x 3 s z z
M w
L
E i k
M u u 6 3
U 1 h b 3 9 j c
K m 6
X d n b 3 9 g
/
K h 0 c t
E 6 e a 8
S a
L
Z a w 7
A
T
V c
C s
W b
K
F
D y
T q
I 5 j
Q
L
J 2 8
H 4 b u a 3 n 7 g 2
I l
Y
N n
C
T c j
+ h
Q i
V
A w i l b q 9
H
D
E k f
Y b
/
X
L
F r b p z k
F
X i 5 a
Q
C
O e r 9 8 l d v
E
L
M 0 4 g q
Z p
M
Z 0
P
T d
B
P 6
M a
B
Z
N 8
W u q l h i e
U j e m
Q d y 1
V
N
O
L
G z
+ b 3
T s m
Z
V
Q
Y k j
L
U t h
W
S u
/ p 7
I a
G
T
M
J
A p s
Z 0
R x
Z
J a 9 m f i f 1 0 0 x v
P
E z o
Z
I
U u
W
K
L
R
W
E q
C c
Z k 9 j w
Z
C
M 0
Z y o k l l
G l h b y
V s
R
D
V l a
C
M q 2
R
C 8 5
Z d
X
S e u i 6 l 1
V 3
Y f
L
S u 0 2 j 6
M
I
J 3
A
K 5
+
D
B
N d
T g
H u r
Q
B
A
Y
S n u
E
V 3 p x
H 5 8
V 5 d z 4
W r
Q
U n n z m
G
P 3
A
+ f w
A
D 1
I
/ z
<
/ l a t e x i t
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
L j v
C
/
H 4 a 8
P 9
M s o
/
P
H
O
S 4
X i p 8
F
Y
I
=
"
>
A
A
A
C
D
H i c b
V
D
L
S g
M x
F
M 3
U
V 6 2 v q k s 3 w
S
K 4
K j
O i 6
K
Z
Q 1
I
U r q
T
B 9
Q
G c 6
Z
N
J
M
G 5 p 5 k
G
T
E
E u
Y
D 3
P g r b l w o 4 t
Y
P c
O f f m
G m 7 0
N
Y
D g c
M 5 5 5
J 7 j 5 8 w
K q
R p f h u
F p e
W
V 1 b
X i e m l j c 2 t 7 p 7 y 7 1 x
J x y j
F p 4 p j
F v
O
M j
Q
R i
N
S
F
N
S y
U g n 4
Q
S
F
P i
N t f 3
S
V
+
+ 1 7 w g
W
N
I 1 u
O
E
+
K
G a
B
D
R g
G
I k t e
S
V
K 0 6
I 5
B
A j p q 4 z z 6 4 5 6 q
F
H
P d v
J
P
E
V r
V t
Z
T t 5 6 d 6
Z
R
Z
N
S e
A i 8
S a k
Q q
Y o e
G
V v 5 x
+ j
N
O
Q
R
B
I z
J
E
T
X
M h
P p
K s
Q l x
Y x k
J
S c
V
J
E
F 4 h
A a k q 2 m
E
Q i
J c
N
T k m g 0 d a 6 c
M g 5 v p
F
E k 7
U 3 x
M
K h
U
K
M
Q 1 8 n 8 9
X
F v
J e
L
/ 3 n d
V
A
Y
X r q
J
R k k o
S 4 e l
H
Q c q g j
G
H e
D
O x
T
T r
B k
Y 0 0
Q 5 l
T v
C v
E
Q c
Y
S l 7 q
+ k
S 7
D m
T 1 4 k r
Z
O q d
V
Y 1 7 0 4 r 9 c t
Z
H
U
V w
A
A 7
B
M b
D
A
O a i
D
G 9
A
A
T
Y
D
B
I 3 g
G r
+
D
N e
D
J e j
H f j
Y x o t
G
L
O
Z f f
A
H x u c
P
A
+
K b l g
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" i e 9 g
P
V
G 6 5 5 4
G
O o 1
P w p u 5 0 0
R n t
M
M
=
"
>
A
A
A
C
H
X i c b
Z
D
L
S g
M x
F
I
Y z 9
V b r b d
S l m 2
A
R
X
E i
Z k
Y p u
C k
V d u
J
J
K 7
Q
U 6 7
Z
B
J 0 z
Y 0 c y
H
J i
C
X
M i 7 j x
V d y 4
U
M
S
F
G
/
F t z
L
Q
V t
P
V
A 4
M t
/ z i
H 5 f y 9 i
V
E j
L
+ j
I y
C 4 t
L y y v
Z 1 d z a
+ s b m l r m 9
U x d h z
D
G p 4
Z
C
F v
O k h
Q
R g
N
S
E 1
S y
U g z 4 g
T 5
H i
M
N b 3 i
R 9 h t 3 h
A s a
B r d y
F
J
G 2 j
/ o
B 7
V
G
M p
J
Z c s
+ j 4
S
A 4 w
Y u o y c a s d u
+
S o e 1 d
V
X
T v p 0
C
M 4
+ k
E n c
R
U t a
V
L
X
+ u 6 a e a t g j
Q v
O g z 2
F
P
J h
W x
T
U
/ n
G 6
I
Y 5 8
E
E j
M k
R
M u 2
I t l
W i
E u
K
G
U l y
T i x
I h
P
A
Q 9
U l
L
Y 4
B 8
I t p q 7
C 6
B
B 1 r p w l 7
I 9
Q k k
H
K u
/
N x
T y h
R j 5 n p 5
M v
Y j
Z
X i r
+ 1 2 v
F s n f
W
V j
S
I
Y k k
C
P
H m o
F z
M o
Q 5 h
G
B b u
U
E y z
Z
S
A
P
C n
O q
/
Q j x
A
H
G
G p
A 8 3 p
E
O x
Z y
/
N
Q
P y 7
Y
J w
X r p p g v n 0
/ j y
I
I 9 s
A 8
O g
Q 1
O
Q
R l c g
Q q o
A
Q w e w
B
N 4
A a
/
G o
/
F s v
B n v k 9
G
M
M d 3
Z
B
X
/
K
+
P w
G
M j 2 h
+
A
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
W
E o d t z
F
+
M 0 9 1 k
+ j q
I
B
T
W
I
H v s
C
D
M
=
"
>
A
A
A
C
H
X i c b
V
B
L
S w
M x
G
M z 6 r
P
V
V 9 e g l
W
A
Q
P
U n
Z
L
R
S
+
F o h 4 8
S a
X 2
A d 1 2 y a
Z p
G 5 p 9 k
G
T
F
J e w f 8 e
J f 8 e
J
B
E
Q 9 e x
H 9 j t q 2 g r
Q
O
B y c z 3 k c y 4
I a
N
C m u a
X s b
C 4 t
L y y m l n
L r m 9 s b m 3 n d n
Y b
I o g 4
J n
U c s
I
C 3
X
C
Q
I o z 6 p
S y o
Z a
Y
W c
I
M 9 l p
O m
O
L l
K
/ e
U e 4 o
I
F
/
K
+
O
Q d
D w 0 8
G m f
Y i
S 1 5
O
R
K t o f k
E
C
O m
L h
O n 1 i 2
W b
X
X v q
J p
T
T
L r 0
G
M
Y
/ 1
E 4 c
R c t
W 0 l
X
X
+ u 7 k 8 m b
B
H
A
P
O
E 2 t
K 8 m
C
K q p
P 7 s
H s
B j j z i
S 8 y
Q
E
G 3
L
D
G
V
H
I
S 4 p
Z i
T
J 2 p
E g
I c
I j
N
C
B t
T
X 3 k
E d
F
R 4 3
Q
J
P
N
R
K
D
/
Y
D r o 8 v 4
V j 9 v a
G
Q
J 0
T s u
X o y z
S
J m v
V
T 8 z 2 t
H s n
/
W
U d
Q
P
I 0 l 8
P
H m o
H z
E o
A 5 h
W
B
X u
U
E y x
Z r
A n
C n
O q
/
Q j x
E
H
G
G p
C 8 3 q
E q z
Z y
P
O k
U
S x
Y
J w
X z p p
S v n
E
/ r y
I
B 9 c
A
C
O g
A
V
O
Q
Q
V c g
S q o
A w w e w
B
N 4
A a
/
G o
/
F s v
B n v k 9
E
F
Y 7 q z
B
/ 7
A
+
P w
G
O
K
C h
/
A
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
X
G y
Y
V
T
Z m
A 1 t y 3 o 5
C d y 3 h
O y
T 5 m s
Y
=
"
>
A
A
A
C
H
X i c b
V
B
L
S w
M x
G
M z
W
V 6 2 v q k c v w
S
J 4 k
L
I r
F b 0
U i n r w
J
J
X a
B 3
T b
J
Z u m b
W g 2 u y
R
Z s
Y
T 9
I 1 7 8
K 1 4 8
K
O
L
B i
/ h v
T
B
+
C t g 4
E
J j
P f
R z
L j
R 4 x
K
Z d t f
V m p h c
W l 5
J b 2 a
W
V v f 2
N z
K b u
/
U
Z
B g
L
T
K o 4
Z
K
F o
+
E g
S
R j m p
K q o
Y a
U
S
C o
M
B n p
O 4
P
L k
Z
+
/
Y 4
I
S
U
N
+ q 4
Y
R a
Q
W o x 2 m
X
Y q
S
M 5
G
U
L b o
B
U
H y
O m
L x
O v 0 u
Z
F
V 9 9 7 u u
L x p
E 2
P 4
P
C
H u o m n a d
F
J 2 v r a 3
L 1 s z s 7 b
Y 8
B 5 4 k x
J
D k x
R 9 r
I f b i f
E c
U
C 4 w g x
J 2
X
T s
S
L
U 0
E o p i
R p
K
M
G 0 s
S
I
T x
A
P d
I 0 l
K
O
A y
J
Y e p 0 v g g
V
E 6 s
B s
K c 7 i
C
Y
/
X 3 h k a
B l
M
P
A
N 5
O j
L
H
L
W
G 4 n
/ e c 1
Y d c 9 a m v
I o
V o
T j y
U
P d m
E
E
V w l
F
V s
E
M
F w
Y o
N
D
U
F
Y
U
P
N
X i
P t
I
I
K x
M o
R l
T g j
M b e
Z 7
U j v
P
O
S d 6
+
K e
R
K 5 9
M 6 0 m
A
P 7
I
N
D 4
I
B
T
U
A
J
X o
A y q
A
I
M
H 8
A
R e w
K v 1 a
D 1 b b 9 b 7
Z
D
R l
T
X d 2 w
R 9
Y n 9
+ 3 4 6
L s
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" i e 9 g
P
V
G 6 5 5 4
G
O o 1
P w p u 5 0 0
R n t
M
M
=
"
>
A
A
A
C
H
X i c b
Z
D
L
S g
M x
F
I
Y z 9
V b r b d
S l m 2
A
R
X
E i
Z k
Y p u
C k
V d u
J
J
K 7
Q
U 6 7
Z
B
J 0 z
Y 0 c y
H
J i
C
X
M i 7 j x
V d y 4
U
M
S
F
G
/
F t z
L
Q
V t
P
V
A 4
M t
/ z i
H 5 f y 9 i
V
E j
L
+ j
I y
C 4 t
L y y v
Z 1 d z a
+ s b m l r m 9
U x d h z
D
G p 4
Z
C
F v
O k h
Q
R g
N
S
E 1
S y
U g z 4 g
T 5
H i
M
N b 3 i
R 9 h t 3 h
A s a
B r d y
F
J
G 2 j
/ o
B 7
V
G
M p
J
Z c s
+ j 4
S
A 4 w
Y u o y c a s d u
+
S o e 1 d
V
X
T v p 0
C
M 4
+ k
E n c
R
U t a
V
L
X
+ u 6 a e a t g j
Q v
O g z 2
F
P
J h
W x
T
U
/ n
G 6
I
Y 5 8
E
E j
M k
R
M u 2
I t l
W i
E u
K
G
U l y
T i x
I h
P
A
Q 9
U l
L
Y 4
B 8
I t p q 7
C 6
B
B 1 r p w l 7
I 9
Q k k
H
K u
/
N x
T y h
R j 5 n p 5
M v
Y j
Z
X i r
+ 1 2 v
F s n f
W
V j
S
I
Y k k
C
P
H m o
F z
M o
Q 5 h
G
B b u
U
E y z
Z
S
A
P
C n
O q
/
Q j x
A
H
G
G p
A 8 3 p
E
O x
Z y
/
N
Q
P y 7
Y
J w
X r p p g v n 0
/ j y
I
I 9 s
A 8
O g
Q 1
O
Q
R l c g
Q q o
A
Q w e w
B
N 4
A a
/
G o
/
F s v
B n v k 9
G
M
M d 3
Z
B
X
/
K
+
P w
G
M j 2 h
+
A
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
W
E o d t z
F
+
M 0 9 1 k
+ j q
I
B
T
W
I
H v s
C
D
M
=
"
>
A
A
A
C
H
X i c b
V
B
L
S w
M x
G
M z 6 r
P
V
V 9 e g l
W
A
Q
P
U n
Z
L
R
S
+
F o h 4 8
S a
X 2
A d 1 2 y a
Z p
G 5 p 9 k
G
T
F
J e w f 8 e
J f 8 e
J
B
E
Q 9 e x
H 9 j t q 2 g r
Q
O
B y c z 3 k c y 4
I a
N
C m u a
X s b
C 4 t
L y y m l n
L r m 9 s b m 3 n d n
Y b
I o g 4
J n
U c s
I
C 3
X
C
Q
I o z 6 p
S y o
Z a
Y
W c
I
M 9 l p
O m
O
L l
K
/ e
U e 4 o
I
F
/
K
+
O
Q d
D w 0 8
G m f
Y i
S 1 5
O
R
K t o f k
E
C
O m
L h
O n 1 i 2
W b
X
X v q
J p
T
T
L r 0
G
M
Y
/ 1
E 4 c
R c t
W 0 l
X
X
+ u 7 k 8 m b
B
H
A
P
O
E 2 t
K 8 m
C
K q p
P 7 s
H s
B j j z i
S 8 y
Q
E
G 3
L
D
G
V
H
I
S 4 p
Z i
T
J 2 p
E g
I c
I j
N
C
B t
T
X 3 k
E d
F
R 4 3
Q
J
P
N
R
K
D
/
Y
D r o 8 v 4
V j 9 v a
G
Q
J 0
T s u
X o y z
S
J m v
V
T 8 z 2 t
H s n
/
W
U d
Q
P
I 0 l 8
P
H m o
H z
E o
A 5 h
W
B
X u
U
E y x
Z r
A n
C n
O q
/
Q j x
E
H
G
G p
C 8 3 q
E q z
Z y
P
O k
U
S x
Y
J w
X z p p
S v n
E
/ r y
I
B 9 c
A
C
O g
A
V
O
Q
Q
V c g
S q o
A w w e w
B
N 4
A a
/
G o
/
F s v
B n v k 9
E
F
Y 7 q z
B
/ 7
A
+
P w
G
O
K
C h
/
A
=
=
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
"
X
G y
Y
V
T
Z m
A 1 t y 3 o 5
C d y 3 h
O y
T 5 m s
Y
=
"
>
A
A
A
C
H
X i c b
V
B
L
S w
M x
G
M z
W
V 6 2 v q k c v w
S
J 4 k
L
I r
F b 0
U i n r w
J
J
X a
B 3
T b
J
Z u m b
W g 2 u y
R
Z s
Y
T 9
I 1 7 8
K 1 4 8
K
O
L
B i
/ h v
T
B
+
C t g 4
E
J j
P f
R z
L j
R 4 x
K
Z d t f
V m p h c
W l 5
J b 2 a
W
V v f 2
N z
K b u
/
U
Z
B g
L
T
K o 4
Z
K
F o
+
E g
S
R j m p
K q o
Y a
U
S
C o
M
B n p
O 4
P
L k
Z
+
/
Y 4
I
S
U
N
+ q 4
Y
R a
Q
W o x 2 m
X
Y q
S
M 5
G
U
L b o
B
U
H y
O m
L x
O v 0 u
Z
F
V 9 9 7 u u
L x p
E 2
P 4
P
C
H u o m n a d
F
J 2 v r a 3
L 1 s z s 7 b
Y 8
B 5 4 k x
J
D k x
R 9 r
I f b i f
E c
U
C 4 w g x
J 2
X
T s
S
L
U 0
E o p i
R p
K
M
G 0 s
S
I
T x
A
P d
I 0 l
K
O
A y
J
Y e p 0 v g g
V
E 6 s
B s
K c 7 i
C
Y
/
X 3 h k a
B l
M
P
A
N 5
O j
L
H
L
W
G 4 n
/ e c 1
Y d c 9 a m v
I o
V o
T j y
U
P d m
E
E
V w l
F
V s
E
M
F w
Y o
N
D
U
F
Y
U
P
N
X i
P t
I
I
K x
M o
R l
T g j
M b e
Z 7
U j v
P
O
S d 6
+
K e
R
K 5 9
M 6 0 m
A
P 7
I
N
D 4
I
B
T
U
A
J
X o
A y q
A
I
M
H 8
A
R e w
K v 1 a
D 1 b b 9 b 7
Z
D
R l
T
X d 2 w
R 9
Y n 9
+ 3 4 6
L s
<
/ l a t e x i t
>
practical scenario entails adaptation from a bag of source models - each of these source domains are correlated to the target by different amounts and adaptation involves not only incorporating the combined prior knowledge from multi-ple models, but simultaneously preventing the possibility of negative transfer. In this paper, we introduce the problem of unsupervised multi-source adaptation without access to source data. We develop an algorithm based on the princi-ples of pseudo-labeling and information maximization and provide intuitive theoretical insights to show that our frame-work guarantees performance better than the best available source and minimize the effect of negative transfer.
To solve this problem of multiple source model adaptation without accessing the source data, we deploy Information
Maximization (IM) loss [23] on the weighted combination of target soft labels from all the source models. We also use the pseudo-label strategy inspired from deep cluster method [4], along with the IM loss to minimize noisy cluster assignment of the features. The overall optimization jointly adapts the feature encoders from sources as well as the correspond-ing source weights, combining which the target model is obtained.
Main Contributions. We address the problem of multiple source UDA, with no access to the source data. Towards solving the problem, we make the following contributions:
• We propose a novel UDA algorithm which operates with-out requiring access to the source data. We term it as Data frEe multi-sourCe unsupervISed domain adaptatiON (DECI-SION). Our algorithm automatically identiﬁes the optimal blend of source models to generate the target model by opti-mizing a carefully designed unsupervised loss.
• Under intuitive assumptions, we establish theoretical guar-antees on the performance of the target model which shows that it is consistently at least as good as deploying the single best source model, thus, minimizing negative transfer.
• We validate our claim by extensive numerical experiments, demonstrating the practical beneﬁts of our approach.
METHOD
UDA [14]
MSDA [33]
HTL [40]
U-HTL [23]
DECISION(Ours)
MULTIPLE
DOMAINS
NO
SOURCE
DATA
SOURCE
MODEL
UNLABELED
TARGET
DATA
✗
✓
✗
✗
✓
✗
✗
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✗
✓
✓
Table 1. Comparison to different adaptation settings by at-tributes demonstrated in the paper. Our proposed setting sat-isﬁes all the criteria desired in a holistic adaptation framework. pothesis transfer learning (HTL) [40, 34, 1] aims to transfer learnt source hypotheses to a target domain without access to source data. However, data is assumed to be labeled in the target domain in contrast to our scenario, limiting its appli-cability to real-world settings. Recently, [21, 23] extend the standard HTL setting to unsupervised target data (U-HTL) by adapting single source hypotheses via pseudo-labeling.
Our paper takes this one step further by introducing multiple source models, which may or may not be positively corre-lated with the target domain.
Multi-source domain adaptation. Multi-source domain adaptation (MSDA) extends the standard UDA setting by in-corporating knowledge from multiple source models. Latent space transformation methods [50] aim to align the features of different domains by optimizing a discrepancy measure or an adversarial loss. Discrepancy based methods seek to align the domains by minimizing measures such as maxi-mum mean discrepancy [10, 50] and R´enyi-divergence [13].
Adversarial methods aim to make features from multiple domains indistinguishable to a domain discriminator by opti-mizing GAN loss [47], H−divergence [49] and Wasserstein distance [46, 22]. Domain generative methods [36, 24] use some form of domain translation, such as the CycleGAN
[51], to perform adaptation at the pixel level. All these meth-ods assume access to the source data during adaptation. 2.