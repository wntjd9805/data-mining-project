Abstract
Despite the recent advances in multiple object tracking (MOT), achieved by joint detection and tracking, dealing with long occlusions remains a challenge. This is due to the fact that such techniques tend to ignore the long-term mo-tion information. In this paper, we introduce a probabilis-tic autoregressive motion model to score tracklet proposals by directly measuring their likelihood. This is achieved by training our model to learn the underlying distribution of natural tracklets. As such, our model allows us not only to assign new detections to existing tracklets, but also to inpaint a tracklet when an object has been lost for a long time, e.g., due to occlusion, by sampling tracklets so as to ﬁll the gap caused by misdetections. Our experiments demon-strate the superiority of our approach at tracking objects in challenging sequences; it outperforms the state of the art in most standard MOT metrics on multiple MOT benchmark datasets, including MOT16, MOT17, and MOT20. 1.

Introduction
Tracking multiple objects in a video is key to the suc-cess of many computer vision applications, such as sport analysis, autonomous driving, robot navigation, and visual surveillance. With the recent progress in object detection, tracking-by-detection [2] has become the de facto approach to multiple object tracking; it consists of ﬁrst detecting the objects in the individual frames and then associating these detections with trajectories, known as tracklets. While these two steps were originally performed sequentially, recent ad-vances have beneﬁted from treating detection and tracking jointly [3, 53, 66]. These approaches cast MOT as a local tracking problem, utilizing either an object detector’s re-gression head [3] or an additional offset head [53, 66] to per-form temporal re-alignment of the object bounding boxes in consecutive frames. In other words, these approaches treat tracking as the problem of propagating detection identities across consecutive frames. While this strategy constitutes the state of the art on many benchmark datasets in terms of MOT metrics that highlight the quality of the detections, e.g., MOTA, it fails to maintain identities throughout occlu-sions, and thus tends to produce many identity switches. In this paper, we address this issue by developing a stochas-tic motion model that helps the tracker to maintain identi-ties, even in the presence of long-term occlusions. In other words, we show that, while largely ignored in the recent
MOT literature, motion remains a critical cue for tracking, even with the great progress achieved by detectors. This is evidenced by our experimental results on multiple MOT benchmark datasets, in which our approach outperforms the state of the art by a large margin.
Motion has, of course, been considered in the past, mostly in the tracking-by-detection literature, via either model-based ﬁltering techniques [5, 25, 56] or more sophis-ticated data-driven ones based on RNNs [14, 17, 41, 44, 47, 55, 59, 60]. However, all of these approaches treat human motion as a deterministic or a uni-modal process. Here, we argue that human motion is a stochastic multi-modal pro-cess, and should thus be modeled stochastically. Note that a similar concept has also been explored in the context of trajectory forecasting, where the problem is to often given perfect (ground-truth) trajectories, predict ﬁxed-length con-tinuations of those trajectories as a single path [1, 23], or a distribution over different paths [19, 24, 29, 39, 48, 49].
However, to the best of our knowledge, these techniques have not been incorporated in the context of MOT, where we deal with noisy observations (detections), frequent oc-clusions, and assignment uncertainties.
Therefore, we introduce a stochastic autoregressive mo-tion model that explicitly learns the multi-modal distribu-tion of natural trajectories. This allows us to estimate the likelihood of a tracklet given a sequence of bounding box locations and the tracklets of the surrounding agents. We then use this model to compute the likelihood of a tracklet after assigning it a new detection. Moreover, learning the multi-modal distribution of tracklets allows us to inpaint a tracklet in the presence of misdetections caused by occlu-sion by sampling from the learned distribution. This is also what the visual cortex of the human brain does when rea-soning about dynamically occluded objects [15, 52].
To summarize, our contributions are as follows: (1) We 14329
introduce a stochastic autoregressive model to score a track-let by the likelihood that it represents natural motion. (2)
Since our model learns the multi-modal distribution of nat-ural human motion, it can generate multiple plausible con-tinuations of the tracklets and inpaint tracklets containing missed detections. (3) Our stochastic motion model can bet-ter preserve identities over longer time horizons than recent
MOT approaches, especially when there are occlusions.
We conduct comprehensive ablation studies, demonstrat-ing the effectiveness of the different components of our approach. Our method outperforms the state of the art in multiple MOT benchmark datasets, particularly improv-ing the metrics related to long-term identity preservation, such as IDF1, ID Switch (IDs), and Mostly Tracked Track-lets (MT). This is further conﬁrmed by our experiments on the challenging new MOT20 [13] dataset, targeting highly crowded scenarios. We refer to our model as ArTIST, for Autoregressive Tracklet Inpainting and Scoring for
Tracking. The code of ArTIST is publicly available1. 2.