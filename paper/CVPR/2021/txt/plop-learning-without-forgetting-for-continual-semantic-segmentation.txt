Abstract
Deep learning approaches are nowadays ubiquitously used to tackle computer vision tasks such as semantic seg-mentation, requiring large datasets and substantial com-putational power. Continual learning for semantic seg-mentation (CSS) is an emerging trend that consists in up-dating an old model by sequentially adding new classes.
However, continual learning methods are usually prone to catastrophic forgetting. This issue is further aggravated in CSS where, at each step, old classes from previous it-erations are collapsed into the background.
In this pa-per, we propose Local POD, a multi-scale pooling distil-lation scheme that preserves long- and short-range spa-tial relationships at feature level. Furthermore, we de-sign an entropy-based pseudo-labelling of the background w.r.t. classes predicted by the old model to deal with back-ground shift and avoid catastrophic forgetting of the old classes. Our approach, called PLOP, signiﬁcantly outper-forms state-of-the-art methods in existing CSS scenarios, as well as in newly proposed challenging benchmarks1. 1.

Introduction
Semantic segmentation is a fundamental problem of computer vision, that aims at assigning a label to each pixel of an image.
In recent years, the introduction of Convo-lutional Neural Networks (CNNs) has addressed semantic segmentation in a traditional framework, where all classes are known beforehand and learned at once [61, 73, 11].
This setup, however, is quite limited for practical applica-tions. In a more realistic scenario, the model should be able to continuously learn new classes without retraining from scratch. This setup, referred here as Continual Semantic
Segmentation (CSS), has emerged very recently for medi-cal applications [51, 52] before being proposed for general segmentation datasets [49, 7].
Deep learning approaches that deal with CSS face two main challenges. The ﬁrst one, inherited from continual 1Code is available at https://github.com/arthurdouillard/CVPR2021_PLOP
Figure 1: Our two-part strategy aims at learning a segmen-tation network in a continual learning framework, where old class pixels are collapsed into the background at cur-rent stage. We generate pseudo labels from old predictions (blue) to deal with the background shift, and retain short-and long-range spatial dependencies by Local POD distilla-tion (red) to prevent catastrophic forgetting. learning, is called catastrophic forgetting [55, 21, 62], and points to the fact that neural networks tend to completely and abruptly forget previously learned knowledge when learning new information [35]. Catastrophic forgetting presents a real challenge for continual learning applications based on deep learning methods, especially when storing previously seen data is not allowed for privacy reasons.
The second issue, CSS speciﬁc, is the semantic shift of the background class. In a traditional semantic segmenta-tion setup, the background contains pixels that don’t belong to any other class. However, in CSS, the background con-tains pixels that don’t belong to any of the current classes.
Thus, for a speciﬁc learning step, the background can con-tain both future classes, not yet seen by the model, as well as old classes. Thus, if nothing is done to distinguish pixels belonging to the real background class from old class pix-4040
els, this background shift phenomenon risks exacerbating the catastrophic forgetting even further [7].
In this paper, we propose a deep learning strategy to ad-dress these two challenges in CSS. Instead of reusing old images, our approach, called PLOP , standing for Pseudo-label and LOcal POD leverages the old model in two man-ners, as illustrated on Fig. 1. First, we propose a feature-based multi-scale distillation scheme to alleviate catas-trophic forgetting. Second, we employ a conﬁdence-based pseudo-labeling strategy to retrieve old class pixels within the background. For instance, if a current ground truth mask only distinguish pixels from class sofa and background, our approach allows to assign old classes to background pixels, e.g. classes person, dog or background (the semantic class).
We thoroughly validate PLOP on several datasets, show-casing signiﬁcant performance improvements compared to the state-of-the-art methods in existing CSS scenarios. Fur-thermore, we propose several novel scenarios to further quantify the performances of CSS methods when it comes to long term learning, class presentation order and domain shift. Last but not least, we show that PLOP largely outper-forms every CSS approach in these scenarios. To sum it up, our contributions are three-folds:
• We propose a multi-scale spatial distillation loss to better retain knowledge through the continual learning steps, by preserving long- and short-range spatial rela-tionships, avoiding catastrophic forgetting.
• We introduce a conﬁdence-based pseudo-labeling strategy to identify old classes for the current back-ground pixels and deal with background shift.
• We show that PLOP signiﬁcantly outperforms state-of-the-art approaches in existing scenarios and datasets for CSS, as well as in several newly proposed chal-lenging benchmarks. 2.