Abstract
How to represent an image? While the visual world is presented in a continuous manner, machines store and see the images in a discrete way with 2D arrays of pixels. In this paper, we seek to learn a continuous representation for images. Inspired by the recent progress in 3D reconstruc-tion with implicit neural representation, we propose Local
Implicit Image Function (LIIF), which takes an image co-ordinate and the 2D deep features around the coordinate as inputs, predicts the RGB value at a given coordinate as an output. Since the coordinates are continuous, LIIF can be presented in arbitrary resolution. To generate the contin-uous representation for images, we train an encoder with
LIIF representation via a self-supervised task with super-resolution. The learned continuous representation can be presented in arbitrary resolution even extrapolate to ⇥30 higher resolution, where the training tasks are not provided.
We further show that LIIF representation builds a bridge between discrete and continuous representation in 2D, it naturally supports the learning tasks with size-varied im-age ground-truths and signiﬁcantly outperforms the method with resizing the ground-truths. Our project page with code is at https://yinboc.github.io/liif/. 1.

Introduction
Our visual world is continuous. However, when a ma-chine tries to process a scene, it will usually need to ﬁrst store and represent the images as 2D arrays of pixels, where the trade-off between complexity and precision is controlled by resolution. While the pixel-based representation has been successfully applied in various computer vision tasks, they are also constrained by the resolution. For example, a dataset is often presented by images with different resolu-tions. If we want to train a convolutional neural network, we will usually need to resize the images to the same size, which may sacriﬁce ﬁdelity. Instead of representing an im-age with a ﬁxed resolution, we propose to study a contin-uous representation for images. By modeling an image as a function deﬁned in a continuous domain, we can restore and generate the image in arbitrary resolution if needed.
Figure 1: Local Implicit Image Function (LIIF) represents an image in continuous domain, which can be presented in arbitrary high resolution.
How do we represent an image as a continuous function?
Our work is inspired by the recent progress in implicit neu-ral representation [34, 27, 6, 38, 18, 41] for 3D shape re-construction. The key idea of implicit neural representation is to represent an object as a function that maps coordinates to the corresponding signal (e.g. signed distance to a 3D object surface, RGB value in an image), where the function is parameterized by a deep neural network. To share knowl-edge across instances instead of ﬁtting individual functions for each object, encoder-based methods [27, 6, 41] are pro-posed to predict latent codes for different objects, then a de-coding function is shared by all the objects while it takes the latent code as an additional input to the coordinates.
Despite its success in 3D tasks [38, 39], previous encoder-based methods of implicit neural representation only suc-ceeded in representing simple images such as digits [6], but failed to represent natural images with high ﬁdelity [41].
In this paper, we propose the Local Implicit Image Func-tion (LIIF) for representing natural and complex images in a continuous manner. In LIIF, an image is represented as a set of latent codes distributed in spatial dimensions. Given a coordinate, the decoding function takes the coordinate in-formation and queries the local latent codes around the co-ordinate as inputs, then predicts the RGB value at the given 8628
coordinate as an output. Since the coordinates are continu-ous, LIIF can be presented in arbitrary resolution.
To generate such continuous representation for pixel-based images, since we hope the generated continuous rep-resentation can generalize to higher precision than the in-put image, we train an encoder with the LIIF representa-tion via a self-supervised task with super-resolution, where the input and ground-truth are provided in continuously changing up-sampling scales.
In this task, take a pixel-based image as an input, the encoded LIIF representation is trained to predict a higher resolution counterpart of the input. While most of the previous works on image super-resolution [10, 23, 24, 22] focus on learning an up-sampling function for speciﬁc scales in a convolution-deconvolution framework, LIIF representation is continuous, and we show it can be presented in arbitrary high resolution, that can even extrapolate to ⇥30 higher resolution where the train-ing tasks are not provided.
We further demonstrate that LIIF builds a bridge be-tween discrete and continuous representation in 2D. In the learning tasks with size-varied image ground-truths, LIIF can naturally exploit the information provided in different resolutions. Previous methods with ﬁxed-size output usu-ally need to resize all the ground-truths to the same size for training, which may sacriﬁce ﬁdelity. Since the LIIF repre-sentation can be presented in arbitrary resolution, it can be trained in an end-to-end manner without resizing ground-truths, which achieves signiﬁcantly better results than the method with resizing the ground-truths.
Our contributions include: (i) A novel method for repre-senting natural and complex images continuously; (ii) LIIF representation allows extrapolation to even ⇥30 higher res-olution which is not presented during training time; (iii) We show LIIF representation is effective for the learning tasks with size-varied image ground-truths. 2.