Abstract
Learning pose invariant representation is a fundamental problem in shape analysis. Most existing deep learning al-gorithms for 3D shape analysis are not robust to rotations and are often trained on synthetic datasets consisting of pre-aligned shapes, yielding poor generalization to unseen poses. This observation motivates a growing interest in ro-tation invariant and equivariant methods. The ﬁeld of rota-tion equivariant deep learning is developing in recent years thanks to a well established theory of Lie group representa-tions and convolutions. A fundamental problem in equivari-ant deep learning is to design activation functions which are both informative and preserve equivariance. The recently introduced Tensor Field Network (TFN) framework pro-vides a rotation equivariant network design for point cloud analysis. TFN features undergo a rotation in feature space given a rotation of the input pointcloud. TFN and similar designs consider nonlinearities which operate only over ro-tation invariant features such as the norm of equivariant features to preserve equivariance, making them unable to capture the directional information. In a recent work en-titled ”Gauge Equivariant Mesh CNNs: Anisotropic Con-volutions on Geometric Graphs” Hann et al. interpret 2D rotation equivariant features as Fourier coefﬁcients of func-tions on the circle. In this work we transpose the idea of
Hann et al. to 3D by interpreting TFN features as spher-ical harmonics coefﬁcients of functions on the sphere. We introduce a new equivariant nonlinearity and pooling for
TFN. We show improvments over the original TFN design and other equivariant nonlinearities in classiﬁcation and segmentation tasks. Furthermore our method is competi-tive with state of the art rotation invariant methods in some instances. 1.

Introduction
In recent years many successful deep learning architec-tures for 3D geometric deep learning and point cloud anal-ysis in particular have been developed, we refer to [14] for a comprehensive survey. Yet, most methods developed for point cloud analysis are not robust to rotations. Further-more point cloud dataset like ModelNet [33] or ShapeNet
[6] used for training and evaluating these methods often consist of synthetic pre-aligned shapes.
In consequence, well established point cloud methods like [25, 27, 4, 31, 21] fail to generalise to unseen poses. An important perfor-mance gap between the aligned and unaligned or rota-tion augmented settings has been reported in in multiple publications [11, 24, 7, 37]. Recently numerous works
[12, 22, 24, 7, 37, 36, 20, 39, 28] have addressed the issue of designing rotation invariant deep learning architectures for 3D data analysis with a variety of approaches. A particu-larly interesting property for 3D deep learning algorithms closely related to rotation invariance is rotation equivari-ance. At a high level a rotation equivariant neural network produces features that undergo a rotation in feature space given a rotation of the input. The key point is that this trans-form only depends on the rotation applied to the input. This is a precious property for learning, guaranteeing immediate generalization to unseen poses. Many rotation equivariant designs [30, 17, 11, 32, 2] have been proposed, thanks to a well established theory of SO(3) representations. A fun-damental challenge in the design of equivariant networks is the design of equivariant non-linearities. To preserve equiv-ariance such non-linearities must commute with the rota-tions of equivariant features, this constraint limits the pos-sible designs. The aforementioned methods either rely on non-linearities applied to rotation invariant quantities like the norm of equivariant features which cannot capture di-rectional information or, consider polynomial equivariant features which can be expensive to compute and compli-cates training. In the recent work [9] Hann et al. introduce a non linearity for local intrinsic rotation equivariant fea-tures over surfaces by interpreting the features as Fourier coefﬁcients of functions over the circle, composing these functions with non linear activations and getting new equiv-ariant features by computing the Fourier coefﬁcients of the composed functions. In this work we explore a similar ap-113174
proach in the context of 3D rotation equivariant features from Tensor Field Networks [30] over point-clouds. We propose a simple yet effective design of rotation equivari-ant non-linearities for Tensor Field Networks. TFN relies on convolutional ﬁlters based on spherical harmonics and the resulting features share the same equivariant properties as the spherical harmonics basis. We interpret such fea-ture vectors as the set of coefﬁcients of a function on the unit sphere. Moving to a sphere function representation by applying inverse spherical harmonics transform we can ap-ply non trivial activation functions or MLP’s in a pointwise fashion over the sphere. We then return back to the equivari-ant feature representation by computing the spherical har-monics transform of the resulting function. This operation has a non trivial effect on both the norm and direction of equivariant features, allowing to capture directional infor-mation. We present the general setting of point cloud con-volutions and TFN and brieﬂy review the underlying the-ory in section (2). In section (3) we describe our method and speciﬁcities of our design compared to the general ap-proach described in section (2). We present our results in section (4) where we compare our method to state of the art rotation invariant methods for shape classiﬁcation and seg-mentation and show improvements over existing equivariant non-linearities. We believe our contibution is of general rel-evance to other equivaraint networks like [32] sharing sim-ilar structures to TFN. 2.