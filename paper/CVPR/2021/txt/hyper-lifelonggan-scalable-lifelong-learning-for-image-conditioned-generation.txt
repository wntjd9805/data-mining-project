Abstract
Deep neural networks are susceptible to catastrophic forgetting: when encountering a new task, they can only remember the new task and fail to preserve its ability to ac-complish previously learned tasks. In this paper, we study the problem of lifelong learning for generative models and propose a novel and generic continual learning framework
Hyper-LifelongGAN which is more scalable compared with state-of-the-art approaches. Given a sequence of tasks, the conventional convolutional ﬁlters are factorized into the dy-namic base ﬁlters which are generated using task speciﬁc
ﬁlter generators, and deterministic weight matrix which lin-early combines the base ﬁlters and is shared across different tasks. Moreover, the shared weight matrix is multiplied by task speciﬁc coefﬁcients to introduce more ﬂexibility in com-bining task speciﬁc base ﬁlters differently for different tasks.
Attributed to the novel architecture, the proposed method can preserve or even improve the generation quality at a low cost of parameters. We validate Hyper-LifelongGAN on diverse image-conditioned generation tasks, extensive ab-lation studies and comparisons with state-of-the-art models are carried out to show that the proposed approach can ad-dress catastrophic forgetting effectively. 1.

Introduction
The continuous learning ability is one of the hallmarks of human intelligence. Humans are lifelong learners, we ac-quire and accumulate knowledge throughout our lives. The accumulation of knowledge in turn makes us more and more knowledgeable, and better and better at learning when en-countering new problems. In contrast to human learning, modern deep neural networks are susceptible to catastrophic 2246
forgetting [26]: when adapted to perform new tasks, they often fail to generalize and cannot maintain their ability to accomplish previously learned tasks (see Figure 1 (a)). Re-cent approaches [35, 41, 40] have been proposed for life-long learning for generative models, and how generative models can continually learn a sequence of tasks was ex-plored in these methods. Though progress has been made towards lifelong learning for generative models, it remains a challenging area.
The pioneer work addressing catastrophic forgetting in the generative setting is memory replay [35], namely gener-ating data of previous tasks using a trained model and treat-ing these generated data as part of the training examples in the new tasks. Although alleviating catastrophic forget-ting by taking advantage of the generative setting, memory replay is limited to label-conditioned generation scenarios: when training data for only the current task is accessible, no conditional image can be accessed and as a result no images could be generated for replay. More generic continual learn-ing frameworks [41, 40] have been proposed enabling life-long learning of image-conditioned generation tasks. Life-longGAN [41] continually adapts a single trained model to later tasks, thus the whole model is shared across all tasks.
However, due to the intrinsic differences among tasks, it is hard to adapt all parameters of a trained model to a new task. As a result, LifelongGAN is not able to preserve the generation quality of previous tasks while learning the new task well. This performance degradation makes it not scal-able in general. PiggybackGAN [40] addresses the perfor-mance degradation problem by sacriﬁcing memory storage.
Though it is more parameter efﬁcient compared with train-ing separate models for each task, the unconstrained ﬁlters bring millions of additional parameters for each new task.
This storage requirement limits its scalability. Therefore, a more scalable continual learning framework that can pre-serve the generation quality with no or little sacriﬁce of stor-age is valuable.
In this paper, we introduce a generic continual learning framework Hyper-LifelongGAN (see Figure 1 (b)) that is more scalable compared with state-of-the-art approaches.
Hypernetwork [13] and knowledge distillation [15] are em-ployed to address catastrophic forgetting for generative tasks. First, all the conventional convolutional and decon-volutional ﬁlters in the generator are factorized into a set of base ﬁlters and a weight matrix that linearly combines the base ﬁlters. And instead of learning deterministic base ﬁl-ters, we learn to generate dynamic base ﬁlters from random noises using hypernetworks. Given a sequence of tasks, dif-ferent hypernetworks are trained to generate base ﬁlters for different tasks (referred to as task speciﬁc ﬁlter generators); while the weight matrix is deterministic, and shared across all the tasks. Moreover, the shared weight matrix is multi-plied by task speciﬁc coefﬁcients to introduce more ﬂexibil-ity in combining task speciﬁc ﬁlters differently for different tasks. The memory requirement is low since the base ﬁlters in each layer can be generated with just few thousand pa-rameters, and the weight matrix is shared across all tasks.
To keep the memory of previous tasks, knowledge is ex-tracted from a previously trained model and distilled to the model trained for the new task, encouraging the new model to generate the same output as the previous model.
To summarize, our contributions are as follows. First, we propose a novel and generic continual learning frame-work Hyper-LifelongGAN that is more scalable. Second, we propose to factorize conventional convolutional ﬁlters into dynamic task speciﬁc base ﬁlters and deterministic task in-dependent weight matrix. This design enables the proposed model to preserve or even improve the generation quality of a sequence of tasks at a low cost of parameters. Third, ex-tensive ablation studies and comparisons with state-of-the-art models are carried out across diverse data domains, qual-itative and quantitative results are provided to illustrate the capability of our framework to learn new generation tasks without the catastrophic forgetting of previous tasks. 2.