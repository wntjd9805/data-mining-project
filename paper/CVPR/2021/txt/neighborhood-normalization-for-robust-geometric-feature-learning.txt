Abstract
Extracting geometric features from 3D models is a common ﬁrst step in applications such as 3D registration, tracking, and scene ﬂow estimation. Many hand-crafted and learning-based methods aim to produce consistent and distinguishable geometric features for 3D models with partial overlap. These methods work well in cases where the point density and scale of the overlapping 3D objects are similar, but struggle in applications where 3D data are obtained independently with unknown global scale and scene overlap. Unfortunately, instances of this resolution mismatch are common in practice, e.g., when aligning
In this work, we introduce data from multiple sensors. a new normalization technique, Batch-Neighborhood
Normalization, aiming to improve robustness to mean-std variation of local feature distributions that presumably can happen in samples with varying point density. We empirically demonstrate that the presented normalization method’s performance compares favorably to comparison methods in indoor and outdoor environments, and on a clinical dataset, on common point registration benchmarks in both standard and, particularly, resolution-mismatch set-tings. The source code and clinical dataset are available at https://github.com/lppllppl920/NeighborhoodNormalization-Pytorch. 1.

Introduction
Estimating point correspondences between 3D models is a key step in many computer vision tasks, e.g. 3D registra-tion, tracking, and scene ﬂow estimation pipelines. 3D de-scriptors facilitate this process by extracting discriminative and consistent geometric features for estimating correspon-dences, including hand-crafted features [41, 22, 42, 52], and
*These authors contributed equally to this work learning-based descriptors [54, 25, 13, 12, 19]. Learning-based descriptors have gained prominence in recent years, achieving superior performance on common point cloud registration benchmarks [54, 18], but in general, these meth-ods assume that the point density or resolution of different point clouds is the same. This is a reasonable assumption when using voxel grid downsampling to pre-process data since the resolution depends on a ﬁxed voxel size.
However, resolution mismatch can often occur when data are not measured in physical 3D Euclidean space. Re-constructions from monocular videos, for example, are in-herently scale-ambiguous. Without additional prior knowl-edge such as scene overlap ratio between samples, a consis-tent voxel size for grid downsampling is difﬁcult to obtain, inevitably leading to variable point density across samples.
Similarly, stereo camera setups are vulnerable to calibra-tion errors that affect the accuracy of the depth estimation, so that the choice of the camera affects point cloud reso-lution. Even when physical distances can be estimated or measured from 3D sensors without errors, resolution mis-match can still arise due to hardware discretization, which results in the same scene producing point clouds with dif-ferent resolutions when captured from different distances.
High-resolution samples can be downsampled in this case, but this leads to computation inefﬁciency and information loss. Consequently, it is desirable to develop 3D geomet-ric feature learning techniques that are robust to resolution mismatch.
We hypothesize that the lack of robustness to resolution mismatch is due in part to the global nature of common normalization methods in convolutional neural networks (CNNs), which are the basis of learning-based descriptors.
When two point clouds exhibit resolution mismatch, cor-responding regions contain different numbers and distribu-tions of points, making a common feature representation more difﬁcult to learn. This is especially challenging when global scales of samples are unknown, which, without ad-13049
ditional prior knowledge, is inevitable in the case of recon-struction from monocular videos and calibration errors de-scribed above. By incorporating local point cloud statis-tics into internal normalization layers, we aim to improve the expressivity of the network across resolutions. We draw further inspiration from the contrast normalization approach present in the human vision system [34], which lends cre-dence to increasing local normalization.
Contributions:
Our main contributions are as fol-lows: 1) We present a novel normalization technique,
Batch-Neighborhood Normalization (B-NHN), that aims to increase the network’s robustness to task-irrelevant mean-std variation of local feature distribution, where resolution mismatch that we try to deal with is a speciﬁc data varia-tion potentially causing that. This technique is general and can be applied to any neural network architecture having the concept of convolution over local neighbors. Speciﬁcally, on 3DMatch [54] and KITTI odometry [18] datasets for ge-ometric descriptor benchmarking, we show that our method performs favorably against the state-of-the-art on the stan-dard benchmarks, and outperforms previous methods by a large margin on the created resolution-mismatch ones. 2)
Additionally, we contribute a dataset of nasal cavities built from CT scans to benchmark the performance of geometric feature extraction methods on a medical video-CT registra-tion task, where resolution mismatch is common. 2.