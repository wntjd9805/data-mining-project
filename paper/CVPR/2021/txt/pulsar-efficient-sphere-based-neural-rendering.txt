Abstract 1.

Introduction
We propose Pulsar, an efﬁcient sphere-based differen-tiable rendering module that is orders of magnitude faster than competing techniques, modular, and easy-to-use due to its tight integration with PyTorch. Differentiable rendering is the foundation for modern neural rendering approaches, since it enables end-to-end training of 3D scene represen-tations from image observations. However, gradient-based optimization of neural mesh, voxel, or function representa-tions suffers from multiple challenges, i.e., topological in-consistencies, high memory footprints, or slow rendering speeds. To alleviate these problems, Pulsar employs: 1) a sphere-based scene representation, 2) a modular, efﬁcient differentiable projection operation, and 3) (optional) neu-ral shading. Pulsar executes orders of magnitude faster than existing techniques and allows real-time rendering and optimization of representations with millions of spheres.
Using spheres for the scene representation, unprecedented speed is obtained while avoiding topology problems. Pulsar is fully differentiable and thus enables a plethora of applica-tions, ranging from 3D reconstruction to neural rendering.
A differentiable rendering pipeline is the foundation for all modern neural rendering approaches that learn 3D scene representations based on image observations. Recently, neural rendering has empowered a large variety of appli-cations, such as novel-view synthesis [22], facial reenact-ment [36], and 3D reconstruction [17]. Modern neural ren-dering can be broken up into three components: 1) a 3D neural scene representation, 2) a projection from 3D data to a consistent 2D representation (the projection step) and 3) processing the projected data using a statistical model, usu-ally a neural network, to produce the ﬁnal image (the neural shading step). This strategy combines the strengths of clas-sical rendering and neural networks. Through the projec-tion step, a consistent geometric representation of the scene is generated, while the neural shading step can produce re-alistic images through the use of the latest generative neu-ral networks that can approximate complex natural image formation phenomena without having to explicitly model them.
Ideally, such a neural rendering approach can be jointly trained in an end-to-end fashion: a 3D representation of the 1440
scene is learned and sent through the projection and shading step. The resulting image can be compared to ground truth observations to inform an optimization process, not only to improve the generative model in the shading step, but also to jointly learn the representation of the scene and potentially unknown parameters of the projection step. This process requires the efﬁcient computation of gradients through the complete pipeline in a scalable manner, such that high per-formance can be obtained even for the geometry of complex and detailed scenes rendered at real-world resolutions.
In this paper, we present Pulsar, an efﬁcent, sphere-based, differentiable rendering module that is orders of magnitude faster than competing techniques, modular, and easy-to-use due to its tight integration with PyTorch. Pulsar aims to fulﬁll all mentioned requirements through a variety of measures, from the design of the scene representation down to low-level data-parallel optimizations, which lead to unprecedented speed for the forward and backward pass.
First, we choose an entirely sphere-based representation of 3D data. Each sphere is parameterized by its position in space and its radius.
In addition, each sphere has an as-signed opacity and can have an arbitrary vector as payload, such as a color or a general latent feature vector. Image for-mation is based on a volumetric compositing schema that aggregates the payload in back-to-front order to form the
ﬁnal image or a screen space feature map. This makes it easy to handle point cloud data from 3D sensors directly, allows for the optimization of the scene representation with-out problems of changing topology (as they would exist for meshes) and is more efﬁcient for rendering than recent approaches based on volumetric grids or fully-connected networks, since our representation, sparse by design, culls empty space. In addition, our sphere-based representation eliminates the need for acceleration structures, such as a k-d tree or octree, thus naturally can support dynamic scenes.
Additionally, it leads to a well-deﬁned, simple render and blending function that can be differentiated without approx-imation. We deliberately keep the illumination computa-tions separate from the geometry projection step as it can be easily handled in a separate step. Lastly, we integrate Pulsar with the PyTorch [26] optimization framework to make use of auto-differentiation and ease the integration with deep learning models.
The strategy described above allows Pulsar to render and differentiate through the image formation for 3D scenes with millions of spheres on consumer graphics hardware.
Up to one million spheres can be rendered and updated at real-time speed for an image resolution of 1024 1024 pix-els (the time spent executing C++ code is less than 22 ms for rendering and less than 6 ms for gradient calculation).
Pulsar supports a generalized pinhole and orthogonal cam-era model and computes gradients for camera parameters as well as to update the scene representation. We demon-× strate that a large variety of applications can be successfully handled using Pulsar, such as 3D reconstruction, neural ren-dering, and viewpoint synthesis. Pulsar is open source and thus will enable researchers in the future to solve a large va-riety of research problems on their own. In summary, our main technical contributions are:
• A fast, general purpose, sphere-based, differentiable rendering module that is tightly integrated in PyTorch and enables end-to-end training of deep models with geometry and projection components.
• Pulsar executes orders of magnitude faster than exist-ing techniques and allows real-time rendering and op-timization of representations with millions of spheres.
• We demonstrate that a large variety of applications can be handled with Pulsar, such as 3D reconstruction, modeling realistic human heads, and novel view syn-thesis for scenes. 2.