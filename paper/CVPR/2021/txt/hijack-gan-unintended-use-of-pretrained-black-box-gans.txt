Abstract
While Generative Adversarial Networks (GANs) show increasing performance and the level of realism is becom-ing indistinguishable from natural images, this also comes with high demands on data and computation. We show that state-of-the-art GAN models – such as they are being pub-licly released by researchers and industry – can be used for a range of applications beyond unconditional image gen-eration. We achieve this by an iterative scheme that also allows gaining control over the image generation process despite the highly non-linear latent spaces of the latest GAN models. We demonstrate that this opens up the possibility to re-use state-of-the-art, difﬁcult to train, pre-trained GANs with a high level of control even if only black-box access is granted. Our work also raises concerns and awareness that the use cases of a published GAN model may well reach be-yond the creators’ intention, which needs to be taken into account before a full public release. Code is available at https://github.com/a514514772/hijackgan. 1.

Introduction
Generative Adversarial Nets (GANs) [14] have achieved remarkable success in many applications, such as image synthesis [20, 19, 21] and image translation [8, 10, 9, 33].
By learning a mapping between noise and images, the mod-els are skilled to produce photo-realistic images from ran-dom noise. However, as the architectures become sophis-ticated [20, 19, 7], training modern GANs often requires massive data and computation resources. For example, it takes one high-quality face dataset, 8 V100 GPUs, and one week to train a single StyleGAN [1] model.
In light of this trend, it is crucial to reuse existing pre-trained GANs, such as those being released by researchers or industry, for building green AI systems, in which the critical factor is to achieve other tasks beyond the original intention of GANs.
To reuse GANs for other tasks, prior works have shown that semantic manipulation can be realized by vector arith-metic [23] or moving along constant attribute vectors [13, 28, 25, 12] in latent spaces.
For instance, Interface-GAN [25] demonstrates that facial attribute manipulation can be achieved by moving noise close to or away from the linear decision boundary of the desired attribute. Although these methods reveal the potential that pre-trained GANs could go beyond unconditional generation, they highly rely on the assumption of linear manifolds, thereby ignoring the nature of highly non-linear latent spaces (e.g., Z-space of StyleGAN [25, 34]). This strong assumption could be harmful, especially for rare attributes, and lead to ineffec-tive manipulation.
Inspired by this observation, we propose a novel frame-work, which gains high-level control over unconditional im-age generation by iteratively traversing the non-linear latent spaces. Speciﬁcally, we ﬁrst train a proxy model that by-passes the gradients from one pretrained GAN and other
ﬁxed task models, and then dynamically decides the moving direction in each step, thus producing smoother and more effective attribute transition. Next, we propose an orthogo-nal constraint to solely edit the attribute of interest while re-taining others in images. Despite only black-box access, we show that our method can achieve various unintended tasks, including manipulation over facial attributes, head poses, and landmarks.
As a result of our experiments, we ﬁnd that our frame-work with pre-trained GANs not only facilitates other vi-sion tasks but raises concerns regarding further usage. Even without access to model parameters, the models can still be applied to unintended tasks potentially for malicious pur-poses. The owners of GANs should be aware and cau-tious about the potential risks before releasing their models.
Overall, our contributions are summarized below.
• We propose a framework which leverages off-the-shelf
GANs to approach unintended vision tasks in a black-box setting.
• We propose a constraint that helps our framework solely edit the attribute of interest while retaining oth-ers in images. 7872
• Extensive results show that our method can produce smoother and more effective manipulation while pre-serving non-target attributes better, as compared to prior work. We also shed light on the potential risks of unintended usage by gaining control over facial at-tributes, head poses, and landmarks. 2.