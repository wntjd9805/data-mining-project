Abstract
Monocular 3D prediction is one of the fundamental problems in 3D vision. Recent deep learning-based ap-proaches have brought us exciting progress on this problem.
However, existing approaches have predominantly focused on end-to-end depth and normal predictions, which do not fully utilize the underlying 3D environment’s geometric structures.
This paper introduces StruMonoNet, which detects and enforces a planar structure to enhance pixel-wise predictions. StruMonoNet innovates in leveraging a hybrid representation that combines visual feature and a surfel representation for plane prediction. This formulation allows us to combine the power of visual feature learning and the ﬂexibility of geometric representations in incorpo-rating geometric relations. As a result, StruMonoNet can detect relations between planes such as adjacent planes, perpendicular planes, and parallel planes, all of which are beneﬁcial for dense 3D prediction. Experimental results show that StruMonoNet considerably outperforms state-of-the-art approaches on NYUv2 and ScanNet. 1.

Introduction
Monocular 3D prediction is a long-standing problem in 3D vision. Recent approaches [9, 8, 21, 35, 20, 12, 22], which apply end-to-end feature learning, have shown great promise of applying deep learning to this problem. 3D prediction involves many correlated tasks. An interesting problem is how to explore the interconnections among these tasks that can beneﬁt each other. This paper studies the interconnections between predictions of local geometric elements such as depth and normal and predictions of middle-level planar structures rich in 3D scenes. Our goal is to answer critical questions in developing suitable geometric representations for plane detection and extracting rich relations among planes to enhance the predictions of depth, normal, and plane equations.
Speciﬁcally, we introduce StruMonoNet, which takes a single RGB image as input and outputs joint predictions of depth, normal, and a planar structure (See Figure 1). Instead of training a network to regress a ﬁxed number of plane
Figure 1. StruMonoNet takes a single RGB image of a 3D scene as input (Left) and outputs a joint prediction of the underlying planar structure and relations (Middle) and surfels (Right). equations (c.f. [25]), StruMonoNet utilizes an intermediate representation that combines surfels (positions + normals) and dense visual features. This formulation enables a simple clustering module for plane detection, where visual features guide the clustering procedure through a trainable sub-module. It also fully incorporates depth/normal labels for plane detection through predicted surfels, which are unavailable in black box plane detection.
Unlike merely detecting individual planes, StruMonoNet detects and enforces geometric relations between planes, e.g., adjacent planes, perpendicular planes, and parallel planes. Enforcing such structures enhances the prediction accuracy of individual planes signiﬁcantly. StruMonoNet introduces a novel plane synchronization module that au-tomatically detects such relations and enforces them to enhance the predicted planes’ accuracy.
StruMonoNet takes inspiration from the observation that depth and normal prediction errors of a deep-learning ap-proach typically have large variance and small bias. There-fore, one can rectify the prediction error by applying suit-able averaging operations. Although it is impossible to rec-tify the predictions across different images, StruMonoNet achieves the partial goal of averaging them among detected planar regions of each image. The improved predictions then propagate to non-planar regions. Note that the adja-cency, perpendicular, and parallel planes are critical from this aspect. They allow us to incorporate more pixels for rectiﬁcation.
Our approach outperforms the state-of-the-art ap-proaches on two benchmark datasets ScanNet [6] and
NYUv2 [26] for monocular depth prediction. We also achieve considerable improvements on normal prediction 7413
(Table 3) on NYUv2 and plane detection (Table 5) on
ScanNet over state-of-the-art methods.
In summary, our contributions include
• A hybrid representation that combines positions, nor-mals, and visual features for joint predictions of planar structures and pixel-wise depth and normal.
• A synchronization module that detects planes and their geometric relations such as adjacent planes, perpendic-ular planes, and parallel planes.
• State-of-the-art results on depth prediction on ScanNet and NYUv2, state-of-the-art results on normal predic-tion on NYUv2, and state-of-the-art results on planar detection on ScanNet. 2.