Abstract 1.

Introduction
Existing face relighting methods often struggle with two problems: maintaining the local facial details of the sub-ject and accurately removing and synthesizing shadows in the relit image, especially hard shadows. We propose a novel deep face relighting method that addresses both prob-lems. Our method learns to predict the ratio (quotient) image between a source image and the target image with the desired lighting, allowing us to relight the image while maintaining the local facial details. During training, our model also learns to accurately modify shadows by using estimated shadow masks to emphasize on the high-contrast shadow borders. Furthermore, we introduce a method to use the shadow mask to estimate the ambient light inten-sity in an image, and are thus able to leverage multiple datasets during training with different global lighting in-tensities. With quantitative and qualitative evaluations on the Multi-PIE and FFHQ datasets, we demonstrate that our proposed method faithfully maintains the local facial de-tails of the subject and can accurately handle hard shad-ows while achieving state-of-the-art face relighting perfor-mance.
Face relighting is the problem of turning a source image of a human face into a new image of the same face under a desired illumination different from the original lighting.
It has long been studied in computer vision and computer graphics and has a wide range of applications in face-related problems such as face recognition [10,13,23] and entertain-ment [22]. With the everlasting interest in consumer pho-tography and photo editing, the ability to produce realistic relit face images will remain an important problem.
Many existing face relighting models utilize intrinsic de-composition of the image into face geometry, lighting, and reﬂectance [3,5,6,13–16,18,20,24,25,29,32,34,36,39]. The source image is then relit by rendering with a novel illumi-nation. Other relighting methods employ image-to-image translation [20, 31, 41] or style transfer [17, 19, 27, 28].
For most face relighting applications, one important re-quirement is the preservation of the subject’s local facial details during relighting. Intrinsic decomposition methods often compromise high frequency details and can leave ar-tifacts in the relit face images due to errors in the geometry or reﬂectance estimation. Another important feature of a 14719
desirable face relighting model is proper shadow handling.
For entertainment in particular, adding and removing shad-ows accurately is crucial in producing photorealistic results.
Most existing relighting methods, however, do not model hard self-cast shadows caused by directional lights.
Our proposed method uses an hourglass network to for-mulate the relighting problem as a ratio (quotient) im-age [26] estimation problem. The ratio image estimated by our model can be multiplied with the source image to generate the target image under the new illumination. This approach allows our model to maintain the local facial de-tails of the subject while adjusting the intensity of each pixel during relighting. We employ an estimation loss to enable ratio image learning, as well as a structural dissimilarity (DSSIM) loss based on the SSIM metric [37] to enhance the perceptual quality of relit faces. In addition, we incor-porate PatchGAN [8] to further improve the plausibility.
During training, we generate and leverage shadow masks, which indicate estimated shadow regions for each image using the lighting direction and 3D shape from 3D
Morphable Model (3DMM) [4] ﬁtting. The shadow masks enable us to handle shadows through weighted ratio image estimation losses. We place higher emphasis on the pixels close to shadow borders in the source and target relight-ing images, with larger weights placed on borders of high-contrast cast shadows over soft ones. This simple strategy allows learning how to accurately add and remove both hard and soft shadows under various relighting scenarios.
Our training process can leverage images with both dif-fuse and directional lighting across multiple datasets, which improves our ability to handle diverse lighting and general-ize to unseen data over methods that only train on a sin-gle dataset [20, 31, 41]. To enable this, we use our shadow masks to estimate the ambient lighting intensity in each image, and modify our lighting to account for differences in ambient lighting across images and datasets. Thus, our model accommodates for differences in the environment be-tween images in controlled and in-the-wild settings.
Our proposed method has three main contributions:
⋄
We propose a novel face relighting method that mod-els both high-contrast cast shadows and soft shadows, while preserving the local facial details.
⋄
Our technical approach involves single image based ra-tio image estimation to better preserve local details, shadow border reweighting to handle hard shadows, and ambient light compensation to account for dataset differences.
Our approach achieves the state-of-the-art relighting results on two benchmarks quantitatively and qualitatively.
⋄ 2.