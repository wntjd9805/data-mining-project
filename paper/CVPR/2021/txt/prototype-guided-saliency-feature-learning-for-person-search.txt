Abstract
Existing person search methods integrate person detec-tion and re-identiﬁcation (re-ID) module into a uniﬁed sys-tem. Though promising results have been achieved, the misalignment problem, which commonly occurs in person search, limits the discriminative feature representation for re-ID. To overcome this limitation, we introduce a novel framework to learn the discriminative representation by uti-lizing prototype in OIM loss. Unlike conventional methods using prototype as a representation of person identity, we utilize it as guidance to allow the attention network to con-sistently highlight multiple instances across different poses.
Moreover, we propose a new prototype update scheme with adaptive momentum to increase the discriminative ability across different instances. Extensive ablation experiments demonstrate that our method can signiﬁcantly enhance the feature discriminative power, outperforming the state-of-the-art results on two person search benchmarks including
CUHK-SYSU and PRW. 1.

Introduction
Person search aims to localize a target person in a gallery of pedestrian images. While inputs of person re-identiﬁcation (re-ID) task are auto-detected person bound-ing boxes [15], those of person search task are in-the-wild image containing large amounts of backgrounds. The sim-plest way to solve the person search problem is to crop all the pedestrians adopting off-the-shelf detector [21], and pass them into re-ID module as [1]. This, however, divide the two tasks which affect each other into separate tasks and are inefﬁcient in real-world applications. To address this, recent methods [30, 18, 2, 40] formulate detection and re-ID into a uniﬁed framework by sharing the backbone net-work, and train both tasks in an end-to-end fashion.
The main goal of person search, as well as re-ID is to generate a discriminative feature from an image for match-ing the same class (identity) to the target person. Exist-ing methods focus on feature representation learning [29]
∗Corresponding author
Figure 1. Examples of misalignment problem in person search task caused by (a) the presence of other instances, (b) mis-detection and (c) background objects. to classify different instances in a gallery of pedestrian im-ages. However, as shown in Fig. 1, misalignment issue arises from occlusion with other instances or background objects, and false positives from detector that hinder robust feature representation. To overcome this, recent methods
[16, 39, 37, 24, 25] exploit attention mechanism to obtain a saliency map emphasizing discriminative parts of human (e.g. clothes or handbags). However, person detection and re-ID are inherently contradictory [32], since the former aims to classify everyone in an image into person class, while the latter aims to distinguish individual person for identiﬁcation. It limits the applicability of attention mech-anism in conventional re-ID methods to the person search framework.
On the other hand, loss functions for training the fea-ture representation such as cross-entropy [35] or triplet loss
[5] are widely used in re-ID community, in order to make the same identities be closer in embedding space, while dif-4865
ferent identities to be far apart. However, these two losses are not scalable to person search because the uniﬁed frame-work restrains the batch size for training to be small. To realize this, Xiao et al. [30] propose a novel online in-stance matching (OIM) loss for person search. OIM loss aggregates diverse patterns of identity into a feature vec-tor which is representative of a certain identity, i.e., proto-type [23, 34], and then optimizes all features to be closer to their corresponding prototype by minimizing intra-class variation [27]. However, the prototype is updated in an on-line manner regardless of the input, whereas the input iden-tity might be affected by noise components which disturb the optimization of prototype.
In this paper, we conjecture that the prototype in OIM loss can be used as guidance to solve misalignment prob-lems in conventional methods.
Inspired by the fact that prototype optimally describes each class, we aim to learn the attention mechanism so that attention could focus on the region that is similar to its prototype. Speciﬁcally, we compute the pixel level afﬁnity between the prototype and feature of the detected instance, and exploit it as guid-ance for attention learning. This map emphasizes region which highly responses to the prototype, and supervises the saliency to attention module to highlight consistent region against pose or viewpoint variation during inference. In ad-dition, we introduce a new prototype update scheme for dis-criminative feature learning from OIM loss. Rather than utilizing ﬁxed momentum for prototype update, we deﬁne the momentum as the ratio of the following two cosine sim-ilarities between 1) target and positive prototype pair and 2) target and hardest negative prototype pair. When the tar-get feature is closer to the hardest negative prototype, low momentum is assigned to the target feature to prevent the prototype from moving closer to the hardest negative.
The main contributions of this paper can be summarized as follows:
• We present a prototype-guided attention module, to en-able learning of attention mechanism in person search by exploiting prototype as guidance.
• We introduce a new prototype update scheme to in-crease the discriminative ability of prototype across different instances.
• We demonstrate the advantage of our proposed method over state-of-the-art methods through extensive exper-imental evaluations. 2.