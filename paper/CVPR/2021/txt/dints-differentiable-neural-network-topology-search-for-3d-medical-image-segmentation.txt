Abstract
Recently, neural architecture search (NAS) has been ap-plied to automatically search high-performance networks for medical image segmentation. The NAS search space usually contains a network topology level (controlling con-nections among cells with different spatial scales) and a cell level (operations within each cell). Existing meth-ods either require long searching time for large-scale 3D image datasets, or are limited to pre-deﬁned topologies (such as U-shaped or single-path) .
In this work, we fo-cus on three important aspects of NAS in 3D medical image segmentation: ﬂexible multi-path network topology, high search efﬁciency, and budgeted GPU memory usage. A novel differentiable search framework is proposed to sup-port fast gradient-based search within a highly ﬂexible network topology search space. The discretization of the searched optimal continuous model in differentiable scheme may produce a sub-optimal ﬁnal discrete model (discretiza-tion gap). Therefore, we propose a topology loss to alleviate this problem. In addition, the GPU memory usage for the searched 3D model is limited with budget constraints dur-ing search. Our Differentiable Network Topology Search scheme (DiNTS) is evaluated on the Medical Segmentation
Decathlon (MSD) challenge, which contains ten challeng-ing segmentation tasks. Our method achieves the state-of-the-art performance and the top ranking on the MSD chal-lenge leaderboard. 1.

Introduction
Automated medical image segmentation is essential for many clinical applications like ﬁnding new biomarkers and monitoring disease progression. The recent developments in deep neural network architectures have achieved great performance improvements in image segmentation. Man-ually designed networks, like U-Net [34], have been widely used in different tasks. However, the diversity of medical image segmentation tasks could be extremely high since the image characteristics & appearances can be completely dis-tinct for different modalities and the presentation of diseases
Figure 1. Limitations of existing differentiable topology search formulation. E.g. in Auto-DeepLab [21], each edge in the topol-ogy search space is given a probability β. The probabilities of in-put edges to a node sum to one, which means only one input edge for each node would be selected. A single-path discrete model (red path) is extracted from the continuous searched model. This can result in a large “discretization gap” between the feature ﬂow of the searched continuous model and the ﬁnal discrete model. can vary considerably. This makes the direct application of even a successful network like U-Net [34] to a new task less likely to be optimal.
The neural architecture search (NAS) algorithms [49] have been proposed to automatically discover the opti-mal architectures within a search space. The NAS search space for segmentation usually contains two levels: net-work topology level and cell level. The network topology controls the connections among cells and decides the ﬂow of the feature maps across different spatial scales. The cell level decides the speciﬁc operations on the feature maps.
A more ﬂexible search space has more potential to contain better performing architectures.
In terms of the search methods in ﬁnding the optimal ar-chitecture from the search space, evolutionary or reinforce-ment learning-based [49, 33] algorithms are usually time consuming. C2FNAS [45] takes 333 GPU days to search one 3D segmentation network using the evolutionary-based methods, which is too computationally expensive for com-mon use cases. Differentiable architecture search [23] is much more efﬁcient and Auto-DeepLab [21] is the ﬁrst work to apply differentiable search for segmentation net-work topology. However, Auto-DeepLab’s differentiable formulation limits the searched network topology. As shown in Fig. 1, this formulation assumes that only one in-5841
put edge would be kept for each node. Its ﬁnal searched model only has a single path from input to output which limits its complexity. Our ﬁrst goal is to propose a new dif-ferentiable scheme to support more complex topologies in order to ﬁnd novel architectures with better performance.
Meanwhile, the differentiable architecture search suffers from the “discretization gap” problem [4, 38]. The dis-cretization of the searched optimal continuous model may produce a sub-optimal discrete ﬁnal architecture and cause a large performance gap. As shown in Fig. 1, the gap comes from two sides: 1) the searched continuous model is not binary, thus some operations/edges with small but non-zero probabilities are discarded during the discretiza-tion step; 2) the discretization algorithm has topology con-straints (e.g. single-path), thus edges causing infeasible topology are not allowed even if they have large probabili-ties in the continuous model. Alleviating the ﬁrst problem by encouraging a binarized model during search has been explored [5, 38, 27]. However, alleviating the second prob-lem requires the search to be aware of the discretization al-gorithm and topology constraints. In this paper, we propose a topology loss in search stage and a topology guaranteed discretization algorithm to mitigate this problem.
In medical image analysis, especially for some longitu-dinal analysis tasks, high input image resolution and large patch size are usually desired to capture miniscule longitu-dinal changes. Thus, large GPU memory usage is a major challenge for training with large high resolution 3D images.
Most NAS algorithms with computational constraints focus on latency [1, 3, 18, 36] for real-time applications. How-ever, real-time inference often is not a major concern com-pared to the problem caused by huge GPU memory usage in 3D medical image analysis. In this paper, we propose addi-tional GPU memory constraints in the search stage to limit the GPU usage needed for retraining the searched model.
We validate our method on the Medical Segmentation
Decathlon (MSD) dataset [37] which contains 10 repre-sentative 3D medical segmentation tasks covering differ-ent anatomies and imaging modalities. We achieve state-of-the-art results while only takes 5.8 GPU days (recent
C2FNAS [45] takes 333 GPU days on the same dataset).
Our contributions can be summarized as:
• We propose a novel Differentiable Network Topology
Search scheme DiNTS, which supports more ﬂexible topologies and joint two-level search.
• We propose a topology guaranteed discretization algo-rithm and a discretization aware topology loss for the search stage to minimize the discretization gap.
• We develop a memory usage aware search method which is able to search 3D networks with different
GPU memory requirements.
• We achieve the new state-of-the-art results and top ranking in the MSD challenge leaderboard while only taking 1.7% of the search time compared to the NAS-based C2FNAS [45]. 2.