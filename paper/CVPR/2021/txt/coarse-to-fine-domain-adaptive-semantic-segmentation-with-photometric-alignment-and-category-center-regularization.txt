Abstract
Unsupervised domain adaptation (UDA) in semantic segmentation is a fundamental yet promising task reliev-ing the need for laborious annotation works. However, the domain shifts/discrepancies problem in this task compro-mise the ﬁnal segmentation performance. Based on our observation, the main causes of the domain shifts are dif-ferences in imaging conditions, called image-level domain shifts, and differences in object category conﬁgurations called category-level domain shifts. In this paper, we pro-pose a novel UDA pipeline that uniﬁes image-level align-ment and category-level feature distribution regularization in a coarse-to-ﬁne manner. Speciﬁcally, on the coarse side, we propose a photometric alignment module that aligns an image in the source domain with a reference image from the target domain using a set of image-level operators; on the ﬁne side, we propose a category-oriented triplet loss that imposes a soft constraint to regularize category cen-ters in the source domain and a self-supervised consistency regularization method in the target domain. Experimental results show that our proposed pipeline improves the gen-eralization capability of the ﬁnal segmentation model and signiﬁcantly outperforms all previous state-of-the-arts. 1.

Introduction
Semantic segmentation is a fundamental computer vi-sion task that aims to assign a semantic category label to every pixel in an image.
It has been widely used in many important downstream tasks such as autonomous driving [25, 5] and medical image analysis [4, 28, 10]. Re-cent state-of-the-art methods on semantic segmentation are primarily deep learning based [1, 15, 36] and require a large number of high quality annotated ground-truth data which are difﬁcult to obtain especially in practical applica-tions. Unsupervised domain adaptation semantic segmenta-*These authors have equal contribution.
†Corresponding author tion is an alternative method to solve the data scarcity prob-lem where it generalizes models trained on the source do-main composed of synthetic images and labels to perform well on the target domain composed of real world images only [21, 13, 30, 11, 20]. However, the problem is that semantic segmentation models trained merely on synthetic data exhibit poor performance on real world images due to the differences in multiple aspects (also called domain shifts/discrepancies), including exposure, contrast, lighting, object shape and surface textures, between the source do-main and the target domain. Therefore, matching the dis-tributions between the source and target domains to learn domain-invariant representations is crucial to solve the do-main shifts.
Although the domain shifts could be caused by multiple factors, based on our observation, the primary causes can be summarized into two groups, namely image-level do-main shifts and category-level domain shifts. For the image-level domain shifts, these refer to the differences in imag-ing conditions, such as lighting and settings in the camera imaging pipeline. Existing works on solving image-level domain shifts through image style transfer generally utilize deep models such as generative models and image-to-image translation models [17, 37] while another line of research focuses on using Fourier transformation [33]. These meth-ods have proven that transferring image style of one do-main to another domain can bring the two domains closer.
However, the downside of these methods is that they ei-ther require to carry out a computationally expensive train-ing process for the deep models or generate inferior style-transferred output images as shown in Figure 5.
Despite the fact that the domain gap can be minimized by global alignment methods such as the above, there is no guarantee that samples from different object categories in the target domain can be well separated. This is be-cause some categories are naturally close to others in terms of body shape, pose and textures. To solve this problem, existing methods adopt category anchors computed on the source domain to guide the alignment between the two do-4051
mains [34, 30], which can be regarded as a hard constraint on the category centers. The problem of this design is that it does not regularize the distance between different cate-gory features, and categories with similar feature distribu-tions in the source domain also have similar distributions in the target domain, which results in erroneous classiﬁ-cation results especially when no supervision information is available in the target domain. Our experimental results have demonstrated that imposing soft regularization meth-ods on category distributions can improve the model’s ca-pacity to adjust the relative magnitude of inter-category and intra-category feature distances.
According to the analysis above, performing alignment from either image-level perspective or category-level per-spective alone will not solve the domain shifts reasonably.
Therefore, we approach the problem from a different per-spective and propose a novel and efﬁcient pipeline that uni-ﬁes image-level alignment and category-level feature dis-tribution regularization in a coarse-to-ﬁne manner. In gen-eral, on the coarse side, we propose a novel and efﬁcient image-level alignment module to coarsely align the two domains; on the ﬁne side, we introduce a new category-oriented triplet loss to softly regularize the category centers in the source domain and propose a self-supervised consis-tency regularization method in the target domain. By ad-dressing both level of domain shifts simultaneously, we can signiﬁcantly improve the performance of our proposed do-main adaptation method.
Coarse Alignment. To solve the image-level domain shifts discussed above, we propose a global photometric alignment (GPA) module that aligns an image in the source domain with a reference image from the target domain us-ing a set of image-level operators. Our method is superior to other generative methods and Fourier transformation based methods in two aspects: ﬁrst, compared to the generative counterparts, our method requires no extra training process and produces stochastic image results; second, the quality of the translated image and the performance of our method is comparable to its generative counterpart and is superior to that of Fourier transformation based methods.
Category-level Feature Distribution Regularization.
To address category-level domain shifts on the ﬁne side, in addition to the common strategy of using pseudo la-bels for the target domain, we propose two novel regular-ization methods for the source and target domains respec-tively. First, considering the fact that there are annotated ground truth labels in the source domain, we propose a category-oriented triplet loss (CTL) that imposes a soft con-straint to regularize category centers calculated using the source image pixel features, which actively enlarges the distances among category centers, making inter-category distances in a high-level feature space larger than intra-category distances by a predeﬁned margin. Second, inspired by the commonly used self-supervised learning methods: consistency regularization and pseudo-labeling, we propose a simple yet effective consistency regularizer for the tar-get domain, called target domain consistency regularization (TCR), which constrains the prediction on an augmented target image to be consistent with the pseudo label of the corresponding non-augmented image, forcing the class la-bels of similar semantic contents to be consistent in the tar-get domain.
In conclusion, this paper has the following contributions:
• We propose a novel coarse-to-ﬁne domain adap-tive semantic segmentation pipeline that seamlessly combines coarse image-level alignment with ﬁner category-level feature distribution regularization.
• We introduce two novel and effective category-level regularization methods for the source and target do-mains respectively. The ﬁrst one is called category-oriented triplet loss that regularizes category centers in the source domain while the second one performs tar-get domain consistency regularization.
• Our method outperforms all previous methods, achieving new state-of-the-art performance on both
GTA5
Cityscapes
→ benchmarks.
SYNTHIA
Cityscapes and
→ 2.