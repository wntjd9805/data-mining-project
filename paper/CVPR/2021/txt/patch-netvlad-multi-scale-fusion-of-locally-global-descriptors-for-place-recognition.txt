Abstract
Visual Place Recognition is a challenging task for robotics and autonomous systems, which must deal with the twin problems of appearance and viewpoint change in an always changing world. This paper introduces Patch-NetVLAD, which provides a novel formulation for combining the advantages of both local and global descriptor methods by deriving patch-level features from NetVLAD residuals.
Unlike the ﬁxed spatial neighborhood regime of existing local keypoint features, our method enables aggregation and matching of deep-learned local features deﬁned over the feature-space grid. We further introduce a multi-scale fusion of patch features that have complementary scales (i.e. patch sizes) via an integral feature space and show that the fused features are highly invariant to both condition (sea-son, structure, and illumination) and viewpoint (translation and rotation) changes. Patch-NetVLAD achieves state-of-the-art visual place recognition results in computationally limited scenarios, validated on a range of challenging real-world datasets, including winning the Facebook Mapillary
Visual Place Recognition Challenge at ECCV2020. It is also adaptable to user requirements, with a speed-optimised version operating over an order of magnitude faster than the state-of-the-art. By combining superior performance with improved computational efﬁciency in a conﬁgurable framework, Patch-NetVLAD is well suited to enhance both stand-alone place recognition capabilities and the overall performance of SLAM systems. 1.

Introduction
Visual Place Recognition (VPR) is a key prerequisite for many robotics and autonomous system applications, both as a stand-alone positioning capability when using a prior map and as a key component of full Simultaneous Localization
And Mapping (SLAM) systems. The task can prove challeng-ing because of major changes in appearance, illumination and even viewpoint, and is therefore an area of active re-search in both the computer vision [3, 19, 35, 43, 79, 81, 82]
Input 
Image
CNN
VLAD 
Residuals
W
∑
H
∑
∑
∑
∑
∑
∑
∑
NetVLAD l n o i s u
F e a c
S
-i t l u
M
Patch-NetVLAD
Figure 1. Patch-NetVLAD is a novel condition and viewpoint invariant visual place recognition system that produces a similarity score between two images through local matching of locally-global descriptors extracted from a set of patches in the feature space of each image. Furthermore, by introducing an integral feature space, we are able to derive a multi-scale approach that fuses multiple patch sizes. This is in contrast with the original NetVLAD paper, which performs an appearance only aggregation of the whole feature space into a single global descriptor. and robotics [10, 11, 12, 27, 39, 45] communities.
VPR is typically framed as an image retrieval task [45, 59, 76, 24], where, given a query image, the most sim-ilar database image (alongside associated metadata such as the camera pose) is retrieved. There are two com-mon ways to represent the query and reference images: using global descriptors which describe the whole im-age [3, 79, 27, 59, 10, 58, 82], or using local descriptors that describe areas of interest [20, 52, 18, 23, 14]. Global descriptor matching is typically performed using nearest neighbor search between query and reference images. These global descriptors typically excel in terms of their robust-ness to appearance and illumination changes, as they are directly optimized for place recognition [3, 59]. Conversely, local descriptors are usually cross-matched, followed by geometric veriﬁcation. Local descriptor techniques priori-114141  
tize spatial precision, predominantly on a pixel-scale level, using a ﬁxed-size spatial neighborhood to facilitate highly-accurate 6-DoF pose estimation. Given the complementary strengths of local and global approaches, there has been little research [9, 65, 76] attempting to combine them. The novel
Patch-NetVLAD system proposed here combines the mutual strengths of local and global approaches while minimizing their weaknesses.
To achieve this goal, we make a number of contributions (see Fig. 1): First, we introduce a novel place recognition sys-tem that generates a similarity score between an image pair through a spatial score obtained through exhaustive matching of locally-global descriptors. These descriptors are extracted for densely-sampled local patches within the feature space using a VPR-optimized aggregation technique (in this case
NetVLAD [3]). Second, we propose a multi-scale fusion technique that generates and combines these hybrid descrip-tors of different sizes to achieve improved performance over a single scale approach. To minimize the computational growth implications of moving to a multi-scale approach, we develop an integral feature space (analogous to integral images) to derive the local features for varying patch sizes.
Together these contributions provide users with ﬂexibility based on their task requirements: our ﬁnal contribution is the demonstration of a range of easily implemented system conﬁgurations that achieve different performance and com-putational balances, including a performance-focused con-ﬁguration that achieves state-of-the-art recall performance when tight error thresholds are required, a balanced conﬁg-uration that performs almost as well as the state-of-the-art while being 3× faster than SuperGlue and 28× faster than
DELG, and a speed-focused conﬁguration that is at least an order of magnitude faster than the state-of-the-art.
We extensively evaluate the versatility of our proposed system on a large number of well-known datasets [71, 46, 80, 79, 82] that capture all challenges present in VPR. We com-pare Patch-NetVLAD with several state-of-the-art global fea-ture descriptor methods [3, 59, 79], and the recent global and local descriptor DELG [9]. We additionally introduce new
SuperPoint [18] and SuperGlue [62]-enabled VPR pipelines as competitive local descriptor baselines. Patch-NetVLAD outperforms the global feature descriptor methods by large margins (from 6% to 330% relative increase) across all datasets, and achieves superior performance (up to a rel-ative increase of 54%) when compared to SuperGlue. Patch-NetVLAD outperforms DELG [9] in some datasets while performing worse in others; however, the order-of-magnitude difference in compute speed makes Patch-NetVLAD much more suitable in practical scenarios. Patch-NetVLAD won the Facebook Mapillary Long-term Localization Challenge as part of the ECCV 2020 Workshop on Long-Term Vi-sual Localization. To characterise the system’s proper-ties in detail, we conduct numerous ablation studies show-casing the role of the individual components comprising
Patch-NetVLAD, particularly the robustness of the system to changes in various key parameters. To foster future re-search, we make our code available for research purposes: https://github.com/QVPR/Patch-NetVLAD. 2.