Abstract
Occlusion
Human De-occlusion Model
De-occlusion
In this paper, we tackle the problem of human de-occlusion which reasons about occluded segmentation masks and invisible appearance content of humans. In par-ticular, a two-stage framework is proposed to estimate the invisible portions and recover the content inside. For the stage of mask completion, a stacked network structure is devised to reﬁne inaccurate masks from a general instance segmentation model and predict integrated masks simulta-neously. Additionally, the guidance from human parsing and typical pose masks are leveraged to bring prior infor-mation. For the stage of content recovery, a novel parsing guided attention module is applied to isolate body parts and capture context information across multiple scales. Besides, an Amodal Human Perception dataset (AHP) is collected to settle the task of human de-occlusion. AHP has advan-tages of providing annotations from real-world scenes and the number of humans is comparatively larger than other amodal perception datasets. Based on this dataset, ex-periments demonstrate that our method performs over the state-of-the-art techniques in both tasks of mask comple-tion and content recovery. Our AHP dataset is available at https://sydney0zq.github.io/ahp/. 1.

Introduction
Visual recognition tasks have witnessed signiﬁcant ad-vances driven by deep learning, such as classiﬁcation [21, 14], detection [38, 10] and segmentation [28, 51]. De-spite the achieved progress, amodal perception, i.e. to rea-son about the occluded parts of objects, is still challeng-In contrast, it is easy for humans ing for vision models. to interpolate the occluded portions with human visual sys-tems [59, 34]. To reduce the recognition ability gap be-tween the models and humans, recent works have proposed methods to infer the occluded parts of objects, including es-*The work was mainly done during an internship at ByteDance Inc.
†Corresponding author.
Mask Completion
Content Recovery (a) Pipeline
Portrait Editing 3D Mesh Generation
Pose Estimation (b) Demo Applications
Figure 1. (a) The pipeline of our framework to tackle the task of human de-occlusion, which contains two stages of mask comple-tion and content recovery. (b) Some applications which demon-strate better results can be obtained after human de-occlusion. timating the invisible segmentation [25, 59, 37, 50, 54] and recovering the invisible content of objects [6, 50, 54].
In this paper, we aim at the problem of estimating the in-visible masks and the appearance content for humans. We refer to such a task as human de-occlusion. Compared with general amodal perception, human de-occlusion is a more special and important task, since completing human body plays key roles in many vision tasks, such as portrait edit-ing [1], 3D mesh generation [19], and pose estimation [11] as illustrated in Fig 1 (b). Different from common object de-occlusion task (e.g., vehicle, building, furniture), hu-man de-occlusion presents new challenges in three aspects.
First, humans are non-rigid bodies and their poses vary dra-matically. Second, the context relations between humans and backgrounds are relatively inferior to common objects which are usually limited to speciﬁc scenes. Third, to seg-ment and recover the invisible portions of humans, the algo-rithm should be able to recognize the occluded body parts to be aware of symmetrical or interrelated patches.
To precisely generate the invisible masks and the appear-ance content of humans, we propose a two-stage framework to accomplish human de-occlusion as shown in Fig 1 (a).
The ﬁrst stage segments the invisible portions of humans, 3691
and the second stage recovers the content inside the regions obtained in the previous stage. In the testing phase, the two stages are cascaded into an end-to-end manner.
Previous methods [54, 6, 50] adopt perfect modal 1 mask as an extra input (e.g., ground-truth annotation or well-segmented mask), and expect to output amodal mask. How-ever, obtaining ground-truth or accurate segmented masks is non-trivial in actual applications. To address the issue, our ﬁrst stage utilizes a stacked hourglass network [31] to segment the invisible regions progressively. Speciﬁcally, the network ﬁrst applies a hourglass module to reﬁne the inaccurate input modal mask, then a secondary hourglass module is applied to estimate the integrated amodal mask.
In addition, our network beneﬁts from human parsing and typical pose masks. Inspired by [22, 50], human parsing pseudo labels are served as auxiliary supervisions to bring prior cues and typical poses are introduced as references.
In the second stage, our model recovers the appearance content inside the invisible portions. Different from typical inpainting methods [36, 27, 52, 30, 49], the context infor-mation inside humans should be sufﬁciently explored. To this end, a novel parsing guided attention (PGA) module is proposed to capture and consolidate the context informa-tion from the visible portions to recover the missing content across multiple scales. Brieﬂy, the module contains two at-tention streams. The ﬁrst path isolates different body parts to obtain relations of the missing parts with other parts. The second spatially calculates the relationship between the in-visible and the visible portions to capture contextual infor-mation. Then the two streams are fused by concatenation and the module outputs an enhanced deep feature. The module works at different scales for stronger recovery ca-pability and better performance.
As most existing amodal perception datasets [59, 37, 16] focus on amodal segmentation and few human images are involved, an amodal perception dataset speciﬁed for hu-man category is required to evaluate our method. On ac-count of this, we introduce an Amodal Human Perception dataset, namely AHP. There are three main advantages of our dataset: a) the number of humans in AHP is compara-tively larger than other amodal perception datasets; b) the occlusion cases synthesized from AHP own amodal seg-mentation and appearance content ground-truths from real-world scenes, hence subjective judgements and consistency of the invisible portions from individual annotators are un-necessary; c) the occlusion cases with expected occlusion distribution can be readily obtained. Existing amodal per-ception datasets have ﬁxed occlusion distributions but some scenarios may have gaps with them.
Our contributions are summarized as follows:
• We propose a two-stage framework for precisely gen-1The terms ‘modal’ and ‘amodal’ are used to refer to the visible and the integrated portions of an object respectively. erating the invisible parts of humans. To the best of our knowledge, this is the ﬁrst study which both considers human mask completion and content recovery.
• A stacked network structure is devised to do mask completion progressively, which speciﬁcally reﬁnes inaccurate modal masks. Additionally, human parsing and typical poses are introduced to bring prior cues.
• We propose a novel parsing guided attention (PGA) module to capture body parts guidance and context in-formation across multiple scales.
• A dataset, namely AHP, is collected to settle the task of human de-occlusion. 2.