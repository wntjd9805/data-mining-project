Abstract
We introduce Point2Skeleton, an unsupervised method to learn skeletal representations from point clouds. Exist-ing skeletonization methods are limited to tubular shapes and the stringent requirement of watertight input, while our method aims to produce more generalized skeletal represen-tations for complex structures and handle point clouds. Our key idea is to use the insights of the medial axis transform (MAT) to capture the intrinsic geometric and topological natures of the original input points. We ﬁrst predict a set of skeletal points by learning a geometric transformation, and then analyze the connectivity of the skeletal points to form skeletal mesh structures. Extensive evaluations and com-parisons show our method has superior performance and robustness. The learned skeletal representation will beneﬁt several unsupervised tasks for point clouds, such as surface reconstruction and segmentation. 1.

Introduction
Generating skeleton-based representations to capture the underlying shape structures is a classic problem in com-puter vision and computer graphics. Skeletonization has been shown to beneﬁt various tasks including shape recog-nition [4,40], 3D reconstruction [38,43], segmentation [24], shape matching [34, 36], pose estimation [28, 32], action recognition [21,33] and animation [5]. Extracting skeletons of 3D shapes using hand-crafted rules [3, 26, 37] has been researched for decades. With the recent advances in 3D vi-sion with deep learning, predicting curve skeletons for 3D shapes using networks [44] is beginning to be studied.
In fact, the existing methods only target a speciﬁc cate-gory of shapes that can be abstracted appropriately by curve segments, i.e., shapes composed of tubular parts. Also, gen-erating an internal representation, such as the skeleton, for a 3D shape heavily relies on watertight surface meshes to explicitly give inside/outside classiﬁcation labels and pre-cisely compute certain geometric functions [12, 14]. These
* corresponding authors
Figure 1. We introduce an unsupervised method to learn skeletal meshes from point clouds. The skeletal meshes contain both 1D curve segments and 2D surface sheets which can represent under-lying structures of various shapes. restrictions critically limit the applicability of the existing skeletonization methods. Hence, it is imperative to develop an effective method for computing a generalized skeletal representation for an arbitrary 3D shape. Such a skele-tonization method should be able to handle general input beyond the closed surface, such as point clouds with miss-ing parts, in order to signiﬁcantly extend the utility of skele-ton in various computer vision and graphics tasks. (a) (b) (c)
Figure 2. Illustration of the medial axis transformation (MAT) and the skeletal mesh. (a) The MAT of a 2D shape; (b) the original
MAT of a 3D shape; (c) the skeletal mesh.
We observe that the medial axis transform (MAT), one of the best known examples of skeletal representation, has a rigorous mathematical deﬁnition for arbitrary shapes, un-like the curve skeleton which is only empirically understood for tubular objects. Given a 3D shape, the MAT [8] is de-ﬁned as the set of points in the interior with more than one closest point on the boundary surface; the MAT encodes the shape to a lower-dimensional representation with the asso-ciated radius function. The examples are shown in Fig. 2.
Despite its simple deﬁnition, the MAT is difﬁcult to use 4277
in practice for the following two reasons: (1) the compu-tation of the MAT is expensive, since it requires the in-put 3D shape to be deﬁned by a closed boundary surface and a substantial amount of time for geometric processing; (2) the MAT is notoriously sensitive to surface noise, i.e., small perturbations to the shape surface lead to numerous insigniﬁcant branches [2,15] (Fig. 2 (b)); such a noisy MAT does not clearly reﬂect the structures of the given shape.
These difﬁculties motivate us to resort to the formula-tion of the MAT and the representational power of the deep neural network to learn a generalized skeletal representa-tion. We name this representation skeletal mesh, which is an important extension to the curve skeleton. As shown in
Fig 2, the skeletal mesh follows a similar but not identical deﬁnition to the MAT; it circumvents the drawbacks of the
MAT and has its own merits: (1) it is structurally meaning-ful and topologically informative, where the tubular parts can be properly abstracted by a few curves while the pla-nar or bulky parts by interior surfaces; (2) the skeletal mesh is simpler and more compact than the standard MAT; it fo-cuses on the fundamental geometry of a shape and can cope with point clouds, making it robust to surface noise and par-tially missing data. Therefore, given such a representation, the expressive capacity for the geometry and topology of a 3D shape is signiﬁcantly enhanced.
In this paper, we propose Point2Skeleton, an unsuper-vised method for learning skeletal meshes from 3D point clouds. Our method consists of two main steps as shown in Fig 1. The ﬁrst step is to predict the skeletal points by learning a geometric transformation. The second step is to connect the skeletal points to form a mesh structure; we adopt a graph structure, and analyze the edge connectivity by jointly leveraging the properties of skeletal mesh and the correlations learned by a graph auto-encoder (GAE). Our main contributions are:
• To our best knowledge, Point2Skeleton is the ﬁrst unsupervised learning method for generalized point cloud skeletonization.
• We present novel unsupervised formulations for geo-metric learning of 3D point clouds, i.e., learning in-trinsic geometric transformations and predicting con-nectivity for mesh generation.
• We introduce a new representation, called skeletal mesh, which gives new insights into some unsuper-vised tasks for point clouds, such as surface recon-struction and segmentation. 2.