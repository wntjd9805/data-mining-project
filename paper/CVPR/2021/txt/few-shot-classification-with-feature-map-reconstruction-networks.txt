Abstract
In this paper we reformulate few-shot classiﬁcation as a reconstruction problem in latent space. The ability of the network to reconstruct a query feature map from support features of a given class predicts membership of the query in that class. We introduce a novel mechanism for few-shot classiﬁcation by regressing directly from support features to query features in closed form, without introducing any new modules or large-scale learnable parameters. The result-ing Feature Map Reconstruction Networks are both more performant and computationally efﬁcient than previous ap-proaches. We demonstrate consistent and substantial ac-curacy gains on four ﬁne-grained benchmarks with vary-ing neural architectures. Our model is also competitive on the non-ﬁne-grained mini-ImageNet and tiered-ImageNet benchmarks with minimal bells and whistles.1 1.

Introduction
Convolutional neural classiﬁers have achieved excellent performance in a wide range of settings and benchmarks, but this performance is achieved through large quantities of labeled images from the relevant classes.
In practice, such a large quantity of human-annotated images may not always be available for the categories of interest. Instances of relevant classes may be rare in the wild, and identi-fying them may require expensive expert annotators, lim-iting the availability of training points and labels respec-tively. These problems are compounded in settings such as robotics, where a model may need to learn and adapt quickly in deployment, without waiting for ofﬂine data col-lection. Producing a performant classiﬁer in these settings requires a neural network that can rapidly ﬁt novel, possibly unseen classes from a small number of reference images.
A promising approach to this problem of few-shot clas-siﬁcation is the family of metric learning techniques, where the standard parametric linear classiﬁer head is replaced with a class-agnostic distance function. Class membership
*Equal contribution 1Code is available at https://github.com/Tsingularity/FRN
Figure 1. Visual intuition for FRN: we reconstruct each query im-age as a weighted sum of components from the support images.
Reconstructions from the same class are better than reconstruc-tions from different classes, enabling classiﬁcation. FRN performs the reconstruction in latent space, as opposed to image space, here. is determined by distance in latent space from a point or points known to belong to each class. Simple distance func-tions such as cosine [13, 8] and Euclidean distance [30] lead to surprisingly powerful classiﬁers, though more com-plex [29], non-Euclidean [17], and even learned parametric options [32] are possible, and yield sizable gains.
One overarching problem common to all these tech-niques is the fact that the convolutional feature extractors used to learn the metric spaces produce feature maps char-acterizing appearance at a grid of spatial locations, whereas the chosen distance functions require a single vectorial rep-resentation for the entire image. The researcher must de-cide how to convert the feature map into a vector represen-tation. Optimally, this conversion would preserve the spa-tial granularity and detail of the feature map without over-ﬁtting to pose, but existing, widely-employed approaches do not accomplish this. Global average-pooling, the stan-dard solution for parametric softmax classiﬁers, averages information from disparate parts of the image, completely 8012
discarding spatial details that might be necessary for ﬁne distinctions. Flattening the feature map into a single long vector preserves the individual features [30, 32], but also encodes the explicit location of each feature. This sensitiv-ity to feature location and arrangement (i.e., object pose), regardless of underlying semantic content, is highly unde-sirable. Larger and more responsive receptive ﬁelds will re-duce this sensitivity, but instead overﬁt to specious cues [9].
We aim to avoid these tradeoffs entirely, preserving spatial detail while disentangling it from location.
We introduce Feature Map Reconstruction Networks (FRN), which accomplish this by framing class member-ship as a problem of reconstructing feature maps. Given a set of images all belonging to a single class, we produce the associated feature maps and collect the component fea-ture vectors across locations and images into a single pool of support features. For each query image, we then at-tempt to reconstruct every location in the feature map as a weighted sum of support features, and the negative aver-age squared reconstruction error is used as the class score.
Images from the same class should be easier to reconstruct, since their feature maps contain similar embeddings, while images from different classes will be more difﬁcult and pro-duce larger reconstruction errors. By evaluating the recon-struction of the full feature map, FRN preserves the spatial details of appearance. But by allowing this reconstruction to use feature vectors from any location in the support images,
FRN explicitly discards nuisance location information.
While prior methods based on feature map reconstruc-tion exist, these methods either rely on constrained iterative procedures [43] or large learned attention modules [9, 16].
Instead, we frame feature map reconstruction as a ridge re-gression problem, allowing us to rapidly calculate a solution in closed form with only a single learned, soft constraint.
The resulting reconstructions are discriminative and se-mantically rich, making FRN both simpler and more pow-erful than prior reconstruction-based approaches. We vali-date these claims by demonstrating across-the-board supe-riority on four ﬁne-grained few-shot classiﬁcation datasets (CUB [38], Aircraft [21], meta-iNat and tiered meta-iNat [41]) and two general few-shot recognition bench-marks (mini-ImageNet [37] and tiered-ImageNet [27]).
These results hold for both shallow and deep network ar-chitectures (Conv-4 [30, 18] and ResNet-12 [14, 18]). 2.