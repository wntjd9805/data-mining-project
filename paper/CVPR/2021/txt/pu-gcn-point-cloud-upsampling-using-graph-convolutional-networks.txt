Abstract
The effectiveness of learning-based point cloud upsampling pipelines heavily relies on the upsampling modules and feature extractors used therein. For the point upsampling module, we propose a novel model called NodeShufﬂe, which uses a Graph Convolutional Network (GCN) to better encode local point information from point neighborhoods.
NodeShufﬂe is versatile and can be incorporated into any point cloud upsampling pipeline. Extensive experiments show how NodeShufﬂe consistently improves state-of-the-art upsampling methods. For feature extraction, we also propose a new multi-scale point feature extractor, called
Inception DenseGCN. By aggregating features at multiple scales, this feature extractor enables further performance gain in the ﬁnal upsampled point clouds. We combine
Inception DenseGCN with NodeShufﬂe into a new point upsampling pipeline called PU-GCN. PU-GCN sets new state-of-art performance with much fewer parameters and more efﬁcient inference. Our code is publicly available at https://github.com/guochengqian/PU-GCN . 1.

Introduction
Point clouds are a popular way to represent 3D data. This increasing popularity stems from the increased availability of 3D sensors like LiDAR. Such sensors are now a critical part of important applications in robotics and self-driving cars. However, due to hardware and computational con-straints, these 3D sensors often produce sparse and noisy point clouds, which show evident limitations especially for small objects or those far away from the camera. Therefore, point cloud upsampling, the task of converting sparse, in-complete, and noisy point clouds into dense, complete, and clean ones, is attracting much attention.
Following the success in image super-resolution [4, 18, 13, 24], deep learning methods now achieve state-of-the-art results in point cloud upsampling [39, 40, 38, 17]. Most
* Guocheng and Abdulellah contributed equally to this work.
Figure 1: Effectiveness of proposed NodeShufﬂe and In-ception DenseGCN. We propose a Graph Convolutional
Network (GCN) based upsampling module NodeShufﬂe and a multi-scale feature extractor Inception DenseGCN. Inte-grating NodeShufﬂe into the 3PU [38] upsampling pipeline allows for better upsampling and better structure preserva-tion capability. We propose PU-GCN that combines both
Inception DenseGCN and NodeShufﬂe (NS) upsampling modules.
In PU-GCN, Inception DenseGCN can further improve upsampling quality and generate ﬁne-grained de-tails (e.g. the neck and ball shape of the faucet). The origi-nal 3PU uses duplicate-based upsampling. deep upsampling pipelines comprise two major compo-nents: feature extraction and point upsampling. The per-formance of the point upsampling component tends to de-ﬁne the effectiveness of the ﬁnal network. Current methods use either multi-branch MLPs (PU-Net [40]) or a duplicate-based approach (3PU [38] and PU-GAN [17]) to upsample 3D points. Multi-branch MLPs operate on each point sep-arately, ignoring any neighborhood information, while du-plicate upsampling methods tend to generate point patches similar to the input point clouds. Although the feature ex-traction modules used in their networks can encode the lo-cality, these shortcomings of the upsampling modules still lead to upsampled point clouds that lack local detail (see 11683
Figure 1). To better represent locality and aggregate the point neighborhood information, we leverage the power of graphs and speciﬁcally Graph Convolutional Networks (GCNs). GCNs are considered a powerful tool to process non-Euclidean data, and recent research on point cloud se-mantic and part segmentation show their power in encod-ing local and global information [32, 16, 15, 30]. In this paper, we use GCNs to design a novel and versatile point upsampling module called NodeShufﬂe (Figure 2), which is better equipped at encoding local point information and at learning to generate new points instead of merely repli-cating parts of the input.
Point clouds often represent objects of variable part sizes. Using multi-scale features is an effective way to encode this property and is essential for obtaining point clouds of high quality. Recent works like PU-Net [40] ex-tract point features at different downsampled levels. While such an architecture can encode multi-scale features, down-sampling leads to loss of ﬁne-grained details. In contrast, 3PU [38] proposes a progressive upsampling network using different numbers of neighbors in subsequent upsampling units. This achieves different receptive ﬁelds and encodes multi-scale information. However, 3PU is computation-ally expensive due to its progressive nature. In this paper, we tackle this multi-scale feature learning problem using a multi-path densely connected GCN architecture called In-ception DenseGCN. Following its prevalent usage in image recognition [27, 28, 26] for the merits of efﬁcient extraction of multi-scale image information, we adopt the Inception architecture to encode multi-scale point features, after it is modiﬁed to use densely connected GCNs instead of CNNs.
Contributions. We summarize our contributions as three-fold. (1) We propose NodeShufﬂe, a novel point cloud up-sampling module using graph convolutions. We show how
NodeShufﬂe can be seamlessly integrated into current point upsampling pipelines and consistently improve their per-formance. (2) We design Inception DenseGCN, a feature extraction block that effectively encodes multi-scale infor-mation. We combine Inception DenseGCN and NodeShuf-ﬂe into a new architecture called PU-GCN. As compared to the state-of-the-art, PU-GCN achieves better upsampling quality, requires less parameters, and runs faster. Through extensive quantitative and qualitative experiments and for both synthetic and real data, we show the superior perfor-mance of PU-GCN. (3) We compile PU1K, a new large-scale point cloud upsampling dataset with various levels of shape diversity. We show the challenge of PU1K to current learning-based methods. 2.