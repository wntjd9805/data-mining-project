Abstract
Super-resolution based on deep convolutional net-works is currently gaining much attention from both academia and industry. However, lack of proper eval-uation measures makes it diﬃcult to compare ap-proaches, hampering progress in the ﬁeld. Traditional measures, such as PSNR or SSIM, are known to poorly correlate with the human perception of image qual-ity. Therefore, in existing works common practice is also to report Mean-Opinion-Score (MOS) — the re-sults of human evaluation of super-resolved images.
Unfortunately, the MOS values from diﬀerent papers are not directly comparable, due to the varying num-ber of raters, their subjectivity, etc. By this paper, we introduce Neural Side-By-Side — a new measure that allows super-resolution models to be compared au-tomatically, eﬀectively approximating human prefer-ences. Namely, we collect a large dataset of aligned image pairs, which were produced by diﬀerent super-resolution models. Then each pair is annotated by sev-eral raters, who were instructed to choose a more visu-ally appealing image. Given the dataset and the labels, we trained a CNN model that obtains a pair of images and for each image predicts a probability of being more preferable than its counterpart. In this work, we show that Neural Side-By-Side generalizes across both new models and new data. Hence, it can serve as a natu-ral approximation of human preferences, which can be used to compare models or tune hyperparameters with-out raters’ assistance. We open-source the dataset and the pretrained model1 and expect that it will become a handy tool for researchers and practitioners. 1.

Introduction
Image super-resolution (SR) is a long-standing task in image processing, which aims to recover high-1https://github.com/KhrulkovV/NeuralSBS resolution images from low-resolution ones. During the last decades, this task has attracted ever-growing research attention, since super-resolution is a critical component of many computer vision pipelines, includ-ing surveillance[15, 31], video enhancement[1], medi-cal imaging[4] and others. Over the years, a plethora of super-resolution methods has been developed, from simple interpolation techniques to more powerful mod-els, employing deep architectures, which currently dominate the super-resolution landscape. Overall, these days SR is an active research direction, and the community constantly develops new model architec-tures, optimization objectives, regularization, and nor-malization techniques.
Given a large number of diﬀerent SR models ap-pearing in the literature, practitioners need an instru-ment to select the model that is the most eﬀective in many pa-on the particular data. Furthermore, pers model hyperparameters are chosen based on the performance on the academical benchmarks and can be suboptimal for the real task in hand. In practice, model selection and hyperparameter tuning are even more challenging, since “ground truth” high-resolution images can be absent for real data. This implies that the established full-reference measures (such as PSNR,
SSIM[29], LPIPS[32]) cannot be used, and human eval-uation is often the only option to choose the model.
The human evaluation is typically referred to as Mean-Opinion-Score (MOS) and denotes the average rating that human raters assigned to images produced by the particular SR model. Being an adequate evalu-ation measure for SR, MOS, however, is both time-consuming and expensive, which prevents its usage, e.g. to tune hyperparameters.
In this paper, we introduce Neural Side-By-Side — a new instrument for no-reference super-resolution eval-uation that can be used for model comparison or hy-43214988
perparameter tuning. In a nutshell, we collect a large number of aligned image pairs, where each image is pro-duced by some super-resolution model. Then each pair is labeled by humans, who are instructed to select a more visually appealing image from each pair. Impor-tantly, the pairs consist of aligned images, i.e. they cor-respond to the same low-resolution image. Hence, the rater labels reﬂect only image quality and do not relate to their content. We refer to this dataset as SBS180K and release both images and labels for further research.
Given the SBS180K dataset, we train a CNN model that obtains an image pair and predicts probabilities of each image being more attractive compared to its counterpart. These probabilities, averaged over a large number of pairs, can then be used as a quantitative measure to compare two super-resolution models. In the experimental section, we demonstrate that Neural
Side-By-Side generalizes to both new models and new image sets, hence it can be used as an eﬀective ”ap-proximation” of human evaluation. Indeed, there were several attempts to learn no-reference measures of gen-eral image quality[16, 8, 17, 11, 7, 23, 10, 13, 27, 5].
However, these measures are not tailored speciﬁcally for image super-resolution and we demonstrate their inferiority to Neural Side-By-Side in the experimental section.
We summarize the contributions of our paper as fol-lows: 1. We introduce Neural Side-By-Side — a new no-reference technique to compare super-resolution models. The Neural Side-By-Side outperforms the existing no-reference measures in terms of approxi-mating human evaluation and can serve as a handy tool for both academicians and practitioners. 2. We release SBS180K — a dataset of aligned im-age pairs, produced by diﬀerent super-resolution models. The dataset is needed to reproduce the results from our paper and can be used to train and evaluate new models. 3. We evaluate several established models with Neu-ral Side-By-Side on common benchmarks. We expect that the obtained numbers can be useful for further development of more advanced super-resolution models. 2.