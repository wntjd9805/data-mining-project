Abstract
Labelled/unlabelled	images
We propose a novel pool-based Active Learning frame-work constructed on a sequential Graph Convolution Net-work (GCN). Each images feature from a pool of data rep-resents a node in the graph and the edges encode their sim-ilarities. With a small number of randomly sampled im-ages as seed labelled examples, we learn the parameters of the graph to distinguish labelled vs unlabelled nodes by minimising the binary cross-entropy loss. GCN performs message-passing operations between the nodes, and hence, induces similar representations of the strongly associated nodes. We exploit these characteristics of GCN to select the unlabelled examples which are sufﬁciently different from la-belled ones. To this end, we utilise the graph node embed-dings and their conﬁdence scores and adapt sampling tech-niques such as CoreSet and uncertainty-based methods to query the nodes. We ﬂip the label of newly queried nodes from unlabelled to labelled, re-train the learner to optimise the downstream task and the graph to minimise its modi-ﬁed objective. We continue this process within a ﬁxed bud-get. We evaluate our method on 6 different benchmarks: 4 real image classiﬁcation, 1 depth-based hand pose esti-mation and 1 synthetic RGB image classiﬁcation datasets.
Our method outperforms several competitive baselines such as VAAL, Learning Loss, CoreSet and attains the new state-of-the-art performance on multiple applications. 1.

Introduction
Deep learning has shown great advancements in several computer vision tasks such as image classiﬁcation [15, 22] and 3D Hand Pose Estimation (HPE) [26, 41, 25]. This has been possible due to the availability of both the powerful computing infrastructure and the large-scale datasets. Data annotation is a time-consuming task, needs experts and is also expensive. This gets even more challenging to some of the speciﬁc domains such as robotics or medical image analysis. Moreover, while optimizing deep neural network architectures, a gap is present concerning the representative-Inference
Train
Phase	I
Learner
Unlabelled features
Labelled features
Phase	II
;
Adjacency	matrix
Sequential	GCN
Active	Learning
Query	sample
Annotate	 new	sample
Oracle
Phase	V
Phase	IV
Uncertainty	sampling
GCN	
Layer
Phase	III 0.21 0.9 0.93 0.11 0.88 0.89
Unlabelled/labelled	 confidence
Figure 1: The diagram outlines the proposed pipeline.
Phase I: Train the learner to minimise the objective of downstream task from the available annotations, Phase II:
Construct a graph with the representations of images ex-tracted from the learner as vertices and their similarities as edges, Phase III: Apply GCN layers to minimise binary cross-entropy between labelled and unlabelled, Phase IV:
Apply uncertainty sampling to select unlabelled examples to query their labels, Phase V: Annotate the selection, pop-ulate the number of labelled examples and repeat the cycle. ness of the data [4]. To overcome these issues, active learn-ing [10, 20] has been successfully deployed to efﬁciently select the most meaningful samples.
Essentially, there are three distinct components in any
Active Learning (AL) framework. These components are learner, sampler, and annotator.
In brief, a learner is a model trained to minimize the objective of the target task.
The sampler is designed to select the representative unla-belled examples within a ﬁxed budget to deliver the highest performance. Finally, an annotator labels the queried data for learner re-training. Based on the relationship between learner and sampler, AL frameworks can be categorised into two major groups: task-dependent and task-agnostic. Task-dependents are the ones where the sampler is specially de-signed for a speciﬁc task of the learner. Majority of the previous works in active learning [8, 10, 1, 38, 6, 11] are 9583
In other words, the sampling task-dependent in nature. function is dependent on the objective of the learner. This design limits the model to become optimal for a speciﬁc type of task while suffering from its scalability problem.
Some of the recent works such as VAAL [33] and Learning
Loss [42] tackle such a problem. VAAL trains a variational auto-encoder (VAE) that learns a latent space for better dis-crimination between labelled and unlabelled images in an adversarial manner. Similarly, Learning Loss introduces a separate loss-prediction module to be trained together with the learner. The major drawback of these approaches is the lack of a mechanism that exploits the correlation be-tween the labelled and the unlabelled images. Moreover,
VAAL has no way to communicate between the learner and the sampler. Graph Convolutional Networks(GCNs) [18, 5] are capable of sharing information between the nodes via message-passing operations. In the AL domain, the appli-cation of GCNs [6, 11, 1, 38] is also slowly getting priority.
However, these methods are applied only to speciﬁc kind of datasets i.e. graph-structured data such as Cora, CiteSeer, and PubMed [40]. In this work, we are exploring the image domain beyond graph-structured data.
To address the above-mentioned issues, we propose a se-quential GCN for Active Learning in a task-agnostic man-ner. Figure 1 shows the pipeline of the proposed method. In the Figure, Phase I implements the learner. This is a model trained to minimize the objective of the downstream task.
Phase II, III and IV compose our sampler where we de-ploy the GCN and apply the sampling techniques on graph-induced node embeddings and their conﬁdence scores. Fi-nally, in Phase V, the selected unlabelled examples are sent for annotation. At the initial stage, the learner is trained with a small number of seed labelled examples. We extract the features of both labelled and unlabelled images from the learner parameters. During Phase II, we construct a graph where features are used to initialise the nodes of the graph and similarities represent the edges. Unlike VAAL[33], the initialisation of the nodes by the features extracted from the learner creates an opportunity to inherit uncertainties to the sampler. This graph is passed through GCN layers (Phase
III) and the parameters of the graph are learned to identify the nodes of labelled vs unlabelled example. This objective of the sampler is independent of the one from the learner.
We convolve on the graph which does message-passing op-erations between the nodes to induce the higher-order rep-resentations. The graph embedding of any image depends primarily upon the initial representation and the associated neighbourhood nodes. Thus, the images bearing similar se-mantic and neighbourhood structure end up inducing close representations which will play a key role in identifying the sufﬁciently different unlabelled examples from the la-belled ones. The nodes after convolutions are classiﬁed as labelled or unlabelled. We sort the examples based on the conﬁdence score, apply an uncertainty sampling approach (Phase IV), and send the selected examples to query their labels(Phase V). We called this sampling method as Uncer-tainGCN. Figure 2 simulates the UncertainGCN sampling technique. Furthermore, we adapt the higher-order graph node information under the CoreSet [31] for a new sampling technique by introducing latent space distancing. In princi-ple, CoreSet [31] uses risk minimisation between core-sets on the learner feature space while we employ this opera-tion over GCN features. We called this sampling technique as CoreGCN. Our method has a clear advantage due to the aforementioned strengths of the GCN which is demon-strated by both the quantitative and qualitative experiments (see Section 4). Traversing from Phase I to Phase V as shown in Figure 1 completes a cycle. In the next iteration, we ﬂip the label of annotated examples from unlabelled to labelled and re-train the whole framework.
We evaluated our sampler on four challenging real do-main image classiﬁcation benchmarks, one depth-based dataset for 3D HPE and a synthetic image classiﬁcation benchmark. We compared with several competitive sam-pling baselines and existing state-of-the-arts methods in-cluding CoreSet, VAAL and Learning Loss. From both the quantitative and the qualitative comparisons, our proposed framework is more accurate than existing methods. 2.