Abstract 3D object detection is an important yet demanding task that heavily relies on difﬁcult to obtain 3D annotations.
To reduce the required amount of supervision, we propose 3DIoUMatch, a novel semi-supervised method for 3D ob-ject detection applicable to both indoor and outdoor scenes.
We leverage a teacher-student mutual learning framework to propagate information from the labeled to the unlabeled train set in the form of pseudo-labels. However, due to the high task complexity, we observe that the pseudo-labels suf-fer from signiﬁcant noise and are thus not directly usable.
To that end, we introduce a conﬁdence-based ﬁltering mech-anism, inspired by FixMatch. We set conﬁdence thresholds based upon the predicted objectness and class probability to
ﬁlter low-quality pseudo-labels. While effective, we observe that these two measures do not sufﬁciently capture localiza-tion quality. We therefore propose to use the estimated 3D
IoU as a localization metric and set category-aware self-adjusted thresholds to ﬁlter poorly localized proposals. We adopt VoteNet as our backbone detector on indoor datasets while we use PV-RCNN on the autonomous driving dataset,
KITTI. Our method consistently improves state-of-the-art methods on both ScanNet and SUN-RGBD benchmarks by signiﬁcant margins under all label ratios (including fully la-beled setting). For example, when training using only 10% labeled data on ScanNet, 3DIoUMatch achieves 7.7 abso-lute improvement on mAP@0.25 and 8.5 absolute improve-ment on mAP@0.5 upon the prior art. On KITTI, we are the ﬁrst to demonstrate semi-supervised 3D object detection and our method surpasses a fully supervised baseline from 1.8% to 7.6% under different label ratio and categories. 1.

Introduction
Object detection is a key task in 3D scene understand-ing.
It provides a concise representation of raw sensor measurements in the form of semantically meaningful 3D bounding boxes. This low-dimensional representation can
*: equal contribution
Project page: http://THU17cyz.github.io/3DIoUMatch already serve numerous applications in autonomous driving and AR/VR, as well as in robot navigation and manipula-tion. As a result, in recent years there has been a surge of interest in developing improved object detection pipelines and indeed current state-of-the-art methods show impres-sive performance. Yet, much of their success is attributed to the availability of large datasets of 3D scenes that are care-fully annotated. While rapid advances in sensor technology facilitate the collection of 3D scenes at scale, annotating them remains the main bottleneck. This calls for detection methods that can leverage both labeled and unlabeled data at train time.
In this work, we aim to address this requirement by proposing a novel semi-supervised 3D object detection method which we dub 3DIoUMatch. As a generally appli-cable method, 3DIoUMatch can be applied to both indoor scene datasets, i.e. ScanNet[4] and SUN-RGBD[28], and outdoor datasets, i.e. KITTI[7]. We adopt popular point-based object detectors, VoteNet [18] and PV-RCNN [24], as our backbone object detection networks for the indoor and outdoor scenes, correspondingly. To provide supervi-sion to the unlabeled scenes, we leverage a teacher-student mutual learning framework [29] and use the bounding box predictions from the teacher network as pseudo-labels to su-pervise the student network on unlabeled data. However, unlike most pseudo-label techniques that were designed for classiﬁcation, in the highly complex (joint regression and classiﬁcation) task of object detection, we observe that the pseudo-labels suffer from signiﬁcant noise, and using them directly is suboptimal.
Inspired by FixMatch [26], the state-of-the-art semi-supervised learning (SSL) method for 2D image classi-ﬁcation that proposed conﬁdence-based ﬁltering to im-prove pseudo-label quality, we adopt a pseudo-label ﬁlter-ing mechanism for 3D object detection by setting thresh-olds on predicted class probabilities (and objectness scores for VoteNet), so as to ﬁlter out teacher proposals with po-tentially erroneous semantic labels or ones not belong to foreground. While effective, these criteria alone are not suf-ﬁcient to capture localization quality, and the pseudo-labels may still have large errors in the bounding box parameters. 14615
To that end, we further propose to leverage estimated IoU (intersection over union) as a localization quality measure for pseudo-label ﬁltering. IoU estimation was ﬁrst proposed in the context of 2D object detection as a localization con-ﬁdence in the pioneering work IoU-Net [12], where esti-mated IoU was proven successful in replacement of class conﬁdence for test-time Non-Maximal Suppression (NMS).
To the best of our knowledge, leveraging IoU estimation for pseudo-label ﬁltering is a novel idea for SSL on both 2D and 3D object detection. Equipping the detectors with a 3D
IoU estimation module, we are able to ﬁlter out poorly lo-calized pseudo-labels and leverage estimated IoU for both train-time and test-time NMS.
A key challenge when ﬁltering based on IoU estima-tion is how to properly set the threshold. Unlike object-ness and class conﬁdence for which high threshold values (e.g. 0.9) work well, 3D IoU is more sensitive to small er-rors. Setting the threshold too high would reduce the num-ber of pseudo-labels to very few, from which little could be learned. To balance between quality and coverage, we propose a two-stage ﬁltering process: ﬁrst, using a rela-tively low IoU threshold; then, an IoU-guided class-aware
Lower-Half Suppression (LHS) that removes only half of the highly-overlapping boxes with low predicted IoU. Our proposed LHS thus naturally sets a threshold that is both dynamic and class-aware. Our experiments show that LHS outperforms IoU-guided NMS, which suppresses all but the top one during semi-supervised training.
Our method consistently improves upon the previ-ous state-of-the-art method, SESS [34], on both Scan-Net and SUN-RGBD benchmarks by signiﬁcant mar-gins. When using only 10% labeled data on ScanNet, 3DIoUMatch outperforms SESS by 7.7 absolute improve-ment on mAP@0.25 and by 8.5 absolute improvement on mAP@0.5. When using 5% labeled data on SUN-RGBD, 3DIoUMatch outperforms SESS by 4.8 absolute improve-ment on mAP@0.25 and by 8.0 absolute improvement on mAP@0.5. On KITTI, we are the ﬁrst to demonstrate semi-supervised 3D object detection work and surpass fully-supervised baseline by large margins under all label ratios.
Our main contributions can be summarized as follows: 1. We propose a novel semi-supervised method for 3D object detection in point clouds based on pseudo-label propagation along with a carefully designed ﬁltering mechanism. 2. For the ﬁrst time, we leverage predicted 3D IoU as a lo-calization conﬁdence score for pseudo-label ﬁltering, and further propose IoU-guided Lower-Half Suppres-sion for robust pseudo-label deduplication. This idea is generally applicable and can be coupled to different 3D detectors on both indoor and outdoor scenes. 3. We achieve markedly improved performance over the previous state-of-the-art semi-supervised 3D object detection methods on the two major indoor object de-tection benchmarks, ScanNet and SUN-RGBD, under low label ratios and fully labeled setting. As the ﬁrst semi-supervised 3D object detection work on KITTI, we also achieve signiﬁcant improvements compared to fully supervised method. 2.