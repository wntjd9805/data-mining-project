Abstract
SiamRPN++
DiMP
LTMU
Adversarial attack arises due to the vulnerability of deep neural networks to perceive input samples injected with im-perceptible perturbations. Recently, adversarial attack has been applied to visual object tracking to evaluate the robust-ness of deep trackers. Assuming that the model structures of deep trackers are known, a variety of white-box attack ap-proaches to visual tracking have demonstrated promising results. However, the model knowledge about deep trackers is usually unavailable in real applications. In this paper, we propose a decision-based black-box attack method for visual object tracking. In contrast to existing black-box ad-versarial attack methods that deal with static images for im-age classiﬁcation, we propose IoU attack that sequentially generates perturbations based on the predicted IoU scores from both current and historical frames. By decreasing the
IoU scores, the proposed attack method degrades the accu-racy of temporal coherent bounding boxes (i.e., object mo-tions) accordingly. In addition, we transfer the learned per-turbations to the next few frames to initialize temporal mo-tion attack. We validate the proposed IoU attack on state-of-the-art deep trackers (i.e., detection based, correlation
ﬁlter based, and long-term trackers). Extensive experiments on the benchmark datasets indicate the effectiveness of the proposed IoU attack method. The source code is available at https://github.com/VISION-SJTU/IoUattack. 1.

Introduction
Visual object tracking is one of the fundamental com-puter vision problems with a wide range of applications.
The convolutional neural networks (CNNs) have signiﬁ-cantly advanced visual tracking performance. Meanwhile, the enigma of interpreting CNNs has perplexed existing vi-sual tracking algorithms as well. For example, injecting imperceptible perturbations into input images leads deep neural networks to predict incorrectly [37, 43, 48]. To in-*Corresponding author. (a) Original results (b) IoU attack
Figure 1. IoU attack for visual object tracking. State-of-the-art deep trackers (i.e., SiamRPN++ [22], DiMP [1], and LTMU [5]) effectively locate target objects in the original video sequences as shown in (a). Our IoU attack decreases their tracking accuracies by injecting imperceptible perturbations as shown in (b). vestigate the robustness of visual tracking algorithms with deep models, recent approaches [3, 44, 16, 24] assume that the model structures of deep tracking algorithms are known and carry out white-box attack on them. Despite the demon-strated promising results, the concrete structures and param-eters of deep trackers are barely known in real applications.
In this paper, we investigate black-box adversarial attack for visual tracking, where the model knowledge of deep track-ers is unknown.
Prevalent black-box attack algorithms inject impercep-tible perturbations into input images to decrease network classiﬁcation accuracies. Although these methods are ef-fective to attack static images, they are not suitable to at-tack temporally moving objects in videos. This is because 6709
deep trackers maintain temporal motions of the target object within tracking models (i.e., the correlation ﬁlters [6, 35] or deep binary classiﬁers [30, 17, 23, 22]). When localizing the target object, these deep trackers produce temporally coherent bounding boxes (bbxs). Meanwhile, deep track-ers constrain the search area to be close to the predicted bbx from the last frame. As existing black-box methods rarely degrade temporally coherent bbxs, perturbations produced based on CNN classiﬁcation scores are not effective for vi-sual tracking. An intriguing direction thus arises to inves-tigate the black-box attack on both individual frames and temporal motions among sequential frames with a holistic decision-based approach.
In this paper, we propose IoU attack for visual track-ing. IoU attack is a decision-based black-box attack method which focuses on both image content and target motions in video sequences. When processing each frame, we start im-age content attack with two bbxs. One is predicted by the deep tracker using the original frame, which is perturba-tion free. The other one is predicted by the same tracker using the same frame with noisy perturbations. These two bbxs are used to compute an IoU score as feedback to our
IoU attack. For each frame, we use an iterative orthogonal composition method for image content attack. During each iteration of orthogonal attack, we ﬁrst randomly generate several tangential perturbations whose noise levels are the same. Then, we compute their IoU scores and select the tangential perturbation with the lowest score. The selected perturbation is the most effective one to attack the current frame at the current iteration. We then increase the selected perturbation in its normal direction to add a small amount of noise, which is the normal perturbation. We compose both tangential and normal perturbations to generate the pertur-bations for the current iteration of orthogonal attack.
For target motion attack, we compute an IoU score be-tween the bbxs from both the current and the previous frames. This IoU score is integrated into the tangential per-turbation identiﬁcation process. To this end, our orthogonal attack deviates a deep tracker from its original performance of both the current and historical frames. We transfer the learned perturbations to the next few frames as perturbation initialization to reinforce temporal motion attack. As a re-sult, the deviation from the original tracking results ensures the success of black-box attack on deep trackers shown in
Figure 1. We extensively validate the proposed IoU attack on state-of-the-art methods including detection based [22], correlation ﬁlter based [1], and long-term [5] trackers. Ex-periments on benchmark datasets demonstrate the effective-ness of the proposed black-box IoU attack. 2.