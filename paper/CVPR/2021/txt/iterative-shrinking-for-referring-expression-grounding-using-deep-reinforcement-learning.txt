Abstract
In this paper, we are tackling the proposal-free referring expression grounding task, aiming at localizing the target object according to a query sentence, without relying on off-the-shelf object proposals. Existing proposal-free meth-ods employ a query-image matching branch to select the highest-score point in the image feature map as the target box center, with its width and height predicted by another branch. Such methods, however, fail to utilize the contextual relation between the target and reference objects, and lack interpretability on its reasoning procedure. To solve these problems, we propose an iterative shrinking mechanism to localize the target, where the shrinking direction is decided by a reinforcement learning agent, with all contents within the current image patch comprehensively considered. Be-sides, the sequential shrinking processes enable to demon-strate the reasoning about how to iteratively ﬁnd the tar-get. Experiments show that the proposed method boosts the accuracy by 4.32% against the previous state-of-the-art (SOTA) method on the RefCOCOg dataset, where query sentences are long and complex with many targets referred by other reference objects. 1.

Introduction
The aim of referring expression grounding (REG) is to recognize and localize the target object in an image accord-ing to its query sentence (referring expression), which re-quires joint comprehension in both visual and linguistic do-mains. REG is a fundamental multi-modality task, serv-ing as the basis for many downstream tasks, including the visual question answering [15, 4, 17, 54, 20, 1, 48], im-age caption [9, 5, 7, 34, 65, 49, 42], image-text matching
[25, 65, 3, 64, 6, 51, 21], etc. It attracts much attention from
∗corresponding author 1The work was supported by National Natural Science Foundation of
China under 61972323 and Key Program Special Fund in XJTLU under
KSF-T-02, KSF-P-02. https://github.com/insomnia94/ISREG
Figure 1. Illustration of the difference between (a) existing feature-point level matching methods, and (b) the proposed iterative shrinking method. The query sentence for the target in this im-age is “the cat above the shelf”.
In (a), dots depict the feature points within the image feature map, with the surrounding area representing its corresponding image region. Red dots indicate the feature points whose corresponding image regions may cover the target (i.e., the cat on the shelf) or distracting objects (i.e., cats on other places), while black dots are unrelated feature points. It can be observed that there is no such feature point whose image region can cover both the target object (i.e., cat) and the reference object (i.e., shelf). In (b), for each iteration, the area in the dashed box in-dicates the image patch after shrinking, and the red arrow depicts the shrinking direction, which is decided by comprehensively con-sidering all contents in the image patch before shrinking. both computer vision (CV) and natural language processing (NLP) areas in recent years.
Conventional methods formulate REG as a region-retrieval problem [61, 63, 56, 53, 26, 27, 10], with proposals of all candidate objects provided in advance. The candidate proposals can be either provided from the bounding box 14060
ground-truth or generated by a pre-trained object detector (e.g., Faster RCNN [38]). The matching networks of these
REG models predict the similarity score between the query and each proposal, with the highest-score proposal selected as the target object. In this way, conventional REG meth-ods highly rely on the ground-truth bounding boxes or an accurate object detector which requires a lot of extra data to train it in advance. To overcome these shortcomings, some proposal-free methods attempt to predict the REG re-sult without object proposals.
All existing proposal-free REG methods [22, 59, 41, 58] directly follow the pipeline of one-stage detector (e.g.,
YOLOv3 [37]) and adopt a two-branch style network, with the ﬁrst branch to calculate the similarity score between the query sentence and each feature point within the image fea-ture map, and the second branch to generate its bounding box coordinates. The predicted bounding box of the feature point with the highest score is viewed as the ﬁnal result.
These methods, with the matching process conducted be-tween the query sentence and each image feature point, per-form well for simple queries with the target described by its own attribute (e.g., “man in blue”), but it is difﬁcult for them to deal with complex queries, especially when the target is referred by another reference object. As can be observed from Fig.1.(a), since there is no such a feature point whose corresponding image region covers both the target “cat” and the reference object “shelf”, the contextual relation between the target and the reference object, serving as the key to dis-tinguish the target from other distracting objects, cannot be fully utilized in such a matching process. Thus, the REG performance is greatly compromised.
Another shortcoming of these methods is lack of in-terpretability. As the matching network predicts the ﬁnal matching scores of all feature points in one step, its inner reasoning procedure is hidden and invisible. Thus, if the matching model fails, it is formidable to analyze the causes.
To tackle these problems simultaneously, we formal-ize REG as a sequence of image-level shrinking processes.
Within each iteration, the image shrinks along a certain di-rection, with a non-target image region removed. After sev-eral shrinking iterations, only the target image region re-mains, and it is viewed as the ﬁnal result. The shrinking di-rection in each iteration is predicted by a trainable network.
As the optimal shrinking direction is uncertain for each it-eration, conventional supervised training is not suited. We propose to model it as a Markov decision process [14] and adopt reinforcement learning (RL) to tackle it. RL only re-quires a “feedback” or “reward” after each shrinking step, rather than the exact supervision label. Besides, RL consid-ers not only the current reward but also the potential reward in future, which further improves the performance.
Our proposed method can better utilize the contextual re-lation between the target and reference objects because the shrinking direction is decided by comprehensively consid-ering all objects within the current image patch. For an in-stance, as shown in Fig.1.(b), in the ﬁrst iteration, the image region where a black cat lies on the chair is removed (i.e., shrinking towards right), because “chair” does not occur in the query. In the second iteration, after analyzing the spatial relation between each candidate cat and the reference ob-ject “shelf”, it is decided to remove the image region where a cat lies inside the shelf (i.e., shrinking towards top), due to its mismatching spatial relation against the query. Ulti-mately, only the image region accurately covering the target cat remains. As the relation information in a query is fully utilized, the proposed method can better deal with complex queries and images (e.g., RefCOCOg [30]), whilst existing matching methods fail to handle such cases (Fig.1.(a)).
To sum up, this paper has three main contributions:
• We make the earliest attempt to solve REG as a condi-tional decision-making process and build the ﬁrst RL-based REG framework. Thanks to these iterative de-cisions, the reasoning about how to localize the target can be visualized step by step.
• We formalize REG as a sequence of image-level shrinking processes, with the shrinking direction in each iteration decided by an RL agent after compre-hensively considering all objects in the image patch, allowing the relation information in a query to be fully utilized.
• The proposed method boosts the accuracy by 4.32% against the previous SOTA method [22] on the Ref-COCOg dataset, where query sentences are long and complex, with many targets referred by other reference objects. An average accuracy gain of 1.33% on Ref-COCOg, RefCOCO+ and RefCOCO is also achieved. 2.