Abstract
We present a method to estimate dense depth by optimizing a sparse set of points such that their diffusion into a depth map minimizes a multi-view reprojection error from RGB supervision.
We optimize point positions, depths, and weights with respect to the loss by differential splatting that models points as Gaussians with analytic transmittance. Further, we develop an efficient optimization routine that can simultaneously optimize the 50k+ points required for complex scene reconstruction. We validate our routine using ground truth data and show high reconstruc-tion quality. Then, we apply this to light field and wider baseline images via self supervision, and show improvements in both av-erage and outlier error for depth maps diffused from inaccurate sparse points. Finally, we compare qualitative and quantitative results to image processing and deep learning methods. 1.

Introduction
In multi-view reconstruction problems, estimating dense depth can be difficult for pixels in smooth regions. As such, 2D diffusion-based techniques [19, 8] perform gradient-based densification using only a sparse set of depth labels in image space. These assume smoothness between points to densify the point set. Smoothness can be a good assumption; for instance, many indoor scenes have low texture walls and adhere to the basic assumption that diffusion implies. But, diffusion from noisy point samples may produce results with lower accuracy, and it can be difficult to identify and filter out noisy or erroneous points from a sparse set. However, given the correct noise-free constraints, diffusion can be shown to produce comparable or better results than state-of-the-art dense processing methods.
So, how can we handle noisy points? We present a method to optimize point constraints for a set of linear equations rep-resenting the solution to the standard Poisson problem of depth diffusion. For this, we develop a differentiable and occlusion-aware image-space representation for a sparse set of scene points that allows us to solve the inverse problem efficiently using gra-dient descent. We treat each point as a Gaussian to be splatted into the camera, and use the setting of radiative energy transfer through participating media to model the occlusion interaction between Gaussians. This method allows us to optimize over po-sition, depth, and weight parameters per point, and to optimize the point set via reprojection error from multiple RGB images.
Figure 1: Left: Diffusion from an noisy point set produces sig-nificant errors from points found along RGB edges instead of depth edges (top, log absolute error). In the background, smooth depth regions have banding; in the foreground, RGB texture de-tails are pulled into the depth causing outliers on the floor. Right:
Our differentiable point optimization reduces error across the image, removing banding errors and minimizing texture pull.
On synthetic and real-world data across narrow-baseline light field multi-view data, and with initial results on wider-baseline unstructured data, we show that our method reduces significant diffusion errors caused by noisy or spurious points. Further, we discuss why edges are difficult to optimize via reprojection from depth maps. Finally, in comparisons to both image processing and deep learning baselines, our method shows competitive performance especially in reducing bad pixels. Put together, we show the promise of direct point optimization for diffusion-based dense depth estimation.
Data, code, and results: visual.cs.brown.edu/diffdiffdepth 2.