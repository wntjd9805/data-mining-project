Abstract
We propose a novel lossy image and residual joint compression framework for learning ℓ∞-constrained near-lossless image compression. Speciﬁcally, we obtain a lossy reconstruction of the raw image through lossy image com-pression and uniformly quantize the corresponding resid-ual to satisfy a given tight ℓ∞ error bound. Suppose that the error bound is zero, i.e., lossless image compression, we formulate the joint optimization problem of compress-ing both the lossy image and the original residual in terms of variational auto-encoders and solve it with end-to-end training. To achieve scalable compression with the error bound larger than zero, we derive the probability model of the quantized residual by quantizing the learned prob-ability model of the original residual, instead of training multiple networks. We further correct the bias of the de-rived probability model caused by the context mismatch be-tween training and inference. Finally, the quantized resid-ual is encoded according to the bias-corrected probability model and is concatenated with the bitstream of the com-pressed lossy image. Experimental results demonstrate that our near-lossless codec achieves the state-of-the-art per-formance for lossless and near-lossless image compression, and achieves competitive PSNR while much smaller ℓ∞ er-ror compared with lossy image codecs at high bit rates. 1.

Introduction
Image compression is a ubiquitous technique in com-puter vision. For certain applications with stringent de-mands on image ﬁdelity, such as medical imaging or image archiving, the most reliable choice is lossless image com-pression. However, the compression ratio of lossless com-pression is upper-bounded by Shannon’s source coding the-orem [36], and is typically between 2:1 and 3:1 for practical lossless image codecs [50, 47, 37, 14, 5, 38]. To improve the compression performance while keeping the reliability
∗Corresponding author of the decoded images, ℓ∞-constrained near-lossless image compression is developed [6, 15, 2, 47, 51] and standardized in traditional codecs, e.g., JPEG-LS [47] and CALIC [51].
Different from lossy image compression with Peak Signal-to-Noise Ratio (PSNR) or Multi-Scale Structural SIMilar-ity index (MS-SSIM) [45, 46] distortion measures, ℓ∞-constrained near-lossless image compression requires the maximum reconstruction error of each pixel to be no larger than a given tight numerical bound. Lossless image com-pression is a special case of near-lossless image compres-sion, when the tight error bound is zero.
With the fast development of deep neural networks (DNNs), learning-based lossy image compression [40, 3, 39, 41, 34, 24, 4, 31, 27, 22, 8, 7, 23, 25, 29] has achieved tremendous progress over the last four years. Most re-cent methods for lossy image compression adopt variational auto-encoder (VAE) architecture [17, 18] based on trans-form coding [11], where the rate is modeled by the entropy of quantized latent variables and the reconstruction distor-tion is measured by PSNR or MS-SSIM. Through end-to-end rate-distortion optimization, the state-of-the-art meth-ods, such as [7], can achieve comparable performance with the lastest compression standard Versatile Video Coding (VVC) [32]. However, the above transform coding scheme cannot be directly employed on near-lossless image com-pression, because it is difﬁcult for DNN-based transforms to satisfy a tight bound on the maximum reconstruction error of each pixel, even without quantization. Invertible trans-forms, such as integer discrete ﬂow [13] or wavelet-like transform [25], are possible solutions to lossless compres-sion but not to general near-lossless compression.
In this paper, we propose a new joint lossy image and residual compression framework for learning near-lossless image compression, inspired by the traditional “lossy plus residual” coding scheme [10, 26, 2]. Speciﬁcally, we obtain a lossy reconstruction of the raw image through lossy im-age compression and uniformly quantize the corresponding residual to satisfy the given ℓ∞ error bound τ . Suppose that the error bound τ is zero, i.e., lossless image compression, we formulate the joint optimization problem of compress-11946
ing both the lossy image and the original residual in terms of
VAEs [17, 18], and solve it with end-to-end training. Note that our VAE model is novel, different from transform cod-ing based VAEs [3, 39, 4] for simply lossy image compres-sion or bits-back coding based VAEs [42, 19] for lossless image compression.
To achieve scalable near-lossless compression with error bound τ > 0, we derive the probability model of the quan-tized residual by quantizing the learned probability model of the original residual at τ = 0, instead of training mul-tiple networks. Because residual quantization leads to the context mismatch between training and inference, we fur-ther propose a bias correction scheme to correct the bias of the derived probability model. An arithmetic coder [48] is adopted to encode the quantized residual according to the bias-corrected probability model. Finally, the near-lossless compressed image is stored including the bitstreams of the encoded lossy image and the quantized residual.
Our main contributions are summarized as follows:
• We propose a joint lossy image and residual compression framework to realize learning-based lossless and near-lossless image compression. The framework is inter-preted as a VAE model and can be end-to-end optimized.
• We realize scalable compression by deriving the proba-bility model of the quantized residual from the learned instead of probability model of the original residual, training multiple networks. A bias correction scheme fur-ther improves the compression performance.
• Our codec achieves the state-of-the-art performance for lossless and near-lossless image compression, and achieves competitive PSNR while much smaller ℓ∞ er-ror compared with lossy image codecs at high bit rates. 2.