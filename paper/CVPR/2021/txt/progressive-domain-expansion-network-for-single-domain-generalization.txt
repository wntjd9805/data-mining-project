Abstract
Single domain generalization is a challenging case of model generalization, where the models are trained on a single domain and tested on other unseen domains. A promising solution is to learn cross-domain invariant rep-resentations by expanding the coverage of the training do-main. These methods have limited generalization perfor-mance gains in practical applications due to the lack of ap-propriate safety and effectiveness constraints. In this pa-per, we propose a novel learning framework called pro-gressive domain expansion network (PDEN) for single do-main generalization. The domain expansion subnetwork and representation learning subnetwork in PDEN mutu-ally beneﬁt from each other by joint learning. For the domain expansion subnetwork, multiple domains are pro-gressively generated in order to simulate various photo-metric and geometric transforms in unseen domains. A series of strategies are introduced to guarantee the safety and effectiveness of the expanded domains. For the do-main invariant representation learning subnetwork, con-trastive learning is introduced to learn the domain invari-ant representation in which each class is well clustered so that a better decision boundary can be learned to improve it’s generalization. Extensive experiments on classiﬁcation and segmentation have shown that PDEN can achieve up to 15.28% improvement compared with the state-of-the-art single-domain generalization methods. Codes will be re-leased soon at https://github.com/lileicv/PDEN 1.

Introduction
In this paper, we deﬁne domains as various distributions of objects appearance caused by different external condi-tions(such as weather, background, illumination etc.) or in-*Corresponding author (a) The traditional decision bound-ary learned with the original train-ing domain. (b) The new decision boundary learned with our progressively ex-panded domains. (c) Domain generalization scenario
Figure 1. The illustration of our PDEN for single domain general-ization. The tiny images in (a) and (b) with red border denote the source domain and the one with green border denote the expanded domains with our PDEN. trinsic attributes(such as color, texture, pose etc.), as shown in Fig.1. The performance of a deep model usually drops when applied to unseen domains. For example, The accu-racy of the CNN model(trained on MNIST) on MNIST test set is 99%, while that on SVHN test set is only 30%. Model generalization is important to machine learning.
Two solutions have been proposed to deal with the above issue, namely, domain adaptation [10, 30, 36, 9] and do-main generalization [29, 11, 12, 16]. Domain adaptation aims to generalize to a known target domain whose labels are unknown. Distribution alignment(e.g., MMD) and style 224
transfer(e.g., CycleGAN) are frequently used in these meth-ods to learn domain-invariant features. However, it requires data from the target domain to train the model, which is dif-ﬁcult to achieve in many tasks due to lack of data.
Domain generalization, which not requires access to any data from the unseen target domain, can solve these prob-lems. The idea of domain generalization is to learn a domain-agnostic model from one or multiple source do-mains. Particularity, in many ﬁelds we are usually faced with the challenge of giving a single source domain, which is deﬁned as single domain generalization [33]. Recently, studies have made progress on this task [34, 45, 38, 40, 33, 46]. All of these methods, which are essentially data augmentation, improve the robustness of the model to the unseen domain by extending the distribution of the source domain. Speciﬁcally, additional samples are generated by manually selecting the augmentation type[45, 34] or by learning the augmentation through neural networks[33, 46].
Data augmentation has proved to be an important means for improving model generalization [44]. However, such methods require the selection of an augmentation type and magnitude based on the target domain, which is difﬁcult to achieve in other tasks. They cannot guarantee the safety and effectiveness of synthetic data or even reduce accuracy.
[42, 20].
In this paper, we propose the progressive domain expan-sion network (PDEN) to solve the single domain general-ization problem. Task models and generators in PDEN mu-tually beneﬁt from each other through joint learning. Safe and effective domains are generated by the generator under the precise guidance of the task model. The generated do-mains are progressively expanded to increase the coverage and improve the completeness. Contrastive learning is in-troduced to learn the cross-domain invariant representation with all the generated domains. It is noteworthy that we can
ﬂexibly replace the generator in PDEN to achieve different types of domain expansion.
Our main contributions are as follows:
• We propose a novel framework called progressive do-main expansion network (PDEN) for single domain generalization. The PDEN contains domain expansion subnetwork and domain invariant representation learn-ing subnetwork, which mutually beneﬁt from each other by joint learning.
• For the domain expansion subnetwork, multiple do-mains are progressively generated to simulate various photometric and geometric transforms in unseen do-mains. A series of strategies are introduced to guaran-tee the safety and effectiveness of these domains.
• For the domain invariant representation learning sub-network, contrastive learning is introduced to learn the domain invariant representation in which each class is well clustered so that a better decision boundary can be learned to improve it’s generalization.
• Extensive experiments on classiﬁcation and segmen-tation have shown the superior performance of our method. The proposed method can achieve up to 15.28% improvement compared with other single-domain generalization methods. 2.