Abstract
Recent supervised multi-view depth estimation networks have achieved promising results.
Similar to all super-vised approaches, these networks require ground-truth data during training. However, collecting a large amount of multi-view depth data is very challenging. Here, we pro-pose a self-supervised learning framework for multi-view stereo that exploit pseudo labels from the input data. We start by learning to estimate depth maps as initial pseudo labels under an unsupervised learning framework rely-ing on image reconstruction loss as supervision. We then reﬁne the initial pseudo labels using a carefully de-signed pipeline leveraging depth information inferred from a higher resolution image and neighboring views. We use these high-quality pseudo labels as the supervision sig-nal to train the network and improve, iteratively, its per-formance by self-training. Extensive experiments on the
DTU dataset show that our proposed self-supervised learn-ing framework outperforms existing unsupervised multi-view stereo networks by a large margin and performs on par compared to the supervised counterpart. Code is available at https://github.com/JiayuYANG/
Self-supervised-CVP-MVSNet. 1.

Introduction
The goal of Multi-view Stereo (MVS) is to reconstruct the 3D model of a scene from a set of images captured at multiple viewpoints. While this problem has been studied for decades [19], the current best performance is achieved by cost-volume based supervised deep neural networks for
MVS [23, 24, 22, 9, 5, 21]. The success of these networks mainly relies on large amount of ground truth depth as train-ing data, which is generally captured by expensive and mul-tiple synchronized images and depth sensors.
The use of synthetic data is considered a good alternative to handle the main challenges in collecting training data for
MVS [25]. Given a set of 3D scene models with a proper setting of lighting conditions, we can obtain a large num-ber of synthetic multiple view images with ground truth depths [25]. While it is possible to train the network us-ing this synthetic data, for successfully deploying the model in real scenes, we still require to ﬁne-tune the model us-ing data from the target domain [16]. Another alternative is adopting an unsupervised learning strategy [6, 13]. In this case, the few existing unsupervised MVS approaches use an image reconstruction loss to supervise the training pro-cess. This training strategy heavily relies on image colors’ photometric consistency for multiple views images, which is sensitive to illumination changes. While both alternatives remove the dependency on depth labels, their performance is far inferior compared to their corresponding supervised counterparts on the target domain.
In this paper, we propose a self-supervised learning framework for depth inference from multi-view images.
Our goal is to generate high-quality depth maps as pseudo labels for training the network only from multiple view images. To this end, we ﬁrst rely on an image recon-7526
struction loss to supervise the training of a cost-volume based depth inference network. We then use this unsuper-vised network to infer depth maps as pseudo labels for self-supervision [15]. While our unsupervised network can es-timate accurate depth for pixels with rich textures and sat-isfying color consistency across views, these pseudo depth labels still contain a large amount of noise.
To reﬁne the pseudo labels, we ﬁrst propose to infer depth from a higher resolution image than the required training image to obtain depth estimates of higher accuracy for trustful pixels. Then, we ﬁlter depth with large errors by leveraging depth information from neighboring views and,
ﬁnally, use multi-view depth fusion, mesh generation, and depth rendering to ﬁll in the incomplete pseudo depth la-bels. With our carefully designed pipeline, we improve the pseudo labels’ quality; and use them for training the net-work, improving its performance within a few iterations.
Our contributions can be summarized as follows:
• We propose a self-supervised learning framework for multi-view depth estimation.
• We generate an initial set of pseudo depth labels from an unsupervised learning network and then improve their quality with a carefully designed pipeline to use them to supervise the network yielding performance improvements.
Our extensive set of experiments demonstrate that the pro-posed self-supervised framework outperforms existing un-supervised MVS networks by a large margin and performs on par compared to the supervised counterpart. 2.