Abstract
Deep face recognition has achieved remarkable im-provements due to the introduction of margin-based soft-max loss, in which the prototype stored in the last linear layer represents the center of each class. In these methods, training samples are enforced to be close to positive pro-totypes and far apart from negative prototypes by a clear margin. However, we argue that prototype learning only employs sample-to-prototype comparisons without consid-ering sample-to-sample comparisons during training and the low loss value gives us an illusion of perfect feature embedding, impeding the further exploration of SGD. To this end, we propose Variational Prototype Learning (VPL), which represents every class as a distribution instead of a point in the latent space. By identifying the slow feature drift phenomenon, we directly inject memorized features into prototypes to approximate variational prototype sam-pling. The proposed VPL can simulate sample-to-sample comparisons within the classiﬁcation framework, encour-aging the SGD solver to be more exploratory, while boost-ing performance. Moreover, VPL is conceptually simple, easy to implement, computationally efﬁcient and memory saving. We present extensive experimental results on pop-ular benchmarks, which demonstrate the superiority of the proposed VPL method over the state-of-the-art competitors. 1.

Introduction
Recent state-of-the-art face recognition methods [35, 28, 45, 8, 41, 19] mainly focus on employing margin penalty to enhance the discriminative feature embedding. The pi-oneering work [35] uses the Triplet loss to enforce faces from the same class to be closer than faces from different classes, by a clear margin in the Euclidean space. However,
* Equal contributions.
InsightFace is a nonproﬁt Github project for 2D and 3D face analysis. (a) Prototype Learning (b) Variational Prototype Learning
Figure 1: Difference between the Prototype Learning (PL) and the proposed Variational Prototype Learning (VPL). The prototype learning (e.g. softmax loss) employs sample-to-prototype compar-isons and represents every class as a point in the latent space. By contrast, the proposed VPL represents every class as a distribu-tion in order to simulate sample-to-sample comparison within the classiﬁcation framework. the sample-to-sample comparisons in the Triplet loss are constrained to the local mini-batch, and therefore sophis-ticated mining strategies are required to choose an infor-mative mini-batch [34, 35] and select representative triplets within the mini-batch [52, 33, 40]. On large-scale datasets
[31, 13], there is a combinatorial explosion in the num-ber of triplets, which results in an immensely complicated mining step. To this end, margin-based softmax meth-ods [28, 5, 45, 43, 8, 41, 19] introduce a margin penalty into the prototype learning and conduct global comparisons between training samples and class-wise prototypes. The sample-to-prototype comparison is more efﬁcient and stable than the sample-to-sample comparison, as (a) the prototype number is much smaller than the sample number, and (b) both the class-wise prototype and the embedding network are optimized in every iteration during training. In that man-ner, the prototypes try to memorize positive features and forget negative features, while the embedding features try to get close to positive prototypes and keep far apart from negative prototypes. 11906
Even though the margin-based softmax methods show great efﬁciency, stability and capability in face recognition, each class is only represented by one point in the latent space, bearing no variation information, as shown in Fig. 1(a). There exists abundant literature on modeling the faces as subspaces [42, 3, 48, 7], manifolds [17, 20] or probabilis-tic distributions [37, 1] in the feature space. In these works, each class is represented by a group of discrete points or a continuous distribution in the latent space, instead of one point. In fact, representing each class by one point as in the prototype learning can sometimes lead to model degener-ation. In real-world applications, the face training data in-herently follows an unbalanced distribution [56, 59, 61, 11], where some identities have plenty of samples, while other identities only contain very few samples. In Sec. 4.2, our derivative analysis indicates that the prototype is learned by continually absorbing positive sample features and elimi-nating negative sample features. When data becomes shal-low, there are limited intra-class variations and the proto-type vector can easily remember all samples within one class [11]. For instance, consider one training identity with only two facial images and the corresponding deep features x1 and x2. If the prototype can learn to remember the cen-troid (x1 + x2)/2, regardless of the degree of similarity be-tween x1 and x2, the sample-to-prototype similarities can be very high. Therefore, the single point representation of the prototype can sometimes hinder the further exploration of the SGD solver, and thus the model may converge at sub-optimal local-minima.
To deal with the aforementioned model degeneration, re-cent methods attempt to either improve the margin values for the tail classes [27] or recall the beneﬁt from sample-to-sample comparisons [61, 11]. AdaptiveFace [27] pro-poses adaptive margins for rich and poor classes. CVC
[61] employs sample features to initialize the prototypes.
SST [11] employs the semi-Siamese networks and con-structs a dynamic queue with gallery features to replace original prototypes. However, each method introduces signiﬁcant trade-offs. The margin average loss proposed in [27] only enforces the margin values to increase for all classes, which can lead to over-ﬁtting on the training data. The classiﬁcation-veriﬁcation-classiﬁcation strategy proposed in [61] is not an end-to-end solution, and its step-wise ﬁne-tuning is arduous. The Semi-Siamese networks proposed in [11] employ a probe-set network to embed the probe features and another gallery-set network to update prototypes by gallery features, which results in additional memory consumption. Finally, CVC [61] and SST [11] are only designed to tackle the bisample problem instead of handling general deep face recognition.
In this paper, we ﬁrst identify the limitations of pro-totype learning, which represents each class as a point in the latent space and employs sample-to-prototype compar-isons during training without considering class-wise vari-ations. This single point approximation of class represen-tation facilitates the network training but also impedes the further exploration of SGD. To this end, we propose the
Variational Prototype Learning (VPL) which represents ev-ery class as a distribution instead of a point in the latent space, as illustrated in Fig. 1(b). Based on the observation of slow feature drift phenomenon after the early phase of training, we directly inject memorized features from recent mini-batches into the corresponding prototypes to approx-imate variational prototype sampling. The proposed VPL can easily simulate sample-to-sample comparisons within the classiﬁcation framework, encouraging the SGD solver to be more exploratory and boosting performance consider-ably.
To summarize, our key contributions are:
• We point out the limitations of the prototype learning and propose a novel Variational Prototype Learning (VPL) method which represents each class as a dis-tribution instead of a point in the latent space.
• Based on the observation of slow feature drift, we de-sign a computationally efﬁcient and memory-saving way for the variational prototype sampling, that is, in-jecting memorized features into the corresponding pro-totypes. In our VPL, both sample-to-prototype com-parisons and sample-to-sample comparisons are ex-ploited.
• The proposed VPL is a plug-and-play module, provid-ing an orthogonal improvement to recent margin-based or mining-based softmax methods. Extensive experi-mental results on popular benchmarks demonstrate the superiority of our VPL over the state-of-the-art com-petitors in deep face recognition. 2.