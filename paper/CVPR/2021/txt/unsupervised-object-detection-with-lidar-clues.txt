Abstract
Despite the importance of unsupervised object detection, to the best of our knowledge, there is no previous work addressing this problem. One main issue, widely known to the community, is that object boundaries derived only from 2D image appearance are ambiguous and unreliable.
To address this, we exploit LiDAR clues to aid unsuper-vised object detection. By exploiting the 3D scene struc-ture, the issue of localization can be considerably mitigated.
We further identify another major issue, seldom noticed by the community, that the long-tailed and open-ended (sub-In this
)category distribution should be accommodated. paper, we present the ﬁrst practical method for unsuper-vised object detection with the aid of LiDAR clues. In our approach, candidate object segments based on 3D point clouds are ﬁrstly generated. Then, an iterative segment la-beling process is conducted to assign segment labels and to train a segment labeling network, which is based on fea-tures from both 2D images and 3D point clouds. The la-beling process is carefully designed so as to mitigate the issue of long-tailed and open-ended distribution. The ﬁ-nal segment labels are set as pseudo annotations for object detection network training. Extensive experiments on the large-scale Waymo Open dataset suggest that the derived unsupervised object detection method achieves reasonable accuracy compared with that of strong supervision within the LiDAR visible range. 1.

Introduction
Unsupervised object detection requires localization and classiﬁcation of object instances without manual annota-tions in 2D images. Due to the importance of the prob-lem, various relevant tasks have been studied. For exam-ple, some weakly-supervised object detection methods [18, 22, 5, 43, 74] seek to detect objects with image-level anno-*Equal contribution. † This work is done when Hao Tian and Yuntao
Chen are interns at SenseTime Research.
Figure 1: Illustration of the proposed approach. tations only, while some semi-supervised object detection methods [62, 41, 73] are trained on both bounding box an-notated data and additional massive unlabeled images. Un-supervised object proposal generation [12, 25, 77, 67, 1] has also been widely studied. However, to the best of our knowledge, there is no previous work addressing the unsu-pervised object detection problem.
Recently, considerable progress has been made in un-supervised feature learning [55]. The networks with the unsupervised learned features achieve accuracies on par with those of strong supervision when ﬁne-tuned on down-stream tasks.
In this trend, some cluster discrimination based methods [85, 42, 35, 9, 91, 13, 79] have tried to ad-dress the unsupervised image classiﬁcation problem. Com-petitive results compared with semi-supervised learning on
ImageNet [21] are obtained in [79]. However, there is still a signiﬁcant gap between unsupervised classiﬁcation and un-supervised object detection, which involves both localizing and classifying multiple object instances in images.
One widely-known issue for unsupervised object detec-5962
(a) unlabeled categories. (b) semantic sub-groups in the ‘vehicles’ category.
Figure 2: Examples of object categories and semantic sub-groups discovered in the training images, which are not annotated in the Waymo Open dataset [71]. tion is how to localize object instances precisely from the cluttered background without any human annotations. Un-supervised object localization from 2D images is extremely challenging because objects are of heterogeneous colors and textures with various shapes and occlusions. For exam-ple, unsupervised object proposals are usually generated by merging over-segmented regions according to color or tex-ture clues [12, 25, 77, 67, 1], which suffer from ambiguous and unreliable object boundaries. Although the object re-call rate can be satisfactory with large proposal numbers, the precision rate is very low due to the ambiguities.
For the localization challenge, we argue that the key missing piece is the 3D scene structure, which is essen-tial for human vision. Object boundaries can be better dis-tinguished in the 3D point cloud because different objects cannot occupy the same 3D location. On the other hand, 3D shape information can also be used to better classify ob-jects. Thanks to the popularization of LiDAR sensors, such synchronized 2D images and 3D point clouds have become much easier to obtain. Here we choose to generate can-didate object segments based on 3D topology and to learn to label these segments into different categories / clusters1.
The labeling predictions are also based on features of both 2D images and 3D point clouds.
With the localization issue mitigated, we further iden-tify another major issue, seldom noticed by the com-munity: accommodating the long-tailed and open-ended (sub-)category distribution in unsupervised object detec-tion. Research works in unsupervised classiﬁcation [85, 42, 35, 9, 91, 13, 79] are mostly experimented on bal-anced and closed-world datasets (e.g., ImageNet [21] and
CIFAR [45]), which consist of known number of categories with balanced number of images. In unsupervised object proposal generation [12, 25, 77, 67, 1], all the object cat-1The predictions made by our approach are actually of clusters because no annotations are utilized. But for the coherence of terminology, we use the term categories without confusion in the paper. egories merge into one single class of foreground objects.
Thus, the long-tail and open-ended distribution problem does not bother. However, for object detection, the datasets (e.g., LVIS [34] and Open Images [47]) often have a long-tailed distribution, due to the nature of natural scenes. In the situation of unsupervised object detection, the difﬁculty is even further magniﬁed, where the actual number of ap-peared object categories is unknown. Besides, the long-tailed and open-ended distribution not only exists in object categories but also exists in different semantic sub-groups (e.g., different views, poses) of the same object category.
There is no hint which sub-groups belong to the same cat-egory till ﬁnal evaluation or human examination. These se-mantic sub-groups need to be accurately discovered and de-tected so as to capture the whole semantic categories. The challenge of long-tailed and open-ended distribution brings difﬁculty for the labeling of candidate object segments. The head categories contain many object segments, while the tail categories contain very few. Proper labeling mechanism is necessary so as to avoid the tail categories being buried with the cluttered background.
This paper presents the ﬁrst practical method for unsu-pervised object detection with the aid of LiDAR clues. The input is a training set composed of synchronized 2D image and 3D point cloud pairs without any type of human an-notations, while the output is an object detection network applicable to 2D images. Our approach is illustrated in Fig-ure 1. For each training pair, candidate object segments are
ﬁrst extracted from the 3D point cloud, based on the 3D topology instead of 2D image appearance.
Iterative seg-ment labeling is then conducted to assign segment labels and to train a segment labeling network, assuming segments with similar 2D image appearances and 3D shapes are of the same category. Such iterative optimization makes the pre-dicted categories ﬁt the long-tailed and open-ended distri-butions. The ﬁnal segment labels are set as pseudo annota-tions for object detection network training. During testing, 5963
the trained detection network is applied to 2D images.
In iterative labeling, the segment labeling network and its training mechanism are carefully designed to accommo-date the nature of the long-tailed and open-ended distribu-tion. In the segment labeling network, motivated by [72], we cancel the competition among foreground categories to prevent misclassifying objects in tail categories as back-ground. During network training, only segments labeled as foreground are utilized to provide training losses, to avoid the impact of those foreground segments wrongly labeled as background. The negative examples are generated by jit-tering the segments labeled as foreground. Starting from a large number of allowed object categories (10,000 by de-fault), our approach will automatically discover the effec-tive number and distribution of appeared categories.
Extensive experiments on the large-scale Waymo Open dataset [71] suggest that the derived unsupervised object detection method achieves reasonable accuracy compared with that of strong supervision within the LiDAR visible range. Besides, our approach can detect object categories appear in the training images but are not annotated in the dataset, such as ‘trash bin’, ‘trafﬁc sign’, and ‘ﬁre hydrant’.
Figure 2 and Figure 4 show some example results of our proposed approach. Code shall be released. 2.