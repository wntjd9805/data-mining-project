Abstract
Linguistic knowledge is of great beneﬁt to scene text recognition. However, how to effectively model linguistic rules in end-to-end deep networks remains a research chal-lenge.
In this paper, we argue that the limited capacity of language models comes from: 1) implicitly language modeling; 2) unidirectional feature representation; and 3) language model with noise input. Correspondingly, we pro-pose an autonomous, bidirectional and iterative ABINet for scene text recognition. Firstly, the autonomous suggests to block gradient ﬂow between vision and language models to enforce explicitly language modeling. Secondly, a novel bidirectional cloze network (BCN) as the language model is proposed based on bidirectional feature representation.
Thirdly, we propose an execution manner of iterative correc-tion for language model which can effectively alleviate the impact of noise input. Additionally, based on the ensemble of iterative predictions, we propose a self-training method which can learn from unlabeled images effectively. Extensive experiments indicate that ABINet has superiority on low-quality images and achieves state-of-the-art results on sev-eral mainstream benchmarks. Besides, the ABINet trained with ensemble self-training shows promising improvement in realizing human-level recognition. Code is available at https://github.com/FangShancheng/ABINet. 1.

Introduction
Possessing the capability of reading text from scene im-ages is indispensable to artiﬁcial intelligence [24, 41, 45].
To this end, early attempts regard characters as meaningless symbols and recognize the symbols by classiﬁcation mod-els [42, 15, 46]. However, when confronted with challenging environments such as occlusion, blur, noise, etc., it becomes faint due to out of visual discrimination. Fortunately, as text carries rich linguistic information, characters can be reasoned according to the context. Therefore, a bunch of
*The corresponding author methods [16, 14, 29, 48] turn their attention to language modeling and achieve undoubted improvement.
However, how to effectively model the linguistic behavior in human reading is still an open problem. From the observa-tions of psychology, we can make three assumptions about human reading that language modeling is autonomous, bidi-rectional and iterative: 1) as both deaf-mute and blind people could have fully functional vision and language separately, we use the term autonomous to interpret the independence of learning between vision and language. The autonomous also implies a good interaction between vision and language that independently learned language knowledge could contribute to the recognition of characters in vision. 2) The action of reasoning character context behaves like cloze task since illegible characters can be viewed as blanks. Thus, predic-tion can be made using the cues of legible characters on the left side and right side of the illegible characters simultane-ously, which is corresponding to the bidirectional. 3) The iterative describes that under the challenging environments, humans adopt a progressive strategy to improve prediction conﬁdence by iteratively correcting the recognized results.
Firstly, applying the autonomous principle to scene text recognition (STR) means that recognition models should be decoupled into vision model (VM) and language model (LM), and the sub-models could be served as func-tional units independently and learned separately. Recent attention-based methods typically design LMs based on
RNNs or Transformer [39], where the linguistic rules are learned implicitly within a coupled model [19, 36, 33] (Fig. 1a). Nevertheless, whether and how well the LMs learn character relationship is unknowable. Besides, this kind of methods is infeasible to capture rich prior knowledge by directly pre-training LM from large-scale unlabeled text.
Secondly, compared with the unidirectional LMs [38],
LMs with bidirectional principle capture twice the amount of information. A straightforward way to construct a bidirec-tional model is to merge a left-to-right model and a right-to-left model [28, 5], either in probability-level [44, 36] or in feature-level [52] (Fig. 1e). However, they are strictly less powerful as their language features are unidirectional repre-7098
sentation in fact. Also, the ensemble models mean twice as expensive both in computations and parameters. A recent striking work in NLP is BERT [5], which introduces a deep bidirectional representation learned by masking text tokens.
Directly applying BERT to STR requires masking all the characters within a text instance, whereas this is extremely expensive since each time only one character can be masked.
Thirdly, LMs executed with iterative principle can re-ﬁne the prediction from visual and linguistic cues, which is not explored in current methods. The canonical way to perform an LM is auto-regression [44, 3, 47] (Fig. 1d), in which error recognition is accumulated as noise and taken as input for the following prediction. To adapt the Transformer architectures, [25, 52] give up auto-regression and adopt parallel-prediction (Fig. 1e) to improve efﬁciency. However, noise input still exists in parallel-prediction where errors from VM output directly harm the LM accuracy. In addi-tion, parallel-prediction in SRN [52] suffers from unaligned-length problem that SRN is tough to infer correct characters if text length is wrongly predicted by VM.
Considering the deﬁciencies of current methods from the aspects of internal interaction, feature representation and execution manner, we propose ABINet guided by the princi-ples of Autonomous, Bidirectional and Iterative. Firstly, we explore a decoupled method (Fig. 1b) by blocking gradient
ﬂow (BGF) between VM and LM, which enforces LM to learn linguistic rules explicitly. Besides, both VM and LM are autonomous units and could be pre-trained from images and text separately. Secondly, we design a novel bidirec-tional cloze network (BCN) as the LM, which eliminates the dilemma of combining two unidirectional models (Fig. 1c).
The BCN is jointly conditioned on both left and right con-text, by specifying attention masks to control the accessing of both side characters. Also, accessing across steps is not allowed to prevent leaking information. Thirdly, we propose an execution manner of iterative correction for LM (Fig. 1b).
By feeding the outputs of ABINet into LM repeatedly, predic-tions can be reﬁned progressively and the unaligned-length problem could be alleviated to a certain extent. Additionally, treating the iterative predictions as an ensemble, a semi-supervised method is explored based on self-training, which exploits a new solution toward human-level recognition.
Contributions of this paper mainly include: 1) we propose autonomous, bidirectional and iterative principles to guide the design of LM in STR. Under these principles the LM is a functional unit, which is required to extract bidirectional representation and correct prediction iteratively. 2) A novel
BCN is introduced, which estimates the probability distribu-tion of characters like cloze tasks using bidirectional repre-sentation. 3) The proposed ABINet achieves state-of-the-art (SOTA) performance on mainstream benchmarks, and the
ABINet trained with ensemble self-training shows promising improvement in realizing human-level recognition. text text
Language
Language text y1 y2 yn feature
Fusion
Trm
Trm
Trm
Vison image (a)
Vison image (b) y1` y2
`   ` yn yn (c) y1 y2
<e> 
<e> y1 yn
<e>
RNN
RNN
RNN
Trm
Trm
Trm
Trm
Trm
Trm
<s> y1 (d) yn y1
` y2
`
<s>
<s>
`  yn-1 yn
` right-to-left (e) left-to-right
Figure 1. (a) Coupled language model. (b) Our autonomous lan-guage model with iterative correction. (c) Our bidirectional struc-ture. (d) Unidirectional RNN in auto-regression. (e) Ensemble of two unidirectional Transformers in parallel-prediction. 2.