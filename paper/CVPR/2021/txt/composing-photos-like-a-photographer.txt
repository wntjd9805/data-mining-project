Abstract
We show that explicit modeling of composition rules beneﬁts image cropping. Image cropping is considered a promising way to automate aesthetic composition in profes-sional photography. Existing efforts, however, only model such professional knowledge implicitly, e.g., by ranking from comparative candidates. Inspired by the observation that natural composition traits always follow a speciﬁc rule, we propose to learn such rules in a discriminative manner, and more importantly, to incorporate learned composition clues explicitly in the model. To this end, we introduce the concept of the key composition map (KCM) to encode the composition rules. The KCM can reveal the common laws hidden behind different composition rules and can in-form the cropping model of what is important in compo-sition. With the KCM, we present a novel cropping-by-composition paradigm and instantiate a network to imple-ment composition-aware image cropping. Extensive experi-ments on two benchmarks justify that our approach enables effective, interpretable, and fast image cropping. 1.

Introduction
Professional photography is expensive, because a well-captured photo needs to take many factors into account.
One of the most important factors is composition. Com-position by deﬁnition refers to “the nature of something’s ingredients or constituents; the way in which a whole or mixture is made up”.1 In photography, not only do those visual constituents of interest matter, but they compose fol-lowing an aesthetic standard. Aesthetic composition, how-ever, requires expert knowledge and extensive training. Can ordinary people compose photos like a photographer? The desire to popularize such knowledge and experience in ev-eryday life has driven enthusiasm for an interesting research
*Corresponding author. 1Deﬁnition by Oxford dictionary. 4.58
Best 1.03
Worst
…
Candidates-Presetting
Scoring & Ranking
Cropping Result (a) Prior Arts: Cropping by Ranking 0.80
Clues for Diagonal
… 0.05
Merging 0.15
Key Composition Map
Cropping Result
Clues for Horizontal
Composition 
Distribution 0.80
Diagonal 0.15
Horizontal 0.05
Others (b) Ours: Cropping by Composition
Figure 1. High-level ideas between prior arts and ours. (a) Prior image cropping methods follow a cropping-by-ranking paradigm, where no composition clue is modeled explicitly; (b)
Our idea is to guide image cropping by composition. Our ap-proach achieves this by discovering the key composition map and the composition distribution of the image, which can produce well-composed, interpretable cropping results. topic in computer vision—image cropping.
Given an arbitrarily captured image, image cropping aims to remove extraneous areas and to ﬁnd a region in which visual constituents conform to aesthetic composi-tion [38]. Aesthetic composition is an art. As the humanist photographer Henri Cartier-Bresson said, “In a photograph, composition is the result of a simultaneous coalition, the or-ganic coordination of elements seen by the eye.” However, it is not immediately clear how such organic coordination can be achieved by image cropping.
Aesthetics-inspired approaches consider that good image cropping should be able to extract the most ‘attractive’ area, expecting that such an area obeys photographic composition rules and aesthetic attributes [6, 10]. However, these ap-proaches typically follow a cropping-by-ranking paradigm, without explicit modeling of the composition rules. As 7057
shown in Fig. 1(a), prior arts generate cropping results by presetting substantial candidate boxes, scoring the boxes per attention estimation or aesthetic assessment, and rank-ing them according to the scores. The box receiving the highest score is considered the ﬁnal output. This paradigm assumes that aesthetic composition is automatically learned on a set of cropping views with relative aesthetic annota-tions [5, 21, 37, 42].
Does the assumption above hold in reality? A key in-sight of this work is that good image cropping should model explicit, interpretable composition rules [13]. Explicitness informs certain composition rules one image obeys; inter-pretability indicates major elements that determine the com-position. They can provide image cropping with reasonable and reliable clues.
In this work, we introduce a new cropping-by-composition paradigm and propose a novel Composition-Aware Cropping Network (CACNet) to model the compo-sition rules explicitly within the network (Fig. 1(b)). We as-sume the composition rules are learnable. This assumption is inspired by the observation that composition generally follows the basic, common arrangement of visual elements.
For instance, the rule-of-thirds places important elements at the point where two horizontal and two vertical lines inter-sect; the horizontal rule arranges the major elements hori-zontally; the diagonal rule exploits leading diagonal lines to create dynamic senses. Since these leading elements play a critical role in composition, our idea is to learn a network to discover these elements to guide image cropping.
To this end, CACNet designs two branches: a com-position branch and a cropping branch.
The compo-sition branch aims to learn the composition rules from data. This is achieved by categorizing images into 9 rules [17]: rule-of-thirds (RoT), center (Cen.), horizontal (Hor.), symmetric (Sym.), diagonal (Dia.), curved (Cur.), vertical (Ver.), triangle (Tri.), and repeated pattern (Pat.). These rules are then characterized by class activation maps (CAMs) [43].
Different CAMs are further squeezed to a 2D map we call the key composition map (KCM). As illustrated in Sec. 3.2, the KCM reveals the common laws hidden behind differ-ent composition rules.
It is therefore used to inform the cropping branch of what is important in composition. The cropping branch ﬁnally exploits an anchor-point regressor to generate the cropping output conditioned on the KCM.
Extensive experiments on two benchmarks show that i) effective:
CACNet exhibits many appealing properties:
CACNet achieves state-of-the-art performance against re-cent competitors; ii) interpretable: the KCM can indicate why a cropping process makes sense; and iii) fast: since
CACNet does not need to generate substantial candidate boxes, it can process images up to 155 FPS on a single RTX 2080 Ti GPU.
To our knowledge, we are among the ﬁrst to explicitly model composition rules in the network and to bring the interpretability of composition into image cropping. 2.