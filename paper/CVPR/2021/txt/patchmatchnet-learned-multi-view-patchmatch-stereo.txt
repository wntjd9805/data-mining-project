Abstract
We present PatchmatchNet, a novel and learnable cas-cade formulation of Patchmatch for high-resolution multi-view stereo. With high computation speed and low memory requirement, PatchmatchNet can process higher resolution imagery and is more suited to run on resource limited de-vices than competitors that employ 3D cost volume regular-ization. For the ﬁrst time we introduce an iterative multi-scale Patchmatch in an end-to-end trainable architecture and improve the Patchmatch core algorithm with a novel and learned adaptive propagation and evaluation scheme for each iteration. Extensive experiments show a very com-petitive performance and generalization for our method on
DTU, Tanks & Temples and ETH3D, but at a signiﬁcantly higher efﬁciency than all existing top-performing models: at least two and a half times faster than state-of-the-art methods with twice less memory usage. Code is avail-able at https://github.com/FangjinhuaWang/
PatchmatchNet. 1.

Introduction
Given a collection of images with known camera param-eters, multi-view stereo (MVS) describes the task of recon-structing the dense geometry of the observed scene. De-spite being a fundamental problem of geometric computer vision that has been studied for several decades, MVS is still a challenge. This is due to a variety of de-facto un-solved problems occurring in practice such as occlusion, il-lumination changes, untextured areas and non-Lambertian surfaces [1, 22, 30].
The success of Convolutional Neural Networks (CNN) in almost any ﬁeld of computer vision ignites the hope that data driven models can solve some of these issues that clas-sical MVS models struggle with. Indeed, many learning-based methods [6, 26, 36, 39, 40] appear to fulﬁll such promise and outperform some traditional methods [15, 29] on MVS benchmarks [1, 22]. While being successful at the benchmark level, most of them do only pay limited atten-tion to scalability, memory and run-time. Currently, most
Figure 1: Comparison with state-of-the-art learning-based multi-view stereo methods [7,16,38,39,40,41] on DTU [1].
Relationship between error, GPU memory and run-time with image size 1152×864. learning-based MVS methods [6, 26, 36, 39] construct a 3D cost volume, regularize it with a 3D CNN and regress the depth. As 3D CNNs are usually time and memory consum-ing, some methods [36, 39] down-sample the input during feature extraction and compute both, the cost volume and the depth map at low-resolution. Yet, according to Fig. 1, delivering depth maps at low resolution can harm accuracy.
Methods that do not scale up well to realistic image sizes of several mega-pixel cannot exploit the full resolution due to memory limitations. Evidently, low memory and time con-sumption are key to enable processing on memory and com-putational restricted devices such as phones or mixed reality headsets, as well as in time critical applications. Recently, researchers tried to alleviate these limitations. For example,
R-MVSNet [40] decouples the memory requirements from the depth range and sequentially processes the cost volume
[7, 16, 38] in-at the cost of an additional runtime penalty. clude cascade 3D cost volumes to predict high-resolution depth map from coarse to ﬁne with high efﬁciency in time and memory.
Several traditional MVS methods [15, 29, 35, 42] aban-don the idea of holding a structured cost volume completely and instead are based on the seminal Patchmatch [2] algo-rithm. Patchmatch adopts a randomized, iterative algorithm for approximate nearest neighbor ﬁeld computation [2]. In particular, the inherent spatial coherence of depth maps is exploited to quickly ﬁnd a good solution without the need to look through all possibilities. Low memory requirements – 14194
independent of the disparity range – and an implicit smooth-ing effect make this method very attractive for our deep learning based MVS setup.
In this work, we propose PatchmatchNet, a novel cas-cade formulation of learning-based Patchmatch, which aims at decreasing memory consumption and run-time for high-resolution multi-view stereo. It inherits the advantages in efﬁciency from classical Patchmatch, but also aims to im-prove the performance with the power of deep learning.
Contributions: (i) We introduce the Patchmatch idea into an end-to-end trainable deep learning based MVS frame-work. Going one step further, we embed the model into (ii) a coarse-to-ﬁne framework to speed up computation.
We augment the traditional propagation and cost evaluation steps of Patchmatch with learnable, adaptive modules that improve accuracy and base both steps on deep features. We estimate visibility information during cost aggregation for the source views. Moreover, we propose a robust train-ing strategy to introduce randomness into training for im-proved robustness in visibility estimation and generaliza-tion. (iii) We verify the effectiveness of our method on var-ious MVS datasets, e.g. DTU [1], Tanks & Temples [22] and ETH3D [30]. The results demonstrate that our Patch-matchNet achieves competitive performance, while reduc-ing memory consumption and run-time compared to most learning-based methods. 2.