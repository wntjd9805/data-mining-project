Abstract
The two-stage methods for instance segmentation, e.g.
Mask R-CNN, have achieved excellent performance re-cently. However, the segmented masks are still very coarse due to the downsampling operations in both the feature pyramid and the instance-wise pooling process, especially for large objects. In this work, we propose a new method called ReﬁneMask for high-quality instance segmentation of objects and scenes, which incorporates ﬁne-grained fea-tures during the instance-wise segmenting process in a multi-stage manner. Through fusing more detailed informa-tion stage by stage, ReﬁneMask is able to reﬁne high-quality masks consistently. ReﬁneMask succeeds in segmenting hard cases such as bent parts of objects that are over-smoothed by most previous methods and outputs accurate boundaries. Without bells and whistles, ReﬁneMask yields signiﬁcant gains of 2.6, 3.4, 3.8 AP over Mask R-CNN on
COCO, LVIS, and Cityscapes benchmarks respectively at a small amount of additional computational cost. Further-more, our single-model result outperforms the winner of the
LVIS Challenge 2020 by 1.3 points on the LVIS test-dev set and establishes a new state-of-the-art. Code will be avail-able at https://github.com/zhanggang001/ReﬁneMask. 1.

Introduction
Instance segmentation [4, 9, 14, 16, 25, 28] is a fun-damental but challenging task in computer vision, which aims to assign each pixel into a speciﬁc semantic category and differentiate instances in the same category. The re-cent top-performing methods [4, 9, 14, 16] for instance seg-mentation generally follow a two-stage paradigm. Taking
Mask R-CNN [14] as an example, a powerful detector is
ﬁrst employed to generate high-quality bounding boxes and
*Corresponding Author
Figure 1: Comparison among three methods for image seg-mentation: (a) Mask R-CNN, (b) DeepLabV3+, and (c) our proposed ReﬁneMask. The segmentation results are indi-cated by the blue or orange shadows. The boundary accu-racy denotes the average accuracy of the predicted masks in boundary regions, and the non-boundary accuracy is de-ﬁned similarly (the deﬁnition of boundary region can be found in Section 3.3). Both accuracies of the three meth-ods are calculated over the entire COCO dataset [20]. then a parallel segmentation branch is introduced to pre-dict binary mask for each instance inside the bounding box.
Speciﬁcally, in the latter step, a pooling operation, e.g.,
RoIAlign [14], is used to extract instance features from the feature pyramid [19], then pixel-wise classiﬁcation is per-formed based on the output features of the mask head.
Despite the strong abilities provided by the powerful ob-ject detector [23] to locate and distinguish instances, Mask
R-CNN loses the image details which are indispensable for high-quality instance segmentation task, see Figure 1 (a).
The loss of details is mainly due to two factors. Firstly, the features fed into the pooling operation are from multi-ple levels of the feature pyramid, and the higher-level fea-tures usually result in coarser spatial resolution. For these high-level features, it is hard to preserve details when map-ping the mask prediction back to input space. Secondly, the pooling operation itself further reduces the spatial size of the features into a smaller size, e.g. 7×7 or 14×14, which 6861
also causes information loss. 2.