Abstract
In recent years, convolutional neural networks (CNNs) have become a prominent tool for texture recognition. The key of existing CNN-based approaches is aggregating the convolutional features into a robust yet discriminative de-scription. This paper presents a novel feature aggregation module called CLASS (Cross-Layer Aggregation of Statis-tical Self-similarity) for texture recognition. We model the
CNN feature maps across different layers, as a dynamic pro-cess which carries the statistical self-similarity (SSS), one well-known property of texture, from input image along the network depth dimension. The CLASS module characterizes the cross-layer SSS using a soft histogram of local differen-tial box-counting dimensions of cross-layer features. The resulting descriptor encodes both cross-layer dynamics and local SSS of input image, providing additional discrimina-tion over the often-used global average pooling. Integrating
CLASS into a ResNet backbone, we develop CLASSNet, an effective deep model for texture recognition, which shows state-of-the-art performance in the experiments. 1.

Introduction
Texture recognition is an important yet challenging prob-lem in computer vision, with a broad spectrum of applica-tions such as material classiﬁcation [3, 6, 34], terrain recog-nition [42] and microscopic image analysis [23]. Its impor-tance comes from the ubiquitousness of texture in our visual world as well as from the primal visual cue provided by tex-ture. One main challenge in texture recognition arises from the various yet contradicting characteristics of textures [12], e.g., uniformity/deformability and regularity/randomness.
Such variable internal properties, together with the exter-∗Corresponding author: Yuhui Quan.
†Z. Chen and F. Li carried out the experiments and contributed equally.
‡This work was supported in part by National Nature Science Foun-dation of China under Grants 61872151 and 62072188, in part by CCF-Tencent Open Fund 2020, in part by Science and Technology Program of
Guangdong Province under Grant 2019A050510010. nal distortions from environments, lead to large variability in texture images which is difﬁcult to resolve.
In recent years, deep learning with convolutional neu-ral networks (CNNs) has emerged as a universal approach for texture recognition; see e.g. [8, 15, 23, 28, 42, 44–46].
These approaches address the local variability and distor-tion of texture by leveraging CNNs for learning effective image features. However, as demonstrated in [8, 46], typi-cal CNNs with fully-connected (FC) layers are not a good choice for texture recognition. The reason is, convolutional feature maps are spatially indexed and the FC layer acting like a spatial transform does not remove the correlation to spatial coordinates from its output. As a result, the output of
FC layers may be sensitive to the the transforms in spatial domain, one main source of variability of textures.
In other words, CNN-based texture recognition requires a feature aggregation module that can generate a distinct description from convolutional features which is robust to spatial transforms. While the robustness to spatial arrange-ment can be easily achieved by simply accumulating spatial features, e.g. global average pooling (GAP) [1, 10, 45], the question is how to ensure and improve the discrimination during aggregation. Recently, several feature aggregation schemes for this purpose have been proposed; e.g. Fisher vector [8] and feature encoding [42, 46]. They aggregate features based on certain statics of a feature tensor.
In this work, we propose a novel yet effective aggrega-tion module, named CLASS (Cross-Layer Aggregation of
Statistical Self-similarity), for CNN-based texture recogni-tion. It differs from existing work in two aspects: utilization of cross-layer statistics and explicit exploitation of statisti-cal self-similarity (SSS). 1.1. Motivations and Main Idea
Cross-layer statistics A CNN builds up a hierarchical rep-resentation of an image based on a series of convolutional layers. The feature maps from one layer to the next encode
If we texture structures from a smaller to a larger scale. treat the generation of feature maps of a texture image along
CNN layers as a dynamic evolution process, its characteris-5231
tics of dynamics can provide useful clues for texture recog-nition. It is shown in [25] that the evolution rule of texture structure across scales is useful for recognition. However, characterizing cross-layer dynamics of texture features is non-trivial, e.g. which statistical quantities to use is a ques-tion, and there is little related work on it. This inspired us to investigate the exploitation of cross-layer statistics for
CNN-based texture recognition.
SSS in texture While texture contains different yet con-tradicting properties, one consensus has been reached that texture can be well modeled by a stochastic process with statistical stationarity, and a texture image is a realization of such a process with external distortions. The statistical stationarity implies that each region on a texture image has similar values in terms of certain statistics. This property relates directly to SSS [26]: the patterns at different scales, although not identical, are represented by the same statis-tics. In the past, SSS has demonstrated its effectiveness in characterizing textures, with applications to texture recogni-tion, analysis and synthesis; see e.g. [2,30,36,38,40,41,47].
Despite its importance, SSS has not been explicitly utilized in existing CNN-based texture recognition approaches.
Cross-layer SSS Wavelet transforms are a prominent tool for exploiting the SSS of images. Many studies showed that the SSS of an image is carried along and well expressed in the wavelet representation [17, 37, 39], which exists not only over space but also across scales. Indeed, CNNs have deep relationships to wavelet transforms. For instance, the hierarchical convolutional feature maps in a CNN can be viewed as a generalization of the multi-scale representation in the wavelet domain [10]. Bruna and Mallat [4] showed that the wavelet scattering transform equals to an un-trained
CNN. Also, the max pooling is similar to taking local max-imums in wavelet leader representation [39]. Therefore, if we treat a CNN as a counterpart of wavelet transform, SSS is likely to be carried from image domain along the feature maps in the CNN. In other words, SSS occurs both spatially and across layers in the CNN.
Inspired by above, we model the feature maps of a well-learned CNN to have cross-layer SSS and construct the
CLASS module to exploit it for aggregation. Our basic idea is illustrated in Fig. 1. The feature maps selected from dif-ferent CNN layers are stacked as a feature tensor in order.
The cross-layer SSS is actually the one in the tensor along the channel dimension. To exploit it locally, a sliding win-dow is used to sample spatially-local and through-channel blocks from the tensor. On each sampled block, we calcu-late the so-called differential box-counting (DBC) dimen-sion [33], a well-established quantity in fractal geometry for characterizing SSS. The DBC views a feature tensor as a hyper-surface and examines the number of boxes required to cover the surface over different box scales. Then, the his-togram of the DBC dimensions on all blocks is used as the descriptor. See Sec. 4.2 for details.
Figure 1. Illustration of basic idea of CLASS. 1.2. Contributions
Integrating the CLASS module into a ResNet backbone, we propose CLASSNet, an effective deep network for tex-ture recognition. Its effectiveness is demonstrated by exten-sive experiments. To summarize, our main contributions in this work are as follows.
Exploiting cross-layer statistics in feature aggregation
Different from most existing approaches (e.g. [1, 10, 15]) which aggregate convolutional features inside individual layers, we propose to perform feature aggregation using a cross-layer manner. This allows exploiting additional infor-mation ignored by inner-layer feature aggregation. There are some approaches (e.g. [44, 45]) that merge feature maps from different layers into a new one, on which feature ag-gregation is performed. Different from these approaches, the CLASS module directly calculates statistical quantities across layers. Our work thus can inspire further studies on cross-layer analysis for other image classiﬁcation tasks.
Incorporating SSS and deep representations We exploit
SSS for feature aggregation in CNN-based texture recogni-tion. While SSS is undoubtedly an essential property for texture, it has not been explicitly exploited in existing deep-learning-based approaches. In this paper, we show that the measurement on SSS provides an effective tool for improv-ing feature aggregation. This can inspire future studies on combining SSS and deep CNNs for texture-related tasks.
Friendly SSS-based pooling The calculation of DBC di-mensions and related computations in CLASS involve sev-eral complicated operations. We provide an efﬁcient imple-mentation for it, which enables the module to be painlessly ported onto and jointly trained with the backbone CNN in an end-to-end manner (unlike [8]). This allows pre-trained backbones to be transferred conveniently and effectively via
ﬁne-tuning. In addition, like some recent pooling modules,
CLASS outputs a ﬁxed-size descriptor for arbitrary-size in-put, allowing CLASSNet to handle varying image sizes.
State-of-the-art (SOTA) performance Beneﬁting from the effectiveness of the CLASS module, our CLASSNet achieved SOTA results on several benchmark datasets. 5232
2.