Abstract
Previous method
Unsupervised Domain Adaptation (UDA) transfers pre-dictive models from a fully-labeled source domain to an unlabeled target domain.
In some applications, however, it is expensive even to collect labels in the source do-main, making most previous works impractical. To cope with this problem, recent work performed instance-wise cross-domain self-supervised learning, followed by an ad-ditional ﬁne-tuning stage. However, the instance-wise self-supervised learning only learns and aligns low-level dis-criminative features.
In this paper, we propose an end-to-end Prototypical Cross-domain Self-Supervised Learn-ing (PCS) framework for Few-shot Unsupervised Domain
Adaptation (FUDA)1. PCS not only performs cross-domain low-level feature alignment, but it also encodes and aligns semantic structures in the shared embedding space across domains. Our framework captures category-wise seman-tic structures of the data by in-domain prototypical con-trastive learning; and performs feature alignment through cross-domain prototypical self-supervision. Compared with state-of-the-art methods, PCS improves the mean classiﬁ-cation accuracy over different domain pairs on FUDA by 10.5%, 3.5%, 9.0%, and 13.2% on Ofﬁce, Ofﬁce-Home,
VisDA-2017, and DomainNet, respectively. 1.

Introduction
Deep Learning has achieved remarkable performance in various computer vision tasks, such as image classiﬁca-tion [30, 32] and semantic segmentation [43, 77, 8]. De-spite high accuracy, deep neural networks trained on spe-ciﬁc datasets often fail to generalize to new domains owing to the domain shift problem [66, 15, 67]. Unsupervised do-main adaptation (UDA) transfers predictive models from a fully-labeled source domain to an unlabeled target domain.
Although it is challenging with no label information in the
*Equal contribution; correspondence to xyyue@berkeley.edu 1Project page: http://xyue.io/pcs-fuda
Deceive Domain
Classiﬁer
Train domain classiﬁer
Update features
Ours
PCS source prototype target prototype unlabeled source unlabeled target
After adaptation labeled source
Figure 1: We address the task of few-shot unsupervised domain adaptation. Top: Existing domain-classiﬁer based methods align source and target distributions but fail to extract discriminative fea-tures due to lack of labeled data. Bottom: Our method estimates prototypes for in-domain and cross-domain self-supervised learn-ing to extract domain-aligned discriminative features. target domain, many UDA methods [67, 31, 44, 18] could achieve high accuracy on the target domain using the abun-dant explicit supervision in source domain, together with the unlabeled target samples for domain alignment.
In some real-world applications, however, providing large-scale annotations even in the source domain is often challenging due to the high cost and difﬁculty of annotation.
Taking medical imaging for instance, each image of the Di-abetic Retinopathy dataset [28] is annotated by a panel of 7 or 8 U.S. board-certiﬁed ophthalmologists, with a total group of 54 doctors. Thus practically it is too stringent to assume the availability of source data with abundant labels.
In this paper, to cope with the labeling costs of the source domain, we instead consider a few-shot unsuper-vised domain adaptation (FUDA) setting, where only an ex-tremely small fraction of source samples are labeled, while 13834
all the rest source and target samples remain unlabeled.
Most state-of-the-art UDA methods align source and tar-get features by minimizing some form of distribution dis-tances [44, 45, 63, 18], and learn the discriminative rep-resentation by minimizing the supervision loss on fully-labeled source domain data. In FUDA, however, since we have a very limited number of labeled source samples, it is much harder to learn discriminative features in the source domain, not to mention in the target domain.
Several recent papers [29, 10, 27, 52, 72] on self-supervised learning (SSL) present promising representation learning results on images from a single domain and [39] further extended to perform SSL across two domains for better domain adaptation performance. Despite the im-proved performance, the instance-based method in [39] has some fundamental weaknesses. First, the semantic structure of the data is not encoded by the learned structure. This is because the in-domain self-supervision in [39] treats two instances as negative pairs as long as they are from differ-ent samples, regardless of the semantic similarity. Conse-quently, many instances sharing the same semantic are un-desirably pushed apart in the feature space. Second, the cross-domain instance-to-instance matching in [39] is very sensitive to abnormal samples. Imagine a case where the embeddings of source and target samples are far apart (i.e. the domain gap is large) and one abnormal source sample is mapped closer to all target samples than any other source sample. Then the method in [39] would match all target samples to the same source sample (cf. Figure 3). For a given sample, the matched sample in the other domain may change drastically during the training procedure, making the optimization harder to converge. Third, the two-stage pipeline (i.e. SSL followed by domain adaptation) is com-plicated and experiments show that the optimal DA methods for different datasets are different. As a result, the training is rather cumbersome and it is unclear how to choose the op-timal DA method in the second stage for different datasets.
In this paper, we propose Prototypical Cross-domain
Self-supervised learning, a novel single-stage framework for FUDA that uniﬁes representation learning and domain alignment with few-shot labeled source samples. PCS con-tains three major components to learn both discriminative and domain-invariant features. First, PCS performs in-domain prototypical self-supervision to implicitly encode the semantic structure of data into the embedding space.
This is motivated by [41], but we further leverage the known semantic information of the task and learn better seman-tic structure in each domain. Second, PCS performs cross-domain instance-to-prototype matching to transfer knowl-edge from source to the target in a more robust manner. In-stead of instance-to-instance matching, matching a sample to a prototype (i.e. representative embedding for a group of instances that are semantically similar) is more robust to abnormal instances in the other domain and makes the optimization converge faster and more smoothly. Third,
PCS uniﬁes prototype learning with cosine classiﬁer and update cosine classiﬁer adaptively with source and target prototypes. transfers from source prototypes to target proto-types for better performance on the target domain. In order to further mitigate the effect of cross-domain mismatching, we perform entropy maximization to obtain a more diversi-ﬁed output. We show that together with entropy minimiza-tion, this is equivalent to maximizing the mutual informa-tion (MI) between input image and the network prediction.
To summarize, our contributions are three-fold:
• We propose a novel Prototypical Cross-domain Self-supervised learning framework (PCS) for few-shot un-supervised Domain Adaptation.
• We propose to leverage prototypes to perform bet-ter semantic structure learning, discriminative feature learning, and cross-domain alignment in a uniﬁed, un-supervised and adaptive manner.
• While it is hard to choose the optimal domain adapta-tion method in the complex two-stage framework [39],
PCS can be easily trained in an end-to-end matter, and outperforms all state-of-the-art methods by a large margin across multiple benchmark datasets. 2.