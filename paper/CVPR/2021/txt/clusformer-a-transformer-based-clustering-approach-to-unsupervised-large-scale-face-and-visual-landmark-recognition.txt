Abstract
The research in automatic unsupervised visual cluster-ing has received considerable attention over the last cou-ple years.
It aims at explaining distributions of unla-beled visual images by clustering them via a parameterized model of appearance. Graph Convolutional Neural Net-works (GCN) have recently been one of the most popular clustering methods. However, it has reached some limita-tions. Firstly, it is quite sensitive to hard or noisy sam-ples. Secondly, it is hard to investigate with various deep network models due to its computational training time. Fi-nally, it is hard to design an end-to-end training model be-tween the deep feature extraction and GCN clustering mod-eling. This work therefore presents the Clusformer, a sim-ple but new perspective of Transformer based approach, to automatic visual clustering via its unsupervised atten-tion mechanism. The proposed method is able to robustly deal with noisy or hard samples. It is also ﬂexible and ef-fective to collaborate with different deep network models with various model sizes in an end-to-end framework. The proposed method is evaluated on two popular large-scale visual databases, i.e. Google Landmark and MS-Celeb-1M face database, and outperforms prior unsupervised clustering methods. Code will be available at https:
//github.com/VinAIResearch/Clusformer 1.

Introduction
The research in automatic unsupervised visual cluster-ing, e.g. human faces or landmark photos, has gained con-siderable prominence lately thanks to the nature of huge amount of available unlabeled data and the demand of con-sistent visual recognition algorithms across various chal-lenging conditions. Indeed, stand-alone visual recognition algorithms, e.g. Face Recognition [36] or Visual Landmark
Recognition [38], are important in practical applications where there is signiﬁcant difference between probe and gallery visual photos [23]. In Face Recognition, the algo-Figure 1. The proposed Clusformer uses the self-attention mech-anism to detect the hard, noisy samples in a cluster, while prior methods use GCNs that are unable to address this problem com-pletely. rithms of face recognition in a supervised manner have now become mature. Compared to the state-of-the-art (SOTA) results of supervised Face Recognition algorithms [7, 15], the number of studies in face clustering are still limited. The solutions are still not as good as supervised methods.
Many complex factors could affect the appearance of a visual photo, e.g. illumination, poses, occlusions, in real-world scenarios. Providing tolerance to these factors is the main challenge for accurate visual clustering methods.
Among these factors, lacking of robust features is often the most important factor to deal with. Visual data is usually easy to collect but costly to annotate. Therefore, Graph
Convolutional Networks (GCNs) have become one of the most popular methods to tackle visual clustering in an un-supervised manner. However, recent visual clustering meth-ods, e.g face clustering [14, 27, 18, 40, 39], still have some limitations, e.g. accurate clustering, algorithm complexity or computational time. 1.1. Contributions of This Work
This work presents the new Clusformer, a simple but novel perspective of Transformer based approach, to auto-matically cluster visual samples in an unsupervised man-ner. The method is able to robustly deal with noisy and hard samples thanks to its effective self-attention mechanism. To 10847
the best of our knowledge, it is one of the ﬁrst work to uti-lize the self-attention mechanism in Transformer to tackle visual clustering problems effectively. The contributions of this work are therefore three-fold. Firstly, a new Trans-former based clustering architecture is introduced in the context of top-down clustering large-scale unsupervised vi-sual databases. Secondly, new Visual Grammar and Cosine
Distance Encoding (CDE) modeling mechanisms are intro-duced to efﬁciently incorporate into the Clusformer frame-work to solve the visual clustering problems. Finally, the proposed approach consistently achieves the state-of-the-art (SOTA) results compared against the recent clustering methods [40, 39] on two standard visual benchmarks, i.e.
Google Landmark and MS-Celeb-1M face database. 2.