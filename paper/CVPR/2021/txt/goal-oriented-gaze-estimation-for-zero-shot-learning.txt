Abstract
Zero-shot learning (ZSL) aims to recognize novel classes by transferring semantic knowledge from seen classes to unseen classes. Since semantic knowledge is built on at-tributes shared between different classes, which are highly local, strong prior for localization of object attribute is ben-eﬁcial for visual-semantic embedding. Interestingly, when recognizing unseen images, human would also automati-cally gaze at regions with certain semantic clue. There-fore, we introduce a novel goal-oriented gaze estimation module (GEM) to improve the discriminative attribute lo-calization based on the class-level attributes for ZSL. We aim to predict the actual human gaze location to get the vi-sual attention regions for recognizing a novel object guided by attribute description. Speciﬁcally, the task-dependent attention is learned with the goal-oriented GEM, and the global image features are simultaneously optimized with the regression of local attribute features. Experiments on three ZSL benchmarks, i.e., CUB, SUN and AWA2, show the superiority or competitiveness of our proposed method against the state-of-the-art ZSL methods. The ablation analysis on real gaze data CUB-VWSW also validates the beneﬁts and accuracy of our gaze estimation module. This work implies the promising beneﬁts of collecting human gaze dataset and automatic gaze estimation algorithms on high-level computer vision tasks. The code is available at https://github.com/osierboy/GEM-ZSL. 1.

Introduction
With prior knowledge on seen classes, humans have a re-markable ability to recognize novel classes using shared and distinct attributes of both seen and unseen classes. Inspired by this cognitive competence, zero-shot learning (ZSL) was proposed as a challenging image classiﬁcation setting to mimic the human cognitive process [32]. Given the seman-*Equal contribution.
†Corresponding author: Xiao Bai (baixiao@buaa.edu.cn). tic descriptions of both seen and unseen classes but only the training images of seen classes, ZSL aims to classify test images of unseen classes.
Based on the classes that a model sees in the test phase,
ZSL can be categorized into conventional or generalized setting. In conventional ZSL, the test images belong only to unseen classes. For the more practical and challenging generalized ZSL (GZSL) setting, the test images may be-long to both seen and unseen classes. The semantic de-scriptions (attributes) are shared information between seen and unseen classes, which ensure the knowledge transfer-ring. Early works [3, 4, 14, 40, 45] on ZSL build embed-ding between seen classes and their attributes. Then un-seen classes are classiﬁed by the nearest neighbor search in the embedding space. These embedding based meth-ods usually have a large bias towards seen classes under the GZSL setting, since the embedding is learned only by seen classes samples. To solve this problem, by leveraging the generative models [17, 30, 29], many feature generation approaches [31, 57, 62, 46, 47, 37] have been proposed to generate unseen classes, than convert ZSL into a conven-tional classiﬁcation problem.
Most of the existing embedding or feature generation based methods extract global features from pre-trained or end-to-end trainable models. However, only the global im-age features cannot effectively represent the ﬁne-grained in-formation between seen and unseen images, which is im-portant for ZSL. More recently, attention based end-to-end models [59, 68, 67, 60] have tried to exploit the semantic vector as guidance to learn more discriminative part fea-tures. However, they simply learn regions embedding of different attribute features but neglect the importance of dis-criminative attribute localization [50, 61].
Very interestingly, when facing an unseen object with the guidance of an attribute description, humans are capable of paying attention to parts of the object with discriminative attributes, which is the gaze behavior. Karessli et al. [27] proved that gaze data is useful in ZSL since they provide an effective prior that can naturally capture the localized discriminative attribute. Inspired by the human gaze mech-3794
Figure 1. Illustration of the proposed method. Our GEM-ZSL is an end-to-end trainable model with two main parts, a gaze estimation module and a plain ZSL backbone. For the gaze estimation module, the projected word vector of each attribute by Word Encoder is ﬁrst utilized as query to guide the localized attribute learning. The ground truth attributes ϕ(y) of speciﬁc seen class are simultaneously used as supervision in the Attribute Localization module. Then, an Attention Transition module is utilized to calibrate the attention regions by real gaze data with a designed gaze loss. Finally, the plain ZSL backbone learns the global image feature which is jointly optimized with the localized attribute, and the backbone accomplishes zero-shot recognition in a Cosine Metric Space. anism, we propose a novel goal-oriented Gaze Estimation
Method for Zero-Shot Learning (GEM-ZSL). As shown in
Figure 1, we ﬁrst design an attribute description-oriented gaze estimation module (GEM) to learn different attribute regions. The GEM consists of three sub-modules, atten-tion module (AM), attention transition (AT) module and at-tribute localization (AL) module. The AM is based on bi-linear pooling which is widely used in the visual question answering task [15, 64]. We use the projected word vector of attributes as query to guide the learning process for the localization of the discriminative attribute. The ground truth attributes of speciﬁc seen class are simultaneously used as supervision by the mean squared error (MSE) of the AL module. Then an AT module is utilized to calibrate the at-tention regions by real gaze data (if available) with a de-signed gaze loss. In this way, we can learn the part feature with localized discriminative attribute that humans subcon-sciously pay attention to. Finally, the joint global features learned by an image encoder (IE), the local features and the class semantic embedding are used to learn a cosine met-ric space, which helps to reduce the intra-class variance and improve the recognition of unseen classes when compared to dot product similarity.
The contribution of this paper can be summarized as fol-lows: (1) We propose a novel goal-oriented gaze estimation method to mimic the human cognitive process for recog-nizing unseen classes. With the guidance of attribute de-scription, the proposed method can predict the human gaze that can be transformed to attribute attention for zero-shot (2) We demonstrate the effectiveness of our recognition. method for improving the localization of discriminative at-tributes, which further enhances the discrimination of the (3) Comprehensive experi-global features for ZSL task. ments over three ZSL benchmarks, i.e., CUB, AWA2 and
SUN, show that our method can achieve superior or compet-itive performance compared with the state-of-the-art ZSL
In addition, the quantitative and qualitative re-methods. sults on gaze estimation experiment also validate the effec-tiveness of our GEM. 2.