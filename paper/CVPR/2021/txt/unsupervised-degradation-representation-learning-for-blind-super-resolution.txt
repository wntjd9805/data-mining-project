Abstract
Most existing CNN-based super-resolution (SR) methods are developed based on an assumption that the degradation is ﬁxed and known (e.g., bicubic downsampling). However, these methods suffer a severe performance drop when the real degradation is different from their assumption. To han-dle various unknown degradations in real-world applica-tions, previous methods rely on degradation estimation to reconstruct the SR image. Nevertheless, degradation esti-mation methods are usually time-consuming and may lead to SR failure due to large estimation errors.
In this pa-per, we propose an unsupervised degradation representa-tion learning scheme for blind SR without explicit degrada-tion estimation. Speciﬁcally, we learn abstract representa-tions to distinguish various degradations in the representa-tion space rather than explicit estimation in the pixel space.
Moreover, we introduce a Degradation-Aware SR (DASR) network with ﬂexible adaption to various degradations based on the learned representations.
It is demonstrated that our degradation representation learning scheme can extract discriminative representations to obtain accurate degradation information. Experiments on both synthetic and real images show that our network achieves state-of-the-art performance for the blind SR task. Code is avail-able at: https://github.com/LongguangWang/
DASR. 1.

Introduction
Single image super-resolution (SR) aims at recovering a high-resolution (HR) image from a low-resolution (LR) observation. Recently, CNN-based methods [9, 22, 24, 2, 32] have dominated the research of SR due to the powerful feature representation capability of deep neural networks.
As a typical inverse problem, SR is highly coupled with the degradation model [3]. Most existing CNN-based methods are developed based on an assumption that the degradation is known and ﬁxed (e.g., bicubic downsampling). However, these methods suffer a severe performance drop when the real degradation differs from their assumption [12].
Figure 1. An illustration of our unsupervised degradation repre-sentation learning scheme.
To handle various degradations in real-world applica-tions, several methods [42, 33, 40, 34] have been proposed to investigate the non-blind SR problem. Speciﬁcally, these methods use a set of degradations (e.g., different combi-nations of Gaussian blurs, motion blurs and noises) for training and assume the degradation of the test LR image is known at the inference time. These non-blind methods produce promising SR results when the true degradation is known in priori.
To super-resolve real images with unknown degrada-tions, degradation estimation [28, 3] needs to be performed to provide degradation information for non-blind SR net-works [42, 33, 40, 34]. However, these non-blind methods are sensitive to degradation estimation. Consequently, the estimation error can further be magniﬁed by the SR net-work, resulting in obvious artifacts [12]. To address this problem, Gu et al. [12] proposed an iterative kernel cor-rection (IKC) method to correct the estimated degradation by observing previous SR results. By iteratively correcting the degradation, artifact-free results can be gradually pro-duced. Since numerous iterations are required at test time by degradation estimation methods [28, 3] and IKC [12], these methods are time-consuming.
Unlike the above methods that explicitly estimate the degradation from an LR image, we investigate a different approach by learning a degradation representation to distin-guish the latent degradation from other ones. Motivated by recent advances of contrastive learning [13, 10, 35, 17, 5], a contrastive loss is used to conduct unsupervised degra-dation representation learning by contrasting positive pairs against negative pairs in the latent space (Fig. 1). The 10581
beneﬁts of degradation representation learning are twofold:
First, compared to extracting full representations to esti-mate degradations, it is easier to learn abstract representa-tions to distinguish different degradations. Consequently, we can obtain a discriminative degradation representation to provide accurate degradation information at a single in-ference. Second, degradation representation learning does not require the supervision from groundtruth degradation.
Thus, it can be conducted in an unsupervised manner and is more suitable for real-world applications with unknown degradations.
In this paper, we introduce an unsupervised degradation representation learning scheme for blind SR. Speciﬁcally, we assume the degradation is the same in an image but can vary for different images, which is the general case widely used in literature [42, 3, 40]. Consequently, an image patch should be similar to other patches in the same image (i.e., with the same degradation) and dissimilar to patches from other images (i.e., with different degradations) in the degra-dation representation space, as illustrated in Fig. 1. More-over, we propose a degradation-aware SR (DASR) network with ﬂexible adaption to different degradations based on the learned representations. Speciﬁcally, our DASR incor-porates degradation information to perform feature adap-tion by predicting convolutional kernels and channel-wise modulation coefﬁcients from the degradation representa-tion. Experimental results show that our network can handle various degradations and produce promising results on both synthetic and real-world images under blind settings. 2.