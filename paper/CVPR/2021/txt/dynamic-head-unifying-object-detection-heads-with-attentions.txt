Abstract
The complex nature of combining localization and clas-siﬁcation in object detection has resulted in the ﬂourished development of methods. Previous works tried to improve the performance in various object detection heads but failed to present a uniﬁed view.
In this paper, we present a novel dynamic head framework to unify object detection heads with attentions. By coherently combining multiple self-attention mechanisms between feature levels for scale-awareness, among spatial locations for spatial-awareness, and within output channels for task-awareness, the pro-posed approach signiﬁcantly improves the representation ability of object detection heads without any computational overhead. Further experiments demonstrate that the effec-tiveness and efﬁciency of the proposed dynamic head on the COCO benchmark. With a standard ResNeXt-101-DCN backbone, we largely improve the performance over pop-ular object detectors and achieve a new state-of-the-art at 54.0 AP. The code will be released at https://github. com/microsoft/DynamicHead. 1.

Introduction
Object detection is to answer the question “what ob-jects are located at where” in computer vision applications.
In the deep learning era, nearly all modern object detec-tors [10, 21, 11, 32, 25, 28, 30] share the same paradigm – a backbone for feature extraction and a head for localization and classiﬁcation tasks. How to improve the performance of an object detection head has become a critical problem in existing object detection works.
The challenges in developing a good object detection head can be summarized into three categories. Firstly, the head should be scale-aware, since multiple objects with vastly distinct scales often co-exist in an image. Secondly, the head should be spatial-aware, since objects usually ap-pear in vastly different shapes, rotations, and locations un-der different viewpoints. Thirdly, the head needs to be task-aware, since objects can have various representations (e.g., bounding box [11], center [25], and corner points [30]) that own totally different objectives and constraints. We ﬁnd re-cent studies [11, 32, 25, 28, 30] only focus on solving one of the aforementioned problems in various ways. It remains an open problem how to develop a uniﬁed head that can ad-dress all these problems simultaneously.
In this paper, we propose a novel detection head, called dynamic head, to unify scale-awareness, spatial-awareness, and task-awareness all together.
If we consider the out-put of a backbone (i.e., the input to a detection head) as a 3-dimensional tensor with dimensions level × space × channel, we discover that such a uniﬁed head can be re-garded as an attention learning problem. An intuitive so-lution is to build a full self-attention mechanism over this tensor. However, the optimization problem would be too difﬁcult to solve and the computational cost is not afford-able.
Instead, we can deploy attention mechanisms separately on each particular dimension of features, i.e., level-wise, spatial-wise, and channel-wise. The scale-aware attention module is only deployed on the dimension of level.
It learns the relative importance of various semantic levels to enhance the feature at a proper level for an individual object based on its scale. The spatial-aware attention module is de-ployed on the dimension of space (i.e., height × width).
It learns coherently discriminative representations in spatial locations. The task-aware attention module is deployed on channels. It directs different feature channels to favor dif-ferent tasks separately (e.g., classiﬁcation, box regression, and center/key-point learning.) based on different convolu-tional kernel responses from objects.
In this way, we explicitly implement a uniﬁed attention mechanism for the detection head. Although these attention mechanisms are separately applied on different dimensions of a feature tensor, their performance can complement each other. Extensive experiments on the MS-COCO benchmark demonstrate the effectiveness of our approach. It offers a great potential for learning a better representation that can 17373
be utilized to improve all kinds of object detection models with 1.2% ∼ 3.2% AP gains. With the standard ResNeXt-101-DCN backbone, the proposed method achieves a new state of the art 54.0% AP on COCO. Besides, compared with EffcientDet [24] and SpineNet [8], dynamic head uses 1/20 training time, yet with a better performance. 2.