Abstract
We propose a novel end-to-end learning-based approach for single image defocus deblurring. The proposed ap-proach is equipped with a novel Iterative Filter Adap-tive Network (IFAN) that is speciﬁcally designed to han-dle spatially-varying and large defocus blur. For adaptively handling spatially-varying blur, IFAN predicts pixel-wise deblurring ﬁlters, which are applied to defocused features of an input image to generate deblurred features. For effec-tively managing large blur, IFAN models deblurring ﬁlters as stacks of small-sized separable ﬁlters. Predicted separa-ble deblurring ﬁlters are applied to defocused features us-ing a novel Iterative Adaptive Convolution (IAC) layer. We also propose a training scheme based on defocus disparity estimation and reblurring, which signiﬁcantly boosts the de-blurring quality. We demonstrate that our method achieves state-of-the-art performance both quantitatively and quali-tatively on real-world images. 1.

Introduction
Defocus deblurring aims to restore an all-in-focus image from a defocused image, and is highly demanded by daily photographers to remove unwanted blur. Moreover, restored all-in-focus images can greatly facilitate high-level vision tasks such as semantic segmentation [21, 30] and object detection [6, 3]. Despite the usefulness, defocus deblurring remains a challenging problem as defocus blur is spatially varying in size, and its shape also varies across the image.
A conventional strategy [28, 7, 22, 5, 12, 14] is to model defocus blur as a combination of different convo-lution results obtained by applying predeﬁned kernels to a sharp image. It estimates per-pixel blur kernels based on the blur model and then performs non-blind deconvolution
[8, 15, 13]. However, this approach often fails due to the re-strictive blur model, which disregards the nonlinearity of a real-world blur and constrains defocus blur in speciﬁc shapes such as disc [7] or Gaussian kernels [28, 22, 12, 14].
Recently, Abuolaim and Brown [1] proposed the ﬁrst end-to-end learning-based method, DPDNet, which does not rely on a speciﬁc blur model, but directly restores a sharp image. Thanks to the end-to-end learning, DPDNet outperforms previous approaches for real-world defocused images. They show that dual-pixel data obtainable from some modern cameras can signiﬁcantly boost the deblurring performance, and present a dual-pixel defocus deblurring (DPDD) dataset. However, ringing artifacts and remaining blur can often be found in their results, mainly due to its na¨ıve UNet [26] architecture, which is not ﬂexible enough to deal with spatially-varying and large blur [37].
In this paper, we propose an end-to-end network embed-ded with our novel Iterative Filter Adaptive Network (IFAN) for single image defocus deblurring. IFAN is speciﬁcally designed for the effective handling of spatially-varying and large defocus blur. To handle the spatially-varying nature of defocus blur, IFAN adopts an adaptive ﬁlter prediction scheme motivated by recent ﬁlter adaptive networks (FANs)
[35, 37]. Speciﬁcally, IFAN does not directly predict pixel values, but generates spatially-adaptive per-pixel deblurring
ﬁlters, which are then applied to features from an input de-focus blurred image to generate deblurred features.
To efﬁciently handle large defocus blur that requires large receptive ﬁelds, IFAN predicts stacks of small-sized separable ﬁlters instead of conventional ﬁlters unlike pre-vious FANs. To apply predicted separable ﬁlters to fea-tures, we also propose a novel Iterative Adaptive Convo-lution (IAC) layer that iteratively applies separable ﬁlters to features. As a result, IFAN signiﬁcantly improves the de-blurring quality at a low computational cost in the presence of spatially-varying and large defocus blur.
To further improve the single image deblurring quality, we train our network with novel defocus-speciﬁc tasks: de-focus disparity estimation and reblurring. The learning of defocus disparity estimation exploits dual-pixel data, which provides stereo images with a tiny baseline, whose dispari-ties are proportional to defocus blur magnitudes [9, 24, 1].
Leveraging dual-pixel stereo images, we train IFAN to pre-2034
dict the disparity map from a single image so that it can also learn to predict blur magnitudes more accurately.
On the other hand, the learning of reblurring task, which is motivated by the reblur-to-deblur scheme in [4], uti-lizes deblurring ﬁlters predicted by IFAN for reblurring all-in-focus images. For accurate reblurring, IFAN needs to predict deblurring ﬁlters that contain accurate information about the shapes and sizes of defocus blur. During training, we introduce an additional network that inverts predicted deblurring ﬁlters to reblurring ﬁlters and reblurs the ground-truth all-in-focus image. We then train IFAN to minimize the difference between the defocused input image and the corresponding reblurred image. We experimentally show that both tasks signiﬁcantly boost the deblurring quality.
To verify the effectiveness of our method on diverse real-world images from different cameras, we extensively eval-uate the method on several real-world datasets such as the
DPDD dataset [1], Pixel dual-pixel test set [1], and CUHK blur detection dataset [27]. In addition, for quantitative eval-uation, we present the Real Depth of Field (RealDOF) test set that provides real-world defocused images and their ground-truth all-in-focus images.
To summarize, our contributions include:
• Iterative Filter Adaptive Network (IFAN) that effec-tively handles spatially-varying and large defocus blur,
• a novel training scheme that utilizes the learning of de-focus disparity estimation and reblurring, and
• state-of-the-art performance of defocus deblurring in terms of deblurring accuracy and computational cost. 2.