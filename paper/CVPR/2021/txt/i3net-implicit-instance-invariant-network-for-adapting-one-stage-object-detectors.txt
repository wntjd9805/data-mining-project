Abstract
Recent works on two-stage cross-domain detection have widely explored the local feature patterns to achieve more accurate adaptation results. These methods heavily rely on the region proposal mechanisms and ROI-based instance-level features to design ﬁne-grained feature alignment modules with respect to the foreground objects. How-ever, for one-stage detectors, it is hard or even impossi-ble to obtain explicit instance-level features in the detec-tion pipelines. Motivated by this, we propose an Implicit
Instance-Invariant Network (I3Net), which is tailored for adapting one-stage detectors and implicitly learns instance-invariant features via exploiting the natural characteristics of deep features in different layers. Speciﬁcally, we facil-itate the adaptation from three aspects: (1) Dynamic and
Class-Balanced Reweighting (DCBR) strategy, which con-siders the coexistence of intra-domain and intra-class vari-ations to assign larger weights to those sample-scarce cate-gories and easy-to-adapt samples; (2) Category-aware Ob-ject Pattern Matching (COPM) module, which boosts the cross-domain foreground objects matching guided by the categorical information and suppresses the uninformative background features; (3) Regularized Joint Category Align-ment (RJCA) module, which jointly enforces the category alignment at different domain-speciﬁc layers with a consis-tency regularization. Experiments reveal that I3Net exceeds the state-of-the-art performance on benchmark datasets. 1.

Introduction
Object detection has achieved remarkable progress due to the unprecedented development of deep convolutional networks (CNNs) and the existence of large-scale annotated
*Corresponding authors
Figure 1: Upper: Illustration of previous two-stage cross-domain detection methods. Lower: Motivation of the pro-posed method based on the observation with respect to the characteristics of deep features in different layers. datasets. However, collecting large amounts of instance-level annotated data in various domains for object detection is prohibitively costly. An alternative would be applying the off-the-shelf detection model trained on the source do-main to a new target domain. However, deep object de-tectors suffer from performance degradation when applied to a new domain under the presence of domain shift [41].
This problem has inspired the research on Unsupervised
Domain Adaptation (UDA) [27], which aims to bridge the distribution discrepancy between source and target domains via knowledge transfer. Numerous approaches, such as mo-ment matching [11, 6, 23, 25, 49] and adversarial learn-ing [7, 42, 37, 24, 44], have been proposed for cross-domain image classiﬁcation and semantic segmentation. 12576
Compared to the conventional UDA problems, cross-domain object detection is a more sophisticated and chal-lenging problem since the adaptation of classiﬁcation and regression should be simultaneously considered. Current methods [4, 53, 34, 1, 14, 3, 46, 52, 45] mostly resort to the adversarial feature adaptation to explore discriminative fea-ture patterns at local-level, global-level, and instance-level for adapting two-stage detectors (see top of Fig. 1), Faster
R-CNN [33]. However, they heavily rely on the region pro-posal mechanisms and ROI-based instance-level features to design ﬁne-grained feature alignment modules with respect to the foreground objects. For example, Zhu et al. [53] mine the target discriminative regions based on the region pro-posals derived from the RPN. Cai et al. [1] regularize the relational graphs by using the ROI-based features. Chen et al. [3] and Xu et al. [45] assist the instance-level feature alignment by the contextual or categorical regularization.
One-stage object detectors, such as SSD [22] and Reti-naNet [21], have the merits of being faster and simpler in real-world applications. Unfortunately, it is unrealistic to obtain explicit instance-level features in the one-stage de-tectors due to the lack of region proposal step. Hence, how to adapt one-stage detectors is vital for practical scenarios but yet to be thoroughly studied. The motivation of this pa-per is shown in the bottom of Fig. 1. Deep features in the standard CNNs must eventually transition from general to speciﬁc along the network [48]. Inspired by this, in one-stage detectors, we can reasonably envision that the fea-tures at lower layers (e.g., color, corner, edge, and illumi-nation) are expected to be mostly instance-uninformative, while the features at higher layers (e.g., object categories) are instance-informative. Therefore, we need to alleviate the negative inﬂuence of uninformative features and pro-mote the alignment of informative features, i.e., suppress redundant (such as background) information from the lower layers and enhance the cross-domain semantic correlation of foreground objects at the higher layers.
In this paper, we propose an Implicit Instance-Invariant
Network (I3Net) that removes the need for requiring ex-plicit instance-level features. Instead, we implicitly learn instance-invariant features via the alignment of transfer-able regions and images while preserving the inter-domain class relationships. To be speciﬁc, we facilitate the adap-tation of one-stage detectors from three aspects. Firstly, upon observing that there exist two conceptually orthog-onal distribution variations hidden in the target data, i.e., intra-domain and intra-class variations, we propose a Dy-namic and Class-Balanced Reweighting (DCBR) strategy to dynamically reweight each target sample based on its adaptation difﬁculty, which is measured by the degree of class imbalance and the prediction uncertainty of a multi-label classiﬁer. Secondly, considering that object with the same category label but from different domains will share similar object patterns, we design a Category-aware Object
Pattern Matching (COPM) module to boost cross-domain foreground objects matching guided by the categorical in-formation and suppress the uninformative background fea-tures at lower layers. Finally, we develop a Regularized
Joint Category Alignment (RJCA) module to enable cat-egory alignment by considering complementary effect of different domain-speciﬁc layers and further incorporate a consistency regularization term with respect to the average prediction of different detection heads. Experimental re-sults show that the proposed I3Net signiﬁcantly improves the state-of-the-art performance of one-stage cross-domain object detection on three benchmarks. 2.