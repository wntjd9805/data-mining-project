Abstract
Generative adversarial network (GAN) has become one of the most important neural network models for classical unsupervised machine learning. A variety of discriminator loss functions have been developed to train GAN’s discrim-inators and they all have a common structure: a sum of real and fake losses that only depends on the actual and generated data respectively. One challenge associated with an equally weighted sum of two losses is that the training may beneﬁt one loss but harm the other, which we show causes instability and mode collapse. In this paper, we in-troduce a new family of discriminator loss functions that adopts a weighted sum of real and fake parts, which we call adaptive weighted loss functions or aw-loss functions. Us-ing the gradients of the real and fake parts of the loss, we can adaptively choose weights to train a discriminator in the direction that beneﬁts the GAN’s stability. Our method can be potentially applied to any discriminator model with a loss that is a sum of the real and fake parts. Experiments validated the effectiveness of our loss functions on uncon-ditional and conditional image generation tasks, improving the baseline results by a signiﬁcant margin on CIFAR-10,
STL-10, and CIFAR-100 datasets in Inception Scores (IS) and Fr´echet Inception Distance (FID) metrics. 1.

Introduction
Generative Adversarial Network (GAN) [15] has be-come one of the most important neural network models for unsupervised machine learning. The origin of this idea lies in the combination of two neural networks, one genera-tive and one discriminative, that work simultaneously. The task of the generator is to generate data of a given distri-bution, while the discriminator’s purpose is to try to rec-*Research supported in part by NSF OIA 2040665, NIH UH3
NS100606-05, and R01 HD101508-01 grants.
†Research supported in part by NSF under grants DMS-1821144 and
DMS-1620082. ognize which data are created by the generative model and which are the original ones. While a variety of GAN mod-els have been developed, many of them are prone to issues with training such as instability where model parameters might destabilize and not converge, mode collapse where the generative model produces a limited number of different samples, diminishing gradients where the generator gradi-ent vanishes and training does not occur, and high sensitiv-ity to hyperparameters.
In this paper, we focus on the discriminative model to rectify the issues of instability and mode collapse in train-ing GAN. In the GAN architecture, the discriminator model takes samples from the original dataset and the output from the generator as input and tries to classify whether a par-ticular element in those samples is real or fake data [15].
The discriminator updates its parameters by maximizing a discriminator loss function via backpropagation through the discriminator network. In many of the proposed mod-els [15, 16, 30, 28], the discriminator loss function consists of two equally weighted parts: the “real part” that purely re-lies on the original dataset and the “fake part” that depends on the generator network and its output; for simplicity we will call them Lr and Lf for real and fake losses, respec-tively. For example, in the original GAN paper [15], the discriminator loss function LD is written as
LD = Lr + Lf , (1) log D(x) and Lf = Ez∼pz (cid:2) with Lr = Ex∼pd (cid:2) log(1 −
, where D and G are the discriminative and gen-D(G(z))) (cid:3) erative models, respectively, pd is the probability distribu-tion of the real data, and pz is the probability distribution of the generator parameter z. (cid:3)
The goal of the GAN discriminator training is to increase both Lr and Lf so that the discriminator D(·) assigns high scores to real data and low scores to fake data. This is done in (1) by placing equal weights on Lr and Lf [15]. How-ever, the training with LD is not performed equally on Lr and Lf . Indeed, a gradient ascent training step along the
∇LD may decrease Lr (or Lf ), depending on the angle be-4781
tween ∇LD and ∇Lr (or ∇Lf ). For example, if we have a large obtuse angle between ∇Lr and ∇Lf , which is the case in most training steps (see §5.1), training along the di-rection of ∇LD may potentially decrease either Lr or Lf by going in the opposite direction to ∇Lr or ∇Lf (see §3 and §5.2). We suggest that this reduction on the real loss may destabilize training and cause mode collapses. Speciﬁ-cally, if a generator is converging with its generated samples close to the data distribution (or a particular mode), a train-ing step that increases the fake loss will reduce the discrimi-nator scores on the fake data and, by the continuity of D(·), reduce the scores on the nearby real data as well. With the updated discriminator now assigning lower scores to the re-gions of data where the generator previously approximated well, the generator update is likely to move away from that region and to the regions with higher discriminator scores (possibly a different mode). Hence, we see instability or mode collapse. See §5.3 for experimental results.
We propose a new approach in training the discrimina-tive model by modifying the discriminator loss function and introducing adaptive weights in the following way,
Law
D = wr · Lr + wf · Lf . (2)
We adaptively choose wr and wf weights to calibrate the training in the real and fake losses. Using the information of ∇Lr and ∇Lf , we can control the gradient direction,
∇Law
D , by either training in the direction that beneﬁts both
Lr and Lf or increasing one loss while not changing the other. This attempts to avoid a situation where training may beneﬁt one loss but signiﬁcantly harm the other. A more detailed mathematical approach is presented in §3.
Our proposed method can be applied to any GAN model with a discriminator loss function composed of two parts as in (1). For our experiments we have applied adap-tive weights to the SN-GAN [34], AutoGAN [14], and
BigGAN [5] models for unconditional as well as condi-tional image generating tasks. We have achieved signif-icant improvements on them for CIFAR-10, STL-10 and
CIFAR-100 datasets in both Inception Scores (IS) and
Fr´echet Inception Distance (FID) metrics, see §4. Our code is available at https://github.com/vasily789/adaptive-weighted-gans.
Notation: We use h·, ·i2 to denote the Euclidean in-ner product, kxk2 the Euclidean 2-norm, and ∠2(x, y) := arccos (cid:16) hx,yi2 kxk2kyk2 (cid:17) the angle between vectors x and y. 2.