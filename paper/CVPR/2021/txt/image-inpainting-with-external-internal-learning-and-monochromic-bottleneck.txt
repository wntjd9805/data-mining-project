Abstract
Although recent inpainting approaches have demon-strated signiﬁcant improvement with deep neural networks, they still suffer from artifacts such as blunt structures and abrupt colors when ﬁlling in the missing regions. To ad-dress these issues, we propose an external-internal inpaint-ing scheme with a monochromic bottleneck that helps im-age inpainting models remove these artifacts. In the exter-nal learning stage, we reconstruct missing structures and details in the monochromic space to reduce the learning di-mension. In the internal learning stage, we propose a novel internal color propagation method with progressive learn-ing strategies for consistent color restoration. Extensive experiments demonstrate that our proposed scheme helps image inpainting models produce more structure-preserved and visually compelling results. 1.

Introduction
Image inpainting is a task that aims to complete the miss-ing regions of an image with visually realistic and semanti-cally consistent content. Image inpainting can beneﬁt gen-eral users in various practical applications, including un-wanted object removal from an image, face defect removal, and image editing. While we have witnessed signiﬁcant progress in image inpainting, inpainting models still suf-fer from abrupt color artifacts, especially when the missing regions are large. This work will analyze the weaknesses of state-of-the-art inpainting approaches and present a novel framework to improve existing inpainting methods.
State-of-the-art inpainting methods roughly fall into two categories of patch matching by iteratively nearest-neighbor search and deep learning models, with different pros and cons. PatchMatch [3] is a learning-free method that only utilizes internal statistics of a single image. As shown in
Fig. 1, it generates smooth patterns and colors that are con-sistent with the non-missing region, but it fails to ﬁll in semantic-aware content. The deep learning based inpaint-ing approaches can learn semantic-aware models by train-ing on large-scale datasets. These approaches have ex-∗Equal contribution plored coarse-to-ﬁne inpainting models in different fash-ions. They may ﬁrst generate edges [20, 17], structural information [24], segmentation maps [29] or blurry im-ages [37, 38, 36], and then use these intermediate outputs as guidance for ﬁlling in details. However, their results still suffer from color and texture artifacts. One of the most common artifacts observed is color bleeding, as shown in
Fig. 1. These methods trained on a large-scale dataset tend to introduce inconsistent colors that do not conform to the color distribution of the test image. On the other hand, we observe that color bleeding artifacts seldom appear in the internal methods.
Based on the observations above, we propose a ro-bust inpainting method by combining the best of both worlds. We adopt a novel external-internal inpainting scheme with a monochromic bottleneck: ﬁrst complet-ing the monochromic image via learning externally from large-scale datasets and then colorizing the completed monochrome by learning internally on the single test im-age. Our proposed method is orthogonal to early inpainting approaches and thus can be easily applied to improve pre-vious learning-based inpainting models for a higher-quality generation. In the external learning stage, by changing the output of the reconstruction network from polychromatic images to monochromic images, we reduce the dimension of the optimization space from R3 to R, leading to more structure-preserving reconstruction (Section 4.3). Models trained in this way also show stronger generalization abil-ity on cross-dataset evaluation.
In the colorization stage, motivated by the recent advancement in deep internal learn-ing, we propose a novel internal color propagation approach guided by the completed monochromic bottleneck. How-ever, similar monochromic values can map to different poly-chromic outputs even in a single image. We, therefore, adopt a progressive restoration strategy for combining both local and global color statistics. Our external-internal learn-ing scheme not only facilitates structure reconstruction but also ensures color consistency. By focusing on the inter-nal color distribution of a single image, we can eliminate abrupt colors and produce a visually pleasing image (Sec-tion 3.1.1).
We conduct extensive experiments to evaluate the perfor-5120
Input
GatedConv [38]
Figure 1. Image inpainting results by traditional and deep learning methods. Zoom in for details.
EdgeConnect [20]
PartialConv [19]
PatchMatch [3]
GMCNN [32]
Ours mance of our method on four public datasets Places2 [42],
Paris StreetView [21], CelebA-HQ [15] and DTD [6].
We apply our method to different baseline networks (Gat-edConv [38], EdgeConnect [20], HiFill [36] and GM-CNN [32]), and observe meaningful improvement in terms of structure preservation and color harmonization. Further-more, we perform model analysis and ablation studies to verify our hypothesis and modiﬁcations. The main contri-butions of our paper can be summarized as:
• To the best of our knowledge, we are the ﬁrst to in-troduce an external-internal learning method to deep image inpainting. It learns semantic knowledge exter-nally by training on large datasets while fully utilizes internal statistics of the single test image.
• We design a progressive internal color restoration net-work that achieves outstanding colorization perfor-mance in our case.
• We generalize our proposed method to several deep inpainting models and observe clear improvement in terms of visual quality and model generalization abil-ity on multiple datasets. 2.