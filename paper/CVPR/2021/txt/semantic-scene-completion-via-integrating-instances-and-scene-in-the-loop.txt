Abstract
Semantic Scene Completion aims at reconstructing a complete 3D scene with precise voxel-wise semantics from a single-view depth or RGBD image. It is a crucial but chal-lenging problem for indoor scene understanding.
In this work, we present a novel framework named Scene-Instance-Scene Network (SISNet), which takes advantages of both in-stance and scene level semantic information. Our method is capable of inferring ﬁne-grained shape details as well as nearby objects whose semantic categories are easily mixed-up. The key insight is that we decouple the instances from a coarsely completed semantic scene instead of a raw input image to guide the reconstruction of instances and the over-all scene. SISNet conducts iterative scene-to-instance (SI) and instance-to-scene (IS) semantic completion. Speciﬁ-cally, the SI is able to encode objects’ surrounding context for effectively decoupling instances from the scene and each instance could be voxelized into higher resolution to cap-ture ﬁner details. With IS, ﬁne-grained instance information can be integrated back into the 3D scene and thus leads to more accurate semantic scene completion. Utilizing such an iterative mechanism, the scene and instance completion beneﬁts each other to achieve higher completion accuracy.
*The ﬁrst two authors contribute equally to this work.
†H. Li and K. Lin are the co-corresponding authors.
Extensively experiments show that our proposed method consistently outperforms state-of-the-art methods on both real NYU, NYUCAD and synthetic SUNCG-RGBD datasets.
The code and the supplementary material will be available at https://github.com/yjcaimeow/SISNet. 1.

Introduction
A comprehensive indoor scene understanding in 3D be-havior is pivotal for many computer vision tasks, such as robot navigation, virtual/augmented reality and localization, to name a few. Semantic Scene Completion (SSC) aims at reconstructing full voxel-wise semantics of a 3D scene from a single-view image. However, as the real-world sce-narios always have various object shapes/sizes, crowded placements, and object-to-object occlusions, precisely re-constructing and understanding the semantics of a whole 3D scene from partial observations is of great challenges.
To overcome the incomplete and complex nature of 3D scene understanding, various 3D scene/instance completion and segmentation techniques have been proposed in recent years. Most existing Semantic Scene Completion (SSC) methods [9, 7, 20, 18, 35, 5, 20, 18, 48, 10, 7, 49, 15] pass the incomplete scene from view frustum to a neural net-work. They design complex modules to aggregate multi-level context information to guide the prediction of volu-metric occupancy of invisible regions and semantic cate-324
gories over the whole scene. However, objects’ shapes usu-ally cannot be reliably reconstructed in ﬁne-details and the semantic categories of close-by objects are easily mixed-up, due to the limited resolution of voxelization and absence of instance-level constraints, as illustrated by the chairs and windows in Figure 1 (e). Some recent Semantic Instance
Completion (SIC) methods [13, 12, 17, 1] attempt to recon-struct certain types of objects in the scene to help the under-standing of the 3D scene. They general follow the pipeline of detecting instances and then completing each individu-als or aligning with CAD models to achieve ﬁne-grained reconstruction. Instance-level completion can greatly pre-serve the structures and details of the objects. However, detecting objects from partially observed scenes itself is a challenging problem. In addition, the surrounding semantic information of the scene and more complete shape are help-ful for better distinguishing each individuals. Such valuable knowledge is much ignored in the current instance detection and completion methods.
In this paper, we aims to design a mechanism that can efﬁciently propagate and integrate the information between the scene and instances to achieve more accurate SSC prediction. To this end, we introduce a Scene-Instance-Scene Network, a novel framework that conducts iterative scene-to-instance and instance-to-scene semantic comple-tion. Unlike existing SIC methods that conduct instance completion on the raw partial observations or SSC methods that only consider the scene-level knowledge, our frame-work takes full advantages of the 3D voxel-wise scene-level ground truths for assisting instance completion, which in turn, improves the whole scene semantic completion in an iterative manner.
Speciﬁcally, the proposed method ﬁrst aggregates multi-modal information from the visible regions’ 2D semantic segmentation maps and truncated signed distance function (TSDF)1 to generate a coarsely completed 3D semantic scene. Given the roughly completed scene, the follow-up scene-to-instance completion localizes each instances and locally voxelizes them into higher resolution to recover de-tailed 3D shapes, which are then placed back to the scene to further promote the scene’s completion. The intuition behind this design is that objects are the main components of the scene and they are tightly correlated with the scene.
For example, when the windows are well reconstructed, the surrounding walls can be easily inferred. It is worth not-ing that we iterate the scene-instance-scene completion in a weight-sharing manner by training with multi-stage data si-multaneously. The iterative completion mechanism enables instances and scene information to be fully propagated and integrated without extra parameters, resulting in more accu-1TSDF is a representation to encode depth volume, where every voxel stores the distance value d to its closest surface and the sign of the value indicates whether the voxel is in visible or invisible spaces. rate and comprehensive understanding of the 3D scene.
In summary, our contributions are three folds:
• We introduce a novel framework, Scene-Instance-Scene Network (SISNet), that fully takes advantages of both scene- and instance-level knowledge, to achieve high-quality semantic scene completion. Our method greatly boosts the instance completion performance es-pecially for semantic confusing objects and shape’s de-tails with a coarsely completed 3D scene’s knowledge in hand. And in turn, ﬁne-detail instance completion leads to more accurate prediction of semantic scene completion.
• We design a scene-instance-scene iterative completion mechanism, which gradually improves the completion results to better reconstruct the 3D scene without in-creasing extra parameters.
• Experimental results demonstrate that the proposed method outperforms state-of-the-art semantic scene completion methods signiﬁcantly on both synthetic and real datasets. 2.