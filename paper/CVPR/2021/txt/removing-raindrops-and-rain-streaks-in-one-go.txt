Abstract 1.

Introduction
Existing rain-removal algorithms often tackle either rain streak removal or raindrop removal, and thus may fail to handle real-world rainy scenes. Besides, the lack of real-world deraining datasets comprising different types of rain and their corresponding rain-free ground-truth also im-pedes deraining algorithm development. In this paper, we aim to address real-world deraining problems from two as-pects. First, we propose a complementary cascaded net-work architecture, namely CCN, to remove rain streaks and raindrops in a uniﬁed framework. Speciﬁcally, our CCN re-moves raindrops and rain streaks in a complementary fash-ion, i.e., raindrop removal followed by rain streak removal and vice versa, and then fuses the results via an attention based fusion module. Considering signiﬁcant shape and structure differences between rain streaks and raindrops, it is difﬁcult to manually design a sophisticated network to re-move them effectively. Thus, we employ neural architecture search to adaptively ﬁnd optimal architectures within our speciﬁed deraining search space. Second, we present a new real-world rain dataset, namely RainDS, to prosper the de-velopment of deraining algorithms in practical scenarios.
RainDS consists of rain images in different types and their corresponding rain-free ground-truth, including rain streak only, raindrop only, and both of them. Extensive experimen-tal results on both existing benchmarks and RainDS demon-strate that our method outperforms the state-of-the-art.
*This work was done when Ruijie Quan, Yuanzhi Liang interned at
Baidu Research. Yi Yang is the corresponding author.
Rainy weather would severely degrade the performance of outdoor vision systems. Rain streaks in the air severely impair the visibility of captured scenes. Concurrently, rain-drops falling on camera lenses or windshields further re-duce the image quality as images are captured through rain-drenched glasses. Hence, removing rain from images plays an important role in outdoor vision applications, such as au-tonomous driving.
Existing deraining works have achieved promising pro-gresses and they can be divided into two major categories: rain streak removal and raindrop removal. Rain streak re-moval methods [29, 42, 41, 53, 54, 44, 11, 5, 9] remove rain streaks mainly based on their sparse line-shape nature. Ex-isting raindrop removal methods [48, 12, 6, 30, 33] remove raindrops by identifying their various shapes, positions and sizes. Previous deraining methods usually assume only one type of rain exhibits in images. However, in real-world rainy weather, rain streaks and raindrops often co-occur dur-ing image capture. Therefore, this phenomenon poses a crit-ical challenge to the existing deraining algorithms.
In this paper, we develop a novel complementary cas-caded network, dubbed CCN, to remove raindrops and rain streaks jointly in a uniﬁed framework. Our CCN consists of two branches to remove rain in different orders, i.e., raindrop removal followed by rain streak removal and rain streak removal followed by raindrop removal. In this com-plementary fashion, our network removes both types of rain more thoroughly, as illustrated in Fig. 1. Moreover, we present an attention based fusion to merge the outputs from the two branches to achieve satisfactory deraining results.
Considering different shapes, sizes and optical effects of 9147
Rain-free
Raindrop
Rain streak
Raindrop & rain streak d l r o w
-l a e
R c i t e h t n y
S
Figure 2: Top: Examples of real-world image pairs in
RainDS. Bottom: Examples of the synthetic image pairs in RainDS. (Best view on screen) rain, it might be difﬁcult to manually design a powerful net-work that is able to remove different types of rain. There-fore, we resort to a neural architecture search (NAS) method to ﬁnd an optimal architecture for deraining.
In particu-lar, we also design a speciﬁc deraining search space that takes several effective deraining operations into account, such as cascaded convolutions with large- and small-size kernels [36] and spatial attention modules [8]. After archi-tecture search, our network can fully explore global and lo-cal information of the raindrops and rain streaks and restore clean images.
In order to train CCN and enable it to generalize well on real images, we manage to collect a real-world rain dataset, dubbed RainDS, including images of rain streaks, raindrops and both of them as well as their corresponding clean im-ages1. Moreover, to enrich the diversity of our dataset, we include some synthetic data generated in autonomous driv-ing scenes. Examples of RainDS are illustrated in Fig. 2.
The training set of RainDS includes both real and synthetic data. In this way, we can not only train our network on real data to reduce the domain gap between real and synthetic data but also evaluate it on real data quantitatively. Experi-mental results on RainDS demonstrate that our method out-performs the state-of-the-art in real-world scenarios, thus making our method more favorable.
Overall, our contributions are summarized as follows:
• We propose a new complementary cascaded deraining network, named CCN, to simultaneously remove both raindrops and rain streaks in a complementary manner, thus removing rain more thoroughly.
• We design a speciﬁc deraining search space that takes different rain characteristics into account, and then search an optimal architecture within this space for our generic deraining task. 1All the images are captured by a Cannon EOS D60 camera in real life.
• To the best of our knowledge, our introduced dataset
RainDS is the ﬁrst real-world deraining dataset includ-ing different types of rain captured in various lighting conditions and scenes. RainDS signiﬁcantly facilitates bridging the domain gap between real and synthetic data and improving the model generalization ability.
• Our method achieves state-of-the-art performance on both existing datasets (only rain streak or raindrop) and our proposed benchmark. 2.