Abstract
We tackle the task of image retrieval with text feedback, where a reference image and modiﬁer text are combined to identify the desired target image. We focus on designing an image-text compositor, i.e., integrating multi-modal inputs to produce a representation similar to that of the target im-age. In our algorithm, Content-Style Modulation (CoSMo), we approach this challenge by introducing two modules based on deep neural networks: the content and style modu-lators. The content modulator performs local updates to the reference image feature after normalizing the style of the image, where a disentangled multi-modal non-local block is employed to achieve the desired content modiﬁcations.
Then, the style modulator reintroduces global style infor-mation to the updated feature. We provide an in-depth view of our algorithm and its design choices, and show that it accomplishes outstanding performance on multiple image-text retrieval benchmarks. Our code can be found at: https://github.com/postBG/CosMo.pytorch 1.

Introduction
Image retrieval is a crucial computer vision task that serves as the foundation for a variety of applications such as product search [22, 45, 61], person re-identiﬁcation [69, 14, 42], and internet search [61, 52]. One of the most challenging aspects of building image retrieval systems is the ability to understand the user’s intention accurately.
Currently, a majority of image search engines are based on either image-to-image matching [52, 61] or image-text matching [59, 74, 70], where a user provides a single im-age or sentence as an input to ﬁnd the most relevant images.
However, it is not straightforward to express the complex target concept via a single image or text and design a model representing the intended concept. Furthermore, the users are unable to reﬁne the retrieved results that fail to reﬂect their intention effectively.
We explore a different setting of image search—image retrieval with text feedback [66, 10]—where a reference im-∗ equal contribution.
Similar t-shirt but  has a different print. (a) Example of a content modiﬁcation
Similar t-shirt but  blue instead of red. (b) Example of a style modiﬁcation
Figure 1. Examples of image retrieval with text feedback. Starting from a reference image, the user interacts with the system by pro-viding a text input that expresses the desired changes. Given these inputs, the system retrieves images from a database that most ac-curately resembles the user’s request. (a) and (b) depict examples of content and style modiﬁcations, respectively. age and a modiﬁer text are used jointly as a query, as il-lustrated in Figure 1. Here, the reference image does not have any attribute labels, and the modiﬁer text is a de-scription of how the reference image should be changed to obtain the desired results, i.e., target images. While in-herently more complex than the standard image retrieval setting, this approach allows users to express their con-cepts more precisely by leveraging visual-linguistic infor-mation. In addition, since the users can recursively reﬁne the search results based on previous results, the proposed algorithm would eventually lead to substantially improved output quality with high ﬁdelity to input queries.
To tackle the task of image retrieval with text feedback, we create an image-text composition module that produces features similar to the target image features by combining the representations of the reference image and the modi-ﬁer text. There are two main challenges in designing such a composition module. First, the module should be able to se-lectively preserve and modify the reference image features, 802
i.e. determine what to maintain and what to update. Sec-ond, the concepts conveyed in the modiﬁer texts may range from being speciﬁc to certain contents of the image, to be-ing more global and stylistic changes, as illustrated in Fig-ure 1(a) and (b), respectively. As such, the module should be able to handle changes in both content and style.
A few works have contributed to the task of the image re-trieval with text feedback. Most notably, TIRG [66] adopts gating and residual modules. The gating module uses a ref-erence image and a modiﬁer text to produce gate values that select what to update, while the residual module yields ad-ditive changes to the gated image feature. Although the al-gorithm design of TIRG [66] is intuitive, it fails to account for the wide range of input contents and styles, and thus, shows limited performance. On the other hand, VAL [10] employs multiple composition modules in varying depths of network, and each module produces the outputs that are used for retrieval. While VAL [10] is better suited to ad-dress the style-content issue, its use of additional modules in multiple layers demands much more resources.
In this work, we propose a novel image-text compositor, the Content-Style Modulator (CoSMo), which directly ad-dresses both the content and style changes conveyed by the modiﬁer text. CoSMo consists of two modules: the Con-tent Modulator (CM) and the Style Modulator (SM). In CM, we introduce a Disentangled Multi-modal Non-local block (DMNL), which is an extension of the Non-local block [67] to the multi-modal setting, to effectively transform the con-tents of the reference image feature. To ensure that DMNL focuses on modifying contents rather than style, we ﬁrst re-move any style information by instance normalization of the reference image features. Moreover, we implement a few tricks in DMNL, which is imperative for stable training, es-pecially in the multi-modal setting. In SM, we reintroduce style information to the transformed image feature. This module gates the channel-wise statistics of the original ref-erence image feature, and predicts additional channel-wise statistics based on the modiﬁer text feature.
Overall, our contributions are summarized as follows:
• We propose a novel image-text compositor, referred to as CoSMo, that is able to modulate both the contents and the style of the reference image.
• We design the content modulator, which employs the disentangled multi-modal non-local block with addi-tional tricks to facilitate stable training. The proposed style modulator selectively preserves style information in the original image feature and adds new styles based on the text input.
• We demonstrate the effectiveness of CoSMo on mul-tiple image-text retrieval benchmarks, where we out-perform recent state-of-the-art methods. We also pro-vide an extensive set of ablation experiments, as well as analysis that provide insight into our method. 2.