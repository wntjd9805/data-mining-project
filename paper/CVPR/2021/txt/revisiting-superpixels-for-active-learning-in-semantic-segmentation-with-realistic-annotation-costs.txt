Abstract
State-of-the-art methods for semantic segmentation are based on deep neural networks that are known to be data-hungry. Region-based active learning has shown to be a promising method for reducing data annotation costs. A key design choice for region-based AL is whether to use regularly-shaped regions (e.g., rectangles) or irregularly-shaped region (e.g., superpixels). In this work, we address this question under realistic, click-based measurement of annotation costs. In particular, we revisit the use of super-pixels and demonstrate that the inappropriate choice of cost measure (e.g., the percentage of labeled pixels), may cause the effectiveness of the superpixel-based approach to be under-estimated. We benchmark the superpixel-based ap-proach against the traditional “rectangle+polygon”-based approach with annotation cost measured in clicks, and show that the former outperforms on both Cityscapes and PAS-CAL VOC. We further propose a class-balanced acquisition function to boost the performance of the superpixel-based approach and demonstrate its effectiveness on the evalu-ation datasets. Our results strongly argue for the use of superpixel-based AL for semantic segmentation and high-light the importance of using realistic annotation costs in evaluating such methods. 1.

Introduction
In recent years, we have witnessed the rapid develop-ment and great success brought by deep learning on many computer vision tasks, where the state-of-the-art is domi-nated by deep learning methods. A key ingredient to the success of deep learning is the availability of large corpora of annotated training data. In practice, however, the anno-tation cost for labeling such a corpus can be prohibitively expensive, especially for dense prediction tasks like seman-tic image segmentation where pixel-wise labeling is needed.
Active learning (AL) offers one approach to address this annotation burden by selecting only the most informative samples for labeling.
Previous AL methods for semantic image segmenta-tion can be broadly classiﬁed into image-based methods
[35, 31, 8] and region-based methods [23, 4, 6] according to the granularity of data selection for annotation. Image-based approaches consider an entire image as a sample while region-based approaches divide images into non-overlapping patches and consider each patch as a sample.
Further design choices for the region-based approach are the shape and size of the regions chosen for annotation.
Previous work suggests that region-based selection outper-forms image-based selection due to the increase in data vari-ability [23]; we thus focus on region-based AL in this work.
A fundamental consideration in navigating these de-sign choices for region-based AL is the cost of annotat-ing a sample. Many works have measured annotation cost in terms of the number (or percentage) of labeled pixels
[35, 31, 8, 4, 18], which is not reﬂective of the polygon-based annotation process used in practice [7]. As an al-ternative, click-based annotation costs have been proposed
[23, 6] to better capture the true annotation costs. More concretely, three types of clicks are usually involved in the polygon-based annotation process: 1) polygon clicks for annotating vertices of the polygon enclosing the object-of-interest; 2) intersection clicks for annotating the intersection points between object boundaries and region boundaries; 3) class clicks for assigning a single class label to each seg-ment within the region. The number of polygon and inter-section clicks required will likely be higher for regularly-shaped regions (squares, rectangles) that typically do not respect actual object boundaries. These clicks can be re-duced (even avoided) if AL is conducted with boundary-preserving regions, such that the annotator only needs to focus on assigning classes for each region.
This consideration of annotation costs motivates the use of (irregularly-shaped) superpixels in region-based AL
[18, 30] instead of regularly-shaped squares or rectan-gles. Superpixel algorithms divide an image into non-10988
overlapping irregularly-shape regions by grouping percep-tually similar pixels together, such that superpixels preserve natural object boundaries well. As a result, most pixels within a superpixel are from the same semantic category.
This enables the use of a light-weight annotation scheme where each superpixel is annotated by only one class la-bel that represents the majority of the pixels, reducing the need for polygon and intersection clicks. As illustrated in
Fig. 1, annotating approximately the same number of pix-els, “rectangle+polygon”-based method requires more than 10 clicks, while the superpixel-based method only requires 1 click.
However, the advantages of superpixel-based approaches for region-based AL remain unclear. Recent work sug-gests that the advantage of superpixel-based approaches over pixel-based approaches is marginal [18], possibly be-cause pixel-based annotation costs were used in the evalua-tion. On the other hand, while more realistic click-based an-notation costs have been used to benchmark rectangle-based methods [23, 6], comparisons between superpixel-based methods and rectangle-based methods have not been per-formed. It therefore remains unclear if a superpixel-based approach can indeed reduce annotation cost compared to the traditional “rectangle+polygon” based approach. We address this question in this work, by revisiting the use of superpixels for region-based AL, performing analyses on the effect of region shape and size on region-based AL with more realistic, click-based measurements of annota-tion costs.
Our contributions can be summarized as follows:
• We revisit segmentation with realistic the superpixel-based approach for AL in semantic click-based annotation cost taken into consideration, and the traditional demonstrate its effectiveness over
“rectangle+polygon”-based approach.
• We investigate how region size affects the superpixel-rectangle-based based scheme and the traditional scheme respectively, and show that the former outper-forms for a wide range of region sizes.
• We propose a class-balanced acquisition function to further boost the performance of the superpixel-based approach by favoring the selection of informative sam-ples from under-represented object categories. 2.