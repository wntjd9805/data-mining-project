Abstract
Analyzing complex scenes with Deep Neural Networks is a challenging task, particularly when images contain multi-ple objects that partially occlude each other. Existing ap-proaches to image analysis mostly process objects inde-pendently and do not take into account the relative occlu-sion of nearby objects. In this paper, we propose a deep network for multi-object instance segmentation that is ro-bust to occlusion and can be trained from bounding box supervision only. Our work builds on Compositional Net-works, which learn a generative model of neural feature ac-tivations to locate occluders and to classify objects based on their non-occluded parts. We extend their generative model to include multiple objects and introduce a frame-work for efﬁcient inference in challenging occlusion sce-In particular, we obtain feed-forward predictions narios. of the object classes and their instance and occluder seg-mentations. We introduce an Occlusion Reasoning Module (ORM) that locates erroneous segmentations and estimates the occlusion order to correct them. The improved seg-mentation masks are, in turn, integrated into the network in a top-down manner to improve the image classiﬁcation.
Our experiments on the KITTI INStance dataset (KINS) and a synthetic occlusion dataset demonstrate the effectiveness and robustness of our model at multi-object instance seg-mentation under occlusion. Code is publically available at https://github.com/XD7479/Multi-Object-Occlusion. 1.

Introduction
Scenes in images most often depict multiple objects that partially occlude each other. Recent studies [38, 18] showed that deep networks are less robust at recognizing partially occluded objects compared to Humans. The main difﬁcul-ties are raised by the combinatorial variability of the object ordering and positioning, as well as the fact that scenes can contain known and unknown object classes.
One approach to address the problem of occlusion in
Figure 1: Our proposed model corrects erroneous instance segmentations through multi-object reasoning. Left: Two input images that are processed independently. The seg-mentation results identify visible object parts in blue, in-visible parts in red, and context in green. Note how in the top image, the model cannot identify the occlusion. Center:
By enforcing consistency between segmentations of nearby objects, our model can identify conﬂicting segmentations (white area). Right: Reasoning about the occlusion order resolves the erroneous predictions. deep networks is data augmentation [36, 5, 34, 1]. While this increases the robustness of deep networks, the classi-ﬁcation performance on partially occluded objects still re-mains substantially worse compared to non-occluded ob-jects. Recent work introduced compositional deep networks (CompositionalNets) and showed that these are more ro-bust to partial occlusion compared to data augmentation ap-proaches [16, 17, 30]. CompositionalNets are deep neural network architectures in which the fully connected classiﬁ-cation head is replaced with a differentiable compositional model. The structure of the compositional model enables
CompositionalNets to decompose images into objects and context, as well as to further decompose objects into their individual parts. The generative nature of the composi-tional model enables it to segment objects and occluders 11141
[28] and to recognize objects based on their non-occluded parts. However, CompositionalNets, as well as other pop-ular architectures, treat each object in an image indepen-dently and do not explicitly exploit the mutual relationship of nearby objects.
In this paper, we introduce a deep network for multi-object instance segmentation that is robust to occlusion and can be trained from bounding box supervision only. Our work builds on and signiﬁcantly extends Compositional-Nets. Speciﬁcally, we extend the generative model in Com-positionalNets to allow for instance segmentation of mul-tiple mutually occluding objects in an image. This multi-object generative model is hard to optimize because of the mutual dependencies between objects. To solve this opti-mization efﬁciently, we introduce an Occlusion Reasoning
Module (ORM) that takes as input the independent predic-tions of each objects label, the instance segmentation and the occluder segmentation (Figure 1). We proceed to esti-mate possibly erroneous predictions through an occlusion voting mechanism. During occlusion voting, each object in the image votes for every pixel in its bounding box if the pixel is occupied by the object or if is occluded. Pixels which receive ambiguous votes from multiple objects indi-cate segmentation errors. To correct these we leverage the occlusion order of overlapping bounding boxes based on the classiﬁcation scores. The corrected instance and occlusion segmentation masks are fed back into the CompositionalNet to mask out those features that induced segmentation errors, and to improve the prediction of the object class.
We perform extensive experiments on the KITTI IN-Stance dataset (KINS). We further introduce a synthetic dataset that comprises artiﬁcially generated images of par-tially occluded objects, which are generated by superim-posing segmented objects from the KITTI. The synthetic generation of partially occluded images enables us to eval-uate custom types of occlusion challenges such as: pair-wise occlusion, multi-object occlusion and mixed occlusion containing both known and unknown object classes as oc-cluders. Our experimental results highlight that reasoning about multi-object occlusion signiﬁcantly enhances the ro-bustness of deep networks as it enables them to detect er-roneous feed-forward predictions and self-correct through
In summary, our reasoning about multi-object occlusion. contributions in this work are: 1. We introduce a deep network for multi-object in-stance segmentation that is robust to occlusion and can be trained from bounding box super-vision only. Speciﬁcally, our network deﬁnes a generative model of multiple objects and achieves enhanced robustness through reasoning about multi-object occlusion. 2. We introduce an Occlusion Reasoning Module (ORM) that enables efﬁcient inference in generative mod-els with multiple objects. In particular, it detects erroneous feed-forward predictions and and corrects them through rea-soning about the occlusion order of objects. 3. We achieve state-of-the-art performance at instance segmentation under occlusion on the KITTI INStance (KINS) dataset. 4. We introduce an occlusion challenge generated from real-world segmented objects with accurate annotations and propose a taxonomy of occlusion scenarios that pose a par-ticular challenge for computer vision. 2.