Abstract
In multi-object tracking, the tracker maintains in its memory the appearance and motion information for each object in the scene. This memory is utilized for ﬁnding matches between tracks and detections, and is updated based on the matching. Many approaches model each target in isolation and lack the ability to use all the targets in the scene to jointly update the memory. This can be problematic when there are similarly looking objects in the scene. In this paper, we solve the problem of simultaneously considering all tracks during memory updating, with only a small spatial overhead, via a novel multi-track pooling module. We addi-tionally propose a training strategy adapted to multi-track pooling which generates hard tracking episodes online. We show that the combination of these innovations results in a strong discriminative appearance model under the bilin-ear LSTM tracking framework, enabling the use of greedy data association to achieve online tracking performance.
Our experiments demonstrate real-time, state-of-the-art on-line tracking performance on public multi-object tracking (MOT) datasets. The code and trained models are available at https://github.com/chkim403/blstm-mtp. 1.

Introduction
In the typical tracking-by-detection setting of multi-object tracking, a trained target detector is assumed to exist, and the goal of the tracking algorithm is to solve the data association problem: associating detections from different frames into tracks. The standard approach involves building an appearance model and a motion model for each target be-ing tracked. The appearance model stores features from past appearances, which are compared against detections in each new frame, and the motion model predicts where the target will be located in the next frame. Because of the ambiguity in appearance, many previous trackers utilized sophisticated
* Part of this work was conducted while Chanho Kim was visiting
Oregon State University. data association schemes that relied on evidence from mul-tiple frames to determine the correct track. These choices result in a tracker which is not capable of real-time online performance, i.e. it cannot generate a result without delay after processing a new frame in the video. This is unfortu-nate, because real-time online tracking is critically impor-tant for numerous practical applications in AI. For example, in robotics applications such as autonomous driving, online processing is critical to support real-time decision-making.
One issue that has necessitated sophisticated data asso-ciation schemes is that the appearance models are usually built to match tracks and detections individually, without considering other tracks and detections in the matching pro-cess. This approach does not have sufﬁcient discriminative power to address the ambiguities arising when several sim-ilar targets move adjacent to each other in the video, e.g. multiple men in black suits. In this situation, either more subtle features need to be utilized for target discrimination, or the likelihood of the matching needs to be decreased to accommodate this uncertainty. This in turn requires the matching approach to utilize the appearance information from other nearby tracks in making a determination.
This paper introduces a novel approach to appearance modeling that takes all tracked objects into account when matching detections. Suppose each track has a stored on-line memory about all of its past appearances, we propose a novel multi-track pooling module which stores a max-pooled version of the memory from all other tracks. This extension allows the appearance model to take into account online negative examples from other objects within the same video (see Fig. 1). We show that multi-track pooling greatly enhances the discriminative power of the appearance model for track scoring and improves overall performance.
We leverage the additional discriminative power of our matching approach to achieve real-time online tracking by means of a simple, greedy data association method: Each track is matched with the detection that has the highest like-lihood of belonging to the track. Greedy association is ex-tremely efﬁcient, resulting in fast performance. In this work we test the hypothesis that our discriminative appearance and motion modeling can enable this simple data associa-19553
2 3 4 5 1
LSTM
LSTM
LSTM
LSTM
LSTM
Proposed Work
Previous Work
Track 1’s Classifier
Track 1’s Classifier
Track 2’s Classifier
Track 2’s Classifier
·
·
·
·
·
·
Figure 1. Existing recurrent neural network-based track classiﬁers used only matched detections for updating its appearance memory during tracking. This does not consider other objects in the scene (i.e. negative examples), which may have similar appearances. We propose to improve the predicted likelihood of such a classiﬁer by augmenting its memory with appearance information about other tracks in the scene with multi-track pooling, leveraging the appearance information from the full set of tracks in the scene. The resulting classiﬁer learns to adapt its prediction based on the information from other tracks in the scene. tion mechanism to achieve strong tracking performance.
Our online tracking framework additionally incorporates components from recent tracking works. First, we utilize the Bilinear LSTM framework [17] as the basis for our matching approach, due to its effective memory construc-tion. Second, we incorporate training strategies that han-dle long tracks using truncated backpropagation through time [32], in contrast to prior works [31, 17] in which the models were trained with short tracks. Third, we ex-tend object tracks to frames without detections using a mo-tion model, thereby compensating for missing detections.
Fourth, we trained a bounding box corrector to correct bounding box coordinates, which is especially helpful for the extended tracks.
In summary, this paper makes the following contribu-tions: 1. A novel multi-track pooling module which enables a track classiﬁer to take online negative examples into account during testing and thus adjust its prediction adaptively depending on the objects in the scene. 2. A training strategy that is adapted to train the proposed track pooling module by utilizing within-batch depen-dencies among tracks and that enables long sequence training with the original full tracks instead of short tracks used in [31, 17]. 3. A real-time, online multi-object tracking algorithm that achieves state-of-the-art online tracking perfor-mance on standard tracking benchmarks. 2.