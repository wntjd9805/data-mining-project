Abstract
Semi-supervised learning (SSL) is a key approach to-ward more data-efﬁcient machine learning by jointly lever-age both labeled and unlabeled data. We propose Al-phaMatch, an efﬁcient SSL method that leverages data aug-mentations, by efﬁciently enforcing the label consistency between the data points and the augmented data derived from them. Our key technical contribution lies on: 1) us-ing alpha-divergence to prioritize the regularization on data with high conﬁdence, achieving similar effect as FixMatch
[32] but in a more ﬂexible fashion, and 2) proposing an optimization-based, EM-like algorithm to enforce the con-sistency, which enjoys better convergence than iterative reg-ularization procedures used in recent SSL methods such as
FixMatch, UDA, and MixMatch. AlphaMatch is simple and easy to implement, and consistently outperforms prior arts on standard benchmarks, e.g. CIFAR-10, SVHN, CIFAR-100, STL-10. Speciﬁcally, we achieve 91.3% test accuracy on CIFAR-10 with just 4 labelled data per class, substan-tially improving over the previously best 88.7% accuracy achieved by FixMatch. 1.

Introduction
[7]
Semi-supervised learning (SSL) is a powerful paradigm for leveraging both labeled and unlabeled data jointly in machine learning (ML). Effective SSL methods can help build accurate prediction out of very limited la-beled data, and can also boost state-of-the-art performance and robustness in typical supervised learning by leveraging extra unlabeled data [see e.g., 20, 39, 41]. Due to the high cost of collecting labels and the availability of a vast amount of unlabeled data, breakthroughs in SSL can dramatically advance the application of ML in countless ﬁelds.
Recently, data augmentation has been shown a powerful tool for developing state-of-the-art SSL methods, includ-ing unsupervised data augmentation (UDA) [38], FixMatch
[32], MixMatch [2], ReMixMatch [3] and Π-model [30].
All these methods are based on the similar idea of enforcing the consistency between the label of a data point and that of its perturbed version generated by data augmentation. This encourages the learned models to be invariant under given data augmentation transforms, hence incorporating inherent structures of the data into semi-supervised learning.
The performance of these algorithms can be critically inﬂuenced by what matching objective and matching algo-rithm are used to enforce the consistency. For the objective,
UDA applies a KL divergence penalty to enforce the con-sistency uniformly on all the data points. More recently,
FixMatch shows that it is useful to focus on matching the consistency on the high conﬁdence data points with a hard thresholding approach, by applying regularization only on data with conﬁdence higher than a threshold and use the hard label as the target.
In terms of the matching algo-rithm, most of the existing methods, including UDA and
FixMatch, are based on a similar iterative regularization procedure that uses the label distribution predicted from the previous iteration as the target for the next step. Although being simple and intuitive, a key problem is that this iter-ative procedure does not correspond to optimizing a ﬁxed objective function, and hence may suffer from instability and non-convergence issues.
This work proposes two key algorithmic advances to im-prove the objective and algorithm for consistency matching in SSL: 1) we propose to use alpha-divergence to measure the label consistency. We show that, by using a large value of α in alpha-divergence, we can focus more on high con-ﬁdence instances in a way similar to the hard-thresholded regularization of FixMatch, but in a more “soft” and ﬂex-ible fashion. 2) We propose an optimization-based frame-work for consistency matching, which yields an EM-like algorithm with better convergence property than the com-monly used iterative regularization procedures. By com-bining these two key techniques, our main algorithm Al-phaMatch yields better SSL with more effective and stable consistency regularization.
Empirically, we ﬁnd that AlphaMatch consistently out-performs recently-proposed SSL methods such as Fix-113683
Match, ReMixMatch, MixMatch, and UDA both in terms of accuracy and data efﬁciency, on various benchmarks in-cluding CIFAR-10, SVHN CIAFR-100, and STL-10.
In particular, our method improves over the state-of-the-art method, FixMatch, across all the settings we tested. Our improvement is particularly signiﬁcant when the labels are highly limited. For example, on CIFAR-10, we improve the 88.71%±3.35% accuracy of FixMatch to 91.35%±3.38% when only 4 labelled images per class are given. 2.