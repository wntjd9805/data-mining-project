Abstract 1.

Introduction
What scene elements, if any, are indispensable for recog-nizing a scene? We strive to answer this question through the lens of an exotic learning scheme. Our goal is to iden-tify a collection of such pivotal elements, which we term as
Scene Essence, to be those that would alter scene recog-nition if taken out from the scene. To this end, we devise a novel approach that learns to partition the scene objects into two groups, essential ones and minor ones, under the supervision that if only the essential ones are kept while the minor ones are erased in the input image, a scene recog-nizer would preserve its original prediction. Speciﬁcally, we introduce a learnable graph neural network (GNN) for labelling scene objects, based on which the minor ones are wiped off by an off-the-shelf image inpainter. The features of the inpainted image derived in this way, together with those learned from the GNN with the minor-object nodes pruned, are expected to fool the scene discriminator. Both sub-jective and objective evaluations on Places365, SUN397, and MIT67 datasets demonstrate that, the learned Scene
Essence yields a visually plausible image that convincingly retains the original scene category.
Looking at the image in Fig. 1(a), we may effortlessly tell that it is a scene of a hotel room. But if we are asked to pinpoint a few indispensable objects in the scene, if any, that dedicate our recognition, it might take us some effort to ﬁg-ure them out: maybe the sofa, or the table, or a combination of both? If we human observers ﬁnd this to be a non-trivial task, shall we expect deep networks to be competent?
In this paper, we target at learning to extract a collec-tion of such scene objects, which, together with the scene background, are coined as Scene Essence. In other words,
Scene Essence comprises the scene background and pivotal scene objects, if any, that jointly make a scene a scene, and hence serves as a scene signature. We show an example of the learned Scene Essence, in Fig. 1(c), where only the sofa and the bed are preserved while all other objects are wiped off by an off-the-shelf image inpainter [91]. This derived
Scene Essence image successfully fools a state-of-the-art scene recognizer [99], since it is still categorized as a hotel room; in fact, even when we human observers look at this image, likely we will not even doubt it is being a hotel-room image. Should we, however, take one more object from the
Scene Essence, for example the bed as shown in Fig. 1(c), the scene recognizer will immediately alter its prediction, in this case to a living room, which indeed appears to be such 8322
Figure 2: (a) and (b) respectively show the original dorm scene image and its corresponding Scene Essence; (c) shows the learned
Scene Essence if provided with a label of bedroom, and (d) shows the one learned with a label of ofﬁce. for human.
Despite prior efforts on attribution maps [65, 73] and activation maps [101, 54] also aim to interpret the scene recognition rationale, the proposed Scene Essence distin-guishes itself from the perspective that it reasons at object level and meanwhile delivers a minimum set of objects to ensure the image being recognized as the original category.
Furthermore, Scene Essence comes with other unique and interesting properties, such as generating images of other categories and hence enabling scene transfer. For example, an image of the dorm category is shown in Fig. 2(a); when trained with the original label, Scene Essence will remove the dispensable objects like the books on the bed, and keep the essential ones as in Fig. 2(b). If, however, we train our network with other labels, such as bedroom or ofﬁce, Scene
Essence would consequently produce images displayed re-spectively in Fig. 2(c) and Fig. 2(d), which are indeed vi-sually convincing scenes from the two categories and hence offer an exotic and inexpensive way of conducting scene transfer.
We devise a novel approach to learning Scene Essence, by explicitly accounting for both object-level semantics and visual evidences. The core idea here is to learn a partition of scene objects into two groups, essential ones and minor ones, such that if the minor ones are erased by an image in-painter while the essential ones are preserved, a scene clas-siﬁer would not alter its predicted label. To this end, we propose an innovative network architecture that ﬁrst takes an image as input and conducts object detection using an off-the-shelf detector module. Each detected object is mod-eled as a node in a scene graph, which is then fed into a learnable hierarchical Graph Neural Network (GNN) for la-beling each node as essential or minor. Next, an off-the-shelf image inpainter is introduced to erase the minor ob-jects and produce the Scene Essence image, whose visual feature is concatenated with the features learned from GNN and afterwards fed into a scene discriminator. The GNN module, therefore, learns to update its parameters from the supervision back-propagated from the scene discriminator and the image inpaitner, and eventually specializes in iden-tifying essential objects.
In sum, our contribution is an exotic scene signature, termed as Scene Essence, that maintains a minimum set of scene objects to preserve its predicted label and meanwhile offers an inexpensive way for scene transfer. Scene Essence is derived via a novel network architecture, in which a GNN learns to categorize scene objects under the supervision that if only the essential ones are kept while the rest ones are wiped off, a scene recognizer will stick to its original pre-diction. We conduct extensive objective and subjective ex-periments to evaluate Scene Essence in terms of recognition accuracy, visual quality, and inter-category transferability, and showcase that it may readily serve as a new option for interpreting scene recognition rationale at the object level. 2.