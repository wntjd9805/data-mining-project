Abstract 1.

Introduction
In this paper we introduce SMPLicit, a novel generative model to jointly represent body pose, shape and clothing ge-ometry. In contrast to existing learning-based approaches that require training speciﬁc models for each type of gar-ment, SMPLicit can represent in a uniﬁed manner different garment topologies (e.g. from sleeveless tops to hoodies and to open jackets), while controlling other properties like the garment size or tightness/looseness. We show our model to be applicable to a large variety of garments including T-shirts, hoodies, jackets, shorts, pants, skirts, shoes and even hair. The representation ﬂexibility of SMPLicit builds upon an implicit model conditioned with the SMPL human body parameters and a learnable latent space which is semanti-cally interpretable and aligned with the clothing attributes.
The proposed model is fully differentiable, allowing for its use into larger end-to-end trainable systems. In the exper-imental section, we demonstrate SMPLicit can be readily used for ﬁtting 3D scans and for 3D reconstruction in im-ages of dressed people.
In both cases we are able to go beyond state of the art, by retrieving complex garment ge-ometries, handling situations with multiple clothing layers and providing a tool for easy outﬁt editing. To stimulate fur-ther research in this direction, we will make our code and model publicly available at http://www.iri.upc. edu/people/ecorona/smplicit/.
Building a differentiable and low dimensional genera-tive model capable to control garments style and deforma-tions under different body shapes and poses would open the door to many exciting applications in e.g. digital animation of clothed humans, 3D content creation and virtual try-on.
However, while such representations have been shown ef-fective for the case of the undressed human body [35, 45], where body shape variation can be encoded by a few pa-rameters of a linear model, there exist so far, no similar ap-proach for doing so on clothes.
The standard practice to represent the geometry of dressed people has been to treat clothing as an additive dis-placement over canonical body shapes, typically obtained with SMPL [4, 26, 37, 44]. Nevertheless, these types of ap-proaches cannot tackle the main challenge in garment mod-eling, which is the large variability of types, styles, cut, and deformations they can have. For instance, upper body cloth-ing can be either a sleeveless top, a long-sleeve hoodie or an open jacket. In order to handle such variability, existing approaches need to train speciﬁc models for each type of garment, hampering thus their practical utilization.
In this paper, we introduce SMPLicit, a topologically-aware generative model for clothed bodies that can be con-trolled by a low-dimensional and interpretable vector of pa-rameters. SMPLicit builds upon an implicit network ar-11875
chitecture conditioned on the body pose and shape. With these two factors, we can predict clothing deformation in 3D as a function of the body geometry, while controlling the garment style (cloth category) and cut (e.g. sleeve length, tight or loose-ﬁtting). We independently train this model for two distinct cloth clusters, namely upper body (includ-ing sleeveless tops, T-shirts, hoodies and jackets) and lower body (including pants, shorts and skirts). Within each clus-ter, the same model is able to represent garments with very different geometric properties and topology while allowing to smoothly and consistently interpolate between their ge-ometries. Shoes and hair categories are also modeled as independent categories. Interestingly, SMPLicit is fully dif-ferentiable and can be easily deployed and integrated into larger end-to-end deep learning systems.
Concretely, we demonstrate that SMPLicit can be read-ily applied to two different problems. First, for ﬁtting 3D scans of dressed people. In this problem, our multi-garment
“generic” model is on a par with other approaches that were speciﬁcally trained for each garment [37, 44]. We also ap-ply SMPLicit for the challenging problem of 3D reconstruc-tion from images, where we compare favorably to state-of-the-art, being able to retrieve complex garment geometries under different body poses, and can tackle situations with multiple clothing layers. Fig. 1 shows one such example, where besides reconstructing the geometry of the full out-ﬁt, SMPLicit provides semantic knowledge of the shape, allowing then for garment editing and body re-posing, key ingredients of virtual try-on systems.
To summarize, the main contributions of our work are: (1) A generative model that is capable of representing clothes under different topology; (2) A low-dimensional and semantically interpretable latent vector for controlling clothing style and cut; (3) A model that can be conditioned on human pose, shape and garment style/cut; (4) A fully differentiable model for easy integration with deep learn-ing; (5) A versatile approach that can be applied to both 3D scan ﬁtting and 3D shape reconstruction from images in the wild; (6) A 3D reconstruction algorithm that produces controllable and editable surfaces. 2.