Abstract
Universal style transfer retains styles from reference images in content images. While existing methods have achieved state-of-the-art style transfer performance, they are not aware of the content leak phenomenon that the im-age content may corrupt after several rounds of stylization process. In this paper, we propose ArtFlow to prevent con-tent leak during universal style transfer. ArtFlow consists of reversible neural ﬂows and an unbiased feature transfer module. It supports both forward and backward inferences and operates in a projection-transfer-reversion scheme. The forward inference projects input images into deep features, while the backward inference remaps deep features back to input images in a lossless and unbiased way. Extensive ex-periments demonstrate that ArtFlow achieves comparable performance to state-of-the-art style transfer methods while avoiding content leak. 1.

Introduction
Neural style transfer aims at transferring the artistic style from a reference image to a content image. Start-ing from [11, 13], numerous works based on iterative op-timization [12, 44, 30, 34] and feed-forward networks [23, 53, 3, 63] improve style transfer from either visual qual-ity or computational efﬁciency. Despite tremendous efforts, these methods do not generalize well for multiple types of style transfer. Universal style transfer (UST) is pro-posed to improve this generalization ability. The represen-tative UST methods include AdaIN [20], WCT [32], and
Avatar-Net [45]. These methods are continuously extended by [15, 22, 60, 1, 45, 33, 40, 31, 2, 56]. While achieving favorable results as well as generalizations, these methods are limited to disentangling and reconstructing image con-tent during the stylization process. Fig. 1 shows some ex-amples. Existing methods [32, 20, 45] effectively stylize
∗J. An and S. Huang contribute equally. This work is done when J.
An is an intern in Tencent AI Lab. The code is available at https:// github.com/pkuanjie/ArtFlow.
T
C
W
N
I a d
A t e
N
-r a t a v
A (a) Content (b) Style (c) Round 1 (d) Round 20
Figure 1. Content leak visualization. Existing style transfer meth-ods are not effective to preserve image content after several rounds of stylization process as shown in (d), although their performance is state-of-the-art in the ﬁrst round as shown in (c). content images in (c). However, image contents are cor-rupted after several rounds of stylization process where we send the reference image and the output result into these methods. We deﬁne this phenomenon as content leak and provide an analysis in the following:
Content leak appears due to the design of UST methods that usually consist of three parts: the ﬁrst part is a ﬁxed en-coder for image embedding, the second part is a learnable decoder to remap deep features back to images, and the third part is a style transfer module based on deep features. We observe that the ﬁrst part is ﬁxed. The appearance of content leak indicates the accumulated image reconstruction errors brought by the decoder, or the biased training process of ei-ther the decoder or the style transfer module. Speciﬁcally, the content leaks of WCT [32] and its variants [31, 40, 56] is mainly caused by the image reconstruction error of the decoder. The content leak of AdaIN series [20, 22, 60] and
Avatar-Net [45] are additionally caused by the biased de-coder training and a biased style transfer module, respec-tively. Sec. 3 shows more analyses.
In this work, we propose an unbiased style transfer framework called ArtFlow to robustify exisiting UST meth-ods upon overcoming content leak. Different from the prevalent encoder-transfer-decoder structure, ArtFlow in-862
>Ic
>Is
Encoder
T
Decoder
Out
>Ic
>Is
Out
PFN
T (a) Universal Style Transfer Framework (b) ArtFlow Framework
Figure 2. A comparison between the auto-encoder based style transfer framework and the proposed ArtFlow framework. troduces both forward and backward inferences to formu-late a projection-transfer-reversion pipeline. This pipeline is based on neural ﬂows [5] and only contains a Projection
Flow Network (PFN) in conjunction with an unbiased fea-ture transfer module. The neural ﬂow refers to a number of deep generative models [5, 18] which estimate density through a series of reversible transformations. Our PFN follows the neural ﬂow model GLOW [28] which consists of a chain of revertible operators including activation nor-malization layers, invertible 1 × 1 convolutions, and afﬁne coupling layers [6]. Fig. 2 shows the structure of ArtFlow.
It ﬁrst projects both the content and style images into latent representations via forward inference. Then, it makes unbi-ased style transfer upon deep features and reconstructs the stylized images via reversed feature inference.
The proposed PFN avoids the image reconstruction er-ror and image recovery bias which usually appear in the encoder-decoder framework. PFN allows unbiased and lossless feature extraction and image recovery. To this end,
PFN facilitates the comparison of style transfer modules in a fair manner. Based on PFN, we perform theoretical and empirical analyses of the inherent biases of style trans-fer modules adopted by WCT, AdaIN, and Avatar-Net. We show that the transfer modules of AdaIN and WCT are un-biased, while the transfer module of Avatar-Net is biased towards style. Consequently, we adopt the transfer modules of AdaIN and WCT as the transfer modules for ArtFlow to achieve an unbiased style transfer.
The contributions of this work are three-fold:
• We reveal the Content Leak issue of the state-of-the-art style transfer algorithms and identify the three main causes of the Content Leak in AdaIN [20], WCT [32], and Avatar-Net [45].
• We propose an unbiased, lossless, and reversible net-work named PFN based on neural ﬂows, which allows both theoretical and empirical analyses of the inherent biases of the popular style transfer modules.
• Based on PFN in conjunction with an unbiased style transfer module, we propose a novel style transfer framework, i.e., ArtFlow, which achieves comparable style transfer results to state-of-the-art methods while avoiding the Content Leak issue.
Figure 3. Loss curves of AdaIN [20] training: Using both content and style losses vs. only using the content loss. standing research topic. Before deep neural networks [49, 37, 59, 57] are applied to the style transfer, several algo-rithms based on stroke rendering [16], image analogy [17, 46, 10, 48, 35, 51, 50], and image ﬁltering [61] are pro-posed to make artistic style transfer. These methods usu-ally have to trade-off between style transfer quality, gen-eralization, and efﬁciency. Gatys et al. [11, 13] introduce a Gram loss upon deep features to represent image styles, which opens up the neural style transfer era. Inspired by
Gatys et al., numerous neural style transfer methods have been proposed. We categorize these methods into one style per model [29, 54, 23, 53, 55, 58, 44, 30], multi-style per model [7, 3, 19, 14], and universal style transfer meth-ods [4, 32, 20, 45, 15, 2, 56, 38, 60, 1] with respect to their generalization abilities. In this paper, our ArtFlow belongs to universal style transfer and it consists of reversible neural
ﬂows. The forward and backward inferences are utilized for lossless and unbiased image recovery.
Neural ﬂows. Neural ﬂows refer to a subclass of deep gen-erative models, which learns the exact likelihood of high dimensional observations (e.g., natural images, texts, and audios) through a chain of reversible transformations. As a pioneering work of neural ﬂows, NICE [5] is proposed to transform low dimensional densities to high dimensional observations with a stack of afﬁne coupling layers. Fol-lowing NICE, a series of neural ﬂows, including RealNVP
[6], GLOW [28], and Flow++ [18], are proposed to improve
NICE with more powerful and ﬂexible reversible transfor-mations. The recently proposed neural ﬂows [28, 18, 39] are capable of synthesizing high-resolution natural/face im-ages, realistic speech data [43, 26], and performing make-up transfer [8]. In this work, the proposed ArtFlow consists of a reversible network PFN and an unbiased feature trans-fer module. The content leak can be addressed via loss-less forward and backward inferences and unbiased feature transfer. In comparison, BeautyGlow [8] shares the similar spirits but is not applicable for unbiased style transfer. 3. Pre-analysis 2.