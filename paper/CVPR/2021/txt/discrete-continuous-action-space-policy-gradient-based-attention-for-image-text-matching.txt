Abstract
Image-text matching is an important multi-modal task with massive applications. It tries to match the image and the text with similar semantic information. Existing ap-proaches do not explicitly transform the different modali-ties into a common space. Meanwhile, the attention mech-anism which is widely used in image-text matching models does not have supervision. We propose a novel attention scheme which projects the image and text embedding into a common space and optimises the attention weights di-rectly towards the evaluation metrics. The proposed atten-tion scheme can be considered as a kind of supervised atten-tion and requiring no additional annotations. It is trained via a novel Discrete-continuous action space policy gradi-ent algorithm, which is more effective in modelling complex action space than previous continuous action space policy gradient. We evaluate the proposed methods on two widely-used benchmark datasets: Flickr30k and MS-COCO, out-performing the previous approaches by a large margin. 1.

Introduction
Computer Vision and Natural Language Processing are two important areas of modern artiﬁcial intelligence, which can be processed jointly in cross-modal tasks. A large amount of research has been conducted to bridge the vi-sion and language modalities [32, 35, 5, 19, 18]. Image-text matching or retrieval is one of the critical topics in this area, which has a huge application scope in many real-world sce-narios. The image-text matching requires a machine learn-ing model to extract the high-level semantic representations and measure the similarities across modalities accordingly.
Existing methods use deep learning models to extract the image and language features, and apply various met-ric learning techniques to automatically ﬁnd the seman-tic similarities between the samples from the two modali-*Corresponding Author
Figure 1: Our Motivations: The attention weights are utilised as a projection from each modality to a common space. Existing continuous PG assumes a simple Normal distribution. Instead, we considered the mean values as dis-crete actions ﬁrst and then use multiple Normal distribu-tions to form a compound distribution, which is more real-istic. Best Viewed in Colour. ties [5, 19, 18]. Metric learning is powerful in visual se-mantic embedding as it tries to measure and manipulate the similarities between samples regardless of the domain differences. However, it is not designed to perform an ex-plicit transformation from one modality to another, often leading to sub-optimal performance. Though there are ap-proaches apply Instance Loss [37], i.e., a classiﬁcation over image and text categories, to form a multi-task learning ap-proach with metric learning loss for image-text matching, the performance gain is limited as the Instance Loss opti-mises the embedding in the category domain, which does not perform explicit transformation either. An image often contains many ﬁne-grained objects. A ﬂat vector represen-tation from a vanilla deep CNN model such as ResNet [9] is not powerful enough to discover these objects and their rela-tionships. Hence, advanced methods employ image features from a pre-trained object detector [28] and apply the visual attention mechanism [35] on these features to discriminate the important features over irrelevant ones [1]. Attention mechanism plays a signiﬁcant role in varying computer vi-8096
sion tasks. It is considered as hidden neurons in these mod-els, but often leads to incorrect selection of image features for lacking a direct supervision [23].
In this paper, to make an explicit transformation and provide supervision to the attention mechanism in image-text matching, we propose a policy gradient (PG) [30] opti-mised attention adjustment over the visual and text features in image-text matching. The attention weights in our ap-proach can be considered as a transformation from a spe-ciﬁc modality to a common space, as the attention weights perform a vector transformation in the last image and text vectors used for matching, instead of selecting important features in the previous layers of the deep learning mod-els [35]. The attention weights are trained by the PG method with the batch-wise ranking metrics and the instance-wise
Average Precision (AP) as the reward function. These at-tention weights are directly optimised via PG algorithm to achieve optimal ranking results and higher AP metrics. It can be considered as a kind of supervised attention mecha-nism, and this supervision does not need any additional an-notations. This PG-based attention mechanism is straight-forward and is optimised towards the evaluation metrics. It is also more accurate than the conventional soft attention which is only a regular neuron.
To be more speciﬁc, as shown in Figure 1, we consider the attention weights generation as an action selecting pro-cess in PG, whose space can be ﬂexibly pre-deﬁned. The ac-tion space in conventional PG is discrete, which is not suit-able for the feature adjustment like in the attention mech-anism. One solution is applying a continuous action space
PG algorithm [20], which consider the action space as a
Gaussian distribution and sample action values from this distribution. Restricting the action distribution to Normal is not optimal, and such a hypothesis lacks theoretical and practical support. In reality, the distribution of the action space might be very complex, which cannot be described via a simple Normal distribution. Hence, we consider the action is continuous and sampled from multiple Normal dis-tributions with a different mean (µ) and standard deviation (σ) values. We ﬁrst treat the µ as discrete actions, sampled from a pre-deﬁned action space while σ is obtained from a neural model as it is continuous. We want to use this µ and σ to form a Normal distribution and sample continuous action from this distribution, which is applied as the atten-tion weights to adjust the feature representations for both the visual embedding and the text embedding. Usually, in conventional PG, we do not need the µ to be trainable as we only back-propagate the gradient to the log-probabilities.
In contrast, in this case, the subsequently obtained Normal distributions need the µ being able to be back-propagated to make the Normal distribution learn-able. As there in-volves sampling in obtaining the µ, it is not trainable in this current form. To make this µ differentiable, instead of di-rectly using greedy sampling or ǫ-greedy sampling. We use a Gumbel-softmax to relax the discreteness [12] and make the sampled µ trainable together with the Normal distribu-tion. We call this method “Discrete-continuous PG” as it involves both discrete and continuous action space, making them beneﬁt from each other. In fact, by using the discrete and continuous action space, the action space used to sam-ple the attention weights is a compound distribution, which can model a high complex distribution. We evaluate our algorithm and model on image-text matching task, achiev-ing state-of-the-art performance on two widely-used bench-mark datasets. To summarise, our contributions are three-fold: (1) We propose a novel attention supervision scheme for image-text matching task based on policy gradient. (2)
We propose a new Discrete-continuous policy gradient al-gorithm by leveraging both the discrete and continuous ac-tion space. (3) The achieved state-of-the-art results validate the effectiveness of the attention supervisions scheme and the novel policy gradient algorithm. 2.