Abstract
Pan-sharpening is a process of merging a high-resolution (HR) panchromatic (PAN) image and its cor-responding low-resolution (LR) multi-spectral (MS) image to create an HR-MS and pan-sharpened image. However, due to the different sensors’ locations, characteristics and acquisition time, PAN and MS image pairs often tend to have various amounts of misalignment. Conventional deep-learning-based methods that were trained with such mis-aligned PAN-MS image pairs suffer from diverse artifacts such as double-edge and blur artifacts in the resultant PAN-sharpened images. In this paper, we propose a novel frame-work called shift-invariant pan-sharpening with moving ob-ject alignment (SIPSA-Net) which is the ﬁrst method to take into account such large misalignment of moving object re-gions for PAN sharpening. The SISPA-Net has a feature alignment module (FAM) that can adjust one feature to be aligned to another feature, even between the two differ-ent PAN and MS domains. For better alignment in pan-sharpened images, a shift-invariant spectral loss is newly designed, which ignores the inherent misalignment in the original MS input, thereby having the same effect as opti-mizing the spectral loss with a well-aligned MS image. Ex-tensive experimental results show that our SIPSA-Net can generate pan-sharpened images with remarkable improve-ments in terms of visual quality and alignment, compared to the state-of-the-art methods. 1.

Introduction
The satellite images are being used in a wide range of applications such as environmental monitoring, surveil-lance systems, and mapping services as well. Google
EarthTM is one of the most popular virtual globe applica-tions. Such high-resolution multi-spectral images are ob-*Corresponding author.
Figure 1. Pan-sharpening results from different methods on
WorldView-3 dataset. Our proposed SIPSA-Net generates an artifact-free pan-sharpened image, where other methods generate blurry and distorted images. tained from commercialized pan-sharpening software that fuses low-resolution (LR) multi-spectral (MS) images and high-resolution (HR) single channel panchromatic (PAN) images to generate pan-sharpened (PS) images. The pro-duced PS images should have similar high-frequency details as the PAN images and similar colors as the MS images.
However, when the PS images in the virtual globe applica-tions are compared with the original PAN and MS images, many types of artifacts are often observed for which the de-tails of PS images are not as sharp as those of the PAN im-ages and colors appear to be distorted from the MS images.
Recently, many deep-learning-based pan-sharpening methods [6, 12, 16, 25, 27] have been proposed and shown to outperform previous state-of-the-art pan-sharpening methods [3, 4, 8, 15, 19]. Most of these methods train their networks by minimizing the difference between the pseudo-ground-truth MS images and the network output PS images 10166
in supervised manners, despite of the absence of the actual ground-truth PS images. One of the main difﬁculties of the pan-sharpening is the inherent misalignment between PAN and MS image pairs. Due to the different sensors’ character-istics, physical locations and capturing time, PAN and MS image pairs inevitably have large pixel-misalignment that is even worse for locally moving objects such as cars on a highway. This often leads to various artifacts in output PS images such as double edges and blur artifact especially on the moving object regions having extreme misalignment.
In this paper, we propose a novel framework called shift-invariant pan-sharpening (SIPSA-Net) that solves the PS problem considering the global misalignment as well as the local misalignment due to different acquisition time for moving objects on the ground. SIPSA-Net is optimized to align the colors from MS images to the corresponding shapes in PAN images through a newly proposed feature alignment module (FAM). SIPSA-Net further elaborates the alignment by utilizing our novel shift-invariant spectral loss that ignores the inherent misalignment in the original MS input, thereby having the same effect as optimizing the spectral loss with an well-aligned MS image. As shown in Fig. 1, the output image from SIPSA-Net shows good alignment between structures and colors especially around the moving cars. In the PS outputs from other methods, the colors of the cars are smeared in the upward direction as comet tail artifacts. All source codes are publicly available at https://github.com/brachiohyup/SIPSA. 1.1. Our contributions
Our contributions can be summarized as follows:
• Alignment-aware pan-sharpening: Except for the global registration, none of the previous PS methods considered the extreme local misalignment induced by moving ob-jects. We propose the ﬁrst deep-learning-based PS method that can generate both locally and globally well-aligned PS images from misaligned PAN-MS image pairs.
• Feature alignment module: The newly proposed feature alignment module learns a probability map of offsets in the feature domain for the aligned MS pixels with respect to the pixel locations in the PAN image to cope with both global and local misalignment. The probability map and the features extracted from the MS image are then used to generate the aligned MS image with respect to its corre-sponding PAN image.
• Shift-invariant spectral (SiS) loss: The conventional deep-learning-based PS methods have optimized their networks by using the misaligned MS images as the pseudo-ground-truth. However, this approach leads to artifacts in the PS outputs such as double-edge and blur artifacts. To remedy this, a SiS loss is proposed, which is effective in trans-ferring the spectral information from the misaligned MS images to match the corresponding details in PAN images.
SiS loss is calculated as the minimum difference between the output PS image and each of the multiple-shifted ver-sions of MS input images. In this way, the loss becomes shift-invariant in color registration of the misaligned MS image to the PAN image. 2.