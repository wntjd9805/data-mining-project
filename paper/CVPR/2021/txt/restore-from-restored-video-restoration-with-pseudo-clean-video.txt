Abstract
In this study, we propose a self-supervised video denois-ing method called “restore-from-restored.” This method
ﬁne-tunes a pre-trained network by using a pseudo clean video during the test phase. The pseudo clean video is ob-tained by applying a noisy video to the baseline network.
By adopting a fully convolutional neural network (FCN) as the baseline, we can improve video denoising performance without accurate optical ﬂow estimation and registration steps, in contrast to many conventional video restoration methods, due to the translation equivariant property of the
FCN. Speciﬁcally, the proposed method can take advantage of plentiful similar patches existing across multiple con-secutive frames (i.e., patch-recurrence); these patches can boost the performance of the baseline network by a large margin. We analyze the restoration performance of the
ﬁne-tuned video denoising networks with the proposed self-supervision-based learning algorithm, and demonstrate that the FCN can utilize recurring patches without requir-ing accurate registration among adjacent frames.
In our experiments, we apply the proposed method to state-of-the-art denoisers and show that our ﬁne-tuned networks achieve a considerable improvement in denoising performance. 1.

Introduction
Video restoration, which aims to recover the high-quality video frames from the low-quality video, is one of the oldest research ﬁelds in video processing. Video denoising, which removes noise in the video frames, has been investigated considerably. However, estimating a clean image from a corrupted frame is a well-known inverse problem. To solve such an ill-posed problem, various types of approaches, in-* Corresponding author.
Code is available at https://github.com/shlee0/RFR-video-denoising. cluding prior model, likelihood model, optimization, and deep learning techniques, have been introduced.
A common natural image property used for image restoration is patch-recurrence in which similar patches ex-ist within a single image. Particularly, patch-recurrence has been considerably studied in single-image super-resolution (SR) methods [9, 11, 12]. Although these patches can be de-formed by camera and/or object motion in a video, patch-recurrence over neighboring video frames is much richer than that of a single image and can further improve the qual-ity of the restored frames [19, 18]. Moreover, rich patch-recurrence information can greatly help in the ﬁne-tuning of video restoration networks during the test stage, without using ground-truth clean images.
Lehtinen et al. [16] proposed single-image denoising method (noise-to-noise), which allows the training of the restoration network without ground-truth clean images.
Ehret et al. [7] proposed a frame-to-frame training tech-nique, which extends the noise-to-noise training algorithm for video restoration; the frame-to-frame training algorithm can also perform ﬁne-tuning without using the ground-truth clean video by aligning noisy patches among consecutive frames using optical ﬂow. However, estimating accurate optical ﬂow under large displacements, occlusion, and se-vere degradation (e.g., noise and blur) is a challenging task.
Thus, in this work, we propose a new training algorithm called “restore-from-restored,” which allows ﬁne-tuning of pre-trained networks without using the ground-truth clean video and accurate optical ﬂow for registration.
Our proposed method updates the parameters of pre-trained networks using pseudo clean images, which are out-puts of the pre-trained baseline networks from noisy input frames. Our algorithm is simple yet effective for removing noise in video frames and works particularly well with the existence of numerous recurring patches. That is, we gen-erate pairs of training images, which are composed of the pseudo clean video and its noisy versions, to ﬁne-tune the network. In practice, pixel locations of the same patches in different video frames vary due to motions, but with the aid 3537
of the translation equivariant property of a fully convolu-tional network (FCN), our algorithm can update the network parameters without using optical ﬂow to align the translated patches only if they are fully convolutional. We demonstrate the superiority of the proposed algorithm by applying it to state-of-the-art video denoising networks and providing im-proved denoising results. The contributions of this study are summarized as follows:
• We propose a novel self-supervised training algorithm to ﬁne-tune fully pre-trained networks without using the clean ground-truth video.
• We explain why and how the proposed training scheme works with the patch-recurrence property.
• The proposed method can be easily integrated with state-of-the-art denoising networks and yields state-of-the-art denoising results on the benchmark datasets in-cluding not only synthetic but also real noise. 2.