Abstract
Various combinations of cameras enrich computa-tional photography, among which reference-based super-resolution (RefSR) plays a critical role in multiscale imag-ing systems. However, existing RefSR approaches fail to accomplish high-ﬁdelity super-resolution under a large res-olution gap, e.g., 8× upscaling, due to the lower consider-ation of the underlying scene structure. In this paper, we aim to solve the RefSR problem in actual multiscale camera systems inspired by multiplane image (MPI) representation.
Speciﬁcally, we propose Cross-MPI, an end-to-end RefSR network composed of a novel plane-aware attention-based
MPI mechanism, a multiscale guided upsampling module as well as a super-resolution (SR) synthesis and fusion module.
Instead of using a direct and exhaustive matching between the cross-scale stereo, the proposed plane-aware attention mechanism fully utilizes the concealed scene structure for efﬁcient attention-based correspondence searching. Fur-ther combined with a gentle coarse-to-ﬁne guided upsam-pling strategy, the proposed Cross-MPI can achieve a ro-bust and accurate detail transmission. Experimental results on both digitally synthesized and optical zoom cross-scale data show that the Cross-MPI framework can achieve su-perior performance against the existing RefSR methods and is a real ﬁt for actual multiscale camera systems even with large-scale differences. 1.

Introduction
With computational photography prospering over the past few decades, higher-quality and ﬁdelity imaging is in sustained demand for both industry and daily life. Hybrid multiscale imaging camera systems [27, 29, 9, 19] stand out for their capability to compose different camera char-acteristics and obtain a much higher spatial bandwidth. Hy-brid multiscale imaging has been successfully applied in various imaging systems, including hybrid light ﬁeld cam-eras [27], gigapixel video systems [29], and mobile phones
Figure 1: Top: Our Cross-MPI network takes cross-scale stereo images as input and generates super-resolved MPIs through a delicate plane-aware attention mechanism and an effective multiscale guided upsampling module. Bottom:
An 8× SR comparison between Cross-MPI and the state-of-the-art RefSR work, CrossNet [37] and TTSR [28], along with our intermediate depth estimation result. with multi-camera systems [9, 19]. To realize hybrid mul-tiscale imaging, one of the key issues is how to match and fuse cross-resolution images from different cameras under certain perspective parallax.
Reference-based image super-resolution (RefSR) has been proposed to solve the cross-scale reconstruction prob-lem and applied to gigapixel video systems [29] or hy-brid light ﬁeld imaging systems [1, 27]. RefSR aims to super-resolve a low-resolution (LR) image through addi-tional high-resolution (HR) reference image(s). Unlike data-driven single image super-resolution (SISR) [16, 33, 32, 14, 17], which only utilizes prior knowledge learned from massive data to build an upsampling model, RefSR can produce much more satisfactory results due to the ad-ditional HR references, especially for upsampling factors 14842
larger than 4×.
Currently, most RefSR methods typically follow a
“warp-and-synthesis” pipeline, which can be further di-vided into two branches based on different detail trans-fer schemes, including pixel-alignment and patch-matching
RefSR. For the pixel-alignment RefSR, the warping pro-cess is conducted based on a certain pixel-to-pixel map-ping between two images, e.g., optical ﬂow [37] and depth map [27, 35]. Nevertheless, pixel-alignment RefSR would fail when dealing with large-parallax cases or image pairs under a large resolution gap due to the lack of ability to capture long-distance correspondences. For the patch-matching RefSR [1, 36, 27, 34, 28], image patches are ex-tracted to locate correspondences and blended accordingly for HR detail transmission. However, it is limited by com-plex textures or textureless areas and inherently generates grid artifacts due to averaging window blurs. To summa-rize, existing RefSR methods neglect the underlying scene structure of cross-scale views, and cannot capture corre-spondences and transfer high-ﬁdelity details with large res-olution gaps (e.g., 8×) and large parallax.
In this paper, we set sights on an emerging scene rep-resentation and view synthesis framework, i.e., multiplane images (MPIs), to solve the cross-scale RefSR problem in actual multiscale camera systems. Thanks to the MPIs, the performance of image-based novel view synthesis [38, 23, 22, 5, 18] has drastically improved in the last few years. The
MPI representation has many good properties, including the ability to capture concealed surfaces from the input views and the adaptability to discontinuous edges and transparent scenes. However, the MPI estimation requires image pairs to have the same resolution with slight viewpoint changes, which is not available in RefSR tasks, especially when the resolution gap of the input pair is up to 8×.
To fully understand the scene structure, we propose an end-to-end MPI-based approach that fully explores the properties of cross-scale image pairs by leveraging vanilla MPIs in an efﬁcient multiscale guided coarse-to-ﬁne pipeline. First, we introduce a novel MPI represen-tation established on a lightweight plane-aware attention module. Compared with the original MPI estimation net-work with simple concatenation and convolution, our plane-aware attention mechanism explicitly captures correspon-dences along depth planes. Moreover, compared with pop-ular non-local attention mechanisms [25, 6, 24, 28], which have to maintain a large matrix for exhaustive pixel-to-pixel comparison, it takes much fewer computations and less stor-age space. Second, to estimate robust and detailed corre-spondences in a space with a considerable resolution differ-ence, e.g., 8×, we design a multiscale guided upsampling module. This module takes the correspondences captured in LR space as input and conducts gentle correspondence upsampling with guidance from the HR reference view in a coarse-to-ﬁne manner, producing super-resolved MPIs.
Finally, accurate transmission and fusion of high-quality details can be accomplished utilizing the obtained super-resolved MPI representation. The entire pipeline is de-signed in an end-to-end fashion and can infer high-ﬁdelity depth information in an unsupervised manner. Experimen-tal results show that our method is visually and quantita-tively superior to existing methods with high computational efﬁciency. We also build a real hybrid cross-scale stereo system and collect zooming data to validate the superior performance of the proposed algorithm. The main contri-butions of this paper are as follows:
• We take a close look at the RefSR problem through the lens of the MPI representation, achieving super-resolution up to 8× on real hybrid imaging systems.
• We propose a novel plane-aware attention mechanism for MPI estimation that can achieve more explicit and efﬁcient correspondence estimation compared with the original direct concatenation-and-convolution opera-tion.
• We propose a novel multiscale guided upsampling module for cross-scale multiplane image synthesis that can solve the matching problem under large resolution differences. A ﬁne-detailed depth map that encodes the scene structure can also be inferred. 2.