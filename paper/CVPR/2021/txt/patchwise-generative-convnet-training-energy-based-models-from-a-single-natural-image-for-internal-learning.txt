Abstract raising the following fundamental question:
Exploiting internal statistics of a single natural im-age has long been recognized as a signiﬁcant research paradigm where the goal is to learn the internal distribu-tion of patches within the image without relying on exter-nal training data. Different from prior works that model such a distribution implicitly with a top-down latent vari-able model (e.g., generator), this paper proposes to explic-itly represent the statistical distribution within a single nat-ural image by using an energy-based generative framework, where a pyramid of energy functions, each parameterized by a bottom-up deep neural network, are used to capture the distributions of patches at different resolutions. Meanwhile, a coarse-to-ﬁne sequential training and sampling strategy is presented to train the model efﬁciently. Besides learning to generate random samples from white noise, the model can learn in parallel with a self-supervised task (e.g., recover the input image from its corrupted version), which can fur-ther improve the descriptive power of the learned model.
The proposed model is simple and natural in that it does not require an auxiliary model (e.g., discriminator) to assist the training. Besides, it also uniﬁes internal statistics learning and image generation in a single framework. Experimen-tal results presented on various image generation and ma-nipulation tasks, including super-resolution, image editing, harmonization, style transfer, etc, have demonstrated the ef-fectiveness of our model for internal learning. 1.

Introduction
Learning internal statistics or modeling the internal dis-tribution of patches within a single natural image can date back to learning statistical models for texture synthesis in
In 1926, a pioneer Julesz [16] initiated computer vision. the research on texture perception in pre-attentive vision by
*This work was conducted when Zilong Zheng was a research intern at
Baidu Research – 10900 NE 8th St. Bellevue, WA 98004, USA.
What features and statistics are characteristics of a texture pattern, so that texture pairs that share the same features and statistics cannot be told apart by pre-attentive human visual perception?
— B´ela Julesz [16]
Julesz’s question implies two challenging tasks: (1) What are the internal statistical properties that deﬁne a texture from the human perception perspective? (2) Given a set of statistical properties, how can we synthesize diverse realis-tic texture patterns with identical internal statistical proper-ties? These two questions motivate various researchers on pursuing statistical representation and learning frameworks for texture synthesis. Representative pioneer works include k-gon statistics [45], primal sketch [22], and FRAME (Fil-ters, Random ﬁeld, And Maximum Entropy) [46] etc. The
FRAME, in particular, models texture as an energy-based model (EBM) [19], seeking to represent stochastic textures by simultaneously learning statistics of textures based on
Gabor ﬁlter responses and generating novel texture patterns that exhibit the same statistics as the learned texture image by Gibbs sampling [10].
Empowered with the recent development of deep learn-ing techniques, the energy-based Generative ConvNet [36] (also known as DeepFRAME model [34]) has been pro-posed as a deep generalization of the FRAME model for modeling high dimensional signals. Remarkable successes of the generative ConvNets have been shown in model-ing and synthesizing images [36, 6, 27, 5, 12], video se-quences [41, 42], 3D voxels [38, 39], molecule [4], un-ordered point clouds [37], etc.
More recently, the computer vision community has shown a growing interest in the research topic of deep inter-nal learning (DIL), with works [33, 30, 28] that train deep models on a single natural example. In this paper, we bring the powerful energy-based generative ConvNet framework into DIL by proposing an unconditional generative model 12961
learned from a single natural image. Speciﬁcally, we show that the internal statistics of overlapping patches within an image can be learned by an energy-based generative Con-vNet, in which the internal statistics are represented by an energy function parameterized by a deep convolutional neu-ral network, and the generation is driven by the estimated energy function. To capture different scales of internal sta-tistical properties, we sequentially learn a pyramid of EBMs with different resolutions in a coarse-to-ﬁne manner. The
EBM at each scale is a generative ConvNet and trained by the “analysis by synthesis” scheme, in which we gener-ate samples from the EBM via Markov chain Monte Carlo (MCMC) [21, 1] and then use the samples to compute the gradient of the log-likelihood to update the model parame-ters. Taking advantage of the multiple resolution setting, the sampling of each EBM can be more efﬁcient by using a se-quential sampling strategy, where the lower resolution EBM uses its synthesized images to initialize the MCMC of the higher resolution EBM. Once the EBMs are trained from a single image, the pyramid of the learned statistics can be useful for different vision tasks, such as generation of im-ages with complex structures and textures, super-resolution, image editing, style transfer, and harmonization. The pro-posed energy-based internal learning framework is appeal-ing because of the following aspects:
• Architecture efﬁciency: Each EBM at a different reso-lution only contains one single bottom-up network as the energy function, and does not need any other assisting network architecture for joint training.
• Training efﬁciency: The EBM relies on maximum like-lihood estimation (MLE), which in general does not en-counter the mode collapse issue that would commonly oc-cur in adversarial learning [11].
• Representation efﬁciency: The energy-based learning amounts to training a model that can synthesize images that match the observed statistics. It uniﬁes the concepts of description and generation into one single framework.
The main contributions of this work are four-fold: (i)
We are the ﬁrst to study energy-based deep internal learning from a single image. (ii) We propose to sequentially train and sample from a pyramid of EBMs with different resolu-tions in a coarse-to-ﬁne manner for efﬁcient sampling, sta-ble training and powerful representation. (iii) To enhance the training, we propose to train our energy-based frame-work in parallel with some self-supervised tasks. (iv) We provide strong results in our experiments to verify the ef-fectiveness of the proposed framework in a wide range of image generation and manipulation tasks. 2.