Abstract
Recently, deep learning based methods have demon-strated promising results on the graph matching problem, by relying on the descriptive capability of deep features extracted on graph nodes. However, one main limitation with existing deep graph matching (DGM) methods lies in their ignorance of explicit constraint of graph structures, which may lead the model to be trapped into local mini-mum in training. In this paper, we propose to explicitly for-mulate pairwise graph structures as a quadratic constraint incorporated into the DGM framework. The quadratic con-straint minimizes the pairwise structural discrepancy be-tween graphs, which can reduce the ambiguities brought by only using the extracted CNN features. Moreover, we present a differentiable implementation to the quadratic constrained-optimization such that it is compatible with the unconstrained deep learning optimizer. To give more pre-cise and proper supervision, a well-designed false matching loss against class imbalance is proposed, which can bet-ter penalize the false negatives and false positives with less overﬁtting. Exhaustive experiments demonstrate that our method achieves competitive performance on real-world datasets. The code is available at: https://github. com/Zerg-Overmind/QC-DGM . 1.

Introduction
Graph matching aims to ﬁnd an optimal one-to-one node correspondence between graph-structured data, which has been widely used in many tasks [3, 6, 9, 14, 20, 37]. By in-tegrating the similarity between nodes and edges in a com-binatorial fashion, graph matching is often mathematically formulated as a quadratic assignment problem (QAP) [29].
The study of this paper is funded by the National Natural Sci-ence Foundation of China (NSFC) under grant contracts No.61922065,
No.61771350 and No.41820104006 and 61871299. It is also supported by Supercomputing Center of Wuhan University.
Corresponding author: Gui-Song Xia (guisong.xia@whu.edu.cn). (a) DGM without quadratic constraint (b) DGM with quadratic constraint (our method)
Figure 1. Deep graph matching with/without quadratic constraint.
Matching results are in left and the predicted (black) v.s. the ground truth (red) correspondence matrices are in right.
QAP is known to be NP-hard [16], and various approxima-tion techniques [25, 26, 28, 34] have been proposed to make it computationally tractable.
Until recently, deep graph matching (DGM) methods give birth to many more ﬂexible formulations [13, 32, 39, 45] besides traditional QAP. DGM aims to learn the mean-ingful node afﬁnity by using deep features extracted from convolutional neural network. To this end, many existing
DGM methods [32, 39, 45] primarily focus on the feature modeling and reﬁnement for more accurate afﬁnity con-struction. The feature reﬁnement step is expected to capture the implicit structure information [39] encoded in learnable parameters. However, nodes with similar deep features are hard to distinguish from each other in deep graph match-ing, while their structure contexts may be very different.
Moreover, the implicit structure information is not speciﬁc enough, which is insufﬁcient to clearly represent the struc-tural discrepancy over graphs (e.g., Fig. 1(a)).
In traditional graph matching, it is common to incor-porate pairwise structures into the formulation to enhance matching accuracy [25], which inspired us to consider quadratic structural constraint in deep graph matching to maximize the adjacency consensus and achieve global con-sistency. More precisely, we use the pairwise term of 5069
Figure 2. Overview of our proposed architecture for deep graph matching under quadratic constraint. Node attributes consisting geometric prior and deep features are reﬁned to build the initial node afﬁnity matrix, which is followed by a Sinkhorn layer and then further optimized under quadratic constraint (QC). Loss between the prediction and the ground truth (GT) is calculated by the proposed false matching loss (FM-Loss).
Koopmans-Beckmann’s QAP [29] as our quadratic con-straint to minimize the adjacency discrepancy of graphs to be matched (e.g., Fig. 1(b)). To this end, we present a modiﬁed Frank-Wolfe algorithm [23], which is a differen-tiable optimization scheme w.r.t. learnable parameters in our model and the relaxed Koopmans-Beckmann’s QAP.
Another important issue of deep graph matching is class imbalance. Concretely, the result of a graph matching task is usually represented as a permutation matrix, where only a small portion of the entries take the value of one represent-ing the pairs to be matched while the rest are zero-valued, leading to the imbalance between matched and unmatched entries. In case of such class imbalance, it will be problem-atic to establish the loss function between predicted match-ing matrices and ground truth matrices by using the con-ventional cross-entropy-type loss functions (see Section 3.4 for details). To our best knowledge, there is no loss func-tion speciﬁcally designed for deep graph matching to take care of the class imbalance issue so far. To this end, we de-sign a novel loss function for deep graph matching, called
False Matching Loss, which will be experimentally shown to be better for dealing with class imbalance and overﬁtting in compared with previous works.
Our main contributions are highlighted as follows: 2. Preliminaries and