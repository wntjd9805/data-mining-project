Abstract
Video quality assessment for User Generated Content (UGC) is an important topic in both industry and academia.
Most existing methods only focus on one aspect of the per-ceptual quality assessment, such as technical quality or compression artifacts. In this paper, we create a large scale dataset to comprehensively investigate characteristics of generic UGC video quality. Besides the subjective ratings and content labels of the dataset, we also propose a DNN-based framework to thoroughly analyze importance of con-tent, technical quality, and compression level in perceptual quality. Our model is able to provide quality scores as well as human-friendly quality indicators, to bridge the gap be-tween low level video signals to human perceptual quality.
Experimental results show that our model achieves state-of-the-art correlation with Mean Opinion Scores (MOS). 1.

Introduction
Video streaming services currently consume the majority of today’s internet trafﬁc [23]. Service providers typically optimize and stream transcoded versions of the content that may have come from a professional (e.g., Netﬂix) or ca-In the former case, the sual creator (e.g., social media). service provider has a pristine original and can rely on full-reference video quality assessment methods to optimize the quality / bitrate of transcodes sent to viewers. Instead, so-cial media platforms often serve User Generated Content (UGC), where the non-pristine version shared by a user of-ten has pre-existing distortions or compression artifacts.
Given the prevalence of UGC on social media sharing platforms, understanding the perceptual subjective video quality of such content (and compressed versions of it) are important to make informed quality of service trade-offs.
Unlike early approaches at blind video and image quality assessment, where a set of pre-existing distortions is ap-plied to pristine content [36, 16], the biggest challenge of
UGC is its diversity due to several factors. First, the con-tent could be a popular live show watched by millions of people, or a bunch of meaningless frames with no views.
Second, the original quality could be created by a 4K HDR camera with professional post-processing, or captured by a low-end shaky camera. Finally, it is unclear how many ad-ditional operations have been applied on the video: some videos have been cropped, rescaled, or heavily compressed before being uploaded. The UGC video quality discussed in this paper is a generic concept, encompassing a mixture of content attractiveness, aesthetic quality [21, 29], and com-pression artifacts [39]. Each of these factors affects a view-ers’ expectation of the video quality, and may signiﬁcantly inﬂuence their watching experience.
While an uploader may not be able to alter the subject matter of the video, feedback that quantiﬁes the contributing perceptual quality factors may beneﬁt the uploader. Also, understanding the quality of the original can be used by the service provider to optimize recommendation systems (if multiple videos are present at a single event) or to further compress low quality originals with little or no perceptual impact on the ﬁnal result [35]. Taking advantage of such optimizations allows for better user experience at lower cost for the provider. Perceptual quality metrics are also becom-ing an integral part of image and video enhancement frame-works [13, 28, 40], and have shown promising results.
In this paper, we propose a framework to analyze video quality in a comprehensive way to allow for all the above applications. Unlike traditional video quality assessment metrics that work as black boxes outputting a single quality score, our model also provides human-friendly descriptors (as illustrated in Table 1) that decomposes the perceptual quality of the content into its constituent parts. Our contri-butions are as follows1:
• An enhanced dataset to explore distinct characteristics of
UGC video quality, which contains subjective data for both original videos and corresponding transcoded ver-sions. The collected ground truth data makes to it possi-ble to understand the relationship between video content and perceptual quality, and improve content-aware video compression (Sec. 3). 1All data are available at https://media.withyoutube.com/ugc-dataset 113435
UGC videos
CoINVQ diagnosis report
Compression level 0.924
Content labels
Distortion types
Dance,
Musical ensemble,
Outdoor recreation
Gaussian blur,
Multiplicative noise,
Color saturation 0.022
Food,
Recipe,
Cooking
Color saturation,
Denoise,
Pixelate 0.015
Vehicle,
Car,
Video game
Color shift,
Quantization,
Contrast change 0.039
Action-adventure game,
Vehicle,
Cartoon
Multiplicative noise,
Gaussian blur,
Color saturation
Quality predicted by single feature (CP, CT, DT)
Quality predicted by all features (CP+CT+DT)
MOS (from subjective tests) (2.862, 3.621, 3.16) (3.107, 3.172, 2.95) (3.69, 3.376, 3.548) (4.029, 3.89, 3.941) 2.955 2.754 3.03 2.881 3.448 3.29 3.971 3.795
Table 1. Understanding generic UGC video quality by Comprehensive Interpretation Network for Video Quality (CoINVQ), which pro-vided an overall quality estimation as well as human friendly quality indicators, including compression level (0: low, 1: high), content labels (3800+ UGC entities [2]), distortion types (20+ artiﬁcial distortions [17]). CP, CT, DT: features from Compression, Content, and Distortion submodels. Besides a single quality score, CoINVQ report also reveals the rationale of quality assessment. For example, the ﬁrst video has interesting contents (Dance and outdoor recreation), i.e. its content quality is good (CT=3.621). However, it is heavily compressed (CP=2.862) and has distortions like blur and noise (DT=3.16), which leads to a poor watching experience (CP+CT+DT=2.955).
• We design a comprehensive framework to analyze UGC video quality from different aspects, such as semantic content, technical quality, and compression level, which brings new insights to interpret video perceptual quality as the interaction of complementary features (Sec. 4).
• The proposed model achieves state-of-the-art precision on UGC quality prediction, while also providing reliable indications for quality degradation caused by compres-sion (Sec. 5). 2.