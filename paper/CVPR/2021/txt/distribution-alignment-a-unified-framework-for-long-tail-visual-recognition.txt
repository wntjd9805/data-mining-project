Abstract
Despite the recent success of deep neural networks, it remains challenging to effectively model the long-tail class distribution in visual recognition tasks. To address this prob-lem, we ﬁrst investigate the performance bottleneck of the two-stage learning framework via ablative study. Motivated by our discovery, we propose a uniﬁed distribution alignment strategy for long-tail visual recognition. Speciﬁcally, we de-velop an adaptive calibration function that enables us to adjust the classiﬁcation scores for each data point. We then introduce a generalized re-weight method in the two-stage learning to balance the class prior, which provides a ﬂexible and uniﬁed solution to diverse scenarios in visual recogni-tion tasks. We validate our method by extensive experiments on four tasks, including image classiﬁcation, semantic seg-mentation, object detection, and instance segmentation. Our approach achieves the state-of-the-art results across all four recognition tasks with a simple and uniﬁed framework. 1.

Introduction
While deep convolutional networks have achieved great successes in many vision tasks, it usually requires a large number of training examples for each visual category. More importantly, prior research mostly focuses on learning from a balanced dataset [22], where different object classes are approximately evenly distributed. However, for large-scale vision recognition tasks, partially due to the non-uniform distribution of natural object classes and varying annotation costs, we typically learn from datasets with a long-tail class label distribution. In such scenarios, the number of training instances per class varies signiﬁcantly, from as few as one example for tail classes to hundreds or thousands for head classes [48, 26, 14, 51, 49, 36].
*This work was done when Songyang Zhang was a research intern at Megvii Technology. This work was supported by Shanghai NSF
Grant (No. 18ZR1425100), National Key R&D Program of China (No. 2017YFA0700800), and Beijing Academy of Artiﬁcial Intelligence (BAAI).
Code is available: https://github.com/Megvii-BaseDetection/DisAlign
Figure 1: Per-class performance of the two-stage learn-ing baseline and our empirical classiﬁcation bound on
ImageNet-LT val split. Two methods share the same repre-sentation while our bound setting retrains the classiﬁer head with the balanced full dataset.
The intrinsic long-tail property of our visual data in-troduces a multitude of challenges for recognition in the wild [1], as a deep network model has to simultaneously cope with imbalanced annotations among the head and medium-sized classes, and few-shot learning in the tail classes. A naively learned model would be largely dominated by those few head classes while its performance is much degraded for many other tail classes.
Early works on re-balancing data distribution focus on learning one-stage models, which achieve limited successes due to lack of principled design in their strategies [2, 33, 3, 9, 26, 41]. More recent efforts aim to improve the long-tail prediction by decoupling the representation learning and classiﬁer head learning [19, 28, 35, 38, 23]. However, such a two-stage strategy typically relies on heuristic design to adjust the decision boundary of the initially learned classiﬁer head, which often requires tedious hyper-parameter tuning in practice. This severely limits its capacity to resolve the mismatch between imbalanced training data distribution and balanced evaluation metrics.
In this work, we ﬁrst perform an ablative analysis on the two-stage learning strategy to shed light on its performance bottleneck. Speciﬁcally, our study estimates an ‘ideal’ clas-12361
siﬁcation accuracy using a balanced dataset to retrain the classiﬁer head while keeping the ﬁrst-stage representation
ﬁxed. Interestingly, as shown in Fig. 1, we ﬁnd a substan-tial gap between this ideal performance and the baseline network, which indicates that the ﬁrst-stage learning with unbalanced data provides a good representation, but there is a large room for improvement in the second stage due to the biased decision boundary (See Sec. 3.1 for details).
Based on those ﬁndings, we propose a simple and yet ef-fective two-stage learning scheme for long-tail visual recog-nition problems. Our approach focuses on improving the second-stage training of the classiﬁer after learning a fea-ture representation in a standard manner. To this end, we develop a uniﬁed distribution alignment strategy to calibrate the classiﬁer output via matching it to a reference distribu-tion of classes that favors the balanced prediction. Such an alignment strategy enables us to exploit the class prior and data input in a principled manner for learning class decision boundary, which eliminates the needs for tedious hyper-parameter tuning and can be easily applied to various visual recognition tasks.
Speciﬁcally, we develop a light-weight distribution align-ment module for calibrating classiﬁcation scores, which con-sists of two main components. In the ﬁrst component, we in-troduce an adaptive calibration function that equips the class scores with an input-dependent, learnable magnitude and margin. This allows us to achieve a ﬂexible and conﬁdence-aware distribution alignment for each data point. Our second component explicitly incorporates a balanced class prior by employing a generalized re-weight design for the reference class distribution, which provides a uniﬁed strategy to cope with diverse scenarios of label imbalance in different visual recognition tasks.
We extensively validate our model on four typical vi-sual recognition tasks, including image classiﬁcation on three benchmarks (ImageNet-LT [26], iNaturalist [36] and
Places365-LT [26]), semantic segmentation on ADE20k dataset [49], object detection and instance segmentation on
LVIS dataset [14]. The empirical results and ablative study show our method consistently outperforms the state-of-the-art approaches on all the benchmarks. To summarize, the main contributions of our works are three-folds:
• We conduct an empirical study to investigate the perfor-mance bottleneck of long-tail recognition and reveal a critical gap caused by biased decision boundary.
• We develop a simple and effective distribution align-ment strategy with a generalized re-weight method, which can be easily optimized for various long-tail recognition tasks without whistles and bells.
• Our models outperform previous work with a large mar-gin and achieve state-of-the-art performance on long-tail image classiﬁcation, semantic segmentation, object detection, and instance segmentation. 2.