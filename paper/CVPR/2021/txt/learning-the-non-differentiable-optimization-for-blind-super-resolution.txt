Abstract
Previous convolutional neural network (CNN) based blind super-resolution (SR) methods usually adopt an it-erative optimization way to approximate the ground-truth (GT) step-by-step. This solution always involves more com-putational costs to bring about time-consuming inference.
At present, most blind SR algorithms are dedicated to ob-taining high-ﬁdelity results; their loss function generally employs L1 loss. To further improve the visual quality of
SR results, perceptual metric, such as NIQE, is necessary to guide the network optimization. However, due to the non-differentiable property of NIQE, it cannot be as the loss function. Towards these issues, we propose an adap-tive modulation network (AMNet) for multiple degradations
SR, which is composed of the pivotal adaptive modulation layer (AMLayer).
It is an efﬁcient yet lightweight fusion layer between blur kernel and image features. Equipped with the blur kernel predictor, we naturally upgrade the
Instead of considering it-AMNet to the blind SR model. erative strategy, we make the blur kernel predictor train-able in the whole blind SR model, in which AMNet is well-trained. Also, we ﬁt deep reinforcement learning into the blind SR model (AMNet-RL) to tackle the non-differentiable optimization problem. Speciﬁcally, the blur kernel predic-tor will be the actor to estimate the blur kernel from the input low-resolution (LR) image. The reward is designed by the pre-deﬁned differentiable or non-differentiable metric.
Extensive experiments show that our model can outperform state-of-the-art methods in both ﬁdelity and perceptual met-rics. 1.

Introduction
Single image super-resolution (SISR) refers to estimat-ing the plausible and sharp detailed high-resolution (HR) image from its counterpart low-resolution (LR) image. It
∗Corresponding author has been widely used in image/video enhancement, remote sensing imaging, and video surveillance. Recently, the in-troduction of convolutional neural networks (CNNs) makes the SISR performance reach a new height. Numerous CNN-based SISR methods [6, 7, 8, 16, 18, 13, 39, 19, 27] have explored network architecture designs and training strate-gies. They have focused on supervised settings with a ﬁxed degradation model, e.g., bicubic downsampling. These al-gorithms achieved impressive results for the bicubic down-sampling condition but produced undesirable artifacts when the images with a different degradation. Zhang et al. [35] proposed SRMD to handle multiple degradations via a sin-gle model to address the issue of multiple degradations.
Different from previous CNN-based methods, SRMD ex-plicitly takes both LR image and its degradation maps as input. Following SRMD, Xu et al. [30] proposed a sin-gle uniﬁed dynamic network trained for variational degra-dations (UDVD) to improve performance; its primary con-tribution is two types of dynamic convolutions. Note that the predeﬁned blur kernel is given; thus, SRMD [35] and
UDVD [30] are both non-blind settings. However, in most practical applications, blur kernels are not provided. Thus, the SR problem with unknown blur kernels, i.e., blind SR, is a more attractive ﬁeld for academia and industry.
In general, to tackle the blind SR problem, previous tech-niques [35, 34] decompose the blind SR problem into two sequential subproblems, i.e., estimating blur kernel from input LR image and generating SR image based on esti-mated kernel. As stated in [22], this solution is not an end-to-end training approach, causing a suboptimal prob-lem. Based on the observation of artifacts caused by kernel mismatch, Gu et al. [10] made efforts to correct an inac-curate blur kernel. They proposed an iterative kernel cor-rection (IKC) method to correct the estimated kernel only by observing the previous SR results. In a deep alternat-ing network (DAN) [22], the authors make the estimation of blur kernel much easier through sending both LR and SR images to Estimator. This iterative principle can make gen-erated SR images gradually approach the ground-truth, but 2093
it will consume more computational costs and make train-ing/testing processing slower.
Besides, the current multiple degradations SR methods (including non-blind and blind settings) [35, 10, 25, 22] mainly adopt mean absolute error (MAE) or mean square error (MSE) as the loss function to achieve high PSNR val-ues. It is rare to explore the multiple degradations percep-tual SR problem. Under the condition of bicubic downsam-pling, many perceptual SR methods incorporate the percep-tual loss [14] and adversarial learning [19] to generate real-istic textures and exact details. Following the training strat-egy in ESRGAN [27], Zhang et al. [34] trained USRNet (complex degradations) with the MAE loss for PSNR per-formance and then ﬁne-tuned the model with the weighted combination of MAE loss, VGG perceptual loss, and rel-ativistic adversarial loss to pursue perceptual quality per-formance. The most challenging problem is the evalua-tion procedure, whether single degradation perceptual SR or multiple degradations perceptual SR. HR images (ground-truth) are not available in many applications. Thus, an objective metric like PSNR/SSIM and perceptual metric like LPIPS [36] cannot be used. At this time, some non-reference image quality assessment (NR-IQA) metrics can be utilized, such as NIQE [24].
Nevertheless, most of these NR-IQA metrics are not dif-ferentiable, which cannot serve as the loss functions to opti-mize the network. Zhang et al. [37] introduced a Ranker to learn the behavior of perceptual metrics. However, training this Ranker needs to make a rank dataset. Speciﬁcally, se-lect two SR images and calculate their ranking order accord-ing to the perceptual metric’s quality score. This method in-directly optimizes the network in the orientation of speciﬁc perceptual metrics. Therefore, there is also a lack of a so-lution that does not need to make a training dataset and ex-plicitly optimize the non-differentiable objective function.
This paper is devoted to addressing the above issues, i.e., how to solve the non-differentiable evaluation metrics op-timization for blind SR problems while maintaining fast training and testing speed (non-iterative). Following the standard approach, we model the LR image as degrada-tion from the HR image with blurring and downsampling.
First, given a blur kernel and a LR image, we need to train a single network for multiple degradations SR as in
[35, 10, 30]. Motivated by style transfer [12] and im-age synthesis [15], we design the new generator architec-ture equipped with modiﬁed adaptive instance normaliza-tion (AdaIN) to control the image SR process. Our genera-tor, namely adaptive modulation network (AMNet) for mul-tiple degradations SR, adjusts the “blur/sharp style” of the image based on the embedding code of blur kernel. In this way, we can signiﬁcantly reduce the tremendous amount of calculation caused by using the spatial feature transform (SFT) layers in SFTMD [10] without sacriﬁcing perfor-mance. Second, we tune the input embedding code of blur kernel to optimize the output SR image towards the given non-differentiable metrics. To this end, a policy is adopted to select the blur kernel code to guide the optimization.
Such a problem can be solved by a reinforcement learning (RL) framework where the agent models actions (blur ker-nel codes) from the observations (LR images). The reward is related to designative evaluation metrics (differentiable or non-differentiable). For implementing the high-speed training/inference, we use only single-step actions (inspired by [17]) in our whole blind SR framework – AMNet-RL (Adaptive Modulation Network with Reinforcement Learn-ing). This paper makes the following contributions:
• We design a novel modiﬁed AdaIN module, which can be used in our proposed adaptive modulation network (AMNet) to better fulﬁll the multiple degradations SR problem while having the attributes of lower computa-tional cost and higher speed than the previous multiple degradations SR methods [35, 10, 30]. To pursue the perceptual effect, we also construct a GAN-based ver-sion of AMNet, denoted as AMGAN.
• We introduce an efﬁcient RL algorithm into our whole blind SR framework. It can optimize the policy to ac-complish the blur kernel estimation task guided by the non-differentiable evaluation metrics. To the best of our knowledge, the proposed method is the ﬁrst RL that optimizes blind SR with the in-differentiable per-ceptual metrics.
• We validate our AMNet-RL (PSNR-oriented), and
AMGAN-RL (perception-driven) can achieve compa-rable results on commonly used datasets. 2.