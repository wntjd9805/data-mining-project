Abstract
Recently, several Space-Time Memory based networks have shown that the object cues (e.g. video frames as well as the segmented object masks) from the past frames are useful for segmenting objects in the current frame. How-ever, these methods exploit the information from the mem-ory by global-to-global matching between the current and past frames, which lead to mismatching to similar objects and high computational complexity. To address these prob-lems, we propose a novel local-to-local matching solution for semi-supervised VOS, namely Regional Memory Net-work (RMNet). In RMNet, the precise regional memory is constructed by memorizing local regions where the target objects appear in the past frames. For the current query frame, the query regions are tracked and predicted based on the optical ﬂow estimated from the previous frame. The proposed local-to-local matching effectively alleviates the ambiguity of similar objects in both memory and query frames, which allows the information to be passed from the regional memory to the query region efﬁciently and effec-tively. Experimental results indicate that the proposed RM-Net performs favorably against state-of-the-art methods on the DAVIS and YouTube-VOS datasets. 1.

Introduction
Video object segmentation (VOS) is a task of estimating the segmentation masks of class-agnostic objects in a video.
Typically, it can be grouped into two categories: unsuper-vised VOS and semi-supervised VOS. The former does not resort to any manual annotation and interaction, while the latter needs the masks of the target objects in the ﬁrst frame.
In this paper, we focus on the latter. Even the object masks in the ﬁrst frame are provided, semi-supervised VOS is still challenging due to object deformation, occlusion, appear-ance variation, and similar objects confusion.
With the recent advances in deep learning, there has been tremendous progress in semi-supervised VOS. Early methods [10, 18, 24] propagate object masks from previ-S
O
V
M e
R
P
M
T
S
N
M
G
E
I
B
F
C t e
N
M
R 10 10 10 10 10 22 22 22 22 22 39 39 39 39 39 52 52 52 52 52
Figure 1. A representative example of video object segmentation on the DAVIS 2017 dataset. Compared to existing methods rely on optical ﬂows (e.g. PReMVOS [18]) and global feature match-ing (e.g. STM [22], EGMN [17], and CFBI [41]), the proposed
RMNet is more robust in segmenting similar objects. ous frames using optical ﬂow and then reﬁne the masks with a fully convolutional network. However, mask prop-agation usually causes error accumulation, especially when target objects are lost due to occlusions and drifting. Re-cently, matching-based methods [4, 17, 22, 28, 32, 41] have attracted increasing attention as a promising solution to semi-supervised VOS. The basic idea of these methods is to perform global-to-global matching to ﬁnd the corre-spondence of target objects between the current and past frames. Among them, the Space-Time Memory (STM) based approaches [17, 22, 28] exploit the past frames saved in the memory to better handle object occlusion and drift-ing. However, these methods memorize and match features in the regions without target objects, which lead to mis-matching to similar objects and high computational com-plexity. As shown in Figure 1, they are less effective to track and distinguish the target objects with similar appearance.
The mismatching in the global-to-global matching can be divided into two categories, as illustrated in Figure 2. (i)
The target object in the current frame matches to the wrong object in the past frame (solid red line). (ii) The target ob-1286
Global-to-Global Matching
Local-to-Local Matching 2.