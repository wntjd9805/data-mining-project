Abstract
Fingerspelling, in which words are signed letter by let-ter, is an important component of American Sign Language.
Most previous work on automatic ﬁngerspelling recogni-tion has assumed that the boundaries of ﬁngerspelling re-gions in signing videos are known beforehand. In this pa-per, we consider the task of ﬁngerspelling detection in raw, untrimmed sign language videos. This is an important step towards building real-world ﬁngerspelling recognition sys-tems. We propose a benchmark and a suite of evaluation metrics, some of which reﬂect the effect of detection on the downstream ﬁngerspelling recognition task. In addition, we propose a new model that learns to detect ﬁngerspelling via multi-task training, incorporating pose estimation and
ﬁngerspelling recognition (transcription) along with detec-tion, and compare this model to several alternatives. The model outperforms all alternative approaches across all metrics, establishing a state of the art on the benchmark. 1.

Introduction
Sign languages, such as American Sign Language (ASL), are natural languages expressed via movements of the hands, face, and upper body. Automatic processing of sign languages would assist communication between deaf and hearing individuals, but involves a number of chal-lenges. There is no standard written form for sign lan-guages. Automatic transcription of sign language into a written language such as English is in general a translation task. In addition, sign language gestures are often coarticu-lated and do not appear in their canonical forms [22, 25].
In this paper, we focus on ﬁngerspelling (Figure 1), a component of sign language in which words are signed letter by letter, with a distinct handshape or trajectory corresponding to each letter in the alphabet of a writ-ten language (e.g., the English alphabet for ASL ﬁnger-spelling). Fingerspelling is used for multiple purposes, in-cluding for words that do not have their own signs (such as many proper nouns, technical terms, and abbreviations) [39] but also sometimes for emphasis or expediency. Finger-spelling accounts for 12% to 35% of ASL, where it is used more than in other sign languages [40]. As impor-tant content words are commonly ﬁngerspelled, automatic
ﬁngerspelling recognition can enable practical tasks such as search and retrieval in ASL media.
Compared to translation between a sign language and a written language, ﬁngerspelling recognition involves tran-scription into a restricted set of symbols, with a mono-tonic alignment with the written form. Linguistically, ﬁn-gerspelling is distinct from other elements of ASL, such as lexical signs and classiﬁers [23, 3], so ﬁngerspelling is likely to beneﬁt from a separate model. The role that ﬁn-gerspelling transcription is likely to play in ASL to English translation is similar to that of transliteration in written lan-guage translation [10]. For all of these reasons, we believe that even as more general ASL processing methods are de-veloped, it will continue to be beneﬁcial to have dedicated
ﬁngerspelling detection and recognition modules.
Fingerspelling recognition has been widely studied [42, 16, 44, 37, 26, 45]. However, in most prior work, it is assumed that the input sequence contains ﬁngerspelling only, sometimes extracted from longer sequences of sign-14166
ing via human annotation. Replacing human annotation with fully automatic detection of ﬁngerspelling – identify-ing time spans in the video containing ﬁngerspelling – is a hurdle that must be cleared to enable truly practical ﬁnger-spelling recognition “in the wild”.
Fingerspelling detection has not been widely studied be-fore. In principle it can be treated as a special case of action detection [52, 6, 55, 11]. However, in contrast to typical action detection scenarios, the actions in the ﬁngerspelling
“class” are highly heterogeneous and many ﬁngerspelling handshapes are also used in non-ﬁngerspelled signs. In ad-dition, considering the goal of using the detector as part of a complete sign language processing system, a ﬁngerspelling detector should be evaluated based on its effect on a down-stream recognition model, a step not normally included in evaluation of action recognition. This makes common de-tection metrics, like average precision (AP) for action de-tection, less informative for ﬁngerspelling detection.
Our design of a detection model is motivated by two observations. The ﬁrst is that articulated pose, in particu-lar handshape, plays a role in the distinctiveness of ﬁnger-spelling from other types of sign. At the same time, pose estimation, while increasingly successful in some domains, may be insufﬁciently accurate for directly informing ﬁnger-spelling recognition, as shown in [45] and in our experi-Instead we incorporate pose estimation as part of ments. training our model, but do not rely on explicit pose esti-mates at test time. The second observation concerns the goal of optimizing ﬁngerspelling detection as a means to an end of improving downstream recognition. We address this by including a ﬁngerspelling recognizer in model training.
Our results show that this multi-task learning approach pro-duces a superior detector compared to baselines that omit the pose and/or recognition losses.
Ours is to our knowledge the ﬁrst work to demonstrate the effect of ﬁngerspelling detection on fully automatic ﬁn-gerspelling recognition in the wild. Beyond this novelty, our contributions are as follows. First, we propose an evaluation framework for ﬁngerspelling detection that incorporates the downstream recognition task into the metrics, and introduce a benchmark based on extending a publicly available data set. Second, we investigate a number of approaches for ﬁn-gerspelling detection, adapted from ﬁngerspelling recogni-tion and action detection, and develop a novel multi-task learning approach. Our model outperforms baseline detec-tion approaches across all evaluation metrics, establishing a state of the art for the proposed benchmark. 2.