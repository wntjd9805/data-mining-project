Abstract
This paper studies the problem of semi-supervised video object segmentation(VOS). Multiple works have shown that memory-based approaches can be effective for video object segmentation. They are mostly based on pixel-level match-ing, both spatially and temporally. The main shortcom-ing of memory-based approaches is that they do not take into account the sequential order among frames and do not exploit object-level knowledge from the target. To ad-dress this limitation, we propose to Learn position and tar-get Consistency framework for Memory-based video object segmentation, termed as LCM. It applies the memory mech-anism to retrieve pixels globally, and meanwhile learns position consistency for more reliable segmentation. The learned location response promotes a better discrimination between target and distractors. Besides, LCM introduces an object-level relationship from the target to maintain tar-get consistency, making LCM more robust to error drifting.
Experiments show that our LCM achieves state-of-the-art performance on both DAVIS and Youtube-VOS benchmark.
And we rank the 1st in the DAVIS 2020 challenge semi-supervised VOS task. 1.

Introduction
Video object segmentation(VOS) is a fundamental com-puter vision task, with a wide range of applications includ-ing video editing, video composition and autonomous driv-ing. In this paper, we focus on the task of semi-supervised video object segmentation. Given a video and the ground truth object mask of the ﬁrst frame, semi-supervised VOS predicts the segmentation masks of the objects speciﬁed by the ground truth mask in the ﬁrst frame for the remain-ing frames. In video sequences, the target object will un-dergo large appearance changes due to continuous motion and variable camera view. And it may disappear in some frames due to occlusion between different objects. Further-more, there are also similar instances of same categories
Reference frame w/o PGM & ORM w/ PGM & ORM (LCM)
Figure 1. Typical memory-based approaches rely on pixel-level similarity, which leads to errors in prediction, as show in second row. The proposed Position Guidance Module(PGM) helps the network track the motion trajectory(bottom left). And the object-aware Object Relation Module(ORM) prevents the network from making fragmented segmentation pieces(bottom right). that are difﬁcult to distinguish, making the problem even harder. Therefore, semi-supervised VOS is extremely chal-lenging despite the provided annotation in the ﬁrst frame.
The fundamental problem of VOS lies in how to make full use of the spatio-temporally structured infor-mation contained in video frames. Memory-based ap-proaches are recently proposed with signiﬁcant perfor-mance improvements in popular VOS benchmarks, e.g.
DAVIS[33, 34] and Youtube-VOS[46]. Space-Time Mem-ory network(STM)[29] is the ﬁrst memory-based semi-supervised VOS method, developing a memory mechanism to store information from all previous frames for the query frame to read. It differs from other matching-based meth-ods as it expands its search range to the entire space-time domain and perform dense matching in the feature space.
However, memory-based methods only consider pixel-level matching and tend to retrieve all pixels with high match-ing score in the query image. It may fail when a non-target region share similar visual appearance with the target re-4144
gions as illustrated in Figure 1. Recently, KMN[36] in-troduces memory-to-query matching to improve STM. But the solution remains pixel similarity matching which cannot deal with appearance changes and deformation. In order to tackle the aforementioned issues, we propose to improve memory-based methods from two aspects: 1) Position con-sistency. The movement of objects usually follows a certain trajectory, which serves as an important instruction to guide segmentation. 2) Target consistency. The overall embed-ding feature for the tracked target should maintain object-level consistency throughout the entire video.
Propagation-based methods[48, 45, 24] introduce to di-rectly utilize the prediction from previous frames for better segmentation. Inspired by these works, we propose to apply previous positional information as a guidance for memory-based methods to maintain position consistency. Typical matching-based methods[17, 6] only consider pixel-level feature without the context information from the entire ob-ject. Inspired by some works in tracking[2] and one/few-shot detection[10, 14], we propose to integrate object-level feature into memory-based network to maintain target con-sistency.
To this end, we propose a novel framework to Learn po-sition and target Consistency for Memory-based video ob-ject segmentation(LCM). Taking advantage of STM, LCM performs pixel-level matching mechanism to retrieve target pixels based on similarity and stores previous information in a memory pool. This procedure is named Global Re-trieval Module(GRM). Besides, LCM learns a local embed-ding named Position Guidance Module(PGM) to fully uti-lize the position consistency and guides the segmentation by learning a location response. To maintain target consis-tency, LCM introduces Object Relation Module(ORM). As the target object is annotated in the ﬁrst frame of a video, the object relationship from the ﬁrst value embedding is en-coded to the query frame, which serves as a consistent fu-sion for context feature during the entire video sequence.
Figure 1 illustrates the effectiveness of our LCM against typical errors in memory-based methods.
Our contributions can be summarized as follows:
• We propose a novel Position Guidance Module to com-pute a location response to maintain position consis-tency in memory-based methods.
• We propose Object Relation Module to effectively fuse object-level information for maintaining consistency of the target object.
• We achieve state-of-the-art performance on both
DAVIS and Youtube-VOS benchmark and rank the 1st in the DAVIS 2020 challenge semi-supervised VOS task. 2.