Abstract
Inspired by the great success of deep neural net-works (DNNs), many unfolding methods have been pro-posed to integrate traditional image modeling techniques, such as dictionary learning (DicL) and sparse coding, into
DNNs for image restoration. However, the performance of such methods remains limited for several reasons. First, the unfolded architectures do not strictly follow the image representation model of DicL and lose the desired physical meaning. Second, handcrafted priors are still used in most unfolding methods without effectively utilizing the learn-ing capability of DNNs. Third, a universal dictionary is learned to represent all images, reducing the model repre-sentation ﬂexibility. We propose a novel framework of deep convolutional dictionary learning (DCDicL), which follows the representation model of DicL strictly, learns the pri-ors for both representation coefﬁcients and the dictionar-ies, and can adaptively adjust the dictionary for each in-put image based on its content. The effectiveness of our
DCDicL method is validated on the image denoising prob-lem. DCDicL demonstrates leading denoising performance in terms of both quantitative metrics (e.g., PSNR, SSIM) and visual quality. In particular, it can reproduce the subtle im-age structures and textures, which are hard to recover by many existing denoising DNNs. The code is available at: https://github.com/natezhenghy/DCDicL_ denoising. 1.

Introduction
How to represent an image signal plays a key role in tra-ditional image processing applications [9, 41, 42, 15, 14].
One popular approach is to represent an image patch vec-tor y∈Rm as a linear combination of atomic bases, i.e., y=
Dx, where D∈Rm×d is the dictionary of atoms, and x∈Rd is the representation coefﬁcient vector. In the early stage, cosine functions [4], wavelets [5] and contourlets [11] are
*The ﬁrst two authors contribute equally to this work.
†Corresponding author.
This work is supported by the Hong Kong RGC RIF grant (R5001-18). commonly used as the dictionary atoms. However, such dictionaries are manually designed under some mathemati-cal constraints and are not ﬂexible enough to represent the complex natural image structures. Later on, researchers turned to learn the dictionary directly from image data, and many dictionary learning (DicL) methods have been devel-oped [30, 56, 71, 64].
The DicL model can be formulated as follows: minD,X 1 2 kDX−Yk2 2+λXψ(X)+λDφ(D) (1) where Y∈Rm×N is a set of N training samples and each column of it is a stretched image patch vector; X∈Rd×N is the representation coefﬁcient matrix of Y over dictionary
D; ψ(·) denotes the prior on coefﬁcient X and φ(·) de-notes the regularization term on D (e.g., kDk2 2); λX and λD are the regularization parameters for X and D, respectively.
The most widely used priors of ψ(·) are sparsity priors, such as kXk0 and kXk1, and the corresponding DicL models are often called Sparse DicL. K-SVD [3, 71] is the most rep-resentative Sparse DicL method. It alternatively performs two steps to learn the dictionary: ﬁx D and perform sparse coding (SC) to compute X, and update D through singular value decomposition (SVD).
Inspired by K-SVD, many DicL methods have been pro-posed [36, 65, 14, 71, 27, 46, 45] and successfully used in various image restoration applications, such as denois-ing [16, 9] and super-resolution [63, 62, 61]. One prob-lem of the patch-based DicL model in Eq. (1) is its lack of shift-invariant property, and convolutional dictionary learn-ing (CDicL) [19] was proposed to address this issue by us-ing the convolution operation to replace the matrix multi-plication in signal representation. Speciﬁcally, the objective function of CDicL can be written as: min
D,{Xi} 1
N
N i=1 1 2 kD⊛Xi−Yik2 2+λXψ(Xi)+λDφ(D)
P (2)
C c=1Dc∗Xi,c, ∗ is the 2D convolution where D⊛Xi = operator, and C is the number of channels; D={Dc}C c=1 is the convolutional dictionary and Dc ∈Rk×k is the c-th 2D dictionary atom (i.e., ﬁlter); Xi ={Xi,c}C c=1 is the representation coefﬁcient (also called feature map) of im-age Yi ∈Rh×w and Xi,c ∈Rh×w is the c-th channel of Xi.
P 630
In CDicL, the sparse prior is commonly used for the fea-ture map Xi (e.g., kXik1) and convolutional sparse cod-ing (CSC) [8, 58] is used to solve the feature map. CDicL has demonstrated its advantages over patch-based DicL in several image processing tasks [34, 19, 21, 32].
With the rapid development of deep learning (DL) tech-niques in recent years, many deep neural network (DNN) based image restoration methods have been proposed [67, 69, 22, 13, 12]. Driven by a large amount of training data and the strong learning capacity of DNN, these methods have surpassed traditional image restoration methods, in-cluding those DicL based ones, by a large margin. Nonethe-less, due to the black-box nature of DNN, there lacks a clear interpretation for its success in image restoration, while
DicL has good interpretability. Therefore, researchers have attempted to integrate DicL, SC and DL for both good per-formance and clear physical meaning. These methods, of-ten called deep unfolding methods, unfold the traditional
SC and DicL models through certain algorithms, and pa-rameterize the model by DNN in an end-to-end learning manner. Representative methods include DKSVD [47],
Learned-CSC [52], CSCNet [50], DCSC [18], etc.
However, the existing deep unfolding methods usually fail to compete with DL methods for several reasons. First, the unfolded architectures do not strictly follow the orig-inal DicL models, which impairs the physical meaning and sacriﬁces the advantages of DicL. Second, most of them [52, 50, 18] still use the handcrafted priors, e.g.,
L1 (sparsity) prior, instead of learning the priors from data, wasting the learning capacity of DNN architectures. Third, they usually learn a universal dictionary for all images, re-ducing the model’s representation capability. In this work, we propose a new unfolding framework, called deep convo-lutional dictionary learning (DCDicL), which resolves the above issues of previous unfolding methods. The contribu-tions of this paper are summarized as follows:
• DCDicL learns the priors for both dictionary and rep-resentation coefﬁcients from the training data, over-coming the disadvantages of handcrafted priors.
• DCDicL learns a speciﬁc dictionary for each image, which is adaptive to the image content. This endows
DCDicL with more powerful capability for recovering image subtle structures.
• To testify the effectiveness of our framework, we ap-ply DCDicL on the image denoising task. It achieves leading denoising performance over not only previous unfolding methods but also DL methods. 2.