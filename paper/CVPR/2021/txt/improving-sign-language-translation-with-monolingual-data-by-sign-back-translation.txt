Abstract
Despite existing pioneering works on sign language translation (SLT), there is a non-trivial obstacle, i.e., the limited quantity of parallel sign-text data. To tackle this parallel data bottleneck, we propose a sign back-translation (SignBT) approach, which incorporates massive spoken language texts into SLT training. With a text-to-gloss trans-lation model, we ﬁrst back-translate the monolingual text to its gloss sequence. Then, the paired sign sequence is gen-erated by splicing pieces from an estimated gloss-to-sign bank at the feature level. Finally, the synthetic parallel data serves as a strong supplement for the end-to-end training of the encoder-decoder SLT framework.
To promote the SLT research, we further contribute CSL-It provides
Daily, a large-scale continuous SLT dataset. both spoken language translations and gloss-level annota-tions. The topic revolves around people’s daily lives (e.g., travel, shopping, medical care), the most likely SLT applica-tion scenario. Extensive experimental results and analysis of SLT methods are reported on CSL-Daily. With the pro-posed sign back-translation method, we obtain a substantial improvement over previous state-of-the-art SLT methods. 1.

Introduction
Sign language serves as the primary communication method among the deaf community. However, in a soci-ety where the spoken language is primarily used, the deaf people face issues of social isolation and communication barrier in daily lives [4]. Due to the signiﬁcant social im-pact and the cross-modality challenge, sign language under-standing has been attracting more and more research atten-tion [1, 4, 10, 17, 22, 26, 37, 48]. In this paper, we concen-trate on sign language translation (SLT), which aims to au-tomatically generate the spoken language translation from a
∗Corresponding authors: Wengang Zhou and Houqiang Li http://home.ustc.edu.cn/˜zhouh156/dataset/csl-daily
Figure 1. Pipelines of sign language translation (SLT) and sign back-translation (SignBT). Our SignBT approach establishes an inverse path of SLT and uses it to enrich text-feature pairs from external monolingual data for SLT training. continuous sign video.
Considering the different grammar rules and vocabular-ies of sign language and spoken language, SLT is typically treated as a sequence-to-sequence learning problem. Ex-isting SLT systems typically rely on the encoder-decoder architectures [10, 11, 25]. Despite the success of encoder-decoder networks in neural machine translation (NMT), the translation quality in SLT is limited, which is partially at-tributed to the huge gap in the training data size. While the News Translation task [3] provides over 77M English-German data, the only suitable SLT dataset PHOENIX-2014T [10] has less than 9K Sign-German data. To alleviate it, there are two possible solutions, i.e., collecting millions of parallel pairs or introducing monolingual data. The high charge of sign video collection and annotation makes the former a luxury. In contrast, making good use of accessible monolingual texts is a promising direction for SLT.
In this work, we propose to generate synthetic parallel data with monolingual texts for SLT training. Our method is inspired by the success of text-to-text back-translation in
NMT [36]. They train an inverse model with available pairs and use it to back-translate the monolingual data. How-ever, when it goes to SLT, the key challenge becomes how to bridge the huge domain gap between text and vision signals.
A straightforward idea is to generate the sign video from a 1316
sentence, which, however is a more challenging task involv-ing various immature techniques, such as skeleton predic-tion [35], gesture generation [12] and temporal coherence
ﬁdelity [38]. A compromise option is to regress the feature sequence of video frames from a sentence. Unfortunately, it is an indeterminate problem and hard to formulate, be-cause one sentence may correspond to numerous possible feature sequences, since the feature space of sign videos is far larger than the combination space of text vocabulary.
To avoid the above problems, we propose a two-stage sign back-translation (SignBT) approach: text-to-gloss and gloss-to-sign. It is formulated as an inverse problem of SLT with an additional signal “gloss” (see Figure 1). Gloss is a token of sign language word, which is annotated along with the order of signs in a video with no clear boundaries. We
ﬁrst train a text-to-gloss translator with available text-gloss pairs and predict the gloss sequence for each monolingual text. Then, to achieve the sequence-level gloss-to-sign con-version, we adopt a primitive but effective method, splic-ing sign pieces from features of segmented videos, which is somewhat analogous to concatenative text-to-speech syn-thesis [18, 43]. To acquire the precise boundary of each gloss, we train a sign-to-gloss network with connectionist temporal classiﬁcation (CTC) [15] and ﬁnd the most likely alignment path for segmentation. The sign pieces could be segmented and stored as a sign bank in advance. Fi-nally, we simplify the whole process into a text-to-text back-translation problem and a sequence splicing operation from pieces in the bank.
The key reason that the synthetic data beneﬁts SLT train-ing lies in the two aspects of realism, i.e., the target text from the real language corpus and the source sign sequence spliced from the real feature bank. Though the fake pair may not be perfect as a real training data, it helps regular-ize the decoder when speaking target language and improve the robustness of extracting information from the source.
Through extensive experiments, we verify the signiﬁcant improvement of SLT models brought by monolingual data.
Acquiring high-quality corpus is always crucial for SLT.
In this paper, we provide the ﬁrst large-scale Chinese Sign
Language Translation benchmark, CSL-Daily. The native expression, compact annotation and clear hand details make our corpus suitable for a series of sign language research, e.g., sign language recognition, translation and generation.
The evaluations on CSL-Daily of various SLT baselines are reported with in-depth analysis.
Our main contributions are summarized as follows,
• We propose a sign back-translation approach to tackle parallel data shortage in SLT.
• We contribute a new large-scale SLT benchmark with rich contents and compact annotations.
• Extensive experiments on two datasets demonstrate the effectiveness of our SignBT mechanism. 2.