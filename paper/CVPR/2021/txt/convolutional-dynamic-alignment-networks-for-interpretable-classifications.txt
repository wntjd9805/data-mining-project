Abstract
We introduce a new family of neural network mod-els called Convolutional Dynamic Alignment Networks1 (CoDA-Nets), which are performant classiﬁers with a high degree of
Their core build-interpretability. ing blocks are Dynamic Alignment Units (DAUs), which linearly transform their input with weight vectors that dynamically align with task-relevant patterns. As a result,
CoDA-Nets model the classiﬁcation prediction through a series of input-dependent linear transformations, allowing for linear decomposition of the output into individual in-put contributions. Given the alignment of the DAUs, the resulting contribution maps align with discriminative input patterns. These model-inherent decompositions are of high visual quality and outperform existing attribution methods under quantitative metrics. Further, CoDA-Nets constitute performant classiﬁers, achieving on par results to ResNet and VGG models on e.g. CIFAR-10 and TinyImagenet. 1.

Introduction
Neural networks are powerful models that excel at a wide range of tasks. However, they are notoriously difﬁcult to interpret and extracting explanations for their predictions is an open research problem. Linear models, in contrast, are generally considered interpretable, because the con-tribution (‘the weighted input’) of every dimension to the output is explicitly given.
Interestingly, many modern neural networks implicitly model the output as a linear transformation of the input; a ReLU-based [21] neural network, e.g., is piece-wise linear and the output thus a 1Code will be available at github.com/moboehle/CoDA-Nets. linear transformation of the input, cf. [20]. However, due to the highly non-linear manner in which these linear trans-formations are ‘chosen’, the corresponding contributions per input dimension do not seem to represent the learnt model parameters well, cf. [1], and a lot of research is being conducted to ﬁnd better explanations for the decisions of such neural networks, cf. [28, 30, 40, 25, 27, 33, 31, 4].
In this work, we introduce a novel network architecture, the
Convolutional Dynamic Alignment Networks (CoDA-Nets), for which the model-inherent contribution maps are faithful projections of the internal computations and thus good ‘explanations’ of the model prediction. There are two main components to the interpretability of the
CoDA-Nets. First, the CoDA-Nets are dynamic linear, i.e., they compute their outputs through a series of input-dependent linear transforms, which are based on our novel
Dynamic Alignment Units (DAUs). As in linear models, the output can thus be decomposed into individual input contributions, see Fig. 1. Second, the DAUs are structurally biased to compute weight vectors that align with relevant patterns in their inputs. In combination, the CoDA-Nets thus inherently produce contribution maps that are ‘opti-mised for interpretability’: since each linear transformation matrix and thus their combination is optimised to align with discriminative features, the contribution maps reﬂect the most discriminative features as used by the model.
With this work, we present a new direction for building inherently more interpretable neural network architectures with high modelling capacity. In detail, we would like to highlight the following contributions: 10029
(1) We introduce the Dynamic Alignment Units (DAUs), which improve the interpretability of neural networks and have two key properties: they are dynamic linear and align their weights with discriminative input patterns. (2) Further, we show that networks of DAUs inherit these two properties. In particular, we introduce Convolutional
Dynamic Alignment Networks (CoDA-Nets), which are built out of multiple layers of DAUs. As a result, the model-inherent contribution maps of CoDA-Nets highlight dis-criminative patterns in the input. (3) We further show that the alignment of the DAUs can be promoted by applying a ‘temperature scaling’ to the ﬁnal output of the CoDA-Nets. (4) We show that the resulting contribution maps perform well under commonly employed quantitative criteria for at-tribution methods. Moreover, under qualitative inspection, we note that they exhibit a high degree of detail. (5) Beyond interpretability, CoDA-Nets are performant classiﬁers and yield competitive classiﬁcation accuracies on the CIFAR-10 and TinyImagenet datasets. 2.