Abstract
Real-scanned point clouds are often incomplete due to viewpoint, occlusion, and noise. Existing point cloud com-pletion methods tend to generate global shape skeletons and hence lack ﬁne local details. Furthermore, they mostly learn a deterministic partial-to-complete mapping, but overlook structural relations in man-made objects. To tackle these challenges, this paper proposes a variational framework,
Variational Relational point Completion network (VRC-Net) with two appealing properties: 1) Probabilistic Mod-eling. In particular, we propose a dual-path architecture to enable principled probabilistic modeling across partial and complete clouds. One path consumes complete point clouds for reconstruction by learning a point VAE. The other path generates complete shapes for partial point clouds, whose embedded distribution is guided by distribution obtained from the reconstruction path during training. 2) Relational
Enhancement. Speciﬁcally, we carefully design point self-attention kernel and point selective kernel module to ex-ploit relational point features, which reﬁnes local shape de-tails conditioned on the coarse completion. In addition, we contribute a multi-view partial point cloud dataset (MVP dataset) containing over 100,000 high-quality scans, which renders partial 3D shapes from 26 uniformly distributed camera poses for each 3D CAD model. Extensive exper-iments demonstrate that VRCNet outperforms state-of-the-art methods on all standard point cloud completion bench-marks. Notably, VRCNet shows great generalizability and robustness on real-world point cloud scans. 1.

Introduction 3D point cloud is an intuitive representation of 3D scenes and objects, which has extensive applications in various vi-sion and robotics tasks. Unfortunately, scanned 3D point clouds are usually incomplete owing to occlusions and missing measurements, hampering practical usages. There-fore, it is desirable and important to predict the complete
⋆ Work partially done while working at NUS.
Our project website: https://paul007pl.github.io/projects/VRCNet 8524
3D shape from a partially observed point cloud.
The pioneering work PCN [29] uses PointNet-based en-coder to generate global features for shape completion, which cannot recover ﬁne geometric details. The follow-up works [14, 23, 15, 27] provide better completion re-sults by preserving observed geometric details from the incomplete point shape using local features. However, they [29, 14, 23, 15, 27] mostly generate complete shapes by learning a deterministic partial-to-complete mapping, lacking the conditional generative capability based on the partial observation. Furthermore, 3D shape completion is expected to recover plausible yet ﬁne-grained complete shapes by learning relational structure properties, such as geometrical symmetries, regular arrangements and surface smoothness, which existing methods fail to capture.
To this end, we propose Variational Relational Point
Completion network (entitled as VRCNet), which con-sists of two consecutive encoder-decoder sub-networks that serve as “probabilistic modeling” (PMNet) and “relational enhancement” (RENet), respectively (shown in Fig. 1 (a)).
The ﬁrst sub-network, PMNet, embeds global features and latent distributions from incomplete point clouds, and pre-dicts the overall skeletons (i.e. coarse completions, see
Fig. 1 (a)) that are used as 3D adaptive anchor points for exploiting multi-scale point relations in RENet.
Inspired by [32], PMNet uses smooth complete shape priors to im-prove the generated coarse completions using a dual-path architecture consisting of two parallel paths: 1) a recon-struction path for complete point clouds, and 2) a comple-tion path for incomplete point clouds. During training, we regularize the consistency between the encoded posterior distributions from partial point clouds and the prior dis-tributions from complete point clouds. With the help of the generated coarse completions, the second sub-network
RENet strives to enhance structural relations by learning multi-scale local point features. Motivated by the success of local relation operations in image recognition [31, 7], we propose the Point Self-Attention Kernel (PSA) as a basic building block for RENet. Instead of using ﬁxed weights,
PSA interleaves local point features by adaptively predict-ing weights based on the learned relations among neighbor-ing points. Inspired by the Selective Kernel (SK) unit [12], we propose the Point Selective Kernel Module (PSK) that utilizes multiple branches with different kernel sizes to ex-ploit and fuse multi-scale point features, which further im-proves the performance.
Moreover, we create a large-scale Multi-View Partial point cloud (MVP) dataset with over 100,000 high-quality scanned partial and complete point clouds. For each com-plete 3D CAD model selected from ShapeNet [26], we ran-domly render 26 partial point clouds from uniformly dis-tributed camera views on a unit sphere, which improves the data diversity. Experimental results on our MVP and Com-pletion3D benchmark [21] show that VRCNet outperforms
SOTA methods. In Fig. 1 (b), VRCNet reconstructs richer details than the other methods by implicitly learning the shape symmetry from this incomplete lamp. Given different partial observations, VRCNet can predict different plausi-ble complete shapes (Fig. 1 (c)). Furthermore, VRCNet can generate impressive complete shapes for incomplete real-world scans from KITTI [3] and ScanNet [2], which reveals its remarkable robustness and generalizability.
The key contributions can be summarized as: 1) We propose a novel Variational Relational point Completion
Network (VRCNet), and it ﬁrst performs probabilistic mod-eling using a novel dual-path network followed by a rela-tional enhancement network. 2) We design multiple rela-tional modules that can effectively exploit and fuse multi-scale point features for point cloud analysis, such as the
Point Self-Attention Kernel and the Point Selective Kernel
Module. 3) Furthermore, we contribute a large-scale multi-view partial point cloud (MVP) dataset with over 100,000 high-quality 3D point shapes. Extensive experiments show that VRCNet outperforms previous SOTA methods on all evaluated benchmark datasets. 2.