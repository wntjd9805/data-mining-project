Abstract
Natural image matting separates the foreground from background in fractional occupancy which can be caused by highly transparent objects, complex foreground (e.g., net or tree), and/or objects containing very ﬁne details (e.g., hairs). Although conventional matting formulation can be applied to all of the above cases, no previous work has at-tempted to reason the underlying causes of matting due to various foreground semantics.
We show how to obtain better alpha mattes by incorpo-rating into our framework semantic classiﬁcation of mat-ting regions. Speciﬁcally, we consider and learn 20 classes of matting patterns, and propose to extend the conven-tional trimap to semantic trimap. The proposed semantic trimap can be obtained automatically through patch struc-ture analysis within trimap regions. Meanwhile, we learn a multi-class discriminator to regularize the alpha predic-tion at semantic level, and content-sensitive weights to bal-ance different regularization losses. Experiments on mul-tiple benchmarks show that our method outperforms other methods and has achieved the most competitive state-of-the-art performance. Finally, we contribute a large-scale Se-mantic Image Matting Dataset with careful consideration of data balancing across different semantic classes. Code and dataset are available at https://github.com/nowsyn/
SIM . 1.

Introduction
The matting equation models an image I as a linear com-bination of a foreground image F and a background image
B modulated by an alpha matte α:
I = αF + (1 − α)B. (1)
The natural image matting problem is to extract the alpha matte α from a given image, which has a wide range of ap-plications in image/video editing. Typical foreground ob-jects can belong to a great variety of categories, such as
This work was done when Yanan Sun was a student intern at Kuaishou
Technology. This work was supported by Kuaishou Technology and the
Research Grant Council of the Hong Kong SAR under grant no. 16201420.
Figure 1. Alpha mattes can have different local shapes and pat-terns depending on the underlying foreground. Left shows a hu-man matte with both soft hair and sharp body boundaries. Right shows a complex matte where the foreground exhibits different degrees of transparency. Deep reasoning of object semantics in natural image matting can advance the state-of-the-art results. humans, furry animals, glass objects with transparent/semi-transparent regions, or objects with complex shapes such as net or tree, thus making this research problem still challeng-ing, see Figure 1.
Natural image matting is an ill-posed problem, so most existing methods take both image and user-supplied clues (scribbles, to solve the prob-lem. Class-agnostic trimap comprising of foreground, back-ground, and unknown regions is the most common choice among traditional and deep learning-based methods. trimaps, etc.) as input
Traditional methods [12, 14, 16, 18, 36, 3, 5, 10, 17, 24, 25] mainly rely on low-level features related to image col-ors or structures. As traditional methods do not take into consideration any semantic information of foreground ob-jects or background scenes, they fail easily in images where foreground pixels mingle deeply with background pixels.
This issue has been addressed to a considerable extent with the introduction of deep neural networks. In [2] images are segmented into soft transitional regions based on seman-tics. However, this method can easily fail in images with entangled colors or large transitional regions. To extract alpha mattes for general objects, deep learning-based meth-ods [11, 43, 31, 6, 20, 26] have contributed various con-volution network designs to greatly improve performance beneﬁting from high-level semantic representations. Re-cent works such as human matting and transparent object matting [38, 49, 29, 7] have focused on solving speciﬁc instances of the matting problem, leveraging prior domain knowledge, and contributing to excellent performance for 111120
these class-speciﬁc matting tasks. However, these deep learning-based methods still utilize semantic information only at a data level and do not adequately consider the un-derlying cause of matting due to different object semantics.
Given the unknown region surrounding a foreground object, different types of boundaries or patterns may exist. For example, a portrait usually has both fuzzy hair and sharp boundaries.
In this paper, we propose to incorporate semantic classi-ﬁcation of matting regions into our matting framework for extracting better alpha matte. Speciﬁcally, we ﬁrst cluster 20 different matting classes based on the regional matting patterns. Our matting classes cover most typical matting scenarios for various foreground objects. Then, we extend the conventional class-agnostic trimap to semantic trimap, which consists of a 2D conﬁdence map for each matting class in the unknown region. The automatically generated semantic trimap with RGB image is then fed into our frame-work as input. Meanwhile, we learn a multi-class discrim-inator for supervision, providing regularization from a se-mantic level for alpha predictions. In particular, to improve prediction with semantics incorporation, we introduce gra-dient constraints with content-sensitive weights to balance different regularization losses.
In summary, our main contributions are: 1. We introduce semantics into the matting task and demonstrate how semantic information can be used to achieve the most competitive performance. To our knowledge, this is the ﬁrst paper to consider seman-tic classiﬁcation of matting patterns in a natural image matting framework. 2. Our main technical contributions include: the intro-duction of semantic trimap, the proposal of learnable content-sensitive weights, and the usage of multi-class discriminator to regularize the matting results. 3. We contribute the ﬁrst large-scale class-balanced Se-mantic Image Matting Dataset covering a wide range of matting patterns to beneﬁt future matting research.
Our new dataset provides new insight and in-depth analysis to the performance of different matting algo-rithms on different matting classes. 2.