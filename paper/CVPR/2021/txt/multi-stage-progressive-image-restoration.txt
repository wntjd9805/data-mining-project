Abstract
Image restoration tasks demand a complex balance be-tween spatial details and high-level contextualized informa-tion while recovering images. In this paper, we propose a novel synergistic design that can optimally balance these competing goals. Our main proposal is a multi-stage ar-chitecture, that progressively learns restoration functions for the degraded inputs, thereby breaking down the over-all recovery process into more manageable steps. Speciﬁ-cally, our model ﬁrst learns the contextualized features us-ing encoder-decoder architectures and later combines them with a high-resolution branch that retains local informa-tion. At each stage, we introduce a novel per-pixel adap-tive design that leverages in-situ supervised attention to reweight the local features. A key ingredient in such a multi-stage architecture is the information exchange be-tween different stages. To this end, we propose a two-faceted approach where the information is not only ex-changed sequentially from early to late stages, but lateral connections between feature processing blocks also exist to avoid any loss of information. The resulting tightly inter-linked multi-stage architecture, named as MPRNet, delivers strong performance gains on ten datasets across a range of tasks including image deraining, deblurring, and denois-ing. The source code and pre-trained models are available at https://github.com/swz30/MPRNet. 1.

Introduction
Image restoration is the task of recovering a clean image from its degraded version. Typical examples of degradation include noise, blur, rain, haze, etc. It is a highly ill-posed problem as there exist inﬁnite feasible solutions. In order to restrict the solution space to valid/natural images, existing restoration techniques [19, 29, 39, 59, 66, 67, 100] explic-itly use image priors that are handcrafted with empirical ob-servations. However, designing such priors is a challenging task and often not generalizable. To ameliorate this issue, recent state-of-the-art approaches [17, 44, 57, 86, 87, 93, 94, 97] employ convolutional neural networks (CNNs) that im-*Equal contribution
[71]
[92]
[70]
[88]
[53]
[91]
Figure 1: Image deblurring on the GoPro dataset [53]. Under different parameter capacities (x-axis), our multi-stage approach performs better than the single-stage baseline [65] (with channel attention [95]), as well as the state-of-the-art (PSNR on y-axis). plicitly learn more general priors by capturing natural image statistics from large-scale data.
The performance gain of CNN-based methods over the others is primarily attributed to its model design. Nu-merous network modules and functional units for image restoration have been developed including recursive resid-ual learning [4, 95], dilated convolutions [4, 81], attention mechanisms [17, 86, 96], dense connections [73, 75, 97], encoder-decoders [7, 13, 43, 65], and generative mod-els [44, 62, 90, 92]. Nevertheless, nearly all of these mod-els for low-level vision problems are based on single-stage design. In contrast, multi-stage networks are shown to be more effective than their single-stage counterparts in high-level vision problems such as pose-estimation [14, 46, 54], scene parsing [15] and action segmentation [20, 26, 45].
Recently, few efforts have been made to bring the multi-stage design to image deblurring [70, 71, 88], and image deraining [47, 63]. We analyze these approaches to iden-tify the architectural bottlenecks that hamper their perfor-mance. First, existing multi-stage techniques either employ the encoder-decoder architecture [71, 88] which is effec-tive in encoding broad contextual information but unreliable in preserving spatial image details, or use a single-scale pipeline [63] that provides spatially accurate but semanti-14821
cally less reliable outputs. However, we show that the com-bination of both design choices in a multi-stage architecture is needed for effective image restoration. Second, we show that naively passing the output of one stage to the next stage yields suboptimal results [53]. Third, unlike in [88], it is im-portant to provide ground-truth supervision at each stage for progressive restoration. Finally, during multi-stage process-ing, a mechanism to propagate intermediate features from earlier to later stages is required to preserve contextualized features from the encoder-decoder branches.
We propose a multi-stage progressive image restoration architecture, called MPRNet, with several key components. 1). The earlier stages employ an encoder-decoder for learn-ing multi-scale contextual information, while the last stage operates on the original image resolution to preserve ﬁne spatial details. 2). A supervised attention module (SAM) is plugged between every two stages to enable progressive learning. With the guidance of ground-truth image, this module exploits the previous stage prediction to compute attention maps that are in turn used to reﬁne the previous stage features before being passed to the next stage. 3). A mechanism of cross-stage feature fusion (CSFF) is added that helps propagating multi-scale contextualized features from the earlier to later stages. Furthermore, this method eases the information ﬂow among stages, which is effective in stabilizing the multi-stage network optimization.
The main contributions of this work are:
• A novel multi-stage approach capable of generating contextually-enriched and spatially accurate outputs. Due to its multi-stage nature, our framework breaks down the challenging image restoration task into sub-tasks to pro-gressively restore a degraded image.
• An effective supervised attention module that takes full advantage of the restored image at every stage in reﬁning incoming features before propagating them further.
• A strategy to aggregate multi-scale features across stages.
• We demonstrate the effectiveness of our MPRNet by set-ting new state-of-the-art on ten synthetic and real-world datasets for various restoration tasks including image de-raining, deblurring, and denoising while maintaining a low complexity (see Fig. 1). Further, we provide detailed ablations, qualitative results, and generalization tests. 2.