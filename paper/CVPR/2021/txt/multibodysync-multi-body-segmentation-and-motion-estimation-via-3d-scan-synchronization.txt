Abstract
We present MultiBodySync, a novel, end-to-end train-able multi-body motion segmentation and rigid registra-tion framework for multiple input 3D point clouds. The two non-trivial challenges posed by this multi-scan multi-body setting that we investigate are: (i) guaranteeing cor-respondence and segmentation consistency across multi-ple input point clouds capturing different spatial arrange-ments of bodies or body parts; and (ii) obtaining ro-bust motion-based rigid body segmentation applicable to novel object categories. We propose an approach to ad-dress these issues that incorporates spectral synchroniza-tion into an iterative deep declarative network, so as to si-multaneously recover consistent correspondences as well as motion segmentation. At the same time, by explicitly disentangling the correspondence and motion segmenta-tion estimation modules, we achieve strong generalizabil-ity across different object categories. Our extensive evalu-ations demonstrate that our method is effective on various datasets ranging from rigid parts in articulated objects to individually moving objects in a 3D scene, be it single-view or full point clouds. Code at https://github.com/ huangjh-pub/multibody-sync. 1.

Introduction
Motion analysis in dynamic point clouds is an emerg-ing area, required by various applications such as surveil-lance, autonomous driving, and robotic manipulation. Our human-made environments are dominated by rigid body movements, ranging from articulated objects to solids like furniture or vehicles. These settings require us to address rigid motions of objects or object parts – which is often referred to as the multi-body motion estimation problem.
Despite its importance, previous work has mainly focused on speciﬁc scenarios with known category semantics, like category-level articulated object segmentation [41], indoor scene instance relocalization [65], or car movement detec-tion [72], leaving the literature of generic motion segmen-tation relatively unexplored.
Figure 1. MultiBodySync. Given an unordered set of point clouds, we simultaneously segment individual moving rigid parts/objects and register them. The transformed point clouds according to the
ﬁrst scan are aggregated and shown in the middle column. Note that the algorithm does not use color information and the right column is shown just for visualization.
Different from traditional single scan analysis algorithms like semantic segmentation [39], the most challenging part in multi-body motion analysis is to disambiguate and dis-tinguish rigid bodies. There, we are naturally required to jointly process and relate multiple inputs, to effectively ﬁnd consistent motion-based part/object segmentations as well as point correspondences to enable a multi-way registra-tion. It is even more challenging when the capture is not temporally dense, i.e., an intermittent acquisition that does not follow a stream such as a video, and might contain large pose variations, hampering naive temporal tracking.
In this paper, we introduce a multi-scan multi-body seg-mentation and motion estimation problem, where the goal is to simultaneously discover and register rigid bodies from multiple scans, represented either as full or partial point clouds, where objects come from unseen categories. As an effective solution, we present MultiBodySync, a fully end-to-end trainable deep declarative architecture [23] able to process an arbitrary number of unordered point sets. As shown in Fig. 1, given a set of scans, MultiBodySync begins relating pairs of scans via 3D scene ﬂow [78, 64] and con-7108
ﬁdence estimation. Then, the following two differentiable (permutation and segmentation) synchronization modules, which are central to our approach, respectively enforce the consistency of pairwise point correspondences and motion segmentation labelings across different scans. Our design explicitly decouples geometry and motion, making Multi-BodySync generalizable to unseen categories without sac-riﬁcing robustness.
We evaluate MultiBodySync on various datasets com-posed of full synthetic point clouds and partial real scans with articulated and solid objects. We also contribute a new dataset DynLab with 8 scenes and 64 scan fragments of dis-tinctly moving objects. Our extensive evaluations demon-strate that our algorithm outperforms the state-of-the-art by a large margin on both multi-body motion segmentation and motion estimation. In brief, our contributions are: 1. We introduce a novel end-to-end trainable architecture for solving the multi-scan multi-body motion estimation and segmentation problem. 2. We theoretically analyze the spectral characteristics of the proposed weighted permutation synchronization. 3. To the best of our knowledge, we showcase the ﬁrst cross-category generalization for the task at hand on both synthetic and real datasets, for both articulated part-level and object-level regimes. knowledge, no prior work can handle multiple scans while enforcing multi-way consistency like we do.
Synchronization. The art of consistently recovering ab-solute quantities from a collection of ratios is now a ba-sic component of the classical multi-view/shape analysis pipelines [56, 14, 15]. Various aspects of the problem have been vastly studied: different group structures [25, 24, 12, 2, 1, 33, 27, 1, 66, 18, 59, 62, 4, 6], closed-form solu-tions [4, 2, 1], robustness [17], certiﬁability [55], global optimality [13], learning-to-synchronize [34, 50, 22] and uncertainty quantiﬁcation [61, 10, 9, 12].
In this work, we are concerned with synchronizing correspondence sets, otherwise known as permutation synchronization (PS) [48] and motion segmentations [3]. PS is rich in the variety of algorithms: low-rank formulations [80, 67], convex pro-gramming [30], distributed optimization [30], multi-graph matching[57] or Riemannian optimization [12]. Out of all those, we are interested in the spectral methods of [2, 46] as they provide efﬁcient, closed-form solutions deployable within a deep declarative network [23] like ours.
To the best of our knowledge, synchronization of corre-spondences [46] or motion segmentation [3] have not been explored in the context of deep learning. This is what we do in this paper to tackle the consistent multi-body motion estimation and segmentation. 2.