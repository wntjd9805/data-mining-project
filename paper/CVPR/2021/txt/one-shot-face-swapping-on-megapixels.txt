Abstract
Face swapping has both positive applications such as entertainment, human-computer interaction, etc., and neg-ative applications such as DeepFake threats to politics, eco-nomics, etc. Nevertheless, it is necessary to understand the scheme of advanced methods for high-quality face swap-ping and generate enough and representative face swapping images to train DeepFake detection algorithms. This pa-per proposes the ﬁrst Megapixel level method for one shot
Face Swapping (or MegaFS for short). Firstly, MegaFS or-ganizes face representation hierarchically by the proposed
Hierarchical Representation Face Encoder (HieRFE) in an extended latent space to maintain more facial details, rather than compressed representation in previous face swapping methods. Secondly, a carefully designed Face Transfer
Module (FTM) is proposed to transfer the identity from a source image to the target by a non-linear trajectory without explicit feature disentanglement. Finally, the swapped faces can be synthesized by StyleGAN2 with the beneﬁts of its training stability and powerful generative capability. Each part of MegaFS can be trained separately so the require-∗Corresponding author ment of our model for GPU memory can be satisﬁed for megapixel face swapping. In summary, complete face repre-sentation, stable training, and limited memory usage are the three novel contributions to the success of our method. Ex-tensive experiments demonstrate the superiority of MegaFS and the ﬁrst megapixel level face swapping database is re-leased for research on DeepFake detection and face image editing in the public domain. 1.

Introduction
Given two face images, face swapping refers to transfer-ring the identity from the source image to the target image, while the facial attributes of the target image hold intact. It has attracted extensive attention in recent years for its broad application prospects in entertainment [4, 24], privacy pro-tection [6, 33], and theatrical industry [34].
Existing face swapping methods can be roughly di-vided into two categories: subject-speciﬁc and subject ag-nostic methods. Subject-speciﬁc face swapping methods
[11, 27, 34] need to be trained and tested on the same pair of subjects, which restricts their potential applications.
On the contrary, subject agnostic face swapping methods 4834
[35, 5, 28, 38, 36] can be applied to arbitrary identities with-out additional training procedures. In this paper, we focus on a more challenging topic: one shot face swapping, where only one image is given from the source and target identity for both training and testing.
With the rapid growth of high resolution image and video data on the web, it becomes increasingly popular to pro-cess high resolution samples. However, generating high resolution swapped faces is rather difﬁcult because of the following problems. Firstly, information is insufﬁcient for high-quality face generation due to the compressed repre-sentation in an end-to-end framework [5, 35, 28]. Secondly, adversarial training is unstable [8], which conﬁnes the res-olution of previous methods only up to 2562. Thirdly, the
GPU memory limitation makes the training untenable, or the training batch is bounded by a small size, which aggra-vates the collapse of the training process.
To this end, this paper proposes the ﬁrst Megapixel level one shot Face Swapping method (MegaFS) by adopting the
“divide and conquer” strategy in three steps. Firstly, to over-come the information loss in the encoder, we adopt GAN
Inversion methods [42, 10, 16, 1, 2, 10, 31, 11, 59] and pro-pose a Hierarchical Representation Face Encoder (HieRFE) to ﬁnd the complete face representation in an extended la-tent space W ++. Secondly, to modify face representations and resolve the problem of previous latent code manipula-tion methods [43, 17, 48, 51, 50, 7, 37, 3] that only one at-tribute can be modiﬁed once a time, a novel swapping mod-ule, Face Transfer Module (FTM), is proposed to control multiple attributes synchronously without explicit feature disentanglement. Finally, the unstable adversarial training problem is evaded by exploiting StyleGAN2 [23] as the de-coder, which is ﬁxed and the discriminator is not used for optimization. Each part of MegaFS can be trained sepa-rately so the GPU memory requirements are satisﬁed for megapixel face swapping. The contributions of this paper can be summarized as:
• To the best of our knowledge, the proposed MegaFS is the ﬁrst method that can conduct one shot face swap-pings at megapixel level.
• For encoding and manipulating the complete face rep-resentation, faces are encoded by HieRFE hierarchi-cally in the new extended latent space W ++ and a new multistep non-linear latent code manipulation module,
FTM, is proposed to manage multiple attributes syn-chronously without explicit feature disentanglement. 2.