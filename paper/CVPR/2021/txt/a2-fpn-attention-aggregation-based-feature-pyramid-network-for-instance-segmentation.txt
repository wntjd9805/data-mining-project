Abstract
Learning pyramidal feature representations is crucial for recognizing object instances at different scales. Fea-ture Pyramid Network (FPN) is the classic architecture to build a feature pyramid with high-level semantics through-out. However, intrinsic defects in feature extraction and fu-sion inhibit FPN from further aggregating more discrimi-native features. In this work, we propose Attention Aggre-gation based Feature Pyramid Network (A2-FPN), to im-prove multi-scale feature learning through attention-guided feature aggregation. In feature extraction, it extracts dis-criminative features by collecting-distributing multi-level global context features, and mitigates the semantic infor-mation loss due to drastically reduced channels. In feature fusion, it aggregates complementary information from ad-jacent features to generate location-wise reassembly ker-nels for content-aware sampling, and employs channel-wise reweighting to enhance the semantic consistency be-fore element-wise addition. A2-FPN shows consistent gains on different instance segmentation frameworks. By replac-ing FPN with A2-FPN in Mask R-CNN, our model boosts the performance by 2.1% and 1.6% mask AP when us-ing ResNet-50 and ResNet-101 as backbone, respectively.
Moreover, A2-FPN achieves an improvement of 2.0% and 1.4% mask AP when integrated into the strong baselines such as Cascade Mask R-CNN and Hybrid Task Cascade. 1.

Introduction
Instance segmentation is one of the most challenging tasks in computer vision. It aims to categorize and localize individual objects with pixel-wise instance masks. Accu-rate instance segmentation has wide applications in real sce-narios including automatic driving and video surveillance.
Driven by the rapid advances in deep convolutional net-works (ConvNets), the development of instance segmenta-tion frameworks, e.g., Mask R-CNN [14], PANet [26], and
*Corresponding author.
Figure 1. Defects in the construction of feature pyramid: (1) information loss, (2) content-agnostic sampling, and (3) semantic inconsistency between adjacent features.
HTC [5], has substantially pushed forward the state-of-the-art. Learning multi-scale feature representations is of great signiﬁcance because high-performance instance segmenta-tion needs to recognize varying numbers of instances across a broad range of scales and locations.
To address the issue of multi-scale processing, Feature
Pyramid Network (FPN) [22] is widely adopted in existing frameworks. FPN leverages the inherent feature hierarchy and constructs a feature pyramid that has strong semantics at all scales by fusing adjacent features through lateral con-nections and a top-down pathway. PAFPN in PANet [26] shortens the information path from the low level to top ones by adding an extra bottom-up pathway, further improving the localization capability of the feature pyramid.
Although FPN and PAFPN are effective in learning multi-scale feature representations, the simple designs in-hibit feature pyramids from further aggregating more dis-criminative features. We decompose the construction of feature pyramid into feature extraction and fusion, and ﬁnd each step has some intrinsic defects, as shown in Figure 1. 1 con-volutional layers are employed to generate features of the same channel dimension. However, the extracted feature maps, especially the high levels, suffer from serious in-formation loss because of drastic dimension reduction. In the ﬁrst step of feature fusion, feature maps are upsampled using interpolation in the top-down pathway or downsam-In feature extraction, lateral connections using 1
× 15343
pled through strided convolution in the bottom-up pathway.
However, interpolation executes the upsampling process in a sub-pixel neighborhood according to the relative posi-tions of pixels, failing to capture rich semantic information.
Strided convolution applies the content-agnostic downsam-pling kernel across the entire image, neglecting the under-lying content of features.
In the second step of feature fusion, two adjacent features are merged by element-wise addition, which ignores the semantic gap between feature maps caused by different depths.
In this work, we propose Attention Aggregation based
Feature Pyramid Network (A2-FPN), to improve multi-scale feature learning through attention-guided feature ag-gregation. Compared to existing frameworks, A2-FPN is distinctive in three signiﬁcant aspects: (1) It extracts dis-criminative features by collecting global context features from the whole feature hierarchy and distributing them to (2) It aggregates complementary information each level. from adjacent features to produce location-wise reassembly kernels for content-aware upsampling and downsampling. (3) It applies channel-wise reweighting to enhance the se-mantic consistency before element-wise addition.
Without bells and whistles, A2-FPN in Mask R-CNN framework leads to an improvement of 2.1% and 1.6% mask
AP compared with the FPN based counterpart when us-ing ResNet-50 and ResNet-101 as backbone, respectively.
Moreover, when integrated into the state-of-the-art instance segmentation methods such as Cascade Mask RCNN and
HTC [5], it achieves 2.0% and 1.4% higher mask AP than baseline models on the MS COCO dataset [24].
Our main contributions are summarized as follows: (1)
We propose Attention Aggregation based Feature Pyramid
Network (A2-FPN), which effectively aggregates pyramidal feature representations through attention-guided feature ex-traction and fusion. (2)We demonstrate that not only cross-scale connections are important, but the node operations to aggregate features are also crucial to the construction of feature pyramid. (3) We evaluate A2-FPN on the chal-lenging COCO dataset [24] through comprehensive experi-ments, and it can bring consistent and substantial improve-ments upon various frameworks and backbone networks. 2.