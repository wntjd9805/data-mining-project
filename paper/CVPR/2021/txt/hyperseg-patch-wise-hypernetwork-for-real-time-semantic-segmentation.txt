Abstract
We present a novel, real-time, semantic segmentation network in which the encoder both encodes and generates the parameters (weights) of the decoder. Furthermore, to allow maximal adaptivity, the weights at each decoder block vary spatially. For this purpose, we design a new type of hypernetwork, composed of a nested U-Net for drawing higher level context features, a multi-headed weight gen-erating module which generates the weights of each block in the decoder immediately before they are consumed, for efﬁcient memory utilization, and a primary network that is composed of novel dynamic patch-wise convolutions. De-spite the usage of less-conventional blocks, our architec-ture obtains real-time performance.
In terms of the run-time vs. accuracy trade-off, we surpass state of the art (SotA) results on popular semantic segmentation bench-marks: PASCAL VOC 2012 (val. set) and real-time seman-tic segmentation on Cityscapes, and CamVid. The code is available: https://nirkin.com/hyperseg. 1.

Introduction
Semantic segmentation plays a crucial role in scene un-derstanding, whether the scene is microscopic, telescopic, captured by a moving vehicle, or viewed through an AR device. New mobile applications go beyond seeking ac-curate semantic segmentation, and also requiring real-time processing, spurring research into real-time semantic seg-mentation. This domain has since become a leading test-bed for new architectures and training methods, with the goals of improving both accuracy and speed. Recent work added capacity [5, 6] and attention mechanisms [20, 45, 49] to improve performance. When runtime is not a concern, the image is often processed multiple times by the model and the results are accumulated. In this paper, we attempt to improve the performance in a different way: by providing the network with additional adaptivity.
We add this adaptivity using a meta-learning tech-nique, often referred to as dynamic networks or hypernet-works [13]. These networks are used for tasks ranging from
Figure 1. Run-time / accuracy trade-off comparison on the
Cityscapes [8] test set. Our models (in orange) achieve the best accuracy and the best run-time vs. accuracy trade-off relative to all previous real-time methods. text analysis [13, 50] to 3D modeling [26, 42], but rarely for generating image-like maps. The reason is that the hyper-networks, as suggested by previous methods, do not fully capture the signals of high resolution images.
Semantic segmentation map are an especially interesting case. They are generated by a coarse to ﬁne pyramid, where each level of the process can beneﬁt from adaptation, since these effects accumulate from one block to the next. More-over, since every part of the image may contain a different object, such adaptation is best done locally.
We thus offer a novel encoder-decoder approach, in which the encoder’s backbone is based on recent advances in the ﬁeld. The encoded signal is mapped to dynamic net-work weights using an internal U-Net, while the decoder consists of dynamic blocks with spatially varying weights.
The proposed architecture achieves SotA accuracy vs. runtime trade-off on the most widely used benchmarks for this task: PASCAL VOC 2012 [11], CityScapes [8], and
CamVid [2]. For CityScapes and CamVid, the SotA accu-racy result is obtained under the real-time conditions. De-spite using an unconventional architecture that employs lo-cally connected layers with dynamic weights, our method is very efﬁcient (See Fig. 1 for our run-time / accuracy trade-off relative to other methods.)
*Performed this work while an intern at Facebook.
To summarize, our contributions are: 14061
• A new hypernetwork architecture that employs a U-Net within a U-Net.
• Novel dynamic patch-wise convolution with weights that vary both per input and per spatial location.
• SotA accuracy vs. runtime trade-off on the major benchmarks of the ﬁeld. 2.