Abstract
The ability to segment teeth precisely from digitized 3D dental models is an essential task in computer-aided or-thodontic surgical planning. To date, deep learning based methods have been popularly used to handle this task.
State-of-the-art methods directly concatenate the raw at-tributes of 3D inputs, namely coordinates and normal vec-tors of mesh cells, to train a single-stream network for fully-automated tooth segmentation. This, however, has the drawback of ignoring the different geometric meanings pro-vided by those raw attributes. This issue might possibly confuse the network in learning discriminative geometric features and result in many isolated false predictions on the dental model. Against this issue, we propose a two-stream graph convolutional network (TSGCNet) to learn multi-view geometric information from different geometric at-tributes. Our TSGCNet adopts two graph-learning streams, designed in an input-aware fashion, to extract more dis-criminative high-level geometric representations from coor-dinates and normal vectors, respectively. These feature rep-resentations learned from the designed two different streams are further fused to integrate the multi-view complemen-tary information for the cell-wise dense prediction task. We evaluate our proposed TSGCNet on a real-patient dataset of dental models acquired by 3D intraoral scanners, and experimental results demonstrate that our method signiﬁ-cantly outperforms state-of-the-art methods for 3D shape segmentation.
∗Equal contribution.
†Corresponding author.
Figure 1. An illustration of 3D dental model. In the local space indicated by the blue box, cell A and cell B are spatially close but with much different normal vectors (indicated by the black arrows
In contrast, cell A and cell C have simi-in the zoomed view). lar normal vectors but are far from each other.
It suggests that coordinates and normal vectors provide completely different geo-metric information. Hence, simply concatenating them as a single feature vector (commonly used in the conventional single-stream networks) cannot properly integrate such complementary informa-tion to learn more discriminative geometric representations for cell classiﬁcation, which will result in many isolated false predictions on dental model (as indicated by one of red dotted circle). 1.

Introduction
An essential task in computer-aided-design system for orthodontic treatment is to provide accurate segmentation of teeth on digitalized 3D dental models reconstructed by in-traoral scanners (IOS). This segmentation information can be used for aiding clinical diagnose, providing digital teeth shape information for personal surgical-orthodontic plan-ning, quantifying the difference between expected and clin-ical treatment results to adjust orthodontic treatment plan, etc. However, segmenting each tooth from the gingiva is 6699
practically challenging, mainly due to heterogeneous tooth appearance: i) Although most human teeth have common geometric characteristics, their shapes are unique and vary ii) Orthodontic patients dramatically across individuals. usually have atypical conditions such as missing, crowded and/or misaligned teeth, all of which may produce indistinct tooth boundaries. iii) Noise and occlusion during scanning may result in a partially reconstructed dental surface with missing parts.
To deal with these challenges, various (semi-) automated methods have been proposed for tooth segmentation on 3D dental models. Conventional approaches typically per-form segmentation by using pre-selected geometric prop-erties (e.g., the 3D coordinates, normal vectors and curva-ture) [40, 41, 9, 8, 32, 22, 38, 1] or projecting 3D meshes onto 2D images [23, 31]. Due to the requirement of man-ual initialization, the efﬁcacy of such semi-automated meth-ods relies on the professional knowledge and experience.
Furthermore, the robustness of these conventional methods may be hampered since the exclusive use of low-level ge-ometric properties would not be able to segment teeth with extreme appearances accurately.
Recently, deep learning-based methods have been pro-posed to learn task-oriented feature representations for fully-automated tooth segmentation. Some of these meth-ods [25, 36] transformed mesh vertices/cells as ordered 2D image-like (or volumetric) inputs and then applied general convolutional neural networks (CNNs) to perform segmen-tation. Although straightforward, such operations tend to ignore the unordered nature of geometric data. They also in-cline to introduce additional computational costs and quan-tization errors during the potential voxelization stage. To avoid additional data pre-processing, more recent meth-ods [5, 14, 13] applied or extended existing point-cloud segmentation networks to perform vertex/cell-wise seman-tic labeling of 3D dental meshes. As the network inputs, the 3D coordinates and normal vectors (of mesh vertices/cells) are typically concatenated in these methods to train a single-stream network. However, considering that the coordinate indicates the cell spatial position, while the normal vector represents the cell morphological structure, directly comb-ing these two completely different attributes as a single fea-ture vector tends to weaken their geometric discrimination (e.g., an example is shown in Fig. 1). Hence, this would confuse those conventional single-stream networks in learn-ing discriminative geometric features for cell classiﬁcation, potentially resulting in isolated false predictions on the den-tal model.
To resolve these issues, we propose a two-stream graph convolutional network (TSGCNet) in this paper to learn multi-view geometric information for end-to-end tooth seg-mentation on 3D dental models.
In order to eliminate the mutual confusion caused by mixed geometric inputs, our TSGCNet starts with two parallel branches, namely C-stream and N-stream, to learn independently multi-scale feature representations from coordinates and normal vec-tors, respectively. Besides, considering different geometric meanings of those attributes, the two streams are also con-structed by different graph-learning strategies designed in an input-aware fashion. That is, C-stream adopts graph-attention convolutions [27] to learn the coarse structures of different teeth from coordinates, while the N-stream adopts graph max-pooling to extract distinctive structural details [27] from the normal vectors, which can further help C-stream to distinguish neighboring cells belonging to different classes (e.g., boundaries between adjacent teeth or between teeth and gingiva). These multi-scale geomet-ric representations produced by the two parallel streams are further fused by the subsequent multi-layer perceptrons (MLPs) to learn complementary multi-view information for dense labeling of all cells on the mesh surface.
The main contributions of this paper can be summarized as follows:
• We propose a novel two-stream graph convolutional network that can independently process coordinates and normal vectors to learn more discriminative ge-ometric features for 3D dental model segmentation.
• We design two different graph-based feature aggrega-tion modules in an input-aware fashion to consume cell coordinates and normal vectors, respectively. That is, the C-stream adopts graph attention convolutions to capture the coarse structure of teeth from coordinates, while the N-stream extract distinctive structural details from normal vectors.
• Our TSGCNet is evaluated on a clinical dataset of 3D dental models for different orthodontic patients digi-tized by IOS. The experimental results show that our
TSGCNet signiﬁcantly outperform state-of-the-art 3D shape segmentation methods. 2.