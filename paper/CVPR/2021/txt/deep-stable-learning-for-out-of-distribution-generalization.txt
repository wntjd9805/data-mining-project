Abstract
Approaches based on deep neural networks have achieved striking performance when testing data and train-ing data share similar distribution, but can signiﬁcantly fail otherwise. Therefore, eliminating the impact of distri-bution shifts between training and testing data is crucial for building performance-promising deep models. Conven-tional methods assume either the known heterogeneity of training data (e.g. domain labels) or the approximately equal capacities of different domains. In this paper, we con-sider a more challenging case where neither of the above assumptions holds. We propose to address this problem by removing the dependencies between features via learning weights for training samples, which helps deep models get rid of spurious correlations and, in turn, concentrate more on the true connection between discriminative features and labels. Extensive experiments clearly demonstrate the ef-fectiveness of our method on multiple distribution general-ization benchmarks compared with state-of-the-art counter-parts. Through extensive experiments on distribution gen-eralization benchmarks including PACS, VLCS, MNIST-M, and NICO, we show the effectiveness of our method com-pared with state-of-the-art counterparts. 1.

Introduction
Many machine learning approaches tend to exploit sub-tle statistical correlations existing in the training distribu-tion for predictions which have been shown to be effec-tive under the I.I.D. hypothesis, i.e., testing and training data is independently sampled from the identical distribu-tion. In real cases, however, such a hypothesis can hardly be satisﬁed due to the complex generation mechanism of real data such as data selection biases, confounding factors, or other peculiarities [5, 54, 12, 47, 21]. The testing distri-bution may incur uncontrolled and unknown shifts from the
*Corresponing author, also with Beijing Key Lab of Networked Mul-timedia t u p n
I e g a m
I e n i l e s a
B t e
N e l b a t
S
) s r u o (
Figure 1: Visualization of saliency maps produced by the vanilla ResNet-18 model and StableNet when most of the training images containing dogs in the water. The lightness of the saliency map indicates how much attention that the models pay on particular area of the input image (i.e. lighter area plays a more crucial role for the prediction than the darker area). Due to the spurious correlation, the ResNet-18 model tends to focus on both dogs and the water while our model focuses mostly on dogs. training distribution, which makes most machine learning models fail to make trustworthy predictions [2, 51]. To ad-dress this issue, out-of-distribution (OOD) generalization is proposed for improving the generalization ability of models under distribution shifts [55, 27].
Essentially, when there incurs a distribution shift, the ac-curacy drop of current models is mainly caused by the spuri-ous correlation between the irrelevant features (i.e. the fea-tures that are irrelevant to a given category, such as features of context, ﬁgure style, etc.) and category labels, and this kind of spurious correlations are intrinsically caused by the subtle correlations between irrelevant features and relevant features (i.e. the features that are relevant to a given cate-gory) [30, 38, 35, 2]. Taking the recognition task of ‘dog’ category as an example, as depicted in Figure 1, if dogs are 5372  
in the water in most training images, the visual features of dogs and water would be strongly correlated, thus leading to the spurious correlation between visual features of water with the label ‘dog’. As a result, when encountering images of dogs without water, or other objects (such as cats) with water, the model is prone to produce false predictions.
Recently, such distribution (domain) shift problems have been intensively studied in the domain generalization (DG) literature [41, 17, 25, 62, 31, 33]. The basic idea of DG is to divide a category into multiple domains so that ir-relevant features vary across different domains while rel-evant features remain invariant [25, 34, 40]. Such training data makes it possible for a well-designed model to learn the invariant representations across domains and inhibit the negative effect from irrelevant features, leading to better generalization ability under distribution shifts. Some pio-neering methods require clear and signiﬁcant heterogeneity, namely that the domains are manually divided and labeled
[61, 16, 46, 9, 42], which cannot be always satisﬁed in real applications. More recently, some methods are proposed to implicitly learn latent domains from data [44, 39, 60], but they implicitly assume that the latent domains are balanced, meaning that the training data is formed by balanced sam-pling from latent domains. In real cases, however, the as-sumption of domain balance can be easily violated, leading to the degeneration of these methods. This is also empiri-cally validated in our experiments as shown in Section 4.
Here we consider a more realistic and challenging set-ting where the domains of training data are unknown and we do not implicitly assume that the latent domains are bal-anced. With this goal, a strand of research on stable learn-ing are proposed [50, 28]. Given that the statistical depen-dence between relevant and irrelevant features is a major cause of model crash under distribution shifts, they propose to realize out-of-distribution generalization by decorrelat-ing the relevant and irrelevant features. Since there is no extra supervision for separating relevant features from ir-relevant features, a conservative solution is to decorrelate all features. Recently, this notion has been demonstrated to be effective in improving the generalization ability of linear models. [29] proposes a sample weighting approach with the goal of decorrelating input variables, and [51] theoreti-cally proves why such sample weighting can make a linear model produce stable predictions under distribution shifts.
But they are all developed under the constraints of linear frameworks. When extending these ideas into deep models to tackle more complicated data types like images, we con-front two main challenges. First, the complex non-linear dependencies among features are much more difﬁcult to be measured and eliminated than the linear ones. Second, the global sample weighting strategy in these methods requires excessive storage and computational cost in deep models, which is infeasible in practice.
To address these two challenges, we propose a method called StableNet. In terms of the ﬁrst challenge, we pro-pose a novel nonlinear feature decorrelation approach based on Random Fourier Features [45] with linear computational complexity. As for the second challenge, we propose an ef-ﬁcient optimization mechanism to perceive and remove cor-relations globally by iteratively saving and reloading fea-tures and weights of the model. These two modules are jointly optimized in our method. Moreover, as shown in
Figure 1, StableNet can effectively partial out the irrelevant features (i.e. water) and leverage truly relevant features for prediction, leading to more stable performances in the wild non-stationary environments. 2.