Abstract
Motions are reﬂected in videos as the movement of pix-els, and actions are essentially patterns of inconsistent mo-tions between the foreground and the background. To well distinguish the actions, especially those with complicated spatio-temporal interactions, correctly locating the promi-nent motion areas is of crucial importance. However, most motion information in existing videos are difﬁcult to la-bel and training a model with good motion representations with supervision will thus require a large amount of human labour for annotation. In this paper, we address this prob-lem by self-supervised learning. Speciﬁcally, we propose to learn Motion from Static Images (MoSI). The model learns to encode motion information by classifying pseudo motions generated by MoSI. We furthermore introduce a static mask in pseudo motions to create local motion patterns, which forces the model to additionally locate notable motion ar-eas for the correct classiﬁcation. We demonstrate that MoSI can discover regions with large motion even without ﬁne-tuning on the downstream datasets. As a result, the learned motion representations boost the performance of tasks re-quiring understanding of complex scenes and motions, i.e., action recognition. Extensive experiments show the con-sistent and transferable improvements achieved by MoSI.
Codes will be soon released. 1.

Introduction
Understanding motion patterns is a key challenge in many video understanding problems such as action recogni-tion [7], action localization [40] and action detection [55].
A suitable way to encode motions can signiﬁcantly boost the performance in those tasks [41]. Early works represent motions using hand-crafted features [35, 46, 34] based on dense trajectories [45] and optical ﬂow [2]. With the suc-cessful application of deep neural networks [14, 22, 18] and the construction of large scale image and video datasets [5, 19], endeavors have been made to design architectures to
Static 
Image
Unmasked MoSI
Label
Prediction 0.0 0.2 0.0 0.7 0.1
Loss
FC Layer
…
…
Pseudo Motions 3D Backbone (a) Unmasked MoSI (no static masks) (b) Dribble (c) Cartwheel
Figure 1: (a) Unmasked MoSI constructs image sequences with pseudo motions from static images. The model is trained to encode motions by predicting the direction and speed of the pseudo motions. For simplicity, the speed gran-ularity here is set as K = 1 (see Sec. 3.1). (b), (c) Grad-CAM [38] visualizations on HMDB51 videos for the conv5 pre-trained by our MoSI on ImageNet [5], where the model locates prominent motions even without ﬁne-tuning on the downstream dataset (See more in Sec. 4.1). extract meaningful motion features [16, 7, 49, 47, 54, 41].
Despite their powerful capability of modeling dynamic vari-ations between frames, the 3D convolutional models require a large amount of manually labeled videos to achieve a good generalized performance [13]. 1276
Recently, self-supervised learning has emerged as a pow-erful technique for training the model without labeled data in both image and video paradigm [51, 11, 20, 6, 33]. These methods learn visual representations by exploiting inher-ent structures of the unlabeled images or videos, for in-stance, by predicting the correct order of spatial or tempo-ral sequences [51, 6, 9, 24] or by predicting partial con-tents [11, 12, 33]. Because videos naturally have an ex-tra axis of time compared to images, some methods ma-nipulate the temporal dimension and predict the playback speeds [1, 52]. Although some of the efforts were able to capture the motion information implicitly, almost none of them aims to model motion information of videos explicitly in a self-supervised fashion.
In this work, we seek to train the video model to di-rectly distinguish different motion patterns. The objective is for the model to encode meaningful motion information, so that prominent motions can be discovered and attended to during ﬁne-tuning. Since directly generating predeﬁned motion patterns from a video set may be difﬁcult, we lever-age static images for motion generation. Formally, we pro-pose a learning framework that learns motions directly from images (MoSI). Its general structure is shown in Fig. 1.
Given the desired direction and the speed of the motions,
MoSI generates pseudo motions from static images. By cor-rectly classifying the direction and speed of the movement in the image sequence, models trained with MoSI is able to well encode motion patterns. Furthermore, a static mask (Fig. 3) is applied to the pseudo motion sequences. This produces inconsistent motions between the masked area and the unmasked one, which guides the network to focus on the inconsistent local motions. We term the one with and without static masks as MoSI and unmasked MoSI respec-tively. Conceptually, the idea of masked MoSI is closely related to attention learning, where the network learns to attend more to the moving areas in videos explicitly cre-ated by pseudo motion. Different from the attention mech-anism [15, 25, 26], where attention is generated by care-fully designed architectures, the attention learned by MoSI is achieved by purely altering the training data.
To the best of our knowledge, this is the ﬁrst time that static images are used as the data source for pre-training video models. Using MoSI, we are able to exploit large-scale image datasets such as ImageNet [5] to train video models. Although images contain less information about dynamics that are intrinsic in videos, the representations learned with MoSI can be as powerful as those learned us-ing videos in terms of motion understanding. Extensive em-pirical studies with HMDB51 and UCF101 further demon-strate the effectiveness of MoSI. Compared with other pre-viously published works, we show that the proposed MoSI reaches new state-of-the-art results for learning video rep-resentations using RGB modality. 2.