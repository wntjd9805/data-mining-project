Abstract dataset and code are available at https://github. com/zzh-tech/RSCD∗.
Joint rolling shutter correction and deblurring (RSCD) techniques are critical for the prevalent CMOS cameras.
However, current approaches are still based on conven-tional energy optimization and are developed for static scenes. To enable learning-based approaches to address real-world RSCD problem, we contribute the ﬁrst dataset,
BS-RSCD, which includes both ego-motion and object-motion in dynamic scenes. Real distorted and blurry videos with corresponding ground truth are recorded simultane-ously via a beam-splitter-based acquisition system.
Since direct application of existing individual rolling shutter correction (RSC) or global shutter deblurring (GSD) methods on RSCD leads to undesirable results due to inherent ﬂaws in the network architecture, we further present the ﬁrst learning-based model (JCD) for RSCD. The key idea is that we adopt bi-directional warping streams for displacement compensation, while also preserving the non-warped deblurring stream for details restoration. The experimental results demonstrate that JCD achieves state-of-the-art performance on the realistic RSCD dataset (BS-RSCD) and the synthetic RSC dataset (Fastec-RS). The 1.

Introduction
Rolling shutter (RS) CMOS cameras dominate the con-sumer market, especially the mobile phone market, due to their largely reduced power consumption, low cost and compact design [13]. However, if the imaging conditions are not ideal, video recorded through RS mechanism will suffer from compound quality issues. Speciﬁcally, the RS distortion (Jello effect) and motion blur become noticeable when there is a large relative motion between the camera and the object, especially in poorly illuminated environment where longer exposure time is required. Joint rolling shutter correction and deblurring (RSCD) techniques are seldom explored and are urgently needed for RS-based devices.
Existing works generally treat rolling shutter correction (RSC) and deblurring as two separate issues. As for RSC methods [30, 29, 47, 18, 37, 20], they assume by default
∗Correspondence regarding the dataset should be addressed to Y. Zheng (yqzheng@ai.u-tokyo.ac.jp). 9219
that there are no blur effects in the captured image but only distortion caused by the scanning strategy of RS that ex-poses each row sequentially. The formation of the image Ir with only RS distortion can be described as follows: r [i] = I (t−tm+itr)
I (t) g
[i], (1) where tm equals (M/2)tr; tr denotes the readout (offset) time for each row of RS; M denotes total number of rows of the image; I (t) r [i] denotes the ith row of the RS distorted image Ir with the middle moment of exposure at time t;
I (t−tm+itr)
[i] denotes the same row of the virtual global g shutter (GS) image Ig with the middle moment of exposure at time t − tm + itr, the entire scene of which is captured si-multaneously. On the other hand, existing deblurring meth-ods (GSD) [40, 10, 33, 24, 35, 25, 26, 44] typically assume the target image is captured by GS. Then, the formation of the GS blurry image Ib is given by:
I (t) b = 1 te Z t+te/2 t−te/2
I (t) g dt, (2) where te denotes the exposure time of GS. The combined effect of RS distortion and blur escalates the problem to a new dimension. The formation of RS distorted and blurry image Irb can be described as follows:
I (t) rb [i] = 1 te Z t−tm+itr+te/2 t−tm+itr−te/2
I (t−tm+itr) g
[i]dt. (3)
As the reverse process of the Eq. (3), RSCD is extremely challenging because it requires estimating pixel-level dis-placements and blur kernels simultaneously.
Under simpliﬁed or idealized conditions, there are few works [34, 22] that speciﬁcally address blind RSCD prob-lem. Assuming a static scene and negligible in-plane rota-tion, Su et al. [34] propose RS-BMD to deliver distortion-free and sharp image by estimating parametric trajectory of the camera. Mohan et al. [22] further remove the lim-itation of parametric trajectory estimation, allowing their method to handle RS blurry image produced by irregular camera trajectory. However, these methods cannot cope with freely moving objects in dynamic scenes, which are often observed in a real-world scenario. Due to the com-plexity of relative motion in the RSCD problem, not only is
RSCD modeling difﬁcult, but inferring the latent image is also time-consuming.
Recently, the success of deep learning methods and the corresponding large-scale datasets has greatly facilitated the development of image and video restoration techniques.
However, the development of learning-based RSCD meth-ods is still hampered by the lack of datasets. Even for pure RSC problem, there is only one public dataset (Fastec-RS [20]) available for data-driven methods, which synthe-sizes RS images by sequentially copying a row of pixels from captured high-FPS GS images. It still remains a chal-lenge to obtain RS distorted and blurry video and the corre-sponding GS sharp video for the same scenes in the wild.
In this paper, to enable data-driven methods for RSCD, we propose BS-RSCD, the ﬁrst dataset used for real-world
RSCD task, using a well-designed beam-splitter acquisi-tion system. A RS camera and a GS camera are physically aligned to capture RS distorted and blurry as well as GS sharp video pairs simultaneously. Based on this dataset, we further explore the possibility of applying deep learn-ing to address realistic RSCD problem. The complexity of BS-RSCD brings a new challenge to the existing neu-ral network architecture of GSD or RSC. Through experi-ments, we found that the existing GSD methods are prone to destroy the original geometric structure of the scene when facing the displacement introduced by RS distortion, while the existing RSC methods are difﬁcult to recover the de-tails from motion blur. To solve this dilemma, we design a novel joint correction and deblurring model (JCD) that incorporates the advantages of both RSC and GSD neural network architectures. To achieve a better trade-off between distortion correction and motion deblurring, JCD fuses bi-directional warped features and non-warped deblurring fea-tures at multiple scales using a deformable attention mod-ule. Our contributions can be summarized as follows:
• We introduce BS-RSCD, the ﬁrst dataset for joint
RSCD problem in real dynamic scenes, using a beam-splitter acquisition system.
• We propose a novel neural network architecture that can handle both RS distortion and blur, using de-formable attention module to fuse features from bi-directional warping and deblurring streams.
• Experimental results demonstrate the superiority of the proposed method over the state-of-the-art methods in both RSC and RSCD tasks, and show the effectiveness of our BS-RSCD dataset. 2.