Abstract
Most existing nighttime visibility enhancement methods focus on low light. Night images, however, do not only suf-fer from low light, but also from man-made light effects such as glow, glare, ﬂoodlight, etc. Hence, when the ex-isting nighttime visibility enhancement methods are applied to these images, they intensify the effects, degrading the vis-ibility even further. High dynamic range (HDR) imaging methods can address the low light and over-exposed re-gions, however they cannot remove the light effects, and thus cannot enhance the visibility in the affected regions.
In this paper, given a single nighttime image as input, our goal is to enhance its visibility by increasing the dynamic range of the intensity, and thus can boost the intensity of the low light regions, and at the same time, suppress the light effects (glow, glare) simultaneously. First, we use a net-work to estimate the camera response function (CRF) from the input image to linearise the image. Second, we decom-pose the linearised image into low-frequency (LF) and high-frequency (HF) feature maps that are processed separately through two networks for light effects suppression and noise removal respectively. Third, we use a network to increase the dynamic range of the processed LF feature maps, which are then combined with the processed HF feature maps to generate the ﬁnal output that has increased dynamic range and suppressed light effects. Our experiments show the ef-fectiveness of our method in comparison with the state-of-the-art nighttime visibility enhancement methods. 1.

Introduction
Due to varying illumination and multiple man-made light sources, night images not only contains low-light regions but also glow, glare, ﬂoodlight, etc., which can severely degrade the visibility of the images. This degra-dation poses challenges for many vision algorithms when applied to nighttime conditions. Hence, enhancing the visi-†This work is supported by MOE2019-T2-1-130.
Input
Our Method
SingleHDR [19]
EnlightenGAN [13]
Figure 1. For the input nighttime image with glow/glare light ef-fects, existing visibility enhancement [13] and HDR [19] imaging methods cannot handle the light effects and incorrectly intensify them. In contrast, our method suppresses the light effects and gen-erates better visibility enhancement results. bility of night images by boosting the intensity of low light regions, yet at the same time suppressing the night light ef-fects (glow, glare) is an important task.
Existing nighttime visibility enhancement methods [11, 3, 13, 26, 10] assume that the input image is under-exposed and has low-light regions. Hence, to improve the visibil-ity, these methods perform intensity boosting and denois-ing. Night images, however, also suffer from over-exposed regions as well as glow, glare, etc. which get intensiﬁed upon intensity boosting, and this further degrades the vis-ibility. Fig. 1 shows an example. As can be observed, the existing visibility enhancement method EnlightenGAN [13] incorrectly intensiﬁes the glow/glare light effects.
HDR imaging methods [19, 6], to some extent, can im-prove the visibility of night images. They take a single 11977
image as input and generates an output image that has a higher dynamic range, which provides better visibility for the under-exposed and over-exposed regions of the image.
Unfortunately, these methods also cannot suppress glow, glare and ﬂoodlight, and thus cannot enhance the visibility of the scenes behind these light effects (see Fig. 1).
In this paper, given a single night image as input, our goal is to improve its visibility by simultaneously increasing the dynamic range (to deal with low-light and over-exposed region) and suppressing the light effects (glow, glare, etc.).
To achieve the goal, we propose a semi-supervised network.
We use paired images (with HDR ground-truths) to train our network to increase the dynamic range, and unpaired images (without ground-truths) to train our network to sup-press the light effects. We ﬁrst estimate the inverse CRF of the input night image using a linearisation network. Unlike methods [16, 19], which use fully-supervised training based on synthesized data, our method uses semi-supervised train-ing using both synthesized (with CRF ground-truths) and real data (without CRF ground-truths), which provides bet-ter generalization capability to our method.
Having obtained the linearised image, we decompose it into low-frequency (LF) and high-frequency (HF) fea-ture maps. The LF feature maps are likely to contain the glow/glare light effects (since they are smooth [17]), while the HF feature maps will contain noise, textures, edges, etc.
The LF and HF feature maps are processed separately using our two networks to suppress the light effects and remove the noise respectively. The processed LF features maps that contain suppressed light effects are passed to another net-work to increase their dynamic range. The resulting LF feature maps are then fused with the processed HF feature maps to generate the output image that has both increased dynamic range and suppressed light effects.
In summary, our contributions are as follows:
• We introduce a new method for single-image night-time visibility enhancement such that the enhanced output image has both increased dynamic range and suppressed glow/glare light effects. To our knowledge, our method is the ﬁrst method to address this problem.
• We train our method using semi-supervised learning.
We use paired data for learning to increase the dynamic range; and, unpaired data for learning the light effect suppression. We use priors such as the smoothness prior for the light effects (glow, glare, ﬂoodlight) in de-signing our unsupervised losses. Our CRF estimation is also semi-supervised, where the unsupervised losses are designed based on the monotonicity constraint of
CRFs and the linearisation constraint obeyed by edge-based pixels in the irradiance domain.
Our experiments show that our method outperforms the state-of-the-art single-image nighttime visibility enhance-ment and HDR imaging methods. 2.