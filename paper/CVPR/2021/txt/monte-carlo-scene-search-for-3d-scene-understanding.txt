Abstract
We explore how a general AI algorithm can be used for 3D scene understanding to reduce the need for train-ing data. More exactly, we propose a modiﬁcation of the Monte Carlo Tree Search (MCTS) algorithm to retrieve objects and room layouts from noisy RGB-D scans. While MCTS was developed as a game-playing algorithm, we show it can also be used for complex perception problems. Our adapted MCTS algorithm has few easy-to-tune hyperparameters and can optimise general losses. We use it to optimise the posterior prob-ability of objects and room layout hypotheses given the
RGB-D data. This results in an analysis-by-synthesis approach that explores the solution space by rendering the current solution and comparing it to the RGB-D observations. To perform this exploration even more efﬁciently, we propose simple changes to the standard
MCTS’ tree construction and exploration policy. We demonstrate our approach on the ScanNet dataset. Our method often retrieves conﬁgurations that are better than some manual annotations, especially on layouts.
∗The ﬁrst two authors contributed equally. 13804
1.

Introduction 3D scene understanding is a fundamental problem in
Computer Vision [41, 53].
In the case of indoor scenes, one usually aims at recognizing the objects and their prop-erties such as their 3D pose and geometry [2, 3, 15], or the room layouts [57, 31, 62, 59, 30, 36, 50, 60, 62, 54, 55], or both [4, 18, 35, 45, 51, 56]. With the development of deep learning approaches, the ﬁeld has made a remarkable progress. Unfortunately, all recent methods are trained in a supervised way on 3D annotated data. Such a supervised approach has several drawbacks: 3D manual annotations are particularly cumbersome to create and creating realis-tic virtual 3D scenes also has a high cost [42]. Moreover, supervised methods also tend to generalize poorly to other datasets. Even more importantly, they can only be as good as the training 3D annotations, and mistakes in manual an-notations are actually common in existing datasets, as we will show.
If one wants to go further and consider more scenes without creating real or synthetic training datasets, it seems important to be able to develop methods that do not rely too much on 3D scenes for training.
Over the history of 3D scene understanding, many non-supervised approaches have already been proposed, in-cluding recently to leverage deep learning object detec-tion methods. They typically combine generative mod-els and the optimization of their parameters. Genera-tive methods for 3D scene understanding indeed often in-volve optimization problems with high complexity, and many optimization tools have thus been investigated, in-cluding Markov Random Fields (MRFs) and Conditional
Random Fields (CRFs) [22, 52, 32], Markov Chains Monte
Carlo (MCMCs) [9, 19, 10, 58], tree search [28], or hill climbing [61, 21]. However, there does not seem to be a clear method of choice: MRFs and CRFs impose strong constraints on the objective function; MCMCs depend on many hyperparameters that are difﬁcult to tune and can re-sult in slow convergence; hill climbing can easily get stuck in a local optimum. The tree search method used by [28] uses a ﬁxed width search tree that can miss good solutions.
In this paper, we advocate for the use of Monte Carlo
Tree Search (MCTS) [12, 5], which is a general discrete AI algorithm for learning to play games [46], for optimization in 3D scene understanding problems. We propose to see perception as a (single-player) game, where the goal is to identify the right 3D elements that explain the scene.
In such cases where the search problem can be organized into a tree structure which is too large for exhaustive evaluation,
MCTS becomes a very attractive option. It also depends on very few easy-to-tune hyperparameters. Moreover, it can be interrupted at any time to return the best solution found so far, which can be useful for robotics applications. A parallel implementation is also possible for high efﬁciency [8]. In short, MCTS is a powerful optimization algorithm, but to the best of our knowledge, it has never been applied to 3D perception problems.
To apply MCTS to 3D scene understanding, as shown in
Fig. 1, we generate proposals for possible objects and layout components using the point cloud generated from the RGB-D sequence, as previous works do from a single RGB-D frame [28, 61]. MCTS can be used to optimize general loss functions, which do not even have to be differentiable. This allows us to rely on a loss function based on an analysis-by-synthesis (or “render-and-compare”) approach to select the proposals that correspond best to the observations. Our loss function compares (non-realistic) renderings of a set of pro-posals to the input images and can incorporate constraints between the proposals. This turns MCTS into an analysis-by-synthesis method that explores possible sets of proposals for the observations, possibly back-tracking to better solu-tions when an exploration does not appear promising.
We adapted the original MCTS algorithm to the 3D scene understanding problem to guide it towards the cor-rect solution faster, and call the resulting method “MCSS”, for Monte Carlo Scene Search. First, it is possible to struc-ture the search tree so that it does not contain any impossi-ble solutions, for example, solutions with intersecting pro-posals. We also enforce the exploration of proposals which are close spatially to proposals in the same path to the root node. Second, we introduce a score based on how the pro-posal improves the solution locally to increase the efﬁciency of search.
In practice, we ﬁrst run MCSS only on the layout pro-posals to recover the layout. We then run MCSS on the ob-ject proposals using the recovered layout. The recovery of the objects thus exploits constraints from the layout, which we found useful as shown in our experiments. In principle, it is possible to run a single MCSS on both the object and layout component proposals, but constraints from the ob-jects did not appear useful to constrain the recovery of the layout for the scenes in ScanNet, which we use to evalu-ate our approach. We therefore used this two-step approach for simplicity. It is, however, possible that more complex scenes would beneﬁt from a single MCSS running on all the proposals.
Running our method takes a few minutes per scene. This is the same order of magnitude as the time required to ac-quire an RGB-D sequence covering the scene, but deﬁni-tively slower than supervised methods. However, our di-rection could lead to a solution that automatically gener-ates annotations, which could be used to train supervised methods for fast inference. We show in the experiments that our method already retrieves annotations that are sometimes more accurate than existing manual annotations, and that it can be applied to new data without tuning any parameters.
Beyond that, MCTS is a very general algorithm, and the approach we propose could be transposed to other percep-13805
tion problems and even lead to an integrated architecture between perception and control, as MCTS has also already been applied to robot motion planning control [25]. 2.