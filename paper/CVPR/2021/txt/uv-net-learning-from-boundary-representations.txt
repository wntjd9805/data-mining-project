Abstract
We introduce UV-Net, a novel neural network architecture and representation designed to operate directly on Boundary representation (B-rep) data from 3D CAD models. The B-rep format is widely used in the design, simulation and manufac-turing industries to enable sophisticated and precise CAD modeling operations. However, B-rep data presents some unique challenges when used with modern machine learning due to the complexity of the data structure and its support for both continuous non-Euclidean geometric entities and discrete topological entities. In this paper, we propose a uni-ﬁed representation for B-rep data that exploits the U and V parameter domain of curves and surfaces to model geometry, and an adjacency graph to explicitly model topology. This leads to a unique and efﬁcient network architecture, UV-Net, that couples image and graph convolutional neural networks in a compute and memory-efﬁcient manner. To aid in future research we present a synthetic labelled B-rep dataset, Soli-dLetters, derived from human designed fonts with variations in both geometry and topology. Finally we demonstrate that
UV-Net can generalize to supervised and unsupervised tasks on ﬁve datasets, while outperforming alternate 3D shape representations such as point clouds, voxels, and meshes. 1.

Introduction
Parametric curves and surfaces form the basis of computer-aided design (CAD) and are widely used in design, simulation, and manufacturing. CAD software is primar-ily concerned with modeling and representing 3D solids— closed, watertight shapes which describe objects unambigu-ously with consistently oriented patches of surface geometry.
The industry-wide standard to represent solid models is the
Boundary representation (B-rep) [41, 23]. The B-rep is a versatile data structure comprised of faces (bounded por-tions of surfaces), edges (bounded pieces of curves) and ver-tices (points), glued together with topological connections between them. The B-rep enables a variety of parametric
Figure 1: UV-Net builds features by sampling points on the edges and faces of solid models. These features are then message-passed among adjacent topological entities. curves and surfaces, such as lines, arcs, planes, cylinders, toruses and Non-Uniform Rational B-Splines (NURBS), to precisely represent complex 3D shapes formed from CAD modeling operations such as extrusions, ﬁllets, and Booleans.
CAD users interact directly with B-rep faces, edges, and ver-tices to select, align, and modify 3D shapes. To leverage the recent advances of deep neural networks in CAD software, an appropriate representation of B-rep data is required. Such a representation has the potential to unlock numerous CAD applications such as auto-complete of modeling operations, smart selection tools, shape similarity search and many more.
Critical to enabling these applications is a representation that encodes the B-rep entities themselves.
Despite widespread usage of B-rep data in the industry, there exists limited research on applying deep neural net-works to this representation directly. There are numerous challenges in feeding B-rep data to neural networks. B-rep data consists of disparate geometric and topological entities, such as parametric curves and surfaces, each with their own set of parameters. Moreover, the mapping between a shape and a surface type is not one-to-one, for example, a plane 11703
can be represented as a B-spline of arbitrary degree. This means raw surface information, such as parametric coefﬁ-cients or spline control points, cannot be fed directly into a neural network, as it would not be invariant to the speciﬁc parameterization. Finally, consideration must be given to how different curve and surface geometry are connected to form the entire shape, i.e. the topology.
An alternate approach is to preprocess B-rep data into well-studied representations, such as images, voxels, point clouds, or triangle meshes. Although plausible, such con-versions are neither differentiable, nor trivial. Discretized representations, such as point clouds or voxels, suffer from loss of ﬁdelity and may lose the critical mapping back to the original B-rep entities. Conversion to triangle meshes can be non-trivial and prone to failure when high quality, manifold meshes are required [13].
To tackle these challenges, we present UV-Net, a novel neural network architecture and representation designed to operate directly on B-rep entities (Figure 1). In this paper, we make the following contributions:
• We present a new representation of 3D CAD models de-rived from B-reps, which captures geometric features from the parameter domain as a regular grid, and topological information as a graph.
• We propose a novel architecture which couples an im-age CNN and a hierarchical graph-neural network in a compute and memory-efﬁcient manner.
• We create and release a synthetic labeled dataset: SolidLet-ters, which unlike other synthetic datasets, is balanced, and has variations in both geometry and topology.
• We demonstrate the efﬁcacy of UV-Net on multiple tasks including 3D shape classiﬁcation, segmentation, and self-supervised shape retrieval on unlabeled data. We achieve state-of-the-art results on both classiﬁcation and segmen-tation tasks by leveraging the full B-rep data structure. 2.