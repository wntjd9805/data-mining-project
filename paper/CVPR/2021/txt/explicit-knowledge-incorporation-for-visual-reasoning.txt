Abstract
Existing explainable and explicit visual reasoning meth-ods only perform reasoning based on visual evidence but do not take into account knowledge beyond what is in the vi-sual scene. To addresses the knowledge gap between visual reasoning methods and the semantic complexity of real-world images, we present the ﬁrst explicit visual reasoning method that incorporates external knowledge and models high-order relational attention for improved generalizabil-ity and explainability. Speciﬁcally, we propose a knowledge incorporation network that explicitly creates and includes new graph nodes for entities and predicates from external knowledge bases to enrich the semantics of the scene graph used in explicit reasoning. We then create a novel Graph-Relate module to perform high-order relational attention on the enriched scene graph. By explicitly introducing struc-tured external knowledge and high-order relational atten-tion, our method demonstrates signiﬁcant generalizability and explainability over the state-of-the-art visual reasoning approaches on the GQA and VQAv2 datasets. 1.

Introduction
Visual question answering (VQA) aims to answer nat-ural language questions about a visual scene. It is a chal-lenging task requiring a deep understanding of both vision and language inputs, as well as knowledge to answer open-ended questions. While deep neural networks (DNNs) are extraordinarily powerful, most DNN-based VQA methods are black boxes driven by superﬁcial correlations between questions and answers [2]. These models are therefore lim-ited in making inferences or generalizations. They also fall short in explaining their decision-making process, espe-cially with complex questions requiring multiple reasoning steps to answer. The lack of generalizability or explainabil-ity in DNN models slows down their applications in many domains, such as healthcare, security, and ﬁnance.
Recent studies aim to address these problems by rep-∗These authors contributed equally.
Question:	Is	the	man	to	the right	of	the	hammer	wearing a	shirt? man suit hammer
Answer:	yes
External
Knowledge over shirt wearing suit under leftOf man on hammer rightOf
G - R e l a t e [ w e a r i n g ]
Figure 1. Explicit visual reasoning methods often fail when the observation does not provide sufﬁcient knowledge. Our method addresses this problem by generating scene graphs with explicit knowledge incorporation (e.g., suit-over-shirt) and inferring high-order relations (e.g., man-wearing-suit-over-shirt) with a novel
G-Relate neural module. resenting the visual information as a structured scene graph [24] or converting the question into a program of ex-ecutable neural modules [11, 12]. These explainable and explicit reasoning models have achieved remarkable perfor-mances on synthetic scenes and questions [14]. However, due to the complexity of real-world images and questions, they are still far from satisfactory when tested on more gen-eral VQA datasets [5, 13]. These data-driven methods de-pend on the accuracy and completeness of the detected ob-jects and their relations, and are ignorant of commonsense or other useful knowledge beyond visual observations. For example, as shown in Fig. 1, to answer the question “Is the man to the right of the hammer wearing a shirt?” visual reasoning models need to detect the shirt and attend to it if it exists. The reasoning task in this example is challenging as the shirt is undetectable from the scene. On the other hand, humans can easily integrate the observation that “the man is wearing a suit” and the commonsense knowledge that “suits are commonly dressed over shirts”, to infer the high-order relation between man and shirt. In this work, to achieve generalizability and explainability in visual reason-1356
ing, we propose an explainable and explicit visual reasoning method based on knowledge incorporation and high-order relational attention. It depicts two major advantages over existing approaches:
First, existing visual reasoning studies either implicitly embed external knowledge as language features [12, 24] or propagate information from external knowledge graphs into a scene graph with static topology [32], which is not able to address undetected objects or missing concepts from the visual scene. Differently, in this work, we explicitly incor-porate commonsense knowledge from an external knowl-edge graph into the scene graph by adding entities and pred-icates as new nodes. As shown in Fig. 1, with our proposed method, the external relations shirt-under-suit and suit-over-shirt can be added to the scene graph to enrich the scene graph. This enriched scene graph offers richer semantics enabling generalizable and explainable reasoning.
Second, existing methods depend on the detected binary relations but lack a mechanism to infer high-order relations between distant nodes in the scene graph. For example, as shown in Fig. 1, existing neural module networks can-not reason correctly with ﬁrst-order Relate modules, be-cause either no direct relations are detected between man and shirt or the question does not specify both (e.g., wearing and over) relations. We address this challenge by design-ing a novel Graph-Relate module that enables high-order relational reasoning. Despite there is no direct relation be-tween man and shirt, G-Relate can infer the probability of man-wearing-shirt based on the two direct relations man-wearing-suit and suit-over-shirt. This allows our model to ef-ﬁciently transfer attention to non-adjacent graph nodes and answer the question correctly.
We summarize the contributions of this work as follows: 1. We propose the ﬁrst explicit visual reasoning model that leverages external knowledge and neural modules to achieve generalizability and explainability. 2. We design a Knowledge Incorporation Network (KI-Net) that explicitly incorporates external knowledge as ad-ditional nodes and edges into a scene graph to provide rich semantics for reasoning. 3. We design a Graph-Relate module that achieves high-order relational attention based on the scene graph topology and semantics. 4. Our method outperforms state-of-the-art explicit rea-soning methods on the GQA [13] and VQAv2 [5] datasets, suggesting its superior generalizability and explainability. 2.