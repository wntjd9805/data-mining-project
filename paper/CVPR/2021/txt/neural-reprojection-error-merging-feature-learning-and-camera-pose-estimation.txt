Abstract
Absolute camera pose estimation is usually addressed by sequentially solving two distinct subproblems: First a fea-ture matching problem that seeks to establish putative 2D-3D correspondences, and then a Perspective-n-Point prob-lem that minimizes, w.r.t. the camera pose, the sum of so-called Reprojection Errors (RE). We argue that generating putative 2D-3D correspondences 1) leads to an important loss of information that needs to be compensated as far as possible, within RE, through the choice of a robust loss and the tuning of its hyperparameters and 2) may lead to an RE that conveys erroneous data to the pose estimator. In this paper, we introduce the Neural Reprojection Error (NRE) as a substitute for RE. NRE allows to rethink the camera pose estimation problem by merging it with the feature learning problem, hence leveraging richer information than 2D-3D correspondences and eliminating the need for choosing a robust loss and its hyperparameters. Thus NRE can be used as training loss to learn image descriptors tailored for pose estimation. We also propose a coarse-to-ﬁne optimization method able to very efﬁciently minimize a sum of NRE terms w.r.t. the camera pose. We experimentally demonstrate that
NRE is a good substitute for RE as it signiﬁcantly improves both the robustness and the accuracy of the camera pose es-timate while being computationally and memory highly efﬁ-cient. From a broader point of view, we believe this new way of merging deep learning and 3D geometry may be useful in other computer vision applications. Source code and model weights will be made available at hugogermain.com/nre. 1.

Introduction
Absolute camera pose estimation is a fundamental step to many computer vision applications, such as Structure-from-Motion (SfM) [19, 33, 34, 39] and visual localiza-tion [32, 37, 38]. Given a pre-acquired 3D model of the world, we aim at estimating the most accurate camera pose
Figure 1. Neural Reprojection Error (NRE) as a substitute for
Reprojection Error (RE): (a) Given a 3D point u, a query image
I and its ground truth camera pose, u can be reprojected into the image plane of I to obtain a 2D point ×. (b) RE takes as input a camera pose and a putative 2D-3D correspondence between u and a 2D location + in I, reprojects u to obtain a 2D point q, com-putes the euclidean distance between + and q and ﬁnally applies a robust loss function (shown in turquoise as a function of q). In ambiguous (middle) or multimodal (bottom) cases, generating a 2D-3D correspondence may lead to a loss function that conveys erroneous data to the pose estimator. (c) NRE does not rely on 2D-3D correspondences, thus + does not exist anymore. Instead,
NRE employs a dense loss map (shown in turquoise as a function of q) that contains much more information than RE, especially in ambiguous and multimodal cases. As a result, a pose estimator is signiﬁcantly more accurate and robust using NRE than RE. of an unseen query image. In practice, as illustrated on the left hand-side of Figure 2, this problem is often addressed by sequentially solving two distinct subproblems: First, a feature matching problem that seeks to establish putative 2D-3D correspondences between the 3D point cloud and the image to be localized, and then a Perspective-n-Point (PnP) problem that uses these correspondences as inputs to minimize a sum of so-called reprojection errors w.r.t. the camera pose. The Reprojection Error (RE) is a function of 414
a 2D-3D correspondence and the camera pose. It consists in reprojecting the 3D point, using the camera pose, into the query image plane, computing the euclidean distance between this reprojection and its putative 2D correspon-dent, and applying a robust loss function, such as Geman-McClure or Tukey’s biweight [3,47]. The robust loss allows to reduce the inﬂuence of outlier 2D-3D correspondences.
We argue that this strong decoupling of the matching stage from the PnP stage limits both the accuracy and the robustness of the camera pose estimate. Generating putative 2D-3D correspondences leads to an important loss of infor-mation since the 3D model and the query image are sum-marized into a set of 2D-3D coordinates. This loss of infor-mation needs to be compensated as far as possible within
RE through the choice of a robust loss and the tuning of its hyperparameters, which usually depend on both the vi-sual content and the amount of outliers generated by the matching stage. Moreover, outlier correspondences convey erroneous data to the pose estimator (see ﬁg. 1).
Contributions: (i) We propose the Neural Reprojection Error (NRE) as a substitute for RE. NRE does not require a 2D-3D correspon-dence as input but relies on a dense loss map. A dense loss map contains much more information than a simple 2D-3D correspondence and conveys data of higher quality to the pose estimator. As a result, the need for choosing a robust loss and its hyperparameters is also eliminated. Computing a dense loss map essentially involves cross-correlations be-tween descriptors that are extracted using a neural network, hence the name Neural Reprojection Error. (ii) Our derivation of NRE makes it differentiable not only w.r.t. to the camera pose but also w.r.t. the descriptors. Thus, providing ground-truth camera poses and minimizing NRE w.r.t. the descriptors yields a well-posed feature learning problem tailored for pose estimation. NRE merges the fea-ture learning problem and the camera pose estimation prob-lem in a new way and allows to rethink the recent end-to-end direct feature metric pose reﬁnement methods that need to consider two different losses. (iii) To estimate the camera pose efﬁciently, we propose to minimize a sum of NRE terms in a coarse-to-ﬁne manner.
As a result, we never compute or store any high-resolution dense loss map. We also describe how to perform the opti-mization using an M-estimator sample consensus approach followed by a graduated non-convexity procedure. We ex-perimentally demonstrate that our novel NRE-based pose estimator is a good substitute for RE-based pose estimators as it signiﬁcantly improves both the robustness and the ac-curacy of the camera pose estimate while being computa-tionally and memory highly efﬁcient.
In the remainder of the paper, after discussing the re-lated work, we introduce some notations and describe our method. We provide a detailed discussion to highlight the differences between NRE and existing approaches. We ﬁ-nally present our evaluation results. 2.