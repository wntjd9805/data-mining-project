Abstract
Previous top-performing approaches for point cloud in-stance segmentation involve a bottom-up strategy, which often includes inefﬁcient operations or complex pipelines, such as grouping over-segmented components, introducing additional steps for reﬁning, or designing complicated loss functions. The inevitable variation in the instance scales can lead bottom-up methods to become particularly sensi-tive to hyper-parameter values. To this end, we propose in-stead a dynamic, proposal-free, data-driven approach that generates the appropriate convolution kernels to apply in response to the nature of the instances. To make the ker-nels discriminative, we explore a large context by gather-ing homogeneous points that share identical semantic cat-egories and have close votes for the geometric centroids.
Instances are then decoded by several simple convolutional layers. Due to the limited receptive ﬁeld introduced by the sparse convolution, a small light-weight transformer is also devised to capture the long-range dependencies and high-level interactions among point samples. The proposed method achieves promising results on both ScanetNetV2 and S3DIS, and this performance is robust to the particular hyper-parameter values chosen. It also improves inference speed by more than 25% over the current state-of-the-art.
Code is available at: https://git.io/DyCo3D 1.

Introduction
Instance segmentation is signiﬁcantly more challenging than semantic segmentation because it requires identifying every individual instance of a class of objects, and the vis-ible extent of each. The information recovered has proven invaluable for scene understanding, however. With the in-creasing applications of 3D sensors (such as LiDAR and laser scanners), point clouds have become an important modality in scene understanding. Although signiﬁcant ad-vances have been made in instance segmentation in the im-age domain [15, 4, 3, 36], instance segmentation with the
*Corresponding author (e-mail: chunhua@icloud.com). s r u
O p u o r
G g n i o
P
R = 1cm
R = 2cm
R = 3cm
Figure 1 – A comparison of the instance segmentation results achieved using DyCo3D, and PointGroup [20]. Our method shows better robustness and generalization to the varying hyper-parameter values. Different instances are shown with random colors, and red ellipses highlight speciﬁc over-segmentation er-rors. Best viewed in color. 3D point clouds has proven far more challenging. This is partly due to the inherent irregularity and sparsity of the data, but also due to the diversity of the scene. By way of example, Mask R-CNN [15], which has shown great suc-cess when applied to 2D images, performs poorly when ap-plied in 3D [19].
Many previous top-performing approaches for point cloud instance segmentation adopt a bottom-up strategy, involving heuristic grouping algorithms or complex post-processing steps. 3D-MPA [11], for example, extracts pro-posals from the predicted instance centroids. Instances are then generated by aggregating proposal-wise embeddings.
PointGroup [20] generates instances proposals by gradu-ally merging neighbouring points that share the same cat-egory label. Both original and centroid-shifted points are explored with a manually speciﬁed search radius. A sep-arate model (labelled ScoreNet) is used to estimate the ob-jectness of the proposals. Both methods achieved promising performance on ScanNetV2 [7] and S3DIS [1] benchmarks.
However, these bottom-up methods often suffer from sev-eral drawbacks: (1) the performance is sensitive to values of the pre-deﬁned hyper-parameters, which require manual tuning. In PointGroup [20], modifying the clustering radius 354
from 3cm to 2cm causes mAP to drop by more than 6%, illustrating the method’s limited robustness and generaliza-tion ability. These results are presented in Fig. 1. (2) they incorporate either complex post-processing steps or train-ing pipelines, rendering them unsuitable for real-time ap-plications such as robotics and driverless cars. For exam-ple, 3D-MPA [11] needs an extra 10-layer graph network and a clustering post-processing step to yield its ﬁnal in-stance segmentation masks. (3) they are heavily reliant on the quality of the proposals, which limits their robustness and can lead to joint/fragmented instances in practice.
In this paper, we propose a novel pipeline tailored to 3D point cloud instance segmentation using dynamic convolu-tion, that we label DyCo3D. Our approach addresses the task with only a few convolution layers, for which the ﬁl-ters are generated on the ﬂy, conditioned on the category and position of the instance to be decoded. To empower the ﬁlters to distinguish different instances, we propose to encode category-speciﬁc context by deploying a light-weight sub-network to explore homogenous points that have close votes for instance centroids and share the semantic labels. Instance masks can be decoded in parallel by con-volving the generated class-speciﬁc ﬁlters with the position embedded features. Compared with bottom-up approaches
[20, 11, 39, 38, 17] that are sensitive to the values of numer-ous hyper-parameters, our approach demonstrates superior-ity on both effectiveness and efﬁciency. Qualitative results illustrating this fact are presented in Fig. 1.
Besides, as has been proved in the 2D image domain, a large receptive ﬁeld and rich context information are critical to the success of instance segmentation [5]. To address the problem in the 3D point cloud, we propose to introduce a small transformer [37] to capture a long-range dependency and build high-level interactions among different regions.
Our contributions are summarised as the following:
• A novel method for 3D point cloud instance segmen-tation based on dynamic convolution that outperforms previous methods in both efﬁciency and effectiveness.
• A proposal-free instance segmentation approach that is more robust than bottom-up strategies.
• A light-weight transformer that enlarges the receptive
ﬁeld and captures non-local dependencies.
• Comprehensive experiments demonstrating that the proposed method achieves state-of-the-art results, with improved robustness, and an inference speed superior to that of its comparators. 2.