Abstract
Gait is considered an attractive biometric identiﬁer for its non-invasive and non-cooperative features compared with other biometric identiﬁers such as ﬁngerprint and iris. At present, cross-view gait recognition methods always establish representations from various deep convolutional networks for recognition and ignore the potential dynamical information of the gait sequences. If assuming that pedes-trians have different walking patterns, gait recognition can be performed by calculating their dynamical features from each view. This paper introduces the Koopman operator theory to gait recognition, which can ﬁnd an embedding s-pace for a global linear approximation of a nonlinear dy-namical system. Furthermore, a novel framework based on convolutional variational autoencoder and deep Koopman embedding is proposed to approximate the Koopman op-erators, which is used as dynamical features from the lin-earized embedding space for cross-view gait recognition. It gives solid physical interpretability for a gait recognition system. Experiments on a large public dataset, OU-MVLP, prove the effectiveness of the proposed method. 1.

Introduction
Gait recognition aims to identify people by recognizing their body shape and walking patterns. Compared to other biometrics such as ﬁngerprint or iris, gait requires relatively low cooperation and can be performed at a longer distance.
Besides, it is also difﬁcult to camouﬂage. Therefore, gait recognition can be applied in some special senses such as criminal investigation [28].
Although the progress is encouraging, gait recognition still suffers from many external factors such as carrying condition, varying pace, clothing, and camera viewpoints, which degrade the performance of gait recognition system-s. Among all these unfavorable factors, camera viewpoints could be the most tricky one [43]. Prior arts proved that the
∗Corresponding author.
Figure 1. Previous works focus on feature fusion of gait silhouette sequences and search for discriminative space where distance is small for the feature pair with the same identity (a). We calcu-late dynamical features in the Koopman space where gait images evolve linearly (b), and then we recognize them from their dynam-ical features. performance of a single-view gait recognition system would drop drastically if the viewpoint is changed [43, 34].
To solve these problems, many deep learning model-s have been proposed for cross-view gait recognition and achieved great performances. In general, such approaches can be grouped into two categories, i.e. appearance-based approaches and model-based approaches, respectively. The former [43, 5, 33, 50, 45] is mainstream for gait recognition in the past few years. These methods extract features from gait silhouette images and optimize the intra-individual dis-tance in the feature space by metric learning loss functions without gait cycle modeling. In addition, temporal fusion units [6, 9, 44, 5, 8, 23] and part-division units [17, 5, 8, 50] are proposed to combine features of silhouette sequences and local parts.
The model-based gait recognition [2, 22, 24] focus on re-constructing body structures from gait sequences in a math-ematical manner. A three-dimensional model conveys more information than a two-dimensional one and can be con-9095
structed to represent the gait pattern. Therefore, it can achieve acceptable performance against viewpoints varia-tion in theory. This point is also supported by some biome-chanical gait analysis [14, 15]. However, the performances of such approaches are vulnerable to the accuracy of pose estimation and the quality of silhouette sequences, which limited their development.
In general, appearance-based methods are good at fea-ture representation but suffer from insufﬁcient data, while model-based approaches are more robust to view differ-ences but challenging to construct. Although deep con-volutional neural networks (ConvNets) can provide a ro-bust feature extractor and achieve excellent performance in controlled scenarios, exiting models still cannot deal with large view differences or variations of clothing and article-carrying very well. Because, in essence, ConvNet is still a two-dimensional template, and the human body is a three-dimensional object. It is not surprising that even having the exact person’s data, the model still cannot deal with his/her 2D projections that are not included in the training set. This issue is also known as the ill-posed problem of computer vision.
Inspired by works on inertial sensor-based gait analy-sis [29, 4], biomechanical gait analysis [14] and dynamical analysis of human gait [3], we realize that dynamical fea-tures are competitive in gait recognition since it models the essence of human gait, the motion process, rather than pure human shapes. Therefore, different from most existing deep learning methods, we explore cross-view gait recognition from a dynamical system perspective. More speciﬁcally, we introduce the Koopman theory, which is a popular tool for analyzing nonlinear systems in the literature of ﬂuid me-chanics [31, 42]. In fact, the Koopman theory has been al-ready applied to computer vision as video background sepa-rations [10], image spooﬁng [37], and motion detection [7].
As for gait recognition, the most relevant work is by Wang et al. [39], in which windowed-dynamic mode decomposi-tion is applied for generating gait energy images. However, only the static gait feature is investigated in their work.
As shown in Figure 1, the Koopman theory focuses on the systematic linear representation of nonlinear systems, which provides a new way of representing the walk cycles of gait. We propose a novel framework for cross-view gait recognition by approximating Koopman operator (see Fig-ure 2). First, aligned silhouettes are fed into a convolutional variational auto-encoder (VAE) for image-level encoding.
Then, we enforce additional constraints and loss function-s [26] to identify Koopman operators where the dynamics evolve linearly following. Finally, a fully-connected net-work is trained for ﬁnal gait representation from the Koop-man matrix.
In summary, we make the following three major contri-butions.
• We introduce the Koopman theory to dynamic feature extraction from gait silhouettes. To our knowledge, this is the ﬁrst study to apply Koopman analysis.
• We propose a novel framework for cross-view gait recognition by integrating convolutional variational autoencoder and deep Koopman embedding.
• We conduct experiments on a widely used large gait database, OU-MVLP [36]. The results prove the ef-fectiveness of our method, which makes an essential contribution to understanding the connections between gait recognition and human walking dynamics. 2.