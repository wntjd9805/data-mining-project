Abstract
Robust model ﬁtting is a core algorithm in a large num-ber of computer vision applications. Solving this prob-lem efﬁciently for datasets highly contaminated with out-liers is, however, still challenging due to the underlying computational complexity. Recent literature has focused on learning-based algorithms. However, most approaches are supervised (which require a large amount of labelled training data). In this paper, we introduce a novel unsuper-vised learning framework that learns to directly solve robust model ﬁtting. Unlike other methods, our work is agnostic to the underlying input features, and can be easily gener-alized to a wide variety of LP-type problems with quasi-convex residuals. We empirically show that our method out-performs existing unsupervised learning approaches, and achieves competitive results compared to traditional meth-ods on several important computer vision problems1. 1.

Introduction
Many computer vision applications require the estima-tion of a model from a set of observations [14]. In outlier-free settings, ﬁtting a geometric model to a dataset can be performed relatively easily by, for example, solving a least squares problem. However, in the presence of outliers in the data, a robust estimator [11, 15] must be employed to ensure the stable performance of any algorithm. As an example, consider SLAM [24], which is now a fundamental building block in several robotic or autonomous driving pipelines. It requires multiple estimations of the fundamental/essential matrices (between the consecutive views, captured along the camera trajectory). In many circumstances, erroneous correspondences between the frames could lead to incor-rect camera pose estimation. Consequently, if the outliers are not removed, the whole tracking trajectory could be severely affected. Therefore, it is desirable to design ro-1Code is available at: https://github.com/hagianga21/
MaxCon_RL 87 51 18 18 50 51 51 87 96 50 51 96 2 51 66 51 66 87 51 66 50 51 66 2 51 96 51 96 2 51 66 2 50 51 2 18 51 2 2 17 51 93
A* method:
[87, 18, 96, 50, 66, 93] 87 51 18 51 87 96 51 66 87 2 50 51 51 87 93 18 51 93
Our method:
[18, 96, 66, 50, 87, 93]
Figure 1: Illustration of the solutions found by our unsu-pervised learning method (right) and a globally optimal al-gorithm [4] (left). The number shows the speciﬁc index of points in the point set. The admissible heuristic in A* method brings the search into some fruitless subparts (green line) before discovering optimal solution (red line). Our agent learns to remove outliers by traversing from the ini-tial state to the goal state in the minimal number of steps (the states are numbered based on the index of the removed point). Observe that both methods terminate at the same solution (i.e., both remove the same set of outliers). bust ﬁtting algorithms that are highly accurate and able to achieve real-time performance. This is a challenging task, as solving robust ﬁtting optimally has been shown to be NP-hard [3, 5].
In addition to popular methods such as Random Sam-ple Consensus (RANSAC) [11] and a number of ran-domized or deterministic variants [7, 6, 21, 17, 2, 4, 1], the advent of deep learning in recent years has inspired research in learning-based approaches for robust estima-tion [30, 31, 23, 28, 8, 19]. The main idea behind these tech-niques is to exploit the learning capabilities of deep Con-volutional Neural Networks (CNNs) to directly regress the robust estimates [19, 8], or quickly identify the outliers [23]
These approaches have demonstrated their superior perfor-mance on many datasets, and hence, developing learning-based robust estimators can be a promising research direc-tion. However, most learning techniques mentioned above 10348
are supervised, hence they typically require a large amount of labelled data. This potential bottleneck could be resolved by either generating ground truth data automatically: by us-ing synthetic data, or by using conventional methods (e.g.
RANSAC) to generate ground truth. However, these ”quick
ﬁxes” have their own drawbacks. Speciﬁcally, a network fully trained on synthetic data may not be able to generalize well to real world scenarios since it has not been exposed to real examples during training. Similarly, ground truth ob-tained from classic conventional methods is not guaranteed to be the gold standard as the obtained solutions may be in-correct. One could, on the other hand, employ some global consensus maximization methods [4] to generate the ground truth, but this would be at the cost of an exceptionally slow training process. Moreover, some methods are problem-speciﬁc, and it is non-trivial to extend them to other robust
ﬁtting tasks.
We address these problems and present a novel unsuper-vised learning framework for robust ﬁtting. Inspired by the success of Reinforcement Learning (RL) in several unsu-pervised tasks [22, 32], we cast our robust ﬁtting problem as a special case of goal oriented learning. Such a transfor-mation is achieved thanks to the underlying tree structure of consensus maximization [4, 18, 1]. Moreover, we also propose a novel architecture that efﬁciently captures the in-stantaneous state of the data during transition. Fig. 1 shows an example of a 2D line ﬁtting problem, where we plot the trajectory of A* [4] (a globally optimal algorithm), and the path traversed by our agent from the initial state to the goal state. Observe that both remove the same set of outliers, which demonstrates the learning capability of our network to effectively explore the environment. Furthermore, in con-trast to the implementation of A*, which explores redundant bases before reaching the optimal, our network can quickly identify the shortest path to reach the goal state, resulting in signiﬁcantly faster run times. (see Section. 3 for more de-tail.) To the best of our knowledge, our work is the ﬁrst to learn a deep architecture model in a reinforcement learning paradigm for consensus maximization in computer vision.
Contributions The main contributions of our paper can be summarized as follows:
• We propose a novel unsupervised learning framework for robust estimation. By exploiting the special struc-ture (see Section. 3) of the problem under the consen-sus maximization formulation, we incorporate robust model ﬁtting into the well-known goal-oriented rein-forcement learning framework, resulting in an efﬁcient learning mechanism without any supervision.
• We develop a new state embedding scheme based on a graph convolutional network, and an efﬁcient back-bone network that allows our agent to effectively ex-plore the action space to achieve the goal state. (see
Section. 3.3 and Section. 3.4) 1.1.