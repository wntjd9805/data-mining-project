Abstract
Sufﬁcient real information in generator is a critical point for the generation ability of GAN. However, GAN and its variants suffer from lack of this point, resulting in brit-In this paper, we propose a novel tle training processes. variant of GAN, Posterior Promoted GAN (P2GAN), which promotes generator with the real information in the poste-rior distribution produced by discriminator. In our frame-work, different from other variants of GAN, the discrimi-nator maps images to a multivariate Gaussian distribution and extracts real information. The generator employs the real information by AdaIN and a latent code regularizer.
Besides, reparameterization trick and pretraining is applied to guarantee a stable training process in practice. The con-vergence of P2GAN is theoretically proved. Experimental results on typical high-dimensional multi-modal datasets demonstrate that P2GAN has achieved comparable results with the state-of-the-art variants of GAN on unsupervised image synthesis. 1.

Introduction
Generative Adversarial Network (GAN) [13] has been widely developed since it was proposed, and its variants have made remarkable progresses in the ﬁeld of image synthesis. Sufﬁcient real information in generator is the key point for such models. The only real information contributing to generator in original GAN is the gradient transferred from discriminator, which is indirect and je-june for generator, leading to brittle training. Some su-pervised variants of GAN [32, 34, 8, 26, 12] use the at-tributes like labels in a direct and strong way with some con-straints on the attributes, which supplies sufﬁcient real in-formation to generator. For unsupervised variants of GAN, there are two major ways to improve the real information
∗Corresponding author. in generator. One approach is to provide more reﬁned gradient from discriminator by introducing new loss func-tions [15, 3, 31, 11, 46, 41]. But the information from gra-dient is still indirect and frangible, which cannot supply a continuous support for generator. The other approach is to enrich the real information by adding priors into input noise [4, 6, 10, 40, 47, 25, 44, 9, 28]. Nevertheless, the real information in prior is only added into input noise, which may be decayed by stacking convolutional layers gradually.
To tackle the above lack of real information issue, in this paper, we propose a novel framework of GAN called
Posterior Promoted GAN (P2GAN). Firstly, unlike tradi-tional discriminator that cannot provide sufﬁcient real in-formation, P2GAN learns abundant real information in the posterior distribution by discriminator, and applies the in-formation to generator in a more straight and robust way.
In speciﬁc, our discriminator maps images to a multivari-ate Gaussian distribution, and matches this distribution with two different given prior distributions for distinguishing.
The discriminator structure is inspired by the encoder of
Variational Autoencoder (VAE) [23]. Secondly, unlike pre-vious works [4, 6, 10, 40, 47, 25, 44, 9, 28] which apply a prior distribution to the input noise, our generator is pro-moted by introducing the external real information into each convolutional layer via Adaptive Instance Normalization (AdaIN) [18] and a latent code regularizer. Directly affect-ing the features in convolutional layers by AdaIN is more powerful than only changing the prior of the input noise.
Thirdly, we change the losses of Least Squares Generative
Adversarial Network (LSGAN) [31] to a distribution ver-sion, and provide theoretical guarantees for its convergence.
Besides, we employ reparameterization trick for reasonably calculating the losses at the implementation level and a pre-training step for initialization.
Our contributions are summarized as follows. First, we propose a novel GAN framework called P2GAN. The dis-criminator outputs a posterior distribution for distinguish-6519
ing real and fake, and extracts plentiful real information in the meantime. The generator utilizes the real information via AdaIN layers to promote its generation ability. Second, we modify the losses of LSGAN to a distribution version, and theoretically prove its convergence via the Pearson X divergence. Third, we propose a new latent code regular-izer as a robust constraint of generator, which can prevent the abundant real information in the posterior distribution from fading away during training. Fourth, we introduce two methods to guarantee model stability in practice: the repa-rameterization trick training and the pretraining step. Our model produces a state-of-the-art performance on multiple image datasets in a fully unsupervised way. 2.