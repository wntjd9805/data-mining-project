Abstract
Few-shot learning aims to correctly recognize query samples from unseen classes given a limited number of sup-port samples, often by relying on global embeddings of im-ages. In this paper, we propose to equip the backbone net-work with an attention agent, which is trained by reinforce-ment learning. The policy gradient algorithm is employed to train the agent towards adaptively localizing the repre-sentative regions on feature maps over time. We further de-sign a reward function based on the prediction of the held-out data, thus helping the attention mechanism to general-ize better across the unseen classes. The extensive experi-ments show, with the help of the reinforced attention, that our embedding network has the capability to progressively generate a more discriminative representation in few-shot learning. Moreover, experiments on the task of image clas-siﬁcation also show the effectiveness of the proposed design.
Figure 1. Few-shot learning processes. (a) Vanilla few-shot learn-ing. (b) Few-shot learning with RAP. The learning process has been formulated as a Markov Decision Process (MDP). 1.

Introduction
The success of deep learning models rely heavily on a signiﬁcant amount of labeled data, but the availability of large datasets is still limited due to the labor-intensive data preparation, which motivates the signiﬁcant interest in few-shot learning [22, 40, 49, 11, 51, 47, 45]. Few-shot learning aims to enable the model to classify unlabeled query ex-amples of unseen classes, utilizing a very small number of labeled support examples. One prominent category of meth-ods is the model-initialization based approach [40, 11, 47].
It temporarily updates the model parameter using support examples via gradient descent steps for the training tasks, and seeks a representation that generalizes well in the test-ing phase. Another line of work, the metric-learning based methods [22, 49, 51], is based on the complex manipulation of global embeddings learned by the backbone network.
*corresponding author
Even though the traditional approaches work well for the task of few-shot learning, they are likely to ignore the spa-tial information encoded within feature maps, which make the model very sensitive to the background clutter on image examples [62]. To fully make use of the available spatial information, attention-oriented designs are recently devel-oped for few-shot learning [53, 55, 7, 62, 42, 16, 9]. Us-ing word embeddings as auxiliary data, semantics-guided attention modules are proposed to capture the relevant vi-sual features among query samples [55, 7, 62]. In addition to the semantics-guided attention, the sample-guided atten-tion designs are able to further explore the feature relevance between support samples and query samples [53, 42, 16].
While these attention models effectively make class features more representative, they tend to focus too much on design-ing a complex meta-learner.
In order to address the aforementioned weakness, in this work, we propose a reinforced-attention policy (RAP) 913
learning, an attention mechanism model for few-shot trained by reinforcement learning. Speciﬁcally, an auxiliary agent is designed to equip the backbone network for com-puting a series of attention maps which recurrently decide where to enforce or ignore over the feature maps.
Our designed RAP enables the backbone network to identify informative parts of the feature maps of an exam-ple, and thus make generated embeddings more discrimina-tive for the few-shot meta-learner. We formulate the fea-ture extraction of examples as a Markov Decision Process (MDP) and optimize RAP in a reinforcement learning set-ting. Given example images, the agent which progressively reﬁnes the attention upon feature maps over time is opti-mized according to the online feedback, i.e., the computed reward. The speciﬁc reward function which incorporates the performance of the meta-learner on the held-out data is designed to guide the agent towards being more generic.
More details are speciﬁed in Fig. 1. As illustrated in Fig. 1 (a), the vanilla few-shot learning process can be viewed the feature extractor, i.e. as a two-component paradigm: the backbone network and the meta-learner. Given several query examples Xq = {Xq,1, Xq,2, ..., Xq,i, ...} and support examples Xs = {Xs,1, Xs,2, ..., Xs,j, ...} with labels Ys =
{Ys,1, Ys,2, ..., Ys,j, ...}, the meta-learner works as a classi-ﬁer to identify the category ˆYq = { ˆYq,1, ˆYq,2, ..., ˆYq,i, ...} of query examples based on embedding features, eq =
{eq,1, eq,2, ..., eq,i, ...} and es = {es,1, es,2, ..., es,j, ...}, computed by the backbone network. How RAP works on a few-shot learning task is further shown in Fig. 1 (b). Using
RAP to equip the backbone network, we convert the few-shot learning into a MDP. The policy module continuously receives the reward rt as feedback from the meta-learner and gives the action at towards the larger total reward. The embedding eT from the last time step T is viewed as the resulting embedding. Hence, instead of ˆYq, we take ˆYq,T as the ﬁnal prediction. The modiﬁcation to only the backbone network makes RAP skip the further design of the meta-learner, such that RAP is able to be embedded in most ex-isting few-shot learning baselines.
The contributions of this work can be summarized as fol-lows: i) Our proposed RAP is capable of attending to in-formative regions of feature maps while avoiding the ex-tra cumbersome meta-learner design. Additionally, most of the few-shot learning baselines can be equipped with
RAP, since RAP is essentially a ﬂexible extension speciﬁc to the backbone network. ii) We provide a novel solution to train the attention mechanism by using reinforcement learn-ing. Intuitively, the recurrent formulation in a reinforcement learning manner can help the attention mechanism to incre-mentally locate useful parts of the features due to the char-acteristic that reinforcement learning is able to substantially learn from experience.
In the experimental part of our few-shot learning, we se-lect several baselines for which RAP agents are trained. In effect, our embedded design pushes the backbone network to produce embeddings which become more discriminative.
Aside from few-shot learning, our design is applicable to image classiﬁcation. The effectiveness is demonstrated via experiments on multiple benchmark datasets. 2.