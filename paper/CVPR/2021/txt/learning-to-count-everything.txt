Abstract
Existing works on visual counting primarily focus on one speciﬁc category at a time, such as people, animals, and cells.
In this paper, we are interested in counting every-thing, that is to count objects from any category given only a few annotated instances from that category. To this end, we pose counting as a few-shot regression task. To tackle this task, we present a novel method that takes a query image together with a few exemplar objects from the query image and predicts a density map for the presence of all objects of interest in the query image. We also present a novel adapta-tion strategy to adapt our network to any novel visual cate-gory at test time, using only a few exemplar objects from the novel category. We also introduce a dataset of 147 object categories containing over 6000 images that are suitable for the few-shot counting task. The images are annotated with two types of annotation, dots and bounding boxes, and they can be used for developing few-shot counting models.
Experiments on this dataset shows that our method outper-forms several state-of-the-art object detectors and few-shot counting approaches. Our code and dataset can be found at https://github.com/cvlab- stonybrook/
LearningToCountEverything. 1.

Introduction
Humans can count objects from most of the visual object categories with ease, while current state-of-the-art compu-tational methods [29, 48, 55] for counting can only handle a limited number of visual categories. In fact, most of the counting neural networks [4, 48] can handle a single cate-gory at a time, such as people, cars, and cells.
There are two major challenges preventing the Com-puter Vision community from designing systems capable of counting a large number of visual categories. First, most of the contemporary counting approaches [4, 48, 55] treat counting as a supervised regression task, requiring thou-sands of labeled images to learn a fully convolutional re-gressor that maps an input image to its corresponding den-sity map, from which the estimated count is obtained by summing all the density values. These networks require dot
Figure 1: Few-shot counting—the objective of our work.
Given an image from a novel class and a few exemplar ob-jects from the same image delineated by bounding boxes, the objective is to count the total number of objects of the novel class in the image. annotations for millions of objects on several thousands of training images, and obtaining this type of annotation is a costly and laborious process. As a result, it is difﬁcult to scale these contemporary counting approaches to handle a large number of visual categories. Second, there are not any large enough unconstrained counting datasets with many visual categories for the development of a general count-ing method. Most of the popular counting datasets [14– 16, 43, 49, 55] consist of a single object category.
In this work, we address both of the above challenges. To handle the ﬁrst challenge, we take a detour from the existing counting approaches which treat counting as a typical fully supervised regression task, and pose counting as a few shot regression task, as shown in Fig. 1. In this few-shot setting, the inputs for the counting task are an image and few exam-ples from the same image for the object of interest, and the output is the count of object instances. The examples are provided in the form of bounding boxes around the objects of interest. In other words, our few shot counting task deals with counting instances within an image which are simi-lar to the exemplars from the same image. Following the convention from the few-shot classiﬁcation task [9, 20, 46], the classes at test time are completely different from the ones seen during training. This makes few-shot counting very different from the typical counting task, where the training and test classes are the same. Unlike the typical counting task, where hundreds [55] or thousands [16] of la-beled examples are available for training, a few-shot count-ing method needs to generalize to completely novel classes 3394
using only the input image and a few exemplars.
We propose a novel architecture called Few Shot
Adaptation and Matching Network (FamNet) for tackling the few-shot counting task. FamNet has two key compo-nents: 1) a feature extraction module, and 2) a density pre-diction module. The feature extraction module consists of a general feature extractor capable of handling a large num-ber of visual categories. The density prediction module is designed to be agnostic to the visual category. As will be seen in our experiments, both the feature extractor and density prediction modules can already generalize to the novel categories at test time. We further improve the per-formance of FamNet by developing a novel few-shot adap-tation scheme at test time. This adaptation scheme uses the provided exemplars themselves and adapts the counting net-work to them with a few gradient descent updates, where the gradients are computed based on two loss functions which are designed to utilize the locations of the exemplars to the fullest extent. Empirically, this adaptation scheme improves the performance of FamNet.
Finally, to address the lack of a dataset for develop-ing and evaluating the performance of few-shot counting methods, we introduce a medium-scale dataset consisting of more than 6000 images from 147 visual categories. The dataset comes with dot and bounding box annotations, and is suitable for the few-shot counting task. We name this dataset Few-Shot Counting-147 (FSC-147).
In short, the main contributions of our work are as fol-lows. First, we pose counting as a few-shot regression task.
Second, we propose a novel architecture called FamNet for handling the few-shot counting task, with a novel few-shot adaptation scheme at test time. Third, we present a novel few-shot counting dataset called FSC-147, comprising of over 6000 images with 147 visual categories. 2.