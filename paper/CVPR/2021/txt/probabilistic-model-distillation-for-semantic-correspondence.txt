Abstract
Semantic correspondence is a fundamental problem in computer vision, which aims at establishing dense corre-spondences across images depicting different instances un-der the same category. This task is challenging due to large intra-class variations and a severe lack of ground truth. A popular solution is to learn correspondences from synthetic data. However, because of the limited intra-class appearance and background variations within syn-thetically generated training data, the model‚Äôs capability for handling ‚Äúreal‚Äù image pairs using such strategy is in-trinsically constrained. We address this problem with the use of a novel Probabilistic Model Distillation (PMD) ap-proach which transfers knowledge learned by a probabilis-tic teacher model on synthetic data to a static student model with the use of unlabeled real image pairs. A probabilis-tic supervision reweighting (PSR) module together with a conÔ¨Ådence-aware loss (CAL) is used to mine the useful knowledge and alleviate the impact of errors. Experimen-tal results on a variety of benchmarks show that our PMD achieves state-of-the-art performance. To demonstrate the generalizability of our approach, we extend PMD to incor-porate stronger supervision for better accuracy ‚Äì the prob-abilistic teacher is trained with stronger key-point super-vision. Again, we observe the superiority of our PMD.
The extensive experiments verify that PMD is able to in-fer more reliable supervision signals from the probabilistic teacher for representation learning and largely alleviate the inÔ¨Çuence of errors in pseudo labels. Code is available at https://github.com/fanyang587/PMD. 1.

Introduction
Matching all pixels between images is a classic research problem in computer vision. Unlike stereo matching [62] or optical Ô¨Çow [3] that deal with images containing different viewpoints of one scene or object, semantic correspondence poses additional challenges by pushing the boundaries of dense matching to correspondence estimation between visu-ally similar images. Matching beyond scene leads to many
‚àóCorresponding author: Fan Yang (fanyang uestc@hotmail.com) (a)
Input (b)
Input (c)
Input
Model A
Model B
Model C
Ensemble
Student model
Predict
Transform A
Model  
Transform B
Model 
Ensemble
Transform C
Model 
Student model
Predict
Probabilistic model 
ùìù ùõç, ùõî
Student model
Sample A
Sample B
Hypotheses 
Sample C
ùìù_e ùüé, ùö∫ errors n o i s i v r e p u
S g n i t h g i e w e r
Predict
Figure 1. Idea Illustration. Instead of (a) ensembling multiple models to generate ‚Äúsoft‚Äù predictions as the student‚Äôs target [22], or (b) creating a single ‚Äúhard‚Äù label from different transforma-tions [54], (c) our idea is to distill knowledge from hypotheses from a probabilistic teacher model in a probabilistic manner. meaningful applications, such as attribute transfer [34, 44], image editing [2, 17, 40], scene collaging [27], object dis-covery and segmentation [43, 59]. This task is extremely challenging due to large intra-class variation and a severe lack of groundtruth correspondence maps.
One way to overcome these challenges is to use hand-crafted image descriptors (e.g., SIFT [50], HOG [9],
DAISY [67]) in combination with different regularization methods [18,31,45‚Äì47,53,61,66] to estimate semantic cor-respondence. Unfortunately, hand-crafted descriptors are intrinsically weak in capturing high-level semantics and thus, less robust to large intra-class variation, geometric deformation and background clutter. Inspired by the suc-cess of self-supervised deep learning models, a series of approaches have been proposed to learn semantic descrip-tors [63], or directly regress parameters of a global trans-7505  
formation model [55, 64], by using synthetically gener-ated data. Although these approaches achieve state-of-the-art performances, using synthetic data could weaken the model‚Äôs ability to deal with complex intra-class and back-ground variations for real pairs due to limited appearance variation in synthetic training pairs. To alleviate this prob-lem, recent approaches use different types of auxiliary an-notations (e.g., key points [5, 6, 8, 29, 37, 42], semantic masks [7, 39], 3D CAD model [68, 70], and image-level la-bels [26, 32, 56, 57]) as supervision signals for model train-ing on real pairs. However, auxiliary annotations not only are labor-intensive to collect, but also could weaken the generalization ability of the learned network models. The observations above inspire us to wonder: Can the knowl-edge learned from synthetic data be generalized and even enhanced to deal with real image pairs without using any manual annotation?
To answer this question, as shown in Figure 1, we pro-pose to perform knowledge distillation within a probabilis-tic teacher-student (PTS) framework. Our idea is to gen-erate pseudo semantic Ô¨Çows on unlabeled real pairs us-ing a teacher model trained on synthetic data, and then train the student model using the pseudo-groundtruth Ô¨Çows.
However, training the student model on the predictions by a single static teacher model would inevitably encode noisy, biased information, which causes the student to be upper-bounded by its teacher model. To address this problem, we employ a probabilistic teacher model to pro-vide multiple/diverse matching hypotheses for each real pair, and use a student model working with a probabilis-tic supervision reweighting (PSR) module to distill ‚Äòcorrect‚Äô (pixel-wise) supervision signals from pseudo correspon-dence maps. Moreover, a conÔ¨Ådence-aware loss (CAL) is introduced to further reduce the impact of errors on pseudo
Ô¨Çows during knowledge distillation.
Our approach, called Probabilistic Model Distillation (PMD), can successfully distill the knowledge from hy-potheses of the probabilistic teacher model trained on syn-thetic data, and safely generalize it into a powerful stu-dent model with potentially unlimited real-world image pairs in an unsupervised manner. We demonstrate that the model trained with our probabilistic model distilla-tion produces better results than all state-of-the-art (SOTA) self-supervised approaches, even those utilizing (auxiliary) manual annotations.
To further demonstrate the advantage and generalizabil-ity of our approach, we extend it to incorporate stronger supervision ‚Äì the probabilistic teacher is trained using the (auxiliary) matched key points. Surprisingly, even with the same training set, the student model outperforms the teacher by a large margin and sets new records on multiple bench-marks. The contributions of this work are summarized as:
‚Ä¢ A novel probabilistic approach for model distilla-tion. To our best knowledge, this is the Ô¨Årst attempt to distill knowledge from multiple/diverse hypotheses produced by a probabilistic teacher model for self-supervised/unsupervised model learning. This approach is able to generalize the knowledge learned from syn-thetic data into a new model for better handling real-world data.
‚Ä¢ A new probabilistic teacher-student network for se-mantic correspondence. We present the probabilistic teacher-student network, an effective instantiation of our probabilistic model distillation for semantic correspon-dences, which consists of a probabilistic teacher model learning knowledge from synthetic data, and a static stu-dent model working with a novel probabilistic supervi-sion reweighting (PSR) module to perform distillation from multiple hypotheses of each real image pair.
‚Ä¢ State-of-the-art results on widely-used benchmarks.
The model trained with our probabilistic model distilla-tion outperforms state-of-the-art methods on a variety of benchmarks, e.g., PF-WILLOW, PF-PASCAL and SPair-71k . Our method even surpasses approaches that require extra (auxiliary) annotations for model learning.
‚Ä¢ Potential generalizability to stronger supervision. We show that our approach can be extended to incorporate stronger supervision signals for better accuracy. With the strongly supervised teacher model, the student model can achieve better performance, outperforming existing state-of-the-art methods with different degrees of supervision. 2.