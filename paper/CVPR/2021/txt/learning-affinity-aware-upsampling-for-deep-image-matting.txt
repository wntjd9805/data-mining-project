Abstract
We show that learning afﬁnity in upsampling provides an effective and efﬁcient approach to exploit pairwise inter-actions in deep networks. Second-order features are com-monly used in dense prediction to build adjacent relations with a learnable module after upsampling such as non-local blocks. Since upsampling is essential, learning afﬁnity in upsampling can avoid additional propagation layers, offer-ing the potential for building compact models. By looking at existing upsampling operators from a uniﬁed mathematical perspective, we generalize them into a second-order form and introduce Afﬁnity-Aware Upsampling (A2U) where up-sampling kernels are generated using a light-weight low-rank bilinear model and are conditioned on second-order features. Our upsampling operator can also be extended to downsampling. We discuss alternative implementations of A2U and verify their effectiveness on two detail-sensitive tasks: image reconstruction on a toy dataset; and a large-scale image matting task where afﬁnity-based ideas con-stitute mainstream matting approaches. In particular, re-sults on the Composition-1k matting dataset show that A2U achieves a 14% relative improvement in the SAD metric against a strong baseline with negligible increase of param-eters (< 0.5%). Compared with the state-of-the-art matting network, we achieve 8% higher performance with only 40% model complexity. 1.

Introduction
The similarity among positions, a.k.a. afﬁnity, is com-monly investigated in dense prediction tasks [22, 4, 8, 36, 20]. Compared with directly ﬁtting ground truths using
ﬁrst-order features, modeling similarity among different po-sitions can provide second-order information. There cur-rently exist two solutions to learn afﬁnity in deep networks: i) learning an afﬁnity map before a non-deep backend and ii) deﬁning a learnable afﬁnity-based module to propagate in-formation. We are interested in end-to-end afﬁnity learning,
∗HL’s contribution was made when he was with The University of Ade-laide. YD and HL contributed equally. Correspondence should be ad-dressed to CS (email: chunhua@icloud.com).
Figure 1 – Visualization of upsampled feature maps with various upsampling operators. From left to right, the input RGB image, feature maps after the last upsampling using nearest neighbor in-terpolation, bilinear upsampling, and our proposed afﬁnity-aware upsampling, respectively. Our method produces better details with clear connectivity. because classic methods often build upon some assump-tions, rendering weak generalization in general cases. Ex-isting approaches typically propagate or model afﬁnity after upsampling layers or before the last prediction layer. While afﬁnity properties are modeled, they sometimes may not be effective for the downstream tasks. For instance,the work in
[20] requires a feature encoding block besides the encoder-decoder architecture to learn afﬁnity. The work in [4] needs more iterations to reﬁne the feature maps according to their afﬁnity at the last stage. As shown in Fig. 1, one plausible reason is that pairwise similarity is damaged during upsam-pling. In addition, it is inefﬁcient to construct interactions between high-dimensional feature maps. We therefore pose the question: Can we model afﬁnity earlier in upsampling in an effective and efﬁcient manner?
Many widely used upsampling operators interpolate val-ues following a ﬁxed rule at different positions. For in-stance, despite reference positions may change in bilinear upsampling, it always interpolates values based on rela-tive spatial distances. Recently, the idea of learning to up-sample emerges [24, 25, 35]. A learnable module is of-ten built to generate upsampling kernels conditioned on feature maps to enable dynamic, feature-dependent upsam-pling behaviors. Two such representative operators include
CARAFE [35] and IndexNet [25]. In our experiments, we
ﬁnd that CARAFE may not work well in low-level vision tasks where details need to be restored. IndexNet instead can recover details much better. We believe that one im-portant reason is that IndexNet encodes, stores, and delivers spatial information prior to downsampling. But computa-tion can be costly when the network goes deep. This mo-6841
tivates us to pursue not only ﬂexible but also light-weight designs of the upsampling operator.
In this paper, we propose to model afﬁnity into upsam-pling and introduce a novel learnable upsampling operator, i.e., afﬁnity-aware upsampling (A2U). As we show later in
Section 4, A2U is a generalization of ﬁrst-order upsam-pling operators: in some conditions, the ﬁrst-order formu-lation in [35] and [24] can be viewed as special cases of our second-order one. In addition, by implementing A2U in a low-rank bilinear formulation, we can achieve efﬁcient upsampling with few extra parameters.
We demonstrate the effectiveness of A2U on two detail-sensitive tasks: an image reconstruction task on a toy dataset with controllable background and a large-scale im-age matting task with subtle foregrounds. Image matting is a desirable task to justify the usefulness of afﬁnity, be-cause afﬁnity-based matting approaches constitute one of prominent matting paradigms in literatures. Top matting performance thus can suggest appropriate afﬁnity model-ing.
In particular, we further discuss alternative design choices of A2U and compare their similarities and differ-ences. Compared with a strong image matting baseline on the Composition-1k matting dataset, A2U exhibits a signif-icant improvement (∼ 14%) with negligible increase of pa-rameters (< 0.5%), proffering a light-weight image matting architecture with state-of-the-art performance. 2.