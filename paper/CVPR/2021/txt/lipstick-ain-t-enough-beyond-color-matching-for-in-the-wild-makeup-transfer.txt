Abstract
Makeup transfer is the task of applying on a source face the makeup style from a reference image. Real-life makeups are diverse and wild, which cover not only color-changing but also patterns, such as stickers, blushes, and jewelries.
However, existing works overlooked the latter components and conﬁned makeup transfer to color manipulation, fo-cusing only on light makeup styles. In this work, we pro-pose a holistic makeup transfer framework that can han-dle all the mentioned makeup components. It consists of an improved color transfer branch and a novel pattern trans-fer branch to learn all makeup properties, including color, shape, texture, and location. To train and evaluate such a system, we also introduce new makeup datasets for real and synthetic extreme makeup. Experimental results show that our framework achieves the state of the art performance on both light and extreme makeup styles. Code is available at https://github.com/VinAIResearch/CPM . 1.

Introduction
Across thousands of years of history, humankind has been fascinated with facial beauty. Humans, particularly fe-males, want to be attractive, and facial appearance is a cru-cial part of this. The cosmetic industry, as reported in 2007, generates a turnover of about $170 billion each year [27].
Among face beautiﬁcation techniques, makeup is the most popular method, accompanied by a wide range of commer-cial products including foundation, eye shadow, lipsticks, blushes, stickers, facial drawings, and facial accessories.
Due to the popularity of makeup, makeup try-on is an vital application in both retail and entertainment. Among makeup try-on techniques, makeup transfer is the most con-venient and effective way. Makeup transfer is the task of transferring the makeup style from one reference face to an-other face. This task is not trivial; it needs to extract makeup components from the composited reference image. It also needs to analyze the face structure to transfer makeup com-ponents between unaligned faces correctly, and there are many factors to account for, including head pose, illumi-nation, facial expressions, and occlusions.
Deep-learning-based generative models are leading methods in tackling this problem. BeautyGAN [16] and
BeautyGlow [6] can provide realistic after-makeup images for simple styles on frontal faces. PSGAN [12] man-ages to handle faces at various head poses and expressions, while CA-GAN [14] focuses on ﬁne-grained makeup-color matching. However, these methods can only work with sim-ple makeup styles based on color distributed in cosmetic re-gions such as skin foundations, lipsticks, and eye-shadows.
They fail miserably on the complex makeups that rely on shape, texture, and location, such as blushes, face paintings, and makeup jewelries. Only LADN [10] considers these ex-13305
treme makeups, but its results are far from satisfactory.
In this work, we consider makeup as a combination of color transformation and pattern addition. We aim to trans-form the color distribution like previous methods while also preserving the shape and appearance of the makeup pattern.
To achieve this objective, we introduce a framework with two branches: Color Transfer Branch and Pattern Transfer
Branch, which could be run independently in parallel. In the
Color Transfer Branch, we employ a CycleGAN-like net-work structure driven by Histogram Matching as suggested by BeautyGAN [16]. In the Pattern Transfer Branch, we learn to extract the makeup pattern mask in a supervised manner. Noticeably, unlike previous methods, both our branches work on warped faces in UV space, thus discard-ing the discrepancy between these faces in terms of shape, head pose, and expression. The results of the two branches are fused to generate the desired output.
We also introduce new makeup-transfer datasets, con-sisting of both synthetic and real images, and covering a wide range of makeup styles. They include extreme makeup styles, which do not exist in previous makeup datasets.
Using the novel network architecture and the newly collected datasets for training, we obtain an all-inclusive makeup transfer method that outperforms all previous meth-ods in terms of coverage, as shown in Fig. 2b. We also run comprehensive experiments, both qualitative and quan-titative, and proposed makeup-transfer benchmarks. Our method outperforms other methods on both light and ex-treme makeup transfer by a wide margin.
In short, our contributions are: (1) We pose makeup as a combination of color transformation and pattern addi-tion, and develop a comprehensive makeup transfer method that works for both light and extreme styles. (2) We de-sign a novel architecture with two branches for color and pattern transfer, and we propose to use warped faces in the UV space when training two network branches to dis-card the discrepancy between input faces in terms of shape, head pose, and expression. (3) We introduce new makeup-transfer datasets containing extreme styles that have not been considered in the previous datasets. (4) We obtain state-of-the-art quantitative and qualitative performance. 2.