Abstract
Self-training is a competitive approach in domain adap-tive segmentation, which trains the network with the pseudo labels on the target domain. However inevitably, the pseudo labels are noisy and the target features are dispersed due to the discrepancy between source and target domains. In this paper, we rely on representative prototypes, the feature cen-troids of classes, to address the two issues for unsupervised domain adaptation. In particular, we take one step further and exploit the feature distances from prototypes that pro-vide richer information than mere prototypes. Speciﬁcally, we use it to estimate the likelihood of pseudo labels to facil-itate online correction in the course of training. Meanwhile, we align the prototypical assignments based on relative fea-ture distances for two different views of the same target, producing a more compact target feature space. Moreover, we ﬁnd that distilling the already learned knowledge to a self-supervised pretrained model further boosts the perfor-mance. Our method shows tremendous performance advan-tage over state-of-the-art methods. The code is available at https://github.com/microsoft/ProDA. 1.

Introduction
Despite the remarkable success of deep learning in com-puter vision, attaining high performance requires vast quan-tities of data.
It is usually expensive to obtain labels for dense prediction tasks, e.g., semantic segmentation. There-fore, people think of leveraging abundant photo-realistic synthetic images with freely generated labels [44, 45].
However, deep neural networks are notoriously sensitive to the domain misalignment that any nuanced unrealism in rendered images will induce poor generalization to real data. To address this issue, domain adaption techniques aim to transfer the knowledge learned from the synthetic images (source domain) to real ones (target domain) with minimal performance loss. In this work, we focus on the challenging
*This work is done during the ﬁrst author’s internship at Microsoft Re-search Asia. case, unsupervised domain adaptation (UDA), where there are no accessible labels in the target domain. Speciﬁcally, we solve the UDA problem for semantic segmentation.
Rather than explicitly aligning the distributions of the source and target domains as most predominant solu-tions [6, 27, 48, 54, 58], self-training [34, 69, 75, 76] has recently emerged as a simple yet competitive approach in the UDA task. This is achieved by iteratively generating a set of pseudo labels based on the most conﬁdent predictions on the target data and then relying on these pseudo labels to retrain the network. In this way, the network gradually learns the adaptation in the self-paced curriculum learning.
However, the performance still lags far behind the super-vised learning or semi-supervised learning using a few la-beled samples, making unsupervised domain adaptation im-practical in real scenarios.
After dissecting the self-training, we ﬁnd two key ingre-dients are lacking in previous works. First, typical prac-tice [75, 76] suggests selecting the pseudo labels according to a strict conﬁdence threshold, while high scores are not necessarily correct, making the network fail to learn reliable knowledge in the target domain. Second, due to the domain gap, the network is prone to produce dispersed features in the target domain. It is likely that for target data, the closer to the source distribution, the higher the conﬁdence score.
As a result, data lying far from the source distribution (i.e. low scores) will never be considered during the training.
In this paper, we propose to online denoise the pseudo labels and learn a compact target structure to address the above two issues respectively. We resort to prototypes, i.e., the class-wise feature centroids, to accomplish the two tasks. (1) We rectify the pseudo labels by estimating the class-wise likelihoods according to its relative feature dis-tances to all class prototypes. This depends on a practical assumption that the prototype lies closer to the true centroid of the underlying cluster, implying that false pseudo labels are in the minority. It is worth noting that the prototypes are computed on-the-ﬂy, and thus the pseudo labels are pro-gressively corrected throughout the training. (2) We draw inspiration from the Deepcluster [4] to learn the intrinsic structure of the target domain. Instead of directly learning 12414
from the cluster assignment, we propose to align soft pro-totypical assignments for different views of the same target, which produces a more compact target feature space. We refer to our method ProDA as we heavily rely on prototypes for domain adaption.
Supercharged with the above techniques, our ProDA can demonstrate clear superiority over prior works. Moreover, we ﬁnd that the domain adaptation can also beneﬁt from the task-agnostic pretraining — distilling the knowledge to a self-supervised model [10, 23] further boosts the perfor-mance to a record high. Our contributions can be summa-rized as follows:
• We propose to online correct the soft pseudo labels ac-cording to the relative feature distances to the proto-types, whereas the prototypes are also updated on-the-ﬂy.
The network thereby learns from denoised pseudo labels throughout the training.
• We propose to rely on the soft prototypical assignment to teach the learning of an augmented view so that a compact target feature space can be obtained.
• We show that distilling the already-learned knowledge to a self-supervised pretrained model further improves the performance signiﬁcantly.
• The proposed ProDA substantially outperforms state-of-the-art. With the Deeplabv2 [8] network, our method achieves the Cityscapes [13] segmentation mIOU by 57.5 and 55.5 when adapting from the GTA5 [44] and SYN-THIA [45] datasets, improving the adaption gain1 by 52.6% and 58.5% respectively over the prior leading ap-proach. 2.