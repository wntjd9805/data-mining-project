Abstract
Cross-view image geo-localization aims to determine the locations of street-view query images by matching with
GPS-tagged reference images from aerial view. Recent works have achieved surprisingly high retrieval accuracy on city-scale datasets. However, these results rely on the assumption that there exists a reference image exactly cen-tered at the location of any query image, which is not ap-plicable for practical scenarios. In this paper, we redeﬁne this problem with a more realistic assumption that the query image can be arbitrary in the area of interest and the refer-ence images are captured before the queries emerge. This assumption breaks the one-to-one retrieval setting of exist-ing datasets as the queries and reference images are not perfectly aligned pairs, and there may be multiple refer-ence images covering one query location. To bridge the gap between this realistic setting and existing datasets, we propose a new large-scale benchmark –VIGOR– for cross-View Image Geo-localization beyond One-to-one Retrieval.
We benchmark existing state-of-the-art methods and pro-pose a novel end-to-end framework to localize the query in a coarse-to-ﬁne manner. Apart from the image-level re-trieval accuracy, we also evaluate the localization accuracy in terms of the actual distance (meters) using the raw GPS data. Extensive experiments are conducted under differ-ent application scenarios to validate the effectiveness of the proposed method. The results indicate that cross-view geo-localization in this realistic setting is still challenging, fos-tering new research in this direction. Our dataset and code will be released at https://github.com/Jeff-Zilence/VIGOR. 1.

Introduction
The objective of image-based geo-localization is to de-termine the location of a query image by ﬁnding the most similar image in a GPS-tagged reference database. Such technologies have proven useful for accurate localization with noisy GPS signals [4, 26] and navigation in crowded cities [12, 9]. Recently, there has been a surge of interest in cross-view geo-localization [24, 22, 7, 17, 29, 21], which uses GPS-tagged aerial-view images as reference for street-view queries. However, the performance may suffer from a large appearance gap between query and reference images.
Recent works [7, 17, 29] have shown that the perfor-mance of cross-view image matching can be signiﬁcantly improved by feature aggregation and sample mining strate-gies. When the orientation of street-view (or ground-view) image is available (provided by phone-based compass), state-of-the-art methods can achieve a top-1 retrieval accu-racy over 80% [17], which shows the possibility of accu-rate geo-localization in real-world settings. However, ex-isting datasets [24, 27, 11] simply assume that each query ground-view image has one corresponding reference aerial-view image whose center is exactly aligned at the location of the query image. We argue this is not practical for real-world applications, because the query image can occur at arbitrary locations in the area of interest and the reference images should be captured before the queries emerge. In this case, perfectly aligned one-to-one correspondence is not guaranteed.
In light of the novelty of this problem, we propose a new benchmark (VIGOR) to evaluate cross-view geo-localization in a more realistic setting. Brieﬂy, given an area of interest (AOI), the reference aerial images are densely sampled to achieve a seamless coverage of the AOI and the street-view queries are captured at arbitrary locations.
In total, 90, 618 aerial images and 238, 696 street panoramas are collected from 4 major cities in the United States (see details in Sec. 3). The new dataset gives rise to two funda-mental differences between this work and prior research.
Beyond One-to-one: Previous research mainly focuses on the one-to-one correspondence because existing datasets consider perfectly aligned image pairs as default. However,
VIGOR enables us to explore the effect of reference sam-ples that are not centered at the locations of queries but still cover the query area. As a result, there could be multiple reference images partially covering the same query loca-tion, breaking the one-to-one correspondence. In our geo-localization method, we design a novel hybrid loss to take advantage of multiple reference images during training. 3640
Beyond Retrieval:
Image retrieval can only provide image-level localization. Since the center alignment is not guaranteed in our dataset, after the retrieval, we further employ a within-image calibration to predict the offset of the query location inside the retrieved image. Therefore, the proposed joint-retrieval-and-calibration framework pro-vides a coarse-to-ﬁne localization. The whole pipeline is end-to-end, and the inference is fast as the offset prediction shares the feature descriptors with the retrieval task. More-over, our dataset is also accompanied with raw GPS data.
Thus a more direct performance assessment, i.e. localiza-tion accuracy in terms of real-world distance (e.g. meters), can be achieved on our dataset.
Our main contributions can be summarized as follows:
• We introduce a new dataset for the problem of cross-view image geo-localization. This dataset, for the ﬁrst time, allows one to study this problem under a more realistic and practical setting and offers a testbed for bridging the gap between current research and practical applications.
• We propose a novel joint-retrieval-and-calibration frame-work for accurate geo-localization in a coarse-to-ﬁne manner, which has not been explored in the past.
• We develop a new hybrid loss to learn from multiple ref-erence images during training, which is demonstrated to be effective in various experimental settings.
• We also validate the potential of the proposed cross-view geo-localization framework in a real-world application scenario (assistive navigation) by simulating noisy GPS. 2.