Abstract (a) Observation model
Pan-sharpening is an important technique for remote sensing imaging systems to obtain high resolution multi-spectral images. Recently, deep learning has become the most popular tool for pan-sharpening. This paper devel-ops a model-based deep pan-sharpening approach. Specif-ically, two optimization problems regularized by the deep prior are formulated, and they are separately responsible for the generative models for panchromatic images and low resolution multispectral images. Then, the two problems are solved by a gradient projection algorithm, and the iter-ative steps are generalized into two network blocks. By al-ternatively stacking the two blocks, a novel network, called gradient projection based pan-sharpening neural network, is constructed. The experimental results on different kinds of satellite datasets demonstrate that the new network out-performs state-of-the-art methods both visually and quanti-tatively. The codes are available at https://github. com/xsxjtu/GPPNN . 1.

Introduction
Multispectral images store multiple images correspond-ing to each band (or say, channel) in an optical spectrum, and they are widely utilized in literature of remote sens-ing. With the limitation of imaging devices, satellites how-ever often measure the low spatial resolution multispectral (LRMS) images [4, 21, 29]. Compared with the multispec-tral image, the panchromatic (PAN) image is characterized by the high spatial resolution but only one band. Lots of satellites carry both multispectral and panchromatic sensors to simultaneously measure the complementary images, such as Landsat8, GaoFen2 and QuickBird. To obtain the high resolution multispectral (HRMS) image, a promising way is to fuse the complementary information of the LRMS im-age and the PAN image. This technique is called as pan-sharpening [4, 21].
Pan-sharpening can be cast as a typical image fusion on
*Corresponding author.
𝑀𝑁×𝑏
𝑷 ∈ 𝑅
𝑀𝑁×𝐵
𝑯 ∈ 𝑅
PAN
Band Reduction
𝑺
HRMS (b) Optimization
+
𝑚𝑛×𝐵
Blurring&Downsampling
𝑲
𝑫
LRMS
𝑳 ∈ 𝑅
𝑷 = 𝑯𝑺
𝑳 = 𝑫𝑲𝑯 𝟐 min𝑯 𝑷 − 𝑯𝑺 𝟐
+ DeepPrior(𝑯) 𝟐 min𝑯 𝑳 − 𝑫𝑲𝑯 𝟐
+ DeepPrior(𝑯)
•
•
•
•
𝑡
෡𝑷
𝑡
𝑹𝑝
𝑡
𝑹ℎ
𝑡
𝑯 (c) GPPNN
Input 
𝑡−1
𝑯
©
⨁
Output 
𝑡−1
𝑺
𝑡
= 𝑯
= 𝑷 − ෡𝑷
𝑡
= 𝜌𝑹𝑝
𝑺
= proxℎ𝑝 𝑯
𝑇
•
•
•
•
𝑡−1
𝑡
+ 𝑹ℎ
𝑡
𝑡
෠𝑳
𝑹𝑙
𝑡
𝑹ℎ
𝑡
𝑯
𝑡−1
𝑡
= 𝑫𝑲𝑯
= 𝑳 − ෠𝑳
𝑹𝑙
= 𝜌 𝑫𝑲
= proxℎ𝑙 𝑯
𝑇
𝑡
𝑡−1
𝑡
+ 𝑹ℎ
Input 
𝑡−1
෡𝑷
©
𝑡
𝑹𝑝
©
⊝
𝑡
𝑹𝑙
⊝
©
𝑡−1
෠𝑳
𝑡−1
𝑯
©
𝑷
𝑳
PAN Block
𝑡
𝑹ℎ
𝑡
𝑹ℎ
MS Block
Element-wise subtraction
©
⨁
Output 
© Convolutional Operator
𝑡
𝑯
Element-wise addition
𝑡
𝑯
⊝
⨁
Figure 1. (a) The observation models for LRMS and PAN images. (b) Two formulated optimization problems and iterative steps of the gradient projection algorithm. (c) The main blocks in our pro-posed GPPNN. super-resolution problems. The past decades witnessed the development of pan-sharpening. The classic algorithms in-cluding component substitution (CS) [7, 12], multiresolu-tion analysis (MRA) [1, 23] and other techniques. In the era of deep learning, convolutional neural networks have emerged as a signiﬁcant tool for pan-sharpening [19]. One of the seminal work is the pan-sharpening neural network (PNN) proposed by Masi et al. [20]. Borrowing the idea of the ﬁrst super-resolution network [2], PNN is fed with the concatenation of a PAN image and an upsampled LRMS 1366
image to regress the HRMS image.
In fact, there are only three convolutional units in PNN, so it is a relatively shallow network. Recently, numerous models have been proposed to improve the PNN. Owing to the triumphs of residual networks [8], several papers utilize the shortcut or residual convolutional units to build deep networks, including MIPSM [16], DRPNN [34] and Pan-Net [38]. They generally contain 10 or more convolutional units. Besides these networks, to make the best of advan-tages of neural networks, some researchers build deeper net-works. For example, Wang et al. employ the densely con-nected convolutional unit [10] to design a 44-layer network
[31] for pan-sharpening.
It is well-known that deepening the layers of networks does not necessarily improve the performance, since it is difﬁcult to train deeper networks and redundant parameters make them easily over-ﬁt. Very recently, the remote sens-ing community begins to rethink how to make the full use of PAN images’ information [9, 24].
It is worthy noting that most the pan-sharpening networks regard the PAN im-age as a channel of the input. This manner ignores different characteristics between PAN and LRMS images. A growing number of researchers attempt to propose the two-branch networks [18, 40]. In the ﬁrst stage, the two branches sep-arately extract the features for PAN and LRMS images. In the second stage, the features are fused to reconstruct the
HRMS image.
Although convolutional neural networks exhibit promis-ing performance in pan-sharpening, they require a large amount of training samples [22, 33], and they do not ac-count for the observation progress of PAN and LRMS im-ages, i.e., lacking the interpretability. Therefore, there still leaves the room for improvement. The research on model-based deep learning is the trend in image processing ﬁeld to close the gap between classic models and neural net-works, and it is found that model-based deep networks usu-ally outperform the intuitively designed networks [22, 33].
Xie et al. present a multispectral and hyperspectral (HS) image fusion network (MHNet) for the hyperspectral pan-sharpening task [35]. There is no doubt that MHNet can be naturally adapted to pan-sharpening [36]. Nonetheless,
MHNet is designed to describe the low-rank property for hyperspectral images, and our experiments show that MH-Net may perform badly in the pan-sharpening scenario.
In this paper, we develop a novel model-based deep net-work for pan-sharpening. Our contributions are summa-rized as follows:
Firstly, this paper considers the generative models for
PAN and LRMS images. That is, as shown in Fig. 1(a),
PAN images are the linear combination of the bands in
HRMS images, and LRMS images are generated by blur-ring and downsampling HRMS images. Combining the ob-servation models and the deep prior, we propose two opti-mization problems, and they can be effectively solved by the gradient projection method as illustrated in Fig. 1(b).
Secondly, inspired by the idea of algorithm unrolling techniques, the iterative steps are generalized as two neu-ral blocks separately justifying the generative models for
PAN and LRMS images. The computational ﬂows in the proposed neural blocks are interpretable. As show in Fig. 1(c), for the MS Block, given a current estimation of the
HRMS image, it generates corresponding LRMS image and computes the residual between the generated LRMS image and the real one. This residual then is upsampled and is added into the current estimation to reconstruct the next
HRMS image. The PAN block can be interpreted simi-larly. We build a new network by alternatively stacking the two blocks. In what follows, it calls the gradient projection based pan-sharpening neural network (GPPNN). To the best of our knowledge, it is the ﬁrst model-driven deep network for pan-sharpening.
Thirdly, the proposed GPPNN is compared with the 13 state-of-the-art (SOTA) and classic pan-sharpening meth-ods. The extensive experiments conducted on three popular satellites (i.e., Landsat8, QuickBird, GF2) demonstrate that our networks outperform other counterparts both quantita-tively and visually. 2.