Abstract z ‚àº N (0, I)
In most existing learning systems, images are typically viewed as 2D pixel arrays. However, in another paradigm gaining popularity, a 2D image is represented as an im-plicit neural representation (INR) ‚Äî an MLP that pre-dicts an RGB pixel value given its (x, y) coordinate.
In this paper, we propose two novel architectural techniques for building INR-based image decoders: factorized multi-plicative modulation and multi-scale INRs, and use them to build a state-of-the-art continuous image GAN. Previous attempts to adapt INRs for image generation were limited to MNIST-like datasets and do not scale to complex real-world data. Our proposed INR-GAN architecture improves the performance of continuous image generators by several times, greatly reducing the gap between continuous image
GANs and pixel-based ones. Apart from that, we explore several exciting properties of the INR-based decoders, like out-of-the-box superresolution, meaningful image-space in-terpolation, accelerated inference of low-resolution images, an ability to extrapolate outside of image boundaries, and strong geometric prior. The project page is located at https://universome.github.io/inr-gan. 1.

Introduction
In deep learning, images are typically represented as 2D arrays of pixels. However, there is another paradigm which views an image as a continuous function F (p) = v that maps a pixel‚Äôs 2D coordinate p = (x, y) 2 R2 to its RGB value v = (r, g, b) 2 R3. The advantage of such a rep-resentation is that it gives a true continuous version of the underlying 2D signal instead of its cropped quantized coun-terpart like pixel-based representations do. In practice, we almost never know the underlying function F (p) and thus have to work with its approximations. The most popular and expressive way to approximate F (p) is through a neural network FŒ∏ [81, 74]. It is called an implicit neural repre-sentation (INR) and is especially popular in 3D deep learn-ing where working with voxels directly (i.e. pixels deÔ¨Åned
ùë¶
ùë•
Linear
Activation
Linear
Activation
Conv 3x3
Upsample
Activation
Conv 3x3
Upsample
Activation z ‚àº N (0, I)
Linear
Activation
Linear
Activation
Œ∏
Figure 1: Comparison between a traditional convolutional generator (left) and an INR-based one (right). A traditional generator directly generates a pixel-based image represen-tation given its latent code z. The INR-based one produces parameters of an MLP. The corresponding pixel-based rep-resentation is obtained by evaluating the INR at each coor-dinate location (x, y) of a speciÔ¨Åed grid. on a 3D grid) is too expensive [51, 11, 67, 55].
Building such a decoder has two severe difÔ¨Åculties: 1) since it is a hypernetwork, i.e. a network that produces pa-rameters for another network [26], it is unstable to train and requires too many parameters in general [9]; and 2) it is too costly to evaluate INRs for a dense high-resolution co-ordinates grid limiting their application to low-resolution images only. To alleviate these issues, we design two factorized multiplica-principled architectural techniques: tive modulation (FMM) layer for hypernetworks and multi-scale INRs. We use these techniques to build INR-GAN: a state-of-the-art continuous image generator that gener-ates pictures in their INR representations. Previous at-tempts to build such a model were only conducted on small
MNIST-like datasets [11, 3, 51] and do not scale to com-plex real-world data. In our case, we managed to achieve
FID [28] scores of 5.09, 4.96 and 16.32 on LSUN Churches 110753
2562, LSUN Bedrooms 2562 and FFHQ 10242, respec-tively, greatly reducing the gap between continuous image
GANs and their pixel-based analogs.
In their contempo-rary work, [1] achieved even better results by employing a large-scale INR-based decoder with learnable coordinate embeddings.
In our paper, we also shed light on many interesting properties of the INR-based decoders:
‚Ä¢ Extrapolating outside of (see
Fig. 2): an ability to generate a ‚Äúzoomed-out‚Äù version of an image without being trained explicitly to do this. image boundaries
‚Ä¢ Geometric prior (see Fig. 4): better encoding of geo-metric properties of a dataset in the latent space.
‚Ä¢ Accelerated low-resolution inference (see Fig. 17): an ability to generate a low-resolution version of an im-age in shorter time than an image of the corresponding training-time resolution.
‚Ä¢ Meaningful image space interpolation (see Fig. 5).
‚Ä¢ Out-of-the-box superresolution (see Fig. 3): an abil-ity to produce a higher-resolution version of an image without being trained for this task at all.
We emphasize that these features come naturally to INR-based decoders and do not require any additional training.
To summarize, our contributions are the following: 1. We propose a novel factorized multiplicative modula-tion (FMM) layer for hypernetworks. It makes it possi-ble to generate INRs with a large number of parameters and stabilizes hypernetwork training. 2. We propose a novel multi-scale INR architecture. It makes it possible to represent high-resolution images in the INR-based form in a very efÔ¨Åcient way. 3. Using the above two techniques we build INR-GAN: an INR-based GAN model that outperforms existing continuous image generators by several times on large real-world datasets. 4. We explore several exciting properties of INR-based decoders, like out-of-the-box superresolution, mean-ingful image-space interpolation, accelerated infer-ence of low-resolution images, an ability to extrapolate outside of image boundaries, and geometric prior. 2.