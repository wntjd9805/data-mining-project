Abstract
State-of-the-art scene text detection methods usually model the text instance with local pixels or components from the bottom-up perspective and, therefore, are sensi-tive to noises and dependent on the complicated heuristic post-processing especially for arbitrary-shape texts. To re-lieve these two issues, instead, we propose to progressive-ly evolve the initial text proposal to arbitrarily shaped text contours in a top-down manner. The initial horizontal text proposals are generated by estimating the center and size of texts. To reduce the range of regression, the ﬁrst stage of the evolution predicts the corner points of oriented tex-t proposals from the initial horizontal ones. In the second stage, the contours of the oriented text proposals are itera-tively regressed to arbitrarily shaped ones. In the last iter-ation of this stage, we rescore the conﬁdence of the ﬁnal localized text by utilizing the cues from multiple contour points, rather than the single cue from the initial horizon-tal proposal center that may be out of arbitrary-shape text regions. Moreover, to facilitate the progressive contour evo-lution, we design a contour information aggregation mech-anism to enrich the feature representation on text contours by considering both the circular topology and semantic con-text. Experiments conducted on CTW1500, Total-Text, ArT, and TD500 have demonstrated that the proposed method e-specially excels in line-level arbitrary-shape texts. Code is available at https://github.com/dpengwen/PCR. 1.

Introduction
Scene text detection has attracted increasing attention in the computer vision community for its ubiquitous appli-cations [46, 11, 10], such as scene understanding, visual search, automatic driving, etc. However, it is a challeng-ing task, due to the effect of scene factors (e.g., complex
∗Corresponding Author. (a) (c) (b)
Figure 1: Illustration of the contour evolution. It evolves the contour of the horizontal text proposal (a) to the corner points (cyan) of the oriented text proposal (b), and then the contour of the oriented text proposal is further evolved to close to the ground-truth contour (green) for multiple times (c). The red point and dash lines are the center and size of the axis-aligned box of the arbitrary-shape text. Yellow ar-rows on the contours indicate the information passing. background, perspective distortion, and various illumina-tion) and the speciﬁc characteristics of scene texts (e.g., arbitrary-shape layout, no well-deﬁned closed boundaries, and various aspect ratios).
To exploit an arbitrary-shape scene text detector that requires localizing explicit contours of text instances, the bottom-up methods [6, 27, 42, 43, 51, 38, 44, 7, 53, 17, 59] have become the dominant mainstream. These methods per-form the pixel-wise semantic segmentation on the entire or shrunk text regions, and simultaneously predict the auxil-iary information of each pixel for clustering text pixels into different instances [6, 42, 53, 51, 38, 43, 44, 17, 63] or lo-cal components [27, 1, 7, 59]. However, due to the huge number of pixels in the image, it would involve complicat-ed post-processings to achieve the accurate bounding box for arbitrary-shape texts. Furthermore, the pixels are easy to generate ambiguous predictions when two scene texts are too close or the space between characters in each text is too large. Though the local components are more robust to the pixel-wise noises, they still need to be linked to different text instances by the heuristic rules [27, 7] or the relational 7393
reasoning network [59]. Most importantly, existing bottom-up methods focus on the local text cues instead of the inte-grated geometric layout of texts, which leads to the lack of global perception.
To obtain the global geometric layout, the top-down methods [5, 50, 4, 22, 13] are proposed to localize arbitrary-shape scene texts. These methods ﬁrst carry out the bina-ry segmentation within the text proposals and then utilize the contour extraction algorithm [35] to obtain the contour of the segmentation mask. However, they require elabo-rate anchors, and are sensitive to the inaccurate localization of text regions. Differently, some other top-down methods
[64, 24, 45, 2, 41] regress the key points on text contours within the text proposals. However, these methods are also dependent on the artiﬁcially-designed anchors, and ignore the constraint of global geometric layout among key points.
To address these issues, the single-shot top-down methods
[20, 39] reconstruct the text contour via the control points of
Bezier curves, or encode the text contour based on the ge-ometric information under polar space. Nevertheless, these single-shot methods only perceive scene texts with complex geometry layout once, which would generate inaccurate lo-calization. It is inconsistent with the human visual system in which look more than once is usually required [58].
In this paper, we develop a novel scene text detection method via Progressive Contour Regression, called PCR, to effectively localize the arbitrary-shape scene text. Specif-ically, we ﬁrst generate horizontal text proposals by estimat-ing their center points and sizes. Then we regress the global contours of the horizontal text proposals to the corner points of oriented text proposals. After that, we evolve the con-tours of the oriented text proposals into arbitrary-shape text contours and iteratively reﬁne them, as described in Fig. 1.
This progressive strategy is helpful to perceive texts with complex layouts, thus can generate accurate localization for arbitrary-shape scene texts. To facilitate the regression of text contour points, we exploit a contour information aggre-gation technique. It not only makes full use of the cyclicity of text contours in geometric topology, but also assembles the contour information into sink nodes in semantic to avoid the inﬂuence of redundant or noisy points on text contours.
This technique can effectively gather rich information and distribute them to each contour point to enhance the feature representation. Additionally, the center points of some hori-zontal bounding boxes of texts with complex geometric lay-outs (e.g., extremely-curved texts, texts with large character spaces, etc.) are not on texts, as shown in Fig. 1 (a). Mean-while, the single center point is also insufﬁcient to repre-sent arbitrary-shape texts based on local cues. Thus, based on the predicted centers, the generated horizontal text pro-posals would contain some false detections. To increase the conﬁdence of the ﬁnal localized contours, we propose a re-liable contour localization mechanism, which is performed by the scoring mechanism based on multiple sampled points on text contours. Our proposed method is an anchor-free model, and can be trained in an end-to-end manner. The model can directly output the polygonal detection with only one simple NMS post-processing.
The main contributions of this work are as follows: i) We propose a novel progressive contour regression framework to detect arbitrary-shape scene texts, which has achieved state-of-the-art performances on multiple public benchmarks, e.g., CTW1500, Total-Text, ArT, and TD500. ii) A contour information aggregation is exploited to en-rich the contour feature representation, which can restrain the effect of redundant and noisy contour points and gener-ate more accurate localization for arbitrary-shape texts. iii) A reliable contour localization mechanism is devel-oped to rescore the localized contours, which can effectively relieve the false detections. 2.