Abstract
Instance segmentation, the task of identifying and sep-arating each individual object of interest in the image, is one of the actively studied research topics in computer vi-sion. Although many feed-forward networks produce high-quality binary segmentation on different types of images, their ﬁnal result heavily relies on the post-processing step, which separates instances from the binary mask. In com-parison, the existing iterative methods extract a single ob-ject at a time using discriminative knowledge-based proper-ties (e.g., shapes, boundaries, etc.) without relying on post-processing. However, they do not scale well with a large number of objects. To exploit the advantages of conven-tional sequential segmentation methods without impairing the scalability, we propose a novel iterative deep reinforce-ment learning agent that learns how to differentiate multiple objects in parallel. By constructing a relational graph be-tween pixels, we design a reward function that encourages separating pixels of different objects and grouping pixels that belong to the same instance. We demonstrate that the proposed method can efﬁciently perform instance segmen-tation of many objects without heavy post-processing. 1.

Introduction
Instance segmentation is one of the challenging com-puter vision problems that assigns instance labels to pix-els to separate objects, which is crucial for understanding a complex scene. Many existing methods are based on com-plex graphical models with deep neural networks (e.g., con-volutional neural network [CNN] or recurrent neural net-work [RNN])) [20, 30]. However, most other methods are still trying to predict the intermediate representation [27] of the labeling map, which require extra post-processing steps.
Some object proposal approaches use bounding boxes to capture the representation of instances [7,21]. Even though,
*Corresponding author they produce instance maps directly, the bounding boxes are often criticized for their coarse representation of the ob-ject’s shape. A recent study by Araslanov et al. [2] aimed to address the issue by employing reinforcement learning for a sequential object detection and segmentation task. Al-though such sequential approaches have shown promising results when it comes to directly detecting and extracting individual instances in the image, they are only applicable to images with a small number of objects due to the sequen-tial nature of the method.
The motivation behind the proposed work stems from our recent development of the cell image segmentation method.
In this development, we observed that separat-ing every individual cell in a large microscopy image is a slow and time-consuming task for conventional segmenta-tion methods. To address this problem, we propose a novel end-to-end instance segmentation method using reinforce-ment learning, which separates multiple instances in paral-lel. Unlike in Araslanov et al. where a single agent han-dles segmentation sequentially, our method leverages mul-tiple pixel-wise agents (similar to Furuta et al. [5]) work-ing concurrently to differentiate multiple objects in an it-erative, end-to-end fashion (Fig. 1). To make multiple in-stances concurrently labeled, we formulate the segmenta-tion problem as an iterative binary graph coloring problem.
To achieve this, we employ the asynchronous advantage actor-critic (A3C) algorithm to train the agents to choose the t-th bit value in a binary representation of the label (0 or 1) at step t of the coloring process. We demonstrate that the proposed method can efﬁciently handle images that have numerous objects of various shapes while maintaining a su-perior segmentation quality comparable to state-of-the-art methods. To the best of our knowledge, this is the ﬁrst rein-forcement learning-based end-to-end instance segmentation that runs in parallel. 2.