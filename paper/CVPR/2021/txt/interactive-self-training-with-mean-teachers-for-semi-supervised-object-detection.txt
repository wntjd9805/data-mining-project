Abstract
The goal of semi-supervised object detection is to learn a detection model using only a few labeled data and thereby reducing the large amounts of unlabeled data, cost of data labeling. Although a few studies have pro-posed various self-training-based methods or consistency regularization-based methods, they ignore the discrepan-cies among the detection results in the same image that oc-cur during different training iterations. Additionally, the predicted detection results vary among different detection models.
In this paper, we propose an interactive form of self-training using mean teachers for semi-supervised object detection. Speciﬁcally, to alleviate the instability among the detection results in different iterations, we pro-pose using nonmaximum suppression to fuse the detection results from different iterations. Simultaneously, we use multiple detection heads that predict pseudo labels for each other to provide complementary information. Furthermore, to avoid different detection heads collapsing to each other, we use a mean teacher model instead of the original detec-tion model to predict the pseudo labels. Thus, the object de-tection model can be trained on both labeled and unlabeled data. Extensive experimental results verify the effectiveness of our proposed method. 1.

Introduction
Object detection has undergone substantial progress in recent years since the successful application of deep con-volutional neural network (CNN) models. These methods generally fall into two categories: single-stage [25, 26, 20, 36] and two-stage methods [27, 9, 8, 10, 18]. However, these methods require large amounts of training samples an-notated with instance-level labels, which limits their scala-bility. To reduce the cost of labeling, weakly supervised learning and semi-supervised learning methods have grad-ually attracted attention recently. Weakly supervised ob-ject detection methods [47, 31, 14, 37] require image-level annotations, while semi-supervised methods [38, 22, 29] require large quantities of unlabeled data but only a few (a) (c) (b) (d)
Figure 1. Illustration of our motivation: (a) and (b) show detec-tion results from different iterations. These changes in the de-tection results hinder the convergence of self-training-based semi-supervised learning models; (c) and (d) show the detection results from different ROI heads. instance-level labeled data. The weakly semi-supervised object detection methods [34, 42] use both fully labeled data and weakly labeled data. In this paper, we aim to leverage unlabeled data to further improve the object detection per-formance using semi-supervised learning.
Although semi-supervised learning has been widely ex-plored in tasks such as image classiﬁcation [1, 15, 30, 40, 44, 2, 35], only a few works [13, 32] have focused on how to apply semi-supervised learning to object detection. The challenges in applying semi-supervised learning to object detection include the fact that each image may have mul-tiple object instances and object detection methods must regress the location for each object, as shown in Figure 1.
Currently, the semi-supervised object detection methods for solving this problem can be divided into two categories: self-training-based methods and consistency regularization-based methods. The self-training-based methods [32] esti-mates the pseudo labels for unlabeled images using a pre-trained model and then jointly trains the model with both labeled and unlabeled data. However, the pseudo labels are generated only once, and they remain ﬁxed during the semi-5941
supervised training, (i.e., incorrect pseudo labels are not corrected during the semi-supervised learning process; thus, the improvements offered by such models is limited).
In contrast, the consistency-regularization-based methods [13] regularize the consistency of the outputs for the same un-labeled image under different forms of data augmentation.
However, this method ignores the discrepancies among the outputs from different iterations.
To overcome the challenges mentioned above, we treat the detection results from different iterations and models as an ensemble rather than using ﬁxed pseudo labels. This ap-proach supports estimating up-to-date detection results for the unlabeled images in the current batch to improve the pseudo label quality during semi-supervised training. How-ever, as illustrated in Figure 1 (a) and (b), the detection re-sults from different iterations can be different.
If we use the results directly as pseudo labels for unlabeled data, the training process would be difﬁcult to converge. Addition-ally, as shown in Figure 1 (c) and (d), the detection re-sults from different detection models (or different region-of-interest (ROI) heads) are also different, which means they may contain complementary information. Thus, the detec-tion results of one model have the potential to improve an-other model.
In this paper, we propose interactive self-training with mean teachers for semi-supervised object detection (ISMT). Speciﬁcally, to improve the quality of pseudo la-bels while ensuring the model convergence during semi-supervised training, we store historical pseudo labels in memory and use nonmaximum suppression (NMS) to fuse the up-to-date detection result with the historical pseudo la-bels. Then, we update the pseudo label memory bank; this stored version serves as the ﬁnal pseudo label for the unla-beled data. Second, we use two ROI heads with different structures to mine complementary information from the un-labeled data. Furthermore, to avoid overﬁtting and prevent the two ROI heads from reaching the same value, we use the mean teacher approach for each student ROI head to es-timate the detection results and provide pseudo labels for the other student ROI head. Compared to the existing self-training-based object detection methods [32], our method performs interactive self-training using the mean teachers as an ensemble to combine the knowledge from different iterations and different ROI heads.
The main contributions of this work are summarized be-low. (1) We propose using NMS to fuse the up-to-date de-tection results with the history pseudo labels to improve the quality of pseudo labels and stabilize the semi-supervised training process. (2) We ﬁrst propose interactive self-training for semi-supervised object detection augmented by the mean teacher approach, in which the ROI heads es-timate pseudo labels for each other and learn from unla-beled data. Our proposed method achieves the state-of-the-art semi-supervised object detection performance across the
MS-COCO [19] and PASCAL-VOC [6] datasets. We also provide an ablation study and a further analysis to verify the effectiveness of each proposed component. 2.