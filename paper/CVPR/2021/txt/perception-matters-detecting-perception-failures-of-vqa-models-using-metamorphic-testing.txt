Abstract
Visual question answering (VQA) takes an image and a natural-language question as input and returns a natural-language answer. To date, VQA models are primarily as-sessed by their accuracy on high-level reasoning questions.
Nevertheless, Given that perception tasks (e.g., recognizing objects) are the building blocks in the compositional pro-cess required by high-level reasoning, there is a demand-ing need to gain insights into how much of a problem low-level perception is. Inspired by the principles of software metamorphic testing, we introduce MetaVQA, a model-agnostic framework for benchmarking perception capabil-ity of VQA models. Given an image i, MetaVQA is able to synthesize a low-level perception question q. It then jointly transforms (i, q) to one or a set of sub-questions and sub-images. MetaVQA checks whether the answer to (i, q) sat-isﬁes metamorphic relationships (MRs), denoting percep-tion consistency, with the composed answers of transformed questions and images. Violating MRs denotes a failure of answering perception questions. MetaVQA successfully detects over 4.9 million perception failures made by popular
VQA models with metamorphic testing. The state-of-the-art
VQA models (e.g., the champion of VQA 2020 Challenge) suffer from perception consistency problems. In contrast, the Oscar VQA models, by using anchor points to align questions and images, show generally better consistency in perception tasks. We hope MetaVQA will revitalize inter-est in enhancing the low-level perceptual abilities of VQA models, a cornerstone of high-level reasoning. 1.

Introduction
Deep learning techniques have been applied to a vari-ety of question-answering tasks. In particular, visual ques-tion answering (VQA) models take an image and a natural-language question as input and return a natural-language answer as output [6]. At present, the standard paradigm is
∗Corresonding Author to use hold-out validation, based on a train–validation–test dataset split, to estimate the accuracy of VQA models. Re-cent works have also shown that high-level logic reasoning consistency might not be preserved by VQA models and provide enhancements accordingly [31, 33, 14].
Q1:
What is the total number  of fences and sheep? 
A1: 4
Q2:
What is the total number  of fences?
A2: 2
Q3:
What is the total number  of sheep?
A3: 3
Q: What is the  total number of microwaves? 
A1:0
A2:3
A3:0
A4:1
A:1
Figure 1: Perception task failures detected by MetaVQA.
Human cognition is believed to be a compositional pro-cess [33]: high-level reasoning and understanding requires to ﬁrst perform multiple perception tasks. For instance, to answer the question “is the microwave occupied?” (the sec-ond image in Fig. 1), a VQA model should ﬁrst detect the microwave, extract its associated properties, identify other objects (e.g., human beings) in the context, understand the question, and try to reason about if the microwave is be-ing used by someone.
In other words, perception tasks (e.g., identifying the microwave) serve as the cornerstone for VQA models to answer high-level reasoning questions.
Despite the overall optimistic views on VQA models’ ac-curacy of performing perception tasks, Fig. 1 presents two failed perception tasks of a popular VQA model. While it is generally hard to check if the answer A1 to Q1 is incor-rect (unless involving human efforts), the sum of A2 and
A3 is inconsistent with A1, indicating that the VQA model obviously failed to answer at least one perception question.
Similarly for the second case, the sum of A1−4 is not equal 16908
to A, indicating that objects are not correctly recognized in the original image or at least in one cut. In contrast to the overall optimistic view on VQA models’ perception ability and recent thrusts on checking high-level reasoning correct-ness [31, 33, 14], preliminary observations shed light on our key incentive of this research: challenge champions. MetaVQA successfully exposes millions of erroneous answers to perception questions.
VQA models of different architectures manifest dis-tinct accuracy in answering perception questions. We give further discussions and studies to explore poten-tial enhancement of perception tasks.
“Is answering perception questions, as the key-stone of high-level reasoning, really a solved task for VQA models?”
Inspired by principles of software metamorphic testing (MT) [10], this research proposes MetaVQA as a model-agnostic approach to testing VQA models on its understand-In particular, given an image i, ing of perception tasks.
MetaVQA synthesizes a question q focusing on the objects and properties detected in i by object detectors. MetaVQA then performs a set of transformations on q and i to generate transformed q′ ∈ Q and i′ ∈ I. MetaVQA checks whether the answers proposed by a VQA model to Q and I satisfy metamorphic relations (MRs), denoting perception consis-tency, with those produced by the same model to q and i.
Violating MRs denotes a failure of answering perception questions for VQA models.
This work aims to study VQA models in a realistic set-ting and to more clearly delineate the perception ability of
VQA models. MetaVQA is effective and shows promis-ing results when evaluating popular VQA models based on different model architectures. Our approach detects over 4.9 million erroneous answers produced by VQA models that have been extensively trained and have shown high leaderboard performance [2]. In particular, MetaVQA re-veals surprising results that the state-of-the-art VQA model,
GridFeat+MoVie which won the 1st place of the VQA 2020 challenge, has higher error rates in perception tasks than its competitors. We provide a detailed investigation of errors detected by MetaVQA. MetaVQA could facilitate model debugging and serve as assessment criteria in addi-tion to standard leaderboard benchmark. In summary, this work makes the following main contributions:
• At the conceptual level, we advocate assessing VQA models’ perception ability, the trust base of high-level logic reasoning. Our model-agnostic approach effec-tively tests VQA models without any knowledge of their internal structure and without a requirement for manually labeled answers.
• At the technical level, we design MetaVQA as a meta-morphic testing framework that implements a set of question- and image-oriented metamorphic relations (MRs). Each MR asserts one or several perception abilities of the VQA models.
• At the empirical level, we use MetaVQA to test ten popular VQA models, including recent years’ VQA
We have released MetaVQA for results veriﬁcation and benchmarking VQA models [1]. 2. Metamorphic Testing (MT)
Determining the correctness of answers produced by
VQA models for arbitrary question-and-image pairs is te-dious and requires considerable manual effort. Inspired by the principles of MT and its major success in automatically detecting bugs and assessing quality of software, AI mod-els, and Big Data sectors [9, 32, 10, 41, 43, 44], we use
MT to assess VQA model accuracy. The overall strength of
MT lies in its ability to assert model correctness via meta-morphic relations (MRs), without the need to specify the ground truth. Each MR denotes a necessary and usually invariant property of the model. For instance, to test the implementation of sin(x), instead of knowing the expected output of arbitrary ﬂoating-point input x (which is rarely possible), we can assert that the MR sin(x) = sin(π − x) always holds when transforming x. A bug in sin(x) is de-tected when the outputs of sin(x) and sin(π − x) differ.
A properly deﬁned MR obviates the need for manually la-beling answers, thus making VQA model assessment much easier and more ﬂexible without any manual effort.
MetaVQA implements a set of MRs to transform inputs, including both questions and images, and assert whether the
VQA answers to the transformed inputs exhibit perception consistency with answers to the original inputs. Our eval-uation shows that the VQA models are prone to generating perception failures, indicating the effectiveness of MT. 3.