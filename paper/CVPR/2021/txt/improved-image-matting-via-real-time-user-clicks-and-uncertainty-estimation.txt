Abstract
Image matting is a fundamental and challenging prob-lem in computer vision and graphics. Most existing matting methods leverage a user-supplied trimap as an auxiliary in-put to produce good alpha matte. However, obtaining high-quality trimap itself is arduous, thus restricting the applica-tion of these methods. Recently, some trimap-free methods have emerged, however, the matting quality is still far be-hind the trimap-based methods. The main reason is that, without the trimap guidance in some cases, the target net-work is ambiguous about which is the foreground target.
In fact, choosing the foreground is a subjective procedure and depends on the user’s intention. To this end, this pa-per proposes an improved deep image matting framework which is trimap-free and only needs several user click inter-actions to eliminate the ambiguity. Moreover, we introduce a new uncertainty estimation module that can predict which parts need polishing and a following local reﬁnement mod-ule. Based on the computation budget, users can choose how many local parts to improve with the uncertainty guid-ance. Quantitative and qualitative results show that our method performs better than existing trimap-free methods and comparably to state-of-the-art trimap-based methods with minimal user effort. 1.

Introduction
Image matting refers to the task of precisely separating the foreground object from the background and accurately estimating the per-pixel opacity near the boundary. It has been studied by academic and industrial communities for many years. Typical applications include image editing,
† Corresponding Author.
The demo of our real-time user interactive matting system can be ﬁnd at https://youtu.be/pAXydeN-LpQ.
ﬁlm production and virtual background for video confer-encing. Given an input image I, it can be formulated as a mathematical optimization problem as follows:
Ii = αiFi + (1 − αi)Bi, (1) where αi ∈ [0, 1] denotes the opacity of the foreground object at pixel i.
It can be observed that, for each pixel, this problem needs to solve 7 unknown values from only 3 known values. Therefore, it is a highly ill-posed problem.
To address this problem, many classical algorithms [2, 21, 8, 35, 37, 5] have been proposed by leveraging a well-deﬁned trimap to constrain the solution space. The trimap divides the image into three types of areas: foreground, background, and transition regions. Then the matting task is then simpliﬁed as the problem of estimating the unknown values only in the transition region. Based on this simpli-ﬁcation, such trimap-based methods [23, 16, 4] can usually achieve very good performance. However, drawing a suit-able trimap itself is very tedious and time-consuming. For some complex cases, it will even cost more than 10 min-utes. Therefore, it is not that friendly, especially to non-professional users.
With the development of deep learning, some studies[6, 41, 30] that do not require the trimap input emerge recently.
However, their performance is still far behind the trimap-based methods. The main reason is that, without the trimap guidance in some cases, deep networks become ambiguous about which is the foreground target to process. To allevi-ate the ambiguity, a large-scale matting dataset of a certain target category (e.g., portrait) is often required for training.
But this solution is not scalable and expensive. More im-portantly, it will totally fail if the users want to choose some new categories that do not appear in the training set. In our understanding, choosing the foreground is subjective and thus some user hint is unavoidable. And the key challenge is how to minimize the user effort in the interactions.
To overcome the aforementioned limitations, we propose 15374
a novel matting approach that considers both performance and user-friendliness, by introducing user clicks into the matting network. To make the network adaptive to any user clicks, we simulate user clicks during training by adding random points into the foreground and background respec-tively. Compared with trimap-based schemes, our method only requires a few user clicks as hints to indicate the fore-ground and background but can achieve comparable perfor-mance. And in most cases which has no foreground am-biguity problem, ours even does not need any user clicks.
When compared to trimap-free methods, our method does not suffer from the ambiguity problem and performs much better. More importantly, it is easy to extend to any unseen category by adding only a few user clicks.
Besides, we further introduce a new uncertainty estima-tion module and a corresponding uncertainty-guided local reﬁnement network. Parallel to the main alpha matte esti-mation branch, the uncertainty estimation branch can pre-dict which parts need further reﬁnement. Based on the computation budget, the users can choose how many lo-cal parts to improve with the uncertainty guidance. Com-pared to some existing methods that use an extra network for global reﬁnement, this manner is more ﬂexible and efﬁ-cient by avoiding some redundant computation for the well-predicted regions. To the best of our knowledge, we are the
ﬁrst that introduces uncertainty in deep image matting.
To demonstrate the effectiveness of our method, we conduct extensive experiments on both synthetic and real datasets and show superior performance. Ablation analysis also justiﬁes its ﬂexibility and adaptability to new categories unseen in the training set. For better application, a real-time user interactive system is provided.
To summarize, our contributions are three-fold as below:
• We present the ﬁrst attempt that introduces user click interaction into the image matting task. It can effec-tively eliminate the ambiguity and boost the matting performance with minimal user effort. In this sense, it can be seen as a new matting scheme between trimap-based and trimap-free methods.
• We introduce a novel uncertainty estimation module and a corresponding uncertainty-guided local reﬁne-ment network. By using the uncertainty map as hints, the network can perform automatic local reﬁnement to produce more precise details and remove undesired blurring artifacts.
• The experimental results show our method performs considerably better than trimap-free approaches and comparably to state-of-the-art trimap-based methods.
Besides, a real-time user interactive system is built. 2.