Abstract 1.

Introduction
We tackle the problem of learning the geometry of mul-tiple categories of deformable objects jointly. Recent work has shown that it is possible to learn a uniﬁed dense pose predictor for several categories of related objects. However, training such models requires to initialize inter-category correspondences by hand. This is suboptimal and the result-ing models fail to maintain correct correspondences as in-dividual categories are learned. In this paper, we show that improved correspondences can be learned automatically as a natural byproduct of learning category-speciﬁc dense pose predictors. To do this, we express correspondences between different categories and between images and cate-gories using a uniﬁed embedding. Then, we use the latter to enforce two constraints: symmetric inter-category cycle consistency and a new asymmetric image-to-category cycle consistency. Without any manual annotations for the inter-category correspondences, we obtain state-of-the-art align-ment results, outperforming dedicated methods for match-ing 3D shapes. Moreover, the new model is also better at the task of dense pose prediction than prior work.
∗Both authors contributed equally to this work.
Algorithms can nowadays understand well the geometry of speciﬁc object categories such as humans: we have reli-able methods for detecting and segmenting them, extracting their 2D landmarks and dense surface coordinates, as well as reconstructing them in 3D. In principle, these methods can be applied to many other types of objects, such as any kind of animal, from pets to wildlife. In practice, however, doing so is often prohibitively expensive. The main bottle-neck is data acquisition, especially for supervised training in 3D, and extensive manual annotation. High-quality 3D human models are bootstrapped using specialized motion capture systems such as domes that are difﬁcult to apply to objects such as wild animals. Annotating 2D geomet-ric primitives such as segments and 2D keypoints can be done manually from raw images, but it is costly and some-what difﬁcult to do for unfamiliar animal anatomies. Thus, a na¨ıve application of existing high-quality model acquisi-tion techniques cannot trivially scale to learning the mas-sive variety of object types that exist in the world, which include 6.5K mammal species, 7.7M animal species, and around 8.7M natural species overall [9, 34]. 404
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
< l a t e x i t   s h a 1
_ b a s e 6 4
=
" ( n u l l
)
"
> ( n u l l
)
<
/ l a t e x i t
>
The key to scaling is to realize that, while there are in-deed millions of different types of objects, these are not in-dependent. For instance, different cat breeds are relatively similar, so a single ‘cat’ model is likely to work well for all cats, just like a single ‘human’ model has been shown to work well for many different human body shapes [32]. In fact, useful information can likely be shared among fairly different types of objects, such as all mammals or all ani-mals. The limit is given by the ability of the model to rep-resent diverse information while capturing and eliminating redundancies wherever possible. The hope is that such a model could learn the geometry of different object types with a cost which is sub-linear in their number.
A similar idea was recently pursued in [35] for the task of dense pose prediction [17]. Just like 2D pose prediction estimates the location of a small number of distinctive ob-ject landmarks, dense pose estimation does so for a contin-uous set of landmarks, identiﬁed as the point of a 3D tem-plate of the object (ﬁg. 1). The goal is to learn a canonical map, i.e. a function that maps all relevant pixels in an im-age to the corresponding points in the template, thus iden-tifying them. For supervised learning, correspondences be-tween images and templates are collected manually, using a category-speciﬁc template for each example object. As a result, annotations for different object categories are un-related, which makes it hard to learn a universal, category-agnostic object representation.
In order to address this problem, the authors of [35] es-tablish initial point-to-point correspondences between dif-ferent category-speciﬁc templates using a mix of manual annotations and automated interpolation. However, as we show in the experiments, their approach has two shortcom-ings. Firstly, their manual correspondence initialization is somewhat arbitrary and thus likely suboptimal. The second problem, which partially arises from the ﬁrst, is that their initial inter-category correspondences are not maintained while the model is trained, and are eventually ‘forgotten’.
In this paper we argue that, if the goal of the alignment is to facilitate learning a multi-category object representation, an optimal alignment should emerge spontaneously as part of the learning process, thus solving the two issues above.
Our key contribution is thus a new learning formulation for universal canonical maps that induces automatically high-quality intra-category correspondences. The most impor-tant outcome is that the learned maps solve the dense pose prediction problem accurately for several object categories while at the same time putting those in correspondence, al-lowing to transfer information between them.
We base our model on learning a single, universal em-bedding space to express all required correspondences.
Points in the different 3D templates as well as image pixels are mapped to this common space, which allows to com-pute dense template-to-template and image-to-template cor-respondences. Differently from [35], the template embed-dings in this work are not initialized from manually anno-tated inter-category correspondences. Instead, all embed-dings are obtained automatically while learning the canon-ical maps for individual categories while satisfying certain consistency constraints.
For the constraints, we use simple but effective rules.
Apart from the most basic one, which encourages similarity of the embeddings of nearby template points (smoothness), we contribute by introducing two types of cycle-consistency for learning canonical surface mappings: The ﬁrst one en-forces cycle consistency between different 3D templates, which encourages bijective correspondences between them.
Additionally, we note that canonical maps, by establishing correspondences from images to templates, are not bijective but injective, and we show that this can be exploited by an asymmetric form of cycle consistency between images and templates. By using the common embedding space, all such constraints are expressed as differentiable loss terms.
Empirically, we demonstrate several advantages of our new approach compared to [35]. We show that our approach
ﬁnds automatically high-quality correspondences between different object categories without any manual supervision for this task. This is compelling because it shows that, as we hypothesized, there is a natural advantage in learning jointly the geometry of different but related object types. In fact, the 3D correspondences we discover in this manner outper-form the ones discovered by state-of-the-art 3D shape align-ment methods. Finally, our method not only aligns canoni-cal maps, but also improves their quality, resulting in more accurate dense pose prediction than the state of the art. 2.