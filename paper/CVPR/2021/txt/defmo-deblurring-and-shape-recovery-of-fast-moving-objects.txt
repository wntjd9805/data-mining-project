Abstract
Objects moving at high speed appear signiﬁcantly blurred when captured with cameras. The blurry appear-ance is especially ambiguous when the object has complex shape or texture. In such cases, classical methods, or even humans, are unable to recover the object’s appearance and motion. We propose a method that, given a single image with its estimated background, outputs the object’s appear-ance and position in a series of sub-frames as if captured by a high-speed camera (i.e. temporal super-resolution). The proposed generative model embeds an image of the blurred object into a latent space representation, disentangles the background, and renders the sharp appearance. Inspired by the image formation model, we design novel self-supervised loss function terms that boost performance and show good generalization capabilities. The proposed DeFMO method is trained on a complex synthetic dataset, yet it performs well on real-world data from several datasets. DeFMO out-performs the state of the art and generates high-quality tem-poral super-resolution frames. 1.

Introduction
Object blurring is a challenging problem in many image processing and computer vision tasks. The primary sources of image blur are rapid camera motion and object motion combined with long exposure time. Many methods were proposed to address the deblurring task, ranging from image deblurring [14, 35] to video temporal super-resolution [19, 31, 34]. However, they consider only low to medium blur, emerging from global camera blur due to camera motion, defocused camera, or objects moving at moderate speed.
Only recently, specialized algorithms for the deblurring of fast moving objects (FMOs) have been introduced [10, 11, 27]. FMOs are deﬁned as objects that move over a distance larger than their size within the camera exposure time (or within a single time frame in video). FMO detec-tion is important in tracking sports with fast object motion like soccer, tennis, or badminton. It is also beneﬁcial in au-n e p y e k r e s a r e e i b o r e a l l a b y e l l o v r e t h g i l c i m p a c
⇒
I
B
I0/7 I1/7 I2/7 I3/7 I4/7 I5/7 I6/7 I7/7 GT
Figure 1. Temporal super-resolution. Given an input image I depicting a blurred fast moving object and an estimated back-ground B, DeFMO decomposes the image into a series of de-blurred sub-frames with sharp object contours. Examples are from test datasets [10, 11, 27], mobile device footage (lighter), and
YouTube videos (mic, cap). Ground truth (GT) corresponds ei-ther to the high-speed camera frame or a static image. Deblurred images It are sharper than the ’GT’, e.g.’pen’ or ’key’. tonomous driving to detect impacts with stones, birds, or other wildlife. FMOs are frequently found when capturing falling or thrown objects like pieces of fruit, leaves, ﬂying insects, hailstorm, or rain. Any moving object becomes an
FMO in low-light conditions or for long exposure. In other words, one needs to increase the exposure time or the speed of the object to observe an FMO.
We consider a setting where the input is an image with an object moving fast and thus appearing blurred. The task is to reconstruct the hypothetical sub-frames that would have been there if this was a short video captured by a high-speed 3456
camera for the same time interval. The physical generative model that leads to the input blurred frame is assumed to be a temporal integration of underlying sharp sub-frames, each of which has a much shorter exposure time. To simplify the problem complexity, we assume that background without the object is given, e.g. from previous frames in the video or as a static image captured when there is no object. In practice, a median of several previous frames works well.
Prior work on FMO deblurring considers only relatively simple, mostly spherical objects [11, 26, 27]. This prior work typically assumes that the object in motion has a con-stant appearance in all sub-frames.
We propose DeFMO – the ﬁrst to go beyond these as-sumptions by handling the time-varying complex appear-ance of fast moving objects that move over 3D trajectories with 3D rotation. DeFMO is a generative model that recon-structs sharp contours and appearance of FMOs. First, we disentangle the blurred fast moving object from the back-ground into a latent space. Then, a rendering network has the objective to render the sharp object in a series of sub-frames, capturing the motion in time. The network is trained end-to-end on a synthetic dataset with complex, highly tex-tured objects. Thanks to self-supervised loss function terms inspired by the image formation model with FMOs, our method easily generalizes to real-world data, as shown in
Fig. 1. DeFMO can be applied to many ﬁelds, such as video temporal super-resolution, data compression, surveillance, astronomy, and microscopy. Overall, the paper makes the following contributions:
• We present the ﬁrst fully neural network model for FMO deblurring that bridges the gap between deblurring, 3D modeling, and sub-frame tracking of FMOs.
• Training only on synthetic data with novel self-supervised losses sets a new state of the art in terms of trajectory and sharp appearance reconstruction of FMOs.
• We introduce a new synthetic dataset with complex ob-jects, textures, and backgrounds. The dataset and model implementation are made publicly available1. 2.