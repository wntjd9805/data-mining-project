Abstract
Recent advances in OCR have shown that an end-to-end (E2E) training pipeline that includes both detection and recognition leads to the best results. However, many exist-ing methods focus primarily on Latin-alphabet languages, often even only case-insensitive English characters. In this paper, we propose an E2E approach, Multiplexed Multilin-gual Mask TextSpotter, that performs script identiﬁcation at the word level and handles different scripts with differ-ent recognition heads, all while maintaining a uniﬁed loss that simultaneously optimizes script identiﬁcation and mul-tiple recognition heads. Experiments show that our method outperforms the single-head model with similar number of parameters in end-to-end recognition tasks, and achieves state-of-the-art results on MLT17 and MLT19 joint text de-tection and script identiﬁcation benchmarks. We believe that our work is a step towards the end-to-end trainable and scalable multilingual multi-purpose OCR system. Our code and model will be released. 1.

Introduction
Reading text in visual content has long been a topic of interest in computer vision, with numerous practical ap-plications such as search, scene understanding, translation, navigation, and assistance for the visually impaired. In re-cent years, advances in deep learning have led to dramatic improvements of Optical Character Recognition (OCR), al-lowing reading text in increasingly diverse and challeng-ing scene environments with higher accuracy than ever be-fore. A common approach is to decompose the task into two sub-problems: text detection, the localization of text in visual media, and text recognition, the transcription of the detected text. While these two components were tradition-ally learned separately, recent works have shown that they can be learned jointly, with beneﬁts to both modules.
As the most commonly spoken language in the world [1] and a lingua franca for research, the English language has been the focus of many public OCR benchmarks [35, 62, 25, 24, 61, 53] and methods [30, 33, 43, 44]. However, English (and other Latin alphabet languages) represent only a frac-tion of the languages spoken (and written) around the world.
OCR technology is also used to study forgotten languages and ancient manuscripts, where alphabets and script styles can vary enormously [14, 15]. Thus, developing OCR capa-bilities in other languages is also important to ensure such technologies are accessible to everyone. Additionally, be-cause of the increasing interconnectedness of the world and its cultures, it is important to develop OCR systems capable of recognizing text from multiple languages co-occurring in the same scene.
While many concepts and strategies from OCR on En-glish text can be adapted to other languages, developing multilingual OCR systems is not completely straightfor-ward. Naively training a separate system for each lan-guage is computationally expensive during inference and does not properly account for predictions made for other languages. Furthermore, previous works [44, 30] have shown that jointly learning text detection and text recog-nition modules is mutually beneﬁcial; separate models lose out on the potential beneﬁts of a shared text detection mod-ule. On the other hand, learning a uniﬁed model with single recognition head also presents problems. While uncased
English only has 26 characters, many Asian languages like
Chinese, Japanese, and Korean have tens of thousands of characters. Different languages/scripts can also have very different word structures or orientations. For example, ver-tically written text is far more common in East Asian lan-guages like Chinese, Japanese and Korean than in Western languages, and characters in Arabic and Hindi are usually connected to each other. This variability in the number of characters as well as the wide variability in script appear-ance characteristics mean it is highly unlikely that a single architecture can capably maximize accuracy and efﬁciency over all languages/scripts, and any imbalances in the train-ing data may result in signiﬁcantly different performances between languages.
Given these challenges, we present a blend of these two approaches, incorporating each one’s advantages while mit-14547
igating their faults. Speciﬁcally, we propose a single text detection module followed by a text recognition head for each language, with a multiplexer routing the detected text to the appropriate head, as determined by the output of a
Language Prediction Network (LPN). This strategy can be seen as analogous to human perception of text. Locating the words of most languages is easy even without knowing the language, but recognizing the actual characters and words requires special knowledge: language/script identiﬁcation typically precedes recognition.
Notably, this multiplexer design has important implica-tions for real-world text spotting systems. Having language-speciﬁc text recognition heads allows custom design of the architecture depending on the difﬁculty and characteristics of each language, while still sharing and jointly learning the same text detection trunk. New languages can also be eas-ily added to the system without re-training the whole model and worrying about affecting the existing languages.
Our contributions can be summarized as follows:
• We propose an end-to-end trainable multiplexed OCR model that can automatically pick the best recognition head for the detected words.
• We propose a language prediction network using masked pooled features as input and an integrated loss function with the recognition heads.
• We design a training strategy that takes advantage of the proposed losses, allows for easy extension to new languages and addresses the data imbalance problem.
• We empirically show that the multiplexed model con-sistently outperforms single-head model and is less prone to training data distribution bias. 2.