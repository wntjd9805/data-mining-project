Abstract
We address the problem of jointly denoising and super resolving neuromorphic events, a novel visual signal that represents thresholded temporal gradients in a space-time window. The challenge for event signal processing is that they are asynchronously generated, and do not carry ab-solute intensity but only binary signs informing temporal variations. To study event signal formation and degrada-tion, we implement a display-camera system which enables multi-resolution event recording. We further propose Event-Zoom, a deep neural framework with a backbone architec-ture of 3D U-Net. EventZoom is trained in a noise-to-noise fashion where the two ends of the network are unﬁltered noisy events, enforcing noise-free event restoration. For res-olution enhancement, EventZoom incorporates an event-to-image module supervised by high resolution images. Our results showed that EventZoom achieves at least 40× tem-poral efﬁciency compared to state-of-the-art (SOTA) event denoisers. Additionally, we demonstrate that EventZoom enables performance improvements on applications includ-ing event-based visual object tracking and image recon-struction. EventZoom achieves SOTA super resolution im-age reconstruction results while being 10× faster. 1.

Introduction
Neuromorphic events are novel visual signals that ad-dress several limitations of mainstream image signals, par-ticularly featuring low power, low latency and high dynamic range (HDR). These are due to the unique sensor design that enables each event pixel to only compare current and last intensity states in log-scale and ﬁre a binary-signed event whenever the log-intensity variation exceeds the pre-set thresholds [6, 10, 24, 35, 42]. Such sensors are suitable for dynamic visual scenarios thanks to their high sensing speed. Yet event cameras are unable to reveal scene appear-(cid:0) Corresponding author: shiboxin@pku.edu.cn project page: https://sites.google.com/view/EventZoom (a) Our multi-resolution display-camera system. (b) EventZoom results. Blue/red: positive/negative events.
Figure 1: We propose EventZoom, a network that performs event denoising and super resolution. ance, especially under static conditions. Moreover, events are ﬁred asynchronously, resulting in spatio-temporal point clouds rather than conventional 2D image/video sequences.
As such, the problem of event signal restoration and enhancement has strong deviation from its image-based counterpart, and requires deliberate modiﬁcations when applying image-based models. A particular body of the past literature has attended to event-to-image reconstruc-tion [2, 7, 20, 37, 38, 45, 46], and shown that image-based visual algorithms can perform comfortably well on event-reconstructed images [37]. An extended branch explored the beneﬁt events could bring to low-level vision. Such tasks take hybrid inputs of events and images, and perform image/video enhancement in HDR and low-light imaging
[15, 50], video synthesis [49], motion deblur [18, 31], and super resolution [44]. Nonetheless, executing visual tasks 12824
by means of event-to-image conversion consumes heavy computational power and time, calling for compact event-to-event restoration and enhancement.
SOTA event restoration and enhancement solutions rely on the intensity signal [1, 48]. Same-resolution images could be employed to label events and a classiﬁcation net-work is further leveraged for event denoising [1]. However, the labeling of captured events can only identify and remove wrongly-ﬁred events, while it cannot retrieve unﬁred events along with previous noisy event removal ﬁlters [4, 19, 27].
Guided Event Filtering (GEF) [48] enables retrieving miss-ing events as well as 8× super resolution (SR). However,
GEF’s performance relies heavily on 1) the quality of high-resolution (HR) images; 2) the accuracy of optical ﬂow esti-mation, which is computationally expensive. When the HR images are blurry or in lack of spatial features, or when the optical ﬂow fails to register events onto image edges, the
ﬁltering output will yield compromised quality.
We propose EventZoom, an end-to-end neural network approach for event denoising and super resolution (EDSR).
EventZoom performs event-to-event transformation based on a backbone of 3D U-Net [52]. Although the network does not require image supervision, an event-to-image (E2I) module was designed to study the beneﬁt from image sig-nals. The E2I module is a combination of a same-resolution event-to-image reconstruction network E2VID [36] and an image SR network FSRCNN [9]. The last layer features from the two networks are used as low-resolution (LR) and
HR features to be concatenated with the corresponding lay-ers of the 3D U-Net. The input and output are 3D tensors.
Two processing steps are involved for converting the raw events to a 3D tensor (event stacking) and reverting the out-put 3D tensor to events (event re-distributing). Overall, this paper makes the following contributions:
• EventZoom is the ﬁrst network approach to solve
EDSR. EventZoom was built upon 3D U-Net and in-corporated an E2I module to leverage HR image infor-mation, while preserving computational efﬁciency.
• We implemented a display-camera system to collect a multi-resolution event dataset (Fig. 1a), and trained the network in a noise-to-noise fashion without ground truth annotation (Fig. 1b).
• EventZoom was applied to event-based visual object tracking and image reconstruction, and achieved sig-niﬁcant performance improvement. 2.