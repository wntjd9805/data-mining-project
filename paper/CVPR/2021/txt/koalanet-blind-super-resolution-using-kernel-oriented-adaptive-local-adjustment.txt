Abstract
Blind super-resolution (SR) methods aim to generate a high quality high resolution image from a low resolution image containing unknown degradations. However, natural images contain various types and amounts of blur: some may be due to the inherent degradation characteristics of the camera, but some may even be intentional, for aesthetic purposes (e.g. Bokeh effect). In the case of the latter, it becomes highly difﬁcult for SR methods to disentangle the blur to remove, and that to leave as is. In this paper, we pro-pose a novel blind SR framework based on kernel-oriented adaptive local adjustment (KOALA) of SR features, called
KOALAnet, which jointly learns spatially-variant degrada-tion and restoration kernels in order to adapt to the spatially-variant blur characteristics in real images. Our KOALAnet outperforms recent blind SR methods for synthesized LR im-ages obtained with randomized degradations, and we further show that the proposed KOALAnet produces the most natural results for artistic photographs with intentional blur, which are not over-sharpened, by effectively handling images mixed with in-focus and out-of-focus areas. 1.

Introduction
When a deep neural network is trained under a speciﬁc scenario, its generalization ability tends to be limited to that particular setting, and its performance deteriorates under a different condition. This is a major problem in single image super-resolution (SR), where most neural-network-based methods have focused on the upscaling of low resolution (LR) images to high resolution (HR) images solely under the bicubic downsampling setting [13, 15, 16, 26], until very recently. Naturally, their performance tends to severely drop if the input LR image is degraded by even a slightly different downsampling kernel, which is often the case in real images
[23]. Hence, more recent SR methods aim for blind SR,
*Both authors contributed equally to this work.
†Corresponding author. where the true degradation kernels are unknown [5, 8].
However, this unknown blur may be of various types with different characteristics. Often, images are captured with a different depth-of-ﬁeld (DoF) by manipulating the aperture sizes and the focal lengths of camera lenses, for aesthetic purposes (e.g. Bokeh effect) as shown in Fig. 1. Recent mobile devices even try to simulate this synthetically (e.g. portrait mode) for artistic effects [24]. Although a camera-speciﬁc degradation could be spatially-equivariant (similar to the way LR images are generated for SR), the blur generated due to DoF of the camera would be spatially-variant, where some areas are in focus, and others are out of focus. These types of LR images are extremely challenging for SR, since ideally, the intentional blur must be left unaltered (should not be over-sharpened) to maintain the photographer’s intent after SR. However, the SR results of such images are yet to be analyzed in literature.
In this paper, we propose a blind SR framework based on kernel-oriented adaptive local adjustment (KOALA) of SR features, called KOALAnet, by jointly learning the degrada-tion and restoration kernels. The KOALAnet consists of two networks: a downsampling network that estimates spatially-variant blur kernels, and an upsampling network that fuses this information by mapping the predicted degradation ker-nels to the feature kernel space, predicting degradation-speciﬁc local feature adjustment parameters that are applied by spatially-variant local ﬁltering on the SR feature maps.
After training under a random anisotropic Gaussian degrada-tion setting, our KOALAnet is able to accurately predict the underlying degradation kernels and effectively leverage this information for SR. Moreover, it demonstrates a good gen-eralization ability on historic images containing unknown degradations compared to previous blind SR methods. We further provide comparisons on real aesthetic DoF images, and show that our KOALAnet effectively handles images with intentional blur. Our contributions are three-fold:
• We propose a blind SR framework that jointly learns spatially-variant degradation and restoration kernels.
The restoration (upsampling) network leverages novel 10611
Original Depth-of-Field Image
Bicubic
IKC
ZSSR
ZSSR+[2]
Ours
Original
Figure 1: Qualitative comparison on artistic photographs with intentional blur for ×4. Some methods (IKC [8], ZSSR [23]+KernelGAN
[2]) over-sharpen even the background (out-of-focus) regions that should be left blurry, while others generate blurry foreground (in-focus) regions. Our KOALAnet handles both regions well, generating results with similar blurriness characteristics as the original image.
KOALA modules to adaptively adjust the SR fea-tures based on the predicted degradation kernels. The
KOALA modules are extensible, and can be inserted into any CNN architecture for image restoration tasks.
• We empirically show that the proposed KOALAnet out-performs the recent state-of-the-art blind SR methods for synthesized LR images obtained under randomized degradation conditions, as well as for historic LR im-ages with unknown degradations.
• We ﬁrst analyze SR results on images mixed with in-focus and out-of-focus regions, showing that our
KOALAnet is able to discern intentionally blurry areas and process them accordingly, leaving the photogra-pher’s intent unchanged after SR. 2.