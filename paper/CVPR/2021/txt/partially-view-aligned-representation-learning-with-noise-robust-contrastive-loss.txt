Abstract
In real-world applications, it is common that only a por-tion of data is aligned across views due to spatial, tempo-ral, or spatiotemporal asynchronism, thus leading to the so-called Partially View-aligned Problem (PVP). To solve such a less-touched problem without the help of labels, we propose simultaneously learning representation and align-ing data using a noise-robust contrastive loss. In brief, for each sample from one view, our method aims to identify its within-category counterparts from other views, and thus the cross-view correspondence could be established. As the contrastive learning needs data pairs as input, we construct positive pairs using the known correspondences and nega-tive pairs using random sampling. To alleviate or even elim-inate the inﬂuence of the false negatives caused by random sampling, we propose a noise-robust contrastive loss that could adaptively prevent the false negatives from dominat-ing the network optimization. To the best of our knowledge, this could be the ﬁrst successful attempt of enabling con-trastive learning robust to noisy labels. In fact, this work might remarkably enrich the learning paradigm with noisy labels. More speciﬁcally, the traditional noisy labels are de-ﬁned as incorrect annotations for the supervised tasks such as classiﬁcation. In contrast, this work proposes that the view correspondence might be false, which is remarkably different from the widely-accepted deﬁnition of noisy label.
Extensive experiments show the promising performance of our method comparing with 10 state-of-the-art multi-view approaches in the clustering and classiﬁcation tasks. The code will be publicly released at https://pengxi.me. 1.

Introduction
Multi-view Representation Learning (MvRL) [2, 16, 24, 37, 44] aims at learning consistent representations from
∗Corresponding author
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
·
View 1
View 2
View 1
View 2
View 1
View 2 (a) (b) (c)
Figure 1. The motivation of this paper.
In the ﬁgure, different colors denote different instances which will present in multiple views, different shapes indicate different categories, and the dot-ted line denotes the desired correspondence. (a) Partially View-aligned problem: only a portion of data is with the known corre-spondence due to complexity of data collection and transmission; (b) Instance-level alignment: it aims to establish the correspon-dence between two cross-view samples of the same instance; (c)
Category-level alignment: each pair consists of the samples be-longing to the same category. Considering the downstream tasks such as clustering and classiﬁcation, category-level alignment is more desirable than instance-level alignment due to its higher ac-cessibility and scalability. multi-view/modal data to facilitate the downstream tasks in-cluding but not limited to clustering, classiﬁcation, and re-trieval. The success of all existing works [2, 37, 44] heavily relies on two assumptions, i.e., the completeness of data and the consistency of views. To be speciﬁc, the completeness assumption requires that the instances are presented in all views, and the consistency assumption requires that the data from different views must be strictly aligned. When one of these two assumptions is unsatisﬁed, it is impossible to perform MvRL. In practice, however, the two assumptions could be easily violated in data collection or transmission, 1134
thus resulting in Partially Data-missing Problem (PDP) and
Partially View-aligned Problem (PVP, see Fig. 1(a)). More speciﬁcally, PDP happens when some data is missed in some views, thus leading to data incompleteness. PVP refers to the case when only a portion of data is aligned, thus leading to data inconsistency. Recently, several works have made remarkable progress on PDP [15, 27, 40], but only a few studies have been conducted to solve PVP.
In this paper, we try to solve PVP without the help of data annotations. Our observation and motivation are shown in
Fig. 1. Ideally, the data is highly expected to be fully aligned at the instance level as shown in Fig. 1(b). To achieve this goal, a straightforward solution is using the Hungarian al-gorithm as a preprocessing step to build the correspondence of two views and then passing the aligned data into a stan-dard multi-view method to learn representation. However, the performance of such a two-stage learning paradigm is sub-optimal because the Hungarian algorithm i) cannot be applied to the multi-view raw spaces which are heteroge-neous; and ii) will not utilize the known correspondence in data. In very recent, Partially View-aligned Clustering (PVC) [18] proposed a differentiable neural module of the
Hungarian algorithm, and thus data alignment and repre-sentation learning could be achieved in a one-stage man-ner. However, both the vanilla Hungarian algorithm and
PVC aim to achieve instance-level alignment which might be over-sufﬁcient to multi-view clustering and classiﬁca-tion. Different from the one-to-one mapping tasks like re-trieval [8, 17], the essence of clustering and classiﬁcation is a one-to-many mapping. Therefore, the category-level alignment is more desirable than the instance-level align-ment for clustering and classiﬁcation thanks to its higher accessibility and scalability. Intuitively, for a given cross-view instance, it has a random probability of 1/N and 1/K to be aligned at the instance- and category-level correctly, where N and K are the number of instances and categories, and K ≪ N . In other words, the category-level alignment enjoys higher accessibility. On the other hand, the compu-tational complexity of the instance-level alignment methods such as the Hungarian algorithm is O(N 3) which prohibits it from handling large-scale datasets.
Based on the above observation and motivation, we solve
PVP by trying to achieve the category- instead of instance-level alignment as shown in Fig. 1(c). To the end, we propose a novel partially view-aligned representation learn-ing method, termed Multi-view Contrastive Learning with
Noise-robust loss (MvCLN). Our basic idea is reformulat-ing the view alignment problem as an identiﬁcation task.
Speciﬁcally, taking bi-view data as a showcase, for each sample from one view, MvCLN aims to identify its coun-terparts that belong to the same category from the other view. To train MvCLN, we construct the positive pairs us-ing the available aligned data and the Negative Pairs (NP) using random sampling. To alleviate or even eliminate the inﬂuence of the False-Negative Pairs (FNP) caused by ran-dom sampling, our MvCLN is with a novel noise-robust contrastive loss. The contributions of this work could be summarized as follows:
• To facilitate one-to-many mapping tasks like cluster-ing, we propose solving PVP by establishing category-rather than instance-level alignment. Such a task-speciﬁc alignment enjoys higher accessibility and scal-ability as shown in the above analysis and the follow-ing experiments;
• We reformulate the alignment problem as a view iden-tiﬁcation task which is further performed under the contrastive learning framework. To the best of our knowledge, this could be one of the ﬁrst works by em-ploying contrastive learning to achieve the category-level alignment;
• To establish the view correspondence using contrastive learning, we propose a novel noise-robust contrastive loss which could alleviate or even eliminate the inﬂu-ence of noisy labels (i.e., FNP) introduced during pair construction. As far as we know, this could be the ﬁrst contrastive learning method with the capacity of han-dling noisy labels. It should be pointed out that, the traditional noisy labels are deﬁned as incorrect an-notations for the supervised tasks such as classiﬁca-tion. In contrast, this work proposes that the view correspondence might be false, which is remark-ably different from the traditional deﬁnition. As a result, our study might enrich the learning paradigm with noisy labels. 2.