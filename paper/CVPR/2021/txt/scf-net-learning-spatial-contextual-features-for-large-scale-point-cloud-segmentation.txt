Abstract
How to learn effective features from large-scale point clouds for semantic segmentation has attracted increasing attention in recent years. Addressing this problem, we pro-pose a learnable module that learns Spatial Contextual Fea-tures from large-scale point clouds, called SCF in this pa-per. The proposed module mainly consists of three blocks, including the local polar representation block, the dual-distance attentive pooling block, and the global contextual feature block. For each 3D point, the local polar represen-tation block is ﬁrstly explored to construct a spatial repre-sentation that is invariant to the z-axis rotation, then the dual-distance attentive pooling block is designed to utilize the representations of its neighbors for learning more dis-criminative local features according to both the geometric and feature distances among them, and ﬁnally, the global contextual feature block is designed to learn a global con-text for each 3D point by utilizing its spatial location and the volume ratio of the neighborhood to the global point cloud. The proposed module could be easily embedded into various network architectures for point cloud segmentation, naturally resulting in a new 3D semantic segmentation net-work with an encoder-decoder architecture, called SCF-Net in this work. Extensive experimental results on two public datasets demonstrate that the proposed SCF-Net performs better than several state-of-the-art methods in most cases. 1.

Introduction
With the rapid development of 3D sensors, semantic seg-mentation of 3D point clouds has attracted more and more attention in the computer vision ﬁeld. Compared with 2D images, 3D point clouds could provide richer geometric in-†Corresponding author.
Figure 1. Diagram of the spatial contextual feature (SCF) module. formation of scenes. However, semantic segmentation of 3D point clouds, particularly segmentation of large-scale point clouds, is still a challenging task due to the fact that 3D point clouds are generally unstructured and unordered.
In recent years, a lot of DNN (Deep Neural Network)-based methods have been proposed for segmenting 3D point clouds [29, 30, 40, 22, 46, 10]. These methods could be roughly divided into 3 categories [11]: projection-based methods [21, 2], discretization-based methods [10, 33, 27, 15], and point-based methods [14, 39, 35, 7, 46, 44, 3, 29, 30, 45]. Both the projection-based and discretization-based methods are computationally expensive to handle large-scale point clouds, which need extra procedures to trans-form point clouds to a regular representation and project the intermediate segmentation results back to the point clouds.
Different from those methods, point-based methods directly work on 3D point clouds. Although some existing point-based methods have achieved promising performances on small-sized point clouds, they could not deal with the large-scale point clouds. Recently, some methods designed for large-scale point clouds have been proposed, such as SPG
[20], PCT [4] and RandLA-Net [13]. However, most of them still have to confront with the following problem: how to learn more effective features from large-scale point clouds for semantic segmentation? 14504
Inspired by the success of contextual information in many visual tasks [43, 5, 24, 19, 28], we investigate how to learn spatial contextual features from large-scale point clouds for semantic segmentation here. We decompose the aforementioned problem into three sub-problems as: 1) how to represent the local context of a 3D point? 2) how to learn local contextual features? 3) how to learn global contextual features?
Addressing the three subproblems, we propose a learn-able module, called SCF in this paper, consisting of 3 blocks, including the local polar representation block, the dual-distance attentive pooling block, and the global con-textual feature block. The diagram of SCF is shown in
Figure 1. For each 3D point, the local polar representa-tion block is ﬁrstly explored to construct a z-axis rotation-invariant representation in a polar coordinate system for representing the local context. Then the representations of its neighbors are integrated to learn effective local features by utilizing the weights learnt by the dual-distance attentive pooling block. Finally, the global contextual feature block learns global context of each 3D point by utilizing both the location and the volume ratio of the neighborhood. Vari-ous network architectures could utilize the proposed module
SCF for point cloud segmentation, and under an encoder-decoder architecture, a new 3D semantic segmentation net-work is presented, called SCF-Net in this work. In sum, the main contributions are listed as follows:
• We propose the Local Polar Representation (LPR) block, which could learn locally z-axis rotation-invariant representation for each 3D point.
• We propose the Dual-Distance Attentive Pooling (DDAP) block, which could automatically learn effec-tive local features based on both the geometric and fea-ture distances.
• We propose the Global Contextual Feature (GCF) block, which could learn the global context of each 3D point from the point cloud.
• We propose the SCF module, which could be applied to various architectures for exploring new point cloud segmentation networks. Extensive experimental re-sults in Section 4 demonstrate that the proposed SCF-Net by embedding the SCF module into a standard encoder-decoder architecture achieves state-of-the-art performances. 2.