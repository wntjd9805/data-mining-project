Abstract
Generalized zero-shot learning (GZSL) aims to recog-nize objects from both seen and unseen classes, when only the labeled examples from seen classes are provided. Re-cent feature generation methods learn a generative model that can synthesize the missing visual features of unseen classes to mitigate the data-imbalance problem in GZSL.
However, the original visual feature space is suboptimal for
GZSL classiﬁcation since it lacks discriminative informa-tion. To tackle this issue, we propose to integrate the gen-eration model with the embedding model, yielding a hybrid
GZSL framework. The hybrid GZSL approach maps both the real and the synthetic samples produced by the genera-tion model into an embedding space, where we perform the
ﬁnal GZSL classiﬁcation. Speciﬁcally, we propose a con-trastive embedding (CE) for our hybrid GZSL framework.
The proposed contrastive embedding can leverage not only the class-wise supervision but also the instance-wise su-pervision, where the latter is usually neglected by existing
GZSL researches. We evaluate our proposed hybrid GZSL framework with contrastive embedding, named CE-GZSL, on ﬁve benchmark datasets. The results show that our CE-GZSL method can outperform the state-of-the-arts by a sig-niﬁcant margin on three datasets. Our codes are available on https://github.com/Hanzy1996/CE-GZSL. 1.

Introduction
Object recognition is a core problem in computer vision.
This problem on a ﬁxed set of categories with plenty of training samples has progressed tremendously due to the ad-*Corresponding authors.
†Zongyan Han, Zhenyong Fu and Jian Yang are with PCA Lab, Key
Lab of Intelligent Perception and Systems for High-Dimensional Informa-tion of Ministry of Education, and Jiangsu Key Lab of Image and Video
Understanding for Social Security, School of Computer Science and Engi-neering, Nanjing University of Science and Technology, China.
Figure 1: Existing semantic embedding methods merely uti-lize the class-wise supervision, which may be unsuitable for some examples as they do not match exactly with the class-level semantic descriptor. The proposed contrastive embed-ding can utilize not only the class-wise supervision but also the instance-wise supervision. vent of deep convolutional neural networks [37]. However, realistic object categories often follow a long-tail distribu-tion, where some categories have abundant training samples and the others have few or even no training samples avail-able. Recognizing the long-tail distributed object categories is challenging, mainly because of the imbalanced training sets of these categories. Zero-Shot Learning (ZSL) [39, 54] holds the promise of tackling the extreme data imbalance between categories, thus showing the potential of address-ing the long-tail object recognition problem. Zero-shot learning aims to classify objects from previously unseen categories without requiring the access to data from those categories. In ZSL, a recognition model is ﬁrst learned on the seen categories, of which the training samples are pro-vided. Relying on the category-level semantic descriptors, such as visual attributes [16, 39] or word vectors [47, 48],
ZSL can transfer the recognition model from seen to unseen object categories in a data-free manner.
In zero-shot learning, we have the available data from seen classes for training. Conventional zero-shot learn-2371
ing [1, 62] assumes that the test set contains the samples from unseen classes only, while in the recent proposed Gen-eralized Zero-Shot Learning (GZSL) [10, 71], the test set is composed of the test samples from both seen and un-seen classes. A large body of conventional ZSL methods learns a semantic embedding function to map the visual fea-tures into the semantic descriptor space [18, 2, 58, 75, 22].
In the semantic space, we can conduct the ZSL classiﬁca-tion by directly comparing the embedded data points with the given class-level semantic descriptors. Semantic em-bedding methods excel in conventional ZSL, yet their per-formance degrades substantially in the more challenging
GZSL scenario, owing to their serious bias towards seen classes in the testing phase [69]. Conventional ZSL is un-necessary to worry about the bias problem towards seen classes as they are excluded from the testing phase. But in GZSL the bias towards seen classes will make the GZSL model misclassify the testing images from unseen classes.
To mitigate the bias problem in GZSL, feature genera-tion based GZSL methods have been proposed [7, 50, 38, 70, 72, 61] to synthesize the training samples for unseen classes. The feature generation method can compensate for the lack of training samples of unseen classes. Merging the real seen training features and the synthetic unseen features yields a fully-observed training set for both seen and un-seen classes. Then we can train a supervised model, such as a softmax classiﬁer, to implement the GZSL classiﬁcation.
However, the feature generation methods produce the syn-thesized visual features in the original feature space. We conjecture that the original feature space, far from the se-mantic information and thus lack of discriminative ability, is suboptimal for GZSL classiﬁcation.
To get the best of both worlds, in this paper, we propose a hybrid GZSL framework, grafting an embedding model on top of a feature generation model.
In our framework, we map both the real seen features and the synthetic unseen features produced by the feature generation model to a new embedding space. We perform the GZSL classiﬁcation in the new embedding space, but not in the original feature space.
Instead of adopting the commonly-used semantic em-bedding model [18, 2], we propose a contrastive embed-ding in our hybrid GZSL framework. The traditional se-mantic embedding in ZSL relies on a ranking loss, which requires the correct (positive) semantic descriptor to be ranked higher than any of wrong (negative) descriptors with respect to the embedding of a training sample. The seman-tic embedding methods only utilize the class-wise supervi-sion. In contrastive embedding, we wish to exploit not only the class-wise supervision but also the instance-wise super-vision for GZSL, as depicted in Figure 1. Our proposed contrastive embedding learns to discriminate between one positive sample (or semantic descriptor) and a large number of negative samples (or semantic descriptors) from differ-ent classes by leveraging the contrastive loss [24, 53, 67].
We evaluate our method on ﬁve benchmark datasets, and to the best of our knowledge, our method can outperform the state-of-the-arts on three datasets by a large margin and achieve competitive results on the other two datasets.
Our contributions are three-fold: (1) we propose a hybrid
GZSL framework combining the embedding based model and the feature generation based model; (2) we propose a contrastive embedding, which can utilize both the class-wise supervision and the instance-wise supervision, in our hybrid GZSL framework; and (3) we evaluate our GZSL model on ﬁve benchmarks and our method can achieve the state-of-the-arts or competitive results on these datasets. 2.