Abstract
Mixture image
Reflection scene
Transmission scene
This paper studies the problem of panoramic image re-ﬂection removal, aiming at reliving the content ambigu-ity between reﬂection and transmission scenes. Although a partial view of the reﬂection scene is included in the panoramic image, it cannot be utilized directly due to its misalignment with the reﬂection-contaminated image. We propose a two-step approach to solve this problem, by ﬁrst accomplishing geometric and photometric alignment for the reﬂection scene via a coarse-to-ﬁne strategy, and then restoring the transmission scene via a recovery network.
The proposed method is trained with a synthetic dataset and veriﬁed quantitatively with a real panoramic image dataset.
The effectiveness of the proposed method is validated by the signiﬁcant performance advantage over single image-based reﬂection removal methods and generalization capacity to limited-FoV scenarios captured by conventional camera or mobile phone users. 1.

Introduction
Single-image reﬂection removal addresses a severely ill-posed problem of recovering the transmission T from a reﬂection-contaminated or mixture image M. A general image formation model of M is formulated as [11]
M = Ω ⊙ T + Φ ⊙ R, (1) where ⊙ is the element-wise multiplication operator, Ω and Φ are the refractive and reﬂective amplitude coefﬁcient map, and R is the reﬂection scene [37]. The major chal-lenge of this problem is that both T and R are part of dif-ferent natural scenes, arousing the difﬁculty to differentiate the dominant content for M. We call it content ambiguity in this paper. Early methods address it through content-free priors, e.g., sparse distribution of reﬂection gradients [17] or ghosting cues [27], while state-of-the-art methods leverage
#Equal contribution. ∗Corresponding author.
Ours
IBCLN
KH20
Figure 1. An example of our testing data and reﬂection removal results from our method, IBCLN [14], and KH20 [9]. both content and content-free priors from a large scale of training data, e.g., LBCLN [14] and Kim et al. [9] (denoted as ‘KH20’ for brevity). Unfortunately, different distribu-tions of T and R modeled by low-level or deep priors are not always observed in real scenarios, especially for strong reﬂections with sharp edges. Figure 1 displays an example where state-of-the-art methods fail to remove strong reﬂec-tions.
The content ambiguity could be signiﬁcantly relieved if we can (partially) capture the reﬂection scene. Fortu-nately, with the development of image stitching technol-ogy (e.g., [6]), capturing panoramic images (also called
’panorama’) becomes handily available, i.e., by either off-the-shelf panoramic cameras for professionals (e.g., Ricoh
Theta series and Insta360 Pro series etc.) or camera phones for casual users (e.g., panorama photography is a stan-dard function for almost all smartphones nowadays such as Google Pixel and Apple iPhone etc.). A panoramic im-age has 360◦ ﬁeld-of-view (FoV) and naturally contains a partial view of the reﬂection scene within a single shot, as 7762
Figure 2. (a) Camera model of capturing a scene containing a glass plate by a panoramic camera. (b) Captured panoramic image. (c) Glass-reﬂected reﬂection image RG, which is ‘captured’ by the virtual camera. (d) Illustration of the geometric and photometric misalignment. (e) Panoramic reﬂection scene RP, which is captured by the real camera. shown in Figure 2 (b). This motivates us to relieve the con-tent ambiguity of reﬂection removal with a panoramic im-age.
Given a panoramic image, it seems to be straightfor-ward to solve Equation (1) and remove reﬂections, since
R has been ‘captured’ and Ω and Φ can be further simpli-ﬁed (e.g., by assuming they are uniform across each image, as commonly adopted by previous works [38]). However, as shown in Figure 2 (a) and (b), the panoramic reﬂection scene captured by the real camera (i.e., RP) is not the glass-reﬂected reﬂection image ‘captured’ by the virtual camera (i.e., RG = Φ ⊙ R). There exists geometric and photo-metric misalignment between the panoramic view RP and the glass-reﬂected view RG, as shown in Figure 2 (c)−(e).
The geometric misalignment is mainly caused by different positions of the real camera and the virtual one formed by glass, while the photometric misalignment is aroused from light attenuation when interacting with glass.
In this paper, we consider reﬂection removal using a sin-gle panoramic image. We solve this problem with a two-step solution including reﬂection alignment and transmis-sion recovery. The ﬁrst step adopts a coarse-to-ﬁne strat-egy to align RP to RG. The coarse alignment is achieved by a pre-processing procedure that explicitly considers mis-alignment factors (Section 3.2), while the ﬁne-grained one is accomplished by a reﬂection reﬁnement network which imposes the mutual information between RP and M (Sec-tion 3.3). With a precisely aligned RG, the second step uti-lizes a transmission recovery network to restore T from M with the guidance of RG (Section 3.4). Our contributions can be summarized as follows:
• We present the ﬁrst work to explicitly relieve the content ambiguity for reﬂection removal using a panoramic image.
• We solve the geometric and photometric misalign-ment between reﬂection scenes in panoramic and glass-reﬂected views, accompanying with high-ﬁdelity transmission recovery after the alignment.
• We show that our method not only achieves supe-rior performance advantage over single-image meth-ods but also generalizes well to casual users without panoramic cameras. 2.