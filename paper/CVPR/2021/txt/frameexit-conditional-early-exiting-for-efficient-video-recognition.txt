Abstract
In this paper, we propose a conditional early exiting framework for efﬁcient video recognition. While existing works focus on selecting a subset of salient frames to re-duce the computation costs, we propose to use a simple sampling strategy combined with conditional early exiting to enable efﬁcient recognition. Our model automatically learns to process fewer frames for simpler videos and more frames for complex ones. To achieve this, we employ a cas-cade of gating modules to automatically determine the ear-liest point in processing where an inference is sufﬁciently reliable. We generate on-the-ﬂy supervision signals to the gates to provide a dynamic trade-off between accuracy and computational cost. Our proposed model outperforms com-peting methods on three large-scale video benchmarks. In particular, on ActivityNet1.3 and mini-kinetics, we outper-form the state-of-the-art efﬁcient video recognition methods with 1.3× and 2.1× less GFLOPs, respectively. Addition-ally, our method sets a new state of the art for efﬁcient video understanding on the HVU benchmark. 1.

Introduction
With the massive growth in the generation of video con-tent comes an increasing demand for efﬁcient and scal-able action or event recognition in videos. The astound-ing performance of deep neural networks for action recog-nition [5, 43, 58, 12, 42, 56] are obtained by densely ap-plying 2D [56, 31, 58, 13] or 3D [40, 5, 18, 12] models over video frames. Despite demonstrating top-notch perfor-mance in recognizing complex and corner case actions, the high data volumes, compute demands, and latency require-ments, limit the application of the state-of-the-art video recognition models on resource-constrained devices.
Extensive studies have been conducted to remedy this issue by designing efﬁcient and light-weight architec-tures [35, 11, 43, 36, 53, 59, 42, 28, 31, 10]. These models have a static computational graph and treat all the videos
*Equal contribution
†Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc
Figure 1: Efﬁcient video recognition by early exiting.
Our proposed method adjusts the amount of computation to the difﬁculty of the input, allowing for signiﬁcant reduc-tion of computational costs. Videos are adopted from [21, 22, 23]. equally regardless of how complex or easy they are for recognition and hence yield sub-optimal results. A large body of research has been focusing on selecting a subset of salient frames to efﬁciently process the video conditioned on the input [55, 52, 57, 8, 15, 29]. Current methods for frame selection rely on learning a policy function to de-termine what action should be taken on the selected frame (e.g. process by a heavy recognition model [51], process at a speciﬁc spatial resolution [33], etc.). Most of these methods either rely on the assumption that salient frames for the sampler network are also salient for the recognition network [29, 15] or require carefully selected reward func-tions in case of using policy gradient methods [55, 52, 49].
Moreover, the sampler network may create an additional computational overhead to the model.
An alternative promising direction to reduce the com-putational complexity of analyzing video content is condi-tional compute using early exiting. Early exiting has re-cently been explored for image classiﬁcation tasks by in-serting a cascade of intermediate classiﬁers throughout the network [30, 39, 54, 24]. In this line of work, the model adjusts the amount of computation to the difﬁculty of the 115608
input and allows for signiﬁcant reduction of computational requirements. Inspired by that, we design an efﬁcient video recognition model that performs automatic early exiting by adjusting the computational budget on a per-video basis.
Our motivation is that a few frames are sufﬁcient for classi-fying “easy” samples, and only some “hard” samples need temporally detailed information (see Figure 1).
In this paper, we propose FrameExit, a conditional early exiting framework with learned gating units that decide to stop the computation when an inference is sufﬁciently reli-able. FrameExit has T classiﬁers accompanied by their as-sociated gates that are attached at different time steps to al-low early exiting. The gates are learned in a self-supervised fashion to control the trade-off between model accuracy and total computation costs. We use the recognition loss as a proxy to generate on-the-ﬂy pseudo-labels to train the gates.
Additionally, our early exiting mechanism combined with a simple, deterministic sampling strategy obviates the need for complex sampling policy functions and yet achieves excellent recognition performance. Finally, we propose an accumulated feature pooling module to generate video representations that enable more reliable predictions by the model. Our contributions are as follows:
• We propose a method that employs a simple, determin-istic frame sampling strategy, combined with an accu-mulated feature pooling module to obtain accurate ac-tion recognition results.
• We propose a conditional early exiting framework for efﬁcient video recognition. We use a cascade of gating modules to determine when to stop further processing of the video. The gates adapt the amount of computa-tion to the difﬁculty of an input video, leading to sig-niﬁcant reductions in computational costs.
• We show state-of-the-art performance on three large-scale datasets. In all cases, we greatly improve the in-ference efﬁciency at a better or comparable recognition accuracy. In particular, on the HVU [7] dataset, we re-port 5× reduction in computation costs while improv-ing the recognition accuracy upon the state-of-the-art methods. 2.