Abstract and smoking scenes.
Most of the existing deep learning-based dehazing meth-ods are trained and evaluated on the image dehazing datasets, where the dehazed images are generated by only exploiting the information from the corresponding hazy ones.
On the other hand, video dehazing algorithms, which can acquire more satisfying dehazing results by exploiting the temporal redundancy from neighborhood hazy frames, re-ceive less attention due to the absence of the video dehazing datasets. Therefore, we propose the ﬁrst REal-world VIdeo
DEhazing (REVIDE) dataset which can be used for the su-pervised learning of the video dehazing algorithms. By utilizing a well-designed video acquisition system, we can capture paired real-world hazy and haze-free videos that are perfectly aligned by recording the same scene (with or without haze) twice. Considering the challenge of exploit-ing temporal redundancy among the hazy frames, we also develop a Conﬁdence Guided and Improved Deformable
Network (CG-IDN) for video dehazing. The experiments demonstrate that the hazy scenes in the REVIDE dataset are more realistic than the synthetic datasets and the proposed algorithm also performs favorably against state-of-the-art dehazing methods. 1.

Introduction
Images and videos captured from the hazy scenes in-evitably suffer from limited visibility and low color satu-ration due to the particles in the haze that will scatter and absorption the light and decrease the albedo of the viewed scene. The goal of the dehazing algorithms is to remove the haze and restore a haze-free scene by given a hazy image or video. This problem has received signiﬁcant attention since the dehazing algorithm is a necessary pre-processing step for many high-level vision tasks (e.g., scene understanding [31] and detection [18]) applied on the outdoor haze, indoor ﬁre,
*These authors contributed equally to this work.
†Corresponding author.
Recently, the introduction of new techniques from ma-chine learning and deep learning provides a broader perspec-tive for dehazing problem and achieves impressive results.
Existing deep learning-based methods [9, 27, 40, 17, 38] are usually trained on the synthetic datasets [19], in which the hazy scene I is formulated by:
I(x) = T (x)J(x) + (1 − T (x))A, (1) where J denotes the haze-free scene, A describes the global atmospheric light indicating the intensity of ambient light, T is the transmission map, and x represents the pixel position.
However, the scattering atmosphere model in Equ. (1) has shown several limitations: it cannot formulate realistic hazy scenes with active light sources [20], with non-homogeneous haze [5], with dense haze layer [4], and under complex illumination conditions. Therefore, the networks trained on these synthetic datasets often generate unsatisﬁed results when handling real-world inputs due to the domain shift [34].
Recently, Some realistic image dehazing datasets [6, 3, 4, 5] are introduced to provide benchmarks for training and evaluating real-world dehazing algorithms. Since then, great progress has been made in the study of the real-world image dehazing task [2, 7, 8].
Although signiﬁcant achievements have been made in sin-gle image dehazing task, we believe that video dehazing al-gorithms can achieve better results by utilizing the temporal redundancy from neighboring frames. However, due to the difﬁculty of collecting real-world video dehazing datasets, the video dehazing task receives less attention than image dehazing [32]. Although plenty of synthetic hazy videos can be obtained by using Equ. (1) [19], the domain gap between synthetic and real-world hazy videos makes these synthetic datasets low practical value. Therefore, collecting a real-world video dehazing dataset for deep learning-based algorithms is a challenging but valuable work.
In this paper, we build a Consecutive Frames Acquisition
System (CFAS), which can be used for collecting paired videos via a controllable robot arm. By utilizing the accurate 9239
relocation ability of the robot arm, the system can record the acquisition points of the last collected video and collect another but exactly the same video if the scene does not change. With the newly-designed video acquisition system and professional haze machines, we can collect the pairs of real hazy and corresponding haze-free videos by gener-ating high ﬁdelity haze between the acquisition of the two videos. By collecting real hazy and corresponding haze-free videos on various indoor scenes, we contribute the REal-world VIdeo DEhazing (REVIDE) Dataset, the ﬁrst video dehazing dataset for supervised learning. Both subjective and objective experiments indicate that the REVIDE dataset contains more realistic hazy frames than the synthetic one, which can help the training and evaluating processes of real-world video dehazing algorithms.
Since the haze spreads over the whole scenes and the den-sity of the haze may change across the neighboring frames of a video, temporal alignment and exploiting temporal re-dundancy are challenging in real-world video dehazing algo-rithms. In this paper, we present a Conﬁdence Guided and
Improved Deformable Network (CG-IDN) for video dehaz-ing. We show that a conﬁdence guided pre-dehazing module and the cost volume [36] can beneﬁt the deformable align-ment module by improving the accuracy of the estimated offsets. Moreover, the conﬁdence map can also be used as guidance for multi-feature fusion. Extensive evaluations demonstrate that the proposed algorithm performs favorably against state-of-the-art video and image dehazing methods.
The contributions of this work are summarized as follows:
• In this paper, we collect a real-world video dehazing dataset containing pairs of real hazy and corresponding haze-free videos. To the best of our knowledge, the proposed dataset is the ﬁrst real-world video dehazing dataset for supervised learning.
• We conduct extensive subjective and objective experi-ments to demonstrate that the collected hazy scenes in the proposed dataset are more realistic than those of syn-thetic datasets, which provides a valuable benchmark for training and evaluating real-world video dehazing algorithms.
• We propose a Conﬁdence Guided and Improved De-formable Network (CG-IDN) for video dehazing and validate its effectiveness in real-world video dehazing tasks. 2.