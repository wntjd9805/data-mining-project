Abstract
With the rapid advances of autonomous driving, it be-comes critical to equip its sensing system with more holistic 3D perception. However, existing works focus on parsing either the objects (e.g. cars and pedestrians) or scenes (e.g. trees and buildings) from the LiDAR sensor. In this work, we address the task of LiDAR-based panoptic segmenta-tion, which aims to parse both objects and scenes in a uni-ﬁed manner. As one of the ﬁrst endeavors towards this new challenging task, we propose the Dynamic Shifting Network (DS-Net), which serves as an effective panoptic segmenta-tion framework in the point cloud realm. In particular, DS-Net has three appealing properties: 1) strong backbone de-sign. DS-Net adopts the cylinder convolution that is specif-ically designed for LiDAR point clouds. The extracted fea-tures are shared by the semantic branch and the instance branch which operates in a bottom-up clustering style. 2)
Dynamic Shifting for complex point distributions. We ob-serve that commonly-used clustering algorithms like BFS or
DBSCAN are incapable of handling complex autonomous driving scenes with non-uniform point cloud distributions and varying instance sizes.
Thus, we present an efﬁ-cient learnable clustering module, dynamic shifting, which adapts kernel functions on-the-ﬂy for different instances. 3)
Consensus-driven Fusion. Finally, consensus-driven fu-sion is used to deal with the disagreement between seman-tic and instance predictions. To comprehensively evalu-ate the performance of LiDAR-based panoptic segmenta-tion, we construct and curate benchmarks from two large-scale autonomous driving LiDAR datasets, SemanticKITTI and nuScenes. Extensive experiments demonstrate that our proposed DS-Net achieves superior accuracies over current state-of-the-art methods. Notably, we achieve 1st place on the public leaderboard of SemanticKITTI, outperforming 2nd place by 2.6% in terms of the PQ metric 1. 1.

Introduction
Autonomous driving, one of the most promising appli-cations of computer vision, has achieved rapid progress in recent years. Perception system, one of the most important modules in autonomous driving, has also attracted extensive studies in previous research works. Admittedly, the clas-sic tasks of 3D object detection [18, 24, 32] and semantic segmentation [20, 30, 35] have developed relatively mature 1Accessed at 2020-11-16.
Codes are available at https : / / github.com/hongfz16/DS-Net. 13090
solutions that support real-world autonomous driving pro-totypes. However, there still exists a considerable gap be-tween the existing works and the goal of holistic perception which is essential for the challenging autonomous driving scenes. In this work, we propose to close the gap by explor-ing the task of LiDAR-based panoptic segmentation, which requires full-spectrum point-level predictions.
Panoptic segmentation has been proposed in 2D detec-tion [15] as a new vision task which uniﬁes semantic and instance segmentation. Behley et al. [3] extend the task to
LiDAR point clouds and propose the task of LiDAR-based panoptic segmentation. As shown in Fig. 1 (a), this task re-quires to predict point-level semantic labels for background (stuff ) classes (e.g. road, building and vegetation), while in-stance segmentation needs to be performed for foreground (things) classes (e.g. car, person and cyclist).
Nevertheless, the complex point distributions of LiDAR data make it difﬁcult to perform reliable panoptic segmen-tation. Most existing point cloud instance segmentation methods [10, 14] are mainly designed for dense and uni-form indoor point clouds. Therefore, decent segmentation results can be achieved through the center regression and heuristic clustering algorithms. However, due to the non-uniform density of LiDAR point clouds and varying sizes of instances, the center regression fails to provide ideal point distributions for clustering. The regressed centers usually form noisy strip distributions that vary in density and sizes.
As will be analyzed in Section 3.2, several heuristic cluster-ing algorithms widely used in previous works cannot pro-vide satisfactory clustering results for the regressed centers of LiDAR point clouds. To tackle the above mentioned technical challenges, we propose Dynamic Shifting Net-work (DS-Net) which is speciﬁcally designed for effective panoptic segmentation of LiDAR point clouds.
Firstly, we adopt a strong backbone design and provide
Inspired by [37], the a strong baseline for the new task. cylinder convolution is used to efﬁciently extract grid-level features for each LiDAR frame in one pass which are further shared by the semantic and instance branches.
Secondly, we present a novel Dynamic Shifting Mod-ule designed to cluster on the regressed centers with com-plex distributions produced by the instance branch. As illus-trated in Fig. 1 (b), the proposed dynamic shifting module shifts the regressed centers to the cluster centers. The shift targets xi are adaptively computed by weighting across sev-eral shift candidates cij which are calculated through kernel functions kj. The special design of the module makes the shift operation capable of dynamically adapting to the den-sity or sizes of different instances and therefore shows supe-rior performance on LiDAR point clouds. Further analysis also shows that the dynamic shifting module is robust and not sensitive to parameter settings.
Thirdly, the Consensus-driven Fusion Module is pre-sented to unify the semantic and instance results to obtain panoptic segmentation results. The proposed consensus-driven fusion mainly solves the disagreement caused by the class-agnostic style of instance segmentation. The fusion module is highly efﬁcient, thus brings negligible computa-tion overhead.
Extensive experiments on SemanticKITTI demonstrate the effectiveness of our proposed DS-Net. To further illustrate the generalizability of DS-Net, we customize a LiDAR-based panoptic segmentation dataset based on nuScenes. As one of the ﬁrst works for this new task, we present several strong baseline results by combining the state-of-the-art semantic segmentation and detection meth-ods. DS-Net outperforms all the state-of-the-art methods on both benchmarks (1st place on the public leaderboard of
SemanticKITTI).
The main contributions are summarized below: 1) To our best knowledge, we present one of the ﬁrst attempts to address the challenging task of LiDAR-based panoptic segmentation. 2) The proposed DS-Net effectively han-dles the complex distributions of LiDAR point clouds, and achieves state-of-the-art performance on SemanticKITTI and nuScenes. 3) Extensive experiments are performed on large-scale datasets. We adapt existing methods to this new task for in-depth comparisons. Further statistical analyses are carried out to provide valuable observations. 2.