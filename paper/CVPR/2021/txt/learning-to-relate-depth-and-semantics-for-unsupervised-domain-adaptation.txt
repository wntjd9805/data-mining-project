Abstract
We present an approach for encoding visual task rela-tionships to improve model performance in an Unsuper-vised Domain Adaptation (UDA) setting. Semantic seg-mentation and monocular depth estimation are shown to be complementary tasks; in a multi-task learning setting, a proper encoding of their relationships can further im-prove performance on both tasks. Motivated by this ob-servation, we propose a novel Cross-Task Relation Layer (CTRL), which encodes task dependencies between the se-mantic and depth predictions. To capture the cross-task re-lationships, we propose a neural network architecture that contains task-speciﬁc and cross-task reﬁnement heads. Fur-thermore, we propose an Iterative Self-Learning (ISL) train-ing scheme, which exploits semantic pseudo-labels to pro-vide extra supervision on the target domain. We experi-mentally observe improvements in both tasks’ performance because the complementary information present in these tasks is better captured. Speciﬁcally, we show that: (1) our approach improves performance on all tasks when they are complementary and mutually dependent; (2) the CTRL helps to improve both semantic segmentation and depth es-timation tasks performance in the challenging UDA setting; (3) the proposed ISL training scheme further improves the semantic segmentation performance. The implementation is available at https://github.com/susaha/ctrl-uda. 1.

Introduction
Semantic segmentation and monocular depth estimation are two important computer vision tasks that allow us to perceive the world around us and enable agents’ reasoning, e.g., in an autonomous driving scenario. Moreover, these tasks have been shown to be complementary to each other, i.e., information from one task can improve the other task’s performance [27, 40, 57]. Domain Adaptation (DA) [11]
Corresponding author: Suman Saha (suman.saha@vision.ee.ethz.ch)
* Equal contribution.
Figure 1: Semantic segmentation improvement with our ap-proach to unsupervised domain adaptation over the state-of-the-art DADA [59] method. Left to right: Cityscapes test images, DADA, and the proposed method (CTRL). Our model correctly segments the “bus”, “rider”, and “wall” classes underrepresented in the target domain (highlighted). refers to maximizing model performance in an environment with a smaller degree of supervision (the target domain) rel-ative to what the model was trained on (the source domain).
Unsupervised Domain Adaptation (UDA) assumes only ac-cess to the unannotated samples from the target domain at train time – the setting of interest in this paper.
Recent domain adaptation techniques [32, 59] proposed to leverage depth information available in the source do-main to improve semantic segmentation on the target do-main. However, they lack an explicit multi-task formula-tion to relate depth and semantics, that is to say, how each semantic category relates to different depth levels. The term depth levels refers to different discrete ranges of depth values, i.e., “near” (1-5m); “medium-range” (5-20m), or
“far” (>20m). This paper aims to design a model that learns explicit relationships between different visual seman-tic classes and depth levels within the UDA context.
To this end, we design a network architecture and a new multitask-aware feature space alignment mechanism for UDA. First, we propose a Cross-Task Relation Layer 8197
(CTRL) – a novel parameter-free differentiable module tai-lored to capture the task relationships given the network’s semantic and depth predictions. Second, we utilize a Se-mantics Reﬁnement Head (SRH) that explicitly captures cross-task relationships by learning to predict semantic seg-mentation given predicted depth features. Both CTRL and
SRH boost the model’s ability to effectively encode corre-lations between semantics and depth, thus improving pre-dictions on the target domain. Third, we employ an Itera-tive Self Learning (ISL) scheme. Coupled with the model design, it further pushes the performance of semantic seg-mentation. As a result, our method achieves state-of-the-art semantic segmentation performance on three challeng-ing UDA benchmarks (Sec. 4). Fig. 1 demonstrates our method’s effectiveness by comparing semantic predictions of classes underrepresented in the target domain to predic-tions made by the previous state-of-the-art method. The paper is organized as follows: Sec. 2 discusses the related work; Sec. 3 describes the proposed approach to UDA, the network architecture, and the learning scheme; Sec. 4 presents the experimental analysis with ablation studies;
Sec. 5 concludes the paper. 2.