Abstract
Monocular depth predictors are typically trained on large-scale training sets which are naturally biased w.r.t the distribution of camera poses. As a result, trained predic-tors fail to make reliable depth predictions for testing exam-ples captured under uncommon camera poses. To address this issue, we propose two novel techniques that exploit the camera pose during training and prediction. First, we in-troduce a simple perspective-aware data augmentation that synthesizes new training examples with more diverse views by perturbing the existing ones in a geometrically consis-tent manner. Second, we propose a conditional model that exploits the per-image camera pose as prior knowledge by encoding it as a part of the input. We show that jointly ap-plying the two methods improves depth prediction on im-ages captured under uncommon and even never-before-seen camera poses. We show that our methods improve perfor-mance when applied to a range of different predictor ar-chitectures. Lastly, we show that explicitly encoding the camera pose distribution improves the generalization per-formance of a synthetically trained depth predictor when evaluated on real images. 1.

Introduction
Monocular depth prediction aims to estimate 3D scene geometry from a 2D image. Despite being a largely under-determined problem, convolutional neural network (CNN) based depth predictors trained on a sufﬁciently large-scale dataset are able to learn the joint statistics of scene ge-ometry and appearance, and achieve impressive perfor-mance [10, 9, 12, 15, 26, 48].
However, an important overlooked fact is that the distri-bution of camera poses in training sets are naturally biased.
As a result, a learned depth predictor is unable to make reli-able predictions on images captured from uncommon cam-era poses, as shown in Fig. 1. Importantly, camera poses of
Figure 1: Contemporary monocular depth predictors, e.g.,
DORN [12], rely on large-scale training data which is naturally biased w.r.t the distribution of camera poses (e.g., pitch angle dis-tribution shown in gray). As a result, DORN makes unreliable predictions on test images captured with uncommon poses (red bars), e.g., pitch angles >120◦. To address this issue, we pro-pose two novel techniques that drastically reduce prediction errors (cf. black bars) by leveraging perspective-aware data augmenta-tion during training and known camera pose at test time. Qualita-tive examples with more extreme camera pitch angles (top) show that incorporating our techniques leads to notable improvements. testing examples may follow a different distribution from that in the training set. This will exacerbate prediction er-rors on images that are captured by cameras with uncom-mon poses relative to the training set.
Contributions. To this end, we propose two novel ap-proaches that signiﬁcantly improve depth prediction under diverse test-time camera poses. First, we introduce a simple perspective-aware data augmentation (PDA) that synthe-sizes new geometrically consistent training examples with more diverse viewpoints by perturbing the camera pose of existing samples. In contrast, common data augmenta-tion (CDA) methods such as random-crop, though widely adopted in prior work [12, 24, 51, 21, 48, 5], produce train-ing examples where the resulting image and target depth are 115759
inconsistent with the perspective geometry (Fig. 2). Second, we propose training a conditional depth predictor which uti-lizes the camera pose (e.g., acquired from IMU or other pose predictors) as a prior (CPP) when estimating depth.
We propose an effective approach to encode CPP as an ad-ditional channel alongside the RGB input. We ﬁnd incorpo-rating pose using CPP yields more accurate depth predictors that generalize much better under diverse test-time camera poses.
Through extensive experiments, we show that these tech-niques signiﬁcantly improve depth prediction on images captured from uncommon and even never-before-seen cam-era poses. Both techniques are general and broadly applica-ble to any network architecture. We show that incorporating them in recent state-of-the-art architectures improves their performance further. Lastly, we show that explicitly han-dling the biased camera pose distribution can improve the performance of a synthetically trained depth predictor when tested on real images. This highlights the importance that camera pose distribution plays in domain adaptation for 3D geometric prediction tasks. 2.