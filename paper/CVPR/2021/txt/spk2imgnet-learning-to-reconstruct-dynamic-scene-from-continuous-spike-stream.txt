Abstract
The recently invented retina-inspired spike camera has shown great potential for capturing dynamic scenes. Differ-ent from the conventional digital cameras that compact the photoelectric information within the exposure interval into a single snapshot, the spike camera produces a continuous spike stream to record the dynamic light intensity variation process. For spike cameras, image reconstruction remains an important and challenging issue. To this end, this paper develops a spike-to-image neural network (Spk2ImgNet) to reconstruct the dynamic scene from the continuous spike stream.
In particular, to handle the challenges brought by both noise and high-speed motion, we propose a hier-archical architecture to exploit the temporal correlation of the spike stream progressively. Firstly, a spatially adaptive light inference subnet is proposed to exploit the local tem-poral correlation, producing basic light intensity estimates of different moments. Then, a pyramid deformable align-ment is utilized to align the intermediate features such that the feature fusion module can exploit the long-term tem-poral correlation, while avoiding undesired motion blur.
In addition, to train the network, we simulate the work-ing mechanism of spike camera to generate a large-scale spike dataset composed of spike streams and correspond-ing ground truth images. Experimental results demonstrate that the proposed network evidently outperforms the state-of-the-art spike camera reconstruction methods. 1.

Introduction (a) Image captured by iPhone11 (b) Spike stream (c) TFP [36] (ICME’ 19) (d) TFI [36] (ICME’ 19) (e) TVS [37] (CVPR’ 20) (f) Proposed
Figure 1. The image for a high-speed rotation disk. For better comparison, we stuck a paper with characters ”CVPR” to the disk. (a) The image captured by the camera of iPhone11, which suffers (b) Spike stream captured by the spike cam-from severe blur. era [6]. (c)-(f) Spike camera reconstruction results with different methods. Our proposed method evidently outperforms the com-peting methods, producing clear image for the high-speed object.
With the prevalence of emerging computer vision ap-plications, such as autonomous driving, robotics and un-manned aerial vehicle, there has been an increasing demand for capturing high-speed motion scenes, which makes the inherent limitations of conventional cameras become evi-dent [17, 15]. Most conventional cameras use a certain ex-posure time window to accumulate the photoelectric infor-mation to form a snapshot image. Such an imaging mech-anism requires the scene to be still during the exposure in-terval. Otherwise, a single point on a moving object may be projected onto different pixels on the image sensor, result-ing in blurry artifacts for the moving objects. 11996
To address this issue, a novel retina-inspired spike cam-era has been invented to capture dynamic scenes with im-proved quality [6, 7]. Instead of recording the visual infor-mation in the whole exposure interval by a snapshot, the spike camera abandons the concept of exposure window.
Each pixel on spike camera sensor accumulates incoming light independently and persistently, and ﬁres spikes when-ever the dispatch threshold is reached, producing a continu-ous stream of spikes recorded at very high temporal resolu-tion. Different from the bio-inspired event cameras [14, 30] that only record the relative light intensity changes at each pixel, the spike camera ﬁres spikes to record the absolute light intensity, providing a more explicit information to re-construct dynamic scenes.
Image reconstruction is one of the most important is-sues for the spike camera, and various image reconstruction methods have been proposed to recover the dynamic scenes from the recorded spike data [36, 37, 35]. TFI and TFP
[36] focused on exploiting the physical properties of spike streams to infer the instantaneous light intensity, but they can not simultaneously handle the challenges that brought by both noise and high-speed motion, leading to unsatisfac-tory reconstruction as shown in Fig. 1(c) and 1(d). TVS
[37] attempted to solve the problem by mimicking human vision. However, the mechanism of human vision is too complicated to be fully understood, and the reconstruction results are still inferior, as shown in Fig. 1(e).
Beneﬁting from the fast inference and excellent repre-sentation capability, deep learning has shown great poten-tial in low-level vision applications [31, 10, 24, 31, 10, 24].
Inspired by the success of deep learning, this paper devel-ops a deep convolutional neural network to reconstruct the dynamic scenes clearly from the spike streams. Considering the characteristics of asynchronous spike data, we propose a hierarchical architecture to exploit the temporal correlation progressively, so as to achieve high-quality reconstruction.
We ﬁrst propose a spatially adaptive light inference (SALI) subnet to infer the instantaneous light intensity of different moments by exploiting the local temporal correlation. In particular, the SALI applies several parallel learnable ﬁl-ters on various temporal scales, so as to adapt the temporal scale to various motion and light conditions. Then, to fur-ther improve the reconstruction, a motion-aligned image re-construction subnet is utilized to fuse the intermediate fea-tures of different moments, so that the long-term temporal correlation can be exploited to reﬁne the reconstruction.
The main contributions of this paper are summarized as follows: 1) We develop an end-to-end convolutional neu-ral network named Spk2ImgNet to reconstruct the dynamic scene from the spike camera data stream. To the best of our knowledge, this is the ﬁrst attempt to solve the spike camera image reconstruction problem using an end-to-end neural network. 2) We propose a hierarchical architecture to exploit the temporal correlation progressively, so that the network can simultaneously handle the challenges brought by both noise and high-speed motion. 3) We formulate the mechanism of spike generation. Based on the analysis, we develop a spike camera simulator to generate synthesized spike stream and corresponding ground-truth images, and build a spike dataset for training spike camera image recon-struction network. 4) Experiments on both real captured spike data and synthesized spike data demonstrate that the proposed network achieves state-of-the-art reconstruction performance for dynamic scenes. 2.