Abstract
Correct symmetry normal
Recent advances have shown that symmetry, a structural prior that most objects exhibit, can support a variety of single-view 3D understanding tasks. However, detecting 3D symmetry from an image remains a challenging task. Previ-ous works either assume the symmetry is given or detect the symmetry with a heuristic-based method. In this paper, we present NeRD, a Neural 3D Reﬂection Symmetry Detector, which combines the strength of learning-based recognition and geometry-based reconstruction to accurately recover the normal direction of objects’ mirror planes. Speciﬁcally, we enumerate the symmetry planes with a coarse-to-ﬁne strategy and ﬁnd the best ones by building 3D cost volumes to examine the intra-image pixel correspondence from the symmetry. Our experiments show that the symmetry planes detected with our method are signiﬁcantly more accurate than the planes from direct CNN regression on both syn-thetic and real datasets. More importantly, we also demon-strate that the detected symmetry can be used to improve the performance of downstream tasks such as pose estimation and depth map regression by a wide margin over existing methods. The code of this paper has been made public at https://github.com/zhou13/nerd. 1.

Introduction
Recovering the 3D orientation of objects in an image is a fundamental problem in 3D vision, which plays important roles in tasks such as robotics, autonomous driving, virtual reality (VR), augmented reality (AR), and 3D scene under-standing. Traditionally, such a problem is hard to solve. Re-searchers can to RGB-D input captured with time-of-ﬂight cameras or structured light [5, 27, 29]. Unfortunately, depth cameras often have limited range and can be interfered with by other light sources, and the requirement of owning a depth camera is inconvenient for average users, which severely re-stricts its applications.
Recent advances in convolutional neural networks in ob-ject detection and instance segmentation have shown good
Input image
Cost Volume
Depth
Incorrect symmetry normal
Correspondence signal
No signal
Input image
Cost volume
Depth
Figure 1: Illustration of the symmetry detection process in NeRD.
For each pixel, we enumerate its depth and warp features along the line according to the symmetry plane hypothesis. If the hypothesis is correct, there should be matched features for most of the pixels. potential in inferring object-level information from RGB im-ages by leveraging supervised learning. Nowadays, single-view neural network-based methods are able to predict the object pose under diﬀerent settings. Some work explores the instance-level 3D pose estimation problem [21, 28, 32] in which the CAD models of the objects are known before-hand. However, these settings are rather limited because in practice we do not have CAD models for many objects.
Therefore, other work tries to tackle the category-level 3D pose estimation problem [4, 25, 39] without relying on the exact CAD models of objects. Unlike the cases where either depth information or CAD models are available, previous single-view category-level 3D pose estimation methods can hardly exploit the geometric constraints between the input
RGB image and the 3D shape and predict the pose solely by interpolating the training data. Hence, such formulation is ill-posed, which leads to inaccurate pose recovery [31].
To address this diﬃculty, we identify a structure that com-monly exists in man-made objects, the reﬂection symmetry, as a geometric connection between the object poses and the 115940
images. We observe that the canonical space of objects often is determined by aligning the Y-Z plane to the symme-try planes of objects [2, 30], so the normal direction of the symmetry plane encodes most of the geometric information regarding the pose of the object. To this end, we propose the NeRD network to detect the reﬂection symmetry from
RGB images. NeRD combines the strength of learning-based recognition and geometry-based reconstruction methods. It
ﬁrst enumerates the normal direction of the mirror plane from the image with a coarse-to-ﬁne strategy and then veri-ﬁes their correctness with a geometric-based neural network.
More speciﬁcally, we incorporate the concept of reﬂection symmetry into deep networks through plane-sweep cost vol-umes built from features of corresponding pixels, as shown in Figure 1. This allows us to accurately recover the normal direction of the mirror plane under the principle of shape-from-symmetry [13].
The network (see Figure 3) consists of a backbone fea-ture extractor, a diﬀerentiable warping module for building the 3D cost volumes, and a cost volume network. This framework naturally enables neural networks to utilize the information from corresponding pixels of reﬂection sym-metry inside a single image. We evaluate our method on the ShapeNet dataset [2] and Pix3D dataset [30]. Exten-sive comparisons and analysis show that by detecting and utilizing intra-image pixel correspondence from reﬂection symmetry, our method has better accuracy for recovering the normal direction of the symmetry plane and hence the object pose, even when the object is not perfectly symmetric.
Our main contributions are summarized as below:
• we identify the problem of learning neural 3D reﬂection symmetry detector, in which the intra-image pixel cor-respondence of symmetry can be utilized for accurate plane normal estimation;
• we propose a novel framework that leverages single-view dense feature matching to estimate symmetry planes, signiﬁcantly outperforming previous methods;
• we show that the learned symmetry planes beneﬁt tremendously a variety of downstream tasks, includ-ing single-view pose recovery and depth estimation. 2.