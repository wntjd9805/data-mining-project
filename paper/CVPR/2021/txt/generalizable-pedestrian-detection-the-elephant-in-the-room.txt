Abstract
Pedestrian detection is used in many vision based ap-plications ranging from video surveillance to autonomous driving. Despite achieving high performance, it is still largely unknown how well existing detectors generalize to unseen data. This is important because a practical detec-tor should be ready to use in various scenarios in appli-cations. To this end, we conduct a comprehensive study in this paper, using a general principle of direct cross-dataset evaluation. Through this study, we ﬁnd that existing state-of-the-art pedestrian detectors, though perform quite well when trained and tested on the same dataset, gener-alize poorly in cross dataset evaluation. We demonstrate that there are two reasons for this trend. Firstly, their de-signs (e.g. anchor settings) may be biased towards pop-ular benchmarks in the traditional single-dataset training and test pipeline, but as a result largely limit their gener-alization capability. Secondly, the training source is gen-erally not dense in pedestrians and diverse in scenarios.
Under direct cross-dataset evaluation, surprisingly, we ﬁnd that a general purpose object detector, without pedestrian-tailored adaptation in design, generalizes much better com-pared to existing state-of-the-art pedestrian detectors. Fur-thermore, we illustrate that diverse and dense datasets, col-lected by crawling the web, serve to be an efﬁcient source of pre-training for pedestrian detection. Accordingly, we pro-pose a progressive training pipeline and ﬁnd that it works well for autonomous-driving oriented pedestrian detection.
Consequently, the study conducted in this paper suggests that more emphasis should be put on cross-dataset evalu-ation for the future design of generalizable pedestrian de-tectors. Code and models can be accessed at https:
//github.com/hasanirtiza/Pedestron. 1.

Introduction
Pedestrian detection is one of the longest standing prob-†Corresponding author. lems in computer vision. Numerous real-world applica-tions, such as, autonomous driving [9, 17], video surveil-lance [16], action recognition [48] and tracking [21] rely on accurate pedestrian/person detection. Recently, con-volutional neural network (CNNs) based approaches have shown considerable progress in the ﬁeld of pedestrian de-tection, where on certain benchmarks, the progress is within striking distance of a human baseline as shown in Fig. 1 left.
However, some current pedestrian detection methods show signs of over-ﬁtting to source datasets, especially in the case of autonomous driving. As shown in Fig. 1 right, current pedestrian detectors, do not generalize well to other (target) pedestrian detection datasets, even when trained on a relatively large scale dataset which is reasonably closer to the target domain. This problem prevents pedestrian detec-tion from scaling up to real-world applications.
Despite being a key problem, generalizable pedestrian detection has not received much attention in the past. More importantly, reasons behind poor performances of pedes-trian detectors in cross-dataset evaluation has not been prop-erly investigated or discussed. In this paper, we argue that this is mainly due to the fact that the current state-of-the-art pedestrian detectors are tailored for target datasets and their overall design is biased towards target datasets, thus reduc-ing their generalization. Secondly, the training source is generally not dense in pedestrians and diverse in scenarios.
Since current state-of-the-art methods are based on deep learning, their performance depend heavily on the quantity and quality of data and there is some evidence that the per-formance on some computer vision tasks (e.g. image classi-ﬁcation) keeps improving at least up-to billions of samples
[29].
At present, all autonomous driving related datasets have at least three main limitations, 1) limited number of unique pedestrians, 2) low pedestrian density, i.e. the challenging occlusion samples are relatively rare, and 3) limited diver-sity as the datasets are captured by a small team primarily for dataset creation instead of curating them from more di-verse sources (e.g. youtube, facebook, etc.).
In last couple of years, few large and diverse datasets,
CrowdHuman [35], WiderPerson [51] and Wider Pedestrian 111328
Figure 1: Left: Pedestrian detection performance over the years for Caltech, CityPersons and EuroCityPersons on the rea-sonable subset. EuroCityPersons was released in 2018 but we include results of few older models on it as well. Dotted line marks the human performance on Caltech. Right: We show comparison between traditional single-dataset train and test eval-uation on Caltech [12] vs. cross-dataset evaluation for three pedestrian detectors and one general object detector (Cascade
R-CNN). Methods enclosed with bounding boxes are trained on CityPersons [50] and evaluated on Caltech [12], while others are trained on Caltech.
[1], have been collected by crawling the web and through surveillance cameras. These datasets address the above mentioned limitations but as they are from a much broader domain, they do not sufﬁciently cover autonomous driving scenarios. Nevertheless, they can still be very valuable for learning a more general and robust model of pedestrians.
As these datasets contain more person per image, they are likely to contain more human poses, appearances and occlu-sion scenarios, which is beneﬁcial for autonomous driving scenarios, provided current pedestrian detectors have the in-nate ability to digest large-scale data.
In this paper, we demonstrate that the existing pedes-trian detection methods fare poorly compared to general object detectors when provided with larger and more di-verse datasets, and that the state-of-the-art general detec-tors when carefully trained can signiﬁcantly out-perform pedestrian-speciﬁc detection methods on pedestrian detec-tion task, without any pedestrian-speciﬁc adaptation on the target data (see Fig. 1 right). We also propose a progressive training pipeline for better utilization of general pedestrian datasets for improving the pedestrian detection performance in case of autonomous driving. We show that by progres-sively ﬁne-tuning the models from the largest (but farthest away from the target domain) to smallest (but closest to the target domain) dataset, we can achieve large gains in perfor-mance in terms of M R−2 on reasonable subset of Caltech (3.7%) and CityPerson (1.5%) without ﬁne-tuning on target domain. These improvement hold true for models from all pedestrian detection families that we tested such as Cascade
R-CNN [8], Faster RCNN [34] and embedded vision based backbones such as MobileNet [20]
The rest of the paper is organized as follows. Section 2 reviews the relevant literature. We introduce datasets and evaluation protocol in Sec. 3. We benchmark our baseline in Sec. 4. We test the generalization capabilities of the pedestrian speciﬁc and general object detectors in Sec. 5.
Finally, conclude the paper in Section 6. 2.