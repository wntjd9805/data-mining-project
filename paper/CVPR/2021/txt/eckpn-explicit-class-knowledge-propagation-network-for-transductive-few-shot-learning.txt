Abstract
Recently, the transductive graph-based methods have achieved great success in the few-shot classiﬁcation task.
However, most existing methods ignore exploring the class-level knowledge that can be easily learned by humans from just a handful of samples.
In this paper, we propose an
Explicit Class Knowledge Propagation Network (ECKPN), which is composed of the comparison, squeeze and cali-bration modules, to address this problem. Speciﬁcally, we
ﬁrst employ the comparison module to explore the pairwise sample relations to learn rich sample representations in the instance-level graph. Then, we squeeze the instance-level graph to generate the class-level graph, which can help obtain the class-level visual knowledge and facilitate mod-eling the relations of different classes. Next, the calibra-tion module is adopted to characterize the relations of the classes explicitly to obtain the more discriminative class-level knowledge representations. Finally, we combine the class-level knowledge with the instance-level sample repre-sentations to guide the inference of the query samples. We conduct extensive experiments on four few-shot classiﬁca-tion benchmarks, and the experimental results show that the proposed ECKPN signiﬁcantly outperforms the state-of-the art methods. 1.

Introduction
Recent deep learning methods rely on a large amount of labeled data to achieve high performance, which may have problems in some scenarios, where the cost of data collection is high, and thus it is difﬁcult to obtain a large amount of labeled data. The learning schema of these deep methods is different from that of humans. After being ex-posed to a few data/samples, human beings can use their prior knowledge to learn quickly so as to successfully rec-ognize new classes. Therefore, how to reduce the gap be-† indicates corresponding author: Changsheng Xu. q
Class 1
Class 2
Support Sample
Query Sample
Class-level Knowledge Representation
Distribution Boundary Learned Through 
Pairwise Sample Relations
Figure 1. An illustration of the role of class-level knowledge rep-resentations (e.g., class centers). tween deep learning methods and human learning abilities has aroused the interest of many researchers. Few-shot learning [17, 21, 45], which simulates the human learning schema, has attracted much attention in the ﬁeld of com-puter vision and machine learning.
As a straightforward method to solve the few-shot learn-ing task, traditional ﬁne-tuning techniques [10] can utilize the samples of the new classes to update the parameters of the network pretrained on the classes with sufﬁcient sam-ples. However, these methods always lead to over-ﬁtting, since only a few training samples are not enough to rep-resent the data distributions of the corresponding classes and learn effective classiﬁers. A successful attempt to solve the over-ﬁtting problem is to apply the meta-learning mech-anism [20] in few-shot learning task. The meta-learning based methods [3, 43, 30, 31, 23, 37, 7, 28, 12, 11, 52, 47, 2, 29] are composed of two steps: meta-train and meta-test. Each step (meta-train or meta-test) consists of multi-ple episodes (sub-tasks), and the data of each episode are composed of support set and query set. These methods keep the meta-train environment consistent with the meta-test to help improve the generalization ability of the mod-els, thereby solving the problem of over-ﬁtting. Nowadays, meta-learning has become a general training mechanism in most of the few-shot learning methods. In this paper, we also follow this training mechanism. 6596
Recently, inspired by the success of graph networks in modeling structure information [14, 8, 42], researchers be-gan to propose the graph-based meta-learning approaches for few-shot learning and obtain the state-of-the-art perfor-mances [38, 12, 28, 29, 47, 27]. These methods treat the samples as nodes to construct the graph and utilize the ad-jacency matrix to model the relations of images. There are two settings of the graph-based meta-learning approaches: transductive setting and inductive setting. The transductive methods characterize the relations of samples from both the support set and the query set for joint prediction, and thus obtain better performances than inductive methods, which can only learn a network based on the relations of support samples and classify each query sample individually.
Existing transductive graph-based methods learn to propagate the class label from the support set to the query set by comprehensively considering the instance-level re-lations of samples. However, these methods ignore the global context knowledge from the perspective of a cate-gory.
In contrast, people can learn richer representations of a new category from just a handful of samples, using them for creating new exemplars, and even creating new abstract categories based on existing categories [18]. This inspires us to consider how to explicitly learn the richer class knowledge to guide the graph-based inference of query samples. As illustrated in Figure 1, if we only uti-lize the sample representations and relations to conduct the few-shot classiﬁcation task, we may misclassify the query sample q into class 2. However, if we learn the class-level knowledge representations explicitly to guide the inference procedure, we can classify q correctly, because q is closer to the representation of the class 1.
In order to address the above problem, we propose an end-to-end transductive graph neural network, which is called Explicit Class Knowledge Propagation Network (ECKPN). The proposed ECKPN is composed of the com-parison, squeeze and calibration modules, which can be
ﬂexibly stacked to explicitly learn and propagate the class-level knowledge. (1) Firstly, the comparison mod-ule captures the rich representations of samples based on the pairwise relations in a instance-level graph. The vi-sual features are always structured vectors and many factors (e.g., frequency, shapes, illumination, textures) could lead to grouping [46, 51] (i.e., a group of dimensions represents a semantic aspect or a piece of knowledge). Thus, we adopt multi-head relations in the message passing of the compari-son module to characterize the group-wise relations of sam-ples, which provides ﬁne-grained comparison of different samples. Each node feature is divided into groups along the dimension, and adjacency matrices are computed for differ-ent groups to obtain multiple relation measurements, which are then aggregated to compute the new node features of the samples. (2) Then, the squeeze module explores the intra-class context knowledge by clustering samples with similar features from the instance-level graph, which results in a class-level graph. The number of nodes in the class-level graph is same as the total number of classes. Thus, each node represents the visual knowledge of a speciﬁc class. (3) Finally, the calibration module explicitly captures the relationships between different classes and learn more dis-criminative class knowledge to guide the graph-based in-ference of query samples. Since the word embeddings of the class names can provide rich semantic knowledge that may not be contained in the visual contents, we combine them with the visual knowledge to obtain the multi-modal knowledge representations of different classes. Based on the multi-modal knowledge representations, a class-level message passing is adopted to exploit the relationship of different classes. The new class-level knowledge repre-sentations obtained by message passing are combined with the corresponding instance-level sample representations to guide the inference of the query samples.
To sum up, the main contributions of this paper are four-fold:
• To the best of our knowledge, we are the ﬁrst to pro-pose an end-to-end graph-based few-shot learning ar-chitecture, which can explicitly learn the rich class knowledge to guide the graph-based inference of query samples.
• We build multi-head sample relations to explore the
ﬁne-grained comparison of pairwise samples, which can facilitate the learning of richer class knowledge based on the pairwise relations.
• We leverage the semantic embeddings of the class names to construct the multi-modal knowledge repre-sentations of different classes, which can provide more discriminative knowledge to guide the inference of the query samples.
• We conduct extensive experiments on four benchmarks (i.e., miniImageNet, tieredImageNet, CIFAR-FS and
CUB-200-2011) for the transductive few-shot classi-ﬁcation task, and the results show that the proposed method achieves the state-of-the-art performances. 2.