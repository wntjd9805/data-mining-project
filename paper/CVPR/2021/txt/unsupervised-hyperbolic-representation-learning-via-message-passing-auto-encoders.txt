Abstract
Most of the existing literature regarding hyperbolic em-bedding concentrate upon supervised learning, whereas the use of unsupervised hyperbolic embedding is less well ex-plored. In this paper, we analyze how unsupervised tasks can beneﬁt from learned representations in hyperbolic space. To explore how well the hierarchical structure of un-labeled data can be represented in hyperbolic spaces, we design a novel hyperbolic message passing auto-encoder whose overall auto-encoding is performed in hyperbolic space. The proposed model conducts auto-encoding the networks via fully utilizing hyperbolic geometry in mes-sage passing. Through extensive quantitative and qualita-tive analyses, we validate the properties and beneﬁts of the unsupervised hyperbolic representations. Codes are avail-able at https://github.com/junhocho/HGCAE. 1.

Introduction
A fundamental problem of machine learning is learning useful representations from high-dimensional data. There are many supervised representation learning methods that achieve good performances for downstream tasks [25, 22, 30, 60] on several data domains such as images and graphs.
In recent years, with the success of deep learning, various large-scale real-world datasets have been collated [25, 24, 56, 49]. However, the larger these datasets and the closer they are to the real world, the expense and effort required to label the data increases proportionally. Thus, unsupervised representation learning is an increasingly viable approach to extract useful representation from real-world datasets.
Recently, many works [39, 40, 11, 16, 5, 1, 19] utilize hyperbolic geometry [23] to learn representations by under-standing the underlying nature of the data domains. It is well known that complex networks contain latent hierarchies be-tween large groups and the divided subgroups of nodes and
*equally contributed. can be approximated as trees that grow exponentially with their depth [23]. Based on this fact, previous works which involve graphs [3, 38, 39, 40, 11, 36] showed the effective-ness of learning representation using hyperbolic spaces (a continuous version of trees) where distances increase expo-nentially when moving away from the origin. More recently, works [5, 27, 1] have been conducted which learn more powerful representations via conducting message passing (graph convolution) [12, 22, 54] in hyperbolic spaces.
In addition, it has been successfully shown that grafting hyperbolic geometry onto computer vision tasks is promis-ing [19]. They observed a high degree of hyperbolicity
[10] in the activations of image datasets obtained from pre-trained convolutional networks. Also, it has been shown that the hyperbolic distance between learned embeddings and the origin of the Poincar´e ball could be considered as a measurement of the model’s conﬁdence. Using these analy-ses, [19] added a single layer of hyperbolic neural networks
[11] to deep convolutional networks and showed the bene-ﬁts of hyperbolic embeddings on few-shot learning and per-son re-identiﬁcation. Another work [28] also demonstrated the suitability of hyperbolic embeddings on zero-shot learn-ing. However, most of the existing hyperbolic representa-tion learning works [19, 28, 5, 27, 1] mainly focus on a su-pervised setting, and the effect of hyperbolic geometry on unsupervised representation learning has not been explored deeply so far [32, 15, 36].
In this paper, we explore the beneﬁts of hyperbolic ge-ometry to carry out unsupervised representation learning upon various data domains. Our motivation is to learn high-quality node embeddings of the graphs that are hierarchical and tree-like without supervision via considering the geom-etry of the embedding space. To do so, we present a novel hyperbolic graph convolutional auto-encoder (HGCAE) by combining hyperbolic geometry and message passing [12].
Every layer of HGCAE performs message passing in the hy-perbolic space and its corresponding tangent space where curvature values can be trained. This is primarily in con-trast to the Poincar´e variational auto-encoder (P-VAE) [32] whose latent space is the Poincar´e ball and conducts mes-5516
sage passing in Euclidean space. The HGCAE conducts auto-encoding the graphs from diverse data domains, such as images or social networks, in the hyperbolic space such as the Poincar´e ball and hyperboloid. To fully utilize hy-perbolic geometry for representation learning, we adopt a geometry-aware attention mechanism [16] when conduct-ing message passing. Through extensive experiments and analyses using the learned representation in the hyperbolic latent spaces, we present the following observations on hi-erarchically structured data:
• The proposed auto-encoder, which combines message passing based on geometry-aware attention and hyper-bolic spaces, can learn useful representations for down-stream tasks. On various networks, the proposed method achieves state-of-the-art results on node clustering and link prediction tasks.
• Image clustering tasks can beneﬁt from embeddings in hyperbolic latent spaces. We achieve comparable results to state-of-the-art image clustering results by learning representations from the activations of neural networks.
• Hyperbolic embeddings of images, the results of unsuper-vised learning, can recognize the underlying data struc-tures such as a class hierarchy without any supervision of ground-truth class hierarchy.
• We show that the sample’s hyperbolic distance from the origin in hyperbolic space can be utilized as a criterion to choose samples, therefore improving the generalization ability of a model for a given dataset. 2.