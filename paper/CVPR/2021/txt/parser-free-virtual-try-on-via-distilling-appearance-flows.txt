Abstract
Image virtual try-on aims to ﬁt a garment image (tar-get clothes) to a person image. Prior methods are heavily based on human parsing. However, slightly-wrong segmen-tation results would lead to unrealistic try-on images with large artifacts. A recent pioneering work employed knowl-edge distillation to reduce the dependency of human pars-ing, where the try-on images produced by a parser-based method are used as supervisions to train a “student” net-work without relying on segmentation, making the student mimic the try-on ability of the parser-based model. How-ever, the image quality of the student is bounded by the
*Y. Song is the corresponding author. This work is done when Y. Ge is an intern in Tencent AI Lab. The code is available at https://github. com/geyuying/PF-AFN. parser-based model. To address this problem, we propose a novel approach, “teacher-tutor-student” knowledge dis-tillation, which is able to produce highly photo-realistic images without human parsing, possessing several appeal-ing advantages compared to prior arts. (1) Unlike existing work, our approach treats the fake images produced by the parser-based method as “tutor knowledge”, where the arti-facts can be corrected by real “teacher knowledge”, which is extracted from the real person images in a self-supervised way. (2) Other than using real images as supervisions, we formulate knowledge distillation in the try-on problem as distilling the appearance ﬂows between the person image and the garment image, enabling us to ﬁnd accurate dense correspondences between them to produce high-quality re-sults. (3) Extensive evaluations show large superiority of our method (see Fig. 1). 8485
1.

Introduction 6%"4 78"2%
!"#$012 34,+5%$
Virtual try-on of fashion image is to ﬁt an image of a clothing item (garment) onto an image of human body. This task has attracted a lot of attention in recent years because of its wide applications in e-commerce and fashion image edit-ing. Most of the state-of-the-art methods such as VTON [9],
CP-VTON [30], VTNFP [33], ClothFlow [8], ACGPN [32], and CP-VTON+ [18] were relied on human segmentation of different body parts such as upper body, lower body, arms, face, and hairs, in order to enable the learning procedure of virtual try-on. However, high-quality human parsing is typ-ically required to train the try-on models, because slightly wrong segmentation would lead to highly-unrealistic try-on images, as shown in Fig.1.
To reduce the dependency of using accurate masks to guide the try-on models, a recent pioneering work WU-TON [13] presented the ﬁrst parser-free network without us-ing human segmentation for virtual try-on. Unfortunately,
[13] has an inevitable weakness in its model design. As shown in the bottom of Fig.2, WUTON employed a conven-tional knowledge distillation scheme by treating a parser-based model (i.e. a try-on network that requires human seg-mentation) as a “teacher” network, and distilling the try-on images (i.e. fake person images) produced by the teacher to a parser-free “student” network, which does not use seg-mentation as input. This is to make the parser-free student directly mimic the try-on ability of the parser-based teacher.
However, the generated images of the parser-based teacher have large artifacts (Fig.1), thus using them as the teacher knowledge to supervise the student model produces unsat-isfactory results since the image quality of the student is bounded by the parser-based model.
To address the above problems, this work proposes a new perspective to produce highly photo-realistic try-on im-ages without human parsing, called Parser Free Appearance
Flow Network (PF-AFN), which employs a novel “teacher-tutor-student” knowledge distillation scheme. As shown at the top of Fig.2, instead of treating the parser-based model as the teacher, PF-AFN only treats it as a “tutor” network that may produce unrealistic results (i.e. tutor knowledge), which need to be improved by a real teacher. The key is to design where the teacher knowledge comes from. To this end, PF-AFN treats the fake person image (tutor knowl-edge) as input of the parser-free student model, which is su-pervised by the original real person image (teacher knowl-edge), making the student mimic the original real images.
This is similar to self-supervised learning, where the stu-dent network is trained by transferring the garment on the real person image to the fake person image produced by the parser-based model. In other words, the student is asked to change the clothes on the fake person image to the clothes on the real person image, enabling it to be self-supervised by the real person image that naturally has no artifacts. In
!"#$%#
>"/% 78"2%
)*+,# 91,.4%(2% 34,+5%$ ,1 6%"4 78"2% 6%"4 78"2%
!"#$012 34,+5%$
!"#$%# 6%"4 78"2% 34,+5%$
&'()'%
!"#$%#&'"$%(
)*+,#
-%+.,#/
)*+,# 91,.4%(2%
>"/% 78"2%
<==%"#"1;%
>4,.$
!"#$%#&?#%%
:+*(%1+
-%+.,#/ (cid:1)
!"#$%
!"#$%#&'"$%(
)%";5%#
-%+.,#/
!"#$%#&?#%%
:+*(%1+
-%+.,#/
:+*(%1+
)%";5%# 91,.4%(2%
)%";5%# 91,.4%(2%
>"/% 78"2% (cid:1)
:+*(%1+
Figure 2. The comparison between WUTON [13] and PF-AFN.
WUTON treats a parser-based network as a “teacher” network and distills the fake person image produced by the teacher to a parser-free “student” network, making the student directly mimic the try-on ability of the parser-based teacher. In comparison, our PF-AFN treats the fake person image as “tutor knowledge” and uses it as the input of the parser-free “student” network, which is supervised by the real person image (teacher knowledge). The parser-based
“tutor” network further distills the appearance ﬂows between the person image and the clothes image, facilitating the high-quality image generation in the “student” network. this case, the images generated by our parser-free model signiﬁcantly outperform its previous counterparts.
To further improve image quality of the student, other than using real images as supervisions, we formulate knowl-edge distillation of the try-on problem as distilling the ap-pearance ﬂows between the person image and the garment image, facilitating to ﬁnd dense correspondences between them to generate high-quality images.
Our work has three main contributions.
First, we propose a “teacher-tutor-student” knowledge distillation scheme for the try-on problem, to produce highly photo-realistic results without using human segmentation as model input, completely removing human parsing. Second, we formulate knowledge distillation in the try-on problem as distilling appearance ﬂows between the person image and the garment image, which is important to ﬁnd accurate dense correspondences between pixels to generate high-quality images. Third, extensive experiments and evalua-tions on the popular datasets demonstrate that our proposed method has large superiority compared to the recent state-of-the-art approaches both qualitatively and quantitatively. 2.