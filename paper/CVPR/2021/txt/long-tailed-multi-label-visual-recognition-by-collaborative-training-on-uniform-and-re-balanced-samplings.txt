Abstract
Long-tailed data distribution is common in many multi-label visual recognition tasks and the direct use of these data for training usually leads to relatively low perfor-mance on tail classes. While re-balanced data sampling can improve the performance on tail classes, it may also hurt the performance on head classes in training due to label co-occurrence. In this paper, we propose a new approach to train on both uniform and re-balanced samplings in a collaborative way, resulting in performance improvement on both head and tail classes. More speciﬁcally, we design a visual recognition network with two branches: one takes the uniform sampling as input while the other takes the re-balanced sampling as the input. For each branch, we con-duct visual recognition using a binary-cross-entropy-based classiﬁcation loss with learnable logit compensation. We further deﬁne a new cross-branch loss to enforce the con-sistency when the same input image goes through the two branches. We conduct extensive experiments on VOC-LT and COCO-LT datasets. The results show that the proposed method signiﬁcantly outperforms previous state-of-the-art methods on long-tailed multi-label visual recognition. 1.

Introduction
By classifying an image into multiple classes, multi-label visual recognition is an important task in computer vision and the state-of-the-art approaches [45, 54, 44, 2, 20, 21, 12, 40, 52, 5] are to train deep networks on a set of training data with ground-truth labels. However, as in many single-label recognition tasks [25, 3, 6, 41, 24, 15, 16, 53], the training data of multi-label recognition may exhibit a long-tailed distribution [39] in terms of class labels – head classes have many samples while tail classes have very few samples. Direct training on such data (with uniform sam-pling) usually produces relatively low performance on the tail classes. In this paper, we focus on solving the problem of long-tailed multi-label visual recognition (LTML).
Re-balanced data sampling [4, 32, 1, 10] is a proven ef-fective approach for addressing the long-tailed visual recog-nition.
It achieves class-wise balance by either down-sampling the head-class data or up-sampling the tail-class data. However, repeating/dropping a tail-class/head-class image may also duplicate/remove head-class/tail-class sam-ples due to label co-occurrence in multi-label recogni-tion [47]. Thus, while re-balanced sampling can improve the recognition performance of tail classes, it may simulta-neously decrease the performance of some head classes for
LTML. Since performance of different classes, either head or tail ones, is usually considered to be equally important in multi-label visual recognition, in this paper, we develop a new method that can combine different data samplings for improving the performance of both head and tail classes.
We consider the uniform and re-balanced samplings.
Given a long-tailed training set for multi-label recognition, the uniform sampling leads to the original long-tailed distri-bution, while the re-balanced sampling expects to achieve a balanced distribution, but yields another biased distri-bution due to label-occurrence. Our basic idea is to use each of them to train a branch of a two-branch network, where two branches follow the same architecture. We fur-ther deﬁne a loss that enforces the consistency across the two branches for the same input to achieve a collaborative training, inspired by the previous mutual learning [51] and co-regularization [27]. The cross-branch consistency com-promises two distributions to achieve an effect equivalent to learning the proposed network from a balanced implicit dis-tribution somewhere between two biased distributions from different samplings.
More speciﬁcally, as shown in Fig. 1(b), the two branches have the same architecture but different param-eters to reﬂect the different distributions of their respec-tive inputs. For each branch, a binary-cross-entropy-based multi-label classiﬁcation loss with learnable logit compen-sation is deﬁned for LTML. For combining two branches, we introduce another loss to collaboratively enforce the pre-diction consistency across the two branches when the same input image is fed to the two branches. Finally, this two-15089
dataset u o r m n i f a m p li n s g
Net 1
Net 2 o r m n i f a m p li n s u g
~ dataset sa re-balanced pling m
Net 1
Net 2
~ ~ (a) (b)
Figure 1. An illustration of the difference between (a) the previous mutual learning [51]/co-regularization [27] networks, where the input from the same distribution is always fed to the two branches, and (b) the proposed network where different inputs, from different samplings, are fed to the two branches. We only use the same input for the two branches for computing the consistency loss. I and J are mini-batch images, ∼ indicates the consistency measurement, and L is the classiﬁcation loss. branch network is trained in an end-to-end manner by min-imizing both classiﬁcation and consistency losses. During the test phase, each test image is fed to both branches with-out considering cross-branch paths and the average of pre-dictions from the two branches is taken as the ﬁnal predic-tion.
Different from previous mutual learning methods [51, 27], where the two branches always take the input from a single distribution, as shown in Fig. 1(a), our proposed method learns two branches from different inputs generated by different samplings and the same input for two branches is only used for computing the consistency loss.
To summarize, the main contributions of this work are: 1 We propose the use of both uniform and re-balanced samplings of the same training set for long-tailed multi-label visual recognition. 2 We develop a two-branch network, as well as a cross-branch loss to enforce the consistency between two branches, for collaborative learning on both uniform and re-balanced samplings. 3 We conduct extensive experiments on VOC-LT and
COCO-LT datasets to verify that the proposed method can simultaneously improve the performance of both head and tail classes. 2.