Abstract
Recent advances in person re-identiﬁcation (ReID) ob-tain impressive accuracy in the supervised and unsuper-vised learning settings. However, most of the existing meth-ods need to train a new model for a new domain by access-ing data. Due to public privacy, the new domain data are not always accessible, leading to a limited applicability of these methods. In this paper, we study the problem of multi-source domain generalization in ReID, which aims to learn a model that can perform well on unseen domains with only several labeled source domains. To address this prob-lem, we propose the Memory-based Multi-Source Meta-Learning (M3L) framework to train a generalizable model for unseen domains. Speciﬁcally, a meta-learning strat-egy is introduced to simulate the train-test process of do-main generalization for learning more generalizable mod-els. To overcome the unstable meta-optimization caused by the parametric classiﬁer, we propose a memory-based iden-tiﬁcation loss that is non-parametric and harmonizes with meta-learning. We also present a meta batch normaliza-tion layer (MetaBN) to diversify meta-test features, further establishing the advantage of meta-learning. Experiments demonstrate that our M3L can effectively enhance the gen-eralization ability of the model for unseen domains and can outperform the state-of-the-art methods on four large-scale
ReID datasets. 1.

Introduction
Person re-identiﬁcation (ReID) aims at matching persons of the same identity across multiple camera views. Recent works in ReID mainly focus on three settings, i.e., fully-*Equal contribution.
This work was done when Yuyang Zhao (yuyangzhao98@gmail.com) was a visiting student at Xiamen University.
†Corresponding author: {zhiming.luo, szlig}@xmu.edu.cn
Train
Train
Test (a) Single-Source UDA
Train
Test
Train
Train
Test (b) Single-Source DG (c) Multi-Source DG
Comparison of different settings in ReID.
Setting
Fully-Supervised
Fully-Unsupervised
Single-Source UDA
Single-Source DG
Multi-Source DG
Source(s)
Target(s)
Multi
Images Labels Images Labels
×
×
×
×
X
X
X
X
X
X
X
×
X
X
X
—
—
X
×
×
—
—
×
×
×
Figure 1: Comparison of different settings in person ReID.
Different background colors indicate different distributions, i.e., domains. Solid/dashed ellipses denote data subset with/without labels. Domain generalization (DG) is de-signed to learn models for unseen domains, while other settings focus on learning models for speciﬁc domains.
Compared to single-source DG, multi-source DG leverages knowledge from multiple labeled datasets, enforcing the model to learn more underlying patterns across domains. supervised [45, 47, 55], fully-unsupervised [23, 24, 39] and unsupervised domain adaptive [8, 44, 52] ReID. Despite their good performance on a seen domain (i.e., a domain with training data), most of them suffer from drastic per-formance decline on unseen domains. In real-world appli-cations, the ReID systems will inevitably search persons in new scenes. Therefore, it is necessary to learn a model that has good generalization ability to unseen domains.
To meet this goal, domain generalization (DG) is a promising solution that aims to learn generalizable models with one or several labeled source domains. As shown in 6277
Fig. 1, compared to other settings, DG does not require the access to target domains. Generally, DG can be divided into two categories, single-source DG [14, 22, 56] and multi-source DG [16, 33], according to the number of source do-mains. Recent works mainly focus on single-source DG where only one labeled source domain is available. How-ever, a single domain provides limited training samples and scene information, restricting the improvement of single-source DG methods. In contrast, multi-source DG utilizes multiple datasets of different distributions, providing more training data that contain numerous variations and environ-mental factors. However, due to the strong compatibility of deep networks, directly aggregating all source domains together might lead the model to overﬁt on the domain bias, hampering the generalization ability of the model.
Although we can sample balanced training data from all source domains during training to reduce the impact of do-main bias, the above issue still remains.
In this paper, we study the multi-source DG and aim to enforce the model to learn discriminative features without domain bias so that the model can be generalized to un-seen domains. To achieve this goal, this paper introduces a meta-learning strategy for multi-source DG, which simu-lates the train-test process of DG during model optimiza-tion.
In our method, we dynamically divide the source domains into meta-train and meta-test sets at each itera-tion. The meta-train is regarded as source data, and the meta-test is regarded as “unseen” data. During training, we encourage the loss of meta-train samples to optimize the model towards a direction that can simultaneously improve the accuracy of meta-test samples. Nevertheless, meta-learning causes a problem for traditional parametric-based identiﬁcation loss — unstable optimization. On the one hand, ReID datasets contain numerous IDs, so the num-ber of classiﬁer parameters will surge when multiple do-mains are used for training. On the other hand, the uni-ﬁed optimization of classiﬁers is unstable due to the asyn-chronous update by the high-order gradients of the meta-test. Consequently, we propose a memory-based identiﬁ-cation loss, which uses a non-parametric memory to take full advantage of meta-learning while avoiding unstable op-timization. We also introduce a meta batch normalization layer (MetaBN), which mixes meta-train knowledge with meta-test features to simulate the feature variations in dif-ferent domains. Our full method is called Memory-based
Multi-Source Meta-Learning (M3L). Experiments on four large-scale ReID datasets demonstrate the effectiveness of our M3L when testing on unseen domains and show that our M3L can achieve state-of-the-art results.
Our contributions are summarized as follows:
• We propose a Multi-Source Meta-Learning framework for multi-source DG, which can simulate the train-test process of DG during training. Our method enables the model to learn domain-invariant representations and thus improves the generalization ability.
• We equip our framework with a memory-based mod-ule, which implements the identiﬁcation loss in a non-parametric way and can prevent unstable optimization caused by traditional parametric manner during meta-optimization.
• We present MetaBN to generate diverse meta-test fea-tures, which can be directly injected into our meta-learning framework and obtain further improvement. 2.