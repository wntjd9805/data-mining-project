Abstract (a) Input (b) 2D primitive
Folding−−−−→ (c) 3D point cloud
Topology matters. Despite the recent success of point cloud processing with geometric deep learning, it remains arduous to capture the complex topologies of point cloud data with a learning model. Given a point cloud dataset con-taining objects with various genera, or scenes with multiple objects, we propose an autoencoder, TearingNet, which tack-les the challenging task of representing the point clouds us-ing a ﬁxed-length descriptor. Unlike existing works directly deforming predeﬁned primitives of genus zero (e.g., a 2D square patch) to an object-level point cloud, our TearingNet is characterized by a proposed Tearing network module and a Folding network module interacting with each other itera-tively. Particularly, the Tearing network module learns the point cloud topology explicitly. By breaking the edges of a primitive graph, it tears the graph into patches or with holes to emulate the topology of a target point cloud, leading to faithful reconstructions. Experimentation shows the superi-ority of our proposal in terms of reconstructing point clouds as well as generating more topology-friendly representations than benchmarks. 1.

Introduction
Based on a point cloud sampled from the surface of an object (or a scene), humans are able to perceive its under-lying shape. Via properly capturing the topology behind the point set, human understanding is robust to variations in scales and viewpoints. Intuitively, topology reﬂects how the points are put together to form an object. Moreover, topology is an intrinsic property of Riemannian manifolds that are usually used to model 3D shapes in geometric learn-ing [2, 23]. Hence, it is important to seek topology-aware representations for point clouds in machine learning.
As an unsupervised learning architecture, autoencoder (AE) [25] is popularly investigated to learn latent represen-tations with unlabeled point clouds. It tries to approximate
∗Work done while the author was an intern at InterDigital. e r o f e
B
) i (
−− g n
− i r a
←− e
T r e t f
A
) i i ( e r o f e
B
) i i i (
−− g n
− i r a
←− e
T r e t f
A
) v i (
Figure 1. TearingNet for point cloud reconstruction. By Tearing and Folding, we achieve high-quality reconstructions (c-ii) and (c-iv). Edges of the primitive graphs are also drawn in (b) and (c). an identity function that is non-trivially constrained by out-putting a compact representation from its encoder network.
The decoder network attempts to reconstruct the point cloud from the compact representation. The compact representa-tion typically takes the shape of a ﬁxed-length codeword which characterizes geometric properties of point clouds.
Therefore, it not only preserves the ability for reconstruc-tion [6] but is also valuable for high-level tasks such as classiﬁcation [40, 42, 11].
With ample topological structures in the real world, un-fortunately, it is non-trivial to produce topology-friendly representations that count for object point clouds with holes (i.e., varying genera) or scene point clouds with a varying 7453
number of objects (i.e., varying zeroth Betti number [33]).
For example, to represent a multi-object scene, a descriptor not only needs to delineate the shapes of individual objects but also the spatial relationship between them. In fact, ex-isting works, including LatentGAN [1], FoldingNet [40],
AtlasNet [14], 3D Point Capsule Network [42] and Graph-TER [11], all target to reconstruct point clouds with simple topologies, e.g., object point clouds. Some other works, such as AtlasNetV2 [8] and DeepSDF [27], even train class-speciﬁc networks to alleviate the effects of ample topologies across classes.
To tackle this challenge, we propose a new autoen-coder for point cloud, entitled TearingNet. Similar to
FoldingNet [40], AtlasNet [14] and 3D Point Capsule Net-work [42], etc., we reconstruct point clouds by deforming genus zero 2D primitives (e.g., a regular 2D patch). Dif-ferently, we novelly tear the primitive with holes or into several parts to match its topology to the target point clouds, e.g., Figure 1b-ii and Figure 1b-iv. Our architecture cou-ples a proposed Tearing network and a Folding network, letting them interact with each other. Especially, by run-ning through a trial folding in the ﬁrst place, our proposal enables the Tearing network to tear a graph deﬁning on the 2D primitive, letting it count for the empty space in object holes and boundaries. The torn primitive graph, with de-sired topology similar to the target point cloud, is fed to the
Folding network again. In this way, the Tearing network and the Folding network run alternatively to decode an accurate reconstruction.
We veriﬁed that the TearingNet generates topology-friendly representations. The superiority of the obtained representations is demonstrated in different down-stream tasks, including shape reconstruction, object counting, and object detection. We also examine why the learned represen-tations are topology-aware by analyzing the feature space.
The contributions of our work can be summarized below: (i) We propose a novel autoencoder—TearingNet—to gen-erate topology-friendly representations for complex 3D point clouds. Our TearingNet includes a Folding net-work (F-Net) and a Tearing network (T-Net) “talking” to each other by a feedback loop, which gradually im-proves the reconstructions. (ii) Our TearingNet endeavors to explicitly learn the target point cloud topology. By tearing a local graph built upon the 2D primitive, we update its topology to match with the ground-truth point cloud. With the notion of graph tearing, our proposal is generalized as a Graph-Conditioned AutoEncoder (GCAE) which discovers and utilizes topology iteratively. (iii) We unroll the proposed TearingNet then apply its pro-duced representations to several tasks that are sensitive to topology, e.g., reconstruction, and object counting, which verify our superiority. We further analyze the structure of the feature space to understand how the topology-friendliness is achieved.
Our paper is organized as follows. Section 2 reviews related work. In Section 3, we present the methodology of the TearingNet under the notion of graph tearing. Section 4 unrolls the TearingNet architecture then illustrates its individ-ual components. Experimentation is presented in Section 5 and conclusions are provided in Section 6. 2.