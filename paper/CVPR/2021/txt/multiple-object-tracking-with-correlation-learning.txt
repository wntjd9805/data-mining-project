Abstract (a) Apperance Only (b) Correlation Boost
Recent works have shown that convolutional networks have substantially improved the performance of multiple object tracking by simultaneously learning detection and appearance features. However, due to the local perception of the convolutional network structure itself, the long-range dependencies in both the spatial and temporal cannot be obtained efﬁciently. To incorporate the spatial layout, we propose to exploit the local correlation module to model the topological relationship between targets and their sur-rounding environment, which can enhance the discrimina-tive power of our model in crowded scenes. Speciﬁcally, we establish dense correspondences of each spatial loca-tion and its context, and explicitly constrain the correla-tion volumes through self-supervised learning. To exploit the temporal context, existing approaches generally utilize two or more adjacent frames to construct an enhanced fea-ture representation, but the dynamic motion scene is inher-ently difﬁcult to depict via CNNs. Instead, our paper pro-poses a learnable correlation operator to establish frame-to-frame matches over convolutional feature maps in the different layers to align and propagate temporal context.
With extensive experimental results on the MOT datasets, our approach demonstrates the effectiveness of correlation learning with the superior performance and obtains state-of-the-art MOTA of 76.5% and IDF1 of 73.6% on MOT17. 1.

Introduction
Multi-Object Tracking (MOT) is an essential compo-nent for computer vision with many applications, such as video surveillance [31] and modern autonomous driv-ing [19, 41]. It aims to continuously locate trajectories of multiple targets in video frames. Decades of research efforts have led to impressive performance on challenging bench-marks [24, 30, 8].
MOT has traditionally adopted the tracking-by-detection paradigm [3, 5, 1, 58], which capitalizes on the natural di-vision of detection and data association tasks for the prob-lem. These algorithms extract appearance features within
Space-time
Query
References (c) Spatial-Temporal Correlation Representation
Figure 1. Visualization of the matching conﬁdences (a)-(b) com-puted between the indicated target (white cross) in the reference image and all locations of the query image. The appearance fea-ture based tracker [58] (a) generates undistinctive and inaccurate conﬁdences due to the existing of similar distractors. In contrast, our Correlation Tracker (b) predicts a distinct high-conﬁdence value at the correct location, with correlation learning (c). each detection patches and record object location informa-tion for subsequent data association [51, 5]. This track-ing paradigm makes researchers mainly focus on optimiz-ing detection [56, 16], feature representation [27, 15], or data association [3, 5, 17]. With the rapid progress of detec-tion algorithms [13, 14, 36, 35], the detection based track-ing has achieved great performance improvement [56, 16].
Although tremendous strides have been made in MOT, there still exists tough challenges in determining distractors and frequent occlusions, especially in complex interactive scenes [8]. Additionally, the above cascaded structure is in-efﬁcient and prevents the joint optimization between stages.
One promising approach is to extend the end-to-end trainable detection framework [36, 35, 64] to jointly learn detection and appearance feature, which has largely ad-vanced the state-of-the-art in MOT [44, 50, 29, 58]. How-ever as illustrated in Fig. 1, in the case of existing similar distractors, the appearance feature generates undistinctive and inaccurate matching conﬁdences (Fig. 1a), severely af-fecting the performance of association. These methods are limited in local descriptors, and it is difﬁcult to distinguish 3876
similar objects. While as shown in Fig. 1c, the context rela-tion map can help to easily distinguish different targets.
Based on those observations, we propose a correlation network to learn the topological information of the ob-ject and context. Speciﬁcally, we use a spatial correlation layer to record the relationship between targets and rela-tive spatial positions. While constructing a full correlation (e.g., non-local [48]) for all locations is computationally prohibitive for real-time MOT, this work constructs a local correlation volume by limiting the search range at each fea-ture pyramid. Besides, our correlation learning is not lim-ited for targets of interest category [53, 49].