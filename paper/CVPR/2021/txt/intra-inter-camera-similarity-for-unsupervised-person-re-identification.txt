Abstract
Most of unsupervised person Re-Identiﬁcation (Re-ID) works produce pseudo-labels by measuring the feature similarity without considering the distribution discrepancy among cameras, leading to degraded accuracy in label computation across cameras. This paper targets to ad-dress this challenge by studying a novel intra-inter cam-era similarity for pseudo-label generation. We decompose the sample similarity computation into two stage, i.e., the intra-camera and inter-camera computations, respectively.
The intra-camera computation directly leverages the CNN features for similarity computation within each camera.
Pseudo-labels generated on different cameras train the re-id model in a multi-branch network. The second stage con-siders the classiﬁcation scores of each sample on different cameras as a new feature vector. This new feature effec-tively alleviates the distribution discrepancy among cam-eras and generates more reliable pseudo-labels. We hence train our re-id model in two stages with intra-camera and inter-camera pseudo-labels, respectively. This simple intra-inter camera similarity produces surprisingly good perfor-mance on multiple datasets, e.g., achieves rank-1 accuracy of 89.5% on the Market1501 dataset, outperforming the re-cent unsupervised works by 9+%, and is comparable with the latest transfer learning works that leverage extra anno-tations. 1.

Introduction
Person Re-Identiﬁcation (ReID) aims to match a given query person in an image gallery collected from non-overlapping camera networks [41, 23]. Thanks to the pow-erful deep Convolutional Neural Network (CNN), great pro-gresses have been made in fully-supervised person ReID
[38, 25, 19, 18, 30]. To relieve the requirement of expensive person ID annotation, increasing efforts are being made on
The code is available at https://github.com/SY- Xuan/
IICS.
Figure 1. t-SNE visualization [20] of features from a subset of
DukeMTMC-ReID. Different colors indicate samples from dif-ferent cameras. Baseline features in (a) suffer from feature dis-tribution discrepancies among cameras. Features learned by our method are visualized in (b), where features from different cam-eras have similar distribution. unsupervised person ReID [36, 49, 12, 33, 32, 6], i.e., train-ing with labeled source data and unlabeled target data, or fully relying on unlabeled target data for training.
Existing unsupervised person ReID works can be grouped into three categories: a) using domain adapta-tion to align distributions of features between source and target domains [32, 15, 29], b) applying Generative Ad-versarial Network (GAN) to perform image style trans-fer, meanwhile maintaining the identity annotations on source domains [49, 31, 45, 3], and c) generating pseudo-labels on target domains for training via assigning simi-lar images with similar labels via clustering, KNN search, etc. [16, 5, 35, 6, 28]. The ﬁrst two categories deﬁne un-supervised person ReID as a transfer learning task, which leverages the labeled data on source domains. Generating pseudo-labels makes it possible to train ReID models with fully unsupervised setting, thus shows better ﬂexibility.
Most of pseudo-labels prediction algorithms share a sim-ilar intuition, i.e., ﬁrst computing sample similarities, then assigning similar samples identiﬁed by clustering or KNN with similar labels. During this procedure, the computed sample similarity largely decides the ReID accuracy. To generate high quality pseudo-labels, samples of the same identity are expected share larger similarities than with those from different identities. However, the setting of un-supervised person ReID makes it difﬁcult to learn reliable 11926
sample similarities, especially for samples from different cameras. For example, each identity can be recorded by multi-cameras with varied parameters and environments.
Those factors may signiﬁcantly change the appearance of the identity. In other words, the domain gap among cam-eras makes it difﬁcult to identify samples of the same iden-tity, as well as to optimize of intra-class feature similarity.
We illustrated the feature distribution of different cameras in Fig. 1 (a).
This paper addresses the above challenge by studying a more reasonable similarity computation for pseudo-labels generation. Identifying samples of the same identify within the same camera is easier than performing the same task among different cameras. Meanwhile, domain gaps can be alleviated by learning generalizable classiﬁers. We hence decompose the sample similarity computation into two stages to progressively seek reliable pseudo-labels. The ﬁrst stage computes sample similarity within each camera with
CNN features. This “intra-camera” distance guides pseudo-label generation within each camera by clustering samples and assigning samples within the same cluster with the same label. Independent pseudo-labels in C cameras hence train the ReID model with a C-branch network, where the shared backbone is optimized by multiple tasks, and each branch is optimized by a speciﬁc classiﬁcation task within the same camera. This stage simpliﬁes pseudo-label generation, thus ensures high quality pseudo-labels and efﬁcient backbone optimization.
The second stage proceeds to compute sample similari-ties across cameras. Sample similarity computed with CNN features can be affected by domain gap, e.g., large domain gap decreases the similarity among samples of the same identity as illustrated in Fig. 1 (a). As discussed in pre-vious works [4, 26], the classiﬁcation probability is more robust the domain gap than raw features. We alleviate the domain gap by enhancing the generalization ability of trained classiﬁers in the ﬁrst stage. Speciﬁcally, we clas-sify each sample with C classiﬁers, and use their classiﬁ-cation scores as a new feature vector. To ensure the clas-siﬁcation scores robust to the domain gap, each classiﬁer trained on one camera should generalize well on other cam-eras. This is achieved with the proposed Adaptive Instance and Batch Normalization (AIBN), which enhances the gen-eralization ability of classiﬁer without reducing their dis-criminative ability. Classiﬁcation scores produced by C classiﬁers are hence adopted to calculate the “inter-camera” similarity to seek pseudo-labels across cameras. The ReID model is ﬁnally optimized by pseudo-labels generated with both stages. Distribution of features learned by our method is illustrated in Fig. 1 (b), where the domain gaps between cameras are effectively eliminated.
We test our approach in extensive experiments on including Market1501 [41], multiple ReID datasets
DukeMTMC-ReID [23] and MSMT17 [31], respectively.
Experiments show that each component in our approach is valid in boosting the ReID performance. A complete approach consisting of intra-inter camera similarities ex-hibits the best performance. For instance, without lever-aging any annotations, our approach achieves rank-1 accu-racy of 89.5% on the Market1501 dataset, outperforming the recent unsupervised works by 9+%. Our method also performs better than many recent transfer learning works that leverage extra annotations. For instance, the recent
MMT [7] and NRMT [40] achieves lower rank-1 accura-cies of 87.7% and 87.8% respectively, even they leverage extra annotations on DukeMTMC-ReID [23] for training.
The promising performance demonstrates the validity of our method, which decomposes the similarity computation into two stages to progressively seek better pseudo-labels for training. This strategy is more reasonable than directly predicting pseudo-labels across cameras in that, it effec-tively alleviates the domain gap between cameras. Besides that, those two stages corresponds to different difﬁculty in predicting pseudo-labels, thus are complementary to each other in optimizing the ReID model. To the best of our knowledge, this is an original work studying better simi-larity computation strategies in unsupervised person ReID. 2.