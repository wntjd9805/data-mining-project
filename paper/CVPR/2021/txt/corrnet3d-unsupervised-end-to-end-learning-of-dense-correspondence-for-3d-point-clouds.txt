Abstract
Motivated by the intuition that one can transform two aligned point clouds to each other more easily and mean-ingfully than a misaligned pair, we propose CorrNet3D – the ﬁrst unsupervised and end-to-end deep learning-based framework – to drive the learning of dense correspon-dence between 3D shapes by means of deformation-like reconstruction to overcome the need for annotated data.
Speciﬁcally, CorrNet3D consists of a deep feature em-bedding module and two novel modules called correspon-dence indicator and symmetric deformer. Feeding a pair of raw point clouds, our model ﬁrst learns the pointwise features and passes them into the indicator to generate a learnable correspondence matrix used to permute the in-put pair. The symmetric deformer, with an additional reg-ularized loss, transforms the two permuted point clouds to each other to drive the unsupervised learning of the correspondence. The extensive experiments on both syn-thetic and real-world datasets of rigid and non-rigid 3D shapes show our CorrNet3D outperforms state-of-the-art methods to a large extent, including those taking meshes as input. CorrNet3D is a ﬂexible framework in that it can be easily adapted to supervised learning if annotated data are available. The source code and pre-trained model will be available at https://github.com/ZENGYIMING-EAMON/CorrNet3D.git. 1.

Introduction
Owing to the ﬂexibility and efﬁciency in representing 3D objects/scenes as well as the recent advances in 3D sens-ing technology, 3D point clouds have been widely adopted in various applications, e.g., immersive communication [2], autonomous driving [33], AR/VR [37], etc. Since each
*This work was supported by the HK RGC Grant CityU 11202320, the
NSFC Grant 61871342, and Singapore MOE Grant 20/20.
†Corresponding author. camera/scanner produces a point cloud in its own camera space rather than the object space, there is no correspon-dence between two point clouds (even they represent the same object), which poses great challenges for downstream processing and analysis, such as motion transfer [39], shape editing [24], dynamic point cloud compression [20], object recognition [3], shape retrieval [11], surface reconstruction
[7], and many others.
Building dense shape correspondence is a fundamen-tal and challenging problem in computer vision and dig-ital geometry processing. There are a considerable num-ber of methods proposed, which can be roughly classiﬁed into two categories: model-based [6, 19, 41, 28] and data-driven [23, 9, 8]. The model-based methods usually use handcrafted features to optimize pre-deﬁned processes. The recent deep learning-based methods train their neural net-works in a data-driven manner and improve the performance to a large extent. However, the existing methods either re-quire a large amount of annotated data which are difﬁcult to obtain or assume the connectivity information is available in the input data, i.e., polygonal meshes. This paper focuses on unsupervised learning of dense correspondence between non-rigid 3D shapes in the form of 3D point clouds, but the proposed method can also be used for rigid 3D shapes. j, z′
Motivation. Let A ∈ Rn×3 and B ∈ Rn×3 be the two point clouds to be corresponded*, where ai = {xi, yi, zi}, 1 ≤ i ≤ n and bj = {x′ j, y′ j}, 1 ≤ j ≤ n are the i-th and j-th 3D points of A and B, respectively. Fig. 1 illustrates our motivation: if A and B are well aligned, it is easier to transform one model to the other. More precisely,
B ∈ Rn×3 the re-ordered A and denote by
B via a designed permutation process, respectively. With a (cid:2) designed reconstruction process, it is expected that we can reconstruct A (resp. B) from
A) more easily and meaningfully than the manner of reconstructing A (resp. (cid:2)
B) from B (resp. A) directly. Therefore, we can minimize
A) to A (resp. B) the reconstruction error from (cid:2)
A ∈ Rn×3 and (cid:2)
B (resp. (cid:2)
B (resp. (cid:2)
*Note that the points are randomly stacked to form a matrix. 6052
Reconstruction
L2 reconstruction
+ regularizations
Point cloud A rmuted
Permuted 
Permutation
Shared network
Reconstructed
Point cloud B
Reconstruction
L2 reconstruction
+ regularizations
Point cloud B rmuted
Permuted 
Reconstructed 
Point cloud A
Figure 1. Illustration of the motivation of our unsupervised deep learning-based framework for computing dense correspondence between two point clouds. to drive the learning of the permutation process, which im-plicitly encodes the dense correspondence between A and
B.
Based on the above intuitive understanding, we propose the ﬁrst unsupervised and end-to-end deep learning-based framework for point clouds. Technically, we propose a novel correspondence indicator and a deformation-like re-construction module to achieve the permutation and recon-struction processes, respectively. To be speciﬁc, the corre-spondence indicator, fed with point-wise high-dimensional feature representations of the input point clouds learned by a hierarchical feature embedding module, generates a permu-tation matrix, which explicitly encodes the point-to-point correspondence. During training, the deformation-like re-construction module receives the aligned point clouds and the global semantic features of inputs to reconstruct each other by optimizing the reconstruction error and additional regularization terms to drive the learning of the permutation matrix.
In summary, we make the following contributions. 1. We propose the ﬁrst unsupervised deep learning frame-work for building dense correspondence between point clouds in an end-to-end manner. 2. We propose two novel modules, i.e., the correspon-dence indicator with the efﬁcient DeSmooth module, the symmetric deformation module, as well as a novel loss function. 3. We show that CorrNet3D can be adapted to both un-supervised and supervised conditions, and handle both non-rigid and rigid shapes well. 4. We experimentally demonstrate the signiﬁcant superi-ority of CorrNet3D over state-of-the-art methods. Es-pecially, CorrNet3D even outperforms the method tak-ing 3D meshes as input. 2.