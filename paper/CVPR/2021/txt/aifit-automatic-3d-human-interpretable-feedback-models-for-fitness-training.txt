Abstract
I went to the gym today, but how well did I do? And where should I improve? Ah, my back hurts slightly... User engagement can be sustained and injuries avoided by being able to reconstruct 3d human pose and motion, relate it to good training practices, identify errors, and provide early, real-time feedback. In this paper we introduce the ﬁrst au-tomatic system, AIFit, that performs 3d human sensing for
ﬁtness training. The system can be used at home, outdoors, or at the gym. AIFit is able to reconstruct 3d human pose, shape, and motion, reliably segment exercise repetitions, and identify in real-time the deviations between standards learnt from trainers, and the execution of a trainee. As a result, localized, quantitative feedback for correct exe-cution of exercises, reduced risk of injury, and continuous improvement is possible. To support research and evalua-tion, we introduce the ﬁrst large scale dataset, Fit3D, con-taining over 3 million images and corresponding 3d human shape and motion capture ground truth conﬁgurations, with over 37 repeated exercises, covering all the major muscle groups, performed by instructors and trainees. Our statisti-cal coach is governed by a global parameter that captures how critical it should be of a trainee’s performance. This is an important aspect that helps adapt to a student’s level of ﬁtness (i.e. beginner vs. advanced vs. expert), or to the expected accuracy of a 3d pose reconstruction method. We show that, for different values of the global parameter, our feedback system based on 3d pose estimates achieves good accuracy compared to the one based on ground-truth mo-tion capture. Our statistical coach offers feedback in nat-ural language, and with spatio-temporal visual grounding. 1.

Introduction
In nowadays busy, high pressure working environments,
ﬁtness is essential in order to stay in shape, maintain bal-ance, enhance the immune system, and prevent the emer-gence of chronic diseases. It is also critical for the elderly in order to maintain mobility, combat anxiety, and slow-down aging. This has increasingly resonated with the broad pub-lic. Besides the growing number of standard gym subscrip-tions, there are emergent online services (e.g. Peloton, Mir-ror or ClassPass, among others) that aim to bring ﬁtness at home. Some trainers run popular Youtube ﬁtness channels or apps (e.g. Athlean-X, The Fitness Marshall, Blogilates, etc.), and public interest spurs billions of searches and views of such instructional video each year. However, whether at the gym, at home, or outdoors, ﬁtness enthusiasts face some of the same outstanding challenges: making sure they exer-cise correctly, avoid injury, gain insights into their progress, maintain motivation to get the job done, and ultimately have fun. Even when personal trainers are available, their en-gagement is typically limited to the time spent with the trainee at the gym. In practice, personal trainers may need to joggle between different clients, making it difﬁcult to provide the continuous observation, feedback, and encour-agement their clients sometimes need in order to progress.
This naturally raises the question whether personal experi-ence can be improved by leveraging recent advances in 3d human sensing and AI. To complement human trainers, in this paper we propose AIFit, the ﬁrst AI-enhanced training system for ﬁtness. The system is able to reconstruct 3d hu-man pose over time, count repetitions, and automatically provide localized feedback, visually grounded in images of the trainee, and phrased in natural language displayed on a screen. In order to support research and evaluation, we introduce Fit3D, a large-scale dataset of over 3 million im-ages and ground truth 3d motion capture poses, collected from 13 subjects (including one licensed ﬁtness instructor and one advanced ﬁtness subject), observed by 4 different
RGB cameras, together with 3d scans of each subject. The dataset features 37 exercises consisting of simple and com-pound motions, covering all major muscle groups and ar-ticulation types, including, among many others, warm-ups, 9919
barbells, dumbbells, push-ups, or yoga.
Our proposed methodology includes large-scale monoc-ular and multi-view evaluation of 3d human pose recon-struction for ﬁtness training using Fit3D, models for auto-matic identiﬁcation of exercise repetitions, as well as meth-ods to compare instructors’ and trainees’ performances ac-cording to statistical policies deﬁned over mined features (passive and active) deﬁning the exercise, and carrying most of its motion energy. Our statistical coach is governed by a global parameter ranging between 0 and 1 that models how critical it is in regard to a student’s performance: 0 - very critical, 1 - very relaxed. In practice, the parameter helps the coach adapt to a student’s level of ﬁtness (i.e. beginner vs advanced vs expert) or to the expected accuracy of the underlying 3d pose reconstruction method. We show that, for different values of this parameter, our feedback system based on 3d pose estimates achieves high accuracy when compared to one based on ground-truth motion capture 3d poses. Finally and importantly, our statistical coach pro-vides easy to understand, visually grounded spatio-temporal feedback, in natural language. A system overview is shown in ﬁg. 1. 2.