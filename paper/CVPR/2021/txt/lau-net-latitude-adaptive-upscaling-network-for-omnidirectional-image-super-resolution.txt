Abstract
The omnidirectional images (ODIs) are usually at low-resolution, due to the constraints of collection, storage and transmission. The traditional two-dimensional (2D) im-age super-resolution methods are not effective for spher-ical ODIs, because ODIs tend to have non-uniformly dis-tributed pixel density and varying texture complexity across latitudes. In this work, we propose a novel latitude adap-tive upscaling network (LAU-Net) for ODI super-resolution, which allows pixels at different latitudes to adopt distinct upscaling factors. Speciﬁcally, we introduce a Laplacian multi-level separation architecture to split an ODI into dif-ferent latitude bands, and hierarchically upscale them with different factors. In addition, we propose a deep reinforce-ment learning scheme with a latitude adaptive reward, in order to automatically select optimal upscaling factors for different latitude bands. To the best of our knowledge,
LAU-Net is the ﬁrst attempt to consider the latitude differ-ence for ODI super-resolution. Extensive results demon-strate that our LAU-Net signiﬁcantly advances the super-resolution performance for ODIs. Codes are available at https://github.com/wangh- allen/LAU- Net. 1.

Introduction
With the rapid development of virtual reality (VR), om-nidirectional images (ODIs) are playing increasingly impor-tant roles in human’s life. When viewing ODIs, people can obtain immersive and interactive experience via changing their viewports in the range of 360 × 180◦. Typically, peo-ple watch ODIs through head-mounted displays (HMD), in which only the viewport with a limited range is visible. To
*Authors contributed equally.
†Corresponding author. make this small viewport in high-resolution (HR), the whole
ODI requires extremely high resolution [11]. However, due to the constraints of capture, storage and transmission , the resolution of ODIs cannot be sufﬁciently high.
Super-resolution (SR) is a common technique to address the aforementioned issue, which aims to restore an HR image from a single or a sequence of low-resolution (LR) images
[12]. As a challenging ill-posed inverse problem, SR has received extensive study for decades [33, 45, 4, 36, 1]. How-ever, the existing SR methods target at two-dimensional (2D) planar images, which are not appropriate for ODIs. For storage convenience, the spherical ODIs are usually pro-jected into 2D planes. The widely used projection method is equirectangular projection (ERP), which leads to non-uniform pixel density across latitudes, in particular geomet-ric distortion in high-latitude areas. As shown in Fig. 1, the density of pixels after ERP is in negative correlation to lati-tudes, i.e., the pixel distribution in higher latitudes tends to be more sparse than those in lower latitudes. In addition, the image patches at high-latitude areas usually have signiﬁcant stretch distortion. Since the 2D SR methods do not consider these characteristics of ODIs, as veriﬁed in Finding 2, they often result in unsatisfactory SR results for ODIs.
For ODI SR, the existing methods primarily rely on as-sembling a sequence of LR ODIs to form an HR ODI. The representative works include Nagahara et al. [27], Arican et al.[2], and Bagnato et al. [3]. All these methods have the same disadvantage, i.e., their performance heavily depends on the number of LR images and the registration accuracy among them. Recently, Ozcinar et al. [28] proposed a gen-erative adversarial network (GAN) to perceptually super-resolve the ODIs, and remove the artifacts in the spherical space. However, they merely treat the ERP projected ODI as a normal 2D image, without considering the varying pixel density across latitudes.
In this paper, we propose a novel latitude adaptive upscal-9189
Figure 1. The basic framework of our method for omnidirectional image super-resolution. ing network (LAU-Net), to dynamically upscale different latitude bands of ODIs with various upscaling factors. To determine the optimal upscaling factors for different latitude bands, we jointly train several evaluators for different bands with a multi-level CNN to ﬁnd the optimal upscaling factor.
The evaluators are trained by reinforcement learning (RL) with the reward encouraging both high SR performance and low computation complexity. As shown in Fig 1, “easy” patches with high latitude and low image complexity are stopped training at the ﬁrst level, while “hard” patches with low latitude and high image complexity progressively go deeper until the last level. Using early quit strategy com-bined with RL network, our LAU-Net obtains better objec-tive quality while saving computations effectively. The main contributions of our work are as follows:
• We establish a large database for ODI SR, which con-sists of 1,000 high-quality ODI images, with diverse image resolutions and content.
• We propose a new network named LAU-Net for ODI
SR, in which different latitude bands are allowed to have distinct upscaling factors for resource efﬁciency.
• We develop an RL scheme to automatically select the optimal upscaling factors for different latitude bands, which signiﬁcantly improves the SR performance using less computational resource. 2.