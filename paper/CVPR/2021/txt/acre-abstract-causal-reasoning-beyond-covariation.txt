Abstract Causal REasoning Beyond Covariation
Chi Zhang
Baoxiong Jia
Mark Edmonds
Song-Chun Zhu
Yixin Zhu
UCLA Center for Vision, Cognition, Learning, and Autonomy
{chi.zhang,baoxiongjia,markedmonds}@ucla.edu, sczhu@stat.ucla.edu, yixin.zhu@ucla.edu
Abstract direct screening-off
Causal induction, i.e., identifying unobservable mecha-nisms that lead to the observable relations among variables, has played a pivotal role in modern scientiﬁc discovery, es-pecially in scenarios with only sparse and limited data. Hu-mans, even young toddlers, can induce causal relationships surprisingly well in various settings despite its notorious difﬁculty. However, in contrast to the commonplace trait of human cognition is the lack of a diagnostic benchmark to measure causal induction for modern Artiﬁcial Intelli-gence (AI) systems. Therefore, in this work, we introduce the Abstract Causal REasoning (ACRE) dataset for system-atic evaluation of current vision systems in causal induc-tion. Motivated by the stream of research on causal discov-ery in Blicket experiments, we query a visual reasoning sys-tem with the following four types of questions in either an independent scenario or an interventional scenario: direct, indirect, screening-off, and backward-blocking, intention-ally going beyond the simple strategy of inducing causal relationships by covariation. By analyzing visual reason-ing architectures on this testbed, we notice that pure neu-ral models tend towards an associative strategy under their chance-level performance, whereas neuro-symbolic combi-nations struggle in backward-blocking reasoning. These de-ﬁciencies call for future research in models with a more comprehensive capability of causal induction. 1.

Introduction
“There is something fascinating about science.
One gets such wholesale returns of conjecture out of such a triﬂing investment of fact.”
— Mark Twain [64]
The history of scientiﬁc discovery is full of intriguing anecdotes. Mr. Twain is accurate in summarizing how inﬂu-ential science theories are distilled from sparse and limited investments. From only three observations, Edmond Hal-ley precisely predicted the orbit of the Halley comet and its next visit, which he did not live to see. From a few cathode indirect backward-blocking
A
B
Figure 1. Abstract causal reasoning tasks administered to human participants [22, 61]. The Blicket machine possesses various ac-tivation patterns in these four cases. One needs to discover the hidden causal relations to answer two types of questions: whether object A / B is a Blicket, and how to make the machine stop / go. rays, Joseph Thomson proved and derived the existence of electrons. From merely crossbreeding of pea plants, Gregor
Mendel established the laws of Mendelian inheritance much beyond pea plants. Out of many other possible conjectures, pioneering scientists picked the most plausible ones.
The above examples of causal induction are only a few acclaimed cases of omnipresent causal reasoning scenarios in science history and our daily life. In fact, despite the no-torious complexity in causal discovery, humans, even young toddlers, can felicitously identify and, sometimes, intervene in the unobservable mechanisms from only a triﬂing num-ber of samples of observable events [19, 58].
This captivating commonplace trait of human cognition and its paramount connection to human learning mecha-nism motivate us to ask a counterpart question for modern
Artiﬁcial Intelligence (AI) systems:
At what level do current visual reasoning systems induce causal relationships?
To answer this question, we propose the Abstract Causal
REasoning (ACRE) dataset. ACRE is inspired by the es-tablished stream of research on Blicket detection originally administered to young toddlers [7, 19, 20, 21, 22, 23, 35, 42, 44, 58, 60, 61, 66, 67]. The original experiments de-signed by Gopnik and Sobel [21] introduced a novel setup for investigating children’s ability of causal induction, in which children were given a special machine referred to as “Blicket detector.” Its underlying mechanism is intuitive:
A Blicket detector would activate, lighting up and making 10643
noise, when a “Blicket” was put on it. The experimenter demonstrated a series of trials to participants by placing various (combinations of) objects on the Blicket detector and showing whether the detector was activated or not. At length, the participants were asked which object is a Blicket and how to make an (in)activated Blicket machine stop (go).
This line of work’s intricate nature lies in how the con-text and query were designed to test abstract causal rea-soning beyond the simple strategy of covariation; see an illustration in Fig. 1. As a base test on causal discovery by covariation, Sobel et al. [61] show that children can correctly associate cause and effect using direct evidence.
They also show that with only indirect evidence asserting the Blicketness of object B, children still made accurate predictions [22]. However, one must go beyond the simple covariation strategy to discover the hidden causal relations in the screening-off case and the backward-blocking case.
Speciﬁcally, in the screening-off setting (Fig. 1 Top), object
B (non-Blicket) is screened-off by A (Blicket) from prob-abilistically activating the machine [22]. The backward-blocking setting (Fig. 1 Bottom) is even more intriguing as object B, not independently tested, has undetermined
Blicketness despite the fact that every appearance of it is associated with an activated machine [61]. See Section 3 for details and the supplementary for a symbolic summary.
The proposed ACRE dataset is built following a sim-ilar querying manner in the Blicket experiments to study how well existing visual reasoning systems can learn to de-rive ample causal information from scarce observation. In particular, inspired by the recent endeavors of visual rea-soning in controlled environments [17, 32, 70], we adopt the CLEVR universe [32] in ACRE’s design and add a
Blicket machine to signal its state of activation, intention-ally simplifying visual information processing and empha-sizing causal reasoning. Following attempts made in ab-stract spatial-temporal reasoning benchmarks [31, 55, 72], we provide the visual reasoning system with sets of panel images as context and use image-based queries to ease lan-guage understanding, echoing the setup and the learning theories in developmental literature [19, 20, 21, 22, 23].
Speciﬁcally, each problem in ACRE consists of 10 pan-els: 6 for context and 4 for query. The 6 context panels are divided into two sets, the ﬁrst of which serves as an intro-duction to the Blicket mechanism that some objects activate the machine, and others do not. This simpler set of panels resembles the introductory trials administered to children in human experiments [22, 61]. Instead of bringing in the con-cept of Blicket1, in queries, we only ask a visual reasoning system to predict the state of the Blicket machine given the objects in the queries. Half of the queries concern the inde-1While the notion of “Blicket” is not necessary for a visual reasoning system to solve the task, we use the term throughout this paper to simplify expressions and facilitate understanding of the core ideas. pendent scenarios, wherein a single object is presented, and the system is challenged to reason about whether this object is one of the causes that could activate the Blicket machine.
The remaining half of the queries are for interventional sce-narios, wherein we intervene in an existing context panel and ask what the state of the Blicket machine would be un-der the intervention. Each query is independent such that statistical bias [22, 61] and potential cheating for abstract reasoning [31, 72] are minimized. In summary, ACRE in-cludes 30, 000 abstract causal reasoning problems, supports all 4 types of reasoning queries (direct, indirect, screening-off, and backward-blocking), and is fully annotated with ob-ject attributes, bounding boxes, and masks. We further de-sign two Out-Of-Distribution (O.O.D.) generalization splits in ACRE to evaluate models’ generalizability.
In experiments, we use the ACRE dataset to analyze cur-rent visual reasoning systems’ ability in causal induction.
Despite remarkable results in other visual reasoning tasks, we notice that pure neural networks [8, 28, 55, 68, 77] fa-vor a covariation-based reasoning strategy and thus can only achieve performance marginally above the chance level. As the ﬁrst attempt in the exploration to empower visual rea-soning systems for causal induction, we resort to neuro-symbolic models [26, 39, 43, 50, 51, 70, 71, 74, 76] that combine neural visual processing [27] and symbolic causal reasoning [18, 49, 53, 62, 78, 79], which turn out to struggle in backward-blocking cases in abstract causal reasoning.
To sum up, this paper makes three primary contributions:
• We propose the Abstract Causal REasoning (ACRE) dataset to probe current visual reasoning systems’ ca-pacity in causal induction. The dataset is inspired by the Blicket experiments and contains 30, 000 problems.
ACRE covers all 4 types of causal reasoning queries (di-rect, indirect, screening-off, and backward-blocking) with additional O.O.D. generalization splits.
• We benchmark and analyze state-of-the-art visual reason-ing models in ACRE. Experimental results show that neu-ral models tend to capture statistical correlations in obser-vation but fail to induce the underlying causal relation-ships demonstrated in the trials.
• We propose neuro-symbolic combinations that improve on pure neural networks. However, our analysis shows that even with the inductive bias in causality, they still fail to distinguish a true cause from superﬁcial covariation in backward-blocking cases. Taken together, these deﬁcien-cies call for future research in models with a more com-prehensive capability of causal induction. 2.