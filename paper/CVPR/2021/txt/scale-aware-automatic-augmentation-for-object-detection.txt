Abstract
We propose Scale-aware AutoAug to learn data augmen-tation policies for object detection. We deﬁne a new scale-aware search space, where both image- and box-level aug-mentations are designed for maintaining scale invariance.
Upon this search space, we propose a new search met-ric, termed Pareto Scale Balance, to facilitate search with high efﬁciency. In experiments, Scale-aware AutoAug yields signiﬁcant and consistent improvement on various object detectors (e.g., RetinaNet, Faster R-CNN, Mask R-CNN, and FCOS), even compared with strong multi-scale training baselines. Our searched augmentation policies are trans-ferable to other datasets and box-level tasks beyond ob-ject detection (e.g., instance segmentation and keypoint es-timation) to improve performance. The search cost is much less than previous automated augmentation approaches for object detection.
It is notable that our searched policies have meaningful patterns, which intuitively provide valu-able insight for human data augmentation design. Code and models are available at https://github.com/Jia-Research-Lab/SA-AutoAug. 1.

Introduction
Object detection, aiming to locate as well as classify var-ious objects, is one of the core tasks in the computer vision.
Due to the large scale variance of objects in real-world sce-narios, it raises concerns on how to bring the scale adap-tation to the network efﬁciently. Previous work handles this challenge mainly from two aspects, namely network ar-chitecture and data augmentation. To make the network scale invariant, in-network feature pyramids [28, 47, 23] and adaptive receptive ﬁelds [25] are usually employed.
Another crucial technique to enable scale invariance is data augmentation, which is independent of speciﬁc architec-tures, and can be generalized among multiple tasks.
This paper focuses on data augmentation for object detection. Current data augmentation strategies can be
Figure 1: Comparison with object detection augmentation strate-gies on MS COCO dataset. Methods in the same vertical line are based upon the same detector. Scale-aware AutoAug outperforms both hand-crafted and learned strategies on various detectors. grouped into color operations (e.g., brightness, contrast, and whitening) and geometric operations (e.g., re-scaling, ﬂip-ping). Among them, geometric operations, such as multi-scale training, improve scale robustness [39, 19]. Sev-eral hand-crafted data augmentation strategies were devel-oped to improve performance and robustness of the detec-tor [41, 42]. Previous work [17, 15] also improves box-level augmentation by enriching foreground data. Though inspir-ing performance gain has achieved, these data augmentation strategies usually rely on heavy expert experience.
Automatic data augmentation policies were widely ex-plored in image classiﬁcation [44, 50, 37, 35, 9]. Its poten-tial for object detection, however, was not thoroughly re-leased. One attempt to automatically learn data augmen-tation policies for object detectors is AutoAug-det [51]1, which performs color or geometric augmentation upon the context of boxes. It does not fully consider the scale issue from image- and box-level, which are found, however, es-sential in object detector design [41, 42, 17]. Moreover, the heavy computational search cost (i.e., 400 TPU for 2 days) impedes it from vastly practical. Thus, scale-aware property and efﬁciency issue are essential to address for searching augmentation in box-level tasks.
In this paper, we propose a new way to automatically
*This work was done during an internship at ByteDance AI Lab. Tao
Kong is responsible for correspondence. †Equal contribution. 1We refer it as AutoAug-det [51] to distinguish from AutoAugment [9]. 9563
learn scale-aware data augmentation strategies for object detection and relevant box-level tasks. We ﬁrst introduce scale-awareness to the search space from two image- and box-levels. For image-level augmentations, zoom-in and
-out operations are included with their probabilities and zooming ratios for search. For box-level augmentations, the augmenting areas are generalized with a new searchable parameter, i.e., area ratio. This makes box-level augmenta-tions adaptive to object scales.
Based on our scale-aware search space, we further pro-pose a new estimation metric to facilitate the search process with better efﬁciency. Previously, each candidate policy is estimated by the validation accuracy on a proxy task [9, 27], which lacks efﬁciency and accuracy to an extend. Our met-ric takes advantage of more speciﬁc statistics, that is, vali-dation accuracy and accumulated loss over different scales, to measure the scale balance. We empirically show that it yields a clearly higher correlation coefﬁcient with the actual accuracy than the previous proxy accuracy metric.
The proposed approach is distinguished from previous work from two aspects. First, different from hand-crafted policies, the proposed method utilizes automatic algorithms to search among a large variety of augmentation candidates.
It is hard to be fully explored or achieved by human effort.
Moreover, compared with previous learning-based meth-ods, our approach fully explores the important scale issue in both image-level and box-level. With the proposed search space and evaluation metric, our method attains decent per-formance with much (i.e., 40×) less search cost.
The overall approach, called Scale-aware AutoAug, can be easily instantiated for box-level tasks, which will be elab-orated on in Sec. 3. To validate its effectiveness, we con-duct extensive experiments on MS COCO and Pascal VOC dataset [30, 16] with several anchor-based and anchor-free object detectors, which are reported in Sec. 4.2.
In particular, with ResNet-50 backbone, the searched augmentation policies contribute non-trivial gains over the strong MS baseline of RetinaNet [29], Faster R-CNN [39], and FCOS [43], and achieve 41.3% AP, 41.8% AP, and 42.6% AP, respectively. We further experiment with more box-level tasks, like instance segmentation and keypoint de-tection. Without bells-and-whistles, our improved FCOS model attains 51.4% AP with the search augmentation poli-cies. Besides, our searched policies present meaningful pat-terns, which provide intuitive insight for human knowledge. 2.