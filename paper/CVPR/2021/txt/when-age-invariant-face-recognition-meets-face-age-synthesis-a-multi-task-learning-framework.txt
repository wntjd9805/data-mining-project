Abstract 10-11-20 21-30 31-40 41-50 51-60 60+
To minimize the effects of age variation in face recog-nition, previous work either extracts identity-related dis-criminative features by minimizing the correlation between identity- and age-related features, called age-invariant face recognition (AIFR), or removes age variation by transform-ing the faces of different age groups into the same age group, called face age synthesis (FAS); however, the former lacks visual results for model interpretation while the lat-ter suffers from artifacts compromising downstream recog-nition. Therefore, this paper proposes a uniﬁed, multi-task framework to jointly handle these two tasks, termed MTL-Face, which can learn age-invariant identity-related repre-sentation while achieving pleasing face synthesis. Specif-ically, we ﬁrst decompose the mixed face features into two uncorrelated components—identity- and age-related features—through an attention mechanism, and then decor-relate these two components using multi-task training and continuous domain adaption.
In contrast to the conven-tional one-hot encoding that achieves group-level FAS, we propose a novel identity conditional module to achieve identity-level FAS, with a weight-sharing strategy to im-prove the age smoothness of synthesized faces.
In addi-tion, we collect and release a large cross-age face dataset with age and gender annotations to advance AIFR and
FAS. Extensive experiments on ﬁve benchmark cross-age datasets demonstrate the superior performance of our pro-posed MTLFace over state-of-the-art methods for AIFR and
FAS. We further validate MTLFace on two popular gen-eral face recognition datasets, showing competitive perfor-mance for face recognition in the wild. The source code and dataset are available at https://github.com/
Hzzone/MTLFace.
∗Corresponding author 8.0 13.0 27.0 31.0 43.0 55.0 76.0
Age Regression
Age Progression
Figure 1: Sample results by our MTLFace. First row: the real faces of the same person at different ages with esti-mated age labels underneath. Remaining rows: the synthe-sized faces when given input faces in the red boxes. 1.

Introduction
Face recognition has been a hot research topic in com-puter vision for many years. Recently, deep-learning-based methods achieve excellent performance, even surpassing humans in several scenarios, by empowering the face recog-nition models with deep neural networks [12, 20, 41]. The traditional wisdom is to utilize the margin-based metrics to increase the intra-class compactness and train the models with a massive amount of data to improve face recognition performance [51].
Despite the remarkable success of general face recogni-tion (GFR), how to minimize the effects of age variation is a lingering challenge for current face recognition systems to correctly identify faces in many practical applications such as ﬁnding lost children. Therefore, it is of great signiﬁcance 7282
to achieve face recognition without age variation, i.e., age-invariant face recognition or AIFR. However, AIFR remains extremely challenging in the following three aspects. First, when the age gap becomes large in cross-age face recogni-tion, age variation can largely affect the facial appearance, compromising the face recognition performance. Second, face age synthesis (FAS) is a complex process involving face aging/rejuvenation (a.k.a age progression/regression) since the facial appearance drastically changes over a long time and differs from person to person. Last, it is infeasible to obtain a large paired face dataset to train a model in ren-dering faces with natural effects while preserving identities.
To overcome these issues, current methods for AIFR can be roughly divided into two categories: generative and discriminative models. Given a face image, the gen-erative models [8, 21, 33] aim to transform the faces of different ages into the same age group in order to assist the face recognition. Recently, generative adversarial net-works (GANs) [11] have been successfully used to enhance the image quality of synthesized faces [23, 26, 49, 54, 55]; they typically use the one-hot encoding to specify the target age group. However, the one-hot encoding represents the age group-level face transformation, ignoring the identity-level personalized patterns and leading to unexpected ar-tifacts. As a result, the performance of AIFR cannot be signiﬁcantly improved due to the unpleasing synthesized faces and unexpected changes in identity. On the other hand, the discriminative models [4, 47] focus on extracting age-invariant features by disentangling the identity-related information from the mixed information so that only the identity-related information is expected for the face recog-nition systems. Although achieving promising performance in AIFR, they cannot provide users, for example policemen, with visual results as the generative methods to further ver-ify the identities, which can compromise the model inter-pretability in the decision-making processes of many prac-tical applications.
To further improve the image quality for generative models and provide the model interpretability for discrim-inative models, we propose a uniﬁed, multi-task learn-ing framework to simultaneously achieve AIFR and FAS, termed MTLFace, which can enjoy the best of both worlds; i.e., learning age-invariant identity-related representation while achieving pleasing face synthesis. More speciﬁ-cally, we ﬁrst decompose the mixed high-level features into two uncorrelated components—identity- and age-related features—through an attention mechanism. We then decor-relate these two components in a multi-task learning frame-work, in which an age estimation task is to extract age-related features while a face recognition task is to extract identity-related features; in addition, a continuous cross-age discriminator with a gradient reversal layer [7] fur-ther encourages the identity-related age-invariant features.
Moreover, we propose an identity conditional module to achieve identity-level transformation patterns for FAS, with a weight-sharing strategy to improve the age smoothness i.e., the faces are aged smoothly. of synthesized faces;
Extensive experiments demonstrate superior performance over existing state-of-the-art methods for AIFR and FAS, and competitive performance for general face recognition in the wild. Fig. 1 presents an example of age progres-sion/regression of the same person from our MTLFace, showing that our framework can synthesize photorealistic faces while preserving identity.
Our contributions are summarized as follows. First, we propose a uniﬁed, multi-task learning framework to jointly handle AIFR and FAS, which can learn age-invariant identity-related representation while achieving pleasing face synthesis. Second, we propose an attention-based fea-ture decomposition to separate the age- and identity-related features on high-level feature maps, which can constrain the decomposition process in contrast to the previous un-constrained decomposition on feature vectors. Age esti-mation and face recognition tasks are incorporated to su-pervise the decomposition process in conjunction with a continuous domain adaption. Third, compared to previous one-hot encoding achieving age group-level face transfor-mation, we propose a novel identity conditional module to achieve identity-level face transformation, with a weight-sharing strategy to improve the age smoothness of synthe-sized faces. Fourth, extensive experiments demonstrate the effectiveness of the proposed framework for AIFR and FAS on ﬁve benchmark datasets, and competitive performance on two popular GFR datasets. Last, we collect and release a large cross-age dataset of millions of faces with age and gender annotations, which can advance the development of the AIFR and FAS. In addition, it is expected to be use-ful for other face-related research tasks; e.g., pretraining for face age estimation. 2.