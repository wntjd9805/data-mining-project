Abstract 1.

Introduction
We introduce the concept of rate-aware deep perceptual preprocessing (DPP) for video encoding. DPP makes a sin-gle pass over each input frame in order to enhance its visual quality when the video is to be compressed with any codec at any bitrate. The resulting bitstreams can be decoded and displayed at the client side without any post-processing component. DPP comprises a convolutional neural network that is trained via a composite set of loss functions that in-corporates: (i) a perceptual loss based on a trained no-reference image quality assessment model, (ii) a reference-based ﬁdelity loss expressing L1 and structural similar-ity aspects, (iii) a motion-based rate loss via block-based transform, quantization and entropy estimates that converts the essential components of standard hybrid video encoder designs into a trainable framework. Extensive testing using multiple quality metrics and AVC, AV1 and VVC encoders shows that DPP+encoder reduces, on average, the bitrate of the corresponding encoder by 11%. This marks the ﬁrst time a server-side neural processing component achieves such savings over the state-of-the-art in video coding.
Streaming high-resolution video comes with an in-evitable trade-off between available bandwidth and visual
In recent years, many video compression stan-quality. dards have been developed, such as Advanced Video Cod-ing (AVC) and AOMedia Video 1 (AV1), which offer a number of advanced coding and prediction tools for efﬁ-cient video encoding and transmission. While these codecs are widely deployed in industry, with AVC still accounting for the largest share of video streaming volume worldwide, the encoding tools are handcrafted and not entirely data de-pendent. This has led to an increased interest in learned video compression methods [24, 13, 11, 35], which claim to offer better encoding efﬁciency by training deep neural networks to improve the rate-distortion performance. How-ever, these methods come with their own pitfalls; typically they require bespoke encoder, bitstream and decoder com-ponents for end-to-end optimization. The decoder is typi-cally computationally heavy and not viable for deployment on CPU-based commodity devices such as mobile phones.
Additionally, work in learned video compression [24, 45] tends to be benchmarked against codecs with limited tools
‘very fast’ preset, low-latency mode and GOP enabled: 14852
sizes of 10 frames. It is unclear if learned video compres-sion methods outperform standards under their more ad-vanced (and most widely used) encoding settings.
In this work we aim to bridge the gap between the data adaptivity and scalability of learned compression methods and the performance and off-the-shelf decoding support of-fered by standard codec implementations. To this end, our proposed deep perceptual preprocessor (DPP) simply prepends any standard video codec at inference, without re-quiring any bespoke encoder of decoder component. The key aspect of our proposal is that it offers rate-aware per-ceptual improvement by encapsulating both perceptual and
ﬁdelity losses, as well as a motion-based rate loss that en-capsulates the effect of motion-compensated prediction and entropy coding.
In addition, our trained DPP models re-quire a single pass over the input and all encodings with different standards-based encoders at various bitrates and resolutions can be subsequently applied to the DPP output.
Experiments versus state-of-the-art AVC, AV1 and Versa-tile Video Coding (VVC) [14] encoders show that DPP al-lows for 11% average reduction in bitrate without requiring changes in encoding, streaming, or video decoding.
We summarize our contributions as follows: 1. We propose a deep perceptual preprocessor (DPP) that preprocesses the input content prior to passing it to any standard video codec, such as AVC, AV1 or VVC. 2. We train the DPP in an end-to-end manner by virtual-izing key components of a standard codec with differ-entiable approximations. We balance between percep-tion and distortion by using an array of no-reference and reference based loss functions. 3. We test our models under the most stringent testing conditions: multi-resolution, multi-QP, convex-hull optimization per clip and high-performance AVC, AV1 and VVC presets used extensively by Netﬂix, Face-book, Intel in several benchmark papers [19, 21, 20].
Visual comparisons of encoder versus DPP+encoder out-puts are shown in Fig. 1 (left), illustrating the visual quality improvement that can be achieved at the same bitrate. Fig. 1 (right) illustrates how DPP is able to offer consistent bitrate savings across three video coding standards of increasing sophistication and complexity, while its runtime overhead diminishes in comparison to the encoding runtime. 2.