Abstract
We show that the inﬂuence of a subset of the train-ing samples can be removed – or “forgotten” – from the weights of a network trained on large-scale image classiﬁ-cation tasks, and we provide strong computable bounds on the amount of remaining information after forgetting. In-spired by real-world applications of forgetting techniques, we introduce a novel notion of forgetting in mixed-privacy setting, where we know that a “core” subset of the training samples does not need to be forgotten. While this varia-tion of the problem is conceptually simple, we show that working in this setting signiﬁcantly improves the accuracy and guarantees of forgetting methods applied to vision clas-siﬁcation tasks. Moreover, our method allows efﬁcient re-moval of all information contained in non-core data by sim-ply setting to zero a subset of the weights with minimal loss in performance. We achieve these results by replacing a standard deep network with a suitable linear approxima-tion. With opportune changes to the network architecture and training procedure, we show that such linear approx-imation achieves comparable performance to the original network and that the forgetting problem becomes quadratic and can be solved efﬁciently even for large models. Un-like previous forgetting methods on deep networks, ours can achieve close to the state-of-the-art accuracy on large scale vision tasks. In particular, we show that our method allows forgetting without having to trade off the model accuracy. 1.

Introduction
When building a classiﬁcation system, one rarely has all the data to be used for training available at the outset. More often, one starts by pre-training a model with some “core” dataset (e.g. ImageNet, or datasets close to the target task) and then incorporates various cohorts of task-speciﬁc data as they become available from diverse sources.
In some cases, the wrong data may be incorporated inadvertently, or the owners may change their mind and demand that their data be removed. One can, of course, restart the training from scratch every time such a demand is made, but at a signiﬁcant cost of time and disruption. What if one could remove the effect of cohort(s) of data a-la-carte, without re-training, in a way that the resulting model is function-ally indistinguishable from one that has never seen the co-hort(s) in question, and in addition has no residual infor-mation about it buried in the weights of the model? Of course, forgetting can always be trivially achieved by ze-roing the weights or replacing them with random noise, but this comes at the expense of the accuracy of the model. Can we forget the cohort of interest without interfering with in-formation about the other data and preserving, to the extent possible, the accuracy of the trained model? Recently, the problem of forgetting has received considerable attention
[15, 16, 13, 19, 5, 24, 35, 41, 6, 39, 12, 7, 36], but solutions have focused on simpler machine learning problems such as linear logistic regression. Removing information from the weights of a standard convolutional network still remains an open problem, with some initial results working only on small scale problems [15, 16]. This is mainly due to the highly non-convex loss-landscape of CNNs, which makes the inﬂuence of a particular sample on the optimization tra-jectory and the ﬁnal weights highly non-trivial to model.
In this paper we introduce Mixed-Linear Forgetting (ML-Forgetting), a method to train large scale computer vi-sion models in such a way that information about a subset of the data can be removed on request – with strong bounds on the amount of remaining information – while at the same time retaining close to the state of the art accuracy on the tasks. To the best of our knowledge, this is the ﬁrst al-gorithm to achieve forgetting for deep networks trained on large-scale computer vision problems without compromis-ing the accuracy. To further improve the performance in realistic use-cases, we introduce the notion of forgetting in a mixed-privacy setting, that is, when we know that a subset
Dc ⇢ D of the training dataset, which we call core data, will not need to be forgotten. For example, the core data may be a large dataset of generic data used for pre-training (e.g., ImageNet) or a large freely available collection of task-speciﬁc data (e.g., a self-driving dataset) which is not likely subject to changes. We show that ML-Forgetting can naturally take advantage of this setting, to improve both ac-792
curacy and bounds on the amount of remaining information after forgetting.
One of the main challenges of forgetting in deep net-works is how to estimate the effects of a given training sam-ple on the parameters of the model, which has lead the re-search to focus on simpler convex learning problem such as linear or logistic regression, for which a theoretical analysis is feasible. To address this problem, Mixed-Linear Forget-ting uses a ﬁrst-order Taylor-series inspired decomposition of the network to learn two sets of weights: a core set wc which is trained only with the core data Dc using a stan-dard (non-convex) algorithm, and a set of linear w of user weights, which is trained to minimize a quadratic loss func-tion on the changeable user data D. The core weights are learned through standard training (since forgetting is not re-quired on core data), while the user weights are obtained as the solution to a strongly convex quadratic optimization problem. This allows us to remove inﬂuence of a subset of the data with strong guarantees. Moreover, by construction, simply setting to zero the user weights removes inﬂuence of all changeable data with the lowest possible drop in perfor-mance, thus easily allowing the user to remove all of their data at the same time.
To summarize, our key contributions are: 1. We introduce the problem of forgetting (unlearning or data deletion or scrubbing) in a mixed-privacy setting which, compared to previous formalizations, is better taylored to standard practice, and allows for better pri-vacy guarantees. 2. In this setting we propose ML-Forgetting. ML-Forgetting trains a set of non-linear core weights and a set of linear user weights, which allow it to achieve both good accuracy, thanks to the ﬂexibility of the non-linear weights, and strong privacy guarantees thanks to the linear weights. 3. As a side effect, all the user data may be forgotten com-pletely with the lowest possible drop in performance by simply erasing the user weights. 4. We show that ML-Forgetting can be applied to large-scale vision datasets, and enjoys both strong forgetting guarantees and test time accuracy comparable to stan-dard training of a Deep Neural Network (DNN). To the best of our knowledge, this is the ﬁrst forgetting algo-rithm to do so. 5. Furthermore, we show that ML-Forgetting can handle multiple sequential forgetting requests without degrad-ing its performance, which is important for real world applications. 2.