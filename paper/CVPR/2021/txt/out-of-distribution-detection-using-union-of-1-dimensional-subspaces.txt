Abstract
The goal of out-of-distribution (OOD) detection is to han-dle the situations where the test samples are drawn from a different distribution than the training data. In this paper, we argue that OOD samples can be detected more easily if the training data is embedded into a low-dimensional space, such that the embedded training samples lie on a union of 1-dimensional subspaces. We show that such embedding of the in-distribution (ID) samples provides us with two main advantages. First, due to compact representation in the fea-ture space, OOD samples are less likely to occupy the same region as the known classes. Second, the ﬁrst singular vector of ID samples belonging to a 1-dimensional subspace can be used as their robust representative. Motivated by these observations, we train a deep neural network such that the
ID samples are embedded onto a union of 1-dimensional subspaces. At the test time, employing sampling techniques used for approximate Bayesian inference in deep learning, input samples are detected as OOD if they occupy the re-gion corresponding to the ID samples with probability 0.
Spectral components of the ID samples are used as robust representative of this region. Our method does not have any hyperparameter to be tuned using extra information and it can be applied on different modalities with minimal change.
The effectiveness of the proposed method is demonstrated on different benchmark datasets, both in the image and video classiﬁcation domains. 1.

Introduction
Many classiﬁcation methods are designed and deployed under the assumption that training data contains samples from all the possible classes that the classiﬁer will encounter during testing. Of course, such assumption does not hold in many applications; as it may not be possible to cover every potential input class in the training set. Thus, it is desir-able to detect out-of-distribution (OOD) samples; the input instances that do not belong to any of the training classes.
In general, OOD detection techniques try to either use the class membership probabilities as a measure of uncertainty
[12, 21, 36, 39, 14], or deﬁne a measure of similarity be-tween the input samples and the training dataset in a feature space [2, 40, 20, 28]. As discussed in [20], the features extracted from a conventional softmax classiﬁer follow a class-conditional Gaussian distribution. However, general class-conditional Gaussian embeddings are not particularly appropriate for outlier detection, as they are not easily dis-tinguishable in the feature space.
In this work, we claim that we can improve the OOD detection performance by constraining the representation of in-distribution (ID) samples in the feature space. Particularly, if we embed the training samples such that the feature vec-tors belonging to each known class lie on a 1-dimensional subspace, OOD samples can be detected more robustly with higher probability, compared to a class-conditional non-degenerate Gaussian embeddings. Such a union of 1-dimensional subspaces representation provides us with two main advantages. First, due to compact representation in the feature space, OOD samples are less likely to occupy the same region as the known classes. In other words, a random vector in a high-dimensional space lies on a speciﬁc 1-dimensional line with probability 0. Second, we show that the ﬁrst singular vector of a 1-dimensional subspace is a robust representative of its samples. We exploit these two desirable features and reject samples as OOD, if they occupy the region corresponding to the training samples with probability 0. This region is identiﬁed by the set of the
ﬁrst singular vectors of the training classes. To estimate the probability, we use Monte Carlo sampling techniques used in Bayesian deep learning such as [25, 8].
Our work is primarily motivated by the rich literature of spectral methods in signal processing and machine learning.
Spectral techniques have been proven to be very effective 9452
for different tasks such as robust estimation [6], learning mixture models [29], representative selection [43], and de-fense against backdoor attacks [35]. We are also inspired by the OOD detection method proposed in [20], in which au-thors use the ID feature vectors to estimate their distribution and to detect OOD samples. In contrast, we engineer the distribution of ID feature vectors to minimize the error prob-ability, without knowing the distributions of OOD samples, and enforce our desired distribution on the feature vectors.
Our proposed method does not need extra information or a subset of OOD examples for hyperparameter tuning or validation. This is in contrast to many existing methods that use some subset of the OOD samples, either during validation [21, 36, 20, 28], or even during training [13, 42].
Despite improving the results, the availability of such extra information is questionable in many real-world applications.
Furthermore, our technique can be easily deployed on many existing frameworks and different modalities, e.g. images, videos, etc. In summary, this paper makes the following contributions:
• We demonstrate that if feature vectors lie on a union of 1-dimensional subspaces, the OOD samples can be robustly detected with high probability and we show how we can impose such constraint on the ID feature vectors (Section 3);
• We propose a new OOD detection test, which exploits the ﬁrst singular vector of the feature vectors extracted from the training set, in conjunction with MC sampling (Section 4);
• Our framework does not have hyperparameters, does not need extra information, and can be easily applied to existing methods with minimal change. Furthermore, the proposed method can be applied to different domains. Here, we introduce a new baseline for OOD detection for human action classiﬁcation in videos. 2.