Abstract
Single-view 3D object reconstruction has seen much progress, yet methods still struggle generalizing to novel shapes unseen during training. Common approaches pre-dominantly rely on learned global shape priors and, hence, disregard detailed local observations. In this work, we ad-dress this issue by learning a hierarchy of priors at different levels of locality from ground truth input depth maps. We argue that exploiting local priors allows our method to ef-ﬁciently use input observations, thus improving generaliza-tion in visible areas of novel shapes. At the same time, the combination of local and global priors enables meaningful hallucination of unobserved parts resulting in consistent 3D shapes. We show that the hierarchical approach generalizes much better than the global approach. It generalizes not only between different instances of a class but also across classes and to unseen arrangements of objects. 1.

Introduction
The usual problem setting of single-view 3D reconstruc-tion assumes an input image with a single dominant object, where the geometry of both the visible and the invisible part of this object shall be reconstructed. For the invisi-ble parts, reconstruction must rely on shape priors, which can be based on the object class, symmetry, or smoothness.
The geometry of the visible parts can be obtained, at least partially, from sensing data (e.g., depth, texture, shading).
Most existing approaches are encoder-decoder net-works [7, 10, 12, 19, 27, 30, 34] and have been shown to barely generalize to novel shape categories [38]. Only few works have targeted generalization explicitly [3, 32, 38].
They argue that, for better generalization, the problem should be split into two parts: (1) prediction of a geometric representation of the visible parts from a single RGB image and (2) prediction of the ﬁnal shape from the geometric rep-resentation. In this paper, we focus on the prediction of the object shape and assume the ground truth depth map to be
Input depth
Ground truth
Global prior (ONet)
Hierarchical prior (HPN, ours)
Figure 1. We employ a hierarchical shape prior to enable recom-bination of partial shapes observed during training. This signif-icantly improves generalization compared to conventional global shape priors. already given as input. This reﬂects the argument that an in-termediate depth map helps generalization [38] and should make the reconstruction of the visible parts almost trivial.
Surprisingly, however, existing approaches fail to gen-eralize even in the visible areas, despite the perfect input.
Consider the example in Fig. 1: ONet [19] trained on sin-gle chairs uses its learned prior to reconstruct the shape for an input with two chairs. Although the required shape prior (chairs) has been seen during training, the approach cannot use this knowledge to explain the clean observation of two chairs (Fig. 1 top left), which leads to an unresolved com-petition between observation and prior (Fig. 1 bottom left).
This reveals a general problem of existing approaches: not only do they not generalize to new object classes, they even do not generalize to new combinations of the same training 15880
classes. Even if we would train these networks on pairs of chairs, they must see all possible conﬁgurations of pairs – a combinatorial explosion.
In this paper, we propose to foster the recombination of previously seen partial shapes by a hierarchical approach. It consists of two main building blocks: (1) a local reconstruc-tion module that reconstructs the shape at a certain level of locality (Fig. 2), and (2) fusion of the beliefs from various levels of locality (Fig. 3). The reconstruction module is ef-fectively an implicit surface network (e.g. ONet) which per-forms shape estimation from patches of the input image. If the patch size covers the whole image, it comes down to the original global surface network. Intuitively, instead of reconstructing the full shape with a single prediction effort, local versions of the network learn to estimate geometry of individual object parts and put those together to obtain the whole shape. Since similar shape parts are likely to repeat between different categories, this strategy offers effective recombination of parts from various training samples and, hence, much better generalization potential.
Since local patches have a limited view of the overall shape, the reconstructed global shape may not look consis-tent, especially in large occluded areas. Therefore, we com-bine multiple patch sizes (including the global one based on the full image) to form a hierarchy of such local networks.
The combination is possible by simple averaging of the logit outputs.
We demonstrate the intriguing effect of the new hier-archical reconstruction concept on various generalization tasks derived from the ShapeNet [5] dataset. This includes tasks that require inter-class generalization and generaliza-tion from single to multiple objects. The results show the huge effect of the ability to recombine parts, which is missing in all previous learning-based reconstruction ap-proaches. This ability also improves the data efﬁciency: in contrast to existing global methods, the performance of our local networks does not noticeably degrade even when training on as little as 1% of the original data. Since the choice of the base reconstruction module is ﬂexible, the hi-erarchy of local networks acts as a working principle that can be applied to enhance the generalization of effectively any method based on implicit functions. We refer to this as
Hierarchical Prior Network (HPN). 2.