Abstract
Data-driven based approaches, in spite of great success in many tasks, have poor generalization when applied to unseen image domains, and require expensive cost of anno-tation especially for dense pixel prediction tasks such as se-mantic segmentation. Recently, both unsupervised domain adaptation (UDA) from large amounts of synthetic data and semi-supervised learning (SSL) with small set of labeled data have been studied to alleviate this issue. However, there is still a large gap on performance compared to their supervised counterparts. We focus on a more practical set-ting of semi-supervised domain adaptation (SSDA) where both a small set of labeled target data and large amounts of labeled source data are available. To address the task of SSDA, a novel framework based on dual-level domain mixing is proposed. The proposed framework consists of three stages. First, two kinds of data mixing methods are proposed to reduce domain gap in both region-level and sample-level respectively. We can obtain two complemen-tary domain-mixed teachers based on dual-level mixed data from holistic and partial views respectively. Then, a stu-dent model is learned by distilling knowledge from these two teachers. Finally, pseudo labels of unlabeled data are generated in a self-training manner for another few rounds of teachers training. Extensive experimental results have demonstrated the effectiveness of our proposed framework on synthetic-to-real semantic segmentation benchmarks. 1.

Introduction
Semantic segmentation with the goal of assigning semantic-level labels to every pixel in an image is one of the fundamental topics in computer vision due to its widely critical real-world applications, such as autonomous driving [11] and robotic navigation [28, 39]. Over the
†Equal contribution
‡Part of this work was done while he was in Noah’s Ark Lab past few years, deep convolutional neural networks(CNNs) have achieved dramatic improvements in semantic segmen-tation [1, 25, 17, 26, 2, 48]. The success of CNN-based methods beneﬁts from large volume of manually labeled data [24, 8], and the assumption of independent and identi-cal data distribution between training and testing samples.
However, performance drops signiﬁcantly when the model trained on training set (source domain) is directly applied to unseen test scenarios (target domain). In addition, densely annotating pixel-wise labels of many samples in target do-main is time-consuming and uneconomical.
To reduce the heavy demand for pixel-wise annotation, one way is to employ large amounts of easy-to-get simula-tion data which can be collected from game engines such as GTA5 [33] and SYNTHIA [34]. In addition, unsuper-vised domain adaptation (UDA) strategy, which aims at transferring knowledge from a synthetic label-rich source domain to a real-world label-scarce target domain, is re-quired to bridge domain gap between synthetic and real-world domains.
Impressive results have been achieved by UDA methods that extract domain-invariant representa-tions via entropy minimization [31, 43], generative mod-elling [16, 12] and adversarial learning [42, 41]. How-ever, domain shift cannot be completely eliminated by these methods due to weak supervision on target examples. There is still a big gap in performance compared with supervised methods. Another way in addressing the issue of heavy an-notation is to annotate only a small set of images from target domain and make full use of plenty of unlabeled data with semi-supervised learning (SSL) techniques [10, 30, 9, 29].
Due to the shortage of labeled data in SSL setting, the ob-tained model has the risk of overﬁtting to the small amount of labeled data. How to effectively utilize available unla-beled and limited labeled data from different domains is the key in improving model’s accuracy and generalization for pixel-wise prediction tasks.
Hence, a more practical task of semi-supervised domain 11018
adaptation (SSDA) is recently introduced by combining the small set of labeled target data images in SSL with the large amounts of labeled source domain data and unlabeled tar-get domain data. In order to address the SSDA problem, one naive way is to equip UDA methods with additional su-pervision on the extra labeled target images (see Baseline in Table 1.). For example, Alleviating Semantic-level Shift (ASS) model [44] is proposed for better promoting the dis-tribution consistency of features by using adversarial learn-ing on outputs from two labeled domains. However, these methods cannot fully explore rich information within avail-able labeled and unlabeled data in two domains.
Semantic segmentation is a dense pixel-wise prediction task, and classiﬁcation of one pixel depends not only on its own value but also on its neighbourhood’s context. We fo-cus on how to effectively utilize labeled data in different domains to extract domain-invariant representations in both region-level and sample-level. The proposed framework consists of three steps. First, two kinds of data mixing meth-ods are proposed to reduce domain gap in both region-level and sample-level. The region-level data mixing is achieved by applying two binary masks to labeled images from two domains and combining the two masked regions, which en-courages a model to extract domain-invariant features about semantic structure from partial view. On the other hand, the image-level data mixing directly mixes labeled images from two domains from holistic view. Such two mixing ways help train two complementary teacher models that work on both two kinds of data distribution. In the second step, we employ knowledge distillation technique to extract
“dark knowledge” from these two complementary teachers, which works as guidance in the learning process of a student model for target domain. By integrating knowledge from two views and making full use of unlabeled data, the stu-dent model of the same network architecture can give even better performance than any of its teachers. Once a good student model for target domain is obtained, pseudo labels could be generated with self-training strategy to expand the set of labeled target domain data for iterative update. Com-pared with traditional self-training methods, which directly use pseudo labels to train a ﬁnal model, we instead leverage these pseudo labels to obtain two stronger domain-mixed teachers, which also leads to stronger student by another round of knowledge distillation. Overall, in our framework, teachers and student are progressively growing, and we can obtain a ﬁnal well-trained student model.
Our contributions of this paper are three-fold:
• Two kinds of data mixing methods are proposed to train domain-mixed teachers across domains in both region-level and sample-level to alleviate data distri-bution mismatch between different domains.
• A stronger student model on target domain can be ob-tained by distilling knowledge from complementary domain-mixed teachers. It can be further strengthened by employing pseudo labels which are generated for unlabeled target data in a self-training manner.
• Extensive experiments demonstrate that the proposed method can achieve superior performance on two com-mon synthetic-to-real semantic segmentation bench-marks with small amounts of labeled data. 2.