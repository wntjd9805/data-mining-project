Abstract
×
Binary grid mask representation is broadly used in in-stance segmentation. A representative instantiation is Mask
R-CNN which predicts masks on a 28 28 binary grid.
Generally, a low-resolution grid is not sufﬁcient to cap-ture the details, while a high-resolution grid dramatically increases the training complexity. In this paper, we propose a new mask representation by applying the discrete cosine transform(DCT) to encode the high-resolution binary grid mask into a compact vector. Our method, termed DCT-Mask, could be easily integrated into most pixel-based in-stance segmentation methods. Without any bells and whis-tles, DCT-Mask yields signiﬁcant gains on different frame-works, backbones, datasets, and training schedules. It does not require any pre-processing or pre-training, and almost no harm to the running speed. Especially, for higher-quality annotations and more complex backbones, our method has a greater improvement. Moreover, we analyze the perfor-mance of our method from the perspective of the quality of mask representation. The main reason why DCT-Mask works well is that it obtains a high-quality mask represen-tation with low complexity. 1.

Introduction
Instance segmentation tasks involve detecting objects and assigning category labels to pixels.
It is the corner-stone of many computer vision tasks, such as autonomous driving and robot manipulation. Recently, the applica-tion of deep convolutional neural networks(CNNs) has greatly promoted the development of instance segmentation
[21, 23, 16, 15, 17]. Pixel-based method is one of the main-stream methods which generates a bounding box by an ob-ject detector and performs pixel mask predicting within a
*These authors contributed equally to this work.
†Corresponding author.
Ground Truth 28 × 28
Reconstructed
Error (a) Binary grid mask representation
Ground Truth 128 × 128
Reconstructed
Error (b) DCT mask representation
Figure 1: Binary grid mask representation vs. DCT mask representation. The leftmost sub-graph is the ground truth, the left-middle is the mask representation, the middle right is the reconstructed mask, the rightmost is the error between the reconstructed mask and the ground truth. low-resolution regular grid. But is the low-resolution grid an ideal choice for mask representation?
×
As a representative instantiation in instance segmen-tation, Mask R-CNN [15] ﬁrst downsamples the binary ground truth to a 28 28 grid and then reconstructs it through upsampling. As shown in Figure 1(a), the binary grid mask representation with low resolution is not sufﬁ-cient to capture detailed features and causes bias during up-sampling. To describe this phenomenon more accurately, we use the metric of Intersection over Union(IoU) between the reconstructed mask and the ground truth to evaluate the quality of mask representation. We ﬁnd that in the COCO val2017 dataset, the 28 28 binary grid achieves only 93.8% IoU. It means even the prediction of the mask branch is exactly accurate, the reconstructed mask has a 6.2% error.
A higher-quality mask representation may reduce the re-construction error. It turns out 128 128 resolution could achieve 98% IoU. But experiments show that the mask aver-×
× 8720
× 28 resolution. age precision(AP) of predicting a higher resolution binary grid is worse than the original 28 (The speciﬁc experimental results will be discussed in the Exper-iments section.) The discriminative pixels of the mask dis-tribute along the object boundaries, while the binary grid mask representation makes excessive predictions over all pixels on the whole large grid. The training complexity will increase sharply as the resolution increases. The improve-ment in the quality of mask representation can not compen-sate for its shortcoming.
A better mask representation with high resolution and low complexity is required.
In this work, we explore to apply the discrete cosine transform to the mask rep-resentation. The discrete cosine transform (DCT) [1] is a widely used transformation technique in signal process-ing and data compression due to its strong “energy com-paction” property [25]. Regarding mask in instance seg-mentation as a binary image, most information is concen-trated in a few low-frequency components. By transform-ing the high-resolution binary mask into the frequency do-main and keeping its low-frequency components, we ob-tain a high-quality and low-complexity mask representa-tion, termed DCT mask representation. Experiments indi-cate that it achieves 97% IoU with only a 300-dimensional vector compressed from a 128 128 resolution mask. The information of the discarded high-frequency components is negligible compared with the improvement brought by higher resolution. Consequentially the overall quality of mask representation is improved. Different from dictio-nary learning compression methods such as principal com-ponent analysis(PCA), sparse coding, and autoencoders,
DCT does not require any pre-training or preprocessing, and the computational complexity of DCT transformation is O(nlog(n)) which could be omitted in the whole frame-work of instance segmentation.
×
In this paper, we integrate the DCT mask representation into the Mask R-CNN [15] framework with slight modiﬁca-tions to the model architecture. Our method termed DCT-Mask consistently improves mask AP by about 1.3% on the
COCO dataset, 2.1% on the LVIS* dataset, and 2.0% on the
Cityscapes. Because DCT mask representation raises the upper bound of the mask quality, it tends to obtain more increase for more complex backbones and higher-quality annotations. On the COCO dataset, DCT-Mask achieves 1.3% and 1.7% increase with ResNet-50[16] and ResNeXt-101[34], respectively. On the LVIS∗ dataset , it achieves 2.1% and 3.1% increase respectively. Besides, we demon-strate the generality of our method on other pixel-based instance segmentation frameworks such as CascadeRCNN
[2].
DCT-Mask does not require extra pre-processing or pre-*We use the COCO sub-categories of the LVIS dataset and evaluate it with same models trained on COCO. training. Compared to the standard Mask R-CNN with
ResNet-50 backbone, the application of our method shows almost no harm to the running speed, which reaches 22 FPS on the V100 GPU. Besides, we analyze the performance of mask prediction from the perspective of the mask quality and reveal that at the same level of complexity, improving the quality of mask representation can effectively improve mask AP.
In summary, this work has the following contributions:
• We propose a high-quality and low-complexity mask representation for instance segmentation, which en-codes the high-resolution binary mask into a compact vector with discrete cosine transform.
• With slight modiﬁcations, DCT-Mask could be inte-grated into most pixel-based frameworks, and achieve signiﬁcant and consistent improvement on different datasets, backbones, and training schedules. Speciﬁ-cally, it obtains more improvements for more complex backbones and higher-quality annotations.
• DCT-Mask does not require extra pre-processing or pre-training. It achieves high-resolution mask predic-tion at a speed similar to low-resolution. 2.