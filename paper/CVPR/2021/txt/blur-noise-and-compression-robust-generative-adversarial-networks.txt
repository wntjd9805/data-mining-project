Abstract
Generative adversarial networks (GANs) have gained considerable attention owing to their ability to reproduce images. However, they can recreate training images faith-fully despite image degradation in the form of blur, noise, and compression, generating similarly degraded images.
To solve this problem, the recently proposed noise robust
GAN (NR-GAN) provides a partial solution by demonstrat-ing the ability to learn a clean image generator directly from noisy images using a two-generator model compris-ing image and noise generators. However, its application is limited to noise, which is relatively easy to decompose owing to its additive and reversible characteristics, and its application to irreversible image degradation, in the form of blur, compression, and combination of all, remains a chal-lenge. To address these problems, we propose blur, noise, and compression robust GAN (BNCR-GAN) that can learn a clean image generator directly from degraded images with-out knowledge of degradation parameters (e.g., blur kernel
Inspired types, noise amounts, or quality factor values). by NR-GAN, BNCR-GAN uses a multiple-generator model composed of image, blur-kernel, noise, and quality-factor generators. However, in contrast to NR-GAN, to address irreversible characteristics, we introduce masking architec-tures adjusting degradation strength values in a data-driven manner using bypasses before and after degradation. Fur-thermore, to suppress uncertainty caused by the combina-tion of blur, noise, and compression, we introduce adap-tive consistency losses imposing consistency between irre-versible degradation processes according to the degrada-tion strengths. We demonstrate the effectiveness of BNCR-GAN through large-scale comparative studies on CIFAR-10 and a generality analysis on FFHQ. In addition, we demon-strate the applicability of BNCR-GAN in image restoration. 1.

Introduction
Constructing generative models to generate images that are indistinguishable from real images is a fundamental problem in computer vision and machine learning. Re-cently, however signiﬁcant advancements have been made in this regard, enabled by the emergence of deep genera-tive models. Among them, generative adversarial networks (GANs) [22], which learn data distributions through adver-sarial training, have attracted considerable attention owing to their high image reproduction ability.
However, a persistent problem is that high-capacity
GANs can replicate training images with high ﬁdelity, even when the images are degraded, and they thus tend to repli-cate various forms of image degradation in their gener-ated images. As shown in Figure 1, when standard GAN is trained with images degraded by blur, noise, and com-pression (i.e., JPEG) (Figure 1(a)), it produces similarly degraded images (Figure 1(b)) because standard GAN ar-chitectures do not consider such image degradation. This 13579        
is problematic when training images are collected in real-world scenarios (e.g., web crawling) because identifying degraded images is laborious. To address this problem, painstaking manual prescreening is often conducted.
One well-explored solution involves restoring images us-ing an image restoration model, such as model-based image restoration methods [12, 23, 17, 57, 8, 56, 16, 54, 58, 18, 75, 42, 88, 67, 19], prior to the training of GANs. However, images restored by these methods tend to be either over-or under-restored owing to the gap between predeﬁned and real priors.1 To overcome this drawback, various learning-based methods have been developed. However, most of these methods require additional supervision for training, such as paired supervision (e.g., pairs of clean and degraded images) [87, 77, 74, 9, 65, 21, 45, 46, 28, 61, 79, 93, 94, 10, 25, 15, 78, 20, 49, 86] or set-level supervision (i.e., labels indicating whether images are degraded) [55, 52].2
AmbientGAN [4] was recently proposed as a different approach. This provides a promising solution by simulat-ing image degradation on generated images and learning a discriminator that distinguishes a real degraded image from a degraded generated image. This formulation allows the learning of a clean image generator directly from degraded images without any pre-processing or paired/set-level su-pervision. However, it relies on a strong assumption that degradation parameters, such as blur kernel types, noise amounts, and quality factor values, are known in advance.
Motivated by these previous studies, we address the problem of developing a model to learn a clean image gen-erator directly from degraded images without knowledge of degradation parameters. In particular, to apply the solution to real-world images, we aim to handle images degraded by a representative image degradation model [87], which ad-dresses blur, noise, and compression in the same order as in a real image acquisition process (detailed in Equation 1).
Based on this objective, we focus on blur, noise, and com-pression, and refer to the abovementioned problem of blur, noise, and compression robust image generation. We ex-emplify a solution using our proposed model, as shown in
Figure 1(c). We aim to devise a model that can learn to gen-erate clean images (Figure 1(c)), even when trained with blurred, noisy, and compressed images (Figure 1(a)).
Noise robust GAN (NR-GAN) [30], which uses a two-generator model consisting of noise and image generators, has provided a partial solution to this problem by demon-strating the ability to learn to generate clean images directly from noisy images. However, NR-GAN assumes that image information is lossless before and after degradation and uti-lizes this characteristic to decompose a degraded image into clean image and degradation components. Hence, its appli-cation is limited to noise, which has additive and reversible 1Deep image prior-based approaches [81, 68] can be used alternatively; however, they require optimization for each individual image. Pre-trained model-based approaches [68] provide another solution; however, they re-quire the collection of clean images for training the pre-trained model. 2Self-supervised learning methods [44, 2, 48] have been also proposed; however, their application has been limited to denoising. characteristics, and its application to irreversible degrada-tion, in the form of blur, compression, and combination of all, remains a challenge.
To address these problems, we propose blur, noise, and compression robust GAN (BNCR-GAN), that can learn a clean image generator directly from blurred, noisy, and compressed images.
To solve the sub-problems, we
ﬁrst propose two variants: blur robust GAN (BR-GAN) and compression robust GAN (CR-GAN), which are spe-ciﬁc to blur and compression, respectively. Along the lines of NR-GAN, BR-GAN and CR-GAN learn a blur-kernel generator and a quality-factor generator, respec-tively, along with clean image generators, to learn a blur-kernel/quality-factor distribution jointly with an image dis-tribution. However, in contrast to NR-GAN, to address the irreversible blur/compression characteristics, masking ar-chitectures adapting degradation strengths in a data-driven are introduced, using bypasses before and after image degradation. This architectural constraint is useful for con-ducting only the necessary changes through blur or com-pression while suppressing unnecessary changes.
The unique problem of BNCR-GAN, which is a uniﬁed model integrating BR-GAN, NR-GAN, and CR-GAN, is that it needs to handle the uncertainty caused by the com-bination of blur, noise, and compression. Thus, we in-corporate novel losses called adaptive consistency losses that impose consistency between irreversible degradation processes according to the degradation strengths. This loss helps prevent the generated image from yielding un-expected artifacts, which can disappear and become unrec-ognizable after irreversible processes.
As the effects of blur, noise, and compression on GANs have not been sufﬁciently examined in previous studies, we
ﬁrst conducted large-scale comparative studies on CIFAR-10 [43], in which we compared diverse models under vari-ous degradation settings, in which we tested 134 total con-ditions. Moreover, following recent large-scale studies on
GANs [47] and NR-GANs [30], we analyze a generality on a more complex dataset, that is, FFHQ [35].3 Finally, we examined the applicability of BNCR-GAN in image restoration and demonstrated that, although BNCR-GAN is designed to be trained in an unsupervised manner, it is nonetheless competitive with two supervised models (i.e.,
CycleGAN with set-level supervision [97] and unsuper-vised adversarial image reconstruction (UNIR) with a pre-deﬁned image degradation model [66]).
Our contributions are summarized as follows.
• We propose blur, noise, and compression robust im-age generation, wherein generation of clean images is learnt directly from degraded images without knowl-edge of degradation parameters.
• To address the sub-problems, we propose BR-GAN and
CR-GAN, which train a blur-kernel generator and a 3We excluded LSUN BEDROOM [91], which was used in [47, 30], because its images were compressed with JPEG and ground-truth non-degraded images were not available. 13580
quality-factor generator, respectively, along with clean
In particular, we devise masking image generators. architectures to adjust the degradation strengths using bypasses before and after degradation.
• To handle all types of image degradation, we further propose BNCR-GAN, which uniﬁes BR-GAN, NR-GAN, and CR-GAN as a single model. In particular, to address the uncertainty caused by the combination, we introduce adaptive consistency losses.
• We provide benchmark scores for these new problems through large-scale comparative studies on CIFAR-10 (in which we tested 134 conditions) and a gener-ality analysis on FFHQ. We also demonstrate the ap-plicability of BNCR-GAN in image restoration. The project page is available at https://takuhirok. github.io/BNCR-GAN/. 2.