Abstract
Recently proposed decoupled training methods emerge as a dominant paradigm for long-tailed object detection.
But they require an extra ﬁne-tuning stage, and the dis-jointed optimization of representation and classiﬁer might lead to suboptimal results. However, end-to-end training methods, like equalization loss (EQL), still perform worse than decoupled training methods.
In this paper, we re-veal the main issue in long-tailed object detection is the imbalanced gradients between positives and negatives, and
ﬁnd that EQL does not solve it well. To address the prob-lem of imbalanced gradients, we introduce a new version of equalization loss, called equalization loss v2 (EQL v2), a novel gradient guided reweighing mechanism that re-balances the training process for each category indepen-dently and equally. Extensive experiments are performed on the challenging LVIS benchmark. EQL v2 outperforms origin EQL by about 4 points overall AP with 14 ∼ 18 points improvements on the rare categories. More impor-tantly, it also surpasses decoupled training methods. With-out further tuning for the Open Images dataset, EQL v2 improves EQL by 7.3 points AP, showing strong gener-alization ability. Codes have been released at https:
//github.com/tztztztztz/eqlv2 1.

Introduction
Object detection is a fundamental computer vision task that aims to recognize and locate objects of a set of pre-deﬁned categories. Modern object detectors [31, 30, 27, 24, 25, 1] have shown promising results on some conventional benchmarks such as COCO [26] and PASCAL VOC [9].
Collected images in these datasets have been carefully se-lected and the quantities of each category are relatively bal-anced. However, in natural images, quantities of categories subject to a long-tailed Zipﬁan distribution. It means that, in
Figure 1: Visualization of accumulative gradients ratio of different trained models. Best view in color. The x-axis is the sorted category index of 1203 categories of LVIS dataset. The y-axis is the accumulative gradient ratio of positives to negatives. Here gradient is the gradient of the output logits with respect to classiﬁcation loss. APr and
APc are the AP for rare and common categories. a realistic scenario, we are confronted with a more complex situation that the obtained objects show an extreme imbal-ance in different categories.
The difﬁculty of training detectors on a long-tailed dataset mainly comes from two aspects. First, deep learning methods are hungry for data, but annotations of tail classes (classes with few samples) might be insufﬁcient for train-ing. Second, the model tends to bias towards head classes (classes with many samples) since the head class objects are the overwhelming majority in the entire datasets.
Current state-of-the-art approaches are based on decou-In general, decoupled pled training schema [18, 23, 39]. training involves a two-stage pipeline that learns represen-tations under the imbalance dataset at the ﬁrst stage, then 1685
re-balances the classiﬁer with frozen representation at the second stage. Despite the success of the decoupled train-ing, it needs an extra ﬁne-tuning stage in training phase. In addition, the representation could be suboptimal since it is not jointly learned with the classiﬁer. So a natural ques-tion to ask is: could end-to-end training methods match or surpass the accuracy of decoupled training methods?
Recently, Tan et al. [36] propose the Equalization Loss (EQL) [36], an end-to-end re-weighing loss function, to protect the learning of tail categories by blocking some neg-ative gradients. Although EQL makes improvements to long-tailed training, the accuracy gap between the end-to-end and decoupled training approaches still exists. To take a step forward, we analyze the gradient statistics of EQL.
Here we plot the positive gradient to negative gradient ratio accumulated in the entire training process for each category classiﬁer, as present in Figure 1. The key observation is: for head categories, the ratio is close to 1, which means the pos-itive gradients and the negative gradients have similar mag-nitude; for tail categories, the gradients are near 0, which means the positive gradients are overwhelmed by the neg-ative gradients. Therefore the gradient ratio could indicate whether a classiﬁer is trained in balance. Compared with the baseline (blue line), the gradient ratio of EQL (orange line) just increases slightly.
In this paper, we propose a new version of equalization loss, called equalization loss v2 (EQL v2) which improves the long-tailed object detection by balancing the positive to negative gradient ratio. In EQL v2, we ﬁrst model the detection problem as a set of independent sub-tasks, each task for one category. Next, we propose a gradient guided re-weighing mechanism to balance the training process of each task independently and equally. Speciﬁcally, the accu-mulated gradient ratio is used as an indicator to up-weight the positive gradients and down-weight the negative gradi-ents. It dynamically controls the training of all sub-tasks and each sub-task is treated equally with the same simple re-weighing rule. The positive to negative gradient ratio of
EQL v2 are shown in Figure 1 (green line). Compared to the baseline and EQL, EQL v2 achieves a more balanced training for most categories.
We conduct experiments on two long-tailed object de-tection dataset, LVIS [12] and OpenImages [20]. On
LVIS, compared to the baseline models, including Mask
R-CNN [14] and Cascade Mask R-CNN [1], it increases overall AP by about 6 points and gains 17 ∼ 20 points AP for tail categories. It outperforms EQL by about 4 points
AP. In addition, EQL v2 surpasses all of the existing long-tailed object detection methods, including end-to-end train-ing and decoupled training methods. On OpenImages, EQL v2 achieves a 9 points AP gain over the baseline model with the same hyper-parameters as on LVIS, which shows the good generalization ability. 2.