Abstract
We present a controllable camera simulator based on deep neural networks to synthesize raw image data under different camera settings, including exposure time, ISO, and aperture. The proposed simulator includes an exposure module that utilizes the principle of modern lens designs for correcting the luminance level. It also contains a noise module using the noise level function and an aperture mod-ule with adaptive attention to simulate the side effects on noise and defocus blur. To facilitate the learning of a simu-lator model, we collect a dataset of the 10,000 raw images of 450 scenes with different exposure settings. Quantitative experiments and qualitative comparisons show that our ap-proach outperforms relevant baselines in raw data synthe-size on multiple cameras. Furthermore, the camera simula-tor enables various applications, including large-aperture enhancement, HDR, auto exposure, and data augmentation for training local feature detectors. Our work represents the Ô¨Årst attempt to simulate a camera sensor‚Äôs behavior leveraging both the advantage of traditional raw sensor fea-tures and the power of data-driven deep learning. The code and the dataset are available at https://github.com/ken-ouyang/neural image simulator. 1.

Introduction
Controllable photo-realistic image generation is a new trending research topic [38]. Most recent works focus on learning a certain scene representation conditioned on dif-ferent viewpoints [27, 26] or lighting [34, 45]. However, in the physical image formulation pipeline, apart from scene, light, and view angle, the camera settings are also impor-tant components, which are yet to be investigated. Modern cameras introduce various settings for capturing sceneries, among which the exposure settings (i.e., exposure time or shutter speed, ISO, and aperture size) are most commonly adjusted. As in Fig. 1, cameras capture the scene radio-metric characteristics and record them as raw image data.
Capturing with different exposure settings not only leads to luminance changes but also results in different side ef-*Joint Ô¨Årst authors
Camera
Raw Image 1
Scene 
Radiometry
Settings 1
Settings 2
Simulator  ùëì
ùëì
Camera
Raw Image 2
Figure 1. The problem formulation of simulating images with dif-ferent camera settings. Given the same scene, a camera can cap-ture different images with different camera settings, where the de-grees of luminance, noise, and blur vary a lot. Our simulator aims to model the mappings between raw images with different camera settings. fects: ISO affects the noise presented, and aperture size de-cides the defocus blur. This paper studies a challenging new task of controllable exposure synthesis with different cam-era settings. Given the original image, we learn a simulator f that maps from the old settings to new settings. To capture the essence of changing exposure settings, we directly ex-plore our simulation on raw data rather than monitor-ready images so that any camera signal processing pipeline can be applied [20].
Several features presented in raw data are beneÔ¨Åcial for the exposure simulation:
‚Ä¢ Raw sensor data directly captures the physical infor-mation, such as the light intensity of a scene. To simulate a new illuminance level, we can analyze the change of captured light intensity under new settings based on the physical prior and the design of the mod-ern lens [32].
‚Ä¢ The noise distribution model on raw sensor data is relatively robust because of the physical imaging model [14].
‚Ä¢ In a close shot scene, the original divisions of blurry and sharp regions provide additional supervision in-7700
formation. It is possible to learn and locate the blurry regions to magnify the defocus blur.
Therefore, we propose a model that consists of three mod-ules, which progressively learn the change of exposure, noise, and defocus blur. We Ô¨Årst adopt an exposure cor-rection module by analyzing the light intensity and reÔ¨Åne it using linear regression. In the second module, we utilize the traditional noise-level-function model [13, 14], and train a deep network to further modify the distribution based on real data. Finally, we propose a new attention module to focus on the blurry regions for aperture enhancement. In this paper, we do not consider cases such as removing de-focus blur (from large to small aperture in the close shot) or motion blur (with moving objects). They are too scene-dependent to Ô¨Ånd a general representation.
Since no existing dataset contains enough image se-quences that are captured at the same scene with different settings, we collect around 10,000 images of 450 such se-quences. The dataset is collected with two modern cam-eras in diverse environments. Extensive experiments on this dataset demonstrate that our proposed model can progres-sively generate both visually and statistically similar results at new exposure settings.
The simulator can beneÔ¨Åt many low-level computer vi-sion tasks such as generating high-dynamic-range (HDR)
It may also generate photos and enhancing defocus blur. realistic images for data augmentation in training deep neu-ral networks. We demonstrate four applications of the sim-ulator: magnifying the defocus blur, generating HDR im-ages, providing environments for training auto-exposure al-gorithms, and data augmentation for training local feature detectors. The contribution of this paper can be summa-rized as:
‚Ä¢ To the best of our knowledge, we are the Ô¨Årst to sys-tematically study the problem of controllable image generation with camera exposure settings, which are important components in the physical image formula-tion pipeline. By leveraging the physical imaging prior and the power of data-driven deep learning, the model achieves better results than all baselines.
‚Ä¢ We demonstrate four applications (large-aperture en-hancement, HDR, auto-exposure, and data augmenta-tion) using the proposed simulator.
‚Ä¢ We collect a large dataset of raw data sequences of the same scenes under different settings. We believe it can beneÔ¨Åt many other computer-vision tasks. 2.