Abstract
Although current deep learning-based face forgery de-tectors achieve impressive performance in constrained sce-narios, they are vulnerable to samples created by unseen manipulation methods. Some recent works show improve-ments in generalisation but rely on cues that are easily cor-rupted by common post-processing operations such as com-pression. In this paper, we propose LipForensics, a detec-tion approach capable of both generalising to novel manip-ulations and withstanding various distortions. LipForensics targets high-level semantic irregularities in mouth move-ments, which are common in many generated videos. It con-sists in ﬁrst pretraining a spatio-temporal network to per-form visual speech recognition (lipreading), thus learning rich internal representations related to natural mouth mo-tion. A temporal network is subsequently ﬁnetuned on ﬁxed mouth embeddings of real and forged data in order to detect fake videos based on mouth movements without overﬁtting to low-level, manipulation-speciﬁc artefacts. Extensive ex-periments show that this simple approach signiﬁcantly sur-passes the state-of-the-art in terms of generalisation to un-seen manipulations and robustness to perturbations, as well as shed light on the factors responsible for its performance. 1.

Introduction
Recent advances in deep generative models, especially
Generative Adversarial Networks (GANs) [24], have en-abled the use of off-the-shelf models that can produce ultra-realistic fake videos with little human effort or expertise.
Face manipulation methods in particular have raised consid-erable concerns due to their ability to alter a person’s iden-tity [38, 30, 34], expression [52, 51, 44], or lip movements
[50, 57, 56] to match the face in a given target video. The misuse of such technology can spread political propaganda, defame individuals, or damage trust in journalism.
With the aid of recent releases of large-scale face forgery
†Corresponding author.
Figure 1. Illustration of our training and testing objectives.
By leveraging semantically high-level, spatio-temporal represen-tations learned via the task of lipreading, our face forgery detector can handle both novel manipulations and common corruptions at test-time. datasets [46, 38, 30, 16], it is possible to train deep con-volutional neural networks (CNNs) to detect fake videos
[3, 25, 64, 4, 14, 45, 42, 36]. Despite excellent accuracy on samples that are independent and identically distributed to the training distribution, it is known that dramatic drops in performance may be experienced when this stringent cri-terion is not met [35, 8, 43]. For example, detectors often signiﬁcantly underperform on novel forgery types. This un-derstandably sparks concerns, as a deployed detector is un-likely to be exposed only to forgeries seen during training.
Moreover, they are often sensitive to common perturbations such as compression and are, as a result, vulnerable to the image processing pipelines on social networks.
Recent attempts to boost generalisation to novel forg-eries include simple data augmentations [59], a two-branch network that ampliﬁes multi-band frequencies [41], an autoencoder-like structure to serve as an anomaly detec-tor [13, 17, 43], and patch-based classiﬁcation to model local patterns [8]. However, these methods still substan-tially overﬁt to seen manipulations. A particularly effective method is Face X-ray [35], which proposes to predict the blending boundary between the background image and the inserted, altered face. Although it attains impressive gen-5039
eralisation in cross-manipulation experiments, it relies on often imperceptible patterns which are susceptible to low-level post-processing operations.
It is natural to ask: Are there semantically high-level in-consistencies across manipulation methods, which are thus more robust to routine perturbations? We observe that most face video forgeries alter the mouth in some way, to match it with someone else’s identity, speech, or expression. Due to the intricate motion of the mouth, current manipula-tion methods ﬁnd it difﬁcult to generate movements with-out falling into the “uncanny valley1.” For example, fake mouths often do not adequately close when they pronounce certain phonemes [4]. We also notice unnatural ﬂuctuations in the speed of movements, as well as alterations in the shape of the mouth or its interior (e.g., teeth) from frame-to-frame, even when there is no speech (see supplementary material for examples). These irregularities provide a pre-cious opportunity for detectors to capitalise on; yet, to the best of our knowledge, previous works do not speciﬁcally target mouth motion using spatio-temporal neural networks.
The human visual system can perceive subtle anomalies in forged oral movements as a result of extensive experience in observing real mouths move. In order to endow a network with such experience, we propose to pretrain it on a large corpus of real videos to perform the difﬁcult task of visual speech recognition, also known as lipreading. To be capa-ble of disambiguating similar words, the network must learn rich spatio-temporal representations related to the mouth as well as the teeth and tongue [12]. Next, we transfer the ac-quired knowledge to face forgery detection. Crucially, we treat the ﬁrst part of the network as a frozen feature extrac-tor that outputs an embedding per frame, and only ﬁnetune the temporal convolutional network that takes these embed-dings as input. This prevents the network from learning to discriminate the data based on unstable, low-level patterns that may not be generated by other forgery methods.
We dub our approach LipForensics (see Figure 1). We conduct extensive experiments to compare its performance with the state-of-the-art in various challenging scenarios.
We ﬁnd that, in most cases, it signiﬁcantly outperforms previous methods with respect to generalisation to unseen forgeries, while exhibiting remarkable robustness to com-mon corruptions which degrade other models’ performance.
Further, in-distribution experiments reveal that LipForen-sics can effectively learn even on heavily compressed data, unlike other detectors. Finally, we validate our design choices through ablation studies, and compare with other large-scale pretraining tasks to demonstrate the superior-ity of lipreading for achieving generalisable and robust face forgery detection. 1The “uncanny valley” refers to the unease experienced by humans when observing a realistic computer-generated face. 2.