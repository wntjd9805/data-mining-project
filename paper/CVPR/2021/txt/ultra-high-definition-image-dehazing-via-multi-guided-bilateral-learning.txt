Abstract
Convolutional neural networks (CNNs) have achieved signiﬁcant success in the single image dehazing task. Un-fortunately, most existing deep dehazing models have high computational complexity, which hinders their application to high-resolution images, especially for UHD (ultra-high-deﬁnition) or 4K resolution images. To address the problem, we propose a novel network capable of real-time dehazing of 4K images on a single GPU, which consists of three deep
CNNs. The ﬁrst CNN extracts haze-relevant features at a reduced resolution of the hazy input and then ﬁts locally-afﬁne models in the bilateral space. Another CNN is used to learn multiple full-resolution guidance maps corresponding to the learned bilateral model. As a result, the feature maps with high-frequency can be reconstructed by multi-guided bilateral upsampling. Finally, the third CNN fuses the high-quality feature maps into a dehazed image. In addition, we create a large-scale 4K image dehazing dataset to support the training and testing of compared models. Experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art dehazing approaches on various benchmarks. 1.

Introduction
Images captured in outdoor usually suffer from notice-able degradation of contrast and visibility since the light scattering and absorption, especially in foggy and hazy weather conditions. Even on a clear day, the impurities of the aerosol attenuate the reﬂected lights of distant objects reaching the camera lens [27, 30].
Single image dehazing aims to estimate the sharp im-age given a hazy input, which is a highly ill-posed prob-lem. Conventional approaches are physically inspired and apply various sharp image priors [3, 18, 31, 44] to regularize the solution space. Most of these methods involve heuris-tic parameter-tuning and expensive computation. Further, these hand-crafted image priors struggle while applying on
*Corresponding authors.
PSNR vs Speed
Ours
AODNet (ICCV'2017)
CAP (TIP'2015)
MS-CNN (ECCV'2016)
DA (CVPR'2020)
MSBDN (CVPR'2020)
PMS (CVPR'2019)
Real time
DehazeNet (TIP'2016)
DCP (CVPR'2009)
GridDehazeNet (ICCV'2019)
NL (CVPR'2016)
FAMED-Net (TIP'2020)
BCCR (CVPR'2016) 10-4 10-3 10-2 10-1 1 102 103 104
Runtime (s)
)
B d (
R
N
S
P 20.0 19.0 18.0 17.0 16.0 15.0 14.0
Figure 1. Speed and accuracy trade-off of the state-of-the-art de-hazing methods and the proposed algorithm on the 4K dehazing dataset. The red dash line denotes the real-time approach for 4K resolution images at 30 fps. The green region indicates the in-ference process at the millisecond (ms) level. The yellow region represents the methods that cannot deal with 4K images directly and needs to use the DDU strategy. For example, the maximum resolution can be handled by GridDehazeNet [32] and MSBDN
[16] is around 1024 × 1024, while PMS [14] can only run on im-ages around 640 × 480. The recent method of DA [40] can dehaze 2K images, i.e., 2560 × 1440. The proposed method generates dehazed images efﬁciently and accurately at 4K resolution. different types of real-world images, where the haze is far more complicated than modeled [1].
Recently, CNNs have been applied in numerous com-puter vision problems, including low-level image recon-struction tasks [22, 42, 48, 46, 49], and showed promising results. Therefore, learning-based methods have also been proposed for dehazing. Early algorithms [9, 26, 38] substi-tute a few modules or steps (e.g., estimating transmission maps or atmospheric lights) in traditional frameworks with learned parameters to make use of external data. More re-cent researches employ trainable end-to-end networks for dehazing images [15, 20, 24, 28, 37]. Although these ap-proaches achieve state-of-the-art results on single image de-hazing task, their models usually have a large size of param-eters and are computationally expensive. 116185  
Existing CNN-based methods have two major limita-tions. First, since learned weights of existing deep models are ﬁxed, these networks need to remove different fog and haze concentrations with the same weights. Therefore, re-covering detailed colors and edges from hazy images is still a non-trivial problem. Second, existing models usually im-plement a highly non-linear mapping from hazy inputs to dehazed results by learning a large number of ﬁlters, which inevitably increases the computational consumption. For example, the recent dehazing methods of GridDehazeNet
[32], PMS [14], MSBDN [16], and Domain Adaption (DA)
[40] cannot directly dehaze 2K or 4K resolution images on an NVIDIA Titan RTX GPU shader with 24G RAM. Al-though the early light-weight deep models [9, 26, 38] can run on 4K images at the millisecond level, the PSNR results are much lower than the recent work of MSBDN [16], PMS
[14], and DA [40] as shown in Figure 1.
Reaching a trade-off between the accuracy and efﬁciency of a network is a non-trivial task. To achieve this, we pro-pose an efﬁcient and interpretable ﬁltering module in bilat-eral space [11]. Since haze effect is inherently contrast (or edges) and color degradations [2, 19, 39], we design edge-aware afﬁne modules for different color channels, which ad-just the bilateral grid to be applied at different regions and channels. Specially, our algorithm extracts high-resolution and low-resolution features for guidance map learning and afﬁne model ﬁtting, respectively. Then, we employ the multi-guided bilateral interpolating into this array of afﬁne models as a function of position and intensity of each color channel that can be applied to restore high-quality feature maps. Finally, we fuse the multiple high-resolution features into the dehazed result. Our analysis shows that the bene-ﬁts of the proposed multi-guided bilateral learning for the dehazing task are two-fold: i) It efﬁciently enables spatially varying restoration since changes in the bilateral grid occur according to the edges and colors in the local region; ii) The proposed model takes less than 8 ms to process a 4K image on a single Titan RTX GPU, which is highly efﬁcient for deployment in practical applications.
The contributions of this paper are as summarized as:
• We propose a multi-guide bilateral learning framework for 4K resolution image dehazing, which can process 4K (3840 × 2160) resolution images at 125 fps.
• We deploy edge-aware modules that adjust the bilateral afﬁne grid to be applied on multi-guided matrices from different color channels for restoring high-quality fea-tures. The method is able to generate more edges and high-frequency details from the hazy input.
• We establish a large and high-quality 4K image dataset for image dehazing. Experimental results on synthetic and real-world images demonstrate the proposed al-gorithm performs favorably against the state-of-the-art methods on arbitrary spatial input sizes. 2.