Abstract
Mask R-CNN
Ours
Tremendous efforts have been made on instance segmen-tation but the mask quality is still not satisfactory. The boundaries of predicted instance masks are usually impre-cise due to the low spatial resolution of feature maps and the imbalance problem caused by the extremely low proportion of boundary pixels. To address these issues, we propose a conceptually simple yet effective post-processing reﬁnement framework to improve the boundary quality based on the results of any instance segmentation model, termed BPR.
Following the idea of looking closer to segment boundaries better, we extract and reﬁne a series of small boundary patches along the predicted instance boundaries. The re-ﬁnement is accomplished by a boundary patch reﬁnement network at higher resolution. The proposed BPR framework yields signiﬁcant improvements over the Mask R-CNN base-line on Cityscapes benchmark, especially on the boundary-aware metrics. Moreover, by applying the BPR framework to the “PolyTransform + SegFix” baseline, we reached 1st place on the Cityscapes leaderboard. Code is available at https://github.com/tinyalpha/BPR. 1.

Introduction
Instance segmentation, which aims to assign a pixel-wise instance mask with a category label to each object in an image, has great potential in various computer vi-sion applications, such as autonomous driving and robotics.
Mask R-CNN [13] is a prevailing two-stage instance seg-mentation framework, which ﬁrst employs a Faster R-CNN
[32] detector to detect objects in an image and further per-∗Equal contribution.
†Corresponding author.
Figure 1: Left: Instance segmentation results and the ex-tracted boundary patches of Mask R-CNN. Right: After the reﬁnement of our BPR framework, the instance mask aligns better with object boundaries. Best viewed with zoom-in. forms binary segmentation within each detected bounding box. Other methods [14, 25] built upon Mask R-CNN consistently achieve superior performance. Driven by the recent development of one-stage detectors [22, 37, 53], a number of one-stage instance segmentation frameworks
[2, 3, 6, 19, 36, 40, 41, 42, 46, 51] have been proposed.
However, the quality of the predicted instance mask is still not satisfactory. One of the most important problems is the imprecise segmentation around instance boundaries.
As shown in Figure 1(left), the predicted instance masks of
Mask R-CNN are coarse and not well-aligned with the real object boundaries. Empirically, correcting the error pix-els near object boundaries can improve the mask quality a lot. We conducted an upper bound analysis in Table 1. A large gain (9.4/14.2/17.8 in AP) can be obtained by simply replacing the predictions with ground-truth labels for pix-els within a certain Euclidean distance (1px/2px/3px) to the predicted boundaries, especially for small objects. 13926
We argue that there are two critical issues leading to low-quality boundary segmentation. (1) The low spatial resolu-tion of the output, e.g. 28×28 in Mask R-CNN or at most 1/4 input resolution in some one-stage frameworks [36, 41], makes ﬁner details around object boundaries disappear. The predicted boundaries are always coarse and imprecise (see
Figure 1 and 4). (2) Pixels around object boundaries only make up a small fraction of the whole image (less than 1%
[16]), and are inherently hard to classify. Treating all pixels equally may leads to an optimization bias towards smooth interior areas, while underestimating the boundary pixels.
As a long-standing challenge in dense prediction tasks, many studies have attempted to improve the boundary qual-ity, while the above issues are still not well solved. For ex-ample, BMask R-CNN [7] and Gated-SCNN [35] employ an extra branch to enhance the boundary awareness of mask features, which can ﬁx the optimization bias to some ex-tent, while the low resolution issue remains unsolved. Poly-Transform [21] and SegFix [48] act as a post-processing scheme to improve the boundary quality. PolyTransform
[21] employs a deforming network with the cropped in-stance patch to predict the offsets of polygon vertices, while suffering from a large computational overhead. SegFix [48] replaces the coarse predictions of boundary pixels with in-terior predictions, but it relies on precise boundary predic-tions. We argue that the instance boundary prediction task shares a similar complexity with instance segmentation.
Considering the human annotation behavior for instance segmentation, the annotators usually ﬁrst localize and cat-egorize each object in the given image, and then explicitly or implicitly segment some coarse instance masks at a low resolution. Afterwards, to obtain a high-quality mask, the annotators need to repeatedly zoom into the local boundary regions and explore the sharper boundary segmentation at higher resolution. Intuitively, high-level semantics are re-quired to localize and roughly segment objects, while low-level details (e.g. colour consistency and contrast) are more critical for segmenting the local boundary regions.
In this paper, motivated by the human segmentation behavior, we propose a conceptually simple yet effective post-processing framework to improve the boundary qual-ity through a crop-then-reﬁne strategy. Speciﬁcally, given a coarse instance mask produced by any instance segmenta-tion model, we ﬁrst extract a series of small image patches along the predicted instance boundaries. After concatenated with mask patches, the boundary patches are fed into a re-ﬁnement network, which performs binary segmentation to reﬁne the coarse boundaries. The reﬁned mask patches are then reassembled into a compact and high-quality in-stance mask, shown in Figure 1(right). We termed the pro-posed framework as BPR (Boundary Patch Reﬁnement).
The proposed framework can alleviate the aforementioned issues and improve the mask quality without any modiﬁ-AP AP50 AP75 APS APM APL
Dist. 57.3 36.4
-63.5 45.8 1px 66.8 50.6 2px 69.3 54.2 3px
∞ 70.4 88.3 36.9 49.3 54.6 58.5 70.4 60.8 64.8 66.5 67.5 70.4 11.1 21.1 26.3 30.4 41.5 32.4 42.6 47.0 50.7 66.7
Table 1: A large gain can be obtained by replacing the pre-dictions for pixels within a certain Euclidean distance to the predicted boundaries with their group-truth labels. ∞ means all error pixels are corrected. Experiments were con-ducted with Mask R-CNN as baseline on Cityscapes val set. cation or ﬁne-tuning to the segmentation models. Since we only crop around object boundaries, the patches are allowed to be processed with the much higher resolution than previous methods, so that low-level details can be re-tained better. Concurrently, the fraction of boundary pixels in the small patch is naturally increased, which can allevi-ate the optimization bias. The proposed BPR framework signiﬁcantly improves the results of Mask R-CNN baseline (+4.3% AP on Cityscapes dataset), and produces substan-tially better masks with ﬁner boundaries. We found that the model trained on the results of Mask R-CNN can be easily transferred to reﬁne the results of other instance seg-mentation models as well, without the need for re-training.
We outperform some boundary reﬁnement methods [17, 48] and show that these methods are complementary by suc-cessfully transferring our model to improve their results.
Furthermore, by applying our BPR framework to the “Poly-Transform + SegFix” baseline [48], we established a new state-of-the-art on the Cityscapes test set with AP of 42.7%, and ranked 1st place on the Cityscapes leaderboard by the
CVPR 2021 submission deadline. 2.