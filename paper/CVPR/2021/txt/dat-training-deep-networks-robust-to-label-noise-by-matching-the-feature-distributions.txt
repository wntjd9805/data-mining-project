Abstract
In real application scenarios, the performance of deep networks may be degraded when the dataset contains noisy labels. Existing methods for learning with noisy labels are limited by two aspects. Firstly, methods based on the noise probability modeling can only be applied to class-level noisy labels. Secondly, others based on the memorization effect outperform in synthetic noise but get weak promotion in real-world noisy datasets. To solve these problems, this paper proposes a novel label-noise robust method named
Discrepant Adversarial Training (DAT). The DAT method has ability of enforcing prominent feature extraction by matching feature distribution between clean and noisy data.
Therefore, under the noise-free feature representation, the deep network can simply output the correct result. To better capture the divergence between the noisy and clean distri-bution, a new metric is designed to change the distribution divergence into computable. By minimizing the proposed metric with a min-max training of discrepancy on classi-ﬁers and generators, DAT can match noisy data to clean data in the feature space. To the best of our knowledge,
DAT is the ﬁrst to address the noisy label problem from the perspective of the feature distribution. Experiments on syn-thetic and real-world noisy datasets demonstrate that DAT can consistently outperform other state-of-the-art methods.
Codes are available at https://github.com/Tyqnn0323/DAT. 1.

Introduction
Beneﬁtting from the support of large-scale annota-tion datasets like ImageNet, deep networks have achieved eyeball-popping performance on various vision problems
*The ﬁrst two authors contributed equally.
†corresponding author. such as image classiﬁcation, object detection and seman-tic segmentation, etc. However, annotating data is an ex-pensive and time-consuming task, especially in manual ex-ecution. Collecting labels from crowdsourcing or crawling websites is a substitutable scheme to make annotation faster and cheaper.
Inevitably, noisy labels will be introduced in the process of these low-quality-annotations. As more complicated network structures are designed for obtaining stronger ﬁtting ability, the deep network has higher capac-ity to overﬁt noisy labels.
It raises an urgent demand on investigating robust learning methods against noisy labels.
Existing methods focus on modeling noise probability or obtaining clean labels by the memorization effect. Noise modeling methods require a precondition, named the con-ditional independent assumption (i.e., noisy labels are only related to ground-true labels, but not to the data samples)
[1, 2, 3, 4]. This conditional independent assumption leads such methods to only apply to class-level noisy labels. The memorization effect means that deep networks learn clean samples in a simple pattern ﬁrst and then gradually learn other noisy samples [5]. Based on this fact, such methods
ﬁlter noisy samples or correct noisy labels with outputs of network [6, 7, 8, 9]. Nevertheless, Jiang et al. found that the memorization effect will lose efﬁcacy on real-world noisy dataset, for the reason that the real-world noisy distribution is close to the original distribution [10]. Research efforts in training with real-world noisy data based on the memoriza-tion effect achieve only marginally effective.
This paper provides a distinctive perspective that noisy labels are processed in the feature distribution instead of la-bel distribution. To achieve this promising methodology, a novel method, named the Discrepant Adversarial Training (DAT), is proposed in this paper. DAT stands out from exist-ing approaches in two aspects. Firstly, DAT avoids the con-ditional independent assumption and focuses on the feature distribution rather than the label distribution. As a result, 6821
it can deal with both class-level and instance-level noisy labels. To our knowledge, no prior work has addressed the label-noise in the feature space. Secondly, even if the noisy distribution is close to the original distribution, DAT can still capture the difference in feature space by calcu-lating distribution divergence. DAT achieves the state-of-the-art accuracy on both synthetic noisy datasets with class-level noisy labels and real-world noisy datasets including instance-level noisy labels.
Contributions of this paper can be summarized as fol-lows:
• This paper theoretically proved that matching the fea-ture distribution from noisy to clean data can deal with the label-noise problem. To apply the theory of match-ing the feature distributions, the proposed DAT method performs an adversarial training on discrepancy be-tween the classiﬁer and the generator with the aid of auxiliary clean dataset. By the adversarial training,
DAT can enforce prominent feature extraction of gen-erator, so that a classiﬁer even with basic structure can effortlessly output the correct result with such a high-quality generator.
• A novel metric h△H-divergence is proposed for cal-culating the distribution divergence. Compared with other metrics [11], the proposed metric has a tighter generalized upper bound for the problem of handling noisy labels.
• DAT can be regarded as a regularization method to pre-vent overﬁtting noisy labels, and the effect is still sig-niﬁcant without clean data. In other words, this paper extends DAT to the absence of auxiliary clean data by a trick. The trick prevents overﬁtting noisy features by matching the macroscopic feature distribution from sampled subset of untrained instances. 2.