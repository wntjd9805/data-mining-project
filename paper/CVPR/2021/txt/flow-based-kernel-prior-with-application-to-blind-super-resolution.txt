Abstract
Kernel estimation is generally one of the key problems for blind image super-resolution (SR). Recently, Double-DIP proposes to model the kernel via a network architec-ture prior, while KernelGAN employs the deep linear net-work and several regularization losses to constrain the ker-nel space. However, they fail to fully exploit the general
SR kernel assumption that anisotropic Gaussian kernels are sufﬁcient for image SR. To address this issue, this paper proposes a normalizing ﬂow-based kernel prior (FKP) for kernel modeling. By learning an invertible mapping be-tween the anisotropic Gaussian kernel distribution and a tractable latent distribution, FKP can be easily used to re-place the kernel modeling modules of Double-DIP and Ker-nelGAN. Speciﬁcally, FKP optimizes the kernel in the la-tent space rather than the network parameter space, which allows it to generate reasonable kernel initialization, tra-verse the learned kernel manifold and improve the optimiza-tion stability. Extensive experiments on synthetic and real-world images demonstrate that the proposed FKP can sig-niﬁcantly improve the kernel estimation accuracy with less parameters, runtime and memory usage, leading to state-of-the-art blind SR results. 1.

Introduction
Image super-resolution (SR) is a fundamental low-level vision task whose goal is to recover the high-resolution (HR) image from the low-resolution (LR) input. With the development of convolutional neural networks (CNN),
CNN-based methods [10, 19, 25, 30, 38, 47, 56] have been gaining the popularity in solving image SR. However, most of existing works assume the blur kernel is ﬁxed and known (e.g., bicubic downsampling kernel), which tends to result in a dramatic performance drop in real-world applications.
Hence, blind image SR that aims to deal with unknown blur
∗Corresponding author. kernels is becoming an active research topic.
Compared to non-blind SR, blind SR generally needs to additionally estimate the blur kernel and thus is more ill-posed. A popular line of work tries to decompose blind
SR into two sub-problems, i.e., kernel estimation and non-blind SR. As a preliminary step of non-blind SR, ker-nel estimation plays a crucial role.
If the estimated ker-nel deviates from the ground-truth, the HR image recon-structed by the non-blind SR methods would deteriorate se-riously [11, 17, 50]. In view of this, this paper focuses on the SR kernel estimation problem.
Recently, some kernel estimation methods, such as
Double-DIP [15, 39] and KernelGAN [3], have shown promising results. Speciﬁcally, with two deep image pri-ors (DIPs) [44], Double-DIP can be used to jointly opti-mize the HR image and blur kernel in the parameter space of untrained encoder-decoder networks by minimizing the
LR image reconstruction error. Although DIP has shown to be effective for modeling natural images, whether it is effective to model blur kernel or not remains unclear. The main reason is that blur kernel usually has a small spatial size and has its own characteristics that differ from natu-In [39], a fully-connected network (FCN) is ral images. used to model the kernel prior, which, however, lacks in-terpretability. With a different framework to Double-DIP,
KernelGAN designs an internal generative adversarial net-work (GAN) for the LR image on the basis of image patch recurrence property [16, 35, 57]. It deﬁnes the kernel im-plicitly by a deep linear network, which is optimized by the GAN loss and ﬁve extra regularization losses such as sparsity loss. Obviously, these two methods do not make full use of the anisotropic Gaussian kernel prior which has been demonstrated to be effective enough for real image
SR [11, 40, 50, 54, 55].
In this paper, we propose a ﬂow-based kernel prior (FKP) for kernel distribution modeling and incorporate it into ex-isting blind SR models. Based on normalizing ﬂow, FKP consists of several batch normalization layers, permutation layers and afﬁne coupling layers, which allow the model 10601
to capture the kernel distribution by learning an invertible mapping between the kernel space and the latent space (e.g., high-dimensional Gaussian). FKP is optimized in an un-supervised way by minimizing the negative log-likelihood loss of the kernel. Once trained, it can be incorporated into existing blind SR models such as Double-DIP and Kernel-GAN for kernel estimation, in which FKP ﬁxes its parame-ters and optimizes the latent variable in the network input space. Speciﬁcally, for Double-DIP, we jointly optimize
DIP for HR image estimation and FKP for kernel estimation by minimizing the LR image reconstruction error. For Ker-nelGAN, we blur the LR image with the kernel estimated by FKP rather than using a deep linear network, and then optimize it by adversarial training.
Using FKP as a kernel prior offers several advantages: 1) Fewer parameters. FKP model only has 143K param-eters, whereas Double-DIP and KernelGAN involve 641K and 151K for kernel modeling, respectively. 2) More stable convergence. On the one hand, unlike Double-DIP that uses random noise input and KernelGAN that uses random net-work parameters for kernel initialization, FKP can explic-itly initialize a reasonable kernel since it is a bijective func-tion. On the other hand, the kernel is implicitly constrained to be in the learned kernel manifold during model optimiza-tion. 3) Better kernel estimation. With a learned kernel prior, the kernel estimation accuracy can be improved for several existing blind SR methods such as Double-DIP and
KernelGAN.
The main contributions are summarized as follows: 1) We propose a kernel prior named FKP that is applica-ble for arbitrary blur kernel modeling. It learns a bi-jective mapping between the kernel and the latent vari-able. To the best of our knowledge, FKP is the ﬁrst learning-based kernel prior. 2) By ﬁxing its parameters and optimizing the latent vari-able, FKP traverses the learned kernel manifold and searches for the kernel prediction, ensuring reasonable kernels for initialization and along optimization. 3) With less parameters, runtime and memory usage, FKP improves the stability and accuracy of existing kernel estimation methods including Double-DIP and Ker-nelGAN, leading to state-of-the-art blind SR perfor-mance. 2.