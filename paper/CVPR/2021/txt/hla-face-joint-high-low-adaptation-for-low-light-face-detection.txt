Abstract
Face detection in low light scenarios is challenging but vital to many practical applications, e.g., surveillance video, autonomous driving at night. Most existing face detectors heavily rely on extensive annotations, while col-lecting data is time-consuming and laborious. To reduce the burden of building new datasets for low light condi-tions, we make full use of existing normal light data and explore how to adapt face detectors from normal light to low light. The challenge of this task is that the gap between normal and low light is too huge and complex for both pixel-level and object-level. Therefore, most existing low-light enhancement and adaptation methods do not achieve desirable performance. To address the issue, we propose a joint High-Low Adaptation (HLA) framework. Through a bidirectional low-level adaptation and multi-task high-level adaptation scheme, our HLA-Face outperforms state-of-the-art methods even without using dark face labels for training. Our project is publicly available at: https:
//daooshee.github.io/HLA-Face-Website/. 1.

Introduction
Face detection is fundamental for many vision tasks, and has been widely used in a variety of practical applications, such as intelligent surveillance for smart city, face unlock, and beauty ﬁlters in mobile phones. Over the past decades, extensive researches have made great progress in face de-tection. However, face detection under adverse illumination conditions is still challenging. Images captured without in-sufﬁcient illumination suffer from a series of degradations, e.g., low visibility, intensive noise, and color cast. These degradations can not only affect the human visual quality, but also worsen the performance of machine vision tasks, which may cause potential risks in surveillance video anal-ysis and nighttime autonomous driving. In Fig. 1 (a), the
∗Corresponding author. This work was supported by the National
Key Research and Development Program of China under Grant No. 2018AAA0102702, the Fundamental Research Funds for the Central Uni-versities, and the National Natural Science Foundation of China under
Contract No. 61772043. This is a research achievement of Key Laboratory of Science, Techonology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology). (a) DSFD (b) LIME + DSFD (c) Ours
Labeled 
Normal Light
Low-level: illumination,  noise pattern, and color transfer
Joint High-Low Adaptation
High-level: semantic feature  adjustment of diﬀerent scenes
Unlabeled 
Low Light (d) Our learning paradigm for dark face detection
Figure 1. Dark face detection visual results and our learning paradigm. Compared with the result of DSFD [26] on original low light images and the enhanced version by LIME [16], our method can better recognize the faces in dark scenarios. state-of-the-art face detector DSFD [26] can hardly detect faces under insufﬁcient illumination, in direct contrast to its over 90% precision on WIDER FACE [49].
To promote the research of low light face detection, a large scale benchmark DARK FACE [50] is constructed.
The emergence of dark face data gives birth to a number of dark face detection researches [27]. However, existing methods are dependent on extensive annotations, therefore have poor robustness and scalability.
In this paper, based on the benchmarking platform pro-vided by DARK FACE, we explore how to adapt normal light face detection models to low light scenarios without the requirement of dark face annotations. We ﬁnd that there are two levels of gaps between normal light and low light.
One is the gap in pixel-level appearance, such as the insufﬁ-cient illumination, camera noise, and color bias. The other is the object-level semantic differences between normal and low light scenes, including but not limited to the exis-tence of street lights, vehicle headlights, and advertisement boards. Traditional low light enhancement methods [16, 52] are designed for improving visual quality, therefore cannot
ﬁll the semantic gap, as shown in Fig. 1 (b). Typical adapta-16195
tion methods [24, 41] are mainly designed for the scenario where the two domains share the same scene, such as adapt-ing from Cityscapes [8] to Foggy Cityscapes [42]. But for our task, the domain gap is more huge, raising a more difﬁ-cult challenge for adaptation.
To adapt from normal light to low light, we propose a High-Low Adaptation Face detection framework (HLA-Face). We consider joint low-level and high-level adapta-tion. Speciﬁcally, for low-level adaptation, typical meth-ods either brighten the dark image or darken the bright im-age. However, due to the huge domain gap, they do not achieve desirable performance.
Instead of unidirectional low-to-normal or normal-to-low translation, we bidirection-ally make two domains each take a step towards each other.
By brightening the low light images and distorting the nor-mal light images, we build intermediate states that lie be-tween the normal and low light. For high-level adaptation, we use multi-task self-supervised learning to close the fea-ture distance between the intermediate states built by low-level adaptation. By combining low-level and high-level adaptation, we outperform state-of-the-art face detection methods even though we do not use the labels of dark faces.
Our contributions are summarized as follows:
• We propose a framework for dark face detection with-out annotated dark data. Through a joint low-level and high-level adaptation, our model achieves superior per-formance compared with state-of-the-art face detection and adaptation methods.
• For low-level adaptation, we design a bidirectional scheme. Through brightening low light data and dis-torting normal light data with noise and color bias, we set up intermediate states and make two domains each take a step towards each other.
• For high-level adaptation, we introduce cross-domain self-supervised learning for feature adaptation. With context-based and contrastive learning, we compre-hensively close the feature distance among multiple domains and further strengthen the representation. 2.