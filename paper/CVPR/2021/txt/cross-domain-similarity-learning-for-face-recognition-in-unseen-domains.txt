Abstract
Face recognition models trained under the assumption of identical training and test distributions often suffer from poor generalization when faced with unknown variations, such as a novel ethnicity or unpredictable individual make-ups during test time. In this paper, we introduce a novel cross-domain metric learning loss, which we dub Cross-Domain
Triplet (CDT) loss, to improve face recognition in unseen domains. The CDT loss encourages learning semantically meaningful features by enforcing compact feature clusters of identities from one domain, where the compactness is measured by underlying similarity metrics that belong to another training domain with different statistics. Intuitively, it discriminatively correlates explicit metrics derived from one domain, with triplet samples from another domain in a uniﬁed loss function to be minimized within a network, which leads to better alignment of the training domains. The net-work parameters are further enforced to learn generalized features under domain shift, in a model-agnostic learning pipeline. Unlike the recent work of Meta Face Recogni-tion [18], our method does not require careful hard-pair sample mining and ﬁltering strategy during training. Exten-sive experiments on various face recognition benchmarks show the superiority of our method in handling variations, compared to baseline and the state-of-the-art methods. 1.

Introduction
Face recognition using deep neural networks has shown promising outcomes on popular evaluation benchmarks
[21, 25, 26, 23]. Many current methods base their ap-proaches on the assumption that the training data – CASIA-Webface [46] or MS-Celeb-1M [19] being the widely used ones – and the testing data have similar distributions. How-ever, when deployed to real-world scenarios, those models often do not generalize well to test data with unknown statis-tics. In face recognition applications, this may mean a shift in attributes such as ethnicity, gender or age between the training and evaluation data. On the other hand, collecting and labelling more data along the underrepresented attributes
Figure 1. Comparison between the conventional triplet and our
Cross-Domain Triplet losses. Top: The standard triplet loss is domain agnostic and utilizes a shared metric matrix, Σ, to measure distances of all (anchor,positive) and (anchor,negative) pairs. Bot-tom: Our proposed Cross-Domain Triplet loss, takes into account
Σ+ and Σ−, i.e., the similarity metrics obtained from positive and negative pairs in one domain, to make compact clusters of triplets that belong to another domain. This, results to better alignment of the two domains. Here, colors indicate domains. is costly. Therefore, given existing data, learning algorithms are needed to yield universal face representations and in turn, be applicable across such diverse scenarios.
Domain generalization has recently emerged to address the same challenge, but mainly for object classiﬁcation with limited number of classes [3, 9, 32]. It aims to employ multiple labeled source domains with different distributions to learn a model that generalizes well to unseen target data at test time. However, many domain generalization methods are tailored to closed-set scenarios and hence, not directly applicable if the label spaces of the domains are disjoint.
Generalized face recognition is indeed a prominent example of open-set applications with very large number of categories, encouraging the need for further research in this area.
In this paper, we introduce an approach to improve the problem of face recognition from unseen domains by learn-ing semantically meaningful representations. To this end, 15292
we are motivated by recent works in few-shot learning [31], domain generalization [9] and face recognition [22], reveal-ing a general fact that, in training a model, it is beneﬁcial to exploit notions of semantic consistency between training data coming from various sources. Therefore, we introduce
Cross-Domain Triplet (CDT) loss based on the triplet ob-jective [36], that learns useful features by considering two domains, where the similarity metrics provided by one do-main are utilized in another domain to learn compact feature clusters of identities (Fig 1).
Such similarity metrics are encoded by means of covari-ance matrices, borrowing the idea from [31]. Different from
[31], however, instead of using class-speciﬁc covariance ma-trices, we cast the problem in domain alignment regime, where our model ﬁrst estimates feature distributions between the anchor and positive/negative samples, namely the sim-ilarity metrics derived from positive/negative pairs in one domain (i.e., Σ+ and Σ− in Fig 1). Then, we utilize these similarity metrics and apply them to triplets of another do-main to learn compact clusters. As supported by theoretical insights and experimental evaluations, our CDT loss aligns distributions of two domains in a discriminative manner.
Furthermore, by leveraging a meta-learning framework, our network parameters are further enforced to learn generalized features under domain shift, following recent studies [9, 18].
Our experiments demonstrate the effectiveness of our approach equipped with the Cross-Domain Triplet loss, con-sistently outperforming the state-of-the-art on practical sce-narios of face recognition for unknown ethnicity using the
Cross-Ethnicity Faces (CEF) [39] and Racial Faces in-the-Wild (RFW) [44] benchmark datasets. Furthermore, it can satisfactorily handle face recognition across other variations as shown by empirical evaluations.
To summarize, we introduce an effective Cross-Domain
Triplet loss function which utilizes explicit similarity met-rics existing in one domain, to learn compact clusters of identities from another domain. This, results to learning semantically meaningful representations for face recogni-tion from unseen domains. To further expose the network parameters to domain shift, under which more generalized features are obtained, we also incorporate the new loss in a model-agnostic learning pipeline. Our experiments show that our proposed method achieves state-of-the-art results on the standard face recognition from unseen domain datasets. 2.