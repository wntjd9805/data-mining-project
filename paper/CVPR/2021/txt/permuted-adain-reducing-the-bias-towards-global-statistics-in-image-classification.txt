Abstract
Recent work has shown that convolutional neural net-work classiﬁers overly rely on texture at the expense of shape cues. We make a similar but different distinction between shape and local image cues, on the one hand, and global image statistics, on the other. Our method, called
Permuted Adaptive Instance Normalization (pAdaIN), re-duces the representation of global statistics in the hidden layers of image classiﬁers. pAdaIN samples a random per-mutation π that rearranges the samples in a given batch.
Adaptive Instance Normalization (AdaIN) is then applied between the activations of each (non-permuted) sample i and the corresponding activations of the sample π(i), thus swapping statistics between the samples of the batch. Since the global image statistics are distorted, this swapping pro-cedure causes the network to rely on cues, such as shape or texture. By choosing the random permutation with probabil-ity p and the identity permutation otherwise, one can control the effect’s strength.
With the correct choice of p, ﬁxed apriori for all experi-ments and selected without considering test data, our method consistently outperforms baselines in multiple settings. In im-age classiﬁcation, our method improves on both CIFAR100 and ImageNet using multiple architectures. In the setting of robustness, our method improves on both ImageNet-C and Cifar-100-C for multiple architectures. In the setting of domain adaptation and domain generalization, our method achieves state of the art results on the transfer learning task from GTAV to Cityscapes and on the PACS benchmark. 1.

Introduction
One of the early successes of computer vision was a face recognition system by Sakai et al. [33] that employed a simple neural network classiﬁer. As it turns out, the network was relying on global image statistics, namely the average brightness, to perform recognition.
In this work, we demonstrate that removing the reliance on global image statistics improves classiﬁcation results in modern networks. To mitigate the effect of the global statis-tics, a deliberate mismatch between the activations of a layer and its accumulated statistics is created. By normalizing with unmatched statistics, the distribution of activation val-ues becomes unreliable as a source for label information.
While changing the global statistics of an image to another was explored in the context of generation [13, 21], we show that it is also useful in a variety of discriminative settings.
Our work is similar in spirit but different in conclusion from recent work [4, 15, 19, 35, 42, 47] that has identiﬁed a bias toward texture at the expense of shape. Such recent methods can often improve the performance of the image classiﬁer on the test set and have been shown to dramatically increase the accuracy of the classiﬁer on shifted image do-mains, in which image transformations change the image statistics but leave most of the shape unchanged.
In our work, we also show classiﬁcation and domain gen-eralization improvements. However, we demonstrate that the increase in classiﬁcation performance occurs simultaneously for both category-based image recognition and texture recog-nition. This suggests that while the texture is often deﬁned as local image statistics, becoming invariant to global image statistics improves both shape and texture recognition.
We demonstrate the effectiveness of our method in a num-ber of settings. First, we demonstrate how classiﬁcation performance improves when adding our permutation-based regularization. Our method improves accuracy on both CI-FAR100 and ImageNet on multiple architectures trained in a vanilla fashion. Second, we train a linear classiﬁer on top of a pre-trained image-classiﬁcation network’s represen-tation layer and show that the accuracy of texture classiﬁ-cation peaks exactly when the image classiﬁcation results are maximized. We show that when this happens, the net-work’s representation of shape does not deteriorate. Next, we demonstrate that our method can reduce the adverse effect of domain shift, by testing it in the setting of domain adaptation and more broadly in domain generalization. Our method achieves state of the art results on the domain adaptation from GTA5 to Cityscapes semantic segmentation and on the
PACS dataset. Lastly, we show that our method allows for a greater robustness when handling corrupted images, where our method is superior to all baseline methods. In the setting 9482
of robustness, our method improves on both ImageNet-C and Cifar-100-C for multiple architectures. 2.