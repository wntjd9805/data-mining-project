Abstract
In this paper, we study two challenging problems in in-complete multi-view clustering analysis, namely, i) how to learn an informative and consistent representation among different views without the help of labels and ii) how to re-cover the missing views from data. To this end, we propose a novel objective that incorporates representation learning and data recovery into a uniﬁed framework from the view of information theory. To be speciﬁc, the informative and consistent representation is learned by maximizing the mu-tual information across different views through contrastive learning, and the missing views are recovered by minimiz-ing the conditional entropy of different views through dual prediction. To the best of our knowledge, this could be the
ﬁrst work to provide a theoretical framework that uniﬁes the consistent representation learning and cross-view data re-covery. Extensive experimental results show the proposed method remarkably outperforms 10 competitive multi-view clustering methods on four challenging datasets. The code is available at https://pengxi.me. 1.

Introduction
In the real world, multi-view data, which often exhibit heterogeneous properties, is collected from diverse sensors or obtained from various feature extractors. As one of the most important unsupervised multi-view methods, multi-view clustering (MVC) aims to separate data points into dif-ferent clusters in an unsupervised fashion [11, 17, 20, 29, 40, 54]. To achieve the end, the key is exploring the consistency across different views so that a common/shared representa-tion is learned [5, 12, 14, 21, 33, 47]. Behind the consistency learning, the implicit assumption is that the views are com-plete, i.e., all data points will present in all possible views.
In practice, however, some views of data points might be missing due to the complexity in data collection and trans-mission, leading to so-called incomplete multi-view prob-∗Corresponding author
Figure 1. Our basic observation and theoretical results from the perspective of information theory. In the ﬁgure, the solid and dot-ted rectangles denote the information contained in view 1 (X1) and view 2 (X2), respectively. In mathematical, the mutual informa-tion I(Z1, Z2) (grey area) quantiﬁes the amount of information shared by Z1 and Z2, where Z1 and Z2 are the representations of X1 and X2, respectively. To learn consistent representations, it is encouraged to maximize I(Z1, Z2).
In addition, minimiz-ing the conditional entropy H(Zi|Zj) (blue area) will encourage the recovery of missing view because Zi is fully determined by
Zj if and only if the conditional entropy H(Zi|Zj) = 0, where i = 1, j = 2 or i = 2, j = 1. Subtly, on the one hand, the maximization of I(Z1, Z2) could increase the amount of the shared information, thus the data recoverability could be beneﬁted, i.e., it is easier to recover one view from the other. On the other hand, as H(Zi|Zj) quantiﬁes the amount of information of Zi conditioned on Zj, the minimization of H(Zi|Zj) will encour-age to discard the inconsistent information across-views, and thus the consistency could be further improved. With the above ob-servation, cross-view consistency and data recovery are treated as two sides of one coin under the above uniﬁed information theory framework. lem (IMP). For example, in online meetings, some video frames might lose the visual or audio signal due to the breakdown of sensors. To solve IMP, some incomplete multi-view clustering algorithms (IMC) have been proposed by employing numerous data recovery methods to com-plete the missing data, e.g., matrix factorization based meth-ods [10, 22, 35, 46, 53] and generative adversarial networks based methods [16, 41, 45]. These works have attempted to overcome the following two challenges: i) how to learn informative and consistent representations across different views? and ii) how to eliminate the inﬂuence of the miss-11174
ing views? Although some promising results have been achieved, almost all existing works treat these two chal-lenges as two independent problems and a uniﬁed theoreti-cal understanding is still lacking.
Different from existing IMC studies, we theoretically show that cross-view consistency learning and data recov-ery could be treated as two sides of one coin and these two challenging tasks could mutually boost. Our motiva-tion comes from [38], as shown in Fig. 1.
It should be pointed out that, [38] utilizes predictive learning to enhance the performance of contrastive learning, while we aim at recovering the missing data through dual prediction. More-over, another difference lies on our theoretical result, i.e., the data recovery and consistency learning could mutually boost through contrastive learning and dual prediction.
Based on our observations and theoretical results, we propose a novel incomplete multi-view clustering termed inCOMPlete muLti-view clustEring via method, conTrastivE pRediction (COMPLETER). In detail, COM-PLETER projects a given dataset into a feature space wherein information consistency and data restorability are guaranteed using three jointly learning objectives. More speciﬁcally, a within-view reconstruction loss is used to learn a view-speciﬁc representation so that the trivial solu-tion is avoided. In the latent feature space, a contrastive loss is introduced to learn the cross-view consistency by maxi-mizing mutual information I(Z1, Z2), and a dual prediction loss is used to recover the missing view by minimizing con-ditional entropy H(Z1|Z2) and H(Z2|Z1).
It should be pointed out that the data recovery referred in this paper is task-oriented, i.e., only the shared instead of all information would be recovered to facilitate the downstream tasks like
MVC. To summarize:
• We provide a novel insight to the community, i.e., the data recovery and consistency learning of incomplete multi-view clustering are with intrinsic connections, which could be elegantly uniﬁed into the framework of information theory. Such a theoretical view is remark-ably different from existing works which treat consis-tency learning and data recovery as two separate prob-lems.
• The proposed COMPLETER method is with a novel loss function which achieves the information consis-tency and data restorability using a contrastive loss and a dual prediction loss. Extensive experiments verify the effectiveness of the proposed loss function. 2.