Abstract 1.

Introduction
Blind face restoration usually relies on facial priors, such as facial geometry prior or reference prior, to restore realistic and faithful details. However, very low-quality inputs cannot offer accurate geometric prior while high-quality references are inaccessible, limiting the applica-bility in real-world scenarios.
In this work, we propose
GFP-GAN that leverages rich and diverse priors encapsu-lated in a pretrained face GAN for blind face restoration.
This Generative Facial Prior (GFP) is incorporated into the face restoration process via spatial feature transform layers, which allow our method to achieve a good balance of realness and ﬁdelity. Thanks to the powerful genera-tive facial prior and delicate designs, our GFP-GAN could jointly restore facial details and enhance colors with just a single forward pass, while GAN inversion methods require image-speciﬁc optimization at inference. Extensive experi-ments show that our method achieves superior performance to prior art on both synthetic and real-world datasets.
Blind face restoration aims at recovering high-quality faces from the low-quality counterparts suffering from un-known degradation, such as low-resolution [13, 48, 9], noise [71], blur [39, 58], compression artifacts [12], etc.
When applied to real-world scenarios, it becomes more challenging, due to more complicated degradation, diverse poses and expressions. Previous works [9, 69, 6] typically exploit face-speciﬁc priors in face restoration, such as fa-cial landmarks [9], parsing maps [6, 9], facial component heatmaps [69], and show that those geometry facial priors are pivotal to recover accurate face shape and details. How-ever, those priors are usually estimated from input images and inevitably degrades with very low-quality inputs in the real world. In addition, despite their semantic guidance, the above priors contain limited texture information for restor-ing facial details (e.g., eye pupil).
Another category of approaches investigates reference priors, i.e., high-quality guided faces [46, 45, 11] or facial 9168
component dictionaries [44], to generate realistic results and alleviate the dependency on degraded inputs. How-ever, the inaccessibility of high-resolution references limits its practical applicability, while the limited capacity of dic-tionaries restricts its diversity and richness of facial details.
In this study, we leverage Generative Facial Prior (GFP) for real-world blind face restoration, i.e., the prior implic-itly encapsulated in pretrained face Generative Adversarial
Network (GAN) [18] models such as StyleGAN [35, 36].
These face GANs are capable of generating faithful faces with a high degree of variability, and thereby providing rich and diverse priors such as geometry, facial textures and col-ors, making it possible to jointly restore facial details and enhance colors (Fig. 1). However, it is challenging to incor-porate such generative priors into the restoration process.
Previous attempts typically use GAN inversion [19, 54, 52].
They ﬁrst ‘invert’ the degraded image back to a latent code of the pretrained GAN, and then conduct expensive image-speciﬁc optimization to reconstruct images. Despite visu-ally realistic outputs, they usually produce images with low
ﬁdelity, as the low-dimension latent codes are insufﬁcient to guide accurate restoration.
To address these challenges, we propose the GFP-GAN with delicate designs to achieve a good balance of realness and ﬁdelity in a single forward pass. Speciﬁcally, GFP-GAN consists of a degradation removal module and a pre-trained face GAN as facial prior. They are connected by a direct latent code mapping, and several Channel-Split Spa-tial Feature Transform (CS-SFT) layers in a coarse-to-ﬁne manner. The proposed CS-SFT layers perform spatial mod-ulation on a split of features and leave the left features to directly pass through for better information preservation, allowing our method to effectively incorporate generative prior while retraining high ﬁdelity. Besides, we introduce facial component loss with local discriminators to further enhance perceptual facial details, while employing identity preserving loss to further improve ﬁdelity.
We summarize the contributions as follows. (1) We leverage rich and diverse generative facial priors for blind face restoration. Those priors contain sufﬁcient facial tex-tures and color information, allowing us to jointly perform face restoration and color enhancement. (2) We propose the GFP-GAN framework with delicate designs of architec-tures and losses to incorporate generative facial prior. Our
GFP-GAN with CS-SFT layers achieves a good balance of
ﬁdelity and texture faithfulness in a single forward pass. (3)
Extensive experiments show that our method achieves su-perior performance to prior art on both synthetic and real-world datasets. 2.