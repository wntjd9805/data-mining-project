Abstract
Previous point cloud semantic segmentation networks use the same process to aggregate features from neighbors of the same category and different categories. However, the joint area between two objects usually only occupies a small percentage in the whole scene. Thus the networks are well-trained for aggregating features from the same category point while not fully trained on aggregating points of dif-ferent categories. To address this issue, this paper proposes to utilize different aggregation strategies between the same category and different categories. Speciﬁcally, it presents a customized module, termed as Category Guided Aggre-gation (CGA), where it ﬁrst identiﬁes whether the neigh-bors belong to the same category with the center point or not, and then handles the two types of neighbors with two carefully-designed modules. Our CGA presents a general network module and could be leveraged in any existing se-mantic segmentation network. Experiments on three differ-ent backbones demonstrate the effectiveness of our method. 1.

Introduction 3D sensor plays an important role in perceiving the en-vironment geometry, it’s widely equipped in home service robots, autonomous cars and even some mobile devices.
Point cloud is an efﬁcient data type to represent the 3D scene. Recently, lots of scene understanding works [22, 23, 30, 15, 27, 34, 35, 3] are committed to designing point-cloud-based neural networks to analyze the semantic label for each point. They usually use an ”Encoder-Decoder” ar-chitecture. The encoder extracts features for every point by aggregating features from neighbors progressively. And the decoder combines the low-level features and the propagated neighboring features to parse the representations to seman-tic labels.
In a real scene, some objects are distinctive, like tables, chairs, and planes. We can classify its category by aggre-gating the features from the object itself. Some objects are
*Corresponding author. 0.75 0.25 0.62 0.38 0.45 0.55 0.6 0.4 0.12 0.88 0.9 0.3 0.7 0.4 0.6 0.1
Same
Direct Augmentation
Different
Co-occurrence Relation
Binary classification
Figure 1. An illustration of our method. We ﬁnd k neighbors for the center point, and identify the probability that they belong to the same or different categories with the center point. Red arrows implies a directly augmentation to the center point. ”Green-Red” dash line means a co-occurrence relation between neighbors and the center. easily confused, like the cup and vase, windows and doors.
Because they are very similar in 3D contour. Since in a real scene, there is a certain dependency between multiple ob-jects, we can leverage the neighbor context to identify those categories.
For those points located in the center area of an object, its context mainly focus on the object itself. In the joint area of two different categories objects, each point gathers features from both the same and different categories. The features of the same category should be similar and serve as compo-nents for object classiﬁcation together. Meanwhile, the fea-tures from the neighbor objects of different categories serve as relation to infer co-occurrence. The learning process for the two types features are different in principle. However, previous works [23, 30, 15, 3] prefer to use a uniﬁed op-erator to cover the two types feature learning. Although the network has strong ﬁtting ability, joint areas only oc-cupy a small percentage in the whole scene, the network tends to learn a group of biased parameters which are more friendly to those areas who keep away from the joint areas, which leading to more ambiguous features in the joint ar-eas. JSENet [6] emphasizes the particularity of edges and designs modules to detect the edge area. It’s useful and ob-tains better results. However, the features for edge detection are different from the semantic segmentation in essence, we think that only detecting the edge is not enough. 11693
In this paper, we propose a neighbor category-guided-aggregation method to augment the representation from any backbones for semantic segmentation. It explicitly models inter-relations between two objects of different categories and enhance intra-consistency in one object. The input are the point-wise representations from any semantic segmenta-tion backbones. First, we ﬁnd k nearest neighbors for each point. With the local context, we identify whether a point and its neighbors belong to the same category. For those who belonging to the same category, we augment the fea-ture of the center point by a weighted sum of neighbors.
For those with different classes, we design a new module to learn how the information from different objects supports the feature learning of the center point. We have conducted several experiments on different datasets and different back-bones. All of the results are improved and we achieve new state of the art in these datasets. Visualized results demon-strate that our method improves both the joint areas and object with internal noise. The key contributions of this paper are as follows,
• We propose a two-path feature augmentation architec-ture to handle the information from the same category and the different categories separately.
• A relational module is proposed to explicitly gather support from objects of different categories.
• Several experiments prove the effectiveness of our method. 2.