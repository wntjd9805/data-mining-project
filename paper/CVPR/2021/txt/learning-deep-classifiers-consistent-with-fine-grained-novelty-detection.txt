Abstract
The problem of novelty detection in ﬁne-grained visual classiﬁcation (FGVC) is considered. An integrated un-derstanding of the probabilistic and distance-based ap-proaches to novelty detection is developed within the frame-work of convolutional neural networks (CNNs). It is shown that softmax CNN classiﬁers are inconsistent with novelty detection, because their learned class-conditional distribu-tions and associated distance metrics are unidentiﬁable. A new regularization constraint, the class-conditional Gaus-sianity loss, is then proposed to eliminate this unidentiﬁa-bility, and enforce Gaussian class-conditional distributions.
This enables training Novelty Detection Consistent Classi-ﬁers (NDCCs) that are jointly optimal for classiﬁcation and novelty detection. Empirical evaluations show that NDCCs achieve signiﬁcant improvements over the state-of-the-art on both small- and large-scale FGVC datasets. 1.

Introduction
Deep convolutional neural networks (CNNs) enabled signiﬁcant breakthroughs in image classiﬁcation [25, 49, 19]. However, CNN classiﬁers are trained under the closed-world assumption that test examples belong to one of the classes on which the CNN was trained. These are referred to as seen or known classes. This assumption is violated in many practical settings, e.g. medical diagnosis [46] or autonomous driving [3], where CNNs can be exposed to images from both seen and unseen classes, i.e. classes that do not appear in the training set. In this setting, CNNs are well-known to assign examples from unseen classes to seen classes with high conﬁdence [6, 56]. In fact, an entire lit-erature on adversarial attacks [51, 16] has grown out of this observation. Novelty detection aims to thwart this problem, by identifying and rejecting examples from unseen classes.
Novelty detection can be divided into the one-class and multi-class settings depending on the number of known classes. In one-class novelty detection [43, 36, 38], which is also known as one-class classiﬁcation (OCC), all train-ing examples are assumed from the same class and have no labels. When seen and unseen classes are from differ-ent domains, novelty detection becomes out-of-distribution (OOD) detection [20, 28, 52, 12, 27]. For instance, a clas-siﬁer of handwritten digit images is confronted with natural images. While OCC and OOD detection have gained signif-icant attention, they are best suited when seen and unseen classes are fundamentally different.
In this work, we address a different and more challenging setting where both seen and unseen classes are sub-classes (e.g., African hunting dog vs. Chesapeake Bay retriever) of a common category (e.g., dog). This is of very practi-cal value for intelligent systems. For example, there might be cases in which it is necessary for surveillance systems deployed at wildlife sanctuaries to detect unseen animal species which might become alien-invasive species. More-over, this is more frequent during the regular operation of vision systems. In applications such as autonomous driv-ing, it is impossible to train for all object sub-classes that already exist, e.g. all road obstacles, or will be created af-ter deployment of the classiﬁer, e.g. new types of scooters or construction signs. Hence, sooner or later, the classiﬁer will face unseen sub-classes. Since this type of novelty de-tection requires ﬁne distinctions between seen and unseen classes, it is best addressed in the multi-class setting, where seen classes are modeled individually.
The core of a novelty detection algorithm is a novelty score or a measure of an example x not belonging to seen classes [9, 39]. This score can be computed by projecting x onto a feature space V, usually the embedding learned by a
CNN, and thresholded to produce a novelty detection deci-sion. Two popular classes of novelty scores are probabilistic and metric-based [41]. The former estimates the probability of x under the distributions of seen classes. The latter es-timates distances between x and seen class representatives.
It can be shown that these two approaches are intrinsically connected for exponential family distributions [5], a family of probability densities that includes most parametric mod-els in common use. Exponential family distributions are de-ﬁned by a sufﬁcient statistic, which can be seen as a feature 1664
transformation or embedding, a set of canonical parame-ters, and a cumulant or log-partition function. The latter is a convex function of the canonical parameters and deﬁnes the geometry of the feature space: its derivatives are the mo-ments of the distribution and its conjugate function deﬁnes the Bregman divergence [10] that underlies the geometry of
V [4]. Hence, for exponential family features, probabilistic and metric scores are two faces of the same coin.
In this work, we leverage the fact that a CNN trained for classiﬁcation induces exponential family class-conditional distributions on its embedding v(x), whose geometry thus follows the associated Bregman divergences. This enables novelty detection by simply thresholding the latter. The difﬁculty, however, is that the standard training by cross-entropy minimization produces class-conditional distribu-tions and corresponding Bregman divergences, that are un-known.
In fact, we show that both class-conditional dis-tributions and Bregman divergences are unidentiﬁable from the CNN parameters. While seen classes are exponentially distributed, these parameters are compatible with many cu-mulant functions and, consequently, Bregman divergences.
This is illustrated in Figure 1(a). Although novelty de-tection can be performed by assuming divergences of spe-ciﬁc forms, e.g. Euclidean distances, this creates an incon-sistency between classiﬁcation and novelty detection that makes the latter suboptimal. It is thus important to consider alternate forms of CNN training that produce classiﬁcation
CNNs consistent with novelty detection. In this work, we propose to regularize CNN training so as to eliminate the unidentiﬁability of Figure 1(a). In particular, we seek regu-larization constraints that guarantee a desired (distribution, divergence) pair. While any pair could be chosen, we en-force multivariate Gaussian distributions and the associated
Mahalanobis distances, for simplicity. However, given the high-dimensional nature of modern CNN embeddings, even covariances constraints are difﬁcult to enforce. We show, however, that it is possible to leverage insights gained from the analysis of embedding geometry to derive a new Class-Conditional Gaussianity (CCG) regularization loss.
As shown in Figure 1(b), the combination of the CCG loss LCCG with the standard cross-entropy loss LCE can be seen as a loss function that operates on the two sides of softmax regression layer. On one hand, LCE shapes the class-posterior probabilities at the output of the layer, en-suring optimal classiﬁcation on seen classes. On the other,
LCCG shapes the class-conditional distributions at the layer input, forcing them to be Gaussian. Finally, because the output class-posterior probability distributions are compati-ble with any exponential family distribution for the class-conditionals, the addition of this regularization does not hinder classiﬁcation performance. Overall, the resulting classiﬁer is consistent with novelty detection, which can be equally implemented by thresholding class-conditional (a) ND-inconsistent CNN (b) ND-consistent CNN
Figure 1. 1(a): A CNN trained for classiﬁcation with the cross-entropy loss LCE is inconsistent with novelty detection (ND). Be-cause the class-conditional distributions learned by the CNN are unidentiﬁable, multiple sets of distributions (visualized using con-tour plots) are compatible with the CNN parameters. 1(b): Reg-ularization with the proposed CCG loss LCCG makes the distribu-tions identiﬁable, in fact Gaussian, without sacriﬁcing classiﬁca-tion performance. probabilities or Bregman divergences, with little loss of classiﬁcation performance on seen classes.
The paper makes four contributions to the study of nov-elty detection. The ﬁrst is a theoretical analysis of the soft-max classiﬁer, showing that although it learns exponential family class-conditional distributions, these are not identi-ﬁable. The second is the derivation of identiﬁability condi-tions, that guarantee Gaussian distributions and associated
Mahalanobis distances. The third is the CCG regulariza-tion loss that encourages these conditions to hold, produc-ing classiﬁers that are consistent with novelty detection. Fi-nally, evaluations on various ﬁne-grained visual classiﬁca-tion datasets demonstrate that our proposed method signiﬁ-cantly advances the state-of-the-art for novelty detection. 2.