Abstract
Domain adaptation deals with training models using large scale labeled data from a speciﬁc source domain and then adapting the knowledge to certain target domains that have few or no labels. Many prior works learn do-main agnostic feature representations for this purpose us-ing a global distribution alignment objective which does not take into account the ﬁner class speciﬁc structure in the source and target domains. We address this issue in our work and propose an instance afﬁnity based criterion for source to target transfer during adaptation, called ILA-DA. We ﬁrst propose a reliable and efﬁcient method to ex-tract similar and dissimilar samples across source and tar-get, and utilize a multi-sample contrastive loss to drive the domain alignment process. ILA-DA simultaneously ac-counts for intra-class clustering as well as inter-class sepa-ration among the categories, resulting in less noisy clas-siﬁer boundaries, improved transferability and increased accuracy. We verify the effectiveness of ILA-DA by ob-serving consistent improvements in accuracy over popu-lar domain adaptation approaches on a variety of bench-mark datasets and provide insights into the proposed align-ment approach. Code will be made publicly available at https://github.com/astuti/ILA-DA. 1.

Introduction
In this work, we propose a method to leverage instance wise similarities across datasets, called ILA-DA, to im-prove unsupervised domain adaptation.
It is well known that models trained on a large-scale labeled dataset are generally sensitive to domain shifts and do not generalize well to data that lies outside the training distribution [65].
Unsupervised domain adaptation [5, 4, 53] emerged as a feasible alternative to transfer knowledge from a labeled source domain to one or more unlabeled target domains by minimizing some notion of divergence between the do-mains [39, 35, 63, 17, 66, 8]. A majority of successful ap-proaches rely on global distribution alignment using adver-Figure 1: Motivation for the proposed approach (a), (b) Most adversarial learning based adaptation approaches achieve global domain alignment which often leads to misalignment near the clas-siﬁer boundaries. (c) Using our afﬁnity matrix based approach in combination with the proposed MSC loss, we achieve better dis-crimination between target samples and improve the adaptation. sarial learning [17, 66, 8, 7, 58], where the objective is to learn features that are good enough to fool a discriminator into classifying source samples as target and vice versa. A major limitation with these methods is that while learning domain agnostic feature representations, they do not con-sider the ﬁner class speciﬁc structure of the samples during the alignment resulting in noisy predictions near classiﬁer boundaries. They do not take into account, for example, the fact that the afﬁnity of different categories across source and target towards alignment can be different, which might lead to misalignment of few categories as shown in Fig. 1.
This problem is alleviated to an extent by many follow-up works that make use of target pseudo labels to guide class speciﬁc alignment [27, 21, 37, 50, 40, 75, 49]. However, the performance of these approaches is in most cases tied to the reliability of predicted pseudo labels which can be noisy without adequate ﬁltering measures, leading to nega-tive alignment between unrelated categories.
In this work, we address these limitations by proposing a novel adaptation approach called ILA-DA (Instance Level
Afﬁnity-based Domain Adaptation). We combine ideas 5361
from metric learning literature [73, 70, 34, 15, 15, 52, 20] to perform cross domain transfer by using instance afﬁnity re-lations between the source and target samples. As opposed to prior works that perform domain level or class level align-ment, we show that a much ﬁner knowledge in the form of sample level similarity can be successfully exploited to im-prove the adaptation process. The main challenge with this approach is that the target domain is completely unlabeled to extract similarity. To overcome this, we propose a near-est neighbor based technique to ﬁrst construct a pairwise afﬁnity matrix. We then use this knowledge of cross do-main positive and negative relations in a multi-sample con-trastive learning (MSC) loss that uses multiple positives and negatives across domains in a contrastive learning frame-work [20, 47].
We identify two advantages using ILA-DA. Firstly, the pairwise similarities provide a relatively stronger signal during training and are shown to be more robust to la-bel corruptions compared to category predictions in many cases [25, 26]. Secondly, our multi-sample contrastive loss aims to cluster similar samples from across domain closer together while pushing dissimilar samples away to avoid negative transfer. This is especially useful in adapta-tion across ﬁne-grained datasets, where the challenge, apart from domain shift, is to additionally acknowledge the large intra-class variation within the categories.
The effectiveness of ILA-DA is reﬂected by improved adaptation accuracy on popular benchmarks like Digits and
Ofﬁce-31 datasets. We also achieve state-of-the-art results on a challenging adaptation dataset Birds-31 [71] without using complementary information such as label-hierarchies and class structure unlike [71], which indicates the useful-ness of our MSC loss in handling wide variety of scenarios.
We further perform extensive ablations and analysis on our methodological choices. All code and data for our method and baselines will be publicly released.
In summary, the key highlights of the paper are:
• We propose a novel adaptation frame work ILA-DA. It uses Multi-Sample Contrastive (MSC) loss to perform instance afﬁnity aware transfer by identifying pairwise similarity relations across source and target domains.
• ILA-DA is designed to be general and can be applied to enhance any existing adversarial adaptation approach.
We show experimental results while using it in com-bination with two popular methods, DANN [17] and
CDAN [36], and observe consistent improvements over both the baselines.
• We validate the effectiveness of the proposed approach numerically by applying it on multiple tasks from var-ious challenging benchmark datasets used for domain adaptation like Digits, Ofﬁce-31 and Birds-31 and ob-serve improved accuracies in all the cases, sometimes outperforming the state-of-the-art by a large margin. 2.