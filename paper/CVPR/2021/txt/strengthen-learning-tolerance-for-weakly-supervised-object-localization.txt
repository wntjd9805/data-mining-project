Abstract
Weakly supervised object localization (WSOL) aims at learning to localize objects of interest by only using the image-level labels as the supervision. While numerous ef-forts have been made in this Ô¨Åeld, recent approaches still suffer from two challenges: one is the part domination is-sue while the other is the learning robustness issue. Specif-ically, the former makes the localizer prone to the local dis-criminative object regions rather than the desired whole ob-ject, and the latter makes the localizer over-sensitive to the variations of the input images so that one can hardly ob-tain localization results robust to the arbitrary visual stim-ulus. To solve these issues, we propose a novel framework to strengthen the learning tolerance, referred to as SLT-Net, for WSOL. SpeciÔ¨Åcally, we consider two-fold learning toler-ance strengthening mechanisms. One is the semantic toler-ance strengthening mechanism, which allows the localizer to make mistakes for classifying similar semantics so that it will not concentrate too much on the discriminative local regions. The other is the visual stimuli tolerance strengthen-ing mechanism, which enforces the localizer to be robust to different image transformations so that the prediction qual-ity will not be sensitive to each speciÔ¨Åc input image. Fi-nally, we implement comprehensive experimental compar-isons on two widely-used datasets CUB and ILSVRC2012, which demonstrate the effectiveness of our proposed ap-proach. 1.

Introduction
Object detection [22, 18] has made great progress in re-cent years due to the success of convolutional neural net-works (CNNs) [27, 30, 9, 15, 17]. However, the conven-tional methods would still suffer from the heavy labor costs for providing the bounding box annotations, which makes researchers start paying more attention on the weakly su-pervised object localization (WSOL) problem [16, 53, 28, 48, 6, 19, 5]. Different from the fully supervised methods,
‚àóCorresponding author. t r a
P
) a ( n o i t a n i m o d
Common Raven White-necked Raven epoch4 epoch20 o t e v i t i s n e
S
) b ( l s u u m i t s l a u s i v
‚Ä¶
‚Ä¶
Training Procedure
Figure 1. Example of typical WSOL issues. (a) Part domination: focusing on most discriminative parts of the object. (b) Sensitive to visual stimulus: the localization accuracy of different instances show the different convergence trend. The IOU values are shown in white text; the predicted and ground-truth boxes are shown in green and red, respectively.
WSOL methods only require the image-level annotations and thus can save a lot of time and labor costs.
Previous WSOL methods can be divided into two main categories, i.e., the uniÔ¨Åed localization-classiÔ¨Åcation frame-work and the separated localization-classiÔ¨Åcation frame-work. The former framework predicts the localization map and classiÔ¨Åcation results in the same network which has been exhaustively studied in the prior works [53, 25, 28, 48, 49, 6, 40, 20]. While the latter framework is appeared in two of the most recent works [42, 19]. These methods achieve localization and classiÔ¨Åcation in two separate net-works, where off-the-shelf CNN models are directly used as the classiÔ¨Åers. SpeciÔ¨Åcally, in GC-Net [19], the authors
Ô¨Årst generate a geometry constrained mask to split fore-ground and background. Then, they optimize the obtained mask under the guidance of a trained classiÔ¨Åer. Different form GC-Net, PSOL [42] directly uses an co-localization methods DDT [53] to generate pseudo bounding boxes for the localization branch. Since the uniÔ¨Åed localization-classiÔ¨Åcation framework has to change the network archi-tecture to obtain better localization performance, the sepa-17403        
(a) Localization branch training 
Transformed image
Localizer
ùëî ¬∑
Input image
Semantic Tolerance
GAP (cid:3400)
F
C (cid:3400)
‚Ñí(cid:2903)(cid:2897)(cid:2904)
‚Ñí(cid:2903)(cid:2897)(cid:2904)
ùë•(cid:2869)
ùë¶(cid:2869)
ùë•(cid:2870)
ùë¶(cid:2870)
‚Ñí(cid:2902)(cid:2889)(cid:2891)
Regressor (b) Classifier training 
Íûè Íûè Íûè 
Visual Stimuli Tolerance
Input image
Classifier
‚Ñí(cid:2887)(cid:2889) (cid:4593)
ùëî
¬∑
‚Ñí(cid:2906)(cid:2903)(cid:2904)
Íûè Íûè Íûè 
Pseudo Location (c) Inference
Location
Regressor
Results
Classifier
Class
Input image
Figure 2. SLT-Net consists of the localizer, regressor, and classiÔ¨Åer. (a) When train the localization branch, the input image and transformed image are fed into the localizer to get two class activate maps (CAM). Then inverse transformations are applied to the CAM of the transformed image, and the inverse transformed CAM is matched to the original CAM. The regressor is supervised by the predicted location of the localizer. (b) The classiÔ¨Åer is trained independently. (c) In the inference process, we get the classiÔ¨Åcation and localization results from the classiÔ¨Åer and regressor, respectively. rated localization-classiÔ¨Åcation framework will have higher classiÔ¨Åcation accuracy. In this paper, we adopt to use the separated localization-classiÔ¨Åcation framework.
For both of the aforementioned WSOL frameworks, one typical problem is the part domination effect of CNNs: pre-dictions tend to be dominated by the most discriminative parts of the object. As shown in Figure 1a, since the Com-mon Raven category and White-necked Raven category has little difference except the color of the neck regions, the class activate maps extracted from these images would only focus on the neck of the bird, which will lead to an incor-rect prediction of the object location. We believe that the reason for this phenomenon is the lack of tolerance to the se-mantic mistakes. In other words, network models used for localization should not be punished too much for predict-ing a similar but wrong semantic class. Another problem in WSOL is the learning robustness issue. While only the image-level supervision is available, the model can hardly extract the equivariant patterns during the learning process.
This makes the models sensitive to the variations of the in-put visual stimulus, such as different hues, contrast, texture, spatial location, etc. Consequently, the convergence trends of different instances‚Äô localization accuracy become quite different. As shown in Figure 1b, although the two images belong to the same category Bobolink, the localization ac-curacy of the top image increases in the whole training pro-cess. On the contrary, the localization result of the bottom image is accurate in the Ô¨Årst training epoch and then drifts to inaccurate regions at the terminate iteration. This phe-nomenon makes it hard to obtain a WSOL model that can achieve accurate performance for the arbitrary input images.
Maybe it is hard to eliminate the variations of the input im-ages, but we can alleviate this problem by enhancing the model‚Äôs tolerance to such variations on our own initiative.
Based on the above considerations, in this paper, we pro-pose a novel weakly supervised object localization frame-work to strengthen the learning tolerance to 1) the mistakes made in semantic classifying and 2) different image trans-formations. We name the proposed methods the SLT-Net.
As shown in Figure 2, SLT-Net is a separate localization-classiÔ¨Åcation framework that contains three sub-networks: a localizer, a regressor, and a classiÔ¨Åer. The localizer and regressor compose the localization branch that provides the location predictions, while the classiÔ¨Åer takes responsibility for predicting the class. To make the localizer tolerate the semantic classiÔ¨Åcation mistakes, we design a class-tolerant classiÔ¨Åcation module and the corresponding class-tolerant activation mapping technique to generate the location map.
SpeciÔ¨Åcally, for each input image, we divide all candidate categories into two groups: one contains the correct cat-egory together with its similar categories, while the other contains the categories that of less similarity to the cor-rect category. For the categories from the former group, we reduce their training losses to make the model allevi-ate the part dominant effect. For the categories from the later group, we use the normal classiÔ¨Åcation training strat-egy to improve the ability of the localizer to distinguish the foreground and background. Moreover, to enhance the tol-erance for different input visual stimulus, we Ô¨Årst apply im-age transformations to actively improve the variability of the training images and then enable the model to learn the desired equivariant patterns by minimizing the difference between the class activates maps of the transformed image and the original image.
To sum up, this work mainly contains the following four-fold contributions:
‚Ä¢ We propose a novel separated localization classiÔ¨Åca-tion method SLT-Net for weakly supervised object localization. SLT-Net improves localization perfor-mance by strengthening the learning tolerance to se-27404
mantic mistakes and data distribution diversity.
‚Ä¢ We propose a class-tolerance classiÔ¨Åcation module to strengthen the tolerance of semantic classiÔ¨Åcation mis-takes, which can mitigate the part domination prob-lem by reducing the punishment of error classiÔ¨Åcation among similar categories.
‚Ä¢ We strengthen the tolerance to image diversity by matching the visual response map of the transformed image to that of the original image.
‚Ä¢ Experiments on the Ô¨Åne-grained dataset CUB and large-scale dataset ILSVRC2012 demonstrate the ef-fectiveness of the proposed method. 2.