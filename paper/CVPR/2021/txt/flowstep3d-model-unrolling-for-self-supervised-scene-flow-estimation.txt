Abstract
Estimating the 3D motion of points in a scene, known as scene ﬂow, is a core problem in computer vision. Tra-ditional learning-based methods designed to learn end-to-end 3D ﬂow often suffer from poor generalization. Here we present a recurrent architecture that learns a single step of an unrolled iterative alignment procedure for reﬁning scene ﬂow predictions. Inspired by classical algorithms, we demonstrate iterative convergence toward the solution us-ing strong regularization. The proposed method can han-dle sizeable temporal deformations and suggests a slim-mer architecture than competitive all-to-all correlation ap-proaches. Trained on FlyingThings3D synthetic data only, our network successfully generalizes to real scans, outper-forming all existing methods by a large margin on the KITTI self-supervised benchmark.1 1.

Introduction
Understanding motion is fundamental to many applica-tions in a variety of ﬁelds, such as human-computer inter-action, robotics, and autonomous driving. The information absorbed within a temporal window is not only a collection of images or a representation of an outcome, but also a de-scription of a process.
Decades ago, computer vision tackled the task of mo-tion estimation, searching for a ﬂow between two images
[3, 7, 14, 22, 41]. One signiﬁcant leap forward in under-standing the motion of a scene, deﬁned as scene ﬂow, is the presence of 3D geometry. It liberates us from consid-ering color as the main correspondence feature and allows examining the structure itself to understand the motion. Ax-iomatic concepts of rigidity [2, 6] provided fast and accu-rate results, but once piece-wise movements [9, 10, 39] or non-rigidity [1, 15, 23] was allowed, scene ﬂow estimation problem became ill-posed and unfortunately hard to solve.
The rise of artiﬁcial intelligence [19] gives hope that solving the 3D ﬂow estimation problem is possible using
Figure 1. Model unrolling. Top: source (green) and target (blue) input point clouds sampled from the KITTI [27] scene-ﬂow dataset. Middle: illustration of our FlowStep3D architecture un-rolled for K iterations. Bottom: source warped over the predicted
ﬂow at each iteration toward the static target at inference time. a network architecture. Indeed, in the last few years, an im-provement in different learning-based methods [12, 21, 31, 37, 43] has been seen, outperforming those that relied on optimization. More importantly, these learned models are fast and robust.
Scene ﬂow estimation is an integral component in the autonomous driving industry, where LiDAR data is used for the perception of the environment. However, LiDAR sensors suffer from sparseness, directly affecting deep-learning ﬂow algorithms that require knowledge of the ob-jects’ spatio-temporal neighborhood. In other words, once the structures do not heavily overlap, the process fails. In an attempt to solve this limitation, we recently have seen all-to-all mechanisms both for images [36] and geometry [31].
However, these methods consume large amounts of mem-ory and tend to produce outliers, as now nearby points can be aligned with inconsistent temporal positions. 1https://github.com/yairkit/flowstep3d
In this work, we focus on the scene ﬂow problem, where 4114
large deviations between the scenes can occur. A small set of points is used to guide the alignment in an all-to-all ap-proach, and a recurrent reﬁnement block is then unrolled to learn movement differentiators. We train our network to predict a single step at a time and converge iteratively to-ward the end ﬂow solution, as illustrated in Fig.1. Although unrolled for K iterations during training, our network can be used for inference with a larger number of iterations to handle more signiﬁcant and complicated deformations.
Trained on synthetic data only, our method improves the state-of-the-art results on the self-supervised KITTI bench-mark by a considerable margin. Our architecture is further tested in a fully-supervised framework and achieves slightly better results compared to prior art while beneﬁting from memory efﬁciency.
The key contributions of this work are as follows:
• We present the ﬁrst recurrent architecture for non-rigid scene ﬂow.
• We provide a slim memory all-to-all correlation pipeline by merging low-resolution correlation with an unrolling iterative reﬁnement process.
• Our proposed network achieves large improvements over existing self-supervised methods on both Fly-ingThings3D and KITTI benchmarks. 2.