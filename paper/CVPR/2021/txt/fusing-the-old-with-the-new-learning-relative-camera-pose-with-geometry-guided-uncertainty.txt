Abstract
Learning methods for relative camera pose estimation have been developed largely in isolation from classical geo-metric approaches. The question of how to integrate predic-tions from deep neural networks (DNNs) and solutions from geometric solvers, such as the 5-point algorithm [37], has as yet remained under-explored. In this paper, we present a novel framework that involves probabilistic fusion between the two families of predictions during network training, with a view to leveraging their complementary beneﬁts in a learn-able way. The fusion is achieved by learning the DNN un-certainty under explicit guidance by the geometric uncer-tainty, thereby learning to take into account the geometric solution in relation to the DNN prediction. Our network features a self-attention graph neural network, which drives the learning by enforcing strong interactions between dif-ferent correspondences and potentially modeling complex relationships between points. We propose motion parme-terizations suitable for learning and show that our method achieves state-of-the-art performance on the challenging
DeMoN [61] and ScanNet [8] datasets. While we focus on relative pose, we envision that our pipeline is broadly applicable for fusing classical geometry and deep learning. 1.

Introduction
Estimating the relative pose between two cameras is a fundamental problem in computer vision, which forms the backbone of structure from motion (SFM) methods. Geomet-ric approaches based on the 5-point method [37] and bundle adjustment (BA) [59] are well-studied, while recent meth-ods based on deep neural networks (DNNs) also achieve promising results [61, 7, 56, 65]. But the question of how the two families of methods may be combined to trade-off their relative beneﬁts has as yet remained under-explored, which is the subject of our study in this paper.
The behavior of geometric methods [18] is theoretically characterizable under a wide range of camera motions. But 5-pt Solver & BA
Image pair with correspondences
Neural Network generalization  interpretability training-free textures degeneracy ambiguity
Uncertainty-based Fusion
Loss
Ground Truth
Camera Pose data prior no degeneracy  global context generalization  interpretability data-hungry
Figure 1. Geometric-DNN relative pose fusion framework. The
DNN pose prediction is fused with the geometric prediction during training, based on their respective prediction uncertainty. such understanding does not always guarantee good per-formance. While high accuracy is obtained in situations with strong perspective effects, performance may degrade due to lack of correspondences, planar degeneracy and bas-relief ambiguity [9], to name a few. On the other hand, learning-based methods may avoid the above issues by learn-ing sophisticated priors that relate images to camera motion, but can suffer from poor generalization outside the training domain and not be amenable to interpretation.
This paper proposes an uncertainty based probabilistic framework to fuse geometric and DNN predictions, as illus-trated in Fig. 1, with the aim of overcoming the limitations of either approach. The underlying intuition is that the geomet-ric solution may be trusted more due to its well-understood rationale if it is highly conﬁdent, but the network should play a role in driving the solution closer to the true one in geo-metrically ill-conditioned scenarios. We obtain geometric uncertainty using the Jacobian of the error functions, serving as an indicator of the quality of the solution, while we design a network to additionally predict the uncertainty associated with camera pose estimation. The uncertainty so obtained may be interpreted as (co)variance of a Gaussian distribu-tion, which allows us to fuse the two predictions using Bayes’ 32
rule. We highlight that the geometric solution and the fusion step are both tightly integrated into our end-to-end trainable pipeline, hence enforcing strong interaction between DNNs and the geometric method during training.
Our relative pose learning framework is the ﬁrst of its kind in terms of forcing the network to give an account of the classical geometric solution along with its uncertainty in a principled way, during training. The network can also be thought of as a means to learn to improve the geometric solution such that the ﬁnal fused one is closer to the ground truth. Further, the geometric guidance also distinguishes our uncertainty learning from previous works (e.g. [27]) that learn standard aleatoric uncertainty [26]. More importantly, our learned uncertainty may be considered as geometrically calibrated, in the sense that its numerical range can readily match to that of the geometric uncertainty and permits a direct fusion of the two during training.
In terms of network architecture, inspired by SuperGlue
[46], we ﬁnd a self-attention [62] graph neural network (GNN) to be effective at learning from keypoint correspon-dences. This is probably since self-attention permits strong interactions between correspondences, which is an essential procedure to determine the relative pose. We also illustrate that even both translation direction and rotation lie on a manifold, fusion is still feasible by careful choice of parame-terization. We term our uncertainty-aware fusion framework as UA-Fusion. UA-Fusion is extensively validated by achiev-ing state-of-the-art performance, especially in challenging indoor datasets with unconstrained motions.
In summary, our contributions include:
• A principled fusion framework to leverage the best of both classical geometric solvers and DNNs for relative pose estimation.
• A self-attention graph neural network whose attention mechanism drives the learning in our fusion pipeline.
• Superior results on benchmark DeMoN dataset [61] as well as in cross-dataset ScanNet experiments [8]. 2.