Abstract
Prior research on self-supervised learning has led to considerable progress on image classiﬁcation, but often with degraded transfer performance on object detection.
The objective of this paper is to advance self-supervised pretrained models speciﬁcally for object detection. Based on the inherent difference between classiﬁcation and detec-tion, we propose a new self-supervised pretext task, called instance localization. Image instances are pasted at various locations and scales onto background images. The pretext task is to predict the instance category given the compos-ited images as well as the foreground bounding boxes. We show that integration of bounding boxes into pretraining promotes better task alignment and architecture alignment for transfer learning. In addition, we propose an augmen-tation method on the bounding boxes to further enhance the feature alignment. As a result, our model becomes weaker at Imagenet semantic classiﬁcation but stronger at image patch localization, with an overall stronger pre-trained model for object detection. Experimental results demonstrate that our approach yields state-of-the-art trans-fer learning results for object detection on PASCAL VOC and MSCOCO1. 1.

Introduction
The dominant paradigm for training deep networks in computer vision is by pretraining and ﬁnetuning [20, 29].
Typically, the pretraining is optimized to ﬁnd a single generic representation that is later transferred to various downstream applications. For example, supervised pre-trained models using image-level labels [26, 25] and self-supervised pretrained models by contrastive learning [22] both transfer remarkably well to a number of tasks, e.g., im-age classiﬁcation, object detection, semantic segmentation and human pose estimation.
Despite the popularity of this approach, we question the existence of such generic and universal representations for transfer learning. Recently, it has been observed that self-1Code and models are available at this link.
‡ indicates corresponding author. 42 41 40
P
A n o i t c e t e
D 39 62
InsLoc
InfoMin
MoCo
BYOL
SimCLR
SWAV 66
Classification Accuracy 70 74
Figure 1.
For visual transfer learning, it is widely assumed that the ImageNet classiﬁcation accuracy and object detection performance are positively correlated. By studying recent self-supervised models, we ﬁnd that this is not actually the case. We propose a novel approach, called Instance Localization (InsLoc), which sacriﬁces ImageNet classiﬁcation accuracy, but enjoys bet-ter generalization ability for object detection. supervised representations which improve upon image clas-siﬁcation performance may fail to translate the advantage to object detection [3, 21]. Also, it is found that high-level features is not what truly matters in transfer to de-tection and segmentation [46]. These indicate that current self-supervised models may overﬁt to the classiﬁcation task while becoming less effective for other tasks of interest.
We identify two issues that contribute to task misalign-ment in transfer learning. The ﬁrst is that the pretrained net-work needs to be re-purposed into the target network archi-tecture for ﬁnetuning. This often involves non-trivial archi-tectural changes, such as inserting a feature pyramid [27] or employing convolution kernels with large dilations [4]. Sec-ond, for typical contrastive learning models, the pretraining pretext task considers an image holistically in instance dis-crimination [41], without explicit spatial modelling over re-gions. Though it enhances transferability for classiﬁcation, this practice is less compatible with spatial reasoning tasks, such as object detection.
In this paper, we propose a new self-supervised pre-text task, called instance localization, speciﬁcally for the downstream task of object detection. Akin to instance dis-13987  
crimination, which learns a classiﬁer for individual image instances, instance localization additionally takes bound-ing box information into account for representation learn-ing. We create our training set by taking crops of fore-ground images and pasting them at various aspect ratios and scales onto different locations of background images. Self-supervised pretraining follows by extracting RoI features using bounding boxes and performing contrastive learning using instance labels. In this way, not only does the network architecture maintain consistency during transfer, but the pretraining task also includes localization modelling, which is crucial for object detection.
Introducing bounding boxes into pretraining encourages explicit alignment between convolutional features and fore-ground regions. The feature responses thus become sensi-tive to translations in the image domain, beneﬁting detec-tion [10]. We additionally ﬁnd that feature alignment can be strengthened by inducing augmentations on the bound-ing box coordinates. Speciﬁcally, spatially jittered bound-ing boxes are randomly selected from a set of region pro-posal anchors.
We implement the approach within the framework of momentum contrast [22]. The network takes the compos-ited images and bounding boxes as input, and extracts re-gion embeddings for contrastive learning. Compared with the baseline approach which considers holistic instances, a linear probe on the last-layer features shows reduced perfor-mance for image classiﬁcation, while achieving improve-ments in regressing bounding box locations. Experimen-tally, we study two popular detection backbone networks,
ResNet50-C4 and ResNet50-FPN. For both backbone net-works, our instance localization approach elevates perfor-mance substantially, surpassing the state-of-the-art transfer learning results on PASCAL VOC [17] and MSCOCO [28].
Notably, our model is even more advantageous for object detection under the small data regime. 2.