Abstract
Skeletal motion plays a vital role in human activity recognition as either an independent data source or a com-plement [33]. The robustness of skeleton-based activity recognizers has been questioned recently [29, 50], which shows that they are vulnerable to adversarial attacks when the full-knowledge of the recognizer is accessible to the at-tacker. However, this white-box requirement is overly re-strictive in most scenarios and the attack is not truly threat-ening.
In this paper, we show that such threats do exist under black-box settings too. To this end, we propose the
ﬁrst black-box adversarial attack method BASAR. Through
BASAR, we show that adversarial attack is not only truly a threat but also can be extremely deceitful, because on-manifold adversarial samples are rather common in skele-tal motions, in contrast to the common belief that adver-sarial samples only exist off-manifold [18]. Through ex-haustive evaluation and comparison, we show that BASAR can deliver successful attacks across models, data, and at-tack modes. Through harsh perceptual studies, we show that it achieves effective yet imperceptible attacks. By an-alyzing the attack on different activity recognizers, BASAR helps identify the potential causes of their vulnerability and provides insights on what classiﬁers are likely to be more robust against attack. 1.

Introduction
Deep learning methods have been proven to be vulnera-ble to carefully devised data perturbations since ﬁrst identi-ﬁed in [45]. This causes major concerns especially in safety and security [1], as the perturbations are imperceptible to humans but destructive to machine intelligence. Conse-quently, how to detect and defend attacks has also been in-vestigated [6]. While the attack on static data (e.g. images, texts, graphs) has been widely studied, the attack on time-∗The research was conducted during the visit to the University of Leeds.
†Corresponding author
‡https://youtu.be/PjWgwnAkV8g series data has only been recently explored [23, 16]. In this paper, we look into a speciﬁc yet important type of time series data, skeletal motions, under adversarial attack.
Skeletal motion is crucial in activity recognition as it in-creases the robustness by mitigating issues such as lighting, occlusion, view angles, etc [37]. Therefore, the vulnera-bility of skeleton-based classiﬁers under adversarial attack has recently drawn attention [29, 61, 50]. Albeit identify-ing a key issue that needs to be addressed, their methods are essentially white-box methods. The attempt on black-box attack is via surrogate models, i.e. attack a classiﬁer in a white-box manner then use the results to attack the target classiﬁer. While white-box attack requires the full knowl-edge of the attacked model which is unlikely to be available in real-world scenarios, black-box attack via surrogate mod-els cannot guarantee success due to its heavy dependence on the choice of the surrogate model [51]. In this paper, we propose BASAR, the very ﬁrst black-box attack method on skeletal action recognition to our best knowledge.
A skeletal motion has unique features that distinguish itself from other data under adversarial attack. First, a skeleton usually has less than 100 Degrees of freedom (Dofs), much smaller than previously attacked data such as images/meshes. This low dimensionality leads to low-redundancy [46], restricting possible attacks within small subspaces. Second, imperceptibility is a prerequisite for any successful attack, but its evaluation on skeletal motions is under-explored. Different from the attack where visual im-perceptibility has high correlations mainly with the pertur-bation magnitude (e.g. images), a skeletal motion has dy-namics that are well-recognized by human perceptual sys-tems. More speciﬁcally, any sparse attack, e.g. on individ-ual joints or individual frames, albeit small would break the dynamics and therefore be easily perceptible. In contrast, coordinated attacks on all joints and frames can provide bet-ter imperceptibility even when perturbations are relatively large [50]. As a result, using the perturbation magnitude alone (as in most existing methods) is not a reliable metric for skeletal motion. Last but not least, prior methods mainly assume that adversarial samples are off the data manifold 7597
[18]. As we will show, skeletal motion is one real-world ex-ample where on-manifold adversarial samples not only ex-ist but are rather common. This raises a serious concern for human activity recognition solutions as these on-manifold adversarial samples are implementable.
Given a motion x with class label Cx, BASAR aims to ﬁnd x′ that is close to x (measured by some distance function) and can fool the black-boxed classiﬁer such that
Cx′ 6= Cx. BASAR formulates it as a constrained optimiza-tion problem, aiming to ﬁnd x′ that is just outside Cx while still on the data manifold. The optimization is highly non-linear due to the complexity of the classiﬁcation boundaries and the data manifold. The former dictates that any greedy search (e.g. gradient-based) near the boundaries will suffer from local minima; while the latter means that not all pertur-bation directions result in equal visual quality (in-manifold perturbation tends to be better than off-manifold perturba-tion). Consequently, there are often conﬂicts between these two spaces when searching for x′. To reconcile the con-ﬂicts, we propose a method called guided manifold walk (GMW). GMW consists of three sub-routines: aimed prob-ing, random exploration, and manifold projection. It starts from a random position (untargeted attack) outside Cx, or a random sample within a speciﬁc class (targeted attack with the speciﬁc class as the targeted class). It then can approach x by aimed probing attempting to ﬁnd a sample which is close to the boundary of Cx, or by random explorations to overcome local minima to ﬁnd samples that are closer to x, or by manifold projection to ﬁnd the closest point on the data manifold. The above sub-routines are iteratively exe-cuted driven by the quality of the adversarial sample until a satisfactory x′ is found or the maximum number of itera-tions is reached.
We extensively evaluate BASAR on several state-of-the-art methods using multiple datasets in both untargeted and targeted attack tasks. The results show that not only is
BASAR successful across models and datasets, it can also
ﬁnd on-manifold adversarial samples, in contrast to the common assumption that adversarial samples only exist off-manifold [18]. On par with very recent work that also found on-manifold samples in images [43], we show, for the ﬁrst time, the existence and commonality of such sam-ples in skeletal motions. We also comprehensively com-pare BASAR with other methods, showing the superiority of BASAR by large margins. Finally, since the perturbation magnitude alone is not enough to evaluate the attack quality, we conduct harsh perceptual studies to evaluate the natural-ness, deceitfulness, and indistinguishability of the attack.
Formally, we demonstrate that adversarial attack is truly a threat to skeleton-based activity recognition. To this end, we propose the ﬁrst black-box attack method and compre-hensively evaluate the vulnerability of several state-of-the-art activity recognition methods. We show the existence of on-manifold adversarial samples in various skeletal motion datasets and provide key insights on what classiﬁers tend to resist on-manifold adversarial samples. 2.