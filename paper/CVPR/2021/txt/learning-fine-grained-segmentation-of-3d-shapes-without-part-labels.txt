Abstract
Learning-based 3D shape segmentation is usually for-mulated as a semantic labeling problem, assuming that all parts of training shapes are annotated with a given set of tags. This assumption, however, is impractical for learn-ing ﬁne-grained segmentation. Although most off-the-shelf
CAD models are, by construction, composed of ﬁne-grained parts, they usually miss semantic tags and labeling those
ﬁne-grained parts is extremely tedious. We approach the problem with deep clustering, where the key idea is to learn part priors from a shape dataset with ﬁne-grained segmen-tation but no part labels. Given point sampled 3D shapes, we model the clustering priors of points with a similarity matrix and achieve part segmentation through minimizing a novel low rank loss. To handle highly densely sampled point sets, we adopt a divide-and-conquer strategy. We par-tition the large point set into a number of blocks. Each block is segmented using a deep-clustering-based part prior net-work trained in a category-agnostic manner. We then train a graph convolution network to merge the segments of all blocks to form the ﬁnal segmentation result. Our method is evaluated with a challenging benchmark of ﬁne-grained segmentation, showing state-of-the-art performance. 1.

Introduction 3D shape segmentation is a fundamental problem in 3D vision. While most existing works focus on semantic seg-mentation of 3D shapes into major parts (e.g., seat, back and leg of a chair), many application scenarios, on the other hand, demand ﬁne-grained shape segmentation. A deﬁnition of ﬁne-grained parts was given in [22]. In that work, ﬁne-grained parts are deﬁned in contrast with seman-tic parts. While semantic parts are major, functional ones (e.g., the back, seat and leg parts of a chair), ﬁne-grained parts mainly refer to modeling components which are, al-beit geometrically insigniﬁcant, conceptually meaningful in
*Corresponding author: kevin.kai.xu@gmail.com,zhoubin@buaa.edu.cn (a) (b)
Figure 1: Two examples of ﬁne-grained segmentation. For each example, the left is the input point cloud and the right is the ﬁne-grained segmentation result. the sense of assembly-based 3D modeling. Therefore, ﬁne-grained segmentation induces an intricate structural analy-sis of 3D objects, which facilitates part-based shape synthe-sis and modeling [13, 25] and meticulous robotic manipu-lation [1, 6]. Consequently, the problem receives increas-ing research attention lately [28, 23], along with dedicated datasets [14].
Previous learning-based approaches to ﬁne-grained 3D shape segmentation usually formulate it as a semantic la-beling problem. This requires a large training dataset of 3D shapes with ﬁne-grained part segmentation and tags.
When working with most online shape repositories such as
ShapeNet [3], ﬁne-grained part segmentation comes for free since most off-the-shelf CAD models are, by construction, composed of ﬁne-grained parts. These ﬁne-grained parts, however, have no, or noisy semantic tags. Annotating ﬁne-grained parts with semantic tags is extremely tedious due to the tiny part size and large part count (range from tens to hundreds; see [23] for statistics). Moreover, many ﬁne-grained parts may not even have a well-deﬁned tag. Due to these reasons, the existing ﬁne-grained part datasets [14] does leave many parts unlabeled.
In this paper, we introduce a deep clustering based ap-proach to ﬁne-grained part segmentation, thus avoiding the requirement of part labels. The key idea is to learn geomet-ric part priors describing what constitutes a ﬁne-grained part, based on a shape dataset with ﬁne-grained segmen-tation but no part labels. Working with point sampled 3D shapes, our method models the clustering priors of 3D points with a similarity matrix of point features capturing 10276
hand-crafted features towards speciﬁc tasks. These features often encode statistical properties of points and are designed to be invariant transformations, which can be categorized as local features [2, 20] and global features [18, 10, 7, 5]. For a speciﬁc task, it is not trivial to ﬁnd the optimal feature combination.
Recently many deep learning architectures have been de-veloped for point cloud data [19, 16, 9]. These methods demonstrate remarkable performance in part segmentation of object and scene segmentation. All these models, how-ever, ﬁnd difﬁcult in handling large point cloud.
In gen-eral, the point sets is down-sampled at ﬁrst, which is used as the input as the input of the neural network. However, after down-sampling, many ﬁne-grained parts are lost. To our knowledge, very few works have studied ﬁne-grained segmentation of point clouds. Mo et al. [14] collected a large-scale dataset with manually annotated ﬁne-grained se-mantic parts. They also proposed some baseline methods for ﬁne-grained segmentation of 3D point cloud. Luo et al. [12] introduced a data-driven iterative perceptual group-ing pipeline for the task of zero-shot 3D shape part discov-ery. Yu et al. [28] proposed a top-down recursive decom-position network for ﬁne-grained segmentation of 3D point cloud. However, their methods require well-deﬁned ﬁne-grained part semantic lables.
Low rank representation and loss. Low rank represen-tation is a robust and efﬁcient tool for processing high-dimensional data. This is because low rank representation has an excellent performance in discovering global struc-tures of data. The low-rank representation can reveal the re-lationships of the samples: the within-cluster afﬁnities are dense while the between-cluster afﬁnities are all zeros [11].
Low rank representation has been widely used in many ap-plications of image processing including image denoising
[24], face recognition [4], and classiﬁcation [29] in recent years.
Recently, Yi et al. [27] introduced a low rank loss based on deep learning for estimating detailed scene illumina-tion using human faces in a single image. The strategy based on the observation that the diffuse chromaticity over a face should be consistent among images, regardless of il-lumination changes, because a person’s facial surface fea-tures should remain the same. The diffuse chromaticity of multiple aligned images of the same face should form a low rank matrix (ideally rank one), so they deﬁne the low rank loss based on the second singular value. Similarly,
Zhu et al. [31] proposed a low-rank loss for 3D shape co-segmentation. The low-rank loss in AdaCoSeg measures the geometric similarity of the same semantic part across different shapes. The network is trained to minimize the rank; no actual low-rank decomposition is conducted. Our low-rank loss is fundamentally different from the one used 10277
Figure 2: Tiny parts demand high sampling rate for accurate
ﬁne-grained segmentation. for any two points how likely they belong to the same part.
This similarity matrix possesses low rank property with the rank equal to the number of ﬁne-grained parts of the shape.
Therefore, ﬁne-grained part segmentation can be achieved by minimizing a novel low rank loss over the similarity ma-trix.
Fine-grained parts are usually very tiny compared to the full shape (see Figure 2 (a)). A moderate sampling rate of 3D shapes can hardly capture the geometry of tiny parts ac-curately, which can result in suboptimal segmentation (see
Figure 2 (b)). Therefore, ﬁne-grained segmentation needs to work with densely sampled shapes. Existing deep learn-ing models for 3D point clouds, such as PointNet [15], usu-ally ﬁnd difﬁculty in handling very large point clouds. To this end, we adopt a divide-and-conquer strategy. We ﬁrst partition the large point set into a number of blocks. Each block is segmented using a deep-clustering-based part prior network, called PriorNet, which is trained in a category-agnostic manner. Beneﬁting from the block-wise training strategy, the required training shapes are greatly reduced.
We then train MergeNet, a graph convolution network, to merge the segments of all blocks to form the ﬁnal segmen-tation.
The main contributions of our paper include:
• a deep-clustering-based formulation for ﬁne-grained segmentation of 3D shapes which learns geometric part priors without relying on part annotations,
• a novel low-rank loss designed for learning ﬁne-grained part priors, and
• a novel graph convolution network based module trained to merge segments in different blocks. 2.