Abstract (a) Input image (b) Ground truth
The objective of this work is to segment high-resolution images without overloading GPU memory usage or losing the ﬁne details in the output segmentation map. The mem-ory constraint means that we must either downsample the big image or divide the image into local patches for sepa-rate processing. However, the former approach would lose the ﬁne details, while the latter can be ambiguous due to the lack of a global picture. In this work, we present Mag-Net, a multi-scale framework that resolves local ambigu-ity by looking at the image at multiple magniﬁcation levels.
MagNet has multiple processing stages, where each stage corresponds to a magniﬁcation level, and the output of one stage is fed into the next stage for coarse-to-ﬁne information propagation. Each stage analyzes the image at a higher resolution than the previous stage, recovering the previ-ously lost details due to the lossy downsampling step, and the segmentation output is progressively reﬁned through the processing stages. Experiments on three high-resolution datasets of urban views, aerial scenes, and medical images show that MagNet consistently outperforms the state-of-the-art methods by a signiﬁcant margin. Code is available at https://github.com/VinAIResearch/MagNet. 1.

Introduction
The current state-of-the-art (SOTA) semantic image seg-mentation techniques [1, 4, 16, 19, 21, 23, 26] are based on deep learning, where a convolutional neural network (CNN) takes an input image and outputs a segmentation map. Most of the existing techniques, however, assume that the entire segmentation process can be performed with a single feed-forward pass of the input image and the entire process can be ﬁtted into GPU memory. Unfortunately, most existing techniques cannot handle high-resolution input images due to memory and other computational constraints. One ap-proach to handle a large input image is to downsample it, but this results in a low-resolution segmentation map, which is not adequate for applications that require high-resolution (c) Downsampling (d) Patch processing (e) GLNet (f) DenseCRF (g) PointRend (h) MagNet (Proposed)
Figure 1: Comparing several semantic segmentation and re-ﬁnement approaches on a high-resolution input image. Down-sampling loses ﬁne details, while Patch Processing wrongly classi-ﬁes local patches due to the lack of the global context. The collab-orative global-local network GLNet fails due to the large discrep-ancy between the global and local branches. Post-processing and reﬁnement methods such as DenseCRF and PointRend can only correct small mistakes due to local inconsistency. MagNet outper-forms other methods, thanks to a novel multi-scale segmentation and reﬁnement framework. Best viewed in color. output with ﬁne details [12, 24], e.g., for tracking the pro-gression of malignant lesion [8]. Another approach to han-dle a large input image is to divide the image into small patches and process each patch independently. This ap-proach, however, does not take into account the global in-formation [22] that is needed to resolve ambiguity in local patches. The limitations of these two approaches are illus-trated in Fig. 1(c) & (d).
One way to address the limitations of the two aforemen-16755
tioned approaches is to combine them, i.e., to fuse global and local segmentation processes. On the one hand, the global view of the entire image can be used to resolve the ambiguity in the appearance of local patches. On the other hand, by analyzing local patches, we can reﬁne the seg-mentation boundaries and recover the lost details due to the downsampling procedure of the global segmentation pro-cess. This approach has been successfully demonstrated recently by the Global-Local Network (GLNet) [5]. How-ever, given an input image with ultra-high resolution, there is a huge gap between the scale of the whole image and the scale of the local patches. This will lead to contrasting output segmentation maps, and it will be difﬁcult to com-bine and reconcile differences with a single feed-forward processing stage (see Fig. 1e); the difﬁculty of this combi-nation task is analogous to constructing a single-span bridge across a wide river.
To bridge the gap between the two extreme ends of the scale space, we propose to consider multiple scales in be-tween. We introduce a novel multi-scale framework where the output segmentation map will be progressively reﬁned as the image is analyzed from the coarsest to the ﬁnest scale.
The core of our framework is a reﬁnement module that can use one segmentation map to reﬁne another. This reﬁne-ment module is used at every stage of our multi-scale pro-cessing pipeline to reﬁne the output segmentation map at its most uncertain locations. Our framework can integrate global contextual cues to produce more accurate segmenta-tion, and it can output high-resolution detailed segmentation maps under a memory constraint. Fig. 1 shows the result of
MagNet and compares it with other segmentation methods, including the recently proposed PointRend [14] method that seeks to reﬁne only at the most uncertain pixels. 2.