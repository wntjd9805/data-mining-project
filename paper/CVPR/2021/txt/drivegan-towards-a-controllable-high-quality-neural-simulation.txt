Abstract
Realistic simulators are critical for training and verify-ing robotics systems. While most of the contemporary simu-lators are hand-crafted, a scaleable way to build simulators is to use machine learning to learn how the environment be-haves in response to an action, directly from data. In this work, we aim to learn to simulate a dynamic environment directly in pixel-space, by watching unannotated sequences of frames and their associated actions. We introduce a novel high-quality neural simulator referred to as DriveGAN that achieves controllability by disentangling different compo-nents without supervision. In addition to steering controls, it also includes controls for sampling features of a scene, such as the weather as well as the location of non-player objects. Since DriveGAN is a fully differentiable simulator, it further allows for re-simulation of a given video sequence, offering an agent to drive through a recorded scene again, possibly taking different actions. We train DriveGAN on multiple datasets, including 160 hours of real-world driv-ing data. We showcase that our approach greatly surpasses the performance of previous data-driven simulators, and al-lows for new key features not explored before. 1.

Introduction
The ability to simulate is a key component of intelli-gence. Consider how animals make thousands of decisions each day. Some of the decisions are critical for survival, such as deciding to step away from an approaching car.
Mentally simulating the future given the current situation is key in planning successfully. In robotic applications such as autonomous driving, simulation is also a scaleable, ro-bust and safe way of testing self-driving vehicles in safety-critical scenarios before deploying them in the real world.
Simulation further allows for a fair comparison of different autonomous driving systems since one has control over the repeatability of the scenarios.
Desired properties of a good robotic simulator include accepting an action from an agent and generating a plausi-ble next world state, allowing for user control over the scene elements, and the ability to re-simulate an observed scenario
Content 
Control
Weather 
Control
Synthesize!
Driving Control
DriveGAN
Neural 
Simulator
Figure 1: We aim to learn a controllable neural simulator that can generate high-ﬁdelity real-world scenes. DriveGAN takes user controls (e.g. steering weel, speed) as input and renders the next screen. It allows users to control different aspects of the scene, such as weather and objects. with plausible variations. This is no easy feat as the world is incredibly rich in situations one can encounter. Most of the existing simulators [9, 41, 30, 46] are hand-designed in a game engine, which involves signiﬁcant effort in content creation, and designing complex behavior models to control non-player objects. Grand Theft Auto, one of the most re-alistic driving games to date, set in a virtual replica of Los
Angeles, took several years to create and involved hundreds of artists and engineers. In this paper, we advocate for data-driven simulation as a way to achieve scaleability.
Data-driven simulation has recently gained attention. Li-darSim [36] used a catalog of annotated 3D scenes to sam-ple layouts into which reconstructed objects obtained from a large number of recorded drives are placed, in the quest to achieve diversity for training and testing a LIDAR-based
[24, 8, 43], on the other hand, learn perception system. to synthesize road-scene 3D layouts directly from images without supervision. These works do not model the dynam-ics of the environment and object behaviors.
As a more daring alternative, recent works attempted to create neural simulators [27, 14] that learn to simulate the environment in response to the agent’s actions directly in pixel-space by digesting large amounts of video data along with actions. This line of work provides a scaleable way to simulation, as we do not rely on any human-provided an-notations, except for the agent’s actions which are cheap
It is also a more chal-to obtain from odometry sensors. 15820
lenging way, since the complexity of the world and the dy-namic agents acting inside it, needs to be learned in a high-resolution camera view. In this paper, we follow this route.
We introduce DriveGAN, a neural simulator that learns from sequences of video footage and associated actions taken by an ego-agent in an environment. DriveGAN lever-ages Variational-Auto Encoder [29] and Generative Adver-sarial Networks [13] to learn a latent space for images on which a dynamics engine learns the transitions within the latent space. The key aspects of DriveGAN are its disen-tangled latent space and high-resolution and high-ﬁdelity frame synthesis conditioned on the agent’s actions. The disentanglement property of DriveGAN gives users addi-tional control over the environment, such as changing the weather and locations of non-player objects. Furthermore, since DriveGAN is an end-to-end differentiable simulator, we are able to re-create the scenarios observed from real video footage allowing the agent to drive again through the recorded scene but taking different actions. This property makes DriveGAN the ﬁrst neural driving simulator of its kind. By learning on 160 hours of real driving data, we showcase DriveGAN to learn high-ﬁdelity simulation, sur-passing all existing neural simulators by a signiﬁcant mar-gin, and allowing for the control over the environment not possible previously. 2.