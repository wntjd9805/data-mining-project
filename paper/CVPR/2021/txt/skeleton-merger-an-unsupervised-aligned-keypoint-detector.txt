Abstract
Detecting aligned 3D keypoints is essential under many scenarios such as object tracking, shape retrieval and robotics. However, it is generally hard to prepare a high-quality dataset for all types of objects due to the ambiguity of keypoint itself. Meanwhile, current unsupervised detec-tors are unable to generate aligned keypoints with good cov-erage. In this paper, we propose an unsupervised aligned keypoint detector, Skeleton Merger, which utilizes skeletons to reconstruct objects. It is based on an Autoencoder archi-tecture. The encoder proposes keypoints and predicts acti-vation strengths of edges between keypoints. The decoder performs uniform sampling on the skeleton and reﬁnes it into small point clouds with pointwise offsets. Then the acti-vation strengths are applied and the sub-clouds are merged.
Composite Chamfer Distance (CCD) is proposed as a dis-tance between the input point cloud and the reconstruction composed of sub-clouds masked by activation strengths. We demonstrate that Skeleton Merger is capable of detecting semantically-rich salient keypoints with good alignment, and shows comparable performance to supervised methods on the KeypointNet dataset. It is also shown that the detec-tor is robust to noise and subsampling. Our code is avail-able at https://github.com/eliphatfs/SkeletonMerger. 1.

Introduction
Being able to fully understand an object is arguably the ultimate goal of computer vision. For 3D point clouds, de-tecting semantic keypoints is currently the most promising and widely adopted approach. [25, 21] Keypoints are cru-cial to the success of many vision applications such as ob-ject tracking, shape registration and in robotics [15, 24, 3, 5]. In many actual cases where objects from the same cate-gory are compared, we desire keypoints to be not only accu-rately located but also aligned within a certain category for
*Cewu Lu is corresponding author. He is the member of Qing Yuan
Research Institute and MoE Key Lab of Artiﬁcial Intelligence, AI Institute,
Shanghai Jiao Tong University, China. He is also the member of Shanghai
Qizhi Research Institute, China.
Figure 1. Examples of detected aligned keypoints and the cor-responding skeletons from our detector. Skeleton is shown in purple lines. Objects are from ModelNet40 [27] and ShapeNet-CoreV2 [4] datasets. performing high-level vision tasks such as 3D object recog-nition and reconstruction. [29]
However, to decide whether a point contains semantics requires high-level intelligence, as ‘semantics’ itself is am-biguously deﬁned. Different people would present different understandings of semantic points. Therefore, very limited human annotated quality data are available so far [31]. Con-sequently, supervised methods can only deal with very lim-ited range of objects covered in the datasets despite their success on many other tasks.
Most unsupervised methods, either traditional hand-crafted ones [19, 33] or deep learning-based [12], take ad-vantage of geometric properties to detect keypoints. While stable, these keypoints are often not rich in semantics, and the coverage of keypoints on the input point cloud is gener-ally low, especially under a small number of points, which limits their performance in downstream tasks. Moreover, the keypoints detected are neither ordered nor aligned. A very recent approach [8] can learn aligned 3D keypoints by decomposing keypoint coordinates into a low-rank non-rigid shape representation. However, in categories like the airplane where objects do not necessarily share highly simi-lar geometric shapes, its performance dramatically declines.
In view of the challenges above, we propose Skeleton 43
Figure 2. Describe objects with skeletons. (a) We observe that human vision can easily distinguish objects with skeletons, but it is harder with keypoints only. (b) Histogram of nearest neighbour distances of points in point clouds to its skeleton (red), large quan-tity of (3200) uniformly sampled points (green) in the bounding box and keypoints (blue).
Merger, an unsupervised keypoint detector that can extract salient and aligned keypoints. As its name suggests, Skele-ton Merger attempts to reconstruct a point cloud from its skeleton. Some examples of detected keypoints and the skeletons are shown in Fig. 1.
Utilizing skeleton to represent a point cloud is inspired by the skeleton extraction problem [6] in traditional graph-ics. We hold the belief that skeleton is a better presen-tation method than that adopted by current deep learning-based frameworks both intuitively and statistically. Qual-itatively speaking, we observe that human vision tends to use a ‘joint-skeleton’ cognitive pattern to recognize things, as is shown in Fig. 2 (a). While accurate and descriptive se-mantics is mostly provided by keypoints, with some discrete keypoints as joints alone, it is merely impossible for hu-man beings to recognize objects. However, if we introduce some auxiliary line segments connecting certain keypoints together to form a skeleton, humans can easily distinguish the object. Quantitatively speaking, statistical results in Fig. 2 (b) show that points of a point cloud are in general closer to those of a skeleton (red), compared with keypoints (blue) or uniform sampling inside the bounding box (green). This indicates skeleton can better ﬁt with local shape features of the original point cloud.
On implementation level, our Skeleton Merger follows a deep Autoencoder architecture. The encoder generates keypoint proposals. It also predicts activation strengths of edges between keypoints. The decoder generates a skele-ton from these results, which is essentially a graph of key-points. It performs uniform sampling on each edge, adds distinct activation strength and offset to reﬁne the shape.
In this way, each skeleton edge is essentially a small sub-cloud. The decoder ﬁnally merges them altogether to form a reconstruction point cloud. Noticing that the order of skele-ton edges is predeﬁned by the encoder, the alignment of keypoints is therefore considerably improved.
The crucial problem now becomes how to construct a loss function that can evaluate how well the reﬁned skele-ton reconstructs the original point cloud. Following the idea of traditional Chamfer loss [2], which is the sum of forward and backward losses, we come up with Composite Chamfer
Distance (CCD), which is the sum of ﬁdelity (forward) and coverage (backward) losses. CCD measures the distance between the input and the reconstructed point cloud com-posed of many sub-clouds masked by activation strengths.
Experimental results show that Skeleton Merger is ca-pable of detecting semantically-rich salient keypoints with good alignment. Our detector achieves signiﬁcantly bet-ter performance than current unsupervised detectors on the
KeypointNet [31] dataset. In fact, its performance is even comparable to supervised methods. Results also show that our detector is robust to noise and subsampling. 2.