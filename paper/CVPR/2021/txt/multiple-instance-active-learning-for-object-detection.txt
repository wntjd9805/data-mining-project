Abstract
Despite the substantial progress of active learning for image recognition, there still lacks an instance-level ac-tive learning method speciﬁed for object detection. In this paper, we propose Multiple Instance Active Object Detec-tion (MI-AOD), to select the most informative images for detector training by observing instance-level uncertainty.
MI-AOD deﬁnes an instance uncertainty learning module, which leverages the discrepancy of two adversarial in-stance classiﬁers trained on the labeled set to predict in-stance uncertainty of the unlabeled set. MI-AOD treats unlabeled images as instance bags and feature anchors in images as instances, and estimates the image uncertainty by re-weighting instances in a multiple instance learning (MIL) fashion. Iterative instance uncertainty learning and re-weighting facilitate suppressing noisy instances, toward bridging the gap between instance uncertainty and image-level uncertainty. Experiments validate that MI-AOD sets a solid baseline for instance-level active learning. On com-monly used object detection datasets, MI-AOD outperforms state-of-the-art methods with signiﬁcant margins, particu-larly when the labeled sets are small. Code is available at https://github.com/yuantn/MI-AOD. 1.

Introduction
The key idea of active learning is that a machine learn-ing algorithm can achieve better performance with fewer training samples if it is allowed to select which to learn.
Despite the rapid progress of the methods with less supervi-sion [21, 20], e.g., weak supervision and semi-supervision,
*Corresponding Authors.
Image 
Uncertainty
Mean 0.6
Mean
Image Uncertainty 0.4
Mean 0.5
Mean
Instance 
Uncertainty
.....
.....
Instances with Significant Uncertainty
Conventional Detector (a)
Image Uncertainty
Class Label “Dog” 0.7
Mean 0.8
Mean 0.9
Mean
Image 
Uncertainty
Mean
Re-weighting
Instance 
Uncertainty
.....
.....
Instances with Re-weighted Uncertainty
MI-AOD Detector (b)
Figure 1. Comparison of active object detection methods. (a) Con-ventional methods compute image uncertainty by simply averag-ing instance uncertainties, ignoring interference from a large num-ber of background instances. (b) Our MI-AOD leverages uncer-tainty re-weighting via multiple instance learning to ﬁlter out in-terfering instances while bridging the gap between instance uncer-tainty and image uncertainty. (Best viewed in color) active learning remains the cornerstone of many practical applications for its simplicity and higher performance.
In the computer vision area, active learning has been widely explored for image classiﬁcation (active image clas-siﬁcation) by empirically generalizing the model trained on the labeled set to the unlabeled set [9, 30, 18, 39, 4, 24, 36, 5330
25, 34]. Uncertainty-based methods deﬁne various metrics for selecting informative images and adapting trained mod-els to the unlabeled set [9]. Distribution-based approaches
[30, 1] aim at estimating the layout of unlabeled images to select samples of large diversity. Expected model change methods [8, 15] ﬁnd out samples that can cause the greatest change of model parameters or the largest loss [42].
Despite the substantial progress, there still lacks an instance-level active learning method speciﬁed for object detection (i.e., active object detection [42, 43, 2]), where the instance denotes the object proposal in an image. The objective goal of active object detection is to select the most informative images for detector training. However, the re-cent methods tackled it by simply summarizing/averaging instance/pixel uncertainty as image uncertainty and unfor-tunately ignored the large imbalance of negative instances in object detection, which causes signiﬁcant noisy instances in the background and interferes with the learning of image uncertainty, Fig. 1(a). The noisy instances also cause the in-consistency between image and instance uncertainty, which hinders selecting informative images.
In this paper, we propose a Multiple Instance Active
Object Detection (MI-AOD) approach, Fig. 1(b), and tar-get at selecting informative images from the unlabeled set by learning and re-weighting instance uncertainty with dis-crepancy learning and multiple instance learning (MIL).
To learn the instance-level uncertainty, MI-AOD ﬁrst de-ﬁnes an instance uncertainty learning (IUL) module, which leverages two adversarial instance classiﬁers plugged atop the detection network (e.g., a feature pyramid network) to learn the uncertainty of unlabeled instances. Maximizing the prediction discrepancy of two instance classiﬁers pre-dicts instance uncertainty while minimizing classiﬁers’ dis-crepancy drives learning features to reduce the distribution bias between the labeled and unlabeled instances.
To establish the relationship between instance uncer-tainty and image uncertainty, MI-AOD incorporates a MIL module, which is in parallel with the instance classiﬁers.
MIL treats each unlabeled image as an instance bag and performs instance uncertainty re-weighting (IUR) by evalu-ating instance appearance consistency across images. Dur-ing MIL, the instance uncertainty and image uncertainty are forced to be consistently driven by a classiﬁcation loss de-ﬁned on image class labels (or pseudo-labels). Optimizing the image-level classiﬁcation loss facilitates suppressing the noisy instances while highlighting truly representative ones.
Iterative instance uncertainty learning and instance uncer-tainty re-weighting bridge the gap between instance-level observation and image-level evaluation, towards selecting the most informative images for detector training.
The contributions of this paper include: (1) We propose Multiple Instance Active Object Detec-tion (MI-AOD), establishing a solid baseline to model the relationship between the instance uncertainty and image un-certainty for informative image selection. (2) We design instance uncertainty learning (IUL) and instance uncertainty re-weighting (IUR) modules, provid-ing effective approaches to highlight informative instances while ﬁltering out noisy ones in object detection. (3) We apply MI-AOD to object detection on commonly used datasets, improving state-of-the-art methods with sig-niﬁcant margins. 2.