Abstract
We introduce the concept of geometric stability to the problem of 6D object pose estimation and propose to learn pose inference based on geometrically stable patches ex-tracted from observed 3D point clouds. According to the theory of geometric stability analysis, a minimal set of three planar/cylindrical patches are geometrically stable and de-termine the full 6DoFs of the object pose. We train a deep neural network to regress 6D object pose based on geomet-rically stable patch groups via learning both intra-patch ge-ometric features and inter-patch contextual features. A sub-network is jointly trained to predict per-patch poses. This auxiliary task is a relaxation of the group pose prediction:
A single patch cannot determine the full 6DoFs but is able to improve pose accuracy in its corresponding DoFs. Work-ing with patch groups makes our method generalize well for random occlusion and unseen instances. The method is eas-ily amenable to resolve symmetry ambiguities. Our method achieves the state-of-the-art results on public benchmarks compared not only to depth-only but also to RGBD meth-ods. It also performs well in category-level pose estimation. 1.

Introduction
The problem of object pose estimation is to determine the 6D rigid transformation from the local object coordinate system to the camera reference frame. Robust and accurate object pose estimation is of primary importance in a vari-ety of applications ranging from robotic manipulation and localization to augmented reality. Recent advances either predict correspondences between observations and template models [36], or regress pose directly [49]. In these tasks,
RGB features learned with convolutional neural networks have been predominantly adopted with notable success [17].
Object pose inference with only color information, how-ever, ﬁnd difﬁculty in handling texture-less objects or un-seen surface texture/appearance. In human perception, ob-ject pose hinges on object geometry [42]. Humans cog-nize shapes and their poses simultaneously and in a cou-pled way [11] in order to achieve a so-called invariant object
*Joint ﬁrst authors
†Corresponding author: kevin.kai.xu@gmail.com (b) (c) (a) (d)
Figure 1: Given the 3D point cloud (b) of a detected object (a), StablePose is trained to predict its 6D pose based on a geometrically stable patch group containing the blue, the orange and the green patches. Each patch determines a few
DoFs and they altogether pin down all six DoFs (c, d). recognition [23]. Geometry enables a natural and powerful pose perception not only mitigating the distraction of color and appearance but also facilitating generalization to ran-dom occlusion and unseen instances. 3D geometric information does have been utilized for pose inference, both in traditional [9, 44] and in learning-based methods [52, 6], especially with the proliferation of depth cameras. The most straightforward use is to per-form ICP-based pose reﬁnement with the geometric infor-mation [40, 30]. Most deep learning approaches learn depth features to enhance color features [46]. Some others infer object poses from geometric features learned on 3D point clouds [12] or voxels [45]. These geometric features, how-ever, are learned without an explicit guidance on the correla-tion between shape and pose, making pose reasoning based on them lack of interpretability and weak in generality.
We propose to learn object pose inference based on 3D surface patches extracted from the point cloud of a single-In particular, we focus on planar and view depth image. cylindrical patches which are omnipresent on the surface of household objects. This design choice stems from two key insights. First, patches are neither too local to capture meaningful geometric information, nor too global to be re-peatable and generalizable across object instances. Second, each patch determines a speciﬁc set of DoFs of object pose.
A minimal set of geometrically stable patches can lock all six DoFs according to the theory of geometric stability (or slippage) analysis [13]. It is therefore possible to accurately reason about 6D object poses over a small group of geomet-rically stable patches (Figure 1). Each stable group usually 15222
contains up to three patches, which facilitates fast learning.
This also enables pose prediction with a redundant set of the stable groups, leading to robust pose estimation generaliz-ing under occlusion and to unseen objects.
We design StablePose, a deep neural network trained to regress 6D object pose based on geometrically stable patch groups. Given a patch-sample 3D point cloud, the network extracts both intra-patch geometric features and inter-patch contextual features.
It then predicts a 6D pose for each stable patch group through aggregating the intra- and inter-patch features. A dense point-to-point pose loss is used to train this network. A crucial design of StablePose is that a subnetwork is trained to predict per-patch poses. This aux-iliary task is a relaxation of the group pose prediction since a single patch cannot determine the full 6DoFs and thus the pose loss downgrades to a weaker point-to-patch loss. Im-posing such weak constraint for each patch in a stable group individually improves pose accuracy in the respective DoFs and altogether reinforces the group pose constraint, similar in spirit to the principle of geometrically stable ICP [14].
Given a 3D point cloud, we ﬁrst extract a set of geomet-rically stable patch groups via performing stability analysis.
We then use StablePose to predict a 6D pose for each sta-ble group. The ﬁnal object pose takes the average of all group poses weighted by group stability. To resolve am-biguities introduced by symmetries and achieve high pose accuracy, StablePose is trained to handle asymmetric ob-jects and objects with discrete and continuous symmetries separately. Through extensive evaluation, we show that Sta-blePose outperforms state-of-the-art learning-based meth-ods by 19.1% for depth-only input and 9.1% for RGBD input on the T-LESS benchmark [18]. Furthermore, our method generalizes well for category-level pose estima-tion, obtaining competitive results on the NOCS-REAL275 benchmark [48] and 18.6% improvement on a more chal-lenging ShapeNet based dataset. Our work makes the fol-lowing contributions:
• We, for the ﬁrst time, introduce the concept of geomet-ric stability into 6D object pose estimation.
• We propose a deep network learning to infer 6D object pose based on geometrically stable patch groups.
It attains high accuracy and robustness with a weak task of patch-wise, under-determined pose estimation.
• We devise several key designs to accommodate a broad range of cases encompassing asymmetric or symmetric objects, objects with occlusion and unseen objects. 2.