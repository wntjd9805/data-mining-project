Abstract
Most works on person re-identiﬁcation (ReID) take ad-vantage of large backbone networks such as ResNet, which are designed for image classiﬁcation instead of ReID, for feature extraction. However, these backbones may not be computationally efﬁcient or the most suitable architectures for ReID. In this work, we aim to design a lightweight and suitable network for ReID. We propose a novel search space called Combined Depth Space (CDS), based on which we search for an efﬁcient network architecture, which we call
CDNet, via a differentiable architecture search algorithm.
Through the use of the combined basic building blocks in
CDS, CDNet tends to focus on combined pattern informa-tion that is typically found in images of pedestrians. We then propose a low-cost search strategy named the Top-k
Sample Search strategy to make full use of the search space and avoid trapping in local optimal result. Furthermore, an effective Fine-grained Balance Neck (FBLNeck), which is removable at the inference time, is presented to balance the effects of triplet loss and softmax loss during the training process. Extensive experiments show that our CDNet (∼1.8
M parameters) has comparable performance with state-of-the-art lightweight networks. 1.

Introduction
Person re-identiﬁcation (ReID) aims to retrieve images of a speciﬁc person from different surveillance cameras.
Since AlexNet [15] was proposed in the ILSVRC-2012
[3], convolution neural networks (CNNs) have become in-creasingly popular. With the emergence of complex mod-els [32, 28, 6], people tend to utilize them as backbones to achieve higher performance on the ReID task. How-ever, there are two obvious drawbacks to such implemen-tations. First, they rely deeply on the performance of the
*Corresponding author
Figure 1. Note that paired salient objects of different sizes can be commonly found in pedestrian images. Our CBlock is designed to explicitly learn such combined patterns. backbone and limit researchers to explore more suitable network architectures for ReID. Second, these backbones require large computational resources and time costs at in-ference time, making them unaffordable for some practi-cal/edge devices with limited computing resources, such as
Instead, by deploying a intelligent surveillance cameras. lightweight network across a number of surveillance cam-eras, only the features these devices extract need to be gath-ered to retrieve the target person, which is much faster than gathering raw images and processing them with very large backbone networks. For these reasons, we aim to construct a lightweight network that is computationally efﬁcient and more suitable for ReID.
In recent years, Neural Architecture Search (NAS) has been utilized to search lightweight but effective networks.
[50] takes 2000 GPU days to search the NASNet via rein-forcement learning, which is far too long for most of re-searchers. To reduce the expensive search cost, [20] pro-poses a novel algorithm called differentiable architecture search (DARTS) using gradient descent, which dramati-cally reduces the search cost to 4 GPU days. Although the searched network architecture is very small, this method (1) The cell contains numer-still has a few drawbacks. ous complex connections, which are detrimental to parallel computing. [19] also notes that the irregular cell structures 6729
are not GPU friendly. (2) The algorithm only searches for normal and reduction cells and applies them to different lay-ers. We argue that CNNs tend to concentrate on different pattern information at different depths and thus need to dis-tinguish structures at different layers. (3) During the search, the algorithm computes each branch during forward prop-agation, even though the contributions of some branches with lower probabilities are negligible, resulting in heavy computational costs. As for the third drawback, [4] chooses to only compute the branch with the maximum weight be-tween two nodes for forward propagation. However, this method may easily become trapped in a single local optimal network architecture since the gradient is mainly updated in the selected branch and other possible branches are gradu-ally ignored; thus, the method cannot make full use of the search space. Apart from the above problems, we observe that most current search spaces are unable to explicitly learn combined pattern features for ReID (see Fig. 1), which are known to have very strong discriminative value.
To address the aforementioned problems and make full use of the advantages of NAS to search lightweight net-works, we propose a novel search space called Combined
Depth Space (CDS) and a new search strategy called the
Top-k Sample Search.
In CDS, we design an efﬁcient
Combined Block (CBlock) consisting of two independent branches with different kernel sizes for explicitly learning combined pattern information.
In this way, our CBlock only has two parallel branches and is thus GPU friendly.
Moreover, our Top-k Sample Search computes the top-k branches according to the weights during the forward prop-agation, avoiding the computation of negligible branches or becoming trapped in a single local optimal network archi-tecture, as is the case for [4]. In this way, we can not only largely reduce the search cost but also obtain a competi-tive lightweight network. Different from [20], we choose to search the cells for each layer independently.
In addition, we jointly optimize the softmax loss and triplet loss for training, as in many works [8, 22, 24]. Par-ticularly, we further propose a simple but effective Balance
Neck (BLNeck) to resolve the inconsistency between the targets of these two losses in the embedding space.
In
[22], although BNNeck is presented to balance the effects of these losses, it does not always work for arbitrary net-work architectures (as shown in Table 6). However, the proposed BLNeck has a strong ability to map an embed-ding space constrained by the triplet loss to one constrained by the softmax loss; thus, the two losses can be optimized harmoniously. The stripe strategy is always used for ex-tracting local features to guide the model to focus on more detailed information. We thus also integrate this idea into our Balance Neck, obtaining a new neck structure called the
Fine-grained Balance Neck (FBLNeck) to further improve the performance.
In summary, the contributions of this paper are summa-rized as follows:
• We propose a novel search space called Combined
Depth Space (CDS), in which the CBlocks explicitly learn combined pattern features and are more suitable for ReID.
• We propose a new search strategy called layer-wise
Top-k Sample Search, which can largely reduce the search cost over that of other search strategies and make full use of the search space.
• We propose a simple but effective Fine-grained Bal-ance Neck (FBLNeck) for balancing the effects of triplet loss and softmax loss to better leverage their ad-vantages.
The extensive experiments show that our CDNet achieves state-of-the-art performance on both ReID and other tasks among lightweight networks. 2.