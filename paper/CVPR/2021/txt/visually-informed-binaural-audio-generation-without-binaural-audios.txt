Abstract
Stereophonic audio, especially binaural audio, plays an essential role in immersive viewing environments. Recent research has explored generating visually guided stereo-phonic audios supervised by multi-channel audio collections.
However, due to the requirement of professional recording devices, existing datasets are limited in scale and variety, which impedes the generalization of supervised methods in real-world scenarios. In this work, we propose Pseu-doBinaural, an effective pipeline that is free of binaural recordings. The key insight is to carefully build pseudo visual-stereo pairs with mono data for training. Speciﬁ-cally, we leverage spherical harmonic decomposition and head-related impulse response (HRIR) to identify the rela-tionship between spatial locations and received binaural audios. Then in the visual modality, corresponding visual cues of the mono data are manually placed at sound source positions to form the pairs. Compared to fully-supervised paradigms, our binaural-recording-free pipeline shows great stability in cross-dataset evaluation and achieves compara-ble performance under subjective preference. Moreover, combined with binaural recordings, our method is able to further boost the performance of binaural audio generation under supervised settings1. 1.

Introduction
Auditory and visual experiences are implicitly but strongly connected. In immersive environments, the percep-tion of sound is impacted by visual scenes [44]. Therefore, researchers have explored ways to generate stereophonic audios with visual guidance, in order to improve the user experience in multimedia products. Speciﬁcally, supervised learning methods [22, 14, 20, 45] have been considered for this purpose.
*Equal contribution. 1Code, models and demo videos are available at https : / / sheldontsui.github.io/projects/PseudoBinaural.
However, it is noteworthy that fully-supervised learning methods, despite the positive results that they achieve under constrained settings, would face signiﬁcant difﬁculties in real-world applications. 1) They rely on videos associated with stereophonic recordings, which we refer to as “visual-stereo” pairs [22, 14]. Obtaining a high-quality collection of real stereo data requires complicated and professional record-ing systems (e.g. microphone arrays or dummy heads), thus is both resource-demanding and time-consuming. 2) The models trained on datasets collected under controlled envi-ronments may overﬁt to the layout of the rooms, rather than capturing the general associations between sound effects and the visual locations of the sound sources. The resultant models would also have poor generalization capability.
The privilege of learning representations from unlabeled data has been well discussed in different ﬁelds of deep learning [40, 18, 3, 23, 25]. This inspires us to explore an alternative approach, namely, to use only mono audios which can be acquired much more easily compared to bin-aural audios. We note that mono audios have been success-fully applied in learning visually informed sound separa-tion [9, 1, 13, 43, 42, 15]. Zhou et al. [45] recently leverage mono audios for stereo generation. However, their stereo-phonic learning procedure still depends on stereo data.
In this work, we propose PseudoBinaural, a novel pipeline that generates visually coherent binaural audios without accessing any recorded binaural data. Our key in-sight is to carefully build pseudo visual-stereo pairs from mono data. Two questions need to be identiﬁed in order to achieve our goal. Given a spatial location, 1) what is the relationship between a mono audio and its binaural counter-part sourcing from that location? 2) How should visual cues be organized to represent the source visually? Our solution is to utilize two mappings. A Mono-Binaural-Mapping to reproduce binaural audios of a single source positioned at any spatial location, and a Visual-Coordinate-Mapping that associates visual modality with spatial locations. Speciﬁ-cally, the Mono-Binaural-Mapping is achieved by adopting spherical harmonic decomposition [8]. A head-related im-pulse response (HRIR) [6] is then used to render binaural 15485
Figure 1: The pipeline of our method. Given one mono source, we create a pseudo visual-stereo pair { ˆV , (ˆl, ˆr)} by assigning the source direction ϑ = (ϑ, ϕ) in the spherical coordinates according to our manually created ˆV . Then mono source s(t) is converted to binaural channels (ˆl(t, ϑ), ˆr(t, ϑ)) through our Mono-Binaural-Mapping procedure by leveraging spherical harmonics decomposition. Within this pipeline, multiple sources can be linearly blended together to build training pairs. Then mono-to-binaural networks can be trained on the created pseudo data. audios from the zero- and ﬁrst-order terms of the decomposi-tion. As for the Visual-Coordinate-Mapping, we pre-deﬁne a correspondence between pixel coordinates and spherical co-ordinates, so that we can easily manipulate visual content to meet the designation of the corresponding source direction.
Existing models for visually informed binaural audio generation can be readily adapted to train on our pseudo visual-stereo pairs. In order to make the best use of mono data, we further propose a new way of leveraging the task of audio-visual source separation [43, 15] to assist the training.
The inference procedure is to simply apply the trained mod-els to videos with mono audios and generate corresponding binaural audios. Our framework renders stable performances on two datasets and in-the-wild scenarios. Moreover, we can mix our pseudo data with real stereophonic recordings to further boost the performance of binaural audio generation under the supervised setting.
Our contributions can be summarized as follows: 1) We identify the mapping between source directions and binaural audios with theoretical analysis. 2) By manipulating the visual modality, pseudo visual-stereo pairs can be generated for model training without relying on any recorded binaural data. 3) Extensive experiments validate the effectiveness and stability of our method on a variety of scenes. Moreover, our pseudo visual-stereo data can serve as a strong augmentation under the supervised setting. 2.