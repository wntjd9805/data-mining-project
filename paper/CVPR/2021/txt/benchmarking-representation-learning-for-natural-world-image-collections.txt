Abstract
Recent progress in self-supervised learning has resulted in models that are capable of extracting rich representations from image collections without requiring any explicit label supervision. However, to date the vast majority of these approaches have restricted themselves to training on stan-dard benchmark datasets such as ImageNet. We argue that
ﬁne-grained visual categorization problems, such as plant and animal species classiﬁcation, provide an informative testbed for self-supervised learning. In order to facilitate progress in this area we present two new natural world vi-sual classiﬁcation datasets, iNat2021 and NeWT. The for-mer consists of 2.7M images from 10k different species up-loaded by users of the citizen science application iNatural-ist. We designed the latter, NeWT, in collaboration with domain experts with the aim of benchmarking the perfor-mance of representation learning algorithms on a suite of challenging natural world binary classiﬁcation tasks that go beyond standard species classiﬁcation. These two new datasets allow us to explore questions related to large-scale representation and transfer learning in the context of ﬁne-grained categories. We provide a comprehensive analysis of feature extractors trained with and without supervision on ImageNet and iNat2021, shedding light on the strengths and weaknesses of different learned features across a di-verse set of tasks. We ﬁnd that features produced by stan-dard supervised methods still outperform those produced by self-supervised approaches such as SimCLR. However, im-proved self-supervised learning methods are constantly be-ing released and the iNat2021 and NeWT datasets are a valuable resource for tracking their progress. 1.

Introduction images
Learning representations of through self-supervision alone has seen impressive advancement over the last few years. There are tantalizing results that show self-supervised methods, ﬁne-tuned with 1% of the train-ing labels, reaching the performance of their fully super-vised counterparts [9]. In many domains, aggregating large
Standard Tasks
What species?
NeWT Tasks
Behavior?
Health?
Age?
...
Context?
Media Collection
Visual Question
Figure 1. Existing ﬁne-grained image datasets are typically fo-cused on a single task e.g. species identiﬁcation. As natural world media collections grow, we have the opportunity to extract in-formation beyond species labels to answer important ecological questions. For example, with the help of community scientists, re-searchers from the NHMLA were able to curate over 500 images of alligator lizards mating, a phenomenon seldomly recorded in the existing scientiﬁc literature [18]. We analyze if trained feature extractors can answer similar novel image understanding ques-tions with minimal additional training and present NeWT, a di-verse benchmark of natural world visual understanding tasks such as animal health, life-stage, behavior, among others. amounts of data is typically not the bottleneck. Rather, it is the subsequent labeling of that data that consumes vast amounts of money and time. This is further compounded in ﬁne-grained domains, e.g. medicine or the natural world, where sufﬁciently well trained annotators are few or their time is expensive. If the beneﬁts of self-supervised learn-ing come to full fruition, then the applicability and impact of computer vision models across many domains will see a rapid increase.
One particular domain that is well suited for this type of advancement is the study of the natural world through pho-tographs collected by communities of enthusiasts. Websites such as iNaturalist [1] and eBird [54] amass large collec-tions of media annually. To date, there are 60M images in iNaturalist spanning the tree of life and 25M images of birds from around the world in eBird, both representing point-in-time records of wildlife.
Identifying the species in an image has been well studied by the computer vision com-12884
munity [60, 32, 3, 58], however this is only the tip of the iceberg in terms of questions one may wish to answer us-ing these vast collections. These datasets contain evidence of the health and state of the individuals depicted, along with their behavior. Having an automated system mine this data for these types of properties could help scientists ﬁll in missing pieces of basic natural history information that are crucial for our understanding of global biodiversity and help measure the loss of biodiversity due to human impact [6].
To give one example, science is ignorant to the nest-ing requirements of thousands of bird species, including the vulnerable Pink-throated Brilliant (Heliodoxa gularis) [67].
Knowing how and where this species builds its nest is a cru-cial piece of information needed when discussing conser-vation based interventions, particularly as it pertains to the ability of this species to exist in degraded and fragmented habitats [67]. While nothing can replace the capabilities of a biologist in the ﬁeld, citizen science projects like eBird and iNaturalist are collecting raw images that could help answer some of these questions. However, herein lies the problem.
It is currently a daunting task to label training datasets for these specialized questions that would satisfy the data ap-petite of an off-the-shelf deep network.
Self-supervised learning is one potential solution that could alleviate the labeling burden by taking advantage of large media collections. While most research on self-supervised learning focuses on ImageNet [52], in this work we expand these techniques to the natural world domain and ﬁne-grained classiﬁcation. Following Goyal et al. [20], we maintain that a good representation should generalize to many different tasks, with limited supervision or ﬁne-tuning. We do not investigate self-supervised learning as an initialization scheme for a model that is further optimized and ﬁnetuned, but rather as a way to learn feature repre-sentations themselves. Importantly, [20] point out that self-supervised feature learning and subsequent feature evalua-tion on the same dataset does not test the generalization of the features. Inspired by this, we present a new large-scale pretraining dataset and new benchmark tasks speciﬁcally designed to enable us to ask questions about the general-ization of self-supervised learning on natural world image collections.
We make the following three contributions:
• iNat2021 - A new large-scale image dataset collected and annotated by community scientists that contains over 2.7M images from 10k different species.
• NeWT - A new suite of 164 challenging natural world visual benchmark tasks that are motivated by real world image understanding use cases.
• A detailed evaluation of self-supervised learning in the context of natural world image collections. We show that despite recent progress, self-supervised features still lag behind supervised variants. 2.