Abstract
Annotations in fully-supervised setting
Tracking segmentation masks of multiple instances has been intensively studied, but still faces two fundamental challenges: 1) the requirement of large-scale, frame-wise annotation, and 2) the complexity of two-stage approaches.
To resolve these challenges, we introduce a novel semi-supervised framework by learning instance tracking net-works with only a labeled image dataset and unlabeled video sequences. With an instance contrastive objective, we learn an embedding to discriminate each instance from the others. We show that even when only trained with im-ages, the learned feature representation is robust to instance appearance variations, and is thus able to track objects steadily across frames. We further enhance the tracking capability of the embedding by learning correspondence from unlabeled videos in a self-supervised manner. In ad-dition, we integrate this module into single-stage instance segmentation and pose estimation frameworks, which sig-niﬁcantly reduce the computational complexity of tracking compared to two-stage networks. We conduct experiments on the YouTube-VIS and PoseTrack datasets. Without any video annotation efforts, our proposed method can achieve comparable or even better performance than most fully-supervised methods1. 1.

Introduction
In recent years, the vision community has rapidly im-proved the performance of instance segmentation at both the image and video levels as a core technique in autonomous driving. The pipeline for segmenting instances from videos commonly includes: (i) segmentation on individual frame; and (ii) linking of each instance across frames for an en-tire video sequence. Most existing approaches [5, 8, 23, 43] employ fully-supervised learning that relies on dense anno-tations of instance segmentation masks and instance asso-∗ This work was done while Yang Fu was a research intern at NVIDIA
† corresponding author 1Project page: https://oasisyang.github.io/projects/ semi-track/index.html
…
…
… large-scale videos
Annotations in our setting
…
…
…
Labeled Images
Unlabeled Videos
Figure 1. The annotations required for our proposed approach vs. those for fully supervised approaches. ciations across video frames (see Fig. 1 top). Since anno-tation of videos, especially in a per-frame manner requires excessive labor, the fully-supervised learning setting, how-ever, becomes the major bottleneck for frame-wise video processing.
To reduce the dependence on labels, self-supervised tracking approaches have been developed to learn pixel-level video correspondences from large-scale unlabeled videos [17, 20, 39]. The learned correspondences can be used to track any ﬁne-grained attributes, e.g., segmen-tation masks, keypoints and textures, on a per-pixel ba-sis. However, such self-supervised approaches aim to learn semantically-independent representations, i.e., they do not discriminate between object instances. Such approaches can be used for tracking only when ground truth attributes are annotated at keyframes, e.g., the 1st frame of any se-quence [28]; or when additional pre-trained instance seg-mentation models are provided.
In this paper, we consider a novel semi-supervised set-ting: we learn to track instances only with a labeled image dataset, and optionally, unlabeled video sequences. In other words, in addition to learning image-level instance segmen-tation, we also learn to associate instances across frames in a self-supervised manner. Our setting strikes a balance 8680
between the fully-supervised and the self-supervised ones.
With regards to it applications, our model can be seam-lessly adapted and utilized for tracking objects on newly captured videos, e.g., trafﬁc scene sequences during au-tonomous driving, without requiring any ofﬂine processing.
A typical way to learn tracking is to model instance as-sociation as a multi-class classiﬁcation problem [43]. Since we do not have the ground truth association labels, we in-stead learn a feature map that should be: (i) discriminative of different instances, and (ii) robust to appearance varia-tion caused by motion of instances in videos. Once learned, any object instance can be tracked by utilizing its feature embedding to search for the most similar one in the next frame. To learn it with only labeled images, we introduce an Instance Contrastive (IC) objective deﬁned densely on the embedding map. This objective encourages the pixel-level feature embedding to be consistent when being sam-pled from the same instance, while being less consistent for different ones.
In addition, we optimize a Maximum
Entropy (ME) regularization to enforce that each instance, on being matched to others, exhibits a uniform distribution.
With this constraint, when a new object enters a sequence, the model can easily detect it by comparing it with all exist-ing instances , and thus assign it a new instance label.
In addition to using labeled images, we also discover when leveraging unlabeled videos, tracking performance can be further improved via self-supervised learning. In this work, we choose to learn self-supervised video correspon-dences. Speciﬁcally, we adopt a cycle-consistency loss by maximizing the likelihood of pixels returning to their orig-inal location on being propagated forward and backward along a stack of frames [17]. Since the feature embedding is utilized to construct the cross-frame afﬁnity for propaga-tion, it can be implicitly enhanced by enforcing this objec-tive.
Intuitively, video correspondence learning improves tracking performance by potentially encouraging the net-work to “see” more instance appearance variations in time.
To further mitigate the data distribution shifts between labeled images, unlabeled videos, and testing videos, we in-troduce a self-supervised test-time adaptation strategy. In-spired by [33], we enhance the model’s tracking capabil-ity by keeping the self-supervised objective at the inference stage, and adapting it to any particular input sequence.
Instead of learning an independent network that sepa-rately produces the feature embedding for tracking, we in-tegrate it as a head in to a bottom-up instance segmenta-tion framework, e.g., SOLO [40]. With labeled images, we jointly train the instance segmentation and the feature em-bedding parts of the network, enriching the original network with the new function of tracking. We note that in addition to introducing a semi-supervised setting, we are also pro-pose a bottom-up framework for tracking masks of multiple instances. Finally, we also show that similar approaches can be generalized to the task of multiple human pose tracking, when building on top of a bottom-up human pose estimation network [42]. In summary, we conclude our contribution as the following:
• A novel semi-supervised setting that can largely re-duce the effort of labelling large-scale video datasets.
• An Instance Contrastive loss equipped with Maximum
Entropy regularization to learn a feature embedding capable of tracking with only labeled images.
• A self-supervised video correspondence learning method that further improves tracking performance by leveraging unlabelled videos.
• Extensive experiments demonstrate that the proposed method performs on par if not better than most state-of-the-arts approaches, for both the video instance seg-mentation and pose tracking tasks. 2.