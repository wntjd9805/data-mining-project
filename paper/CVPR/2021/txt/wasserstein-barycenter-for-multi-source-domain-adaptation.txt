Abstract
Multi-source domain adaptation is a key technique that allows a model to be trained on data coming from various probability distribution. To overcome the challenges posed by this learning scenario, we propose a method for con-structing an intermediate domain between sources and tar-get domain, the Wasserstein Barycenter Transport (WBT).
This method relies on the barycenter on Wasserstein spaces for aggregating the source probability distributions. Once the sources have been aggregated, they are transported to the target domain using standard Optimal Transport for Do-main Adaptation framework. Additionally, we revisit previ-ous single-source domain adaptation tasks in the context of multi-source scenario.
In particular, we apply our al-gorithm to object and face recognition datasets. Moreover, to diversify the range of applications, we also examine the tasks of music genre recognition and music-speech discrim-ination. The experiments show that our method has similar performance with the existing state-of-the-art. 1.

Introduction
Standard data-driven algorithms are based upon the hy-pothesis that training and test data follows the same prob-ability distribution. When this assumption does not hold, a case also known as distributional shift, these algorithms may suffer from performance degradation.
In this case, many predictive models need to be re-trained on the new data, ignoring previous knowledge.
There are various examples of distributional shift such in areas of application of machine learning, as image [22][23][27], natural language [3][2], and speech [15][24] processing. This has been known in the literature as transfer learning.
Transfer learning may be further categorized accord-ing to the nature of distributional shift. First, the features distribution change between training and test sets, that is
Ps(X) 6= Pt(X). This case is commonly referred as do-main adaptation [17]. Additionally, the shift may also occur on the labels distribution Ps(Y ) 6= Pt(Y ), or in the condi-tional distribution Ps(Y |X) 6= Pt(Y |X). These cases are known respectively as target and conditional shift.
In this paper, a focus is given to unsupervised domain adaptation. Hence, we refer to training and test data as com-ing from different domains, respectively a source Ds and target domain Dt. According to [17], the goal of unsuper-vised domain adaptation is to help the learning of a predic-tive model on Dt, using knowledge learned in Ds, without using any labels in the target domain.
In addition, as ﬁrst remarked by [3], the distance be-tween probability distributions play an important role on the model’s performance on the target domain. This inspired various algorithms to explore statistical divergence mini-mization strategies for domain adaptation. In particular, as presented in the seminal works of [4], optimal transport can be used to do so.
Optimal transport is a mathematical theory that was orig-inally devised in the context of transportation of masses un-der least effort [26]. Since there is a natural association be-tween masses and probability distributions, optimal trans-port is suited for devising transformations that match dif-ferent distributions. This theory has two contributions to domain adaptation: the deﬁnition of a transport map T that matches Ps and Pt, and the deﬁnition of a notion of distance between distributions, the Wasserstein distance.
Among the contributions of optimal transport to domain adaptation, the Wasserstein distance is of particular interest in this work. Indeed, it metrizes the space of probability distributions, hence geometric concepts such as the idea of barycenters can be extended to this space [1]. This latter notion is particularly useful for the Multi-Source Domain
Adaptation (MSDA) setting.
The multi-source case in domain adaptation corresponds to when one has access to data coming from various do-mains {Dsk }N k=1. This case is challenging because one needs to minimize the distance from each Psk to Pt jointly.
In the following, we provide our contributions, the intuition for our algorithm, and the paper structure.
Contributions. Our contributions are twofold: (1) we pro-16785
pose a new method for MSDA, the Wassertein Barycenter
Transport (WBT). (2) A comparison with the state-of-the-art, revisiting datasets used for single-source domain adap-tation which can be adapted to the MSDA scenario. In par-ticular, the algorithms are evaluated on acoustic and visual adaptation datasets.
Intuition. We propose an algorithm for solving MSDA based on the Wasserstein barycenter. The intuition is to ag-gregate all source domains {Dsk }N k=1 into a single domain,
Db through the Wasserstein barycenter. Once the aggrega-tion step is done, standard domain adaptation may be em-ployed.
Paper structure. The rest of this paper is organized as fol-lows: section 2 presents the related work in the ﬁelds of domain adaptation, optimal transport, acoustic and visual recognition. Section 3 details the WBT algorithm. Sec-tion 4 details the numerical experiments and its results, as well as it discusses the ﬁndings. Finally, section 5 concludes the paper. 2.