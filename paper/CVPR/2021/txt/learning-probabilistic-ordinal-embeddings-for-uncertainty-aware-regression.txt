Abstract
Uncertainty is the only certainty there is. Modeling data uncertainty is essential for regression, especially in uncon-strained settings. Traditionally the direct regression formu-lation is considered and the uncertainty is modeled by mod-ifying the output space to a certain family of probabilistic distributions. On the other hand, classiﬁcation based re-gression and ranking based solutions are more popular in practice while the direct regression methods suffer from the limited performance. How to model the uncertainty within the present-day technologies for regression remains an open issue. In this paper, we propose to learn probabilistic ordi-nal embeddings which represent each data as a multivariate
Gaussian distribution rather than a deterministic point in the latent space. An ordinal distribution constraint is pro-posed to exploit the ordinal nature of regression. Our prob-abilistic ordinal embeddings can be integrated into popular regression approaches and empower them with the ability of uncertainty estimation. Experimental results show that our approach achieves competitive performance. Code is avail-able at https://github.com/Li-Wanhua/POEs. 1.

Introduction
Regression, as a fundamental machine learning problem, requires to predict a continuous target value y for a given data x. It is also extensively studied due to many important applications, such as age estimation [32, 43, 56], histori-cal image dating [37, 41], and image aesthetic assessmen-t [25, 29, 42]. Recent years have witnessed the enormous success [31, 33, 44] of Deep Neural Networks (DNNs).
Therefore, dominant approaches [27, 42, 56] for regression employ DNNs to leverage the powerful feature representa-tions. As the most natural choice for regression, the direct regression method predicts a scalar value y given an input
∗ Corresponding author
Figure 1. The key difference between deterministic unordered em-beddings and probabilistic ordinal embeddings. We consider the problem of age estimation and display age labels next to the im-ages. Deterministic unordered embeddings represent each facial image as a point in the latent space without considering the da-ta uncertainty and the ordinal property. By contrast, probabilistic ordinal embeddings learn a distribution following the ordinal con-straint in the embedding space. We see that the highly blurred image exhibits high uncertainty and the ordinal relations are pre-served with our probabilistic ordinal embeddings. x and the model is trained with L1 or L2 loss.
Modeling data uncertainty is quite important for regres-sion since it gives a clear probabilistic interpretation of the predictions. In fact, humans usually associate conﬁdence in their judgments. For example, if a person is required to estimate the age of a highly blurred facial image, he will give an estimation with high uncertainty. However, DNNs do not necessarily grasp the data uncertainty which cap-tures the noise inherent in the data [36]. Many recent work-s [12, 20, 36, 55] have been proposed to model the uncer-tainty, which consider the direct regression solutions and replace the point estimation with a probabilistic distribution p(y|x) in the output space. For simplicity, they usually con-sider a certain family of distributions, such as Gaussian or
Laplace, which naturally limits the expressiveness.
Meanwhile, many advanced methods [43, 57, 58] have been presented for regression, which signiﬁcantly surpass the direct regression approach. Some of the dominant ap-13896
proaches include classiﬁcation based methods [46, 47] and ranking based methods [5, 7, 38]. Classiﬁcation based method treats the regression problem as a multi-class clas-siﬁcation problem by discretizing the target space into C classes. Ranking based methods transform the regression problem into multiple binary classiﬁcation sub-problems, where each binary classiﬁer aims to predict whether the rank of a sample is larger than a speciﬁc value. Modeling data uncertainty within these popular regression methods is quite challenging. Unlike the direct regression method which outputs a scalar value, both classiﬁcation based re-gression and ranking based approaches have multiple neu-rons in the output layer. These neurons are highly corre-lated so it is difﬁcult to choose a suitable distribution to re-place them, which makes the above uncertainty-aware strat-egy unsuitable for these advanced regression methods.
To model the data uncertainty within the present-day re-gression methods, we propose Probabilistic Ordinal Em-beddings (POEs), which estimate a multivariate Gaussian distribution, instead of a ﬁxed point in the latent space.
Most existing methods represent each input data as a de-terministic point in the embedding space, i,e., z = fθ(x) is a point in RD, where z ∈ RD is the embedding, f is the mapping function and θ is the parameter of f . However, it is difﬁcult to give an accurate point embedding for noisy data, in which larger uncertainty should be exhibited in the em-bedding space [4, 51]. We consider modeling the data un-certainty in the embedding space and representing each em-bedding as a random variable: z ∼ p(z|x) ∈ RD. Mean-while, the ordinal relation in the target space should be pre-served in the embedding space since the uncertainty main-ly spreads the probability mass across neighbors. There-fore, an ordinal distribution constraint is further proposed to enforce the ordinal property. Figure 1 shows the key d-ifference between deterministic unordered embeddings and probabilistic ordinal embeddings.
In summary, the main contributions of our paper are threefold: (1) To model the data uncertainty of regression, we propose probabilistic ordinal embeddings, which repre-sent each data as a distribution following the ordinal con-straint in the latent space. (2) Our method empowers the present-day regression methods with the ability of uncer-tainty estimation. A per-exemplar uncertainty score can be used to measure the reliability of predictions. (3) Compre-hensive experiments illustrate that uncertainty modeling im-proves the performance and achieves very competitive per-formance on three real-world visual tasks. 2.