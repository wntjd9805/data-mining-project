Abstract (a) Near-Duplicate Retrieval
Detecting spliced images is one of the emerging chal-lenges in computer vision. Unlike prior methods that focus on detecting low-level artifacts generated during the ma-nipulation process, we use an image retrieval approach to tackle this problem. When given a spliced query image, our goal is to retrieve the original image from a database of authentic images. To achieve this goal, we propose rep-resenting an image by its constituent objects based on the intuition that the ﬁnest granularity of manipulations is of-tentimes at the object-level. We introduce a framework, ob-ject embeddings for spliced image retrieval (OE-SIR), that utilizes modern object detectors to localize object regions.
Each region is then embedded and collectively used to rep-resent the image. Further, we propose a student-teacher training paradigm for learning discriminative embeddings within object regions to avoid expensive multiple forward passes. Detailed analysis of the efﬁcacy of different feature embedding models is also provided in this study. Extensive experimental results show that the OE-SIR achieves state-of-the-art performance in spliced image retrieval.
Eiffel 
Tower (b) Instance Retrieval (c-1) Spliced Image Retrieval (c-2)
Figure 1. Three different types of image retrieval tasks. (a) The traditional image retrieval algorithm tries to retrieve near-duplicate images using low-level image statistics. (b) Instance retrieval tries to retrieve the same instance (e.g. building) under different view-point, illumination, and occlusion. (c) Spliced image retrieval (SIR) tries to retrieve authentic images used to create the spliced query image. Results from SIR contain images with large varia-tion, so it is difﬁcult to learn a single embedding that is suitable for the SIR task. 1.

Introduction
With the proliferation of social media platforms and the availability of user-friendly image editing software, adver-saries can now easily share spliced images on the Inter-net and reach millions of people with malicious intent to spread misinformation, disrupt democratic processes, and commit fraud. The ability to detect such spliced images is thus an increasingly important research area. Most ex-isting work learns a mapping function between a spliced image and its corresponding label map, where each pixel in the map denotes whether the pixel has been modiﬁed or not [6, 28, 59, 76]. However, such training strategies re-quire dense pixel-level annotations, which are expensive to obtain and thus prevent their abilities to scale. In this pa-*Work done during author was in Facebook AI. per, we formulate splicing detection as an image retrieval task: given a spliced query image and a large-scale image database, our goal is to retrieve images in the database that are authentic versions of the query image. We describe this as Spliced Image Retrieval (SIR) problem. Once the orig-inal images are retrieved, we can then localize the spliced regions in these images by comparing the query and the re-trieved images.
In contrast to traditional image retrieval which usually focuses on retrieving near-duplicate images or images con-taining speciﬁc instances, SIR focuses on retrieving au-thentic images that were used to create the query. Fig-ure 1 shows examples of near-duplicate retrieval, instance retrieval, and SIR. As shown in the ﬁgure, SIR faces a different set of challenges compared to near duplicate or instance retrieval task. First, the query image may con-14965
tain both manipulated as well as non-manipulated regions (cf. Figure 1 (c-1)). When comparing with images in the database, the query image should be region-speciﬁc rather than using the entire image as in many current image re-trieval systems [5, 21, 49, 22]. Secondly, retrieved images may not overlap and query expansion [12], a common prac-tice in this research area, does not apply. Using Figure 1 (c-1) as an example, if we were to use the ﬁrst image to do query expansion, we might retrieve more images of simi-lar lions and horses but we will not be able the retrieve the image of the cat running in the snow since two images do not share any overlapping content. Third, the query image and the authentic image might have extreme diverse back-grounds (cf. Figure 1 (c-2)), which may cause traditional image retrieval algorithms to fail.
To mitigate these issues, we take advantage of recent ad-vances in object detection [14, 53, 23] and propose Object
Embeddings for Spliced Image Retrieval (OE-SIR). Instead of using a single global representation, OE-SIR generates object-level representations per object region that is then collectively used to represent the image. By representing an image at object-level granularity, and assuming that image manipulations are frequently done by manipulating objects (e.g., faces, logos, etc.), we can extract similar object em-beddings from both spliced and authentic images, achieving the purpose of SIR.
Given detected objects, the next challenge lies in deriv-ing robust feature representations for the task of spliced im-age retrieval. It is appealing to directly use features from detection networks as such embeddings are trained with ad-ditional location information and it is computationally ef-ﬁcient with a single forward pass. However, while exten-sive studies have been conducted on image retrieval, most of them were focused only on embeddings provided by clas-siﬁcation networks [5, 1, 64, 4, 21, 72]. In light of this, we provide a detailed analysis of embeddings derived from dif-ferent pre-trained object detectors, and compare them with image classiﬁcation models. Our analysis shows that even though the object detection networks are trained with ad-ditional annotations, the resulting embeddings are signiﬁ-cantly worse than those from classiﬁcation models for im-age retrieval. This suggests a computationally expensive two-step process for SIR—detecting objects with object de-tectors and then encode them with pretrained classiﬁcation models.
We propose a student-teacher training regime to explore the best of both worlds for computational efﬁciency, i.e., re-liable bounding boxes produced by detectors and discrimi-native features computed with classiﬁcation models. This is achieved by training a lightweight student network on top of the detection model that projects feature maps of the detec-tion model into a more discriminative feature space guided by the teacher model. The student network decouples fea-ture learning from localization, preserving the discrimina-tive power of the features for classiﬁcation.
The contributions of this work include: (1) We introduce the task of spliced image retrieval and propose OE-SIR that derives object-level embeddings. (2) We provide a detailed analysis of embeddings extracted from different pre-trained models and show that embeddings extracted from object de-tection models are less discriminative than those from im-(3) We show that OE-SIR can age classiﬁcation models. outperform traditional image retrieval baseline and achieve signiﬁcantly better results with two SIR datasets. (4) OE-SIR demonstrates state-of-the-art performance in detecting spliced regions by utilizing the original image. 2.