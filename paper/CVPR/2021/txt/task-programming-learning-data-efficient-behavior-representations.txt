Abstract
Specialized domain knowledge is often necessary to ac-curately annotate training sets for in-depth analysis, but can be burdensome and time-consuming to acquire from do-main experts. This issue arises prominently in automated behavior analysis, in which agent movements or actions of interest are detected from video tracking data. To reduce annotation effort, we present TREBA: a method to learn annotation-sample efﬁcient trajectory embedding for be-havior analysis, based on multi-task self-supervised learn-ing. The tasks in our method can be efﬁciently engineered by domain experts through a process we call “task program-ming”, which uses programs to explicitly encode structured knowledge from domain experts. Total domain expert effort can be reduced by exchanging data annotation time for the construction of a small number of programmed tasks. We evaluate this trade-off using data from behavioral neuro-science, in which specialized domain knowledge is used to identify behaviors. We present experimental results in three datasets across two domains: mice and fruit ﬂies. Using embeddings from TREBA, we reduce annotation burden by up to a factor of 10 without compromising accuracy com-pared to state-of-the-art features. Our results thus suggest that task programming and self-supervision can be an ef-fective way to reduce annotation effort for domain experts. 1.

Introduction
Behavioral analysis of one or more agents is a core el-ement in diverse ﬁelds of research, including biology [36, 26], autonomous driving [6, 39], sports analytics [42, 43], and video games [20, 3]. In a typical experimental work-the location and pose of agents is ﬁrst extracted
ﬂow, from each frame of a behavior video, and then labels for experimenter-deﬁned behaviors of interest are applied on a frame-by-frame basis based on the pose and movements of the agents. In addition to reducing human effort, automated quantiﬁcation of behavior can lead to more objective, pre-Correspondence to jjsun@caltech.edu.
Figure 1. Overview of our approach. Part 1: A typical behavior study starts with extraction of tracking data from videos. We show 7 keypoints for each mouse, and draw the trajectory of the nose keypoint. Part 2: Domain experts can either do data annotation (Classiﬁer A) or task programming (Classiﬁer B) to reduce classi-ﬁer error. The middle panel shows annotated frames at 30Hz. Col-ors in the bottom plot represent interpolated performance based on classiﬁer error at the circular markers (full results in Section 4.3).
The size of the marker represents the error variance. cise, and scalable measurements compared to manual anno-tation [1, 10]. However, training behavior detection models can be data intensive and manual behavior annotation often requires specialized domain knowledge and high-frequency temporal labels. As a result, this process of generating train-ing datasets is time-consuming and effort-intensive for ex-perts. Therefore, methods to reduce annotation effort by domain experts are needed to accelerate behavioral studies.
We study alternative ways for domain experts to improve 2876
classiﬁer accuracy beyond simply increasing the sheer vol-ume of annotations. In particular, we propose a framework that uniﬁes: (1) self-supervised representation learning, and (2) encoding explicit structured knowledge on trajectory data using expert-deﬁned programs. Domain experts can construct these programs efﬁciently because keypoint tra-jectories in each frame are typically low dimensional, and experts can already hand-design effective features for tra-jectory data [36, 28]. To best leverage this structured ex-pert knowledge, we develop a framework to learn trajectory representations based on multi-task self-supervised learn-ing, which has not been well-explored for trajectory data.
Our Approach. Our framework, Trajectory Embedding for Behavior Analysis (TREBA), learns trajectory represen-tations through trajectory generation alongside a set of de-coder tasks based on expert-engineered programs. These programs are created by domain experts through a process we call task programming, inspired by the data program-ming paradigm [33]. Task programming is a process by which domain experts identify trajectory attributes relevant to the behaviors of interest under study, write programs, and apply those programs to inform representation learn-ing (Section 3.2). This ﬂexibility in decoder tasks allows our framework to be applicable to a variety of agents and behaviors studied across diverse ﬁelds of research.
Expert Effort Tradeoffs. Since task programming will typically require a domain expert’s time, we study the trade-off between doing task programming and data annotation.
We compare behavior classiﬁcation performance with dif-ferent amounts of annotated training data and programmed tasks. For example, for the domain illustrated in Figure 1, domain experts can reduce error by 13% relative to the base classiﬁer by annotating 701k additional frames, or they can reduce error by 16% by learning a representation using 10 programmed tasks in our framework. Our approach allows experts to trade a large number of annotations for a small number of programmed tasks.
We study our approach across two domains in behavioral neuroscience, namely mouse and ﬂy behavior. We chose this setting because it requires specialized domain knowl-edge for data annotation, and data efﬁciency is important for domain experts. Furthermore, decoder tasks in our frame-work can be efﬁciently programmed by experts based on simple functions describing trajectory attributes for identi-fying behaviors of interest. For example, for mouse social behaviors such as attack [36], important behavior attributes include the speed of each mouse and distance between mice.
The corresponding task could then be to decode these at-tributes from the learned representations.
Our contributions are:
• We introduce task programming as an efﬁcient way for domain experts to reduce annotation effort and encode structural knowledge. We develop a novel method to learn an annotation-sample efﬁcient trajectory repre-sentation using self-supervision and programmatic su-pervision.
• We study the effect of task programming, data annota-tion, and different decoder losses on behavior classiﬁer performance.
• We demonstrate these representations on three datasets in two domains, showing that our method can lead to a 10× annotation reduction for mice, and 2× for ﬂies. 2.