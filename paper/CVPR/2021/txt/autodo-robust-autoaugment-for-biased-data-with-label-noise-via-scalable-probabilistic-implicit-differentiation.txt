Abstract
AutoAugment [4] has sparked an interest in automated augmentation methods for deep learning models. These methods estimate image transformation policies for train data that improve generalization to test data. While re-cent papers evolved in the direction of decreasing policy search complexity, we show that those methods are not ro-bust when applied to biased and noisy data. To overcome these limitations, we reformulate AutoAugment as a gener-alized automated dataset optimization (AutoDO) task that minimizes the distribution shift between test data and dis-torted train dataset.
In our AutoDO model, we explic-itly estimate a set of per-point hyperparameters to ﬂexibly change distribution of train data. In particular, we include hyperparameters for augmentation, loss weights, and soft-labels that are jointly estimated using implicit differentia-tion. We develop a theoretical probabilistic interpretation of this framework using Fisher information and show that its complexity scales linearly with the dataset size. Our exper-iments on SVHN, CIFAR-10/100, and ImageNet classiﬁca-tion show up to 9.3% improvement for biased datasets with label noise compared to prior methods and, importantly, up to 36.6% gain for underrepresented SVHN classes1. 1.

Introduction
Data augmentation (DA) plays one of the key roles in improving accuracy of deep neural networks (DNNs) [14].
DA increases size and diversity of train dataset and con-sequently improves generalization to test data distribution.
Unfortunately, DA design requires expert domain knowl-edge, dataset analysis, and numerous costly experiments. In real applications with biased [31] and noisy-label data [39], the handpicking of DA becomes a challenging task. 1Our code is available at github.com/gudovskiy/autodo
Figure 1. Shared-policy DA dilemma: the distribution of aug-mented train data (dashed blue) may not match the test data (solid red) in the latent space: ”2” is under-augmented, while ”5” is over-augmented. As a result, prior methods cannot match the test distri-bution and the decision of the learned classiﬁer f (θ) is inaccurate.
The automation of DA aims to estimate data transfor-mation models without incurring the aforementioned dif-ﬁculties. The seminal AutoAugment [4] (AA) proposes a
DA policy model estimated by reinforcement learning (RL).
Though AA outperforms prior classiﬁcation baselines, its policy search takes thousands of GPU hours. Follow-up works [9, 16, 8] address the search complexity problem while keeping comparable accuracy results.
In this paper, we show that existing methods are not robust to train dataset distortions such as distribution bias and noisy labels. We attribute this to the policy model that shares parameters across all data points. We illustrate this with the toy classiﬁcation task in Figure 1. The distribu-tion of digits ”2” and ”5” in the train dataset (solid blue) is uneven and less diverse than test distribution (solid red) in the latent space before a linear classiﬁer. Then, the es-timated augmentation policies virtually increase train data size (dashed blue line). However, such DA model evenly in-creases diversity of all digits: digit ”2” is under-augmented, while digit ”5” is over-augmented. This pushes decision boundary of the linear classiﬁer in the wrong direction. A multi-class classiﬁer is even less robust [31], speciﬁcally, when it overﬁts to examples with noisy labels [39].
To overcome these limitations, we propose to estimate 16601
Figure 2. General setting: the validation dataset is selected to approximate the test data distribution Qtest x,y . The train dataset is subject to the speciﬁed data distortions and unknown DA hyperparameters. Unlike prior DA models with shared policies for all train data points, our
AutoDO model g(λ) estimates hyperparameters λi=1...N ∈ RK×1 for each of N train data points via implicit differentiation framework.
DA hyperparameters for each train data point. More-over, our model includes and jointly optimizes loss weights to capture data biases and soft-labels to address noisy la-bels. This reformulates the original AA shared-policy search task into a generalized automated dataset optimiza-tion (AutoDO). The objective of our AutoDO model is to match the distribution of a small clean unbiased validation dataset with a large distorted train dataset using a set of per-point hyperparameters as illustrated in Figure 2. We optimize our model with large-scale hyperparameters using implicit differentiation [21] and analytically show that it is equivalent to maximizing the Fisher information between empirical datasets. Experiments on class-imbalanced data with noisy labels show the advantages of our approach. 2.