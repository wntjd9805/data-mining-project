Abstract 1.

Introduction
We present ARCH, a computational pathology (CP) mul-tiple instance captioning dataset to facilitate dense supervi-sion of CP tasks. Existing CP datasets focus on narrow tasks; ARCH on the other hand contains dense diagnos-tic and morphological descriptions for a range of stains, tissue types and pathologies. Using intrinsic dimensional-ity estimation, we show that ARCH is the only CP dataset to (ARCH-)rival its computer vision analog MS-COCO
Captions. We conjecture that an encoder pre-trained on dense image captions learns transferable representations for most CP tasks. We support the conjecture with evidence that ARCH representation transfers to a variety of pathol-ogy sub-tasks better than ImageNet features or representa-tions obtained via self-supervised or multi-task learning on pathology images alone. We release our best model and in-vite other researchers to test it on their CP tasks.
The success of an intelligent system depends on hav-ing the right representation of data. Computer vision com-munity has gradually moved from engineering features to letting the deep neural networks learn data representations, given a differentiable task objective [1, 18].
Computational pathology (CP), a sub-ﬁeld of medical imaging that entails quantitative proﬁling of spatial patterns in multi-gigapixel whole-slide images (WSIs) of patient tis-sue slides, has followed these developments closely [10].
Deep Learning (DL) has been applied to detecting cancer-ous regions [34], classifying tissue sub-types [28], identi-fying diagnostically relevant structures such as glands [21], nuclei [17], vessels and nerves [15], quantifying spatial pat-terns of tumor inﬁltrating lymphocytes [53] and histology image retrieval [23]. More recently, DL been used to learn representations for challenging tasks of predicting genetic sub-types [16, 31].
With recent advances in weak and unsupervised learning, 16549
Figure 2: Five samples from ARCH. Top left: Caption describes morphological characteristics of Microsatellite Instabil-ity (MSI) in colon cancer; Top right: Caption provides contrastive supervision where cells in ﬁrst two images have to be contrasted against pigmented cells in the last two images; Bottom row: Captions provide morphological description of cell-division or mitosis at different stages. it is becoming widely acceptable to design computer vision systems from pre-trained representations [58, 19, 24, 29, 43, 20]. CP community has followed suit, by relying less on patch-level annotations and instead adopting weakly su-pervised methods such as multiple instance learning (MIL)
[6, 45, 26] or neural image compression (NIC) [57] to per-form inference directly from WSI-level data. However, most of the above methods rely on encoders pre-trained on
ImageNet for feature extraction.
These developments create a growing demand for pre-trained pathology image representations. In this paper, we present ARCH – a new dataset of dense image captions mined from clinical and academic pathology textbooks and articles – and demonstrate the universality of pathology im-age features obtained by pre-training on ARCH.
We conjecture that the global minimum of the multiple instance captioning objective on a dataset like ARCH is the global minimum of the majority of computational pathology sub-tasks commonly solved and published to date. We base this conjecture on several observations made while putting together this dataset and on experimental results reported in this work. In Figure 1, correctly captioning a bag of four im-age instances (left) requires an algorithm to: identify nuclei as well as their category (cyan) [17], describe nuclear char-acteristics (yellow) [40], detect mitotic ﬁgures (red) [9, 61] and even understand the relationship between image mag-niﬁcation and diagnosis (orange). Besides identifying cells and glands (all examples, cyan) [15, 21], an algorithm has to learn to describe an image as being metastatic tumour originating in colon (middle-top) or a metastatic sarcoma from papillary thyroid (middle-bottom). Only recently, Lu et al. [46] proposed a method for addressing the challenging task of identifying metastatic cancers and tumor origins. In
Figure 1 on the right, an algorithm has to identify the bag of four images as prostate and assign it a Gleason grade 4
[48, 3, 5]. The ARCH multiple instance captioning dataset stands out by offering implicit supervision of contrastive learning – where instances within the same bag have to be contrasted in order to generate the caption (Figure 2 top-right). ARCH includes samples that provide explicit su-pervision on genetic characteristics expressed through tis-sue morphology (Figure 2 top-left), a task that has only re-cently been explored [33, 31, 16]. One may also ﬁnd close up descriptions of mitosis at various stages (Figure 2 bot-tom row) [52]. We provide additional samples from ARCH in the Supplementary Material. We also present attention plots (see Figure 3) as additional evidence to support our conjecture and demonstrate examples at low and medium resolutions that are widely available in ARCH.
While ARCH includes unique CP tasks as sub-tasks to image captioning, we believe it is the relationship between the sub-tasks described in captions that provides unique su-pervision during pre-training and results in more general CP image features. In Section 3.2, we compare the intrinsic di-mensionality of CP datasets to their analogs in computer vision. CP datasets appear to have lower intrinsic dimen-sionality than CIFAR100 and CityScapes in their respec-tive tasks of image classiﬁcation and segmentation. ARCH, on the other hand, matches the complexity of its computer vision counterpart, the MS-COCO Captions dataset. Re-cently, Desai et al. [12] showed that pre-training on MS-COCO captions is superior to ImageNet. This might pro-vide a hint to why ARCH pre-training is advantageous to multi-task training. Individual CP tasks provide narrow su-16550
Figure 3: Left: samples of tissue at low and higher power view with their corresponding captions; Right: Model generated attention masks the corresponding words highlighted in bold. Attention masks were generated according to the methods described in Desai et al. [12], see Section 4.2 for details. pervision and even when combined together in a multi-task setting, the supervision signal does not explicitly model the relationship between the tasks.
Finally, besides offering a new computer vision task of multiple instance captioning, ARCH presents a previously unexplored path towards providing information rich ground truth for medical imaging, a ﬁeld known for its annotation scarcity. 2.