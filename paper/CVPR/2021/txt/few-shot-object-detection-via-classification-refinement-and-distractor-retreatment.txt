Abstract
We aim to tackle the challenging Few-Shot Object Detec-tion (FSOD), where data-scarce categories are presented during the model learning. The failure modes of Faster-RCNN in FSOD are investigated, and we ﬁnd that the per-formance degradation is mainly due to the classiﬁcation in-capability (false positives) caused by category confusion, which motivates us to address FSOD from a novel aspect of classiﬁcation reﬁnement. Speciﬁcally, we address the in-trinsic limitation from the aspects of both architectural en-hancement and hard-example mining. We introduce a novel few-shot classiﬁcation reﬁnement mechanism where a de-coupled Few-Shot Classiﬁcation Network (FSCN) is em-ployed to improve the ﬁnal classiﬁcation of a base detec-tor. Moreover, we especially probe a commonly-overlooked but destructive issue of FSOD, i.e., the presence of dis-tractor samples due to the incomplete annotations where images from the base set may contain novel-class objects but remain unlabelled. Retreatment solutions are developed to eliminate the incurred false positives. For FSCN train-ing, the distractor is formulated as a semi-supervised prob-lem, where a distractor utilization loss is proposed to make proper use of it for boosting the data-scarce classes, while a conﬁdence-guided dataset pruning (CGDP) technique is developed to facilitate the few-shot adaptation of base de-tector. Experiments demonstrate that our proposed frame-work achieves state-of-the-art FSOD performance on pub-lic datasets, e.g., Pascal VOC and MS-COCO. 1.

Introduction
Deep learning based object detection [13, 4, 2] have achieved remarkable performance outperforming traditional
*∗ indicates equal contribution (Yiting Li, Haiyue Zhu and Yu Cheng).
† indicates corresponding author: Haiyue Zhu.
Figure 1. FSOD performance gain by eliminating classiﬁcation false positives. approaches [24, 5]. However, deep learning detection relies on the availability of a large number of training samples.
In many practical applications such as robotics [22, 23], labeling a large amount of data is often time-consuming and labor-intensive. This paper focuses on a practically de-sired but rarely explored area, i.e., Few-Shot Object Detec-tion (FSOD). With the aid of data-abundant base classes, the object detector is trained to additionally detect novel classes through very limited samples. Existing approaches are mainly built on top of Faster-RCNN [13]. For example, the current state-of-the-art approach TFA [17] is presented that employs a classiﬁer rebalancing strategy for registering novel classes. During ﬁnetuning, the backbone pre-trained on the base set is reused and being frozen, while only the box classiﬁer and regressor are trained with novel data. De-spite its’ remarkable progress, its performance on challeng-ing benchmarks such as MS-COCO, is still far away from satisfaction compared with those general data-abundant de-tection tasks, which deserves more research efforts as data-efﬁciency is practically preferred in most real-world appli-cations.
To make a step towards the challenging FSOD task, it crucial to ﬁnd out the major cause of performance degrada-15395
tion in novel classes. Regarding the architecture of Faster-RCNN, its localization branch is typically class-agnostic with satisfactory performance. Thus our insight is to tackle the limitations of the classiﬁcation branch for FSOD in this work. Speciﬁcally, we evaluate TFA from two important as-pects on few-shot classes: 1) IOU awareness, i.e., robust-ness to hard negatives and 2) category discriminability, i.e., robustness to category confusion. Models that are weak in the ﬁrst aspect often predict poorly localized hard nega-tives as “conﬁdent” foregrounds of the same category, while those that are weak in the second aspect may suffer from classiﬁcation confusion between categories that share sim-ilar visual features or appear in similar contexts. Next, we analyze the potential performance gain by eliminating these two types of errors separately. For example, given the classi-ﬁcation of a poorly localized box (e.g., IOU=0.4) from cate-gory “dog”, the effect of the ﬁrst type false positives (object-ness error) can be eliminated by erasing the prediction score for its corresponding semantic category “dog”, while scores for other categories are preserved. To eliminate the second type false positives (confusion error), scores for all other categories except “dog” are erased. Results are shown in
Fig. 1. For the 10-shot case, eliminating the objectness error only provides 1.7 points performance gain in mAP, while eliminating the confusion error can dramatically boost the performance gain to 8.0 points, which indicates that classi-ﬁcation results of TFA is IOU-aware but less discriminative to confusable categories.
Maintaining IOU-awareness during ﬁnetuning is not su-pervising, as the objectness knowledge gained from a large dataset is usually universal and generalizable, thus can be reliably generalized into unseen novel classes as well. How-ever, lacking inter-class separability often leads to the is-sue of category confusion. We conjecture possible reasons from the following aspects of architectural limitation: The classiﬁcation branch of Faster-RCNN based detectors is not purposely designed for few-shot adaptation. For ex-ample, the shared feature representation for both classi-ﬁcation and localization is shown to be suboptimal for learning category discriminative representations since clas-siﬁcation requires translation-invariant features while lo-calization prefers translation-covariant features. Such mis-matched learning goals degrade the quality of category-speciﬁc translation invariance features [4], thus pose a tough challenge to learn discriminative classiﬁers when samples of novel classes are scarce.
In this work, we propose a uniﬁed approach for ad-dressing the above limitation. Given the fact that TFA is
IOU-aware but less semantic discriminative, our key insight is to enhance the original classiﬁcation results by inject-ing additional category-discriminative information. In this work, a novel Few-Shot Classiﬁcation Reﬁnement mech-anism is proposed to handle both objectness estimation
Figure 2. Some samples to show the co-occurrence of both base and novel classes in the same image according to the commonly used dataset setting for MS-COCO, “couch”, “person” and “bot-tle” are novel classes while the others are base classes. Due to in-complete annotations, those novel-class objects can be unlabelled in base set. and category discriminability simultaneously. Our frame-work consists of two branches, named as the “IOU-aware classiﬁcation branch” and the “discriminability enhance-ment branch”,which separately perform their efforts on es-timating objectness and alleviating category confusion, re-spectively. As the name suggests, the IOU-aware classiﬁca-tion branch is responsible for producing accurate IOU es-timation for each object proposal, which is implemented by the original TFA. At the same time, the enhancement branch is designed as a translation-invariant classiﬁer to produce category-discriminative classiﬁcation results. After that, outputs of these two complementary branches are ag-gregated together to produce less confused yet IOU-aware conﬁdence.
For exhaustively preserving the classiﬁcation-preferred translation-invariant features, we design the enhancement branch as a decoupled classiﬁer that does not share any pa-rameters with the base detector, where we call it a Few-Shot Correction Network (FSCN). It segments region pro-posal from image space and provides extra classiﬁcation reﬁnement to the base detector. Therefore, the classiﬁca-tion and localization tasks are decoupled in Faster-RCNN, which naturally solves the issue of shared feature represen-tation. To further improve the semantic discriminability of
FSCN, we train it by sampling misclassiﬁed false positives from TFA, so as to drive its focus towards the weakness of the base detector and enhance its capacity for eliminating category confusion.
Moreover, we focus on a unique but practically-existed problem of FSOD in this work, i.e., the presence of dis-tractor samples due to the incomplete annotations, where objects belonging to novel classes can exist in the base set but remain unlabelled. As shown in Fig. 2, such a situa-tion is quite realistic for most real-world applications, e.g., in autonomous driving, FSOD is to extend the detection for a novel object “scooter”. However, “scooter” may also ex-ist in the previous images for training the base classes with no annotations, so that such “scooter” distractors will be false emphasized as “background” continuously, which in-troduces destructive noise. Obviously, completely annotat-ing all novel objects requires to repeatedly review the whole 15396
dataset upon the arrival of each novel classes, which is against the motivation of FSOD that dramatically increases the annotation cost especially when the detection tasks are evolving frequently. Hence, “distractor” is deﬁned as those unlabelled novel-class objects in the base set, where pro-posals corresponding to those unlabelled novel objects are falsely supervised as negative examples. As a result, the positive gradients provided by the few-shot training sam-ples could be easily overwhelmed by the discouraging gra-dients produced by the distractors during the detector ﬁne-tuning, so that the resultant detector often inclines to predict novel classes with lower probabilities thus suffers catas-trophic performance degradation. To the best of our knowl-edge, such the distractor phenomenon has not been treated in existing FSOD works without any attention to address it properly.
In this work, we purposely tackle such distractor phe-nomenon by designing delicate retreatment approaches for both base detector and FSCN correspondingly. For the few-shot adaptation of base detector, a Conﬁdence-Guided
Dataset Pruning (CGDP) technique is proposed in this work, which utilizes the self-supervision to exclude the po-tential distractors to the greatest extent and form a cleaner and balanced training set for few-shot adaptation. More-over, to sample enough hard examples, the training of FSCN has to be performed on the whole dataset, which exists dis-tractors similarly. However, instead of eliminating the dis-tractors, we specially propose a distractor utilization loss to make proper use of those potential unlabelled novel-class objects in the base set through a semi-supervised manner.
In view of the data scarcity of the novel classes, such ex-tra samples help to improve the ﬁnal detection performance with zero additional annotation cost [15, 14]. Here, we sum-marize our main contributions as follow:
• We explore the limitations of the classiﬁer rebalanc-ing method (TFA) for FSOD problems and propose a novel few-shot classiﬁcation reﬁnement framework for exhaustively boosting its FSOD performance. A novel few-shot correction network is developed to achieve great semantic discriminability so as to eliminate false positives caused by category confusion.
• We are the ﬁrst to address the destructive distrac-tor issue for FSOD. Instead of blindly treating it, a conﬁdence-guided ﬁltering strategy is proposed to ex-clude the distractors for base detector ﬁne-tuning.
• A semi-supervised distractor utilization strategy is pro-posed to cooperate with FSCN, which not only sta-bilizes the training process but also signiﬁcantly pro-motes the learning on data-scarce novel classes with no extra annotation cost.
• Our proposed FSOD framework achieves the state-of-the-art results in various datasets with remarkable few-shot performance and knowledge retention ability. 2.