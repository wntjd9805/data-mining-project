Abstract
Image
Ground-truth IEM Result
Inpainted
Foreground
Inpainted
Background
We study image segmentation from an information-theoretic perspective, proposing a novel adversarial method that performs unsupervised segmentation by partitioning images into maximally independent sets. More speciﬁcally, we group image pixels into foreground and background, with the goal of minimizing predictability of one set from the other. An easily computed loss drives a greedy search pro-cess to maximize inpainting error over these partitions. Our method does not involve training deep networks, is com-putationally cheap, class-agnostic, and even applicable in isolation to a single unlabeled image. Experiments demon-strate that it achieves a new state-of-the-art in unsupervised segmentation quality, while being substantially faster and more general than competing approaches.1 1.

Introduction
Deep neural networks have signiﬁcantly advanced a wide range of computer vision capabilities, including image classiﬁcation [38, 55, 56, 27], object detection [22, 50, 40], and semantic segmentation [8, 73]. Nonetheless, neural net-works typically require massive amounts of manually la-beled training data to achieve state-of-the-art performance.
Applicability to problems in which labeled data is scarce or expensive to obtain often depends upon the ability to trans-fer learned representations from related domains.
These limitations have sparked exploration of self-supervised methods for representation learning, where an automatically-derived proxy task guides deep network training. Subsequent supervised ﬁne-tuning on a small la-beled dataset adapts the network to the actual task of inter-est. A common approach to deﬁning proxy tasks involves predicting one part of the data from another, e.g., geometric 1Code is available at https://github.com/lolemacs/iem
Figure 1. Illustration of our Inpainting Error Maximization (IEM) framework for completely unsupervised segmentation, applied to
ﬂowers, birds, and cars. Segmentation masks maximize the error of inpainting foreground given background and vice-versa. relationships [18, 45, 21], colorization [39], inpainting [49].
A recent series of advances focuses on learning representa-tions through a contrastive objective [6, 65, 59, 57], and ef-ﬁciency scaling such systems [25, 11, 24] to achieve parity with supervised pre-training.
Another class of approaches frames unsupervised learn-ing within a generative modeling context, building upon, e.g., generative adversarial networks (GANs) [23] or vari-ational autoencoders (VAEs) [36]. Donahue et al. [19, 20] formulate representation learning using a bidirectional
GAN. Deep InfoMax [16] drives unsupervised learning by maximizing mutual information between encoder inputs and outputs. InfoGAN [12], which adds a mutual informa-tion maximization objective to a GAN, demonstrates that deep networks can learn to perform image classiﬁcation without any supervision—at least for small-scale datasets.
Inspired by this latter result, we focus on the question of whether more complex tasks, such as image segmentation, 14029
can be solved in a purely unsupervised fashion, without re-liance on any labeled data for training or ﬁne-tuning. We address the classic task of generic, category-agnostic seg-mentation, which aims to partition any image into mean-ingful regions (e.g., foreground and background), without relying on knowledge of a predeﬁned set of object classes.
Here we introduce Inpainting Error Maximization (IEM) as an approach to unsupervised segmentation. This ap-proach is motivated by the intuition that a segmentation into objects minimizes the mutual information between the pix-els in the segments, and hence makes inpainting of one seg-ment given the others difﬁcult. This gives a natural adver-sarial objective where a segmenter tries to maxmize, while an inpainter tries to minimize, inpainting error. However, rather than adopt an adversarial training objective we ﬁnd it more effective to ﬁx a basic inpainter and directly maximize inpainting error through a form of gradient descent on the segmentation. Our version of IEM is learning-free and can be applied directly to any image in any domain. Figure 1 shows example results for foreground-background segmen-tation derived from our IEM method which is diagrammed in Figure 2.
We show that the segmentations produced by the learning-free IEM segmenter can be used as noisy training labels to train a deep segmentation network which further improves our segmentation quality. This bootstrapping does not utilize human generated labels and our system has no equivalent of ﬁne-tuning.
While IEM has a natural adversarial nature, we avoid employing a GAN. This contrasts with recent GAN-based unsupervised segmentation approaches, such as ReDO [10] and PerturbGAN [5], which Section 2 reviews in detail. Ex-periments in Section 4 demonstrate that our learning-free method matches or outperforms both. Our work advances unsupervised segmentation via the following contributions:
• An information-theoretic inspired IEM procedure for image segmentation which is fast, learning-free, and can be applied directly to any image in any domain.
• Extensive empirical results showing that our IEM pro-cedure performs competitively with prior work on un-supervised segmentation when measured in terms of intersection-over-union (IoU).
• An optional reﬁnement phase for IEM wherein a neu-ral segmentation network is trained on a subset of im-ages and their IEM segmentations and where the train-ing images are selected to be those having high IEM inpainting error. This network can then be incorpo-rated into the IEM process, resulting in a system that comfortably outperforms all competing methods.
Our results put dominant approaches to unsupervised
In comparison to IEM, gen-segmentation into question. erative modelling not only results in more computationally expensive methods, but also fails at learning high-quality segmentations. IEM provides a new combination of model-ing and learning, and perhaps a new direction for unsuper-vised methods. 2.