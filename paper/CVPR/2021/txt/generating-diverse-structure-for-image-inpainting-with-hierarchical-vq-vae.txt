Abstract
Given an incomplete image without additional con-straint, image inpainting natively allows for multiple solu-tions as long as they appear plausible. Recently, multiple-solution inpainting methods have been proposed and shown the potential of generating diverse results. However, these methods have difﬁculty in ensuring the quality of each so-lution, e.g. they produce distorted structure and/or blurry texture. We propose a two-stage model for diverse inpaint-ing, where the ﬁrst stage generates multiple coarse results each of which has a different structure, and the second stage reﬁnes each coarse result separately by augmenting texture.
The proposed model is inspired by the hierarchical vector quantized variational auto-encoder (VQ-VAE), whose hi-erarchical architecture disentangles structural and textural information.
In addition, the vector quantization in VQ-VAE enables autoregressive modeling of the discrete distri-bution over the structural information. Sampling from the distribution can easily generate diverse and high-quality structures, making up the ﬁrst stage of our model.
In the second stage, we propose a structural attention mod-ule inside the texture generation network, where the mod-ule utilizes the structural information to capture distant correlations. We further reuse the VQ-VAE to calculate two feature losses, which help improve structure coherence and texture realism, respectively. Experimental results on
CelebA-HQ, Places2, and ImageNet datasets show that our method not only enhances the diversity of the inpainting solutions but also improves the visual quality of the gen-erated multiple images. Code and models are available at: https://github.com/USTC- JialunPeng/
Diverse-Structure-Inpainting. 1.

Introduction
Image inpainting refers to the task of ﬁlling in the miss-ing region of an incomplete image so as to produce a com-plete and visually plausible image. Inpainting beneﬁts a se-*This work was supported by the Natural Science Foundation of China (Corresponding author: Dong under Grants 62036005 and 62022075.
Liu.)
Figure 1. (Top) Input incomplete image, where the missing region is depicted in gray. (Middle) Visualization of the generated diverse structures. (Bottom) Output images of our method. ries of applications including object removal, photo restora-tion, and transmission error concealment. As an ill-posed problem, inpainting raises a great challenge especially when the missing region is large and contains complex content.
As such, inpainting has attracted much research attention.
Recently, a series of deep learning-based methods are proposed for inpainting [10, 19]. They usually employ encoder-decoder architectures and train the networks with the combinations of reconstruction and adversarial losses.
To enhance the visual quality of the results, a number of studies [23, 26, 32, 34, 36] adopt the contextual attention mechanisms to use the available content for generating the missing content. Also, several studies [13, 33, 35] propose modiﬁed convolutions in replacement of normal convolu-tions to reduce the artifacts.
The aforementioned methods all learn a deterministic mapping from an incomplete image to a complete im-10775
age. However, in practice, the solution to inpainting is not unique. Without additional constraint, multiple inpainting results are equally/similarly plausible for an incomplete im-age, especially when the missing region is large and con-tains complex content (e.g. Figure 1). Moreover, for typi-cal applications, providing multiple inpainting results may enable the user to select from them according to his/her own preference. It then motivates the design for multiple-solution inpainting.
In contrast to single-solution methods, multiple-solution inpainting shall build a probabilistic model of the missing content conditioned on the available content. Several recent studies [38, 39] employ variational auto-encoder (VAE) ar-chitectures and train the networks with the combinations of
Kullback-Leibler (KL) divergences and adversarial losses.
VAE-based methods [38,39] assume a Gaussian distribution over continuous latent variables. Sampling from the Gaus-sian distribution presents diverse latent features and leads to diverse inpainted images. Although these methods can gen-erate multiple solutions, some of their solutions are of low quality due to distorted structures and/or blurry textures. It may be attributed to the limitation of the parametric (e.g.
Gaussian) distribution when we try to model the complex natural image content. In addition, recent studies more and more demonstrate the importance of structural information, e.g. segmentation maps [12, 27], edges [17, 30], and smooth images [14, 21], for guiding image inpainting. Such struc-tural information is yet to be incorporated into multiple-solution inpainting. Thus, VAE-based methods [38,39] tend to produce multiple results with limited structural diversity, which is called posterior collapse in [29].
In this paper we try to address the limitations of the ex-isting multiple-solution inpainting methods. First, instead of parametric distribution modeling of continuous variables, we resort to autoregressive modeling of discrete variables.
Second, we want to generate multiple structures in an ex-plicit fashion, and then base the inpainting upon the gen-erated structure. We ﬁnd that the hierarchical vector quan-tized VAE (VQ-VAE) [20] is suitable for our study1. First, there is a vector quantization step in VQ-VAE making the latent variables to be all discrete; as noted in [29], these dis-crete latent variables allow the usage of powerful decoders to avoid the posterior collapse. Second, the hierarchical lay-out encourages the split of the image information into global and local parts; with proper design, it may disentangle struc-tural features from textural features of an image.
Based on the hierarchical VQ-VAE, we propose a two-stage model for multiple-solution inpainting. The ﬁrst stage is known as diverse structure generator, where sam-pling from a conditional autoregressive distribution pro-1In this paper we use the basic model in [20], which is called VQ-VAE-2. Note that our method can use other hierarchical VQ-VAE models as well. duces multiple sets of structural features. The second stage is known as texture generator, where an encoder-decoder ar-chitecture is used to produce a complete image based on the guidance of a set of structural features. Note that each set of the generated structural features leads to a complete image (see Figure 1).
The main contributions we have made in this paper can be summarized as follows:
• We propose a multiple-solution image inpainting method based on hierarchical VQ-VAE. The method has two distinctions from previous multiple-solution methods: ﬁrst, the model learns an autoregressive dis-tribution over discrete latent variables; second, the model splits structural and textural features.
• We propose to learn a conditional autoregressive net-work for the distribution over structural features. The network manages to generate reasonable structures with high diversity.
• For texture generation we propose a structural atten-tion module to capture distant correlations of structural features. We also propose two new feature losses to improve structure coherence and texture realism.
• Extensive experiments on three benchmark datasets in-cluding CelebA-HQ, Places2, and ImageNet demon-strate the superiority of our proposed method in both quality and diversity. 2.