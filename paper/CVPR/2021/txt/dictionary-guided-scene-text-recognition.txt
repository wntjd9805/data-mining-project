Abstract
Language prior plays an important role in the way hu-mans detect and recognize text in the wild. Current scene text recognition methods do use lexicons to improve recog-nition performance, but their naive approach of casting the output into a dictionary word based purely on the edit dis-tance has many limitations. In this paper, we present a novel approach to incorporate a dictionary in both the training and inference stage of a scene text recognition system. We use the dictionary to generate a list of possible outcomes and ﬁnd the one that is most compatible with the visual ap-pearance of the text. The proposed method leads to a ro-bust scene text recognition model, which is better at han-dling ambiguous cases encountered in the wild, and im-proves the overall performance of state-of-the-art scene text spotting frameworks. Our work suggests that incorporating language prior is a potential approach to advance scene text detection and recognition methods. Besides, we con-tribute VinText, a challenging scene text dataset for Viet-namese, where some characters are equivocal in the vi-sual form due to accent symbols. This dataset will serve as a challenging benchmark for measuring the applicabil-ity and robustness of scene text detection and recognition algorithms. Code and dataset are available at https:
//github.com/VinAIResearch/dict-guided. 1.

Introduction
Scene text detection and recognition is an important re-search problem with a wide range of applications, from mapping and localization to robot navigation and accessibil-ity enhancement for the visually impaired. However, many text instances in the wild are inherently ambiguous due to artistic styles, weather degradation, or adverse illumination conditions. In many cases, the ambiguity cannot be resolved without reasoning about the language of the text.
In fact, one popular approach to improve the perfor-mance of a scene text recognition system is to use a dictio-nary and cast the predicted output as a word from the dic-tionary. The normal pipeline for processing an input image consists of: (1) detect text instances, (2) for each detected text instance, generate the most probable sequence of char-acters, based on local appearance of the text instance with-out a language model, and (3) ﬁnd the word in the dictionary that has smallest edit distance (also called Levenshtein dis-tance [14]) to the generated sequence of characters and use this word as the ﬁnal recognition output.
However, the above approach has three major problems.
First, many text instances are foreign or made-up words that are not in the dictionary so forcing the output to be a dictio-nary word will yield wrong outcomes in many cases. Sec-ond, there is no feedback loop in the above feed-forward processing pipeline; the language prior is not used in the second step for scoring and generating the most probable sequence of characters. Third, edit distance by itself is in-determinate and ineffective in many cases. It is unclear what to output when multiple dictionary words have the same edit distance to the intermediate output character sequence.
Moreover, many languages have special symbols that have different roles than the main characters of the alphabet, so the uniform treatment of the symbols and characters in edit distance is inappropriate.
In this paper, we address the problems of the current scene text recognition pipeline by introducing a novel ap-proach to incorporate a dictionary into the pipeline. Instead of forcing the predicted output to be a dictionary word, we use the dictionary to generate a list of candidates, which will subsequently be fed back into a scoring module to ﬁnd the output that is most compatible with the appearance feature.
One additional beneﬁt of our approach is that we can incor-porate the dictionary into the end-to-end training procedure, 7383
training the recognition module with hard examples. sequence of characters.
Empirically, we evaluate our method on several bench-mark datasets including TotalText [3], ICDAR2013 [10],
ICDAR2015 [11] and ﬁnd that our approach of using a dic-tionary yield beneﬁts in both training and inference stages.
We also demonstrate the beneﬁts of our approach for rec-ognizing non-English text. In particular, we show that our approach works well for Vietnamese, an Austroasiatic lan-guage based on Latin alphabet with additional accent sym-bols (´, `, ?, ., ˜) and derivative characters (ô, ê, â, ˘a, ơ, ư).
Being the native language of 90 million people in Vietnam and 4.5 million Vietnamese immigrants around the world,
Vietnamese texts appear in many scenes, so detecting and recognizing Vietnamese scene text is an important prob-lem on its own. Vietnamese script is also similar to other scripts such as Portuguese, so an effective transfer learn-ing technique for Vietnamese might be applicable to other languages as well. To this end, a contribution of our paper is the introduction of an annotated dataset for Vietnamese scene text, and our experiments on this dataset is a valuable demonstration for the beneﬁts of the proposed language in-corporation approach.
In summary, the contributions of our paper are twofold.
First, we propose a novel approach for incorporating a lan-guage model into scene text recognition. Second, we in-troduce a dataset for Vietnamese scene text with 2000 fully annotated images and 56K text instances. 2.