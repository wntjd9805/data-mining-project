Abstract
Humans can communicate emotions through a plethora of facial expressions, each with its own intensity, nuances and ambiguities. The generation of such variety by means of conditional GANs is limited to the expressions encoded in the used label system. These limitations are caused either due to burdensome labelling demand or the confounded la-bel space. On the other hand, learning from inexpensive and intuitive basic categorical emotion labels leads to lim-ited emotion variability. In this paper, we propose a novel
GAN-based framework that learns an expressive and inter-pretable conditional space (usable as a label space) of emo-tions, instead of conditioning on handcrafted labels. Our framework only uses the categorical labels of basic emo-tions to learn jointly the conditional space as well as emo-tion manipulation. Such learning can beneﬁt from the im-age variability within discrete labels, especially when the intrinsic labels reside beyond the discrete space of the de-ﬁned. Our experiments demonstrate the effectiveness of the proposed framework, by allowing us to control and gener-ate a gamut of complex and compound emotions while us-ing only the basic categorical emotion labels during train-ing. Our source code is available at https://github. com/stefanodapolito/GANmut. 1.

Introduction
Facial expressions undoubtedly play a major role in the non-verbal communication of human emotions. However, the relationship between what is felt and the correspond-ing expression is complex, and not yet fully understood.
When an emotion is externalized by facial muscle move-ments, sometimes even different emotions lead to the same expression [1, 11]. This is merely the beginning of the many issues in understanding human emotions. Therefore, mod-elling human emotions is a century-long ongoing topic of study [30, 28, 11, 31, 17, 16, 18, 29]. In this process, sev-eral psychological models for emotion representation have been proposed, with no clear consensus among psycholo-gists. At this point, one may wonder, what if we could leverage machine learning for emotion modelling instead?
Existing emotion models rely upon psychologists, who individually have limited observations and personal biases.
Machines, on the other hand, can potentially observe many more images of the diverse emotions. The key question that motivates us, maybe a little beyond the scope of this paper, is, how can we make machines model emotions in a way that is also interpretable to humans?
Before proceeding further, we ﬁrst discuss the current is-sues we perceive. If a categorical model, such as basic emo-tions [10, 20, 27], is used to understand the lab controlled posed expressions, there is almost no need for a new emo-tion model1. On the contrary, understanding spontaneous expressions challenges even the human experts2. One can only expect a further deterioration of agreement if sponta-neous expressions are annotated by non-experts. Therefore, it seems hopeless to collect large-scale data relying upon the categorical emotion model and its corresponding labels.
Several other emotion models also do exist [32]. Among these, the most commonly used are compound emotions [8],
Valance-Arousal (VA) [31], and Action Units (AUs) [9].
These models, although not thoroughly studied, can be only suspected to pose more problems due to not being intu-itive to non-experts. In this regard, the categorical emotion model is arguably the most intuitive one, as well as the most inexpensive means of collecting the data [3]. This leaves us with the necessity of developing a learning algorithm that can learn from imperfect emotion labels. With a slight twist, we ponder whether it is possible to learn the emotional la-bel space itself, which can be tractably (or with meaningful interpretation) mapped to the available imperfect labels.
A major source of confusion in labeling is the discretiza-tion of labels, while emotions themselves are continuous (basic emotions as a psychological model are outdated [1]).
Such discretization lacks two main aspects: intensity and fusion. For example, anger can be of different intensities, which may be expressed in sadness or fear [13]. More speciﬁcally, the hidden intensity and the intermediate emo-tions must be discovered to make the best use of the categor-1Recognition accuracy on constrained CK+ [21] datasets is ≈ 100%. 2AffectNet [22] reports an agreement of only 60.7% between experts. 568
speciﬁcally, conventional conditional GANs fail to do so, as they use classiﬁcation loss which encourages the generator to generate only easily recognizable emotions. In contrast, we introduce the learned labels of complex expressions and reproduce them. The major contributions of this paper are:
• We introduce the problem of learning conditional space for GANs, suitable for imperfect conditional la-bels. This problem is shown to be well suited for the task of emotion modelling and manipulation.
• A novel scheme for training conditional GANs, to search for condition interpretability, has been pro-posed. Our method enables us to generate a gamut of emotions, using only the categorical emotion labels.
• Our experiments on the benchmark dataset demon-strate the superiority of the proposed method, in terms of both qualitative and quantitative measures.
In fact, we also introduces an another conditional space, deﬁned as a mixture of Gaussians, where each mode rep-resents a basic emotion. This paper, however, will progress with the linear representation of basic emotions, for the sake of better readability. Once the linear model is well intro-duced and established, we shall proceed with the second approach. In the theoretical aspect, the Gaussian model dif-fers only in terms of parameterization. From the experimen-tal point of view, such modelling yields a better mixture (in some sense compound) of emotions [8]. 2.