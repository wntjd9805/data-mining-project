Abstract
Hyperbolic graph convolutional networks (GCNs) demonstrate powerful representation ability to model graphs with hierarchical structure. Existing hyperbolic
GCNs resort to tangent spaces to realize graph convolution on hyperbolic manifolds, which is inferior because tangent space is only a local approximation of a manifold. In this paper, we propose a hyperbolic-to-hyperbolic graph con-volutional network (H2H-GCN) that directly works on hy-perbolic manifolds. Speciﬁcally, we developed a manifold-preserving graph convolution that consists of a hyperbolic feature transformation and a hyperbolic neighborhood ag-gregation. The hyperbolic feature transformation works as linear transformation on hyperbolic manifolds. It ensures the transformed node representations still lie on the hy-perbolic manifold by imposing the orthogonal constraint on the transformation sub-matrix. The hyperbolic neigh-borhood aggregation updates each node representation via the Einstein midpoint. The H2H-GCN avoids the distor-tion caused by tangent space approximations and keeps the global hyperbolic structure. Extensive experiments show that the H2H-GCN achieves substantial improvements on the link prediction, node classiﬁcation, and graph classiﬁ-cation tasks. 1.

Introduction
Graph convolutional networks (GCNs) have attracted in-creasing attention for graph representation learning, where nodes in a graph are typically embedded into Euclidean spaces [25, 48, 46, 42, 20, 21]. Several works reveal that many graphs, such as social networks and citation networks, exhibit a highly hierarchical structure [11, 26, 32]. Re-cent studies have shown that hyperbolic spaces can well capture such hierarchical structure compared to Euclidean spaces [30, 31, 12]. Different from Euclidean spaces with zero curvature, hyperbolic spaces possess a constant neg-*Corresponding author (a) Existing hyperbolic GCNs. (b) The proposed H2H-GCN.
Figure 1. Comparisons of exisiting hyperbolic GCNs and the pro-posed H2H-GCN. At the ℓ-th layer, (a) existing hyperbolic GCNs performs Euclidean graph convolutional opeartions, e.g., feature transformation and neighborhood aggregation, in the tangent space
TxL that is a local approximation of the hyperbolic manifold L; (b) H2H-GCN directly performs a hyperbolic feature transforma-tion and a hyperbolic neighborhood aggregation on the hyperbolic manifold to learn node representations, keeping the global hyper-bolic structure. ative curvature, which allows for an exponential growth of space volume with radius. This property of hyperbolic spaces pretty meets the requirements of hierarchical data (e.g., trees) that need an exponential amount of space for branching, and encourages the development of GCNs in hy-perbolic spaces to capture the hierarchical structure under-lying graphs.
Existing hyperbolic GCNs [27, 10, 49] resort to tangent spaces to realize graph convolution in hyperbolic spaces.
Since the hyperbolic space is a Riemannian manifold rather than a vector space, basic operations (such as matrix-vector multiplication and vector addition) well deﬁned in Eu-154
clidean spaces are not applicable in hyperbolic space. To generalize graph convolution to the hyperbolic space, the works in [27, 10, 49] ﬁrst ﬂatten a hyperbolic manifold, and then apply Euclidean graph convolutional operations in the tangent space. The results are projected back to the hyper-bolic manifold. The procedures follow a manifold-tangent-manifold scheme, as shown in Figure 1(a). These meth-ods has promoted the development of GCNs in hyperbolic spaces and achieved good performance. However, the map-ping between the manifold and the tangent space is only locally diffeomorphic, which may distort the global struc-ture of the hyperbolic manifold, especially frequently using tangent space approximations [23, 39].
In this paper, we propose to design a hyperbolic GCN that directly works on the hyperbolic manifold to keep global hyperbolic structure, rather than relying on the tan-gent space. This requires that each step of graph convolu-tion, e.g., feature transformation and neighborhood aggre-gation, satisﬁes a manifold-to-manifold principle. To this end, we present a hyperbolic-to-hyperbolic graph convolu-tional network (H2H-GCN), where graph convolutional op-erations are directly conducted on the hyperbolic manifold.
Speciﬁcally, we developed a manifold-preserving graph convolution consisting of a hyperbolic feature transfor-mation and a hyperbolic neighborhood aggregation. The hyperbolic feature transformation plays the role of linear transformation on hyperbolic manifolds, which requires multiplication of node representations by a transformation matrix. We constrain the transformation matrix to be a block diagonal matrix composed of a scalar 1 and an or-thogonal matrix to ensure the transformed node representa-tions still reside on the hyperbolic manifold. For hyperbolic neighborhood aggregation, we adopt the Einstein midpoint as the weighted message of neighbor nodes to update a node representation. Figure 1(b) depicts that H2H-GCN directly carries out the two steps on hyperbolic manifolds. In con-trast to existing hyperbolic GCNs, the proposed H2H-GCN can avoid the distortion caused by tangent space approxi-mations and keep the global hyperbolic structure underly-ing graphs. We summarize the contributions of this paper as follows.
• We propose a hyperbolic-to-hyperbolic graph convo-lutional network that directly performs graph convolu-tion on hyperbolic manifolds, keeping the global hy-perbolic structure underlying graphs. To the best of our knowledge, this is the ﬁrst hyperbolic GCN with-out relying on tangent spaces.
• We developed a hyperbolic feature transformation that is a linear transformation on hyperbolic manifolds.
The manifold constraint on the transformed hyperbolic representations is ensured by imposing the orthogonal constraint on the transformation sub-matrix. 2.