Abstract
Rotation detection serves as a fundamental building block in many visual applications involving aerial im-age, scene text, and face etc. Differing from the domi-nant regression-based approaches for orientation estima-tion, this paper explores a relatively less-studied method-ology based on classiﬁcation. The hope is to inherently dismiss the boundary discontinuity issue as encountered by the regression-based detectors. We propose new tech-niques to push its frontier in two aspects: i) new encoding mechanism: the design of two Densely Coded Labels (DCL) for angle classiﬁcation, to replace the Sparsely Coded La-bel (SCL) in existing classiﬁcation-based detectors, leading to three times training speed increase as empirically ob-served across benchmarks, further with notable improve-ment in detection accuracy; ii) loss re-weighting: we pro-pose Angle Distance and Aspect Ratio Sensitive Weighting (ADARSW), which improves the detection accuracy espe-cially for square-like objects, by making DCL-based detec-tors sensitive to angular distance and object’s aspect ratio.
Extensive experiments and visual analysis on large-scale public datasets for aerial images i.e. DOTA, UCAS-AOD,
HRSC2016, as well as scene text dataset ICDAR2015 and
MLT, show the effectiveness of our approach. The source code is available at DCL and is also integrated in our open source rotation detection benchmark: RotationDetection. 1.

Introduction
Rotation detection has recently attracted increasing at-tention for their important utility across different scenarios, including aerial images, scene text, and faces etc., which is relatively less studied compared with the vast literature
∗Corresponding author is Junchi Yan. This work was partly sup-ported by National Key Research and Development Program of China (2018AAA0100704), NSFC (61972250, U20B2068 ), and Shanghai Mu-nicipal Science and Technology Major Project (2021SHZDZX0102). Xue
Yang is partly supported by Wu Wen Jun Honorary Doctoral Scholarship,
AI Institute, Shanghai Jiao Tong University. in horizental object detectors that do not estimate the exact rotation while only output the horizontal bounding box.
Many rotation detectors (including those for aerial im-age [46, 15, 47, 2, 6, 51, 45, 30, 48, 49, 50], scene text [56, 23, 14, 26, 19, 18] and face [34, 13, 33]) are derived based on the vanilla detection algorithms [10, 32, 31, 5, 20, 21].
Among them, the rotation detection algorithm based on ﬁve parameters ([x, y, h, w, θ]) dominates. Similar to the coor-dinate regression method in horizontal detection, angle pa-rameter is also predicted by regression. Although gratifying results have been achieved, there are still some fundamental
ﬂaws in the orientation estimation based on regression. An-gle prediction based on regression often introduces bound-ary discontinuity [51, 30, 48, 49], mainly including period-icity of angle (PoA) and exchangeability of edges (EoE).
The main reason for the former is the bounded periodic na-ture of the angle parameter, while the latter is related to the deﬁnition of the bounding box. In general, the root cause is that the ideal predictions are beyond the deﬁned range. Due to the sharp increase in the loss at the boundary, the regres-sion form of the model at the boundary and non-boundary can not be consistent. Therefore, the model has to pre-dict the angle in a more complicated form at the boundary, which increases the burden of the model and also increases the difﬁculty of prediction at the boundary. This is fatal for rotation detection with high precision, especially for objects with large aspect ratios.
Most existing works aim to eliminate the sudden loss in-crease by adding constraints on the loss function or chang-ing the way of calculation, such as IoU Smooth L1 Loss
[51] and Modulated Loss [30], as shown in Table 1. The ad-vantage is that they can borrow the well developed baselines from horizontal object detectors and reuse the related tech-niques to boost the detection performance. However, such ad-hoc techniques applied on the regression-based detectors cannot guarantee the full dismiss of boundary discontinu-ity behavior. To give a more elegant and effective solu-tion, the more recent work called Circular Smooth Label (CSL) [48, 49] argues to apply angle classiﬁcation instead of regression to address PoA. Then, CSL-based method 15819
Method
RetinaNet
RetinaNet
IoU-Smooth L1 Loss [51]
Modulated Loss [30]
CSL [48]
DCL (BCL)
Box Def.
Long-Side Def.
OpenCV Def.
OpenCV Def.
OpenCV Def.
Long-Side Def.
Long-Side Def.
Angle Pred.
Reg.
Reg.
Reg.
Reg.
Cls.: SCL
Cls.: DCL
PoA EoE SLP
X
X
X
X
X
×
×
×
×
×
×
×
X
×
×
×
×
×
Speed mAP50:95
-∼1x
∼1x
∼1x
∼ 1 3 x
∼1x 31.49 34.50 36.23 34.61 35.04 36.71
Table 1: Comparison between different solutions for peri-odicity of angle (PoA), exchangeability of edges (EoE) and square-like problem (SLP) on DOTA val set. The X indi-cates that the method suffers the corresponding problem. combines with the long-side deﬁnition (ﬁve-parameter with 180◦ angular range) of bounding box to further tackle the
EoE problem. The use of ‘CSL+180◦’ 1 leads to a natu-ral solution to get rid of the boundary discontinuity issue.
As angle classiﬁcation based detectors are still in its early stage, there are still many limitations e.g. very heavy pre-diction layer and difﬁculty in handling square-like objects.
The former problem is initially explored by the study [49].
This paper is one of the classiﬁcation-based endeavors in pushing forward this frontier, with two speciﬁc technical advancements as follows.
First, we adopt two Densely Coded Labels (DCL) in con-trast to the Sparsely Coded Label (SCL, including CSL,
One-Hot encoding), which has empirically led to notable training time reduction with meanwhile improved detec-tion accuracy. To make DCL as sensitive to angle dis-tance as CSL, we calculate the decimal difference between the predicted angle and the angle label as a angle distance aware weight. However, this weight will reintroduce the
PoA problem, and we ﬁnd that the long-side deﬁnition method is not conducive to the training of square-like ob-jects. Based on the ﬁndings of the above two issues, we de-sign Angle Distance and Aspect Ratio Sensitive Weighting (ADARSW), which eliminates the PoA and can be adap-tively adjusted according to the object’s aspect ratio, which can greatly reduce the burden of model training. Combing
‘DCL+180◦+ADARSW’ as a whole, extensive experiments and visual analysis on different datasets and detectors prove that DCL-based method can be a better baseline choice than the angle regression-based and CSL-based methods. Our work makes the following contributions: 1) To improve the robustness especially for objects with small aspect ratio, we propose Angle Distance and Aspect
Ratio Sensitive Weighting (ADARSW), which further im-proves accuracy by making our proposed DCL-based de-tector sensitive to angular distance and object’s aspect ratio.
In contrast, the existing CSL-based detector suffers from its long-side deﬁnition for detecting square-like objects. 2) We compare the impact of two classic Densely Coded
Labels (DCL) by introducing them to the angle classiﬁca-tion task for potential speedup, namely Binary Coded La-1Unless otherwise speciﬁed, the CSL-based method mentioned in this paper is based on the long-side deﬁnition method. (a) RetinaNet-Reg (b) RetinaNet-CSL (c) RetinaNet-BCL (d) RetinaNet-GCL
Figure 1: Comparison of four rotation detectors in the boundary case. Red bounding boxes indicate some bad de-tection cases (zoom in for better view). bel (BCL) and Gray Coded Label (GCL), which are more compact than existing CSL. Though GCL has been partly studied in [49], while this paper presents a more thorough investigation especially for BCL. We empirically show that
DCL, especially BCL can lead to notable training speed boost (about three times) as well as detection accuracy. 3) Extensive experiments and visual analysis on different datasets and detectors prove the efﬁcacy of our techniques.
It outperforms state-of-the-art CSL-based detector [48] by: 77.37% vs. 76.17% on DOTA dataset. 2.