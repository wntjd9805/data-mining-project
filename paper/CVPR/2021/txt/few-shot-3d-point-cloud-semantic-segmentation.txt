Abstract chair table
Many existing approaches for 3D point cloud semantic segmentation are fully supervised. These fully supervised approaches heavily rely on large amounts of labeled train-ing data that are difﬁcult to obtain and cannot segment new classes after training. To mitigate these limitations, we pro-pose a novel attention-aware multi-prototype transductive few-shot point cloud semantic segmentation method to seg-ment new classes given a few labeled examples. Speciﬁcally, each class is represented by multiple prototypes to model the complex data distribution of labeled points. Subsequently, we employ a transductive label propagation method to ex-ploit the afﬁnities between labeled multi-prototypes and unla-beled points, and among the unlabeled points. Furthermore, we design an attention-aware multi-level feature learning network to learn the discriminative features that capture the geometric dependencies and semantic correlations be-tween points. Our proposed method shows signiﬁcant and consistent improvements compared to baselines in differ-ent few-shot point cloud semantic segmentation settings (i.e. 2/3-way 1/5-shot) on two benchmark datasets. Our code is available at https://github.com/Na-Z/attMPTI. 1.

Introduction
Point cloud semantic segmentation is a fundamental com-puter vision problem, which aims to estimate the category of each point in the 3D point cloud representation of a scene.
The outcome of 3D semantic segmentation can beneﬁt var-ious real-world applications, including autonomous driv-ing, robotics, and augmented/virtual reality. However, point cloud semantic segmentation is a challenging task due to the unstructured and unordered characteristics of point clouds.
Recently, a number of fully supervised 3D semantic seg-mentation approaches [7, 8, 10, 11, 17, 24, 28, 31] have been proposed and have achieved promising performance on several benchmark datasets [1, 2]. Nonetheless, their success relies heavily on the availability of large amounts of labeled training data that are time-consuming and expensive to collect. Moreover, these approaches follow the closed set t e s t r o p p u
S
Few-shot 
Segmentor
Query point cloud
Segmentation result
Figure 1. Few-shot point cloud semantic segmentation task is to learn a segmentor that segments the query point cloud in terms of new classes with learned knowledge from the support examples.
This ﬁgure illustrates an example with 2-way 1-shot setting. assumption which states that the training and testing data are drawn from the same label space. However, the closed set assumption is not strictly adhered to the dynamic real world, where new classes can easily occur after training. As a result, these fully supervised approaches suffer from poor generalization to new classes with only few examples.
Although several existing works used self-[26], weakly-[6, 27] and semi-supervised [14] learning to mitigate the data hungry bottleneck in fully supervised 3D semantic seg-mentation, these approaches are still under the closed set assumption, where the generalization ability to new classes is overlooked. The increasingly popular few-shot learning is a promising direction that allows the model to generalize to new classes with only a few examples. In few-shot point cloud segmentation, our goal is to train a model to segment new classes given a few labeled point clouds, as illustrated in
Figure 1. We adopt the commonly used meta-learning strat-egy, i.e. episodic training [22], that learns over a distribution of similar few-shot tasks instead of only one target segmen-tation task. Each few-shot task consists of a few labeled samples (support set) and unlabeled samples (query set), and the model segments the query with learned knowledge from the support. Due to the consistency between the training few-shot task and the testing task, the model is endowed with better generalization ability that makes it less susceptible 8873  
to overﬁtting to rare support samples. Despite the beneﬁt of episodic training, few-shot point cloud segmentation still faces two major challenges on how to: 1) distill discrimina-tive knowledge from scarce support that can represent the distributions of novel classes; and 2) leverage this knowledge to effectively perform segmentation.
In this paper, we propose a novel attention-aware multi-prototype transductive inference method for few-shot point cloud semantic segmentation. Speciﬁcally, our approach is able to model the complex distributions of the points within the point clouds of the support set, and perform the seg-mentation via transductive inference with the discriminative features extracted under the few-shot constraint. We are mo-tivated by the prototypical network [21], which represents each class with a single prototype obtained from averaging the embeddings of labeled samples in the support. We pos-tulate that such uni-modal distribution assumption can be violated in point cloud segmentation due to the complex data distribution of points. In particular, the geometric structures of the points can vary largely within the same semantic class.
Consequently, we propose to represent each class with mul-tiple prototypes to better capture the complex distribution.
Furthermore, it is important to learn discriminative features for the few-shot 3D point cloud semantic segmentation set-ting. To this end, we meticulously design an attention-aware multi-level feature learning network to learn the point-wise features by capturing the geometric dependencies and se-mantic correlations between the points. Subsequently, we perform the segmentation step in a transductive manner with
In the multiple prototypes in the learned feature space. contrast to the conventional prototypical network [21] that matches unlabeled instances with the class prototypes by computing their Euclidean distances, our transductive in-ference not only considers the relationships between the unlabeled query points and the multi-prototypes, but also exploits the relationships among the unlabeled query points.
The main contributions of this work are: 1) We are the
ﬁrst to study the promising few-shot 3D point cloud seman-tic segmentation task, which allows a model to segment new classes given a few or even one example(s). 2) We propose a novel attention-aware multi-prototype transduc-tive inference method. Our designs of the attention-aware multi-level feature learning, and the afﬁnity exploitation be-tween multi-prototypes and unlabeled query points enable our model to obtain highly discriminative features and ac-complish more precise segmentation in the few-shot scenario. 3) We conduct comprehensive experiments on the S3DIS and
ScanNet datasets to demonstrate the superior performance of the proposed approach over baselines in different (i.e. 2-/3-way 1-/5-shot) few-shot point cloud segmentation settings.
Speciﬁcally, our method improves over the ﬁne-tuning base-line in the challenging 3-way 1-shot setting by 52% and 53% on the S3DIS and ScanNet dataset, respectively. 2.