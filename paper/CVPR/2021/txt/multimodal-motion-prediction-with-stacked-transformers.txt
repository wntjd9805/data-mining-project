Abstract
Predicting multiple plausible future trajectories of the nearby vehicles is crucial for the safety of autonomous driving. Recent motion prediction approaches attempt to achieve such multimodal motion prediction by implicitly regularizing the feature or explicitly generating multiple candidate proposals. However, it remains challenging since the latent features may concentrate on the most frequent mode of the data while the proposal-based methods depend largely on the prior knowledge to generate and select the
In this work, we propose a novel transformer proposals. framework for multimodal motion prediction, termed as mmTransformer. A novel network architecture based on stacked transformers is designed to model the multimodal-ity at feature level with a set of ﬁxed independent propos-als. A region-based training strategy is then developed to induce the multimodality of the generated proposals. Ex-periments on Argoverse dataset show that the proposed model achieves the state-of-the-art performance on mo-tion prediction, substantially improving the diversity and the accuracy of the predicted trajectories. Demo video and code are available at https://decisionforce. github.io/mmTransformer. 1.

Introduction
Predicting the future trajectories of nearby vehicles is critical for the Autonomous Vehicle systems to understand the surrounding and make informative decisions. Multi-modal prediction, which aims to generate multiple plausible trajectories of the target vehicle, plays a key role to handle the uncertainty in motion prediction and improve the safety of motion planning. Due to the uncertain future events, traf-ﬁc vehicles could perform differently even under the same scene. However, there is only one ground truth trajectory collected in each driving scene. Hence one challenge for
⋆ Co-ﬁrst authors with equal contributions.
Figure 1. Examples of multimodal motion prediction in complex driving scenarios. For each moving vehicle near the ego car, three plausible future trajectories are predicted by the proposed model. enabling multimodal prediction lies in how to learn to cover all the possible outcomes in a given scene with limited train-ing samples.
Recent motion prediction methods mainly follow prob-abilistic approaches [19, 16, 28] or proposal-based ap-proaches [33, 26, 5, 11] to address the aforementioned is-sue. The probabilistic approaches implicitly model the un-certainty of the trajectory through deﬁning the underlying possible models as a latent variable. They either achieve the multimodal prediction with generator conditioned on differ-ent latent variables, or directly constrain the output over a probability distribution(e.g., GMM) to get diverse results.
These methods depend heavily on the predeﬁned prior dis-tribution and the well-designed loss function, which might be prone to the optimization instability and the mode col-lapse issue. Unlike probabilistic approaches which gen-erate multimodal outputs through modeling the latent dis-tribution of the modality, the proposal-based approaches
[11, 33, 5, 25] perform in an alternative way, which ﬁrst de-ﬁnes candidate points or trajectories as proposals, and then regress or classify these proposals to the ground truth. With predeﬁned proposals, these methods alleviate optimization burden and narrow down the feasible space of solutions. Al-though these methods achieve good performance, they still have the following two issues: 1) The result relies heavily on the quality of the predeﬁned anchors since the heuristic methods are applied to sample the candidate points. 2) The 17577
multimodal prediction can not be guaranteed since multi-modal nature of trajectory prediction is not well captured with only one ground truth provided during the training.
In this work, we propose a novel end-to-end multimodal motion prediction framework called MultiModal Trans-former (mmTransformer), where the proposals are ﬁrst randomly initialized and then reﬁned to incorporate con-textual information. mmTransformer is designed based on the transformer architecture, which proves to be effective in modeling sequential data. The whole model can be viewed as stacked transformers in which the past trajec-tories, the road information, and the social interaction are aggregated hierarchically with several transformer encoder-decoder modules. Two multimodal prediction examples of the whole trafﬁc scenes are shown in Fig 1.
We develop two new mechanisms to ameliorate the uni-modal effects brought by identical features. First, we in-troduce a trajectory proposal mechanism to the ﬁeld of mo-tion prediction. Speciﬁcally, queries in the decoders of mm-Transformer are represented as trajectory proposals, which asymptotically aggregate multiple channels of contextual information from encoders, and make independent predic-tions. Since these proposals are orthogonal with each other, each of them will carry customized features, which pro-motes the diversity and multimodality. Second, a region-based training strategy (RTS) is developed to explicitly en-sure the multimodality, which negotiates the conﬂicts be-tween the uniqueness of ground truth and multimodal na-ture of predictions. We divide the surrounding space into several regions and group trajectory proposals into differ-ent sets, with each set being assigned to one region. During training, only the set of proposals assigned to the region where ground truth locates will be utilized to optimize the framework. This new strategy enforces individual proposal to focus on a speciﬁc mode, without compromising the la-tent features learned by other proposals.
The contributions of this paper are summarized as fol-lows: (1) To the best of our knowledge, mmTransformer is the ﬁrst model using stacked transformers for trajectory proposals to aggregate multiple channels of contextual in-formation and achieve multimodal prediction.(2) To pre-serve the multimodal nature of motion forecasting, we de-sign a novel region-based training strategy, which ensures that each individual proposal is capable of capturing a spe-ciﬁc mode. (3) Extensive experiments show the substantial improvement brought by the proposed model architecture and the tailored region-based training strategy. Our model ranked the 1st on the Leaderboard of Argoverse benchmark dated on 16 Nov 2020, and remains competitive on the leaderboard. 2.