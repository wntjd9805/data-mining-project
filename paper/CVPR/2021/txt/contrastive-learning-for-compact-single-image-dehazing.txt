Abstract
Single image dehazing is a challenging ill-posed prob-lem due to the severe information degeneration. However, existing deep learning based dehazing methods only adopt clear images as positive samples to guide the training of de-hazing network while negative information is unexploited.
Moreover, most of them focus on strengthening the dehaz-ing network with an increase of depth and width, leading to a signiﬁcant requirement of computation and memory. In this paper, we propose a novel contrastive regularization (CR) built upon contrastive learning to exploit both the in-formation of hazy images and clear images as negative and positive samples, respectively. CR ensures that the restored image is pulled to closer to the clear image and pushed to far away from the hazy image in the representation space.
Furthermore, considering trade-off between perfor-mance and memory storage, we develop a compact dehaz-ing network based on autoencoder-like (AE) framework. It involves an adaptive mixup operation and a dynamic fea-ture enhancement module, which can beneﬁt from preserv-ing information ﬂow adaptively and expanding the receptive
ﬁeld to improve the network’s transformation capability, re-spectively. We term our dehazing network with autoencoder and contrastive regularization as AECR-Net. The extensive experiments on synthetic and real-world datasets demon-strate that our AECR-Net surpass the state-of-the-art ap-proaches. The code is released in https://github. com/GlassyWu/AECR-Net. 1.

Introduction
Haze is an important factor to cause noticeable visual quality degradation in object appearance and contrast. In-∗Equal contribution.
†Corresponding author. (a) Hazy input (b) Only L1 loss [34] (c) Prior [42] (d) KDDN [23] (e) Our CR (f) Ground-truth
Figure 1. Comparison with only positive-orient supervision. put images captured under hazy scenes signiﬁcantly affect the performance of high-level computer vision tasks, such as object detection [26, 8] and scene understanding [39, 40].
Therefore, image dehazing has received a great deal of re-search focus on image restoration for helping to develop ef-fective computer vision systems.
Recently, various end-to-end CNN-based methods [35, 30, 34, 23, 10, 42] have been proposed to simplify the de-hazing problem by directly learning hazy-to-clear image translation via a dehazing network. However, there ex-ists several issues: (1) Less effectiveness of only positive-orient dehazing objective function. Most existing methods
[5, 25, 34, 10] typically adopt clear images (a.k.a. ground-truth) as positive samples1 to guide the training of dehazing network via L1/L2 based image reconstruction loss with-out any regularization. However, only image reconstruction loss is unable to effectively deal with the details of images, which may lead to color distortion in the restored images (see Fig. 1(b)). Recently, additional knowledge from posi-1In this paper, positive samples, clear images and ground-truth are the same concept in the image dehazing task. 10551
rectly removed for inference.
To achieve the best trade-off between performance and parameters, we also develop a compact dehazing network by adopting autoencoder-like (AE) framework to make dense convolution computation in the low-resolution space and also reduce the number of layers, which is presented in
Fig. 3. The information loss from the reduction of parame-ters can be made up by adaptive mixup and dynamic feature enhancement (DFE). Adaptive mixup enables the informa-tion of shallow features from the downsampling part adap-tively ﬂow to high-level features from the upsampling one, which is effective for feature preserving. Inspired by de-formable convolution [54] with strong transformation mod-eling capability, DFE module dynamically expands the re-ceptive ﬁeld for fusing more spatially structured informa-tion, which signiﬁcantly improves the performance of our dehazing network. We term the proposed image dehazing framework as AECR-Net by leveraging contrastive regular-ization into the proposed AE-like dehazing network.
Our main contributions are summarized as follows:
• We propose a novel ACER-Net to effectively gen-erate high quality haze-free images by contrastive regularization and highly compact autoencoder-like based dehazing network. AECR-Net achieves the best parameter-performance trade-off, compared to the state-of-the-art approaches.
• The proposed contrastive regularization as a universal regularization can further improve the performance of various state-of-the-art dehazing networks.
• Adaptive mixup and dynamic feature enhancement module in the proposed autoencoder-like (AE) dehaz-ing network can help the dehazing model preserve in-formation ﬂow adaptively and enhance the network’s transformation capability, respectively. 2.