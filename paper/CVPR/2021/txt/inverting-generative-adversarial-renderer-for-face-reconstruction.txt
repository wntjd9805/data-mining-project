Abstract
Given a monocular face image as input, 3D face ge-ometry reconstruction aims to recover a corresponding 3D face mesh. Recently, both optimization-based and learning-based face reconstruction methods have taken advantage of the emerging differentiable renderer and shown promising results. However, the differentiable renderer, mainly based on graphics rules, simpliﬁes the realistic mechanism of the illumination, reﬂection, etc., of the real world, thus can-not produce realistic images. This brings a lot of domain-shift noise to the optimization or training process. In this work, we introduce a novel Generative Adversarial Ren-derer (GAR) and propose to tailor its inverted version to the general ﬁtting pipeline, to tackle the above problem.
Speciﬁcally, the carefully designed neural renderer takes a face normal map and a latent code representing other fac-tors as inputs and renders a realistic face image. Since the
GAR learns to model the complicated real-world image, in-stead of relying on the simpliﬁed graphics rules, it is ca-pable of producing realistic images, which essentially in-hibits the domain-shift noise in training and optimization.
Equipped with the elaborated GAR, we further proposed a novel approach to predict 3D face parameters, in which we
ﬁrst obtain ﬁne initial parameters via Renderer Inverting and then reﬁne it with gradient-based optimizers. Exten-sive experiments have been conducted to demonstrate the effectiveness of the proposed generative adversarial ren-derer and the novel optimization-based face reconstruction framework. Our method achieves state-of-the-art perfor-mances on multiple face reconstruction datasets. 1.

Introduction
Faithfully recovering the 3D shapes of human faces from unconstrained 2D images is a challenging task and has numerous applications such as face recognition and face animation [45, 48]. State-of-the-art 3D face reconstruc-tion methods can be generally categorized into two groups, learning-based methods and optimization-based methods.
*K. Lin and H. Li are the co-corresponding authors.
Figure 1. Comparisons with state-of-the-art face renderers. On the second row are input geometry and the ﬁrst row are corresponding rendered images. Output of (b) [50] and (c) [13] are not realistic, since they use graphics-based renderers. And there may exists in-consistency between the input and the rendered image in (d) [10].
Our method faithfully renders realistic images consistent with the input geometry, as shown in (e).
The deep learning-based methods [50, 8, 14, 11] usually take place in a regression manner, which takes facial images as inputs and learn to regress the corresponding 3DMM parameters. However, these methods usually require large amounts of labeled data, while the ground truth 3DMM pa-rameters are rather difﬁcult to acquire. Optimization-based methods [5, 22, 13, 49], on the other hand, generally treat the imaging of faces as a generative process [29], which takes a series of geometry coefﬁcients (e.g., albedo, texture, lighting, viewing angle, etc.) as inputs and outputs a ren-dered image according to certain graphics rules. The dis-tances between the rendered images and the target images are minimized with an optimization framework. However, since the graphics rules generally employ simpliﬁed models to characterize the physical process of capturing face im-ages, many details of the imaging process cannot be mod-eled, which introduces difﬁculties for the optimization of face reconstruction.
Recent developments of the differentiable renderers pro-vide an efﬁcient tool for both types of face reconstruction methods. Speciﬁcally, the regressed parameters in learning-based methods could be rendered to images, with which the photometric loss can be adopted for optimization. In this manner, as shown in [11], learning-based models may be 15619
trained without geometry ground truth of the input image.
For the optimization-based methods, as introduced by [13], differentiable renderers introduce gradient-based optimiza-tion and allow adopting more complicated losses and stabi-lizes the training process.
However, differentiable renderers have two drawbacks.
On the one hand, the differentiable renderers are created by handcrafted rendering rules and are generally not ca-pable of producing realistic images. The domain gap be-tween the rendered and real images hinders the optimiza-tion or the training process. On the other hand, the dif-ferentiable renderers are difﬁcult to optimize as they can only back-propagate errors to local vertices. As shown in (b) and (c) of Figure 1, the rendered image is not realistic since they are using graphics-based renderers. Some meth-ods [22, 25] modify the renderers to make them “more” differentiable and better converge to the optimum via opti-mization, whereas they are still utilizing the graphics-based rendering methods, hence the above two problems remain essential drawbacks of the differentiable renderer.
An intuitive solution is to replace the differentiable ren-derer with a neural renderer, an emerging method to employ a neural network to render an image corresponding with the given geometry and texture conditions. Actually, several types of neural renderers have been proposed and studied before. For instance, Deng et al. [10] proposed a neural renderer, which takes 3DMM parameters as inputs and gen-erates a facial image. Nevertheless, the 3DMM parameters are too abstract for the control of the generative adversar-ial renderer. Therefore, the rendered images, although are more realistic and basically subject to the inputs, do not strictly condition on the 3DMM parameters. As shown in (d) of Figure 1, even though the input geometry parameters are close to the target person, the rendered image shows a large variation. Hence, it is not an ideal neural renderer for face reconstruction.
In this paper, we propose to adopt a novel conditional neural renderer, trained in a self-supervised manner, to re-place the conventional graphics-based differentiable ren-derer, to tackle the aforementioned problems while main-taining the advantages of utilizing a renderer for training.
The proposed conditional face neural renderer takes a face normal map as the geometry condition and a latent code vector to model other inﬂuencing factors. Since we hope the proposed renderer could facilitate the optimization of the face geometry, we decouple the normal map from the other condition factors so that the geometry could be better reconstructed via optimization of the normal map. To fur-ther enhance the controllability of the normal map upon the rendered images, a novel Normal Injection Module (NIM) is proposed, in which the normal map is used to modu-late the convolution kernel by pixel-wise multiplication on each channel, to determine the geometry. On the other hand, the decoupled latent code contains detailed informa-tion about the facial textures, which are also signiﬁcant in reconstructing the image faithfully. With a novel normal consistency loss, the whole neural renderer is trained in a self-supervised manner without any labeled data. As shown in (e) of Figure 1, the proposed GAR could faithfully render a realistic face image, according to the input geometry map.
After the neural renderer is trained, it takes the place of the differentiable renderer in the optimization-based face geometry reconstruction pipeline, in which the deviation between the given image and the rendered image is mini-mized and the geometry corresponding to the normal map is optimized.
Even with the proposed neural renderer, direct optimiza-tion with random initialization still struggles to recover the optimal 3D face shape. We further proposed a novel ap-proach to predict 3D face parameters, in which we ﬁrst pre-dict a set of good initial 3D parameters by a separate neural network and then reﬁne them with a gradient-based opti-mizer. Inspired by the latest GAN inverting technique [4], we train a regression network to predict a good initializa-tion of the latent code for inverting the neural renderer to robustly recover the conditioning face normal map. The op-timal face normal maps and subsequently the corresponding face shapes can then be obtained via iterative gradient-based optimization.
The proposed optimization algorithm has two unique ad-vantages. 1) The optimization process is more stable be-cause the “fully” differentiable neural renderer has larger receptive ﬁelds and can achieve more accurate image re-construction. 2) With the proposed initialization-prediction network, the neural renderer can be easier inverted to con-vergence and achieve better accuracy on face reconstruc-tion.
In summary, the main contributions of the proposed method are three-fold:
• To the best of our knowledge, we are the ﬁrst to employ a conditional neural renderer, instead of a graphics-based differentiable renderer, to facilitate the face re-construction.
• We propose a novel normal-conditioning neural ren-derer that can produce vivid face images conditioned on the input normal map and a latent code.
• We propose a face reconstruction algorithm based on the novel neural renderer, and achieve state-of-the-art performance on multiple face reconstruction datasets. 2.