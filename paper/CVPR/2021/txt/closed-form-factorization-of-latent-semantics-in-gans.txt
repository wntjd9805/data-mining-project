Abstract
A rich set of interpretable dimensions has been shown to emerge in the latent space of the Generative Adversarial
Networks (GANs) trained for synthesizing images.
In order to identify such latent dimensions for image editing, previous methods typically annotate a collection of syn-thesized samples and train linear classiﬁers in the latent space. However, they require a clear deﬁnition of the target attribute as well as the corresponding manual annotations, limiting their applications in practice.
In this work, we examine the internal representation learned by GANs to reveal the underlying variation factors in an unsupervised manner. In particular, we take a closer look into the gen-eration mechanism of GANs and further propose a closed-form factorization algorithm for latent semantic discovery by directly decomposing the pre-trained weights. With a lightning-fast implementation, our approach is capable of not only ﬁnding semantically meaningful dimensions comparably to the state-of-the-art supervised methods, but also resulting in far more versatile concepts across multiple
GAN models trained on a wide range of datasets.1 1.

Introduction
Generative Adversarial Networks (GANs)
[8] have achieved tremendous success in image synthesis [16, 17,
It has been recently found that when learning to 4, 18]. 1Project page is at https://genforce.github.io/sefa/. 1532
synthesize images, GANs spontaneously represent multiple interpretable attributes in the latent space [7, 15, 24, 22, 27], such as gender for face synthesis [24] and lighting condition for scene synthesis [27]. By properly identifying these semantics, we can reuse the knowledge learned by
GANs to reasonably control the image generation process, enabling a wide range of editing applications, like face manipulation [25, 9] and scene editing [27, 29].
The crux of interpreting the latent space of GANs is to ﬁnd the meaningful directions in the latent space corresponding to the human-understandable concepts [7, 15, 24, 22, 27]. Through that, moving the latent code towards the identiﬁed direction can accordingly change the semantic occurring in the output image. However, due to the high dimensionality of the latent space as well as the large diversity of image semantics, ﬁnding valid directions in the latent space is extremely challenging.
Existing supervised approaches typically ﬁrst randomly sample a large amount of latent codes, then synthesize a collection of images and annotate them with some pre-deﬁned labels, and ﬁnally use these labeled samples to learn a classiﬁer in the latent space. To get the labels for training, they either employ pre-trained attribute predic-tors [7, 24, 27] or utilize some simple statistical information of the image (e.g., object position and color tone) [15, 22].
Several limitations rise from the above supervised training process. Firstly, relying on pre-deﬁned classiﬁers hinders the algorithm from being applied to the case where the classiﬁers are not available or difﬁcult to train. On the other hand, sampling is both time-consuming and unstable, e.g., a different collection of synthesized data may lead to a different training result. Some very recent studies explore the unsupervised discovery of interpretable GAN semantics [26, 10], but they also require model training [26] or data sampling [10].
In this work, we propose a novel algorithm to discover the latent semantic directions learned by GANs, which is independent of any kind of training or sampling. We call it SeFa as the short for Semantic Factorization. Instead of relying on the synthesized samples as an intermediate step,
SeFa takes a deep look into the generation mechanism of
GANs to examine the relation between the image variation and the internal representation.
In fact, GANs project a latent code to a photo-realistic image step by step (or say layer by layer), where each step learns a projection from one space to another. Many explanatory factors originate in such process. Thus we investigate the ﬁrst projection step that directly acts on the latent space we want to study. We propose a closed-form method that can identify versatile semantics from the latent space by merely using the pre-trained weights of the generator. More importantly, these variation factors, unsupervisedly found by SeFa, are accurate and in a wider range compared to the state-of-the-art supervised approaches. We demonstrate some interesting manipulation results using the discovered semantics in Fig. 1. For instance, we can rotate the object in an image without knowing its underlying 3D model or pose label. Extensive experiments suggest that our approach is efﬁcient and applicable to most popular GAN models (e.g., PGGAN [16], StyleGAN [17], BigGAN [4], and
StyleGAN2 [18]) that are trained on different datasets. 1.1.