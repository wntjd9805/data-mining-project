Abstract
Learning computational models of image aesthetics can have a substantial impact on visual art and graphic de-sign. Although automatic image aesthetics assessment is a challenging topic by its subjective nature, psychological studies have conﬁrmed a strong correlation between im-age layouts and perceived image quality. While previous state-of-the-art methods attempt to learn holistic informa-tion using deep Convolutional Neural Networks (CNNs), our approach is motivated by the fact that Graph Convo-lutional Network (GCN) architecture is conceivably more suited for modeling complex relations among image regions than vanilla convolutional layers. Speciﬁcally, we present a
Hierarchical Layout-Aware Graph Convolutional Network (HLA-GCN) to capture layout information.
It is a dedi-cated double-subnet neural network consisting of two LA-GCN modules. The ﬁrst LA-GCN module constructs an aesthetics-related graph in the coordinate space and per-forms reasoning over spatial nodes. The second LA-GCN module performs graph reasoning after aggregating signiﬁ-cant regions in a latent space. The model output is a hierar-chical representation with layout-aware features from both spatial and aggregated nodes for uniﬁed aesthetics assess-ment. Extensive evaluations show that our proposed model outperforms the state-of-the-art on the AVA and AADB datasets across three different tasks. The code is available at http://github.com/days1011/HLAGCN . 1.

Introduction
Automatic image aesthetics assessment (IAA) has at-tracted increasing attention in recent years due to its po-tential applications, e.g., image retrieval, album photo rec-ommendation, image enhancement [7,14,44], etc. Early ef-forts focus on extracting elaborately designed hand-crafted features according to the known photographic principles, e.g., the rule-of-thirds [8], color harmony [35], and global
*Corresponding author, xukun@tsinghua.edu.cn
Figure 1. To capture layout information over the whole input space, we ﬁrst partition an image into spatial nodes. Features from the disjoint regions (denoted in colors) in the coordinate space are then projected into the latent space for efﬁcient graph reasoning. image layout [16, 30]. With the advance of Convolution
Neural Networks (CNNs) [20], recent methods aim to map image aesthetics to different types of formulations using
CNNs, i.e., binary classiﬁcation labels [25, 40], aesthetic scores [37] and their distributions [3, 10, 11]. Although sig-niﬁcant progress has been achieved, the performance of em-ploying CNNs for IAA is often compromised due to the fol-lowing two main inherent constraints.
First, general deep aesthetic models require additional operations (e.g., cropping, warping, or padding) to gener-ate the ﬁxed-size input needed for mini-batch compatibil-ity. However, the altered object aspect ratios or image lay-outs often impair the image aesthetics and introduce label noise for representation learning. Several methods try to address such limitations by either feeding the original-sized images [10, 29] or incorporating multiple patches [28, 41] into the network, which slows down the training and infer-ence process signiﬁcantly. Second, the layout information is crucial for assessing visual aesthetics since the appropri-ate arrangement of visual elements in the photograph can add balance and harmony [31, 46]. For example, Fig. 1 (a) 8475
shows an example from DPChallenge1, an on-line commu-nity for photography amateurs. In this landscape scene, ﬁve denoted elements including sky, sailboats, lake and reef, are presented with a comfortable and balanced layout collec-tively manifesting the high-level aesthetics, which won ﬁrst place with an average vote of 7.83. However, due to the inherent limitation of the regular receptive ﬁeld, the convo-lution operations of CNNs are typically inefﬁcient at captur-ing relations among distant regions in the coordinate space.
To address these problems, we propose a double-subnetwork framework based on the Graph Convolution
Networks (GCNs) [17], leveraging layout information for assessing visual aesthetics. Speciﬁcally, we ﬁrst use a
Fully Convolutional Network (FCN) to preserve the spa-tial information of the convolutional feature maps, which are viewed as representations of nodes throughout the en-tire spatial grid. Based on the spatial nodes, we construct an aesthetics graph by connecting every pair of nodes to form edges, and embedding the information regarding con-tent similarity and aspect ratio-embedded spatial relations between nodes as edge weights. Then instead of relying solely on standard convolutions to model aesthetic informa-tion, the proposed 1st Layout-Aware Graph Convolutional
Network (LA-GCN) module performs graph convolutions on the graph. To enable efﬁcient global reasoning over dis-joint regions, we further propose to aggregate nodes with similar semantics in a latent space and perform graph rea-soning via the 2nd LA-GCN module, as shown in Fig. 1 (b).
By fusing features from both spatial and aggregated nodes, our Hierarchical LA-GCN empowers the GCN model with the capacity of learning hierarchical representation for IAA.
Our contributions are summarized as follows: First, we present a layout-aware graph convolution module to explic-itly relate the aesthetic perception to the image layout at-tributes in an end-to-end fashion; second, we propose the
HLA-GCN (Hierarchical LA-GCN) by extending the LA-GCN module to a hierarchical architecture for learning vi-sual representations from both coordinate and latent spaces.
Our proposed framework performs favorably against the state-of-the-art methods on the AVA and AADB datasets for uniﬁed aesthetics assessment, i.e., quality classiﬁcation, score regression, and distribution prediction. 2.