Abstract
A key step towards understanding human behavior is the prediction of 3D human motion. Successful solutions have many applications in human tracking, HCI, and graphics.
Most previous work focuses on predicting a time series of future 3D joint locations given a sequence 3D joints from the past. This Euclidean formulation generally works bet-ter than predicting pose in terms of joint rotations. Body joint locations, however, do not fully constrain 3D human pose, leaving degrees of freedom (like rotation about a limb) undeﬁned. Note that 3D joints can be viewed as a sparse point cloud. Thus the problem of human motion prediction can be seen as a problem of point cloud pre-diction. With this observation, we instead predict a sparse set of locations on the body surface that correspond to mo-tion capture markers. Given such markers, we ﬁt a para-metric body model to recover the 3D body of the person.
These sparse surface markers also carry detailed informa-tion about human movement that is not present in the joints, increasing the naturalness of the predicted motions. Us-ing the AMASS dataset, we train MOJO (More than Our
JOints), which is a novel variational autoencoder with a la-tent DCT space that generates motions from latent frequen-cies. MOJO preserves the full temporal resolution of the input motion, and sampling from the latent frequencies ex-plicitly introduces high-frequency components into the gen-erated motion. We note that motion prediction methods ac-cumulate errors over time, resulting in joints or markers that diverge from true human bodies. To address this, we
ﬁt the SMPL-X body model to the predictions at each time step, projecting the solution back onto the space of valid bodies, before propagating the new markers in time. Quan-titative and qualitative experiments show that our approach produces state-of-the-art results and realistic 3D body an-imations. The code is available for research purposes at https://yz-cnsdqz.github.io/MOJO/MOJO.html. 1.

Introduction
Human motion prediction has been extensively studied as a way to understand and model human behavior. Pro-vided the recent past motion of a person, the goal is to pre-dict either a deterministic or diverse set of plausible motions in the near future. While useful for animation, AR, and
VR, predicting human movement is much more valuable be-3372
cause it means we have a model of how people move. Such a model is useful for applications in sports [59], pedestrian tracking [46], smart user interfaces [53], robotics [31] and more. While this is a variant of the well-studied time-series prediction problem, most existing methods are still not able to produce realistic 3D body motion.
To address the gap in realism, we make several novel contributions but start with a few observations. First, most existing methods for 3D motion prediction treat the body as a skeleton and predict a small set of 3D joints. While some methods represent the skeleton in terms of joint angles, the most accurate methods simply predict the 3D joint locations in Euclidean space. Second, given a sparse set of joint loca-tions, animating a full 3D body is ambiguous because im-portant degrees of freedom are not modeled, e.g. rotation about limb axes. Third, most papers show qualitative re-sults by rendering skeletons and these often look ﬁne to the human eye. We show, however, that, as time progresses, the skeletons can become less and less human in proportion so that, at the end of the sequence, the skeleton rarely corre-sponds to a valid human body. Fourth, the joints of the body cannot capture the nuanced details of how the surface of the body moves, limiting realism of any resulting animation.
We address these issues with a solution, called MOJO (More than Our JOints) the predicts realistic 3D body mo-tion. MOJO incorporates a novel representation of the body in motion, a novel motion generative network, and a novel scheme for 3D body mesh recovery.
First, the set of 3D joints predicted by existing methods can be viewed as a sparse point cloud. In this light, existing human motion prediction methods preform point cloud pre-diction. Thus, we are free to choose a different point cloud that better satisﬁes the ultimate goal of animating bodies.
Speciﬁcally, we model the body with a sparse set of sur-face markers corresponding to those used in motion capture (mocap) systems. We simply swap one type of sparse point cloud for another, but, as we will show, predicting surface markers has key advantages. For example, there exist meth-ods to ﬁt a SMPL body model [33] to such makers, produc-ing realistic animations [32, 34]. Consequently this shift to predicting makers enables us to (1) leverage a powerful statistical body shape model to improve results, (2) imme-diately gives us realistic animations, (3) provides an output representation that can be used in many applications.
Second, to model ﬁne-grained and high-frequency in-teractions between markers, we design a conditional vari-ational autoencoder (CVAE) with a latent cosine space. It not only performs stochastic motion prediction, but also im-proves motion realism by incorporating high-frequency mo-tion details. Compared to most existing methods that en-code motion with a single vector (e.g. the last hidden state of an RNN), our model preserves full temporal resolution of the sequence, and decomposes motion into independent fre-quency bands in the latent space via a discrete cosine trans-form (DCT). Based on the energy compaction property of the DCT [3, 44]1, we train our CVAE with a robust Kull-back–Leibler divergence (KLD) term [60], creating an im-plicit latent prior that carries most of the information at low frequency bands. To sample from this implicit latent prior, we employ diversifying latent ﬂows (DLows) [56] in low-frequency bands to produce informative features, and from the standard normal distribution in high-frequency bands to produce white noise. Pieces of information from various frequencies are then fused to compose the output motion.
Third, in the inference phase, we propose a recursive pro-jection scheme supported by our marker-based representa-tion, in order to retain natural body shape and pose through-out the sequence. We regard the valid body space as a low-dimensional manifold in the Euclidean space of markers.
When the CVAE decoder makes a prediction step, the pre-dicted markers tend to leave this manifold because of error accumulation. Therefore, after each step we project the pre-dicted markers back to the valid body manifold, by ﬁtting an expressive SMPL-X [40] body mesh to the markers. On the ﬁtted body, we know the true marker locations and pass these to the next stage of the RNN, effectively denoising the markers at each time instant. Besides keeping the solution valid, the recursive projection scheme directly yields body model parameters and hence realistic body meshes.
We exploit the AMASS [34] dataset for evaluation, as well as Human3.6M [25] and HumanEva-I [47] to com-pare our methods with the state-of-the-art in stochastic mo-tion prediction. We show that our models with the latent
DCT space outperform the state-of-the-art, and that the re-cursive projection scheme effectively eliminates unrealistic body deformation. We also evaluate realism of the gener-ated motion with a foot skating measure and a perceptual study. Finally, we compare different body representations, in particular our solution with a traditional pipeline, which
ﬁrst predicts 3D joints and then ﬁts a body to the joints.
We ﬁnd that they are comparable w.r.t. prediction diversity and accuracy, but the traditional pipeline can produce in-valid body shapes.
Contributions. In summary, our contributions are: (1) We propose a marker-based representation for bodies in mo-tion, which provides more constraints than the body skele-ton and hence beneﬁts 3D body recovery. (2) We design a new CVAE with a latent DCT space to improve motion modelling. (3) We propose a recursive projection scheme to preserve valid bodies at test time. 2.