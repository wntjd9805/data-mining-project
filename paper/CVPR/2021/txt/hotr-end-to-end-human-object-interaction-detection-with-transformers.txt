Abstract
Human-Object Interaction (HOI) detection is a task of identifying “a set of interactions” in an image, which in-volves the i) localization of the subject (i.e., humans) and target (i.e., objects) of interaction, and ii) the classiﬁca-tion of the interaction labels. Most existing methods have indirectly addressed this task by detecting human and ob-ject instances and individually inferring every pair of the detected instances. In this paper, we present a novel frame-work, referred by HOTR, which directly predicts a set of hhuman, object, interactioni triplets from an image based on a transformer encoder-decoder architecture. Through the set prediction, our method effectively exploits the in-herent semantic relationships in an image and does not require time-consuming post-processing which is the main bottleneck of existing methods. Our proposed algorithm achieves the state-of-the-art performance in two HOI de-tection benchmarks with an inference time under 1 ms after object detection. 1.

Introduction
Human-Object Interaction (HOI) detection has been for-mally deﬁned in [8] as the task to predict a set of hhuman, object, interactioni triplets within an image. Previous meth-ods have addressed this task in an indirect manner by performing object detection ﬁrst and associating hhuman, objecti pairs afterward with separate post-processing steps.
Especially, early attempts (i.e., sequential HOI detectors [5, 18, 17, 26]) have performed this association with a subse-quent neural network, thus being time-consuming and com-putationally expensive.
To overcome the redundant inference structure of se-quential HOI detectors, recent researches [30, 19, 12] pro-posed parallel HOI detectors. These works explicitly lo-calize interactions with either interaction boxes (i.e., the tightest box that covers both the center point of an object
†corresponding authors
Figure 1. Time vs. Performance analysis for HOI detectors on
V-COCO dataset. HOI recognition inference time is measured by subtracting the object detection time from the end-to-end inference time. Blue circle represents sequential HOI detectors, orange cir-cle represents parallel HOI detectors and red star represents ours.
Our method achieves an HOI recognition inference time of 0.9ms, being signiﬁcantly faster than the parallel HOI detectors such as
IPNet [30] or UnionDet [12] (the comparison between parallel
HOI detectors is highlighted in blue). pair) [30, 19] or union boxes (i.e., the tightest box that cov-ers both the box regions of an object pair) [12]. The lo-calized interactions are associated with object detection re-sults to complete the hhuman, object, interactioni triplet.
The time-consuming neural network inference is replaced with a simple matching based on heuristics such as dis-tance [30, 19] or IoU [12].
However, previous works in HOI detection are still limited in two aspects; i) They require additional post-processing steps like suppressing near-duplicate predictions and heuristic thresholding. ii) Although it has been shown that modeling relations between objects helps object detec-tion [11, 2], the effectiveness of considering high-level de-pendency for interactions in HOI detection has not yet been fully explored.
In this paper, we propose a fast and accurate HOI al-gorithm named HOTR (Human-Object interaction TRans-74
former) that predicts a set of human-object interactions in a scene at once with a direct set prediction approach. We de-sign an encoder-decoder architecture based on transformers to predict a set of HOI triplets, which enables the model to overcome both limitations of previous works. First, di-rect set-level prediction enables us to eliminate hand-crafted post-processing stage. Our model is trained in an end-to-end fashion with a set loss function that matches the predicted interactions with ground-truth hhuman, object, interactioni triplets. Second, the self-attention mechanisms of transformers makes the model exploit the contextual rela-tionships between human and object and their interactions, encouraging our set-level prediction framework more suit-able for high-level scene understanding.
We evaluate our model in two HOI detection bench-marks: V-COCO and HICO-DET datasets. Our proposed architecture achieves state-of-the-art performance on two datasets compared to both sequential and parallel HOI de-tectors. Also, note that our method is much faster than other algorithms as illustrated in Figure 1, by eliminating time-consuming post-processing through the direct set-level pre-diction. The contribution of this work can be summarized as the following:
• We propose HOTR, the ﬁrst transformer-based set pre-diction approach in HOI detection. HOTR elimi-nates the hand-crafted post-processing stage of previ-ous HOI detectors while being able to model the cor-relations between interactions.
• We propose various training and inference techniques for HOTR: HO Pointers to associate the outputs of two parallel decoders, a recomposition step to predict a set of ﬁnal HOI triplets, and a new loss function to enable end-to-end training.
• HOTR achieves state-of-the-art performance on both benchmark datasets in HOI detection with an inference time under 1 ms, being signiﬁcantly faster than previ-ous parallel HOI detectors (5∼9 ms). 2.