Abstract
Image-based methods for indoor lighting estimation suf-fer from the problem of intensity-distance ambiguity. This paper introduces a novel setup to help alleviate the ambi-guity based on the event camera. We further demonstrate that estimating the distance of a light source becomes a well-posed problem under this setup, based on which an optimization-based method and a learning-based method are proposed. Our experimental results validate that our approaches not only achieve superior performance for in-door lighting estimation (especially for the close light) but also signiï¬cantly alleviate the intensity-distance ambiguity.
Light source exp(ğ›· ğ‘¡ )
ğ’ğ±
ğ’ğ’
BRDF
Diffuse reflection
ğ’ğ’
ğ‘‘
Event streams
Sphere
ğ‘°(ğ±, ğ‘¡)
Event camera
ğ‘’ = {ğ±, ğ‘¡, ğ‘} 1.

Introduction
Obtaining lighting information is a classic problem in computer vision and graphics. It contributes to solving a variety of vision tasks, such as photometric stereo [29, 78], virtual object compositing [31], and scene understanding
[55]. A ï¬eld of researches study to estimate or calibrate lighting by taking a single image of an illuminated object (e.g., [9, 34]) or scene (e.g., [59, 35]) as the input.
Early work assumes the light source to be distant and fo-cuses on the estimation of light direction (e.g., [15]). This assumption is often violated for indoor scenes due to the lo-calized light sources. Recent advances tackle this problem by either estimating a spatially-varying lighting at different scene points (e.g., [16]) or predicting the light source posi-tions in 3D space (e.g., [14]). However, as these approaches take a single image as the input, this inherently ill-posed problem is likely to suffer from the problem of intensity-distance ambiguity. Because the light distance inferred from a given intensity (recorded by an image) is not guaran-teed to be unique if the light source intensity changes [36].
Recently, the event camera (e.g., [37]) has attracted the attention of many academics due to its advantages of high
#Equal contribution. âˆ—Corresponding author.
Figure 1. The setup of our method: using an event camera to cap-ture the intensity changes on a purely diffuse sphere, which is placed in a dark room, for the split second of turning light on. temporal resolution, high dynamic range, and sensitivity to small intensity changes. And it has been used to solve vari-ous vision tasks such as 3D reconstruction [64], optical ï¬‚ow estimation [13], and segmentation [62].
In this paper, we leverage the event camera to alleviate the intensity-distance ambiguity for indoor lighting estima-tion. Our basic idea is to use more information to better constrain the estimation of light source parameters, because the event camera can capture signals in a split second. To be speciï¬c, we introduce a novel setup as shown in Figure 1.
With such a setup, we observe that the intensity-distance ambiguity can hardly be found for the event streams (Fig-ure 2). We detail the analysis about the ambiguity in Sec-tion 3.2, which is based on our analytic formulation of event streams (Section 3.1). We further show that estimating the distance of light source becomes a well-posed problem with the input of event streams, based on which an optimization-based method is proposed (Section 4.1). We also propose a learning-based method for robust lighting estimation (Sec-tion 4.2). To evaluate our methods, we collect two testing datasets with paired data captured by a traditional camera and an event camera (Section 4.2). Experimental results 14760
(a) (b) (c) (d)
Figure 2. (a)&(b) (or (c)&(d)) are paired data, captured with the same light-emitting diode, i.e., LED, 3w (or 5w), and the same distance of light source 119 cm (or 213 cm). (a)&(c) are RGB im-ages captured by a digital camera while (b)&(d) are event streams captured by an event camera (all event streams in this paper are vi-sualized based on the method in [81]). Even though (a)&(c) have a similar appearance, (b)&(d) display discriminative features. demonstrate that our methods not only achieve superior per-formance for lighting estimation, but also signiï¬cantly alle-viate the intensity-distance ambiguity. In addition, we pro-vide a byproduct application to classify the types of the light source. Our contributions are summarized as: 1. We introduce a novel setup, based on which we show that the intensity-distance ambiguity can be alleviated for the problem of indoor lighting estimation. 2. We show that estimating lighting distance becomes a well-posed problem with our setup, based on which we propose an optimization-based method and a learning-based method. 3. We demonstrate that our methods not only achieve su-perior performance but also signiï¬cantly alleviate the intensity-distance ambiguity for the problem of indoor lighting estimation. Our byproduct of lamp classiï¬ca-tion also veriï¬es the effectiveness of our methods. 2.