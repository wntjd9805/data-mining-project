Abstract
Generative adversarial networks (GANs) learn to map
It is noise latent vectors to high-ﬁdelity image outputs. found that the input latent space shows semantic correla-tions with the output image space. Recent works aim to interpret the latent space and discover meaningful direc-tions that correspond to human interpretable image trans-formations. However, these methods either rely on explicit scores of attributes (e.g., memorability) or are restricted to binary ones (e.g., gender), which largely limits the ap-plicability of editing tasks, especially for free-form artis-In this paper, we pro-tic tasks like style/anime editing. pose an adversarial method, AdvStyle, for discovering in-terpretable directions in the absence of well-labeled scores or binary attributes. In particular, the proposed adversar-ial method simultaneously optimizes the discovered direc-tions and the attribute assessor using the target attribute data as positive samples, while the generated ones being negative.
In this way, arbitrary attributes can be edited by collecting positive data only, and the proposed method learns a controllable representation enabling manipulation
*Corresponding author (hesfe@scut.edu.cn). of non-binary attributes like anime styles and facial char-acteristics. Moreover, the proposed learning strategy atten-uates the entanglement between attributes, such that multi-attribute manipulation can be easily achieved without any additional constraint. Furthermore, we reveal several in-teresting semantics with the involuntarily learned negative directions. Extensive experiments on 9 anime attributes and 7 human attributes demonstrate the effectiveness of our ad-versarial approach qualitatively and quantitatively. Code is available at https://github.com/BERYLSHEEP/AdvStyle. 1.

Introduction
Generative adversarial networks (GANs) [6, 11, 19, 20] have been demonstrated power in generating high  resolution photo realistic images by training with massive diverse data. The rationale of GANs is to learn a non  linear mapping function from the input noise latent codes to output images that conform to real data distributions. Sev  eral works reveal the vector arithmetic property of the latent space, e.g., adding a learned vector to the latent code [29] or combining the latent code of two images [20], result in modifying image semantics. Although it is still uncer  12177
e l y t
S c i m o
C l e d o m r e p u
S (a) Origin (b) [30] (c) Ours
Figure 2: The state of the art method [30] can only deal with distinct binary attributes. Non binary attributes like comic style violate its binarily separable hyperplane as  sumption, leading to unsuccessful or entangled semantic manipulation. Our method does not suffer from these prob  lems. tain how semantics are structured in the latent space, these prior works drive researches to interpret the latent space of
GANs.
A few very recent works aim to discover the meaning  ful directions that correspond to interpretable image trans  formations in the way of unsupervised or supervised learn  ing. Despite unsupervised methods can discover directions of simple image transformations like zooming or transla  tion [17, 28], or heuristically searching for unexpected ones like background removal [33], they cannot precisely locate user desired target attributes.
On the other hand, supervised approaches possess better controllability. This line of study leverages a target attribute accessor to help tracing back the corresponding direction in the latent space. Speciﬁcally, Goetschalckx et al. [10] use the evaluator [21, 23] trained by well scored attribute datasets to obtain the directions of memorability, aesthetic, etc. Tewari et al. [32] leverage annotated 3D data for map  ping the control space of a 3D morphable face model to the latent space of GANs, so that they can control three se  mantic face parameters (pose, expressions, and scene illu  mination). However, well scored attributes or 3D data (see
Tab. 1 for an example) are expensive to obtain and there  fore the practicability is limited. Shen et al. [30] extend the accessor to a pretrained binary classiﬁer to construct a hy  perplane in the latent space for discovering binary attributes like gender or eyeglasses. Notwithstanding the success of this method in editing binary attributes, there are many more attributes that are not binarily separable, and therefore their assumption on the constructed binary hyperplane is invalid for non binary attributes. If we apply binary based method by simply classifying the target attribute as positive (e.g., comic style) while leaving all the others as negative, the learned directions will correspond to incorrect and entan 
Method Annotation type
Annotation example (attribute: value)
[10]
[32]
[30]
Ours Positive attribute only
Scored attribute Memorability: 3D annotation
Binary attribute 3D vertices
Young and Old: 0/1
Supermodel style : 1
Table 1: Different types of annotations required by super  vised latent space exploration methods. gled semantics (see the second column of Fig. 2), as the manually classiﬁed negative samples provide ambiguous, or even misleading guidance.
In this paper, we aim at interpreting the latent space of
GANs beyond binary attributes. To this end, we propose an adversarial method, AdvStyle, that takes only target posi  tive samples for training, and the attribute assessor is trained to distinguish the target positive samples and the generated negative samples. In this way, our approach focuses only on
ﬁnding the positive direction that the generated images are indistinguishable from the target data, producing disentan  gled directions of various semantics. As a result, AdvStyle can perform multi attribute editing without any orthogonal constraint. Moreover, we dynamically update the attribute assessor, rather than using the pre trained ones. This helps to bridge the domain gap between the generated images and the training data of the attribute assessor. The involuntarily learned negative directions, on the other hand, reveal some interesting and unexpected semantics. Some results of our method are shown in Fig. 1.
Our contributions are summarized as follows:
• We propose an adversarial method to discover the di  rections of arbitrary attributes in the latent space of a pre trained GAN, leading to intuitive editing on non  binary attributes beyond the limitation of manual an  notations.
• We show that the adversarially learned directions are well disentangled, therefore multi attribute manipula  tion can be done without additional constraint.
• We further study the interesting and unexpected se  mantics which are involuntarily captured by our neg  ative directions, it helps revealing how the latent space is organized.
• We extend our method to real image editing with GAN inversions methods, it can serve as a ﬂexible and prac  tical editing tool for users. 2.