Abstract
Previous work [40] shows that a better density map rep-resentation can improve the performance of crowd count-ing. In this paper, we investigate learning the density map representation through an unbalanced optimal transport problem, and propose a generalized loss function to learn density maps for crowd counting and localization. We prove that pixel-wise L2 loss and Bayesian loss [29] are special cases and suboptimal solutions to our proposed loss func-tion. A perspective-guided transport cost function is further proposed to better handle the perspective transformation in crowd images. Since the predicted density will be pushed to-ward annotation positions, the density map prediction will be sparse and can naturally be used for localization. Fi-nally, the proposed loss outperforms other losses on four large-scale datasets for counting, and achieves the best lo-calization performance on NWPU-Crowd and UCF-QNRF. 1.

Introduction
Crowd counting and localization draw increasing atten-tion recently because of its practical usage in surveillance, transport management and business. Most of the algorithms predict a density map from a crowd image, where the sum-mation of the density map is the crowd count [41, 4]. A density map (a smooth heat map) is an intermediate repre-sentation of the crowd – one popular method to generate the ground-truth density map is to place a Gaussian kernel on each person’s dot annotation. The density map estimator is then trained as a standard pixel-wise regression problem us-ing L2 loss [12, 40] (see Fig. 1a). In contrast to pixel-wise
L2 loss, Bayesian loss (BL) [29] generates an aggregated dot prediction from the density map prediction, and uses a point-wise loss function between the ground-truth dot an-notations and the aggregated dot prediction (see Fig. 1b).
Both L2 and BL assume a ﬁxed ground-truth repre-sentation, either Gaussian density kernels for L2 or Gaus-sian likelihoods for BL. Recent works [40, 43] have shown that the intermediate density map representation affects the counting performance, and a better density map representa-tion can be learned in an end-to-end manner from the dot-(a) pixel loss prediction density map  dot annotations fix transport (b) (c) fix transport point loss prediction dot prediction p dot annotations optimal transport transport loss + pixel loss + point loss
L2
BL ours prediction dot annotations
Figure 1: Loss functions for counting: (a) L2 loss generates density map as the supervision and uses a pixel-wise loss function. (b) Bayesian loss (BL) [29] computes an aggregated dot prediction and uses a point-wise loss function. We show that L2 and BL are related to an optimal transport problem using a suboptimal transport matrix. (c) Our proposed loss is based on unbalanced optimal transport, where the transport cost is fully minimized and both the pixel-wise and point-wise losses are considered. annotations. However, [40, 43] still use L2 loss for train-ing, which is not appropriate in suppressing background and improving localization. In particular, with L2 loss, a unit change in density in background regions (which is a large localization error) is equivalent to a unit change in density near a dot annotation (which is a small localization error).
Thus the L2 loss function is not ideal for localization or gen-erating compact density maps, and we should prefer a loss function that has an increased penalty for errors far from the annotations, so as to improve localization and compactness.
Considering both motivations of learning the density map representation and using localization-sensitive loss, we propose a generalized loss function based on an unbal-anced optimal transport (OT) framework, which measures the transport cost between the predicted density map and the ground-truth dot annotations (see Fig. 1c). We show that the transport matrix, which is optimized to minimize the loss, is related to the intermediate density map representation. To better handle perspective changes in the image, we propose a perspective-guided transport cost function to better sepa-rate the density around people who are close together due to the camera perspective. The proposed loss function de-composes into four terms: 1) a transport loss that pushes the 1974
predicted density toward annotations; 2) a transport regular-ization term that prevents collapse onto a single annotation; 3) a pixel-wise loss that measures the difference between the predicted density map and the constructed density map (from the transport matrix); 4) a point-wise loss that ensures that all annotations are accounted for in the predicted den-sity map. We further show that our proposed loss is a gen-eralization of the traditional L2 loss with Gaussian density kernel and BL, i.e., they are special cases and suboptimal solutions to the unbalanced OT in our proposed loss.
Compared to previous losses, our proposed loss function has four advantages: 1) the density map representation is learned via the optimized transport matrix; 2) it does not require any special design for background regions (such as
[29, 42]), and naturally pushes predicted density away from the background and towards the annotations; 3) it produces compact density maps that can be naturally used for local-ization; 4) it is less sensitive to the blur factor hyperparam-eter (which is equivalent to the Gaussian kernel variance).
In summary, the contributions of the paper are four-fold: 1. We propose a generalized loss function, motivated by unbalanced optimal transport theory, for crowd count-ing and localization. We prove L2 and BL are special cases and suboptimal solutions of our loss function. 2. To handle perspective effects in crowd images, we propose a perspective-guided transport cost, which in-creases transport costs of density far from the camera, thus making densities in those regions more compact. 3. In extensive experiments on crowd counting, using our loss achieves better performance than traditional loss functions on three large-scale datasets, NWPU-Crowd,
JHU-CROWD++, and UCF-QNRF. 4. Our low-resolution predicted density maps (1/8 image size) achieve the best localization performance on two large benchmarks NWPU-Crowd and UCF-QNRF. 2.