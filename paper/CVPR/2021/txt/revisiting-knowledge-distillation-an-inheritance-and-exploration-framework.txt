Abstract
Knowledge Distillation (KD) is a popular technique to transfer knowledge from a teacher model or ensemble to a student model. Its success is generally attributed to the privileged information on similarities/consistency between the class distributions or intermediate feature representa-tions of the teacher model and the student model. How-ever, directly pushing the student model to mimic the prob-abilities/features of the teacher model to a large extent limits the student model in learning undiscovered knowl-edge/features. In this paper, we propose a novel inheritance and exploration knowledge distillation framework (IE-KD), in which a student model is split into two parts - inheritance and exploration. The inheritance part is learned with a sim-ilarity loss to transfer the existing learned knowledge from the teacher model to the student model, while the explo-ration part is encouraged to learn representations different from the inherited ones with a dis-similarity loss. Our IE-KD framework is generic and can be easily combined with existing distillation or mutual learning methods for training deep neural networks. Extensive experiments demonstrate that these two parts can jointly push the student model to learn more diversiï¬ed and effective representations, and our IE-KD can be a general technique to improve the stu-dent network to achieve SOTA performance. Furthermore, by applying our IE-KD to the training of two networks, the performance of both can be improved w.r.t. deep mutual learning. 1.

Introduction
Knowledge distillation is one of the most popular meth-ods for transferring knowledge from one network (teacher)
*This work was done when the author was visiting Alibaba as a re-search intern.
â€ Corresponding author.
It was ï¬rst proposed by Hinton et to another (student). al. [10] to transfer knowledge from a large teacher network (or ensemble) to a small student network that is easier to deploy. It works by training the student to predict the tar-get classiï¬cation labels and mimic the class probabilities of the teacher, as these features contain additional informa-tion about how the teacher tends to generalize [10]. All recent distillation works follow this philosophy of an ad-ditional consistency control between the class probabilities or intermediate representations of the teacher network and the student network. KD [10] and Tf-KD [32] focus on the consistency of output class probabilities. AT [33], AB [13],
FT [16], OD [12], FEED [22] and FitNet [24] propose dif-ferent consistency controls of intermediate features. FSP
[31] proposes a consistency control of the intra-similarities among intermediate features. In summary, all recent distil-lation methods differ in the metric of consistency between the student model and the teacher model.
However, directly pushing the student model to mimic the probabilities/features of the teacher model limits the stu-dent model in learning new knowledge/features. As shown in Fig. 1(a), the student model trained with KD learns very similar patterns compared with the well-trained teacher (more results will be shown in supplementary materials). In this case, the â€œcheetahâ€ misclassiï¬ed as a â€œcrocodileâ€ by the teacher model is also misclassiï¬ed by the student model trained by KD. The model attributes most of its prediction to the tail of the â€œcheetahâ€ which resembles a â€œcrocodileâ€.
As a result, the student network fails to incorporate new rel-evant patterns on ears and mouth that are quite discrimina-tive between the â€œcheetahâ€ and â€œcrocodileâ€. Therefore, we need a mechanism to ï¬nd more useful features for correct predictions that are omitted by the teacher network.
Intuitively, simply mimicking outputs of the teacher net-work will narrow the search space for the optimal parame-ters of the student network and lead to a poor solution from a feature learning view. Furthermore, we ï¬nd that this phe-nomenon becomes more evident when transferring knowl-3579
ğ¶â„ğ‘’ğ‘’ğ‘¡ğ‘â„ 	 ğºğ‘‡ : 	16%				ğ¶ğ‘Ÿğ‘œğ‘ğ‘œğ‘‘ğ‘–ğ‘™ğ‘’: 	66%
ğ¼ğ‘šğ‘ğ‘”ğ‘’
ğ¿ğ‘…ğ‘ƒ 	ğ‘œğ‘“	ğ‘‡ğ‘’ğ‘ğ‘â„ğ‘’ğ‘Ÿ
ğ¿ğ‘…ğ‘ƒ 	ğ‘œğ‘“	ğ¾ğ·
ğ¶â„ğ‘’ğ‘’ğ‘¡ğ‘â„	 ğºğ‘‡ : 		85%				ğ¶ğ‘Ÿğ‘œğ‘ğ‘œğ‘‘ğ‘–ğ‘™ğ‘’: 			3%
ğ¼ğ‘šğ‘ğ‘”ğ‘’
ğ¿ğ‘…ğ‘ƒ 	ğ‘œğ‘“	ğ¼ğ‘›â„.
ğ¿ğ‘…ğ‘ƒ 	ğ‘œğ‘“	ğ¸ğ‘¥ğ‘. (a) Visualization of learned knowledge (b) Loss curves
Figure 1. Left: Visualization of learned knowledge for classiï¬cation, including the teacher network (LRP of Teacher), student network trained with KD (LRP of KD), inheritance part of IE-KD (LRP of Inh.) and exploration part of IE-KD (LRP of Exp.). LRP [21] is used to interpret the network by visualizing which pixels contribute how much to the classiï¬cation. Right: Training loss (dotted lines) and testing loss (bold lines) on CIFAR-10 of the student network (ResNet-56) which is trained via independent learning (training-from-scratch), KD and IE-KD (using ResNet-20 as teacher network). For a fair comparison, KD and IE-KD correspond to FT and IE-FT here. Directly pushing the student network to mimic the outputs of the teacher network limits the student network in learning new knowledge. It even leads to a poor solution when the student network is larger than the teacher network (high training and testing loss at the same time). edge from a small teacher network to a large student net-work (shown in Fig. 1(b)). According to the observation in
[1, 5], small networks often have as sufï¬cient capacity as large networks but represent the features in a more concise manner [24]. Therefore, a large network should not only mimic this compact representation with some of their pa-rameters to reduce the redundancy of itself, but also should free other parameters to explore more different and comple-mentary features to improve its diversity and generalization ability. Based on the aforementioned analyses, in this paper, we propose a novel inheritance and exploration knowledge distillation framework (IE-KD), to train a student network by partially following the knowledge from the teacher net-work and partially exploring for new knowledge that are complementary to the teacher network.
In our IE-KD, the knowledge is transferred by the two principles of consistency and diversity. Consistency ensures that the well learned knowledge encoded in the teacher net-work is successfully inherited by the student network. Di-versity ensures that the student network can explore new features that are complementary to the inherited ones. The motivation of IE-KD comes from the theory of heredity in evolution [7]. Heredity involves inheritance and variation of traits. Evolution results from natural selection acting on diversity in populations, which originally stems from mu-tations. There are three key factors for evolution: a) in-heritance of compact and effective traits from parents en-coded by genes, b) new diversiï¬ed genotypes generated from genetic mutations, and c) natural selection through stressful environments. Motivated by this, we split the stu-dent network into two parts: one inherits the compact and effective knowledge encoded by factors from the teacher network via consistency/inheritance loss (similarity), and the other is pushed to generate different features via diver-sity/exploration loss (dis-similarity). The supervised task (classiï¬cation/detection) loss plays the role of natural se-lection, guiding the exploration part to converge to diverse yet effective features.
Another closely related motivation for IE-KD comes from the exploration of actions in Q-learning [20], and the popular AlphaGo [26], where half the actions follow the predictions of the policy network, and the other half are randomly sampled from the remaining action space that en-sures adequate exploration of the state space. Besides, [4] proposes a similar form of loss function to attack the heat maps of one white-box DNN, making its attention focus on other regions of the image. Inspired by these insights, we propose our IE-KD framework to improve the training of student network, by exploring the new and undiscovered knowledge apart from the teacher-learned knowledge.
Overall, our IE-KD framework is generic and can be eas-ily combined with existing distillation or mutual learning methods for training deep neural networks. Extensive ex-periments demonstrate that these two parts can jointly push the student model to learn more diversiï¬ed and effective representations, and our IE-KD can be a general technique to improve the student network to achieve SOTA perfor-mance. Furthermore, by applying our IE-KD to the training of two networks, the performance of both can be improved w.r.t. deep mutual learning. 3580
2.