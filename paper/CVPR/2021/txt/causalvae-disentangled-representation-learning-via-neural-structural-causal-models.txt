Abstract
Learning disentanglement aims at ﬁnding a low dimen-sional representation which consists of multiple explana-tory and generative factors of the observational data. The framework of variational autoencoder (VAE) is commonly used to disentangle independent factors from observations.
However, in real scenarios, factors with semantics are not necessarily independent. Instead, there might be an under-lying causal structure which renders these factors depen-dent. We thus propose a new VAE based framework named
CausalVAE, which includes a Causal Layer to transform independent exogenous factors into causal endogenous ones that correspond to causally related concepts in data. We further analyze the model identiﬁabitily, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments are conducted on various datasets, including synthetic and real word bench-mark CelebA. Results show that the causal representations learned by CausalVAE are semantically interpretable, and their causal relationship as a Directed Acyclic Graph (DAG) is identiﬁed with good accuracy. Furthermore, we demon-strate that the proposed CausalVAE model is able to generate counterfactual data through “do-operation” to the causal factors. 1.

Introduction
Disentangled representation learning is of great impor-tance in various applications such as computer vision, speech and natural language processing, and recommender systems
[9, 20, 8]. The reason is that it might help enhance the performance of models, i.e. improving the generalizability,
*Corresponding author. robustness against adversarial attacks as well as the explan-ability, by learning data’s latent disentangled representation.
One of the most common frameworks for disentangled rep-resentation learning is Variational Autoencoders (VAE), a deep generative model trained to disentangle the underly-ing explanatory factors. Disentanglement via VAE can be achieved by a regularization term of the Kullback-Leibler (KL) divergence between the posterior of the latent factors and a standard Multivariate Gaussian prior, which enforces the learned latent factors to be as independent as possible. It is expected to recover the latent variables if the observation in real world is generated by countable independent factors.
To further enhance the independence, various extensions of
VAE consider minimizing the mutual information among latent factors. For example, Higgins et al. [6] and Burgess et al. [3] increased the weight of the KL divergence term to en-force independence. Kim et al. [12, 4] further encourage the independence by reducing total correlation among factors.
Most existing works of disentangled representation learn-ing make a common assumption that the real world observa-tions are generated by countable independent factors. Never-theless we argue that in many real world applications, latent factors with semantics of interest are causally related and thus we need a new framework that supports causal disen-tanglement.
Consider a toy example of a swinging pendulum in Fig. 1.
The position of the illumination source and the angle of the pendulum are causes of the position and the length of the shadow. Through causal disentangled representation learning, we aim at learning representations that correspond to the above four concepts. Obviously, these concepts are not independent and existing methods may fail to extract those factors. Furthermore, causal disentanglement allow us to manipulate the causal system to generate counterfactual data.
For example, we can manipulate the latent code of shadow to 9593
Figure 1. A swinging pendulum: an illustrative example create new pictures without shadow even there are pendulum and light. This corresponds to the ”do-operation” [24] in causality, where the system operates under the condition that certain variables are controlled by external forces. A deep generative model that supports ”do-operation” is of tremendous value as it allows us to ask “what-if” questions when making decisions.
In this paper, we propose a VAE-based causal disentan-gled representation learning framework by introducing a novel Structural Causal Model layer (Mask Layer), which allows us to recover the latent factors with semantics and structure via a causal DAG. The input signal passes through an encoder to obtain independent exogenous factors and then a Causal Layer to generate causal representation which is taken by the decoder to reconstruct the original input. We call the whole process Causal Disentangled Representation
Learning. Unlike unsupervised disentangled representation learning of which the feasibility is questionable [18], addi-tional information is required as weak supervision signals to achieve causal representation learning. By “weak supervi-sion”, we emphasize that in our work, the causal structure of the latent factors is automatically learned, instead of being given as a prior in [14]. To train our model, we propose a new loss function which includes the VAE evidence lower bound loss and an acyclicity constraint imposed on the learned causal graph to guarantee its “DAGness”. In addition, we an-alyze the identiﬁablilty of the proposed model, showing that the learned parameters of the disentangled model recover the true one up to certain degree. The contribution of our paper is three-fold. (1) We propose a new framework named
CausalVAE that supports causal disentanglement and “do-operation”; (2) Theoretical justiﬁcation on model identiﬁabil-ity is provided; (3) We conduct comprehensive experiments with synthetic and real world face images to demonstrate that the learned factors are with causal semantics and can be intervened to generate counterfactual images that do not appear in training data. 2.