Abstract
LR input image
SRNTT result
Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising paradigm to enhance a low-resolution (LR) input image by introducing an additional high-resolution (HR) reference image. Existing Ref-SR methods mostly rely on implicit correspondence matching to borrow HR textures from reference images to compen-sate for the information loss in input images. However, per-forming local transfer is difﬁcult because of two gaps be-tween input and reference images: the transformation gap (e.g. scale and rotation) and the resolution gap (e.g. HR and
LR). To tackle these challenges, we propose C 2-Matching in this work, which produces explicit robust matching cross-ing transformation and resolution. 1) For the transforma-tion gap, we propose a contrastive correspondence network, which learns transformation-robust correspondences using augmented views of the input image. 2) For the resolution gap, we adopt a teacher-student correlation distillation, which distills knowledge from the easier HR-HR matching to guide the more ambiguous LR-HR matching. 3) Finally, we design a dynamic aggregation module to address the po-tential misalignment issue. In addition, to faithfully evalu-ate the performance of Ref-SR under a realistic setting, we contribute the Webly-Referenced SR (WR-SR) dataset, mim-icking the practical usage scenario. Extensive experiments demonstrate that our proposed C 2-Matching signiﬁcantly outperforms state of the arts by over 1dB on the standard
CUFED5 benchmark. Notably, it also shows great gener-alizability on WR-SR dataset as well as robustness across large scale and rotation transformations 1. 1.

Introduction
Reference-based Super-Resolution (Ref-SR) [40, 39, 34, 26] has attracted substantial attention in recent years. Com-pared to Single-Image-Super-Resolution (SISR) [6, 13, 14, 17, 25, 4], where the only input is a single low-resolution (LR) image, Ref-SR super-resolves the LR image with the guidance of an additional high-resolution (HR) reference 1Codes and datasets are available at https : / / github . com / yumingj/C2-Matching.
HR reference image
C2-Matching (ours) result
Figure 1. Cross transformation and Cross resolution matching are performed in our C 2-Matching. Our proposed C 2-Matching successfully transfers the HR details of the reference image by
ﬁnding more accurate correspondences. The correspondences found by our method are marked in red and the correspondences found by SRNTT [39] are marked in blue. image. Textures of the HR reference image are transferred to provide more ﬁne details for the LR image.
The key step in texture transfer for Ref-SR is to ﬁnd correspondences between the input image and the refer-ence image. Existing methods [39, 34, 32] perform corre-spondence matching implicitly. Their correspondences are computed based on the content and appearance similarities, which are then embedded into the main framework. How-ever, it is a difﬁcult task to accurately compute the corre-spondences under real-world variations due to two major challenges: 1) the underlying transformation gap between input images and reference images; 2) the resolution gap be-tween input images and reference images. In Ref-SR, same objects or similar texture patterns are often present in both input images and reference images, but their appearances vary due to scale and rotation transformations. In this case, correspondences computed purely by appearance are inac-curate, leading to an unsatisfactory texture transfer. For the resolution gap, due to the imbalance in the amount of infor-mation contained in an LR input image and an HR reference image, the latter is often downsampled (to an LR image) to match the former (in resolution). The downsampling op-eration inevitably results in information loss, hampering the search for accurate correspondences, especially for the ﬁne-texture regions. 2103
To address the aforementioned challenges, we pro-pose C 2-matching for Robust Reference-based Super-Resolution, where Cross transformation and Cross reso-lution matching are explicitly performed. To handle the transformation gap, a contrastive correspondence network is proposed to learn transformation-robust correspondences between input images and reference images. Speciﬁcally, we employ an additional triplet margin loss to minimize the distance of point-wise features before and after transforma-tions while maximizing the distance of irrelevant features.
Thus, the extracted feature descriptors are more robust to scale and rotation transformations, and can be used to com-pute more accurate correspondences.
As for the resolution gap, inspired by knowledge distil-lation, we propose a teacher-student correlation distillation.
We train the teacher contrastive correspondence network for
HR-HR matching. Since the teacher network takes two HR images as input, it is better at matching the regions with complicated textures. Thus, the knowledge of the teacher model can be distilled to guide the more ambiguous LR-HR matching. The teacher-student correlation distillation enables the contrastive correspondence network to compute correspondences more accurately for texture regions.
After obtaining correspondences, we then fuse the infor-mation of reference images through a dynamic aggregation module to transfer the HR textures. With C 2-Matching, we achieve over 1dB improvement on the standard CUFED5 dataset. As shown in Fig. 1, compared to SRNTT [39], our
C 2-Matching ﬁnds more accurate correspondences (marked as red dotted lines) and thus has a superior restoration per-formance.
To facilitate the evaluation of Ref-SR tasks in a more realistic setting, we contribute a new dataset named Webly-Reference SR (WR-SR) dataset. In real-world applications, given an LR image, users may ﬁnd its similar HR reference images through some web search engines. Motivated by this, for every input image in WR-SR, we search for its ref-erence image through Google Image. The collected WR-SR can serve as a benchmark for real-world scenarios.
To summarize, our main contributions are: 1) To miti-gate the transformation gap, we propose the contrastive cor-respondence network to compute correspondences more ro-bust to scale and rotation transformations. 2) To bridge the resolution gap, a teacher-student correlation distillation is employed to further boost the performance of student LR-HR matching model with the guidance of HR-HR matching, especially for ﬁne texture regions. 3) We contribute a new benchmark dataset named Webly-Referenced SR (WR-SR) to encourage a more practical application in real scenarios. 2.