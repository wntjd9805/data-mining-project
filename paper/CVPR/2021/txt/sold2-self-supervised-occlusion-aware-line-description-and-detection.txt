Abstract
Compared to feature point detection and description, de-tecting and matching line segments offer additional chal-lenges. Yet, line features represent a promising complement to points for multi-view tasks. Lines are indeed well-deﬁned by the image gradient, frequently appear even in poorly tex-tured areas and offer robust structural cues. We thus hereby introduce the ﬁrst joint detection and description of line seg-ments in a single deep network. Thanks to a self-supervised training, our method does not require any annotated line labels and can therefore generalize to any dataset. Our detector offers repeatable and accurate localization of line segments in images, departing from the wireframe parsing approach. Leveraging the recent progresses in descriptor learning, our proposed line descriptor is highly discrimi-native, while remaining robust to viewpoint changes and occlusions. We evaluate our approach against previous line detection and description methods on several multi-view datasets created with homographic warps as well as real-world viewpoint changes. Our full pipeline yields higher repeatability, localization accuracy and matching metrics, and thus represents a ﬁrst step to bridge the gap with learned feature points methods. Code and trained weights are avail-able at https://github.com/cvg/SOLD2. 1.

Introduction
Feature points are at the core of many computer vision tasks such as Structure-from-Motion (SfM) [13, 44], Simul-taneous Localization and Mapping (SLAM) [35], large-scale visual localization [41, 46] and 3D reconstruction [9], due to their compact and robust representation. Yet, the world is composed of higher-level geometric structures which are semantically more meaningful than points. Among these structures, lines can offer many beneﬁts compared to points.
Lines are widespread and frequent in the world, especially in man-made environments, and are still present in poorly textured areas. In contrast to points, they have a natural ori-entation, and a collection of lines provide strong geometric
* Authors contributed equally.
Figure 1: Line segment detection and matching. Our ap-proach detects repeatable lines and is able to match sub-segments to handle partial occlusions. On the right, lines of the same color are matched together. clues about the structure of a scene [57, 49, 15]. As such, lines represent good features for 3D geometric tasks.
Previous methods to detect line segments in images often relied on image gradient information and handcrafted ﬁl-ters [53, 1]. Recently, deep learning has also enabled robust and real-time line detection [18]. Most learned line detectors are however tackling a closely related task: wireframe pars-ing, which aims at inferring the structured layout of a scene based on line segments and their connectivity [17, 63, 59, 64].
These structures provide strong geometric cues, in particular for man-made environments. Yet, these methods have not been optimized for repeatability across images, a vital fea-ture for multi-view tasks, and their training requires ground truth lines that are cumbersome to manually label [17].
The traditional way to match geometric structures across images is to use feature descriptors. Yet, line descriptors face several challenges: line segments can be partially occluded, their endpoints may not be well localized, the scale of the area to describe around each line ﬂuctuates a lot, and it can be severely deformed under perspective and distortion 11368
changes [43]. Early line descriptors focused on extracting a support region around each line and on computing gradient statistics on it [56, 61]. More recently, motivated by the success of learned point descriptors [7, 9, 39], a few deep line descriptors have been proposed [24, 51, 23]. However, they are not designed to handle line occlusion and remain sensitive to poorly localized endpoints.
In this work, we propose to jointly learn the detection and description of line segments. To this end, we introduce a self-supervised network, inspired by LCNN [63] and Super-Point [7], that can be trained on any image dataset without any labels. Pretrained on a synthetic dataset, our method is then generalized to real images. Our line detection aims at maximizing the line repeatability and at being as accurate as possible to allow its use in geometric estimation tasks.
The learned descriptor is designed to be robust to occlusions, while remaining as discriminative as the current learned point descriptors. To achieve that, we introduce a novel line matching based on dynamic programming and inspired by sequence alignment in genetics [36] and classical stereo matching [8]. Thus, our self-supervised occlusion-aware line description and detection (SOLD2) offers a generic pipeline that aims at bridging the gap with the recent learned feature point methods. Overall, our contributions can be summa-rized as follows:
• We propose the ﬁrst deep network for joint line segment detection and description.
• We show how to self-supervise our network for line detec-tion, allowing training on any dataset of real images.
• Our line matching procedure is robust to occlusion and achieves state-of-the-art results on image matching tasks. 2.