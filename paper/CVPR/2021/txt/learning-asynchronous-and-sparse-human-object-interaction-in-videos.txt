Abstract 1.

Introduction such as the activities, temporal the progression of
Human activities can be learned from video. With is possible to discover not only effective modeling it structure the action labels but also the the of
Automatically recognizing such struc-sub-activities. ture from raw video signal is a new capability that promises authentic modeling and successful recognition of human-object interactions. Toward this goal, we in-troduce Asynchronous-Sparse Interaction Graph Networks (ASSIGN), a recurrent graph network that is able to auto-matically detect the structure of interaction events associ-ated with entities in a video scene. ASSIGN pioneers learn-ing of autonomous behavior of video entities including their dynamic structure and their interaction with the coexisting neighbors. Entities’ lives in our model are asynchronous to those of others therefore more ﬂexible in adapting to com-plex scenarios. Their interactions are sparse in time hence more faithful to the true underlying nature and more ro-bust in inference and learning. ASSIGN is tested on human-object interaction recognition and shows superior perfor-mance in segmenting and labeling of human sub-activities and object affordances from raw videos. The native abil-ity of ASSIGN in discovering temporal structure also elim-inates the dependence on external segmentation that was previously mandatory for this task.
Human activities are strongly connected to the surround-ing environment and the objects in it. The interactions be-tween human and object entities observed in videos are a fundamental clue toward a deep understanding of human behavior and the surrounding world [8]. This capability is reﬂected in the human-object interaction (HOI) recognition task, in which human sub-activities (such as drinking) and object affordances (such as drinkable) are segmented and recognized from a video by analyzing the interactive re-lations between entities (Fig. 1). These relations naturally form a spatio-temporal graph where entities (humans or ob-jects) and their dynamic interactions evolve throughout the activity. Although entities can be detected and tracked from video, it is challenging to build a graph model that can au-tomatically discover the temporal structure of activities and natively reﬂect the complex and intricate nature of these in-teractions.
Currently available approaches applied conditional ran-dom ﬁelds [14, 17, 18] and graph neural networks [6, 30] to model the spatio-temporal entity interaction graph. These models assume knowledge of the temporal structure of the video and are limited to the task of assigning activity and affordance labels to the segments.
Rather than this cascaded approach, we exploit the fact that structure and content of events are tightly coupled and may support each other toward the optimal solution in a 16041
joint discovery scheme. Such scheme further allows to break the common assumption that entities in a video are always active and interact continuously. In reality, unlike regularly captured video frames, interactions between enti-ties happen sparsely in time. This suggests that temporal relations in the interaction graph can be pruned into a more concise and efﬁcient graph structure. Authentic modeling of the asynchronous lives of entities allows them to act in-dependently and only update their state when needed.
In light of that, we introduce Asynchronous-Sparse Inter-action Graph Networks (ASSIGN), a joint structure-content discovery framework for sparse and asynchronous human-object interactions. ASSIGN stands on the principle that each entity has an independent life in a video, where each entity behaves and interacts with its coexisting neighbors at its own pace and timing. The temporal structure and the labels of events are discovered jointly using a ﬂexible two-layer dynamic graph network, that can do inference and be trained end-to-end without dependence on external tempo-ral segmentation of events.
We demonstrate the segmentation and labeling capabil-ities of ASSIGN on two major human-object interaction datasets, where ASSIGN attains superior quantitative per-formance and more realistic qualitative results when com-pared to related methods.
In summary, this paper makes three major contributions:
•
•
•
Constructs the ﬁrst end-to-end graph model that jointly learns temporal structure and content label of human-object interaction activities;
Effectively models the sparse and asynchronous enti-ties lives in the context of a social activity; and
Permits efﬁcient relational inference that can skip un-necessary operations, which results in increased ro-bustness to a wide variety of event structures. 2.