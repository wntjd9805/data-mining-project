Abstract 1.

Introduction
Tracking by natural language speciﬁcation is a new ris-ing research topic that aims at locating the target object in the video sequence based on its language description. Com-pared with traditional bounding box (BBox) based tracking, this setting guides object tracking with high-level seman-tic information, addresses the ambiguity of BBox, and links local and global search organically together. Those ben-eﬁts may bring more ﬂexible, robust and accurate track-ing performance in practical scenarios. However, exist-ing natural language initialized trackers are developed and compared on benchmark datasets proposed for tracking-by-BBox, which can’t reﬂect the true power of tracking-by-language. In this work, we propose a new benchmark speciﬁcally dedicated to the tracking-by-language, includ-ing a large scale dataset, strong and diverse baseline meth-ods. Speciﬁcally, we collect 2k video sequences (contains a total of 1,244,340 frames, 663 words) and split 1300/700 for the train/testing respectively. We densely annotate one sentence in English and corresponding bounding boxes of the target object for each video. We also introduce two new challenges into TNL2K for the object tracking task, i.e., ad-versarial samples and modality switch. A strong baseline method based on an adaptive local-global-search scheme is proposed for future works to compare. We believe this benchmark will greatly boost related researches on natural language guided tracking.
*The ﬁrst two authors contribute equally to this work. Yaowei
Wang is the corresponding author. Email: {wangx03, shuxj, wangyw, tianyh}@pcl.ac.cn, zhangzhipeng2017@ia.ac.cn, jiangbo@ahu.edu.cn, fengwu@ustc.edu.cn.
Single object tracking is one of the most important tasks in computer vision and it has been widely used in many applications such as video surveillance, robotics, and au-tonomous vehicles. Usually, they initialize the target object in the ﬁrst frame with a bounding box (BBox), as shown in
Fig. 1 (a), and adjust the BBox along with the movement of the target object. Most of the existing single object track-ers [20–22, 53, 55, 66] are developed based on this setting1, and many benchmark datasets [15, 23, 37, 42, 50, 57, 58] are proposed for this task.
Although these trackers have been adopted in many ap-plications, however, the setting of tracking-by-BBox still suffers from the following issues. (1) The target object in the ﬁrst frame with a BBox is inconvenient to initialize in practical scenarios. In another word, the initialization limits the wide applications of existing BBox initialized trackers. (2) The initialized BBox may be not optimal for the repre-sentation of target object which may lead to ambiguity. As shown in Fig. 1 (a), the tracker may be confused to track the bike or lower body of the pedestrian. Similar views can also be found in [17, 36, 54, 64]. (3) Current BBox-based trackers may perform poorly when facing abrupt appear-ance variation of the target object, like face/cloth changing or species variation in Fig. 1 (b). Because the appearance feature initialized in the ﬁrst frame and the object in the tracking procedure are vastly different. Only one sample initialized in the ﬁrst frame is not enough to handle these challenging scenarios. These observations all inspire us to begin to think about how can we conduct tracking in a more applicable and accurate way? 1https : / / github . com / wangxiao5791509 / Single _
Object_Tracking_Paper_List 113763
bile. For each video, we densely annotate the location infor-mation of the target object for each frame and one sentence in English for the whole video. Speciﬁcally, we describe the category, shape, attributes, properties, and spatial location of the target object which will provide rich ﬁne-grained ap-pearance information and high-level semantic information for tracking. We select 1, 300 videos for training and the rest 700 videos for evaluation. Our videos also reﬂect two attributes for the tracking task, i.e., the adversarial samples and modality switch between RGB and thermal data. To provide a baseline method for other researchers to compare, we design a simple but strong algorithm based on an adap-tive local-global-search scheme. Speciﬁcally, three kinds of baseline results are provided, i.e., Tracking-by-BBox,
Tracking-by-Language, Tracking-by-BBox and Language.
The contributions of this paper can be summarized in the following three aspects:
• We propose the TNL2K dataset for the natural language-based tracking which consists of 2, 000 video se-quences. It aims at offering a dedicated platform for the de-velopment and assessment of natural language-based track-ing algorithms.
• We propose a simple but strong baseline approach (termed AdaSwitcher) for future works to compare, which can switch between the local tracking algorithm and global grounding module adaptively.
• To provide extensive baselines for the comparison on
TNL2K dataset, we also evaluate more than 40 represen-tative BBox-based trackers and analyze their performance using different evaluation metrics. 2.