Abstract
While state of the art image segmentation models typ-ically output segmentations in raster format, applications in geographic information systems often require vector polygons. To help bridge the gap between deep network output and the format used in downstream tasks, we add a frame ﬁeld output to a deep segmentation model for extracting buildings from remote sensing images.
We train a deep neural network that aligns a predicted
This additional frame ﬁeld to ground truth contours. objective improves segmentation quality by leveraging multi-task learning and provides structural information that later facilitates polygonization; we also introduce a polygonization algorithm that that utilizes the frame
Our code
ﬁeld along with the raster segmentation. is available at https://github.com/Lydorn/
Polygonization-by-Frame-Field-Learning. 1.

Introduction
Due to their success in processing large collections of noisy images, deep con-volutional neural networks (CNNs) have achieved state-of-the-art in remote sensing segmentation. Geographic in-formation systems like Open
Street Map (OSM) [29], how-ever, require segmentation data in vector format (e.g., polygons and curves) rather than raster format, which is generated by segmentation net-works. Additionally, methods that extract objects from re-mote sensing images require especially high throughput to handle the volume of high-resolution aerial images captured daily over large territories of land. Thus, modiﬁcations to the conventional CNN pipeline are necessary.
Figure 1: A frame ﬁeld output by our network.
Existing work on deep building segmentation gener-ally falls into one of two general categories. The ﬁrst vectorizes the probability map produced by a network a posteriori, e.g., by using contour detection (march-ing squares [25]) followed by polygon simpliﬁcation (Ramer–Douglas–Peucker [30, 13]). Such approaches suf-fer when the classiﬁcation maps contain imperfections such as smoothed out corners, a common artifact of conven-tional deep segmentation methods. Moreover, as we show in Fig. 2, even perfect probability maps are challenging to polygonize due to shape information being lost from the discretization of the raster output. To improve the ﬁnal polygons, these methods employ expensive and complex post-processing procedures. ASIP polygonization [20] uses polygonal partition reﬁnement to approximate shapes from the output probability map based on a tunable parameter controlling the trade-off between complexity and ﬁdelity.
In [42], a decoder and a discriminator regularize output probability maps adversarially. This requires computing large matrices of pairwise discontinuity costs between pix-els and involves adversarial training, which is less stable than conventional supervised learning.
Another category of deep segmentation methods learns a vector representation directly.
For example, Curve-GCN [23] trains a graph convolutional network (GCN) to deform polygons iteratively, and PolyMapper [21] uses a recurrent neural network (RNN) to predict vertices one at a time. While these approaches directly predict polygon parameters, GCNs and RNNs suffer from several disad-vantages. Not only are they more difﬁcult to train than
CNNs, but also their output topology is restricted to simple polygons without holes—a serious limitation in segment-ing complex buildings. Additionally, adjoining buildings with common walls are common, especially in city centers.
Curve-GCN and PolyMapper are unable to reuse the same polyline in adjoining buildings, yielding overlaps and gaps.
We introduce a building extraction algorithm that avoids the challenges above by adding a frame ﬁeld output to a fully-convolutional network (see Fig. 1). While this has im-perceptible effect on training or inference time, the frame
ﬁeld not only increases segmentation performance, e.g., yielding sharper corners, but also provides useful informa-tion for vectorization. Additional losses learn a valid frame
ﬁeld that is consistent with the segmentation. These losses regularize the segmentation, similar to [37], which includes 5891
MRF/CRF regularization terms in the loss function to avoid extra MRF/CRF inference steps.
The frame ﬁeld allows us to devise a straightfor-ward polygonization method extending the Active Contours
Model (ACM, or “snakes”) [19], which we call the Active
Skeleton Model (ASM). Rather than ﬁtting contours to im-age data, ASM ﬁts a skeleton graph, where each edge con-nects two junction nodes with a chain of vertices (i.e., a polyline). This allows us to reuse shared walls between ad-joining buildings. To our knowledge, no existing method handles this case ([38] shows results with common walls but does not provide details). Our method naturally handles large buildings and buildings with inner holes, unlike end-to-end learning methods like PolyMapper [21]. Lastly, our polygon extraction pipeline is highly GPU-parallelizable, making it faster than more complex methods.
Our main contributions are: (i) a learned frame ﬁeld aligned to object tangents, which improves segmentation via multi-task learning; (ii) coupling losses between outputs for self-consistency, further leveraging multi-task learning; and (iii) a fast polygonization method leveraging the frame
ﬁeld, allowing complexity tuning of a corner-aware simpliﬁcation step and handling non-trivial topology. 2.