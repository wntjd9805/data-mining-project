Abstract
We present a novel mirror segmentation method that leverages depth estimates from ToF-based cameras as an additional cue to disambiguate challenging cases where the contrast or relation in RGB colors between the mirror re-ﬂection and the surrounding scene is subtle. A key observa-tion is that ToF depth estimates do not report the true depth of the mirror surface, but instead return the total length of the reﬂected light paths, thereby creating obvious depth dis-continuities at the mirror boundaries. To exploit depth in-formation in mirror segmentation, we ﬁrst construct a large-scale RGB-D mirror segmentation dataset, which we subse-quently employ to train a novel depth-aware mirror segmen-tation framework. Our mirror segmentation framework ﬁrst locates the mirrors based on color and depth discontinuities and correlations. Next, our model further reﬁnes the mirror boundaries through contextual contrast taking into account both color and depth information. We extensively validate our depth-aware mirror segmentation method and demon-strate that our model outperforms state-of-the-art RGB and
RGB-D based methods for mirror segmentation. Experi-mental results also show that depth is a powerful cue for mirror segmentation. 1.

Introduction
Mirrors are commonly present in human-made scenes, e.g., as personal grooming aids, to create the illusion of enlarged room size, or to enhance safety to enable look-ing around corners or behind the viewer. Yet, mirrors con-fuse many vision systems as they are unable to distinguish real from reﬂected scenes. Hence, the ability to segment mirrors is essential for better scene understanding and to improve practical applications. Automatic mirror segmen-tation is a challenging task as mirrors do not exhibit rel-atively ﬁxed patterns or salient features, making it funda-mentally different from other objects/saliency based seg-mentation/detection problems [18, 37, 59, 64]. Early mir-⋆ Xin Yang (xinyang@dlut.edu.cn) and Xiaopeng Wei are the corre-sponding authors. Xin Yang and Bo Dong lead this project.
RGB Image Depth Map MirrorNet
PMD
Ours
GT
Figure 1. Existing mirror segmentation methods such as Mirror-Net [55] and PMD [25] often fail when there is a large variation in contextual contrast/correlation inside the mirror (1st row, blue arrow), large variation outside the mirror in a mirror-like region (2nd row, red arrow), or when the differences are too subtle (3rd row). In contrast, our depth-aware solution is able to accurately segment the mirrors. ror segmentation solutions relied on user interaction [2] or specialized hardware [50]. Recently, Yang et al. [55] in-troduced MirrorNet, a convolutional neural network, that leverages contextual contrasted features to detect content discontinuities inside and outside the mirror. Lin et al. [25] further boost performance by looking at relation and edge cues. However, these learning based methods often fail when the mirror or mirror-like regions exhibit large vari-ations or when the contextual contrast and correlations are too subtle (Figure 1).
Just as 3D perception plays an important role in scene understanding in the human visual system [7], so can depth information help in computer vision for mirror segmenta-tion. A key observation is that mirrors yield an appar-ent depth that is inconsistent with their true depth and the depth of the surrounding environment; the observed appar-ent depth is the depth of the reﬂected scene. As a result, this creates obvious depth discontinuities at mirror bound-aries (e.g., Figure 1, 2nd column), providing a strong cue for delineating mirrors.
To leverage depth information for mirror segmentation and to stimulate further research in depth-aware mirror seg-mentation, we present the ﬁrst RGB-D mirror segmentation dataset of 3, 049 exemplars. To promote diversity and qual-ity, we curate our RGB-D mirror segmentation dataset from 3044
four widely used publicly available datasets, labeled and segmented by professional annotators. In addition, to ef-ﬁciently leveraging depth information for mirror segmenta-tion, we design a novel positioning and delineating network (PDNet). As the name suggests, PDNet consists of two key modules: (i) a positioning module (PM) that detects and locates the mirror by exploring global and local discontinu-ity and correlation cues in both RGB and depth, and (ii) a delineating module (DM) that captures localized disconti-nuities by performing a local contextual contrast, again in both RGB and depth, for reﬁning the mirror boundaries.
We introduce a novel dynamic weighting scheme to fuse the
RGB and depth correlations in the PM to address variability in measurement noise and depth ranges.
We perform extensive validation experiments to demon-strate the efﬁcacy of our approach and demonstrate that depth provides a powerful and complimenting cue for mir-ror segmentation. In summary, our contributions are: 1. the ﬁrst solution to consider both RGB and depth for mirror segmentation; 2. a new RGB-D mirror segmentation dataset to stimulate research using depth in mirror segmentation; 3. a novel depth-aware mirror segmentation network that leverages both RGB and depth discontinuities and cor-relations inside and outside the mirror; and 4. a novel dynamic weighting scheme to fuse RGB and depth correlations. 2.