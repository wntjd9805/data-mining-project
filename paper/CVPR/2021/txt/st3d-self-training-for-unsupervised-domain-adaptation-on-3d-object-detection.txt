Abstract
We present a new domain adaptive self-training pipeline, named ST3D, for unsupervised domain adaptation on 3D object detection from point clouds. First, we pre-train the 3D detector on the source domain with our proposed ran-dom object scaling strategy for mitigating the negative ef-fects of source domain bias. Then, the detector is itera-tively improved on the target domain by alternatively con-ducting two steps, which are the pseudo label updating with the developed quality-aware triplet memory bank and the model training with curriculum data augmentation. These speciﬁc designs for 3D object detection enable the detec-tor to be trained with consistent and high-quality pseudo labels and to avoid overﬁtting to the large number of easy examples in pseudo labeled data. Our ST3D achieves state-of-the-art performance on all evaluated datasets and even surpasses fully supervised results on KITTI 3D object de-tection benchmark. Code will be available at https:
//github.com/CVMI-Lab/ST3D. 1.

Introduction 3D object detection aims to categorize and localize ob-jects from 3D sensor data (e.g. LiDAR point clouds) with many applications in autonomous driving, robotics, virtual reality, to name a few. Recently, this ﬁeld has obtained remarkable advancements [46, 24, 36, 37, 34, 35] driven by deep neural networks and large-scale human-annotated datasets [13, 38].
However, 3D detectors developed on one speciﬁc do-main (i.e. source domain) might not generalize well to novel testing domains (i.e. target domains) due to unavoidable domain-shifts arising from different types of 3D sensors, weather conditions and geographical locations, etc. For instance, a 3D detector trained on data collected in USA cities with Waymo LiDAR (i.e. Waymo dataset [38]) suf-fers from a dramatic performance drop (of over 45%) [41] when evaluated on data from European cities captured by
*equal contribution
†corresponding author
KITTI task using
Figure 1. Performance of ST3D on Waymo
SECOND-IoU [46], compared to other unsupervised (i.e. source only, naive ST), weakly-supervised (i.e. SN [41]) and fully super-vised (i.e. oracle) approaches. Dashed line denotes fully super-vised target labeled data trained SECOND-IoU.
→
Velodyne LiDAR (i.e. KITTI dataset [13]). Though collect-ing more training data from different domains could allevi-ate this problem, it unfortunately might be infeasible given various real-world scenarios and enormous costs for 3D an-notation. Therefore, approaches to effectively adapting 3D detector trained on labeled source domain to a new unla-beled target domain is highly demanded in practical appli-cations. This task is also known as unsupervised domain adaptation (UDA) for 3D object detection.
In contrast to the intensive studies on UDA of the 2D im-age setting [10, 26, 17, 7, 32, 11, 12], few efforts [41] have been made to explore UDA for 3D detection. Meanwhile, the fundamental differences in data structures and network architectures render UDA approaches for image tasks not readily applicable to this problem. For DA on 3D detec-tion, while promising results have been obtained in [41], the method requires object size statistics of the target domain, and its efﬁcacy largely depends on data distributions.
Recently, self-training has emerged as a simple and ef-fective technique for UDA, attaining state-of-the-art perfor-mance on many image recognition tasks [51, 54, 21]. This motivates us to study self-training for UDA on 3D object detection. Self-training starts from pre-training a model on 10368
source labeled data and further iterating between pseudo la-bel generation and model training on unlabeled target data until convergence is achieved. The pseudo label for 3D ob-ject detection includes oriented 3D bounding boxes for lo-calization and object category information. Despite of the encouraging results in image tasks, our study illustrates that naive self-training [44] does not work well in UDA for 3D detection as shown in Fig. 1 (“source only” vs. “naive ST”).
In this paper, we propose ST3D, redesigning the self-training pipeline, for UDA on 3D object detection. First, in model pre-training, we develop random object scaling (ROS), a simple 3D object augmentation technique, ran-domly scaling the 3D objects to overcome the bias in object size on the labeled source domain. Second, for pseudo la-bel generation, we develop a quality-aware triplet memory bank (QTMB) which encompasses an IoU-based box scor-ing criterion to directly assess the quality of pseudo boxes, a triplet box partition scheme to avoid assigning pseudo la-bels to ambiguous examples, and a memory bank, integrat-ing historical pseudo labels via ensemble and voting, to re-duce pseudo label noise and stabilize training. Finally, in the model training process, we design a curriculum data augmentation (CDA) strategy, progressively increasing the intensity of augmentation, to guarantee effective learning at the beginning and gradually simulate hard examples to improve the model, preventing it from overﬁtting to easy examples – pseudo-labeled data with high conﬁdence.
Experimental results on four 3D object detection datasets
KITTI [13], Waymo [38], nuSenses [4], and Lyft [20] demonstrate the effectiveness of our approach, where the performance gaps between source only results and fully supervised oracle results are closed by a large percentage (16% 75% ). Besides, we outperform the existing ap-proach [41] by a notable margin on all evaluated settings.
It’s also noteworthy that our approach even outperforms the oracle results on the Waymo
KITTI setting when further combined with existing approach [41] as shown in Fig. 1.
→
∼ 2.