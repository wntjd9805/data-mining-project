Abstract
Universal domain adaptation (UniDA) has been pro-posed to transfer knowledge learned from a label-rich source domain to a label-scarce target domain without any constraints on the label sets. In practice, however, it is dif-ﬁcult to obtain a large amount of perfectly clean labeled data in a source domain with limited resources. Existing
UniDA methods rely on source samples with correct anno-tations, which greatly limits their application in the real world. Hence, we consider a new realistic setting called
Noisy UniDA, in which classiﬁers are trained with noisy labeled data from the source domain and unlabeled data with an unknown class distribution from the target domain.
This paper introduces a two-head convolutional neural net-work framework to solve all problems simultaneously. Our network consists of one common feature generator and two classiﬁers with different decision boundaries. By optimiz-ing the divergence between the two classiﬁers’ outputs, we can detect noisy source samples, ﬁnd “unknown” classes in the target domain, and align the distribution of the source and target domains. In an extensive evaluation of different domain adaptation settings, the proposed method outper-formed existing methods by a large margin in most settings. 1.

Introduction
Deep neural networks (DNNs) have achieved impressive results with large-scale annotated training samples, but the performance declines when the domain of the test data dif-fers from the training data. To address this type of distribu-tion shift between domains with no extra annotations, unsu-pervised domain adaptation (UDA) has been proposed to learn a discriminative classiﬁer while there is a shift be-tween training data in the source domain and test data in the target domain [1, 8, 9, 11, 25, 27, 27, 29, 33, 36].
Most existing domain adaptation methods assume that the source and target domains completely share the classes, but we do not know the class distribution of samples in the target domain in real-world UDA. Universal domain adap-Figure 1: Problem setting of Noisy UniDA. Our proposed setting assumes that some source samples have corrupted labels, some classes of the source domain do not appear in the target domain, and the classes of some target samples are not shared by the source domain. tation (UniDA) [41] is proposed to remove the constraints on the label sets, where target samples may contain un-known samples belonging to classes that do not appear in the source domain and some source classes may not appear in the target samples. However, UniDA is still an ideal sce-nario, where existing UniDA methods require source sam-ples with correct annotations to train the model. This re-quirement limits the application of existing UniDA meth-ods in real domain adaptation problems, where clean and high-quality datasets are time consuming and expensive to collect. Data can more easily be collected from a crowd-sourcing platform or crawled from the Internet or social me-dia, but such data are inevitably corrupted with noise (e.g.
YFCC100M [35], Clothing1M [40], and ImageNet [3]).
Hence, we consider a new realistic setting called “Noisy
Universal Domain Adaptation” (Noisy UniDA), as shown in Fig. 1, which has the following properties:
• Labeled data of the source domain contains noisy la-bels. 1
• Some classes of the source domain do not appear in the target domain, and these classes are named source 1The labels of target samples are not considered because they are not available in the setting of UDA. 12515
private classes.
• Some classes of the target domain are not shared by the source domain, and these classes are named target private classes.
Some existing methods [28, 17, 30, 7, 41] aim to solve certain parts of Noisy UniDA. For example, [30] attempted to train domain-adaptive models on noisy source data, [7] worked on the partial problem that the source private classes are absent from the target domain, [28] and [17] attempted to solve the open-set problem of target private classes, and
[41] addressed the settings with the partial problem and the open-set problem together. However, a method that can solve all these problems at the same time does not exist.
Instead of solving each problem separately, we focus on the divergence of DNNs to address all the problems of
Noisy UniDA. Inspired by Co-training for multi-view learn-ing and semi-supervised learning [4, 31], when different models having different parameters are trained on the same data, they learn distinct views of each sample because they have different abilities to learn. As a result, different mod-els in each view would agree on the labels of most samples, and it is unlikely for compatible classiﬁers trained on in-dependent views to agree on a wrong label. We ﬁnd this property can be effective in Noisy UniDA, where the noisy source samples have wrong labels, and target private sam-ples can also be considered to have incorrect labels because their true label is not contained in the label set. When these data are input to different networks, the networks are more likely to output different results because they have differ-ent parameters. Therefore, we utilize a two-head network architecture with two independent classiﬁers to detect all these unwanted samples simultaneously.
The proposed two-head network consists of one common feature generator and two separate label classiﬁers for clas-siﬁcation. The two classiﬁers are updated by the same data at the mini-batch level, but they are initialized differently to obtain different classiﬁers. To detect noisy source samples in each mini-batch, we calculate the divergence between the two classiﬁers’ outputs on the source data, and only source samples with small divergences are chosen to update the network by supervised loss. Using the same principle, tar-get samples with larger divergence are more likely to be tar-get private samples, and we further separate the divergence of the classiﬁers on common and target private samples to reject target private samples. Consequently, we align the distributions of the clean samples from the common classes shared by both domains, where the methods that align the entire distribution are inﬂuenced by incorrect source labels, the source private classes and target private classes.
We evaluated our method on a diverse set of domain adaptation settings. In many settings, our method outper-forms existing methods by a large margin. We summarize the contributions of this paper as follows:
Method
Noisy labels Partial DA Open-set DA
DANN [10]
TCL [30]
ETN [7]
STA [17]
UAN [41]
DANCE [24]
Proposed
✗
✓
✗
✗
✗
✗
✓
✗
✗
✓
✗
✓
✓
✓
✗
✗
✗
✓
✓
✓
✓
Table 1: Summary of recent related methods. UniDA con-sists of Partial DA and Open-set DA. Our proposed method is the only method that covers all the settings.
• We propose a novel experimental setting and a novel training methodology for noisy universal domain adap-tation (Noisy UniDA).
• We propose a divergence optimization framework to detect noisy source samples, ﬁnd target private sam-ples, and align the distributions of the source and tar-get domains according to the divergence of two label classiﬁers.
• We evaluate our method across several real-world do-main adaptation tasks. 2.