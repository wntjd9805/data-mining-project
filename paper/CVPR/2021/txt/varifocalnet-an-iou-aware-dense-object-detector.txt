Abstract
Accurately ranking the vast number of candidate detec-tions is crucial for dense object detectors to achieve high performance. Prior work uses the classiﬁcation score or a combination of classiﬁcation and predicted localization scores to rank candidates. However, neither option re-sults in a reliable ranking, thus degrading detection per-formance. In this paper, we propose to learn an Iou-Aware
Classiﬁcation Score (IACS) as a joint representation of ob-ject presence conﬁdence and localization accuracy. We show that dense object detectors can achieve a more accu-rate ranking of candidate detections based on the IACS. We design a new loss function, named Varifocal Loss, to train a dense object detector to predict the IACS, and propose a new star-shaped bounding box feature representation for
IACS prediction and bounding box reﬁnement. Combining these two new components and a bounding box reﬁnement branch, we build an IoU-aware dense object detector based on the FCOS+ATSS architecture, that we call VarifocalNet or VFNet for short. Extensive experiments on MS COCO show that our VFNet consistently surpasses the strong base-line by ∼2.0 AP with different backbones. Our best model
VFNet-X-1200 with Res2Net-101-DCN achieves a single-model single-scale AP of 55.1 on COCO test-dev, which is state-of-the-art among various object detectors. Code is available at: https://github.com/hyz-xmaster/VarifocalNet. 1.

Introduction
Modern object detectors, regardless of being a two-stage method [1–4] or a one-stage method [5–9], usually ﬁrst generate a redundant set of bounding boxes with classiﬁ-cation scores and then deploy non-maximum suppression (NMS) to remove duplicated bounding boxes on the same object. Generally, the classiﬁcation score is used to rank the bounding box in NMS [1–4,8]. However, this harms the de-tection performance, because the classiﬁcation score is not always a good estimate of the bounding box localization accuracy [10] and accurately localized detections with low
Figure 1: An illustration of our method. Instead of learning to predict the class label (a) for a bounding box, we learn the
IoU-aware classiﬁcation score (IACS) as its detection score which merges the object presence conﬁdence and localiza-tion accuracy (b). We propose a varifocal loss for train-ing a dense object detector to predict the IACS, and a star-shaped bounding box feature representation (the features at nine yellow sampling points) for IACS prediction. With the new representation, we reﬁne the initially regressed box (in red) into a more accurate one (in blue). classiﬁcation scores may be mistakenly removed in NMS.
To solve the problem, existing dense object detectors predict either an additional IoU score [11] or a centerness score [9] as the localization accuracy estimation, and mul-tiply them by the classiﬁcation score to rank detections in
NMS. These methods can alleviate the misalignment prob-lem between the classiﬁcation score and the object localiza-tion accuracy. However, they are sub-optimal, because mul-tiplying the two imperfect predictions may lead to a worse rank basis and we show in Section 3 that the upper bound of the performance achieved by such methods is limited. Be-sides, adding an extra network branch to predict the local-ization score is not an elegant solution and incurs additional computation burden. 8514
To overcome these shortcomings, we naturally would like to ask: Instead of predicting an additional localiza-tion accuracy score, can we merge it into the classiﬁcation score? That is, predict a localization-aware or IoU-aware classiﬁcation score (IACS) that simultaneously represents the presence of a certain object class and the localization accuracy of a generated bounding box.
In this paper, we answer the above question and make (1) We show that accurately the following contributions. ranking candidate detections is critical for high performing dense object detectors, and IACS achieves a better ranking than other methods (Section 3). (2) We propose a new Var-ifocal Loss for training dense object detectors to regress the
IACS. (3) We design a new star-shaped bounding box fea-ture representation for computing the IACS and reﬁning the bounding box. (4) We develop a new dense object detector based on the FCOS [9]+ATSS [12] and the proposed com-ponents, named VarifocalNet or VFNet for short, to exploit the advantage of the IACS. An illustration of our method is shown in Figure 1.
The Varifocal Loss, inspired by the focal loss [8], is a dynamically scaled binary cross entropy loss. However, it supervises the dense object detector to regress continuous
IACSs, and more distinctively it adopts an asymmetrical training example weighting method. It down-weights only negative examples for addressing the class imbalance prob-lem during training, and yet up-weights high-quality posi-tive examples for generating prime detections. This focuses the training on high-quality positive examples, which is im-portant to achieve a high detection performance.
The star-shaped bounding box feature representation uses the features at nine ﬁxed sampling points (yellow cir-cles in Figure 1) to represent a bounding box with the de-formable convolution [13, 14]. Compared to the point fea-ture used in most existing dense object detectors [7–9, 15], this feature representation can capture the geometry of the bounding box and its nearby contextual information, which is essential for predicting an accurate IACS. It also enables us to effectively reﬁne the initially generated coarse bound-ing box without losing efﬁciency.
To verify the effectiveness of our proposed modules, we build the VFNet based on the FCOS+ATSS and evaluate it on COCO benchmark [16]. Experiments show that our
VFNet consistently exceeds the strong baseline by ∼2.0
AP with different backbones, and our best model VFNet-X-1200 with Res2Net-101-DCN reaches a single-model single-scale 55.1 AP on COCO test-dev, surpassing previously published best single-model single-scale results. 2.