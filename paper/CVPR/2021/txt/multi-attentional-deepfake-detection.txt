Abstract
Face forgery by deepfake is widely spread over the in-ternet and has raised severe societal concerns. Recently, how to detect such forgery contents has become a hot re-search topic and many deepfake detection methods have been proposed. Most of them model deepfake detection as a vanilla binary classiﬁcation problem, i.e, ﬁrst use a backbone network to extract a global feature and then feed it into a binary classiﬁer (real/fake). But since the differ-ence between the real and fake images in this task is often subtle and local, we argue this vanilla solution is not op-timal. In this paper, we instead formulate deepfake detec-tion as a ﬁne-grained classiﬁcation problem and propose a new multi-attentional deepfake detection network. Speciﬁ-cally, it consists of three key components: 1) multiple spa-tial attention heads to make the network attend to differ-ent local parts; 2) textural feature enhancement block to zoom in the subtle artifacts in shallow features; 3) aggre-gate the low-level textural feature and high-level semantic features guided by the attention maps. Moreover, to address the learning difﬁculty of this network, we further introduce a new regional independence loss and an attention guided data augmentation strategy. Through extensive experiments on different datasets, we demonstrate the superiority of our method over the vanilla binary classiﬁer counterparts, and achieve state-of-the-art performance. The models will be released recently at https://github.com/yoctta/ multiple-attention. 1.

Introduction
Beneﬁting from the great progress in generative mod-els, deepfake techniques have achieved signiﬁcant success recently and various face forgery methods [19, 41, 21, 31, 32, 44, 28, 38] have been proposed. As such techniques can generate high-quality fake videos that are even indistin-guishable for human eyes, they can easily be abused by ma-† Corresponding Author.
Figure 1: Example of the multiple attentional regions ob-tained by our method. The attention regions are separated and respond to different discriminative features. licious users to cause severe societal problems or political threats. To mitigate such risks,many deepfake detection ap-proaches [27, 34, 22, 33, 26, 45] have been proposed. Most of them model deepfake detection as a vanilla binary clas-siﬁcation problem (real/fake). Basically, they often ﬁrst use a backbone network to extract global features of the suspect image and then feed them into a binary classiﬁer to discrim-inate the real and fake ones.
However, as the counterfeits become more and more re-alistic, the differences between real and fake ones will be-come more subtle and local, thus making such global fea-ture based vanilla solutions work not well. But actually, such subtle and local property shares a similar spirit as the
ﬁne-grained classiﬁcation problem. For example, in the
ﬁne-grained bird classiﬁcation task, some species look very similar and only differentiate from each other by some small and local differences, such as the shape and color of the beak. Based on this observation, we propose to model deep-fake detection as a special ﬁne-grained classiﬁcation prob-lem with two categories.
Inspired by the success of parts based model in the 2185
ﬁne-grained classiﬁcation ﬁeld, this paper presents a novel multi-attention network for deepfake detection. First, in order to make the network attend to different potential ar-tifacts regions, we design multi-attention heads to predict multiple spatial attention maps by using the deep semantic features. Second, to prevent the subtle difference from dis-appearing in the deep layers, we enhance the textural feature obtained from shallow layers and then aggregate both low-level texture features and high-level semantic features as the representation for each local part. Finally, the feature rep-resentations of each local part will be independently pooled by a bilinear attention pooling layer and fused as the repre-sentation for the whole image. Figure 1 gives an example of the discriminative features obtained by our method.
However, training such a multi-attentional network is not a trivial problem. This is mainly because that, unlike single-attentional network [6] which can use the video-level labels as explicit guidance and be trained in a supervised way, the multi-attentional structure can only be trained in an unsu-pervised or weakly-supervised way. By using a common learning strategy, we ﬁnd the multi-attention heads will de-grade to a single-attention counterpart, i.e., only one atten-tion region produces a strong response while all remaining attention regions are suppressed and can not capture use-ful information. To address this problem, we further pro-pose a new attention guided data augmentation mechanism.
In detail, during training, we will deliberately blur some high-response attention region (soft attention dropping) and force the network to learn from other attention regions.
Simultaneously, we introduce a new regional independence loss to encourage different attention heads to attend to dif-ferent local parts.
To demonstrate the effectiveness of our multi-attentional network, we conduct extensive experiments on different existing datasets, including FaceForensics++[34], Celeb-DF[25] and DFDC[9]. It shows that our method is superior to the vanilla binary classiﬁer baselines and achieves state-of-the-art performance.
In summary, the contributions of this paper are threefold as below:
• We reformulate the deepfake detection as a ﬁne-grained classiﬁcation task, which brings a novel per-spective for this ﬁeld.
• We propose a new multi-attentional network architec-ture to capture local discriminative features from mul-tiple face attentive regions. To train this network, we also introduce a regional independence loss and design an attention guided data augmentation mechanism to assist the network training in an adversarial learning way.
• Extensive experiments demonstrate that our method outperforms the vanilla binary classiﬁcation baselines and achieves state-of-the-art detection performance. 2.