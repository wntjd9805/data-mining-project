Abstract
Establishing dense correspondences between a pair of images is an important and general problem. However, dense ﬂow estimation is often inaccurate in the case of large displacements or homogeneous regions. For most appli-cations and down-stream tasks, such as pose estimation, image manipulation, or 3D reconstruction, it is crucial to know when and where to trust the estimated matches.
In this work, we aim to estimate a dense ﬂow ﬁeld re-lating two images, coupled with a robust pixel-wise con-ﬁdence map indicating the reliability and accuracy of the prediction. We develop a ﬂexible probabilistic approach that jointly learns the ﬂow prediction and its uncertainty.
In particular, we parametrize the predictive distribution as a constrained mixture model, ensuring better modelling of both accurate ﬂow predictions and outliers. Moreover, we develop an architecture and training strategy tailored for robust and generalizable uncertainty prediction in the con-text of self-supervised training. Our approach obtains state-of-the-art results on multiple challenging geometric match-ing and optical ﬂow datasets. We further validate the use-fulness of our probabilistic conﬁdence estimation for the task of pose estimation. Code and models are available at https://github.com/PruneTruong/PDCNet. 1.

Introduction
Finding pixel-wise correspondences between pairs of images is a fundamental computer vision problem with nu-merous important applications, including dense 3D recon-struction [40], video analysis [33, 45], image registration
[44, 50], image manipulation [11, 28], and texture or style transfer [20, 26]. Dense correspondence estimation has most commonly been addressed in the context of optical
ﬂow [2, 12, 16, 48], where the image pairs represent con-secutive frames in a video. While these methods excel in the case of small appearance changes and limited displace-ments, they cannot cope with the challenges posed by the more general geometric matching task. In geometric match-ing, the images can stem from radically different views of (a) Query image (b) Reference image (c) Baseline (d) PDC-Net (Ours)
Figure 1. Estimating dense correspondences between the query (a) and the reference (b) image. The query is warped according to the resulting ﬂows (c)-(d). The baseline (c) does not estimate an un-certainty map and is therefore unable to ﬁlter the inaccurate ﬂows at e.g. occluded and homogeneous regions. In contrast, our PDC-Net (d) not only estimates accurate correspondences, but also when to trust them. It predicts a robust uncertainty map that identiﬁes ac-curate matches and excludes incorrect and unmatched pixels (red). the same scene, often captured by different cameras and at different occasions. This leads to large displacements and signiﬁcant appearance transformations between the frames.
In contrast to optical ﬂow, the more general dense corre-spondence problem has received much less attention [31, 37, 42, 52]. Dense ﬂow estimation is prone to errors in the presence of large displacements, appearance changes, or homogeneous regions. It is also ill-deﬁned in case of oc-clusions or in e.g. sky, where predictions are bound to be inaccurate (Fig. 1c). For geometric matching applications, it is thus crucial to know when and where to trust the esti-mated correspondences. For instance, pose estimation, 3D reconstruction, and image-based localization require a set of highly robust and accurate matches as input. The predicted dense ﬂow ﬁeld must therefore be paired with a robust con-ﬁdence estimate (Fig. 1d). Uncertainty estimation is also indispensable for safety-critical tasks, such as autonomous driving and medical imaging. In this work, we set out to 5714
expand the application domain of dense correspondence es-timation by learning to predict reliable conﬁdence values.
We propose the Probabilistic Dense Correspondence
Network (PDC-Net), for joint learning of dense ﬂow and uncertainty estimation, applicable even for extreme appear-ance and view-point changes. Our model predicts the con-ditional probability density of the ﬂow, parametrized as a constrained mixture model. However, learning reliable and generalizable uncertainties without densely annotated real-world training data is a highly challenging problem. Stan-dard self-supervised techniques [31, 35, 52] do not faith-fully model real motion patterns, appearance changes, and occlusions. We tackle this challenge by introducing a care-fully designed architecture and improved self-supervision to ensure robust and generalizable uncertainty predictions.
Contributions: Our main contributions are as follows. (i)
We introduce a constrained mixture model of the predictive distribution, allowing the network to ﬂexibly model both accurate predictions and outliers with large errors. (ii) We propose an architecture for predicting the parameters of our predictive distribution, that carefully exploits the informa-tion encoded in the correlation volume, to achieve general-izable uncertainties. (iii) We improve upon self-supervised data generation pipelines to ensure more robust uncertainty estimation. (iv) We utilize our uncertainty measure to ad-dress extreme view-point changes by iteratively reﬁning the prediction. (v) We perform extensive experiments on a va-riety of datasets and tasks. In particular, our approach sets a new state-of-the-art on the Megadepth geometric matching dataset [25], on the KITTI-2015 training set [9], and out-performs previous dense methods for pose estimation on the
YFCC100M dataset [49]. Moreover, without further post-processing, our conﬁdent dense matches can be directly in-put to 3D reconstruction pipelines [40], as shown in Fig. 2. 2.