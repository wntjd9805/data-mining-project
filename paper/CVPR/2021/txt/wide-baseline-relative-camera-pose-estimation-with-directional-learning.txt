Abstract
Modern deep learning techniques that regress the relative camera pose between two images have difﬁculty dealing with challenging scenarios, such as large camera motions result-ing in occlusions and signiﬁcant changes in perspective that leave little overlap between images. These models continue to struggle even with the beneﬁt of large supervised training datasets. To address the limitations of these models, we take inspiration from techniques that show regressing keypoint locations in 2D and 3D can be improved by estimating a discrete distribution over keypoint locations. Analogously, in this paper we explore improving camera pose regression by instead predicting a discrete distribution over camera poses. To realize this idea, we introduce DirectionNet, which estimates discrete distributions over the 5D relative pose space using a novel parameterization to make the estima-tion problem tractable. Speciﬁcally, DirectionNet factorizes relative camera pose, speciﬁed by a 3D rotation and a trans-lation direction, into a set of 3D direction vectors. Since 3D directions can be identiﬁed with points on the sphere,
DirectionNet estimates discrete distributions on the sphere as its output. We evaluate our model on challenging syn-thetic and real pose estimation datasets constructed from
Matterport3D and InteriorNet. Promising results show a near 50% reduction in error over direct regression methods. 1.

Introduction
Estimating the relative pose between two images is fun-damental to many applications in computer vision such as 3D reconstruction, stereo rectiﬁcation, and camera lo-calization [19]. For calibrated cameras, relative pose is synonymous with the essential matrix, which encapsulates the projective geometry relating two views. Prevailing approaches recover the global model from corresponding points [30, 20, 42] within an iterative robust model ﬁtting process [15, 64]. Recent progress has introduced deep-learned modules that can replace components of this classic
∗Work done while Kefan was a member of the Google AI Residency program (g.co/airesidency). pipeline [62, 50, 10, 9, 52, 43, 47, 2]. While this class of techniques has been extensively analyzed [49], well-known failure cases include where feature detection or matching is difﬁcult, such as low image overlap, large changes in scale or perspective, or scenes with insufﬁcient or repeated textures.
In these cases, it is natural to consider if supervised deep learning can address this basic task of essential matrix es-timation, considering its success in tackling a variety of challenging computer vision problems. Speciﬁcally, can we train a deep neural network to represent the complex function that directly maps image pairs to their relative camera pose?
Such a model would provide an appealing alternative to for-mulations that are sensitive to correspondence estimation performance.
Unfortunately, evidence suggests designing regression models for pose estimation is challenging, and in fact ﬁnding a parameterization of the motion groups effective in deep learning models is still an active research topic [33, 66, 44].
Not surprisingly, the initial works exploring relative pose regression (e.g. [38, 46]) are not conclusively successful in the difﬁcult scenarios described above.
In this work we introduce a novel deep learning model for relative pose estimation, focused on the challenging wide-baseline case. Conceptually, our model generates a discrete probability distribution over relative poses, and the ﬁnal pose estimate is taken as the expectation of this distribution. Our method is inspired by works that show estimating a discrete distribution, or a heatmap over a quantized output space, consistently outperforms direct regression to the continuous output space. This conclusion has been observed in differ-ent applications, such as estimating 2D and 3D keypoint locations [55, 32, 57], and estimating periodic angles [25].
However, it is currently unclear if this idea translates di-rectly to complex higher dimensional output spaces. Relative camera pose lives in a ﬁve dimensional space, so predict-ing a discrete distribution would require O(N 5) storage in the output space alone [35]! Given that this is currently in-tractable for neural networks at any reasonable resolution, the question is how can we apply this concept to the relative pose problem effectively?
To this end, we introduce a novel formulation that builds 3258
upon the idea of estimating discrete probability distributions on the 5D relative pose space. We propose two key compo-nents to execute this idea effectively: 1. A parameterization of the motion space that factorizes poses as a set of 3D direction vectors. A non-parametric differentiable projection step can map these directions to their closest pose. 2. DirectionNet, a convolutional encoder-decoder model for predicting sets of 3D direction vectors. The net-work outputs discrete distributions on the sphere S2, the expected values of which produce direction vectors.
Our core contributions are in recognizing that incorporat-ing a dense structured output in the form of a discrete proba-bility distribution can improve wide-baseline relative pose es-timation, and in introducing a technique to execute this idea efﬁciently. The attributes of this approach that help make it effective include (1) DirectionNet is fully-convolutional and as such does not utilize any fully-connected regression layers, and (2) it allows for additional supervision as both the dense distribution and ﬁnal estimated pose can be supervised.
DirectionNet is deployed in two stages, where the relative rotation is estimated ﬁrst, followed by the relative transla-tion direction. This allows us to derotate the input images after the ﬁrst stage, which reduces the complexity of the translation estimation task.
DirectionNet is evaluated on two difﬁcult wide-baseline pose estimation datasets created from the synthetic images in Interior-Net [27], and the real images in Matterport3D
[4]. DirectionNet consistently outperforms direct regres-sion approaches (for the same pose representation as well as numerous alternatives), as well as classic feature-based approaches. This illustrates the effectiveness of estimating discrete probability distributions as an alternative to direct regression even for a complex problem such as relative pose estimation. Furthermore, these results validate that a super-vised data-driven approach for wide-baseline pose estimation can succeed in cases that are extreme for traditional methods. 2.