Abstract l Vote Cluster l Corresponding Seed Points
--- Ground Truth Bounding Box
--- Predicted Bounding Box 3D object detection in point clouds is a challenging vi-sion task that beneﬁts various applications for understand-ing the 3D visual world. Lots of recent research focuses on how to exploit end-to-end trainable Hough voting for generating object proposals. However, the current voting strategy can only receive partial votes from the surfaces of potential objects together with severe outlier votes from the cluttered backgrounds, which hampers full utilization of the information from the input point clouds.
Inspired by the back-tracing strategy in the conventional Hough voting methods, in this work, we introduce a new 3D object detec-tion method, named as Back-tracing Representative Points
Network (BRNet), which generatively back-traces the repre-sentative points from the vote centers and also revisits com-plementary seed points around these generated points, so as to better capture the ﬁne local structural features surround-ing the potential objects from the raw point clouds. There-fore, this bottom-up and then top-down strategy in our BR-Net enforces mutual consistency between the predicted vote centers and the raw surface points and thus achieves more reliable and ﬂexible object localization and class predic-tion results. Our BRNet is simple but effective, which sig-niﬁcantly outperforms the state-of-the-art methods on two large-scale point cloud datasets, ScanNet V2 (+7.5% in terms of mAP@0.50) and SUN RGB-D (+4.7% in terms of mAP@0.50), while it is still lightweight and efﬁcient. 1.

Introduction
As one of the fundamental tasks that aims at understand-ing 3D visual world, 3D object detection would like to predict amodal 3D bounding boxes and associated seman-tic labels of objects in real 3D scenes. 3D object detec-tion technologies would signiﬁcantly beneﬁt various down-stream real world applications such as augmented reality,
*Lu Sheng is the corresponding author. (a) Partial coverage (b) Outliers
Figure 1. The votes generated by VoteNet [20] and its variants usually suffer from (a) partial coverage of the object surfaces, (b) outliers from the cluttered background. By examining the corre-sponding seed points, the generated proposals from these votes receive erratic features with respect to the objects, and may be less reliable for predicting accurate bounding boxes, orientations and even semantic classes. Best viewed on screen. robotics and etc. In this work, we focus on 3D object de-tection from point clouds. It is even more challenging be-cause the irregular, sparse and orderless characteristics of this special 3D input make it a hard task to design reliable point-based 3D object detection systems by leveraging the recent progress in 2D object detection.
While earlier works resorted to reordering point clouds into regular forms [3, 7, 32, 33, 43], or applying predeﬁned shape templates [15, 19, 40], VoteNet [20] and its vari-ants [36, 41, 2, 1] have shown a great success in design-ing end-to-end 3D object detection networks based on raw point clouds. VoteNet reformulates the traditional Hough voting process into a point-wise regression problem, and generates an object proposal by sampling a number of seed points from the input point cloud whose votes are within the same cluster. The aggregated feature in each vote cluster is then used to estimate the 3D bounding box (e.g. center, size and orientation) and the associated semantic label.
Therefore, the quality of the regressed votes principally determine the reliability of the generated proposals, and then the performance on the object detector. However, al-though the clustered vote centers are quite accurate, the 8963
Figure 2. Back-tracing representative points and revisiting seed points. We show the vote cluster center for the two chairs (in pur-ple points). The representative points are back-traced from the vote cluster center (in red points). We set the number of represen-tative points per proposal as 12 in this case, which are illustrated on the right chair. Then, the seed points within a ﬁxed distance of the representative points are revisited, shown in blue points on the left chair. The revisited seed points provide good coverage of the chair’s surface, which imply the object shape and keep the structural details as the chair armrest. Best viewed on screen. votes are usually not as representative as our expectation.
For example, as illustrated in Fig. 1, by retrieving the seed points of votes from the given vote clusters, these cor-responding seed points either partially cover the underly-ing objects (Fig. 1(a)) or contain severe outliers from the cluttered background (Fig. 1(b)). Therefore as shown in
Fig. 1(a), it is undoubted that we cannot accurately predict the bounding box of a long bookshelf if the votes only cap-ture a small area surrounding the vote center. Likewise as shown in Fig. 1(b), the severe outliers make it impossible to accurately detect the chair based on the vote features. More-over, these seed points are less informative due to the lack of knowledge from the votes, so that there will be less signif-icant gains if we simply back-trace these seed features (as in conventional Hough voting [14]) to improve the voting-based 3D object detection methods.
However, in our point of view, back-tracing is still neces-sary and could partially address the aforementioned issues with a special design. To be speciﬁc, as shown in Fig. 2, we would like to backwardly generate (or trace) the virtual representative points from the center of each vote cluster, and use these virtual points to revisit their surrounding seed points. This generative back-tracing operation indicates possible object shape distributions around the vote center, while the revisited seed features provide complementary lo-cal structural clues that may not be fully discovered by the votes. This bottom-up and then top-down process can end up with a mutual interaction that associates the seed features and the vote features, which has the potential to enhance each other features and enable more robust object class pre-diction and more accurate bounding box regression.
To this end, we propose a new point cloud-based 3D ob-ject detection method, named as Back-tracing Representa-tive Point Network (BRNet), by incorporating the end-to-end learnable back-tracing and revisiting operations into the voting-based framework. Speciﬁcally, we propose a repre-sentative points generation module that generatively sam-ples uniformly distributed representative points within the 3D area of a candidate object, based on the features of a vote cluster center. The generated points can coarsely in-fer the object bounding boxes even though their sampling process is class-agnostic. The revisited seed points of each representative point are aggregated in a similar way as ROI grid pooling [28], but based on the spatial layout of the rep-resentative points. After fusing the aggregated features of the revisited seed points and the features of the vote cluster center, we obtain the reﬁned proposals to eventually detect the objects. Note that the proposed bounding box regression scheme explicitly depends on the spatial distribution of the representative points, thus improves robustness with respect to shape variations within and across object categories.
The contributions of this work are three-fold: (1) the ﬁrst 3D object detection network, named as BRNet, that suc-cessfully adapts the back-tracing step of Hough voting to 3D object detection. (2) an end-to-end learnable network that can generatively back-trace the representative points, reliably revisit the seed points, and then mutually reﬁne the object proposals for more robust object classiﬁcation and more accurate bounding box regression. (3) the state-of-the-art 3D object detection performance on two benchmark datasets, ScanNet V2 [4] (50.9% in terms of mAP@0.50) and the SUN RGB-D [31] (43.7% in terms of mAP@0.50), with lightweight model size and high executive efﬁciency. 2.