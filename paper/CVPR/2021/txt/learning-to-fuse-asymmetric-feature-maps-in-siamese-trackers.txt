Abstract
Recently, Siamese-based trackers have achieved promis-ing performance in visual tracking. Most recent Siamese-based trackers typically employ a depth-wise cross-correlation (DW-XCorr) to obtain multi-channel correla-tion information from the two feature maps (target and search region). However, DW-XCorr has several limitations within Siamese-based tracking: it can easily be fooled by distractors, has fewer activated channels and provides weak discrimination of object boundaries. Further, DW-XCorr is a handcrafted parameter-free module and cannot fully ben-eﬁt from ofﬂine learning on large-scale data.
We propose a learnable module, called the asymmetric convolution (ACM), which learns to better capture the se-mantic correlation information in ofﬂine training on large-scale data. Different from DW-XCorr and its predecessor (XCorr), which regard a single feature map as the convo-lution kernel, our ACM decomposes the convolution oper-ation on a concatenated feature map into two mathemati-cally equivalent operations, thereby avoiding the need for the feature maps to be of the same size (width and height) during concatenation. Our ACM can incorporate useful prior information, such as bounding-box size, with stan-dard visual features. Furthermore, ACM can easily be inte-grated into existing Siamese trackers based on DW-XCorr or XCorr. To demonstrate its generalization ability, we in-tegrate ACM into three representative trackers: SiamFC,
SiamRPN++ and SiamBAN. Our experiments reveal the beneﬁts of the proposed ACM, which outperforms existing methods on six tracking benchmarks. On the LaSOT test set, our ACM-based tracker obtains a signiﬁcant improve-ment of 5.8% in terms of success (AUC), over the baseline. 1.

Introduction cently, trackers based on Siamese networks have gained at-tention due to their combined advantage of high speed and tracking performance. The pioneering method, SiamFC [2], utilizes Siamese networks to extract deep convolutional fea-tures from the template in the initial frame of a video and instances inside the search regions of other frames. A cross correlation layer (XCorr) is then used to compute the sim-ilarity between the template and instances. Consequently, the instance with the highest similarity score is considered the target. The XCorr in SiamFC produces a single-channel response map and assumes the target is located near the highest response. As an extension, SiamRPN [26] formu-lates the tracking problem as one-shot detection. It intro-duces a region proposal network (RPN) [34] and utilizes up-channel cross correlation (UP-XCorr). However, UP-XCorr imbalances the parameter distribution, making the training optimization hard. To address this issue, SiamRPN++ in-troduces a depth-wise correlation (DW-XCorr) to efﬁciently generate a multi-channel correlation feature map. Due to its efﬁciency, several recent Siamese trackers [5, 11, 13, 47, 50] also employ DW-XCorr in their frameworks.
As discussed above, most recent Siamese trackers em-ploy DW-XCorr to compute the similarity between the tem-plate and instances. However, both DW-XCorr and its predecessor XCorr are handcrafted parameter-free modules and are not able to fully beneﬁt from large-scale ofﬂine learning. DW-XCorr has several limitations in the context of tracking. First, it produces similar correlation responses for the target and distractors of homogeneous appearance.
To demonstrate this, we analyze the similarity between DW-XCorr features of a target and its distractors in Fig. 1a. The heatmap is generated by performing an L1 normalization n (kxk1 = i=1 |xi|, where x is a pixel in the correlation feature map and n is the number of channels) on every pixel in the DW-XCorr features. As can be seen, DW-XCorr pro-duces high responses (i.e. feature norms) not only near the
P
Visual tracking is a challenging problem, where the task is to estimate the state of an arbitrary target in each frame of a video, given only its location in the initial frame. Re-. ∗Equal contribution. † Corresponding author.
. Our codes are available at: https : / / github . com / wencheng256/SiamBAN-ACM 16570
icantly lower than the global maximum value. This indi-cates that these channels contribute little to the ﬁnal predic-tions. Last, DW-XCorr often produces responses at irrele-vant background. As a consequence, correlation maps are often blurry and do not have clear boundaries, as shown in
Fig. 1e. This is likely to hinder RPN from making accurate and robust predictions.
The aforementioned shortcomings of DW-XCorr and its predecessor XCorr, within Siamese-based trackers, moti-vate us to look into designing a new module that learns to fuse feature maps by beneﬁting from ofﬂine learning on large-scale data. In case of two feature maps (e.g. the tem-plate and sub-window in a search image) having the same size, a straightforward way is to concatenate (fuse) them and then learn a method for joint training by adding con-volutional layers. Here, the additional convolutional layers can learn to discriminate the target and background. How-ever, such a concatenation strategy is non-trivial in the case of Siamese-based trackers since the two feature maps are of different sizes (height and width). Further, the concatena-tion of feature maps of different sizes is desired to be per-formed in an efﬁcient manner to meet the real-time require-ments during inference. 1.1. Contributions
We introduce a novel module, called the asymmetric con-volution (ACM), that avoids the need for the feature maps to be of the same size during concatenation. Our ACM decom-poses the convolution operation on a concatenated feature map into two mathematically equivalent operations. First, it performs convolutions on two feature maps independently using kernels of the same size as that of the template fea-ture map. Then, it performs a summation on the resulting feature maps, through broadcasting [15]. By utilizing the broadcasting of matrix addition, we efﬁciently compute the summation on these different-sized feature maps.
The proposed ACM produces more discriminative fea-tures, as shown in Fig. 1b, with respect to the target (the red rectangle) and distractors (the green rectangle). This enables the tracker to make more robust predictions. Fur-ther, the maximum values of different channels in our ACM are closer, which indicates that more channels carry use-ful information, as shown in Fig. 1d. At the same time,
ACM can effectively suppress background, thereby provid-ing clear boundaries for the target, as in Fig. 1f. We vali-date these advantages by conducting an extensive analysis on 50k different image pairs from the LaSOT train set [12].
Details are presented in §3.2.
In addition to overcoming the aforementioned limita-tions of DW-XCorr, the proposed ACM is ﬂexible and can also incorporate useful additional information. Here, we incorporate prior information in the form of bounding-box (b-box) size (height and width) from the initial frame in a 16571
Figure 1. Comparison between DW-XCorr and ACM in terms of being fooled by distractors (ﬁrst row), information distribu-tion across channels (second row) and background suppres-sion to better discriminative target boundaries (third row).
DW-XCorr produces similar responses for distractors and the tar-get (Fig. 1a). In contrast, ACM produces more distinct responses (Fig. 1b).
In both cases (a and b), red arrows indicate the fea-ture vectors extracted from the correlation feature maps of the corresponding pixels, followed by computing the cosine similar-ity (cosθ = A·B kAkkBk ) between the two feature vectors (A and B).
Only a few channels of DW-XCorr have high response when track-ing a desired target (Fig. 1c). Instead, more channels of ACM map carries high response with different semantic information, such as top right corner (left) or center of target (right), as shown in
Fig. 1d. We show two example feature channels for DW-XCorr and ACM. DW-XCorr maps are blurry and do not accurately cap-ture shape of target (Fig. 1e). In comparison, AC maps suppresses the background, providing clear boundaries of the target (Fig. 1f). target (the red rectangle), but also near other instances. We compute the cosine similarity between the target and one distractor (the green rectangle) and observe a high value (cosθ > 0.8), indicating that DW-XCorr produces similar results for both. This makes it difﬁcult for RPN to effec-tively discriminate the desired target from distractors.
The second limitation is that only a few channels in the
DW-XCorr feature map are activated, i.e. have a high re-sponse when tracking a particular target [25]. To perform cross-correlation, features of different targets are desired to be orthogonal and distributed in different channels, so that correlation feature channels of different targets are sup-pressed and only a few channels of the same target are ac-tivated. The suppressed channels are unable to help RPN in making robust and precise predictions and can reduce the capacity of the model. As shown in Fig. 1c, the max-imum value of a channel with middle response is signif-video. This prior information helps to overcome the lack of accurate target-box locations in the template image, thereby providing guidance to the RPN heads. Furthermore, we show the generalization ability by replacing the standard
DW-XCorr or XCorr with our ACM in three representative
Siamese-based trackers: SiamFC [2], SiamRPN++ [25] and
SiamBAN [5]. Comprehensive experiments on six track-ing benchmarks show the beneﬁts of our ACM, leading to favorable performance against existing methods. On the large-scale LaSOT test set [12], our ACM-based trackers (SiamFC-ACM, SiamRPN++ACM and SiamBAN-ACM) achieve relative gains of 8.6%, 5.7% and 11.3%, in terms of area-under-the-curve (AUC), over their respective base-lines (SiamFC, SiamRPN++ and SiamBAN). 2.