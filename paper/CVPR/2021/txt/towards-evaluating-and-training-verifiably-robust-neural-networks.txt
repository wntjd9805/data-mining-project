Abstract
Recent works have shown that interval bound propaga-tion (IBP) can be used to train veriﬁably robust neural net-works. Reseachers observe an intriguing phenomenon on these IBP trained networks: CROWN, a bounding method based on tight linear relaxation, often gives very loose bounds on these networks. We also observe that most neu-rons become dead during the IBP training process, which could hurt the representation capability of the network.
In this paper, we study the relationship between IBP and
CROWN, and prove that CROWN is always tighter than
IBP when choosing appropriate bounding lines. We further propose a relaxed version of CROWN, linear bound prop-agation (LBP), that can be used to verify large networks to obtain lower veriﬁed errors than IBP. We also design a new activation function, parameterized ramp function (ParamRamp), which has more diversity of neuron status than ReLU. We conduct extensive experiments on MNIST,
CIFAR-10 and Tiny-ImageNet with ParamRamp activation and achieve state-of-the-art veriﬁed robustness. Code is available at https://github.com/ZhaoyangLyu/
VerifiablyRobustNN . 1.

Introduction
Deep neural networks achieve state-of-the-art perfor-mance in many tasks, e.g., image classiﬁcation, object de-tection, and instance segmentation, but they are vulnerable to adversarial attacks. A small perturbation that is imper-ceptible to humans can mislead a neural network’s predic-tion [22, 4, 1, 13, 3]. To mitigate this problem, Madry et al. [15] develop an effective framework to train robust neu-ral networks. They formulate adversarial training as a ro-bust optimization problem. Speciﬁcally, they use projected gradient descent (PGD) to ﬁnd the worst-case adversarial example near the original image and then minimize the loss at this point during training. Networks trained under this framework achieve state-of-the-art robustness under many attacks [34, 26, 18]. However, these networks are only em-perically robust, but not veriﬁably robust. They become vul-nerable when stronger attacks are presented [24, 6, 23]. (a) Constant (b) Tight (c) Adaptive: Case |l| > u (d) Adaptive: Case |l| ≤ u
Figure 1. Illustration of different strategies to choose bounding lines for the three status of a ReLU neuron. Dead: l ≤ u ≤ 0;
Unstable: l < 0 < u; Alive: 0 ≤ l ≤ u. [l, u] is the input range of the neuron. (a) chooses constant bounding lines. (b) is the tight strategy. (c) and (d) are the two cases of unstable neurons in the adaptive strategy. The adaptive strategy chooses the same bound-ing lines as the tight strategy for dead and alive neurons. See more details in Appendix A.7.
This leads to the development of robustness veriﬁcation, which aims to provide a certiﬁcate that a neural network gives consistent predictions for all inputs in some set, usu-ally an lp ball around a clean image. The key of robust-ness veriﬁcation is to compute the lower and upper bounds of the output logits when input can take any value in the lp ball. The exact bounds can be computed through Satisﬁabil-ity Modulo Theory [11] or solving a Mixed Integer Linear
Programming (MILP) problem [23, 5]. Relaxed bounds can be obtained by reduce the bound computation problem to a linear programming (LP) problem [28] or a semideﬁnite programming (SDP) problem [7]. However, these program-ming based methods are expensive and difﬁcult to scale to large networks. To this end, another approach that makes linear relaxations of the nonlinear activation functions in a network is proposed [20, 21, 25, 27, 33, 12]. Figure 1 il-lustrates different strategies to make linear relaxations of a 4308
ReLU neuron. These methods can compute bounds analyti-cally and efﬁciently. In this paper, we focus on the study of
CROWN [33], which can compute relatively tight bounds while being fast. Other similar approaches [20, 21, 25, 27] are either a special case of CROWN or a different view of it as demonstrated by Salman et al. [19].
Wong et al. [28] propose to incorporate bounds com-puted by the aforementioned linear relaxation based meth-ods in the loss function to train veriﬁably robust net-works. Similar approaches are proposed in several other works [16, 8, 17, 24]. However, these methods generally bring heavy computational overhead to the original training process. Gowal et al. [9] propose to use a simple technique, interval bound propagation (IBP), to compute bounds. IBP is fast and can scale to large networks. Despite being loose, IBP outperforms previous linear relaxation based methods in terms of training veriﬁably robust networks.
Zhang et al. [32] further improve this method by combin-ing IBP with the tighter linear relaxation based method,
CROWN. The resulting method is named CROWN-IBP.
They use CROWN-IBP to compute bounds at the initial training phase and achieve the lowest l∞ veriﬁed errors.
We notice that both IBP trained networks [9] and
CROWN-IBP trained networks [32] are veriﬁed by IBP af-ter training. One natural question is whether we can use tighter linear relaxation based methods to verify the net-works to achieve lower veriﬁed error. Surprisingly, Zhang et al. [32] ﬁnd the typically much tighter method, CROWN, gives very loose bounds for IBP trained networks. It seems that IBP trained networks have very different veriﬁcation properties from normally trained networks. We also ﬁnd that CROWN cannot verify large networks due to its high memory cost. Another phenomenon we observe on IBP and
CROWN-IBP trained networks is that most neurons become dead during training. We believe that this could restrict the representation capability of the network and thus hurt its performance. In this paper, we make the following contri-butions to tackle the aforementioned problems: 1. We develop a relaxed version of CROWN, linear bound propagation (LBP), which has better scalabil-ity. We demonstrate LBP can be used to obtain tighter bounds than IBP on both normally trained networks or
IBP trained networks. 2. We prove IBP is a special case of CROWN and LBP.
The reason that CROWN gives looser bounds than IBP on IBP trained networks is that CROWN chooses bad bounding lines when making linear relaxations of the nonlinear activation functions. We prove CROWN and
LBP are always tighter than IBP if they adopt the tight strategy to choose bounding lines as shown in Figure 1. 3. We propose to use a new activation function, param-eterized ramp function (ParamRamp), to train veriﬁ-ably robust networks. Compared with ReLU, where most neurons become dead during training, Param-Ramp brings more diversity of neuron status. Our ex-periments demonstrate networks with ParamRamp ac-tivation achieve state-of-the-art veriﬁed l∞ robustness on MNIST, CIFAR-10 and Tiny-ImageNet. 2.