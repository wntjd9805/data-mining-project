Abstract
LiDAR-based 3D detection in point cloud is essential in the perception system of autonomous driving. In this pa-per, we present LiDAR R-CNN, a second stage detector that can generally improve any existing 3D detector. To fulﬁl-l the real-time and high precision requirement in practice, we resort to point-based approach other than the popular voxel-based approach. However, we ﬁnd an overlooked is-sue in previous work: Naively applying point-based meth-ods like PointNet could make the learned features ignore the size of proposals. To this end, we analyze this problem in detail and propose several methods to remedy it, which bring signiﬁcant performance improvement. Comprehen-sive experimental results on real-world datasets like Way-mo Open Dataset (WOD) and KITTI dataset with various popular detectors demonstrate the universality and supe-riority of our LiDAR R-CNN. In particular, based on one variant of PointPillars, our method could achieve new state-of-the-art results with minor cost. Codes will be released at https://github.com/tusimple/LiDAR_RCNN . 1.

Introduction
For autonomous vehicles and robots, estimating the 7 Degrees-of-Freedom (location, dimension, and orienta-tion) state of the surrounding objects in complicated real-world environments is a vital task. Recently, LiDAR-based 3D object detection has been received increasing atten-tion [29, 25, 23] due to its ability of direct 3D measuremen-t. However, compared with the well developed 2D image detection, LiDAR-based 3D detection still suffers from the intrinsic difﬁculties of point sparsity and large search space in 3D space.
Given that point clouds from LiDAR are irregular, most 3D detection methods transform such data into regular 3D voxel grids [33, 52, 44, 12] or collections of projected 2D view [11, 3, 46, 17, 45, 16, 18]. While these methods can
*The ﬁrst two authors contribute equally to this work. easily take advantage of the ordered data representation by using regular 2D or 3D convolution for feature extraction conveniently, the quantization error in the construction of voxel or multi-view features limits their performance. On the contrary, point-based methods [28, 30, 41, 26, 48] can learn features from the raw point cloud, but usually, they need complicated and inefﬁcient operations [28] to aggre-gate local information. Consequently, these point-based methods are mostly fused with other representations other than individually used for 3D object detection.
In this paper, we are more interested in another setting like R-CNN [9]: We already have a set of proposals in 3D space and seek to reﬁne them. Therefore, we name our method LiDAR R-CNN. When confronting this usage,
PointNet becomes our ﬁrst choice since the network only needs to process the points from a single object in a small region. Compared with the DNN features with rich seman-tic information, the original point cloud contains the most accurate location information. Intuitively, applying Point-Net [27] on the raw point cloud for detection is straight-forward. However, we ﬁnd that the results of such a naive implementation are unsatisfactory. Through careful analy-sis, we ﬁnd an intriguing size ambiguity problem: Different from voxel-based methods that equally divide the space into
ﬁxed size, PointNet only aggregates the features from points while ignoring the spacing in 3D space. Nevertheless, the spacing encodes essential information, such as the scale of the object. To remedy this issue, we propose a series of solutions and prove their effectiveness through detailed ex-periments. Comprehensive evaluation results on the Waymo
Open Dataset(WOD) [34] prove that our proposed LiDAR
R-CNN can improve the performance of various off-the-shelf detectors signiﬁcantly and consistently. With a well-tuned PointPillars model, we even outperform the state-of-the-art models.
To summarize, our contributions are as follows:
• We propose an R-CNN style second-stage detector for 3D object detection based on PointNet. Our method is plug-and-play to any existing 3D detector, and needs no re-training to the base detectors. 7546
• We reveal the size ambiguity problem when using a point-based R-CNN detector. Through careful analy-sis, we propose several different ways to make the de-tector aware of the size of proposal box. Despite the simple design, it achieves signiﬁcant performance im-provements.
• We test our proposed method on WOD [34] and KIT-TI [8] datasets with various base detectors. Our method could consistently improve the base detectors while running at 200fps for 128 proposals on 2080Ti
GPU. 2.