Abstract
In this paper, we diagnose deep neural networks for 3D point cloud processing to explore utilities of different intermediate-layer network architectures. We propose a number of hypotheses on the effects of speciﬁc intermediate-layer network architectures on the representation capacity of DNNs. In order to prove the hypotheses, we design ﬁve metrics to diagnose various types of DNNs from the follow-ing perspectives, information discarding, information con-centration, rotation robustness, adversarial robustness, and neighborhood inconsistency. We conduct comparative stud-ies based on such metrics to verify the hypotheses. We fur-ther use the veriﬁed hypotheses to revise intermediate-layer architectures of existing DNNs and improve their utilities.
Experiments demonstrate the effectiveness of our method.
The code will be released when this paper is accepted. 1.

Introduction
Recently, a series of works use deep neural networks (DNNs) for 3D point cloud processing and have achieved superior performance in various 3D tasks. However, tradi-tional studies usually designed intermediate-layer architec-tures based on empiricism. Exploring and verifying utili-ties of each speciﬁc intermediate-layer architecture from the perspective of a DNN’s representation capacity still present signiﬁcant challenges for state-of-the-art algorithms.
In this study, we aim to bridge the gap between the intermediate-layer architecture and its utilities. Table 1 lists three kinds of utilities considered in this study, including ro-tation robustness, adversarial robustness, and neighborhood inconsistency. Although there are many heuristic insights
∗Wen Shen and Zhihua Wei have equal contributions.
†Quanshi Zhang is the corresponding author. He is with the John
Hopcroft Center and the MoE Key Lab of Artiﬁcial Intelligence, AI In-stitute, at the Shanghai Jiao Tong University, China.
Ve(cid:85)(cid:76)f(cid:76)ab(cid:76)(cid:79)(cid:76)(cid:87)(cid:92)
Intermediate-layer architectures
Rotation robustness
Adversarial robustness
Neighborhood consistency (a) Modules of using information of local density to reweight features [40]. (b) Modules of using information of
P(cid:85)ed(cid:76)c(cid:87)ab(cid:76)(cid:79)(cid:76)(cid:87)(cid:92) –
Impro(cid:89)e (cid:88)(cid:87)ili(cid:87)ies of e(cid:91)is(cid:87)ing DNNs.
X
X – local coordinates to reweight features [40]. (c) Modules of concatenating multi-scale features [18]. (d) Modules of computing orientation-aware features [11].
Verifiability –
X
X –
Predictability
Improve utilities of existing DNNs. – –
X –
Illustration of
Table 1. speciﬁc intermediate-layer architectures. “–” denotes that the utility has not been examined, instead of indicating non-existence of the util-ity. Please see Fig. 1 for architectural details. the veriﬁed utilities of on utilities of existing architectures for 3D point cloud pro-cessing, there does not exist a rigorous and quantitative ver-iﬁcation of such insights.
Therefore, we propose a method to quantitatively di-agnose the utilities of intermediate-layer network architec-tures, which will provide new insights into architectural de-sign. This is a necessary step towards the deep learning with scientiﬁc rigour. Note that, utilities are not necessarily equivariant to advantages. For example, in most cases, the rotation robustness is supposed to be a good property. How-ever, the rotation robustness sometimes requires a DNN not to encode rotation-sensitive but discriminative features.
This study focuses on two terms, i.e. veriﬁability and predictability. In terms of veriﬁability, we design new met-rics to quantify utilities of existing intermediate-layer archi-tectures to prove intuitive insights. In terms of predictabil-ity, we further use the veriﬁed insights to revise other net-works to improve their utilities. Note that, the revision of intermediate-layer architectures generally dose not change the depth of DNNs, so that we eliminate the inﬂuence of the depth change. 10703
More speciﬁcally, we propose a few hypotheses of util-ities of speciﬁc intermediate-layer architectures, as shown in Table 1.
Theoretically, we could analyze speciﬁc intermediate-layer architectures w.r.t. all utilities. However, due to the limit of the page number, we only verify hypothe-ses with stong connection to human intuitions. We design and conduct comparative studies to verify these hypotheses.
The veriﬁed hypotheses are further used to guide the archi-tectural revision of existing DNNs to improve their utilities.
The veriﬁed hypotheses can be summarized as follows.
• The speciﬁc module in [40], which uses the local den-sity information to reweight features (Fig. 1 (a)), improves the adversarial robustness (Table 1 (a)).
• Another speciﬁc module in [40], which uses local 3D coordinates’ information to reweight features (Fig. 1 (b)), improves the rotation robustness (Table 1 (b)).
• The speciﬁc module in [25, 18], which extracts multi-scale features (Fig. 1 (c)), improves the adversarial ro-bustness and the neighborhood consistency (Table 1 (c)).
Neighborhood consistency measures whether a DNN as-signs similar attention to neighboring points.
• The speciﬁc module in [11], which encodes the infor-mation of different orientations (Fig. 1 (d)), improves the rotation robustness (Table 1 (d)).
In order to verify the above hypotheses, we design the following ﬁve evaluation metrics and conduct a number of comparative experiments to quantify utilities of different intermediate-layer architectures. 1. Information discarding and 2. information concen-tration: Information discarding measures how much infor-mation of an input point cloud is forgotten during the com-putation of a speciﬁc intermediate-layer feature. From the perspective of information propagation, the forward propa-gation through layers can be regarded as a hierarchical pro-cess of discarding input information [31]. Ideally, a DNN is supposed to discard information that is not related to the task. Let us take the task of object classiﬁcation for exam-ple. The information of foreground points is usually sup-posed to be related to the task, while that of background points is not related to the task and is discarded.
To this end, we further propose information concentra-tion to measure the gap between the information related to the task and the information not related to the task. Informa-tion concentration can be used to evaluate a DNN’s ability to focus on points related to the task. 3. Rotation robustness: Rotation robustness measures whether a DNN will use the same logic to recognize the same object when a point cloud has been rotated by a ran-dom angle.
In other words, if two point clouds have the same global shape but different orientations, the DNN is supposed to select the same regions/points to compute the intermediate-layer feature. Unlike images with rich color information, point clouds usually only use spatial contexts for classiﬁcation. Therefore, a well-trained DNN is sup-posed to have the rotation robustness. 4. Adversarial robustness: A reliable DNN is supposed to be robust to adversarial attacks. 5. Neighborhood inconsistency1: Neighborhood incon-sistency measures whether adjacent points have similar im-portance in the computation of an intermediate-layer fea-ture. Adjacent points in a 3D object usually have similar shape contexts, so they are supposed to have similar impor-tance. Therefore, ideally, a well-trained DNN should have a low value of neighborhood inconsistency.
The veriﬁed hypotheses are then applied to existing
DNNs to revise their intermediate-layer architectures and improve their utilities. Note that this study aims to verify some insights about intermediate-layer architectures in the scenario of object classiﬁcation, in order to improve utilities of existing DNNs. The classiﬁcation accuracy is reported in supplementary materials.
Note that in comparative studies, unnecessarily complex intermediate-layer architectures usually bring in additional uncertainty, which will prevent our experiments from ob-taining reliable and rigorous results. Therefore, we conduct experiments on simple-yet-classic intermediate-layer archi-tectures.
Contributions of our study are summarized as follows. (1) We propose a few hypotheses on utilities of speciﬁc intermediate-layer architectures. (2) We design ﬁve metrics to conduct comparative studies to verify these hypotheses, which provide new insights into architectural utilities. (3) It is proved that the veriﬁed hypotheses can be used to revise existing DNNs to improve their utilities. 2.