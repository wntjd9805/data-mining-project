Abstract
This paper is about few-shot instance segmentation, where training and test image sets do not share the same object classes. We specify and evaluate a new few-shot anchor-free part-based instance segmenter (FAPIS). Our key novelty is in explicit modeling of latent object parts shared across training object classes, which is expected to facilitate our few-shot learning on new classes in testing.
We specify a new anchor-free object detector aimed at scor-ing and regressing locations of foreground bounding boxes, as well as estimating relative importance of latent parts within each box. Also, we specify a new network for delin-eating and weighting latent parts for the ï¬nal instance seg-mentation within every detected bounding box. Our eval-uation on the benchmark COCO-20i dataset demonstrates that we signiï¬cantly outperform the state of the art. 1.

Introduction
This paper addresses the problem of few-shot instance segmentation. In training, we are given many pairs of sup-port and query images showing instances of a target object class, and the goal is to produce a correct instance segmen-tation of the query given access to the ground-truth instance segmentation masks of the supports. In testing, we are given only one or a very few support images with their ground-truth instance segmentation masks, and a query image in which we are supposed to segment all instances of the tar-get class. Importantly, the training and test image sets do not share the same object classes. Few-shot instance seg-mentation is a basic vision problem.
It appears in many applications where providing manual segmentations of all object instances is prohibitively expensive. The key chal-lenge is how to conduct a reliable training on small data.
Fig. 1 illustrates a common framework for few-shot in-stance segmentation that typically leverages Mask-RCNN
[12, 43, 29]. First, the support and query images are in-put to a backbone CNN and feature pyramid network (FPN)
[23] for computing the supportâ€™s and queryâ€™s feature maps.
Feature Extraction
Query multi-level  feature maps
Support multi-level  feature maps
ğ‘ƒ& o o o
ğ‘ƒ%
ğ‘ƒ& o o o
ğ‘ƒ%
Backbone + FPN
For each ğ‘ƒ$, ğ‘– = 3 â€¦ 7
Channel-wise  multiplication
Query feature map ğ¹!
*
Conditional 
# feature map ğ¹!
Replaced by  our method
Mask R-CNN
Support  feature map ğ¹"
Masked  avg. pool
Support feature  vector ğ‘“"
Query mask ğ‘š!
Query image ğ‘¥!
Support image ğ‘¥"
Support mask ğ‘š"
Figure 1. A common framework of prior work. The query and support image(s) are input to a backbone CNN with feature pyra-mid network (FPN) to extract the feature maps. The supportâ€™s features modulate the queryâ€™s features by channel-wise multipli-cation, resulting in the conditional query features, which are then input to Mask-RCNN for instance segmentation of the query. Our approach replaces Mask-RCNN with two new modules for anchor-free object detection, and part-based instance segmentation.
Second, for every feature map and every supportâ€™s seg-mentation mask, the masked average pooling computes the supportâ€™s feature vector. Third, the supportâ€™s feature vec-tor is used to modulate the queryâ€™s feature maps through a channel-wise multiplication, resulting in the conditional query feature maps. Finally, the conditional query features are forwarded to the remaining modules of Mask-RCNN to produce instance segmentation of the query.
This framework has limitations. First, Mask-RCNN is anchor-based, and hence might overï¬t to particular sizes and aspect ratios of training objects, which do not character-ize new classes in testing. Second, the Mask-RCNN learns feature prototypes [12] which are correlated with the fea-ture map from the backbone in order to produce object seg-mentation. However, the prototypes typically capture global outlines of objects seen in training [12], and hence may not be suitable for segmenting new object classes with entirely 11099
Support feature  vector ğ‘“)
Anchor-Free object 
Detector (AFD)
SimNet
Dense FG classification 
ğ¶ = {ğ‘&,( } (ğ»Ã—ğ‘ŠÃ—1)
Support mask ğ‘š)
Support image ğ‘¥)
Feature 
Extraction (see Fig. 1) 
ğ‘ƒ*
ğ‘ƒ,
ğ‘ƒ+
ğ‘ƒ-ğ‘ƒ.
Head
Head
Head
Head
Head
Query image ğ‘¥!
Conditional query  feature maps
NMS
Dense prediction of bboxes
T = {ğ‘¡&,(} (ğ»Ã—ğ‘ŠÃ—4)
Dense prediction of  importance of latent parts
Î  = ğœ‹&,( (ğ»Ã—ğ‘ŠÃ—ğ½)
Top selected  bboxes  ğ‘$
Part-based Instance 
Segmenter (PIS)
For each  bbox ğ‘$
Part importance  
ğœ‹$ (1Ã—1Ã—ğ½)
Sigmoid
ğ‘›"# instance mask ğ‘š$ (ğ»%Ã—ğ‘Š%Ã—1)
Convolutional layers
ROI-align pooling
PartNet
Part 1
Part 2
â€¦
Part ğ½
*
Part 1
â€¦
Part ğ½
ReLU +
MaxNorm
Part map ğ‘ƒ (ğ»Ã—ğ‘ŠÃ—ğ½)
ROI pooled part map ğ‘ƒ$ (ğ»%Ã—W%Ã—ğ½)
Inner product
Part Assembling
Module (PAM)
Query mask ğ‘š!
Figure 2. Our FAPIS uses the same feature maps as in Fig. 1, and extends prior work with two new modules: anchor-free object detector (AFD) and part-based instance segmentor (PIS). The AFD produces three types of dense predictions for every location (x, y) in the feature map: (a) Figure-ground (FG) classiï¬cation score; (b) Location of the closest bounding box to (x, y); (c) Relative importance of the latent parts for segmentation of the bounding box closest to (x, y). The PIS consists of the PartNet and Part Assembling Module (PAM). The
PartNet predicts activation maps of the latent parts. After NMS selects the top scoring bounding boxes, for every box n, the PAM fuses the part-activation maps according to the predicted part importance for the box n, resulting in the instance segmentation mn. different shapes in testing.
To address these limitations, we propose FAPIS â€“ a new few-shot anchor-free part-based instance segmenter, illus-trated in Fig. 2. In a given query, FAPIS ï¬rst detects bound-ing boxes of the target object class deï¬ned by the support image and its segmentation mask, and then segments each bounding box by localizing a universal set of latent object parts shared across all object classes seen in training.
Our key novelty is in explicit modeling of latent ob-ject parts, which are smaller object components but may not be meaningful (as there is no ground truth for parts).
Unlike the prototypes of [12], our latent parts capture cer-tain smaller components of objects estimated as important for segmentation. As parts may be shared by distinct ob-jects, including new object classes of testing, we expect that accounting for parts will lead to a more reliable few-shot learning than the aforementioned common framework. We are not aware of prior work that learns latent parts for few-shot instance segmentation.
We make two contributions. First, we specify a new anchor-free object detector (AFD) that does not use a set of candidate bounding boxes with pre-deï¬ned sizes and as-pect ratios, called anchors, and, as shown in [39], in this way mitigates over-ï¬tting to a particular choice of anchors.
The AFD (the orange box in Fig. 2) is aimed at three tasks at every location of the queryâ€™s feature map: dense scoring and regressing locations of foreground bounding boxes, as well as dense estimation of a relative importance of the la-tent parts for segmentation. While all of the latent parts are learned to be relevant for object segmentation, differences in sizes and shapes across instances will render some latent parts more important than some others for segmentation of each instance. Thus, the third head in the AFD estimates the part importance which varies across the predicted bounding boxes in the image, as desired. The AFDâ€™s output is passed to the standard non-maximum suppression (NMS) for se-lecting top scoring bounding boxes.
Second, we specify a new Part-based instance segmenter (PIS). The PIS (the yellow box in Fig. 2) is aimed at local-izing and integrating latent object parts to produce the ï¬nal instance segmentation within every NMS-selected bound-ing box. The PIS consists of the PartNet and part assem-bling module (PAM). The PartNet predicts activation maps of the latent parts, called part maps, where large activations 11100
strongly indicate the presence of the corresponding part in the image. Importantly, high activations of a certain latent part at image location (x, y) may not be important for seg-mentation of the object instance at (x, y) (e.g., when several latent parts overlap but do not â€œcoverâ€ the full spatial extent of the instance). Therefore, for every NMS-selected bound-ing box, these part maps are then integrated by the PAM so as to account for the predicted relative importance of the parts for that box. Finally, all instance segmentations form the output query segmentation mask.
Our evaluation on the COCO-20i dataset [29] demon-strates that we signiï¬cantly outperform the state of the art.
In the following, Sec. 2 reviews prior work; Sec. 3 spec-iï¬es our deep architecture; Sec. 4 presents our implementa-tion details and experimental results; and Sec. 5 describes our concluding remarks. 2.