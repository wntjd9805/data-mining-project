Abstract 1.

Introduction
We introduce KeypointDeformer, a novel unsupervised method for shape control through automatically discovered 3D keypoints. We cast this as the problem of aligning a source 3D object to a target 3D object from the same ob-ject category. Our method analyzes the difference between the shapes of the two objects by comparing their latent representations. This latent representation is in the form of 3D keypoints that are learned in an unsupervised way.
The difference between the 3D keypoints of the source and the target objects then informs the shape deformation algo-rithm that deforms the source object into the target object.
The whole model is learned end-to-end and simultaneously discovers 3D keypoints while learning to use them for de-forming object shapes. Our approach produces intuitive and semantically consistent control of shape deformations.
Moreover, our discovered 3D keypoints are consistent across object category instances despite large shape variations.
As our method is unsupervised, it can be readily deployed to new object categories without requiring annotations for 3D keypoints and deformations. Project page: http:
//tomasjakab.github.io/KeypointDeformer.
Given the vast number of 3D shapes available on the
Internet, providing users with intuitive and simple interfaces for semantically manipulating objects while preserving their key shape properties has a wide variety of applications in
AI-assisted 3D content creation. In this paper, we propose to automatically discover intuitive and semantically mean-ingful control points for interactive editing, enabling detail-preserving shape deformation for object categories.
Speciﬁcally, we identify 3D keypoints as an intuitive and simple interface for shape editing. Keypoints are sparse 3D points that are semantically consistent across an object category. We propose a learning framework for unsupervised discovery of such keypoints and a deformation model that uses the keypoints to deform a shape while preserving local shape detail. We call our model KeypointDeformer.
Figure 1 describes the inference-time use case of Key-pointDeformer. Given a novel shape, KeypointDeformer predicts 3D keypoints on the surface. If a user manipulates a keypoint on a chair leg upwards, the entire leg is deformed in the same direction (bottom). Our approach optionally enables the use of a categorical deformation prior on these
* Work done while interning at Google Research. 12783
edits, such that if a user moves one side of an airplane wing backwards, the opposite side of the wing is deformed sym-metrically in the same direction (top)—while if the user wishes to only move one side of the wing, our approach also allows this. Our framework enables stand-alone shape edits or shape alignment between two shapes, and can also synthesize novel variations of shapes for amplifying stock datasets.
While 3D keypoints may be a good proxy for shape edit-ing, obtaining explicit supervision for keypoints and defor-mation models is not only expensive but also ill-deﬁned. As such, we propose an unsupervised framework for jointly dis-covering the keypoints and the deformation model. To solve our problem, we devise two components that operate in con-cert: (1) a method for discovering and detecting keypoints, and (2) a deformation model that propagates keypoint dis-placements to the rest of the shape. To achieve these, we set up a proxy learning task where the goal is to align a source shape with a target shape, where the two can represent very different instances of a category. We also propose a simple yet effective keypoint regularizer that encourages learning of semantically consistent keypoints that are well-distributed, lie close to the object surface and implicitly preserve underly-ing shape symmetries. The result of our training approach is a deformation model that deforms a shape based on automat-ically discovered 3D control keypoints. Since the keypoints are low-dimensional, we can further learn a category prior on these keypoints, enabling semantic shape editing from sparse user inputs.
Overall, our method has following key beneﬁts: 1. It gives users an intuitive and simple way to interac-tively control object shapes. 2. Both the keypoint prediction and deformation model are unsupervised. 3. We show that keypoints discovered by our method are better for shape control than other kinds of keypoints, including manually annotated ones. 4. Our unsupervised 3D keypoints are semantically consis-tent across object instances of the same category giving us sparse correspondences.
We evaluate the semantic consistency of our unsupervised 3D keypoints on standard benchmarks, and achieve state-of-the-art results among unsupervised methods. We also demonstrate the suitability of our keypoints for shape defor-mation. Finally, we provide qualitative results of user-guided interactive shape control, and include videos of interactive shape control on our project page. 2.