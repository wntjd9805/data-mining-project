Abstract
Predicting all applicable labels for a given image is known as multi-label classiﬁcation. Compared to the stan-dard multi-class case (where each image has only one la-bel), it is considerably more challenging to annotate train-ing data for multi-label classiﬁcation. When the number of potential labels is large, human annotators ﬁnd it difﬁ-cult to mention all applicable labels for each training im-age. Furthermore, in some settings detection is intrinsically difﬁcult e.g. ﬁnding small object instances in high resolu-tion images. As a result, multi-label training data is often plagued by false negatives. We consider the hardest version of this problem, where annotators provide only one relevant label for each image. As a result, training sets will have only one positive label per image and no conﬁrmed nega-tives. We explore this special case of learning from miss-ing labels across four different multi-label image classiﬁca-tion datasets for both linear classiﬁers and end-to-end ﬁne-tuned deep networks. We extend existing multi-label losses to this setting and propose novel variants that constrain the number of expected positive labels during training. Surpris-ingly, we show that in some cases it is possible to approach the performance of fully labeled classiﬁers despite training with signiﬁcantly fewer conﬁrmed labels. 1.

Introduction
The majority of work in visual classiﬁcation is focused on the multi-class setting, where each image is assumed to belong to one of L classes. However, the world is intrinsically multi-label: scenes contain multiple objects,
CT scans reveal multiple health conditions, satellite images show multiple terrain types, etc. Unfortunately, it can be prohibitively expensive to obtain the large number of ac-curate multi-label annotations required to train deep neural networks [10]. Heuristics can be used to reduce the required annotation effort [34, 18], but this runs the risk of increasing error in the labels. Even without heuristics, false negatives are common because (i) rare classes are often missed by human annotators [59, 58] and (ii) detecting absence can be more difﬁcult than detecting presence [59]. This may ex-Figure 1.
It is possible to approach the performance of full su-pervision (LBCE) using only one positive label per image. Here we show test MAP as a function of the number of training labels for PASCAL VOC 2012 [13]. Each curve is generated by ran-domly subsampling m% of the images from the training set for m ∈ {10, 20, . . . , 100}. The number of labels per image then determines the number of observed label on the horizontal axis:
LBCE receives all 20 labels per image, while the other methods only receive one positive label per training image. Despite having a factor of 20 times fewer labels, our LROLE approach achieves comparable performance to the fully labeled case (LBCE). plain why even ﬂagship multi-class datasets like ImageNet have been found to include images that actually belong to multiple classes [60]. Since it is generally infeasible to ex-haustively annotate every image for all classes that could be present, there is a natural trade-off between how many im-ages receive annotations and how completely each image is annotated. On one extreme, we could fully annotate images until the labeling budget is exhausted. In this paper we are interested in the other extreme, in which our dataset consists of many images, but each individual image has minimal su-pervision.
We explore the problem of single positive multi-label learning, where only a single positive label (and no other true positives or true negative labels) is observed for each training image. This is a worthwhile problem for at least three reasons: First, an effective method for this setting 933
could allow for signiﬁcantly reduced annotations costs for future datasets. Second, multi-class datasets may have im-ages that actually contain more than one class. For instance, the iNaturalist dataset has many images of insects on plants, but only one is annotated as the true class [53]. Finally, it is of scientiﬁc interest to understand how well multi-label classiﬁers can be made to perform at the minimal limit of supervision. This is particularly interesting because many standard approaches for dealing with missing labels, e.g. learning positive label correlations [6], performing label matrix completion [4], or learning to infer missing labels
[54] break down in the single positive only setting.
We direct attention to this important but underexplored variant of multi-label learning. Our experiments show that training with a single positive label per image allows us to drastically reduce the amount of supervision required to train multi-label image classiﬁers, while only incurring a tolerable drop in classiﬁcation performance (see Figure 1).
We make three contributions: (i) A uniﬁed presentation and extension of existing multi-label approaches to the single positive multi-label learning setting. (ii) A novel single pos-itive multi-label loss that estimates missing labels during training. (iii) A detailed experimental evaluation that com-pares the performance of multiple different losses across four multi-label image classiﬁcation datasets. 2.