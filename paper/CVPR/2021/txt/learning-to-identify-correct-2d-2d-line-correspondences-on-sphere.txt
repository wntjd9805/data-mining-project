Abstract
Man-made Object
Given a set of putative 2D-2D line correspondences, we aim to identify correct matches. Existing methods ex-ploit the geometric constraints. They are only applica-ble to structured scenes with orthogonality, parallelism and coplanarity. In contrast, we propose the ﬁrst approach suit-able for both structured and unstructured scenes. Instead of geometric constraint, we leverage the spatial regularity on sphere. Speciﬁcally, we propose to map line correspon-dences into vectors tangent to sphere. We use these vectors to encode both angular and positional variations of image lines, which is more reliable and concise than directly using inclinations, midpoints or endpoints of image lines. Neigh-boring vectors mapped from correct matches exhibit a spa-tial regularity called local trend consistency, regardless of the type of scenes. To encode this regularity, we design a neural network and also propose a novel loss function that enforces the smoothness constraint of vector ﬁeld. In addi-tion, we establish a large real-world dataset for image line matching. Experiments showed that our approach outper-forms state-of-the-art ones in terms of accuracy, efﬁciency and robustness, and also leads to high generalization. 1.

Introduction 2D-2D correspondences of points and lines1 are the ba-sis of numerous computer vision algorithms [1, 4, 34]. Pu-tative correspondences can be obtained by various meth-ods [26, 41, 15]. In practice, these correspondences con-sist of correct matches, i.e., inliers and mismatches, i.e., outliers. Outliers are caused by viewpoint differences and repetitive patterns. Since outliers drastically affect the al-gorithm robustness, it is important to identify inliers. Iden-tifying inlier point correspondences has been widely stud-ied. Most existing methods are based on geometric con-straint [31, 38] or spatial regularity [44, 42]. The geometric constraint-based methods leverage the fact that all the in-liers can be ﬁtted by the same parametric model, e.g., essen-∗Pyojin Kim and Yun-Hui Liu are co-corresponding authors. 1 We use “line” to represent “line segment” for writing simpliﬁcation. (a) Putative 2D-2D Line Correspondences
Natural Object
Non-associated Endpoints Image-to-sphere
Mapping
Tangent 
Vector
Non-associated Midpoints
Inclinations
Local Trend Consistency (b) Zoom View of Fig. 1(a) (c) Spatial Regularity of Vectors
Figure 1. (a) A pair of lines with the same number represents a 2D-2D line correspondence. Putative correspondences consist of inliers (blue) and outliers (red). (b) Baseline methods use the incli-nations, midpoints, or endpoints to encode the angular, positional, or both angular and positional variations of image lines, respec-tively. (c) We map line correspondences into vectors tangent to sphere. Neighboring vectors mapped from inliers exhibit a local trend consistency (analogous to “a school of ﬁsh”). tial matrix [12]. The spatial regularity-based methods gen-erate 2D displacement vectors, i.e., optical ﬂow [27] by con-necting point correspondences. They leverage the fact that vectors generated by inliers are regular. The above methods are all applicable to both structured (typically man-made) scenes with orthogonality, parallelism and coplanarity [21], and unstructured (typical natural) scenes [40].
Compared with the above point problem, identifying in-lier line correspondences (see Fig. 1(a)) is more challeng-ing and has not been well studied. Existing geometric constraint-based methods [9, 43] are only suitable for struc-tured scenes since inliers are only geometrically constrained in these scenes. A spatial regularity-based method can the-oretically handle both structured and unstructured scenes, but how to design such a method remains an open question.
Speciﬁcally, we express the spatial regularity of line cor-respondences by both angular and positional variations of image lines. As shown in Fig. 1(b), it is straightforward to use the inclinations, midpoints, or endpoints to encode the angular, positional, or both angular and positional variations 11743
of image lines, respectively. However, as will be shown in
Sections 3 and 6, these baseline methods may be affected by non-association and ambiguity problems, and thus result in unsatisfactory accuracy. Overall, a method suitable for both structured and unstructured scenes does not exist.
We propose the ﬁrst approach, which is applicable to both structured and unstructured scenes, to identify inlier line correspondences. Instead of geometric constraint, we leverage the spatial regularity on sphere. Speciﬁcally, we propose to map line correspondences into vectors tangent to sphere. We use these vectors to encode both angular and positional variations of image lines, which is more reliable and concise than directly using inclinations, midpoints or endpoints of image lines. As shown in Fig. 1(c), neighbor-ing vectors mapped from inliers (but not outliers) exhibit a spatial regularity called local trend consistency, regardless of the type of scenes. To encode this regularity, we design a neural network and also propose a novel loss function that enforces the smoothness constraint of vector ﬁeld [29]. In addition, existing datasets for image line matching are ei-ther small [24, 32] or only provide synthetic images [17]. To solve this problem, we establish a large real-world dataset composed of 11,934 image pairs, and provide a tool to au-tomatically extend it. Our main contributions are:
• We propose a novel image-to-sphere mapping to gen-erate vectors tangent to sphere. These vectors solve the non-association and ambiguity problems, and in-lier vectors exhibit a spatial regularity.
• We propose a novel loss function to learn the spatial regularity of vectors tangent to sphere. Accordingly, our approach is the ﬁrst one applicable to both struc-tured and unstructured scenes.
• We establish a large real-world dataset for image line matching. Our dataset and tool for dataset extension are publicly available.2
Experiments showed that our approach outperforms state-of-the-art ones in terms of accuracy, efﬁciency and robust-ness, and also leads to high generalization. 2.