Abstract
Human trajectory prediction is critical for autonomous platforms like self-driving cars or social robots. We present a latent belief energy-based model (LB-EBM) for diverse human trajectory forecast. LB-EBM is a probabilistic model with cost function deﬁned in the latent space to account for the movement history and social context. The low-dimensionality of the latent space and the high expressivity of the EBM make it easy for the model to capture the multi-modality of pedestrian trajectory distributions. LB-EBM is learned from expert demonstrations (i.e., human trajectories) projected into the latent space. Sampling from or optimizing the learned LB-EBM yields a belief vector which is used to make a path plan, which then in turn helps to predict a long-range trajectory. The effectiveness of LB-EBM and the two-step approach are supported by strong empirical results.
Our model is able to make accurate, multi-modal, and social compliant trajectory predictions and improves over prior state-of-the-arts performance on the Stanford Drone trajec-tory prediction benchmark by 10.9% and on the ETH-UCY benchmark by 27.6%. 1.

Introduction
Forecasting the future trajectories of pedestrians is crit-ical for autonomous moving platforms like self-driving cars or social robots with which humans are interacting.
It has recently attracted interest from many researchers
[15, 64, 25, 50, 3, 7, 28, 32]. See [49] for an overview.
Trajectory forecast is a challenging problem since human fu-ture trajectories depend on a multitude of factors such as past movement history, goals, behavior of surrounding pedestri-ans. Also, future paths are inherently multimodal. Given the past trajectories, there are multiple possible future paths. We propose a latent belief energy-based model (LB-EBM) which captures pedestrian behavior patterns and subtle social inter-action norms in the latent space and make multimodal tra-jectory predictions. LB-EBM is learned from expert demon-strations (i.e., human trajectories) following the principle of inverse reinforcement learning (IRL) [36, 11, 12, 17].
Traditional IRL approaches [36] ﬁrst learn a cost function from expert demonstrations in an outer loop and then use reinforcement learning to extract the policy from the learned cost function in an inner loop. These approaches are often highly computationally expensive. To avoid such an issue,
GAIL (Generative Adversarial Imitation Learning) [21, 7] optimizes a policy network directly. GAIL can generate multimodal action predictions given an expressive policy generator. The multimodality is however modeled implicitly and completely relies on the policy generator. Our approach strikes a middle ground between traditional IRL and GAIL.
We learn an energy-based model (EBM) as the cost function in a low dimensional latent space and map the EBM distribu-tion to actions with a policy generator. Similar to traditional
IRL, we learn a cost function but our cost function is deﬁned in a low dimensional space so that our cost function is eas-ier to model and learn. Resembling GAIL, we also learn a policy generator which allows for directly mapping a latent vector to the action trajectory, while we explicitly learn a multimodal cost function instead of learning it implicitly and completely relying on the policy generator.
An EBM [59, 38, 40] in the form of Boltzmann or Gibbs distribution maps a latent vector to its probability. It has no restrictions in its form and can be instantiated by any function approximators such as neural networks. Thus, this model is highly expressive and learning from human trajec-tories allows it to capture the multimodality of the trajectory distribution. Our proposed LB-EBM is deﬁned in a latent space. An encoder is jointly learned to project human tra-jectories into the latent space and hence provides expert demonstrations to the latent cost function.
Furthermore, this cost function accounts for trajectory his-tory and motion behavior of surrounding pedestrians. Thus sampling from or optimizing the cost function yields a latent belief, regarding future trajectory, which considers the cen-tric agent’s behavior pattern and social context surrounding this agent. A future trajectory is then forecasted in two steps.
We ﬁrst use the social-aware latent belief vector to make a rough plan for future path. It is intuitive that human do not plan every single future step in advance but we often have a rough idea about how to navigate through our future 111814
path, which is based on one’s belief after observing other agents’ motion. The belief is inherently related to the agent’s behavior pattern. This forms the intuitive motivation of our modeling approach. Conditioned on the plan, the trajectory is then predicted with the assistance of individual motion history and social cues. Several recent works take two steps to make trajectory forecast. They either ﬁrst estimate the
ﬁnal goal [32] or make a plan on a coarse grid map [29]. We take a similar approach. The plan in our approach is deﬁned to be positions of some well-separated steps in the future trajectory, which can be easily extracted from the data.
The proposed LB-EBM and other modules are learned end-to-end. We test our model on the Stanford Drone (SDD) trajectory prediction benchmark and the ETH-UCY bench-mark and improves the prior state-of-the-art performance by 10.9% on SDD and 27.6% on ETH-UCY.
Our work has the following contributions.
•
•
•
We propose a latent belief energy-based model (LB-EBM), following the principle of IRL, which naturally captures the multimodal human trajectory distribution.
Our approach predicts multimodal and social compliant future trajectories.
Our model achieves the state-of-the-art on widely-used human trajectory forecasting benchmarks. 2.