Abstract
We show the generative capability of an image classiﬁer network by synthesizing high-resolution, photo-realistic, and diverse images at scale. The overall methodology, called Synthesize-It-Classiﬁer (STIC), does not require an explicit generator network to estimate the density of the data distribution and sample images from that, but instead uses the classiﬁer’s knowledge of the boundary to perform gradient ascent w.r.t. class logits and then synthesizes im-ages using the Gram Matrix Metropolis Adjusted Langevin
Algorithm (GRMALA) by drawing on a blank canvas. Dur-ing training, the classiﬁer iteratively uses these synthesized images as fake samples and re-estimates the class bound-ary in a recurrent fashion to improve both the classiﬁca-tion accuracy and quality of synthetic images. The STIC shows that mixing of the hard fake samples (i.e. those syn-thesized by the one-hot class conditioning), and the soft fake samples (which are synthesized as a convex combination of classes, i.e. a mixup of classes [36]) improves class inter-polation. We demonstrate an Attentive-STIC network that shows iterative drawing of synthesized images on the Im-ageNet dataset that has thousands of classes. In addition, we introduce the synthesis using a class conditional score classiﬁer (Score-STIC) instead of a normal image classiﬁer and show improved results on several real world datasets, i.e. ImageNet, LSUN and CIFAR 10. 1.

Introduction
Discriminative classiﬁers p(y|x) and generative mod-els p(x) are conventionally considered as domains com-plementary to each other, yet the distinction between them is blurring. A generative model p(x) [26] appears as a data generation process that captures the underlying den-sity of a data distribution, whereas the discriminative clas-siﬁer learns complex feature representations of images with a view to learn the class boundaries for subsequent clas-siﬁcation. There is a recent growth of interest in Machine
Learning (ML) and Computer Vision (CV) [15, 20, 7] to use a discriminative classiﬁer and then synthesize novel sam-ples from its understanding of class boundary information.
To elaborate, in the model of [7], the classiﬁer p(y|x) log-5161
Figure 2: The STIC Methodology: Our main objective is to learn a class conditional model by emphasizing the fact that p(x|y) / p(y|x), Eq 1, and synthesise photo-realistic images from a discriminative classiﬁer. Our proposed STIC serves dual objectives: (1) learning smooth class boundaries with Vicinal Risk Minimization; and (2) learning tighter class boundaries using recurrent self-analysis class boundary re-estimation. At time (⌧ + 1), the classiﬁer p(y|x) is adjusting the parameters (✓τ +1) using real images, mixup images; and in addition to that, synthesized images from real classes and synthesized images from mixup classes from previous iteration ⌧ (marked as Fake Sample) are provided to the classiﬁer. Please note that mixup classes are not actually classes but the mixup of logits of two or more classes. The samples are, at time (⌧ ), synthesized from classiﬁer’s knowledge of the class boundary by gradient ascending w.r.t class logits, zτ , using our proposed Gram Matrix
Regularized Metropolis Adjusted Langevin Algorithm sampler (GRMALA), see red dashed arrow. The STIC discriminative classiﬁer is trained for ⌧ 2 {1, 2, · · · , T} number of iterations. its are used to estimate the joint density of the image-label p(x, y), and the marginal of the image distribution, p(x); image, and y: class label. note the random variables, x:
Meanwhile in [15, 20] the classiﬁer logits are used to pro-duce synthesized samples using an MCMC-like sampling mechanism. The classiﬁer, on the other hand, tries to dis-tinguish these synthesized samples and the real images to re-estimate class boundaries. We remark that synthesizing novel samples from a discriminative classiﬁer hinges on an important factor: how well the discriminative classiﬁer has learned the class boundaries?
We note that all the discriminative classiﬁers in [7, 15, 20, 22] used for synthesizing novel samples are trained with
Empirical Risk Minimization (ERM) [31]. Yet, from the lit-erature [4, 36], it is evident that a discriminative classiﬁer trained with ERM does not provide a smoother estimate of uncertainty near to the class boundary regions [4]. Hence, we ask ourselves the question: does training with ERM have any consequence on the synthesizing capabilities of these discriminative classiﬁers? We note that the transitions at class interpolation and sample quality towards class bound-aries of these discriminative classiﬁers are neither smooth nor photo-realistic. In this work, we primarily seek to ad-dress this problem, viz., to build a discriminative classiﬁer that will serve dual objectives: (1) the interpolated samples from one class to another must be photo-realistic; and (2) the classiﬁer must learn tighter class boundaries so as to generate photo-realistic samples.
To address the ﬁrst objective, we train the discrimina-tive classiﬁer with Vicinal Risk Minimization (VRM) [36].
We leverage more virtual mixup image-label samples [36] in addition to the real image-label samples and train the classiﬁer. We then synthesize novel samples. Our novel sample synthesis method is, by design, similar to the Style
Transfer work [6], i.e. starting with an initial image x0 which is updated with gradient ascent using our proposed novel Gram Matrix Regularized Metropolis Adjusted Lan-gavin Algorithm (GRMALA) sampler. To the best of our knowledge, this is the ﬁrst discriminative classiﬁer trained with VRM and subsequently synthesized using a novel GR-MALA sampler. We will discuss this in detail in Sec 3.
Training a discriminative classiﬁer with VRM alone, is however, a necessary condition for learning the smoother estimation of uncertainty among classes, but not a sufﬁ-cient condition that provides tighter class boundaries. Cog-nitive studies [1, 3] have shown evidence where subjects (i.e. human) start with a weak cognitive decision model of an environment or the world, and recurrently reﬁne through mistakes and self-analysis gained from the envi-ronment to develop much stronger cognitive decision mod-els. In a similar spirit, we present our recurrent discrimina-tive network trained with VRM, that we call Synthesize-it-5162
Classiﬁer (STIC). The STIC recurrently eliminates the re-gions which are outside of the class boundaries and forces the sampler to search within class boundaries. The STIC methodology trains the classiﬁer with real images of differ-ent classes and then synthesizes samples conditioned on a class as well as the mixup samples w.r.t. the class logits.
At the next pass, the STIC inputs these synthesized sam-ples as fake samples to the already trained discriminative classiﬁer of the previous pass, thus allowing the classiﬁer to re-estimate class boundaries using real images, the syn-thesized mixup images and the synthesized samples (we call this self-analysis). Similar to [15, 20], we are, in a way, ask-ing the classiﬁer to quantify its own generated samples with respect to the class boundaries. The STIC does the recurrent self-analysis for ⌧ 2 {1, 2, · · · , T } number of passes.
From our empirical observations, we note that if the image space is large (typically > 227 ⇥ 227), the GR-MALA sampler exhibits a slow update. We hence show an attentive-STIC where the discriminative classiﬁer operates on the feature space instead of raw pixel space, thus exhibit-ing fast update. Additionally, we also propose a novel class conditional score matching based discriminative classiﬁer that matches the derivative of the model’s density with the derivative of the data density [29]. We will discuss each of these components elaborately in Sec 3.
Our contributions can be summarized as follows:
• Novel recurrent self analytic STIC trained with VRM and show synthesized images using Gram matrix Reg-ularized MALA (GRMALA) sampler w.r.t class logit
• We show Attentive-STIC model to address the slow mixing problem of MALA-approx. We also propose a novel class conditional score function based discrimi-native classiﬁer (we call it the Score-STIC method)
• We show results on several real world datasets, such as
ImageNet, LSUN and CIFAR 10 2.