Abstract
ClassSR-FSRCNN: 36.97dB / 256M (FSRCNN: 36.81dB / 468M)
We aim at accelerating super-resolution (SR) networks on large images (2K-8K). The large images are usually de-composed into small sub-images in practical usages. Based on this processing, we found that different image regions have different restoration difﬁculties and can be processed
Intuitively, smooth by networks with different capacities. areas are easier to super-solve than complex textures. To utilize this property, we can adopt appropriate SR networks to process different sub-images after the decomposition. On this basis, we propose a new solution pipeline – ClassSR that combines classiﬁcation and SR in a uniﬁed framework.
In particular, it ﬁrst uses a Class-Module to classify the sub-images into different classes according to restoration difﬁ-culties, then applies an SR-Module to perform SR for differ-ent classes. The Class-Module is a conventional classiﬁca-tion network, while the SR-Module is a network container that consists of the to-be-accelerated SR network and its simpliﬁed versions. We further introduce a new classiﬁca-tion method with two losses – Class-Loss and Average-Loss to produce the classiﬁcation results. After joint training, a majority of sub-images will pass through smaller networks, thus the computational cost can be signiﬁcantly reduced.
Experiments show that our ClassSR can help most existing methods (e.g., FSRCNN, CARN, SRResNet, RCAN) save up to 50% FLOPs on DIV8K datasets. This general framework can also be applied in other low-level vision tasks. 1.

Introduction
Image super-resolution (SR) is a long-studied topic, which aims to generate a high-resolution visual-pleasing
∗Corresponding author (e-mail: chao.dong@siat.ac.cn)
Hard
Simple
Medium
Figure 1. The SR result (x4) of ClassSR-FSRCNN. The Class-Module classiﬁes the image “0896” (DIV2K) into 56% simple, 20% medium and 24% hard sub-images. Compared with FSR-CNN, ClassSR-FSRCNN uses only 55% FLOPs to achieve the same performance. image from a low-resolution input.
In this paper, we study how to accelerate SR algorithms on “large” input im-ages, which will be upsampled to at least 2K resolution (2048×1080). While in real-world usages, the image/video resolution for smartphones and TV monitors has already reached 4K (4096 × 2160), or even 8K (7680 × 4320). As most recent SR algorithms are built on CNNs, the mem-ory and computational cost will grow quadratically with the input size. Thus it is necessary to decompose input into sub-images and continuously accelerate SR algorithms to meet the requirement of real-time implementation on real images.
Recent works on SR acceleration focus on proposing light-weight network structures, e.g., from the early FSR-CNN [6] to the latest CARN [2], which are detailed in the
Sec. 2. We tackle this problem from a different perspec-tive. Instead of designing a faster model, we propose a new processing pipeline that could accelerate most SR methods.
Above all, we draw the observation that different image re-gions require different network complexities (see Sec. 3.1).
For example, the ﬂat area (e.g., sky, land) is naturally easier to process than textures (e.g., hair, feathers). This indicates 12016
-50%
-48%
-47%
-49%
Figure 2. PSNR and FLOPs comparison between ClassSR and original networks on Test8K with × 4. that if we can use smaller networks to treat less complex image regions, the computational cost will be signiﬁcantly reduced. According to this observation, we can adopt dif-ferent networks for different contents after decomposition.
Sub-image decomposition is especially beneﬁcial for large images. First, more regions are relatively simple to restore. According to our statistics, about 60% LR sub-images (32 × 32) belong to smooth regions for DIV8K [7] dataset, while the percentage drops to 30% for DIV2K [1] dataset. Thus the acceleration ratio will be higher for large images. Second, sub-image decomposition can help save memory space in real applications, and is essential for low-memory processing chips. It is also plausible to distribute sub-images to parallel processors for further acceleration.
To address the above issue and accelerate existing SR methods, we propose a new solution pipeline, namely
ClassSR, to perform classiﬁcation and super-resolution si-multaneously. The framework consists of two modules –
Class-Module and SR-Module. The Class-Module is a sim-ple classiﬁcation network that classiﬁes the input into a spe-ciﬁc class according to the restoration difﬁculty, while the
SR-Module is a network container that processes the classi-ﬁed input with the SR network of the corresponding class.
They are connected together and need to be trained jointly.
The novelty lies in the classiﬁcation method and training strategy. Speciﬁcally, we introduce two new losses to con-strain the classiﬁcation results. The ﬁrst one is a Class-Loss that encourages a higher probability of the selected class for individual sub-images. The other one is an Average-Loss that ensures the overall classiﬁcation results not bias to a single class. These two losses work cooperatively to make the classiﬁcation meaningful and well-distributed.
The Image-Loss (L1 loss) is also added to guarantee the reconstruction performance. For the training strategy, we
ﬁrst pre-train the SR-Module with Image-Loss. Then we
ﬁx the SR-Module and optimize the Class-Module with all three losses. Finally, we optimize the two modules simul-taneously until convergence. This pipeline is general and effective for different SR networks. scales – FSRCNN (tiny)
[6], works with different
CARN (small) [2], SRResNet (middle) [13] and RCAN (large) [25]. As shown in Fig. 2, the ClassSR method could help these SR networks save 50%, 47%, 48%, 50% compu-tational cost on the DIV8K dataset, respectively. An exam-ple is shown in Fig. 1, where the ﬂat areas (color in light green) are processed with the simple network and the tex-tures (color in red) are processed with the complex one. We have also provided a detailed ablation study on the choice of different network settings.
Overall, our contributions are three-fold: (1) We pro-pose ClassSR. It is the ﬁrst SR pipeline that incorpo-rates classiﬁcation and super-resolution together on the sub-image level. (2) We tackle acceleration by the character-istic of data. It makes ClassSR orthogonal to other accel-eration networks. A network compressed to the limit can still be accelerated by ClassSR. (3) We propose a clas-siﬁcation method with two novel losses. It divides sub-images according to their restoration difﬁculties that are processed by a speciﬁc branch instead of predetermined la-bels, so it can also be directly applied to other low-level vision tasks. The code will be made available: https:
//github.com/Xiangtaokong/ClassSR 2.