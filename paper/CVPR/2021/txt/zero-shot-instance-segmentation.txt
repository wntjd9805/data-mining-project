Abstract
Deep learning has signiﬁcantly improved the precision of instance segmentation with abundant labeled data. How-ever, in many areas like medical and manufacturing, col-lecting sufﬁcient data is extremely hard and labeling this data requires high professional skills. We follow this mo-tivation and propose a new task set named zero-shot in-stance segmentation (ZSI). In the training phase of ZSI, the model is trained with seen data, while in the testing phase, it is used to segment all seen and unseen instances. We
ﬁrst formulate the ZSI task and propose a method to tackle the challenge, which consists of Zero-shot Detector, Seman-tic Mask Head, Background Aware RPN and Synchronized
Background Strategy. We present a new benchmark for zero-shot instance segmentation based on the MS-COCO dataset. The extensive empirical results in this benchmark show that our method not only surpasses the state-of-the-art results in zero-shot object detection task but also achieves promising performance on ZSI. Our approach will serve as a solid baseline and facilitate future research in zero-shot instance segmentation. Code available at ZSI. 1.

Introduction
In recent years, deep learning based instance segmenta-tion methods [1, 2, 3, 4, 5, 6] have made great progress.
These supervised learning paradigm methods strongly rely on large-scale labeled data. However, for many real-world applications, e.g., the medical and manufacturing, collect-ing and labeling data are very time consuming and need professional annotators, which results in that we always do not have labeled data for unseen classes in these tasks. Be-sides, for open-set [7, 8] instance segmentation tasks, we can not label all categories, so there are many unlabeled un-seen classes that need to be segmented. Without abundant labeled data, modern instance segmentation approaches are not competent to train a deep neural network to segment unseen instances. In recent years, many zero-shot learning unseen class fork seen class knife knife fork seen train test model seen unseen
Labeled training data of seen categories
Unlabeled test data of seen and unseen categories
Figure 1. In zero-shot instance segmentation, we can only use the labeled data of seen categories for training but predict the instance segmentation results for both seen and unseen categories. In our method, we use the seen classes data, e.g., “knife” to establish the mapping relationship between visual and semantic concepts during training and then transfer it to segment unseen instances, e.g.,“fork” in inference. methods have been proposed. The latest achievements of zero-shot learning focus on the problem of zero-shot classi-ﬁcation [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]. Limited by the existing benchmarks [20, 21, 22], the zero-shot clas-siﬁcation approaches focus on reasoning a single dominant unseen object in input image, which makes it unsuitable for real scenes. In the real world, several unseen objects be-longing to different classes may appear at the same time.
Therefore, zero-shot object detection (ZSD) [23, 24] and zero-shot semantic segmentation (ZSS) [25] have been pro-2593
posed. ZSD is aiming to simultaneously localize and rec-ognize unseen objects and ZSS is used to segment unseen classes, these tasks are more practical for the real-world sce-narios. However, the bounding box results obtained from
ZSD and the segmentation results of the entire image from
ZSS are still not ﬁne enough when we need pixel-level seg-mentation results of each instance. In order to meet this de-mand for ﬁner results, we introduce a new problem setting, called zero-shot instance segmentation (ZSI). As illustrated in Fig 1, the goal for ZSI is not only to detect all unseen objects, but also to further precisely segment each unseen instance.
There are two main challenges for ZSI task. (i) How to do instance segmentation for unseen classes. Without un-seen classes data, we can not train a deep neural network to segment unseen instances. We introduce extra semantic knowledge contained in pre-trained word-vectors to corre-late the seen and unseen classes. We use the semantic word-vector and image data of seen classes to establish the visual-semantic mapping relationship in a detection-segmentation manner and transfer it from seen to unseen classes. We propose the zero-shot detector and Semantic Mask Head (SMH) to detect and segment each unseen instance. We discuss the details in Section 3.2.1 and Section 3.2.2. (ii)
How to reduce the confusion between background and un-seen classes. Unlike the zero-shot classiﬁcation task that only has one domain object in each image and does not need to consider the background class, ZSI needs to dis-tinguish foreground and background. Since the unseen data are not observed during training, the model is likely to iden-tify the unseen objects as the background, which has a great impact on the performance. We believe that the represen-tation of background class is the key to solve this prob-lem. We ﬁnd that the current representation of the back-ground class has two major drawbacks: (i) The existing se-mantic representation of background is unreasonable. Pre-vious works [23, 24] used the word-vector for the “back-ground” word to represent background class. However, in computer vision task, this simple word-vector learned from unlabeled text data is not enough to represent the complex background; (ii) The existing semantic representation of the background class is ﬁxed, which makes it difﬁcult to adapt to the changing background in different images. To obtain a reasonable and dynamic adaptive word-vector for back-ground class, We propose