Abstract 1.

Introduction
Artistic style transfer aims at migrating the style from an example image to a content image. Currently, optimization-based methods have achieved great stylization quality, but expensive time cost restricts their practical applications.
Meanwhile, feed-forward methods still fail to synthesize com-plex style, especially when holistic global and local patterns exist. Inspired by the common painting process of draw-ing a draft and revising the details, we introduce a novel feed-forward method named Laplacian Pyramid Network (LapStyle). LapStyle ﬁrst transfers global style patterns in low-resolution via a Drafting Network. It then revises the lo-cal details in high-resolution via a Revision Network, which hallucinates a residual image according to the draft and the image textures extracted by Laplacian ﬁltering. Higher reso-lution details can be easily generated by stacking Revision
Networks with multiple Laplacian pyramid levels. The ﬁnal stylized image is obtained by aggregating outputs of all pyra-mid levels. Experiments demonstrate that our method can synthesize high quality stylized images in real time, where holistic style patterns are properly transferred.
Artistic style transfer is an attractive technique which can create an art image with the structure of a content image and the style patterns of an example style image. It has been a prevalent research topic for both academy and industry.
Recently, there have been a lot of methods proposed for neural style transfer, which can be roughly divided into two types: image-optimization and model-optimization methods.
Image-optimization methods iteratively optimize stylized image with ﬁxed network. The seminal work of Gatys et al. [6] achieves style transfer in an iterative optimization process, where the style patterns are captured by correlation of features extracted from a pre-trained deep neural network.
Following works improve [6] mainly in the form of different loss functions [12, 24]. Although superior stylization results are achieved, e.g., STROTSS [12], widespread applications of these methods are still restricted by their slow online optimization process. On the contrary, model-optimization methods update neural networks by training and are feed-forward in testing. There are mainly three subdivided types: (1) Per-Style-Per-Model methods [10, 15, 29, 30, 31] are trained to synthesize images with a single given style image; 5141
(2) Multi-Style-Per-Model methods [2, 5, 32, 17, 34] intro-duce various network architectures to simultaneously han-dle multiple styles; (3) Arbitrary-Style-Per-Model methods
[9, 18, 27, 16, 22] further adopt diverse feature modiﬁcation mechanisms to transfer arbitrary styles. Reviewing these methods, we ﬁnd that although local style patterns can be transferred, complex style mixed with both global and local patterns is still not properly transferred. Meanwhile, artifacts and ﬂaws appear in many cases. To this end, in this work, our main goal is to achieve superior high-quality artistic style transfer results with feed-forward network, where local and global patterns can be reserved aesthetically.
How human painters handle the complex style patterns while painting? A common process, especially for a begin-ner, is to ﬁrst draw a draft to capture global structure and then revise the local details gradually, instead of directly ﬁnishing the ﬁnal painting part-by-part. Inspired by this, we propose a novel neural network named Laplacian Pyramid Network (LapStyle) for style transfer. Firstly, in our framework, a
Drafting Network is designed to transfer global style patterns in low-resolution, since we observe that global patterns can be transferred easier in low resolution due to larger receptive
ﬁeld and less local details. A Revision Network is then used to revise the local details in high-resolution via hallucinating a residual image according to the draft and the textures ex-tracted by Laplacian ﬁltering over the 2× resolution content image. Note that our Revision Network can be stacked in a pyramid manner to generate higher resolution details. The
ﬁnal stylized image is obtained by aggregating outputs of all pyramid levels. Further, we adopt shallow patch discrimina-tors to adversarially learn local style patterns. As illustrated in Fig. 1, appealing stylization results are achieved by our
“Drafting and Revison” process. To summarize, the main contributions are as follows:
• We introduce a novel framework “Drafting and Revi-sion”, which simulates painting creation mechanism by splitting style transfer process into global style pattern drafting and local style pattern revision.
• We propose a novel feed-forward style transfer method named LapStyle. It uses a Drafting Network to trans-fer global style patterns in low-resolution, and adopts higher resolution Revision Networks to revise local style patterns in a pyramid manner according to outputs of multi-level Laplacian ﬁltering of the content image.
• Experiments demonstrate that our method can gener-ate high-resolution and high-quality stylization results, where global and local style patterns are both effec-tively synthesized. Besides, the proposed LapStyle is extremely efﬁcient and can synthesize high resolution stylized image of 512 pix in 110 fps. 2.