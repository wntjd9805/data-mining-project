Abstract
Detecting digital face manipulation has attracted exten-sive attention due to fake media’s potential harms to the public. However, recent advances have been able to reduce the forgery signals to a low magnitude. Decomposition, which reversibly decomposes an image into several con-stituent elements, is a promising way to highlight the hidden forgery details.
In this paper, we consider a face image as the production of the intervention of the underlying 3D geometry and the lighting environment, and decompose it in a computer graphics view. Speciﬁcally, by disentangling the face image into 3D shape, common texture, identity texture, ambient light, and direct light, we ﬁnd the devil lies in the direct light and the identity texture. Based on this observation, we propose to utilize facial detail, which is the combination of direct light and identity texture, as the clue to detect the subtle forgery patterns. Besides, we highlight the manipulated region with a supervised attention mecha-nism and introduce a two-stream structure to exploit both face image and facial detail together as a multi-modality task. Extensive experiments indicate the effectiveness of the extra features extracted from the facial detail, and our method achieves the state-of-the-art performance. 1.

Introduction
While earlier seamless face manipulation has amazed the public broadly, there has been a constant concern about the
In particular, the potential abuse of relevant techniques. recent DeepFake [18] initiated the widespread public dis-cussion among the potential harmful consequence [58] and feasible detection solutions of counterfeit facial media [6].
In this work, we are dedicated to detecting the manip-∗Equal contribution.
†Corresponding author.
Figure 1. In computer graphics, a face image can be decomposed into direct light, ambient light, 3D geometry, common texture and identity texture. We ﬁnd critical clues in direct light and identity texture, and merge them as the facial detail for forgery detection. ulation on facial identity and expression, related to the very popular DeepFakes (DF) [18], Face2Face (F2F) [57],
FaceSwap (FS) [34] and NeuralTextures (NT) [55], which perform the state-of-the-art face manipulation, making it extremely tough to reveal the sophisticated counterfeit ﬂaws from the image view only [46]. This situation stimulates researchers to shift their attention to extracting forgery evi-dence from other aspects besides the original RGB image.
Previous work [66, 14, 63, 46] has discovered that the signals in speciﬁc frequency ranges are replaced by par-ticular patterns during manipulation and proposes to detect forgery by signal decomposition. The assumption is that, by disentangling the face image, we can ﬁnd more critical clues for forgery detection from the constituent elements, which are overlooked or hard to be forged by the ma-nipulation methods, whose loss function mainly constrains pixel values. For example, Zhang et al. [66] identify the unique replications of spectra in the frequency domain due 2929
to the up-sampling process. Chen et al. [14] introduce facial semantic segmentation and Discrete Fourier Trans-form (DFT) to extract both spatial- and frequency-domain features, respectively. However, it is difﬁcult to decide which range of signals contains artifacts since images are captured by different devices, under different environments, and even compressed with different algorithms, leading to large frequency distribution bias across datasets. The hand-crafted [52] and learned [46] frequency ﬁlters also easily suffer from the generalization problem. Therefore, the crucial problems of this topic lie in how to decompose an image and how to identify reliable constituent elements.
This paper considers the physical decomposition where a face image is the intervention result of its underlying 3D geometry, albedo, and the environment lighting. Speciﬁ-cally, we introduce 3D Morphable Model (3DMM) [7] and computer graphics rendering to simulate the generation of a face image. Under Lambertian assumption, we decompose a face image into 5 components (Fig. 1): 3D geometry, common texture, identity texture, ambient light, and direct light. The 3D geometry is the underlying 3D face shape, the common texture is the albedo patterns shared by all the people, the identity texture is the albedo patterns peculiar to this face, the ambient light changes the face color globally, and the direct light generates shading. We introduce the decomposition in Sec. 3.1 in detail.
Figure 2. Samples under strong direct light. The ﬁrst row is the original faces, the second row is the corresponding fake samples, where evident inconsistency exists in the dim region.
Intuitively, the advanced manipulation methods can well reconstruct 3D geometry, common texture and ambient light since we merely see incompatible facial topology, non-face texture and weird skin color among the massive forged images. Thus, these three elements should be normalized.
However, we detect identity texture since it is hard to be simulated due to the rich variations across faces, leading to speciﬁc high-frequency artifacts. Besides, we speculate the direct light as another decisive forgery clue with the observation on large artifacts under intense direct light, shown in Fig. 2. By evaluating various compositions among different components, we ﬁnd that the combination of direct light and identity texture, i.e., the facial detail in
Fig. 1(f), is the best for forgery detection.
When detecting forgery clues with neural networks, we consider the cooperation between face image and facial detail as a multi-modality task and propose a two-stream
Forgery-Detection-with-Facial-Detail Net (FD2Net). To further highlight the discriminative region, we introduce a supervised Detail-guided Attention mechanism in the network, which employs the facial detail difference between real and fake faces as the objective.
In summary, our contributions are: 1) we introduce 3D decomposition into forgery detection and construct facial detail to amplify subtle artifacts. 2) A two-stream structure
FD2Net is proposed to fuse the clues from original images and facial details, where a supervised attention module is introduced to highlight the discriminative region. 3) Com-pared with the other state-of-the-art detection proposals, our method achieves remarkable elevation on both detection performance and generalization ability. 2.