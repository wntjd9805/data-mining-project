Abstract
We propose Mask Guided (MG) Matting, a robust mat-ting framework that takes a general coarse mask as guid-ance. MG Matting leverages a network (PRN) design which encourages the matting model to provide self-guidance to progressively reﬁne the uncertain regions through the de-coding process. A series of guidance mask perturbation op-erations are also introduced in the training to further en-hance its robustness to external guidance. We show that
PRN can generalize to unseen types of guidance masks such as trimap and low-quality alpha matte, making it suit-able for various application pipelines. In addition, we re-visit the foreground color prediction problem for matting and propose a surprisingly simple improvement to address the dataset issue. Evaluation on real and synthetic bench-marks shows that MG Matting achieves state-of-the-art per-formance using various types of guidance inputs. Code and models are available at https://github.com/ yucornetto/MGMatting. 1.

Introduction
Image matting is a fundamental computer vision prob-lem which aims to predict an alpha matte to precisely cut
∗Work done during an internship at Adobe. out an image region. It has many applications in image and video editing [39, 41, 21]. Most previous matting methods require a well-annotated trimap as an auxiliary guidance in-put [39], which explicitly deﬁnes the regions of foreground and background as well as the unknown part for the mat-ting methods to solve. Although such annotation makes the problem more tractable, it can be quite burdensome for users and limits the usefulness of these methods in many non-interactive applications.
Recently, researchers start to study the matting problem in a trimap-free setting. One direction is to get rid of any ex-ternal guidance, and hope that the matting model can cap-ture both semantics and details by end-to-end training on large-scale datasets [45, 31]. Nevertheless, these methods are faced with the generalization challenge due to the lack of semantic guidance when tested on complex real-world images. Another line of works investigate alternatives to the trimap guidance, easing the requirement for human in-put [27, 32, 19, 13]. For example, [19, 13] proposed tech-niques for automatic trimap generation, while [32] takes background images instead as extra inputs. However, these methods often require a very speciﬁc type of guidance they are trained with and thus become less appealing when the guidance inputs may have varied characteristics or forms.
In this work, we introduce a Mask Guided (MG) Mat-ting method which takes a general coarse mask as guidance.
MG Matting is very robust to the guidance input and can 1154
obtain high-quality matting results using various types of mask guidance such as a trimap, a rough binary segmenta-tion mask or a low-quality soft alpha matte. To achieve such robustness to guidance input, we propose a Progressive Re-ﬁnement Network (PRN) module, which learns to provide self-guidance to progressively reﬁne the uncertain matting regions through the decoding process. To further enhance the robustness of our method to external guidance, we also develop a series of guidance mask perturbation operations including random binarization, random morphological op-erations, and also a stronger perturbation CutMask to simu-late diverse guidance inputs during training.
In addition to alpha matting prediction, we also revisit the foreground color prediction problem for matting. With-out accurately recovering the foreground color in the trans-parent region, the composited image will suffer from the fringing issue. We note that the foreground color labels in the widely-used dataset [41] are suboptimal for model train-ing due to the labeling noise and limited diversity. As a simple yet effective solution, we propose Random Alpha
Blending (RAB) to generate synthetic training data from random alpha mattes and images. We show that such simple method can improve the foreground color prediction accu-racy without requiring additional manual annotations. As a result, combining with the proposed PRN, MG Matting is able to generate more visual plausible composition results.
Our contributions can be summarized as follows:
• We propose Mask Guided Matting, a general matting framework working with guidance masks in various qualities and even forms, and achieve a new state-of-the-art performance evaluated on both synthetic and real-world datasets.
• We introduce Progressive Reﬁnement Network (PRN) along with a guidance perturbation training pipeline as a solution to learning a robust matting model.
• We study the problem of foreground color prediction for matting and propose a simple improvement using random alpha blending.
In addition, we collect and release a high-quality matting benchmark dataset of real images to evaluate the real-world performance of matting models. 2.