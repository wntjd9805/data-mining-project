Abstract
In instance-level detection tasks (e.g., object detection), reducing input resolution is an easy option to improve run-time efﬁciency. However, this option traditionally hurts the detection performance much. This paper focuses on boosting performance of low-resolution models by distilling knowledge from a high- or multi-resolution model. We ﬁrst identify the challenge of applying knowledge distillation (KD) to teacher and student networks that act on different input resolutions. To tackle it, we explore the idea of spa-tially aligning feature maps between models of varying in-put resolutions by shifting feature pyramid position and in-troduce aligned multi-scale training to train a multi-scale teacher that can distill its knowledge to a low-resolution student. Further, we propose crossing feature-level fusion to dynamically fuse teacher’s multi-resolution features to guide the student better. On several instance-level detection tasks and datasets, the low-resolution models trained via our approach perform competitively with high-resolution models trained via conventional multi-scale training, while outperforming the latter’s low-resolution models by 2.1% to 3.6% in terms of mAP. Our code is made publicly available at https://github.com/Jia-Research-Lab/MSAD. 1.

Introduction
Deep learning [29, 54, 59, 60, 18, 58, 26, 25] has en-abled instance-level detection (object detection [13, 10, 49], instance segmentation [16, 36], human keypoint detec-tion [53, 80, 57], etc.) methods to achieve previously unattainable performance. Heavy computation require-ment of deep-learning-based instance-level detection mod-els, however, remains an issue for easy adoption of these models in real-world applications [41, 52, 45, 7].
While many model compression techniques [44, 5, 32, 28] have been proposed to train compact models for accel-erated inference, they mostly focus on trimming networks along depth or width [9, 82, 12, 81, 1], or adopting efﬁ-cient block structure design [24, 51, 23, 79, 39, 20, 4]. Be-†Equal contribution.
Teacher
Student
…
…
&
𝑃%
&
𝑃!
&
𝑃" (
𝑃%
’
𝑃!
’
𝑃"
Teacher
Student
…
…
Aligned 
Multi-scale
Training
…
…
Cross 
Feature-level
Distillation
Teacher
Fusion
𝑃%
𝑃!
𝑃"
#
𝑃!
#
𝑃"
#
𝑃$
&
𝑃%
&
𝑃!
&
𝑃"
’
𝑃!
’
𝑃"
’
𝑃$
Spatially conflicted
Spatially aligned 800px 400px 800px 2× 400px (a) Traditional (b) Ours
Figure 1: Conceptual comparison between (a) traditional teacher-student approach and (b) ours, in the setting of us-ing a high-resolution teacher to guide a low-resolution stu-In this setting, the traditional approach of transfer-dent. ring knowledge along the same feature levels fails due to spatially-conﬂicted feature maps. To resolve it, we intro-duce a multi-scale aligned distillation approach. sides depth/width, another critical dimension for the com-pound scaling of network architectures is the input resolu-tion [61, 31]. However, reducing input resolutions to accel-erate instance-level detection is generally not regarded as a decent solution in existing work due to severe performance degradation. For example, for the recent one-stage detec-tor FCOS [64], its mean average precision (AP) drops from 38.7 to 34.6 when the detector is naively trained on 400px images instead of the default 800px images.
We are thus interested to study the fundamental prob-lem to upgrade performance of a low-resolution detection model up to that of its high-resolution counterpart.
There was study to mitigate performance drop by dis-tilling knowledge (KD) from a high-res teacher to a low-res student [31, 73]. KD methods distill knowledge from a heavier teacher network to a compact student mostly in the context of image classiﬁcation [76, 14, 50], since the spatial scales of ﬁnal output of the teacher and student networks are identical. In the context of instance-level detection, it is not trivial to apply KD to high-res teacher and low-res student networks because they do not share the same fea-ture/output spatial size at the same network stages, as illus-14443
trated in Fig. 1(a). Downsampling feature maps and output of the pre-trained large-resolution teacher to match those of the low-resolution student is one naive workaround. But this operation signiﬁcantly corrupts predicted features and output, making them poorly reﬂective of the actual knowl-edge learned by the teacher.
We, instead, explore alignment of feature maps to re-solve the output size mismatch between high-res teacher and low-res student. For the feature pyramid (FPN) struc-ture [33] widely used in instance-level detection networks, the feature map size in last network stage is 2× larger than that of current stage. Based on this observation, for the low-res student, we adopt input resolution 2× smaller than the typical input used for the teacher. This provides feature-level consistency between the two input resolution models and allows their features to match spatially. As shown in
Fig. 1(b), the spatial size of P2 with low-res (downsampled by 2×) input shares the same spatial size as P3 of the high-res input. This simple strategy quickly and effectively en-ables knowledge distillation from teacher to student.
With this novel alignment idea, we propose an aligned multi-scale training method and a crossing feature-level fu-sion module to train a strong teacher. Aligned multi-scale training qualiﬁes a ready-for-distillation robust teacher that performs well across multiple input resolutions. Whereas the crossing feature-level fusion module dynamically fuses the features from multiple-res models within the same teacher network. Finally, the rich multi-scale and multi-resolution knowledge of the multi-scale fusion teacher is distilled to the low-res student, resulting in a high-performing low-resolution model. Fig. 1(b) provides a high-level overview of our approach.
Our main contribution is threefold.
• The alignment concept to align feature maps of models at different input resolutions.
• A framework for training a strong multi-scale and multi-resolution fusion teacher that provides more in-formative training signals to the low-res student that does not have access to ﬁne visual details in high-res images.
• Extensive ablation studies and comparative experi-ments on different instance-level detection tasks to demonstrate the effectiveness of our methods. 2.