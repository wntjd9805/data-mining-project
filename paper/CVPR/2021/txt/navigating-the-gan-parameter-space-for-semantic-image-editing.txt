Abstract
Generative Adversarial Networks (GANs) are currently an indispensable tool for visual editing, being a stan-dard component of image-to-image translation and image restoration pipelines. Furthermore, GANs are especially advantageous for controllable generation since their latent spaces contain a wide range of interpretable directions, well suited for semantic editing operations. By gradually changing latent codes along these directions, one can pro-duce impressive visual effects, unattainable without GANs.
In this paper, we signiﬁcantly expand the range of vi-sual effects achievable with the state-of-the-art models, like
StyleGAN2. In contrast to existing works, which mostly op-erate by latent codes, we discover interpretable directions in the space of the generator parameters. By several sim-ple methods, we explore this space and demonstrate that it also contains a plethora of interpretable directions, which
-  Windows  + are an excellent source of non-trivial semantic manipula-tions. The discovered manipulations cannot be achieved by transforming the latent codes and can be used to edit both synthetic and real images. We release our code and models and hope they will serve as a handy tool for further efforts on GAN-based image editing. 1.

Introduction
Generative Adversarial Networks (GANs) [8] have revo-lutionized image processing research, signiﬁcantly pushing the boundaries of machine learning for image enhancement and visual editing. Different research lines currently exploit
GANs in several principled ways, e.g. using them as an implicit learnable objective [20, 17, 13, 5, 18, 36, 37], em-ploying them as high-quality image priors [35, 2, 9, 22, 23], manipulating their internal representations for visual editing purposes [3, 6]. Furthermore, the GAN latent spaces often
Contact author: Andrey Voynov, an.voynov@yandex.ru https://github.com/yandex-research/navigan 3671
encode human-interpretable concepts [26, 28, 7, 14, 25, 29, 10, 24, 30], which makes GANs the dominant paradigm for controllable generation.
Since the seminal paper [26], which has demonstrated the semantic arithmetic of latent vectors in GANs, plenty of methods to discover interpretable directions in the GAN latent spaces have been developed [26, 28, 7, 14, 25, 29, 10, 24, 30]. These methods successfully identify such direc-tions across different GAN models and hold great potential for effective image editing. These days, many impressive visual effects can be achieved by simply moving the image latent codes along these directions.
Our paper demonstrates that a large number of exciting non-trivial visual effects can be produced by gradually mod-ifying the GAN parameters rather than the latent codes. In more detail, we show that the GAN parameter space also contains a plethora of directions, corresponding to inter-pretable image manipulations. Moreover, we describe sim-ple domain-agnostic procedures that discover such direc-tions in an unsupervised fashion. By extensive experiments, we conﬁrm that the discovered visual effects are substan-tially new and cannot be achieved by the latent code ma-nipulations. Overall, our ﬁndings signiﬁcantly expand the arsenal of GAN-based image editing techniques.
To sum up, our contributions are the following:
• We propose to use the interpretable directions in the space of the generator parameters for semantic edit-ing. Our approach differs from existing works, which operate by the latent codes or the intermediate GAN activations. Our ﬁndings demonstrate that remarkable visual effects can be achieved by slightly changing the
GAN parameters.
• We develop the methods to discover such directions.
The proposed methods are both effective and fast and can work on a single GPU.
• We conﬁrm that the discovered directions are qualita-tively new and correspond to semantic manipulations, which existing methods cannot produce. 2.