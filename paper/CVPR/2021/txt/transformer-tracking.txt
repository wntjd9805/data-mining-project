Abstract
Self-attention
Screen Shots
Cross-attention
Correlation acts as a critical role in the tracking ﬁeld, especially in recent popular Siamese-based trackers. The correlation operation is a simple fusion manner to con-sider the similarity between the template and the search re-gion. However, the correlation operation itself is a local linear matching process, leading to lose semantic informa-tion and fall into local optimum easily, which may be the bottleneck of designing high-accuracy tracking algorithms.
Is there any better feature fusion method than correlation?
To address this issue, inspired by Transformer, this work presents a novel attention-based feature fusion network, which effectively combines the template and search region features solely using attention. Speciﬁcally, the proposed method includes an ego-context augment module based on self-attention and a cross-feature augment module based on cross-attention. Finally, we present a Transformer track-ing (named TransT) method based on the Siamese-like fea-ture extraction backbone, the designed attention-based fu-sion mechanism, and the classiﬁcation and regression head.
Experiments show that our TransT achieves very promis-ing results on six challenging datasets, especially on large-scale LaSOT, TrackingNet, and GOT-10k benchmarks. Our tracker runs at approximatively 50 f ps on GPU. Code and models are available at https://github.com/chenxin-dlut/TransT. 1.

Introduction
Visual object tracking is a fundamental task in computer vision, which aims to predict the position and shape of a given target in each video frame.
It has a wide range of applications in robot vision, video surveillance, unmanned driving, and other ﬁelds. The main challenges of tracking are large occlusion, severe deformation, interference from
*Equal contribution
†Corresponding author: Dr. Dong Wang, wdice@dlut.edu.cn
Ground-Truth
Ours
Ocean-online
DiMP50
Figure 1. Tracking results of TransT and two state-of-the-art track-ers. Our tracker is more robust and accurate in handling various challenges, such as occlusion, similar object interference, motion blur. similar objects, to name a few. Many efforts have been done in recent years [23, 28], however, designing a high-accuracy and real-time tracker is still a challenging task.
For most of the popular trackers (such as SiamFC [1],
SiamRPN [22], and ATOM [9]), correlation plays a critical role in integrating the template or target information into the regions of interest (ROI). However, the correlation op-eration itself is a linear matching process and leads to se-mantic information loss, which limits the tracker to capture the complicated non-linear interaction between the template and ROIs. Thus, previous models have to improve the non-linear representation ability by introducing fashion struc-tures [21, 44, 48], using additional modules [7, 46, 13], de-signing effective online updaters [2, 47, 10], to name a few.
This naturally introduces an interesting question: is there 8126
any better feature fusion method than correlation?
In this work, inspired by the core idea of Trans-former [38], we address the aforementioned problem by designing an attention-based feature fusion network and propose a novel Transformer tracking algorithm (named
TransT). The proposed feature fusion network consists of an ego-context augment module based on self-attention and a cross-feature augment module based on cross-attention.
This fusion mechanism effectively integrates the template and ROI features, producing more semantic feature maps than correlation. Figure 1 provides some representative vi-sual results, illustrating that our TransT method produces insightful attention maps regarding the target and performs better than other competing trackers. Our main contribu-tions are summarized as follows.
• We propose a novel Transformer tracking framework, consisting of feature extraction, Transformer-like fu-sion, and head prediction modules. The Transformer-like fusion combines the template and search region features solely using attention, without correlation.
• We develop our feature fusion network based on an ego-context augment module with self-attention as well as a cross-feature augment module with cross-attention. Compared with correlation-based feature fu-sion, our attention-based method adaptively focuses on useful information, such as edges and similar targets, and establishes associations between distant features, to make the tracker obtain better classiﬁcation and re-gression results.
• Numerous experimental results on many benchmarks show that the proposed tracker performs signiﬁ-cantly better than the state-of-the-art algorithms, es-pecially on large-scale LaSOT, TrackingNet, GOT-10k datasets. Besides, our tracker runs at about 50 f ps in
GPU, which meets the real-time requirement. 2.