Abstract
We address the problem of class incremental learning, which is a core step towards achieving adaptive vision in-telligence. In particular, we consider the task setting of in-cremental learning with limited memory and aim to achieve better stability-plasticity trade-off. To this end, we propose a novel two-stage learning approach that utilizes a dynam-ically expandable representation for more effective incre-mental concept modeling. Speciﬁcally, at each incremental step, we freeze the previously learned representation and augment it with additional feature dimensions from a new learnable feature extractor. This enables us to integrate new visual concepts with retaining learned knowledge. We dy-namically expand the representation according to the com-plexity of novel concepts by introducing a channel-level mask-based pruning strategy. Moreover, we introduce an auxiliary loss to encourage the model to learn diverse and discriminate features for novel concepts. We conduct ex-tensive experiments on the three class incremental learning benchmarks and our method consistently outperforms other methods with a large margin.1 1.

Introduction
Human can easily accumulate visual knowledge from past experiences and incrementally learn novel concepts.
Inspired by this, the problem of class incremental learning aims to design algorithms that can learn novel concepts in a sequential manner and eventually perform well on all ob-served classes. Such capability is indispensable for many real-world applications such as the intelligent robot [31], face recognition [19] and autonomous driving [25]. How-ever, achieving human-level incremental learning remains
∗Both authors contributed equally. This work was supported by Shang-hai NSF Grant (No. 18ZR1425100) 1Code is available at https://github.com/Rhyssiyan/DER-ClassIL.pytorch.
Figure 1: The average incremental accuracy for different model size. We compare our model with prior methods (WA[39], BiC[12], RPSNet[26], iCaRL[27], UCIR[12],
PODNet[6]) and the model trained on all the data (Joint) on the experiment CIFAR100-B0 of 10 steps. challenging for modern visual recognition systems.
There has been much effort attempting to address the in-cremental learning in literature [36, 23, 27, 3, 12, 33, 39].
Among them, perhaps the most effective strategy is to keep a memory buffer that stores part of observed data for the rehearsal [28, 29] in future. However, due to the limited size of data memory, such the incremental learning method still faces several typical challenges in the general continual learning task.
In particular, it requires a model to effec-tively incorporate novel concepts without forgetting the ex-isting knowledge, which is also known as stability-plasticity dilemma [9].
In detail, excessive plasticity often causes large performance degradation of the old categories, re-ferred to as catastrophic forgetting [8]. On the contrary, ex-cessive stability impedes the adaptation of novel concepts.
Most existing works attempt to achieve a trade-off be-tween stability and plasticity by gradually updating data representation and class decision boundary for increasingly 3014
larger label spaces. For instance, regularization methods [4] penalize the change of important weights of previously learned models, while knowledge distillation [27, 3, 12, 6, 34] preserves the network output with available data, and structure-based methods [26, 1] keep old parameters
ﬁxed when allocating more for new categories. Neverthe-less, all those methods either sacriﬁce the model plasticity for the stability, or are susceptible to forgetting due to fea-ture degradation of old concepts. As shown in Figure 1, a large performance gap still exists between the model (Joint) trained on all data and previous state-of-the-art models.
In this work, we aim to address the above weaknesses and achieve a better stability-plasticity trade-off in the class incremental learning. To this end, we adopt a two-stage learning strategy, decoupling the adaptation of feature rep-resentation and ﬁnal classiﬁer head (or classiﬁer for short) of a deep network [15]. Within this framework, we propose a novel data representation, referred to as super-feature, ca-pable of increasing its dimensionality to accommodate new classes. Our main idea is to freeze the previously learned representation and augment it with additional feature di-mensions from a new learnable extractor in each incremen-tal step. This enables us to retain the existing knowledge and provides enough ﬂexibility to learn novel concepts.
Moreover, our super-feature is expanded dynamically based on the complexity of novel concepts to maintain a compact representation.
To achieve this, we develop a modular deep classiﬁca-tion network composed of a super-feature extractor network and a linear classiﬁer. Our super-feature extractor network consists of multiple feature extractors with varying sizes, one for each incremental step. Speciﬁcally, at a new step, we expand the super-feature extractor network with a new feature extractor while keeping the parameters of previous extractors frozen. The features generated by all the extrac-tors are concatenated together and fed into the classiﬁer for the class prediction.
We train the new feature extractor and the classiﬁer on the memory and the newly incoming data. To encourage the new extractor to learn diverse and discriminative fea-tures for new classes, we design an auxiliary loss on distin-guishing new and old classes. Additionally, to remove the model redundancy and learn the compact features for novel classes, we apply a differentiable channel-level mask-based pruning method that dynamically prunes the network ac-cording to the difﬁculty of novel concepts. Finally, given the updated representation, we freeze the super-feature ex-tractor and ﬁnetune the classiﬁer on a balanced training sub-set to solve the class imbalance problem [33, 39].
We validate our approach on three commonly used including CIFAR-100, ImageNet-100, and benchmarks,
ImageNet-1000 datasets. The empirical results and the ab-lation study demonstrate the superiority of our method over prior state-of-the-art approaches. Interestingly, we also ﬁnd that our method could achieve positive backward and for-ward transfer between steps. The main contributions of our work are three-fold:
• To achieve better stability-plasticity trade-off, we de-velop a dynamically expandable representation and a two-stage strategy for the class incremental learning.
• We propose an auxiliary loss to promote the newly added feature module to learn novel classes effectively and a model pruning step to learn compact features.
• Our approach achieves the new state of the art perfor-mance on all three benchmarks under a wide range of model complexity, as shown in Figure 1. 2.