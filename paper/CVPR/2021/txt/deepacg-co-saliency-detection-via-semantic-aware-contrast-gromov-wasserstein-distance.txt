Abstract
The objective of co-saliency detection is to segment the co-occurring salient objects in a group of images. To ad-dress this task, we introduce a new deep network architec-ture via semantic-aware contrast Gromov-Wasserstein dis-tance (DeepACG). We ﬁrst adopt the Gromov-Wasserstein (GW) distance to build dense 4D correlation volumes for all pairs of image pixels within the image group. These dense correlation volumes enable the network to accurately dis-cover the structured pair-wise pixel similarities among the common salient objects. Second, we develop a semantic-aware co-attention module (SCAM) to enhance the fore-ground co-saliency through predicted categorical informa-tion. Speciﬁcally, SCAM recognizes the semantic class of the foreground co-objects, and this information is then mod-ulated to the deep representations to localize the related pixels. Third, we design a contrast edge-enhanced module (EEM) to capture richer contexts and preserve ﬁne-grained spatial information. We validate the effectiveness of our model using three largest and most challenging benchmark datasets (Cosal2015, CoCA, and CoSOD3k). Extensive ex-periments have demonstrated the substantial practical mer-it of each module. Compared with the existing works, Deep-ACG shows signiﬁcant improvements and achieves state-of-the-art performance. 1.

Introduction
Salient object detection mimics the human vision system to identify the most visually distinctive regions in a single image. Extending this task, co-saliency detection (CoSD)
∗Corresponding author. This work is supported in part by National Ma-jor Project of China for New Generation of AI (No. 2018AAA0100400), in part by the NSFC (61876088, 61876090, 61825601, U20B2065), in part by the 333 High-level Talents Cultivation Project of Jiangsu Province (BRA2020291).
Figure 1. Results of different module variants. (a) Input images; (b) Ground truth; (c) DeepACG w/o SCAM&EEM; (d) DeepACG w/o EEM; (e) The proposed DeepACG. is a recently emerging research topic to discover the com-mon salient foreground objects among an image group. Due to its useful potential, it has been increasingly applied in-to various vision applications, including image/video seg-mentation [12, 44, 56, 14], object co-localization [41], and weakly supervised semantic segmentation [40].
CoSD has traditionally been formulated as a two-step procedure. First, visual representations are described us-ing hand-engineered features, including: 1) low-level fea-tures, such as SIFT [2], color feature [29], and texture fea-ture [21]; 2) mid-level attributes [27]; and 3) multi-cue fu-sion [1]. Second, these features are then fed into a sub-sequent module to identify co-saliency. Nonetheless, the hand-engineered features are shallow in nature, and are not able to adapt to large variations of object appearances [58] and complex background textures [43]. Recent studies ﬁrst improve the CoSD by developing deep-learning-based ap-proaches [57, 46] to extract robust and richer visual rep-resentations and explore the semantic correlations between images. These methods have been shown as a promis-ing alternative to conventional approaches. Later, the end-to-end deep learning frameworks [17, 43] have been pro-posed to integrate the process of feature learning and salien-cy map prediction. Deep graph neural network has also been adopted to model the non-local and long-range de-13703
pendencies for CoSD [58]. Although these studies have made a remarkable progress and shown state-of-the-art per-formance, challenges still exist for further research. The
ﬁrst key question is how to design effective architectures to capture more accurate pixel-pair correspondences while incorporating structured information. Second, the seman-tic categories of the co-occurring salient objects are usually unknown, but the intra-class differences of shape and ap-pearances are huge. Third, most existing CoSD works fo-cus mainly on the region accuracy, but lose the ﬁne-grained information on boundaries.
Towards addressing the aforementioned challenges, we present a novel deep network architecture via semantic-aware contrast Gromov-Wasserstein distance (DeepACG) for CoSD. Figure 1 illustrates the effectiveness of Deep-ACG. Gromov-Wasserstein (GW) distance is a notation of distance among metric measure spaces [32, 31, 39]. GW distance is mostly related to the Earth Mover’s Distance (EMD) [35] that is widely applied in various classic vision tasks [35, 61, 51]. EMD is constructed between distribu-tions on the same geometric domain, which measures the structural similarity. Differently, GW distance is built be-tween different geometric domains [37]. It is able to mea-sure distances between pairs of nodes within each domain, as well as measuring how these distances compare to those in the counterpart domain [3]. GW distance can extrac-t soft matches in the presence of diverse geometric struc-tures [37]. It has been shown great success in ﬁnding cor-respondences between a source domain and target domain with shared (semantic) structures in both 2D and 3D set-tings [37]. We adopt GW distance to capture pair-wise cor-respondence for each pixel feature between the target image and source images in the group (Figure 1(c)). Then, we u-tilize the semantic categorical information of the co-salient objects to enhance the localization of pixels (Figure 1(d)).
In the end, a contrast edge-aware design is used to preserve the boundary information and further improve the segmen-tation accuracy (Figure 1(e)).
Our major contributions are summarized as follows: (1) We propose to adopt GW distance to extract dense 4D correlation volumes for all pairs of image pixels and
ﬁnd their correspondences between target and source image domains. With the GW distance, the network is able to min-imize distortion of long-and short-range distances, and ﬁnd the probabilistic matches. The GW distance matching layer can be embedded into the network for end-to-end training. (2) We present a Semantic-aware Co-Attention Module (SCAM) to enhance the co-occurring salient regions. S-CAM ﬁrst predicts the semantic categories of the co-salient objects. Then, this information is modulated to the feature representations to reﬁne the localized semantic regions. (3) We introduce a contrast Edge-Enhanced Module (EEM) to generate ﬁne-grained segmentation for the bound-aries of the co-salient objects. To our best knowledge, this is the ﬁrst edge-aware design in CoSD task. (4) Extensive experiments have been conducted to vali-date the effectiveness of our DeepACG on three largest and most challenging datasets, including Cosal2015 [54], Co-CA [59], and CoSOD3k [9]. Our DeepACG signiﬁcantly outperforms the baseline models, and achieves state-of-the-art performance. 2.