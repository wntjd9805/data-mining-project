Abstract
Absolute Learning
The majority of existing few-shot learning methods de-scribe image relations with binary labels. However, such binary relations are insufﬁcient to teach the network com-plicated real-world relations, due to the lack of decision smoothness. Furthermore, current few-shot learning mod-els capture only the similarity via relation labels, but they are not exposed to class concepts associated with objects, which is likely detrimental to the classiﬁcation performance due to underutilization of the available class labels. For instance, children learn the concept of tiger from a few of ac-tual examples as well as from comparisons of tiger to other animals. Thus, we hypothesize that both similarity and class concept learning must be occurring simultaneously. With these observations at hand, we study the fundamental prob-lem of simplistic class modeling in current few-shot learning methods. We rethink the relations between class concepts, and propose a novel Absolute-relative Learning paradigm to fully take advantage of label information to reﬁne the image an relation representations in both supervised and un-supervised scenarios. Our proposed paradigm improves the performance of several state-of-the-art models on publicly available datasets. 1.

Introduction ject Info. Predictor ject Info. Predictor
Deep learning, a popular learning paradigm in computer vision, has improved the performance on numerous computer vision tasks, such as category recognition, scene understand-ing and action recognition. However, deep models heavily rely on large amounts of labeled training data, costly data collection and labelling.
In contrast, humans enjoy the ability to learn and memo-rize new complex visual concepts from very few examples.
Inspired by this observation, researchers have focused on the so-called Few-shot Learning (FSL), for which a network is trained by the use of only few labeled training instances. Re-Predict yellow red green smooth furry spot eyes legs
Learn to predict various class annotations  when simulating the object relations.
Relative Learning
Compare
How similar?
Relations? e. g.,  colour, shape
Learn to simulate realistic object relations  with all available class annotations.
Absolute-relative Learning
Compare
How similar?
Relations? e. g.,  colour, shape
Predict yellow red green smooth furry spot eyes legs
Absolute Labels: 
Relative Labels:   
Colours, Shapes, Materials, WordNet
Colours, Shapes, Materials, WordNet
Class Label, Scales, Rotations, Jigsaw
Figure 1: Our few-shot learning paradigm. Absolute Learning (AL) refers to the strategy where a pipeline learns to predict ab-solute object information e.g., object or concept class. Relative
Learning (RL) denotes similarity (relation) learning with the use of binary {0, 1} and/or soft [0; 1] similarity labels. Absolute-relative
Learning (ArL) is a combination of AL and RL, which is akin to multi-task learning, and unary and pair-wise potentials in semantic segmentation. ArL is also conceptually closer to how humans learn from few examples. cently, deep networks based on relation-learning have gained the popularity [39, 37, 38, 35, 46, 47, 48, 43, 49, 22, 36].
Such approaches often apply a form of metric learning adapted to the few-shot learning task. They learn object relations (similarity learning on query and support images) based on support classes, and can be evaluated on images containing novel classes.
However, there are two major problems in these relation learning pipelines, namely, (i) binary {0, 1} labels are used to express the similarity between pairs of images, which cannot capture the similarity nuisances in the real-world setting due to the hardness of such modeling, which leads to biases in 19432
.2
the relation-based models, (ii) only pair-wise relation labels are used in these pipelines, so the models have no knowledge of the actual class concepts. In other words, these models are trained to learn the similarity between image pairs while they discard the explicit object classes despite they are accessible in the training stage.
We conjuncture that these two problems pose inconsis-tency between current few-shot learning approaches and human’s cognitive processes. To this end, we propose the
Absolute-relative Learning (ArL) which exposes few-shot learners to both similarity and class labels, and we employ semantic annotations to circumvent the issue with the some-what rigid binary similarity labels {0, 1}.
Our ArL consists of two separate learning modules, namely, Absolute Learning (AL) and Relative Learning (RL).
AL denotes the strategy in which we learn to predict the ac-tual object categories or class concepts in addition to learning the class relations. In this way, the feature extracting network is exposed to additional object- or concept-related knowl-edge. RL refers to the similarity learning strategy for which (apart of binary {0, 1} labels) we employ semantic annota-tions to promote the realistic similarity between image pairs.
We use attributes or word2vec to obtain the semantic relation labels and learn element-wise similarities e.g., if two objects have same colour, texture, etc. Such labels are further used as the supervisory cue in relation learning to capture the realistic soft relations between objects beyond the binary similarity.
By combing AL and RL which constitute on ArL, the relation network is simultaneously taught the class/object concepts together with more realistic class/object relations, thus naturally yielding an improved accuracy. Moreover, we use the predictions from the absolute and relative learners as interpretable features to promote the original relation learning via feedback connections.
Our approach is somewhat related to multi-modal learn-ing which leverages multiple sources of data for training and testing. However, while multi-modal learning combines multiple streams of data on network inputs, our ArL models the semantic annotations in the label space, that is, we use them as the network output. We believe that using multiple abstractions of labels (relative vs. absolute) encourages the network to preserve more information about objects relevant to the few-shot learning task. Our strategy beneﬁts from multi-task learning where two tasks learnt simultaneously help each other to outperform a naive fusion of two separate tasks. These tasks somewhat resemble unary and pair-wise potentials in semantic segmentation.
We note that obtaining the semantic information for novel classes (the testing step in few-shot learning) is not always easy or possible. Since our pipeline design is akin to multi-task rather than multi-modal learning, our model does not require additional labeling at the testing stage. Therefore, it is a more realistic setting than that of existing approaches.
In addition to the classic supervised few-shot recognition, we extend our ArL to the unsupervised scenario. Different with approach [12] that merely applies the self-supervised discriminator as an auxiliary task to improve the performance of supervised FSL, we develop an effective unsupervised
FSL based on ArL. As there is no annotations for training samples, we rely on augmentation labelling (e.g., rotations,
ﬂips and colors) to perform Absolute-relative Learning. Be-low, we summarize our contributions: i. We propose so-called Absolute-relative Learning which can be embedded into popular few-shot pipelines to exploit both similarity and object/concept labelling. ii. We extend our approach to unsupervised FSL, and we show how to create self-supervised annotations for un-supervised Absolute-relative Learning. iii. We investigate the inﬂuence of different types of sim-ilarity measures on attributes in Relative Learning to simulate realistic object relations. iv. We investigate the inﬂuence of different Absolute Learn-ing branches on the classiﬁcation performance.
To the best of our knowledge, we are the ﬁrst to perform an in-depth analysis of object and class relation modeling in the context of supervised and unsupervised few-shot learning given the Absolute-relative Learning paradigm via class, semantic and augmentation annotations. 2.