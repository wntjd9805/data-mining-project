Abstract
Due to the intensive cost of labor and expertise in anno-tating 3D medical images at a voxel level, most benchmark datasets are equipped with the annotations of only one type of organs and/or tumors, resulting in the so-called partially labeling issue. To address this issue, we propose a dynamic on-demand network (DoDNet) that learns to segment multi-ple organs and tumors on partially labeled datasets. DoD-Net consists of a shared encoder-decoder architecture, a task encoding module, a controller for dynamic ﬁlter gen-eration, and a single but dynamic segmentation head. The information of current segmentation task is encoded as a task-aware prior to tell the model what the task is expected to achieve. Different from existing approaches which ﬁx ker-nels after training, the kernels in dynamic head are gener-ated adaptively by the controller, conditioned on both in-put image and assigned task. Thus, DoDNet is able to segment multiple organs and tumors, as done by multiple networks or a multi-head network, in a much efﬁcient and
ﬂexible manner. We created a large-scale partially labeled dataset called MOTS and demonstrated the superior per-formance of our DoDNet over other competitors on seven organ and tumor segmentation tasks. We also transferred the weights pre-trained on MOTS to a downstream multi-organ segmentation task and achieved state-of-the-art per-formance. This study provides a general 3D medical im-age segmentation model that has been pre-trained on a large-scale partially labeled dataset and can be extended (after ﬁne-tuning) to downstream volumetric medical data segmentation tasks. Code and models are available at: https://git.io/DoDNet
∗J. Zhang and Y. Xie contributed equally. Corresponding author: Y.
Xia and C. Shen. Work was done when J. Zhang and Y. Xie were visiting
The University of Adelaide.
Hepatic Vessel & Tumor
Kidney & Tumor
Pancreas & Tumor
Liver & Tumor
Lung Tumor
Colon Tumor
Spleen
Figure 1 – Illustration of partially labeled multi-organ and tu-mor segmentation. This task aims to segment multiple organs and tumors using a network trained on several partially labeled datasets, each of which is originally specialized for the segmen-tation of a particular abdominal organ and/or related tumors.
For instance, the ﬁrst dataset only has annotations of the liver and liver tumors, and the second dataset only provides annota-tions of kidneys and kidney tumors. Here each color represents a partially labeled dataset. 1.

Introduction
Automated segmentation of abdominal organs and tu-mors using computed tomography (CT) is one of the most fundamental yet challenging tasks in medical image analy-sis [22, 18]. It plays a pivotal role in a variety of computer-aided diagnosis tasks, including lesion contouring, surgi-cal planning, and 3D reconstruction. Constrained by the labor cost and expertise, it is hard to annotate multiple or-gans and tumors at voxel level in a large dataset. Conse-quently, most benchmark datasets were collected for the segmentation of only one type of organs and/or tumors, and all task-irrelevant organs and tumors were annotated as the background (see Fig. 1). For instance, the LiTS 1195
dataset [1] only has annotations of the liver and liver tumors, and the KiTS dataset [13] only provides annotations of kid-neys and kidney tumors. These partially labeled datasets are distinctly different from the segmentation benchmarks in other computer vision areas, such as PASCAL VOC [8] and Cityscapes [5], where multiple types of objects were annotated on each image. Therefore, one of the signiﬁ-cant challenges facing multi-organ and tumor segmentation is the so-called partially labeling issue, i.e., how to learn the representation of multiple organs and tumors under the supervision of these partially annotated images.
Mainstream approaches address this issue via separating the partially labeled dataset into several fully labeled sub-sets and training a network on each subset for a speciﬁc segmentation task [39, 16, 40, 21, 43], resulting in ‘multi-ple networks’ shown in Fig. 2(a). Such an intuitive strat-egy, however, increases the computational complexity dra-matically. Another commonly-used solution is to design a multi-head network (see Fig. 2(b)), which is composed of a shared encoder and multiple task-speciﬁc decoders (heads)
[3, 9, 30]. In the training stage, when each partially labeled data is fed to the network, only one head is updated and oth-ers are frozen. The inferences made by other heads are un-necessary and wasteful. Besides, the inﬂexible multi-head architecture is not easy to extend to a newly labeled task.
In this paper, we propose a dynamic on-demand net-work (DoDNet), which can be trained on partially labeled datasets for multi-organ and tumor segmentation. DoDNet is an encoder-decoder network with a single but dynamic head (see Fig. 2(c)), which is able to segment multiple or-gans and tumors as done by multiple networks or a multi-head network. The kernels in the dynamic head are gener-ated adaptively by a controller, conditioned on the input im-age and assigned task. Speciﬁcally, the task-speciﬁc prior is fed to the controller to guide the generation of dynamic head kernels for each segmentation task. Owing to the light-weight design of the dynamic head, the computational cost of repeated inference can be ignored when compared to that of a multi-head network. We evaluate the effectiveness of
DoDNet on seven organ and tumor segmentation bench-marks, involving the liver and tumors, kidneys and tumors, hepatic vessels and tumors, pancreas and tumors, colon tu-mors, and spleen. Besides, we transfer the weights pre-trained on partially labeled datasets to a downstream multi-organ segmentation task, and achieve state-of-the-art per-formance on the Multi-Atlas Labeling Beyond the Cranial
Vault Challenge dataset. Our contributions are three-fold:
• We attempt to address the partially labeling issue from a new perspective, i.e., proposing a single network that has a dynamic segmentation head to segment multiple organs and tumors as done by multiple networks or a multi-head network.
• Different from the traditional segmentation head which is ﬁxed after training, the dynamic segmentation head in our model is adaptive to the input and assigned task, leading to much improved efﬁciency and ﬂexibility.
• The proposed DoDNet pre-trained on partially labeled datasets can be transferred to downstream annotation-limited segmentation tasks, and hence is beneﬁcial for the medical community where only limited annota-tions are available for 3D image segmentation. 2.