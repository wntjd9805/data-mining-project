Abstract
Recently few-shot object detection is widely adopted to deal with data-limited situations. While most previous works merely focus on the performance on few-shot cate-gories, we claim that detecting all classes is crucial as test samples may contain any instances in realistic applications, which requires the few-shot detector to learn new concepts without forgetting. Through analysis on transfer learning based methods, some neglected but beneﬁcial properties are utilized to design a simple yet effective few-shot detector,
Retentive R-CNN. It consists of Bias-Balanced RPN to de-bias the pretrained RPN and Re-detector to ﬁnd few-shot class objects without forgetting previous knowledge. Exten-sive experiments on few-shot detection benchmarks show that Retentive R-CNN signiﬁcantly outperforms state-of-the-art methods on overall performance among all settings as it can achieve competitive results on few-shot classes and does not degrade the base class performance at all.
Our approach has demonstrated that the long desired never-forgetting learner is available in object detection. 1.

Introduction
Computer vision community has seen signiﬁcant progress by applying deep convolutional neural networks trained from a massive amount of data. However, sufﬁcient training data is sometimes unavailable due to extensive hu-man labor for annotation, especially for object detection, and the source data distribution may be long-tailed by na-ture such that certain object categories only contain limited examples. These circumstances raise the need to learn un-der a low-data regime effectively. Inspired by human’s abil-ity to learn new concepts rapidly from a handful of exam-ples, few-shot learning[22, 19, 40, 37, 38, 30, 9, 8, 35, 3, 2, 42] is then proposed to mimic such generalization capabil-ity, with extensive research on image classiﬁcation.
Several recent works[1, 17, 46, 18, 41, 44, 45, 14, 7, 6, 16, 43, 29] have attempted to apply few-shot learning techniques on instance-level tasks, such as object detection, where an extra localization task is included and more com-Figure 1. Performance of previous methods and ours on general-ized few-shot objection on MS-COCO[25] under 10-shot settings, where base class AP and novel class AP are represented by x- and y-axis respectively. The red dashed line represents the base class
AP of a base class detector. Our method does not degrade the base class AP while reaching state-of-the-art performance on novel cat-egories. plicated visual contexts and features encountered, making few-shot object detection way more challenging. However, the majority focus merely on the performance of few-shot categories and ignore the catastrophic forgetting of base classes, which is not realistic. Unlike image classiﬁcation, the capability to detect the joint domain of both classes at once is even crucial for object detection since samples at test time may contain instances of both classes, which re-quires the detector to be computationally efﬁcient and learn new concepts without catastrophic forgetting. The problem of detecting objects of both classes is called Generalized
Few-Shot Detection (G-FSD).
A popular stream of few-shot object detection[17, 46, 45, 14, 6] falls under the umbrella of meta-learning by leverag-ing external exemplars to do a visual search within the im-age. As their computational complexity is proportional to the number of categories, these methods become rather slow or even unavailable when tackling both sets of classes of a dataset. A promising alternative is transfer learning based 4527
approaches[1, 47, 41, 44], which can be trained incremen-tally to detect all classes in a single run. Wang et al.[41] share a similar interest in maintaining the overall perfor-mance on both classes and achieve competitive results by their two-stage ﬁnetuning approach (TFA), in which only the last layer of classiﬁcation and box regression branch of
RCNN[11, 10, 34] is ﬁnetuned while freezing backbone and
RPN[34]. Nevertheless, there still exists a non-negligible base class performance gap with the pretrained model.
To diminish the gap, we ﬁrst analyze the pretrained
RCNN of TFA[41] and ﬁnd advantageous but neglected properties: 1) pretrained base class detector does not predict many false positives on novel class instances despite their saliency 2) RPN is biased on its seen classes instead of be-ing ideally class-agnostic, thus freezing it without exposure to new classes can be suboptimal. By utilizing these prop-erties, we propose a simple yet effective transfer learning based method, Retentive R-CNN, to meet the demands of
G-FSD to learn without forgetting and detect all categories efﬁciently. The name of Retentive R-CNN comes from its surprising ability to fully reserve the performance on base classes. Retentive R-CNN combines base and novel class detectors by Bias-Balanced RPN and Re-detector, introduc-ing little extra cost. Bias-Balanced RPN can better adapt to novel class objects and remain powerful on the base class, thus provides better proposals for both training and infer-ence. Re-detector utilizes a consistency loss to regularize the adaptation during ﬁnetuning and takes advantage of the base class detector’s property to incrementally detect with-out forgetting. It is worth mentioning that our method does not degrade the base class performance at all while achiev-ing competitive performance on novel classes as well, as shown in Figure1. Our contributions can be concluded as follows:
• We ﬁnd properties of base class detectors neglected in few-shot detection literature, which can be utilized to improve both base and novel class performance for transfer learning based methods with little overhead.
• We propose a few-shot detector without forgetting,
Retentive R-CNN, with Bias-Balanced RPN and Re-detector to assist novel class adaptation with base class knowledge and ensemble base and novel class detec-tors.
• Our method achieves state-of-the-art overall perfor-mance on the few-shot detection benchmark[41, 17] across all settings, with leading base class metrics and competitive novel class metrics. 2.