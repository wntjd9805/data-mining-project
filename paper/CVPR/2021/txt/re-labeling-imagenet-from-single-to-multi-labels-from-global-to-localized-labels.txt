Abstract
ImageNet has been the most popular image classiﬁca-tion benchmark, but it is also the one with a signiﬁcant level of label noise. Recent studies have shown that many samples contain multiple classes, despite being assumed to be a single-label benchmark. They have thus proposed to turn ImageNet evaluation into a multi-label task, with ex-haustive multi-label annotations per image. However, they have not ﬁxed the training set, presumably because of a formidable annotation cost. We argue that the mismatch be-tween single-label annotations and effectively multi-label images is equally, if not more, problematic in the training setup, where random crops are applied. With the single-label annotations, a random crop of an image may contain an entirely different object from the ground truth, introduc-ing noisy or even incorrect supervision during training. We thus re-label the ImageNet training set with multi-labels. We address the annotation cost barrier by letting a strong im-age classiﬁer, trained on an extra source of data, generate the multi-labels. We utilize the pixel-wise multi-label pre-dictions before the ﬁnal pooling layer, in order to exploit the additional location-speciﬁc supervision signals. Training on the re-labeled samples results in improved model perfor-mances across the board. ResNet-50 attains the top-1 accu-racy of 78.9% on ImageNet with our localized multi-labels, which can be further boosted to 80.2% with the CutMix reg-ularization. We show that the models trained with local-ized multi-labels also outperforms the baselines on trans-fer learning to object detection and instance segmentation tasks, and various robustness benchmarks. The re-labeled
ImageNet training set, pre-trained weights, and the source code are available at https://github.com/naver-ai/relabel_imagenet. 1.

Introduction
The ImageNet dataset [38] has been at the center of modern advances in computer vision. Since the introduction
Figure 1. Re-labeling ImageNet training data. Original
ImageNet annotation is a single label (“ox”), whereas the image contains multiple ImageNet categories (“ox”, “barn”, and “fence”). Random crops of an image may contain an entirely different object category from the global annota-tion. Our method (ReLabel) generates location-wise multi-labels, resulting in cleaner supervision per random crop. of ImageNet, image recognition models based on convolu-tional neural networks have made quantum jumps in perfor-mances [27, 41, 15]. Improving the model performance on
ImageNet is seen as a litmus test for the general applicabil-ity of the model and the transfer learning performances on downstream tasks [25, 57].
ImageNet, however, turns out to be noisier than one would expect. Recent studies [42, 49, 2, 39] have shed light on an overlooked problem with ImageNet that a signiﬁcant portion of the dataset is composed of images with multi-ple possible labels. This contradicts the underlying assump-tion that there is only a single object class per image: the evaluation metrics penalize any prediction beyond the sin-gle ground-truth class. Thus, researchers have reﬁned the 12340
ImageNet validation samples with multi-labeling policy us-ing human annotators [2, 39], and proposed new multi-label evaluation metrics. Under these new evaluation schemes, re-cent state-of-the-art models [53, 48] that seem to have sur-passed the human level of recognition have been found to fall short of the human performance level.
The mismatch between the multiplicity of object classes per image and the assignment of single labels results in problems not only for evaluation, but also for training: the supervision becomes noisy. The widespread adoption of random crop augmentation [44] aggravates the problem. A random crop of an image may contain an entirely different object from the original single label, introducing potentially wrong supervision signals during training, as in Figure 1.
The random crop augmentation makes supervision noisy not only for images with multiple classes. Even for images with a single class, the random crop often contains no fore-ground object. It is estimated that, under the standard train-ing setup1, 8% of the random crops have no overlap with the ground truths. Only 23.5% of the random crops have the intersection-over-union (IoU) measure greater than 50% with the ground truth boxes (see Figure 2). Training a model on ImageNet inevitably involves a lot of noisy supervision.
Ideally, for each training image, we want a human an-notation telling the model (1) the full set of classes present (multi-label) and (2) where each object is located (localized label). One such format would be a dense pixel labeling
L ∈ {0, 1}H×W ×C where C is the number of classes, as done for semantic segmentation ground truths. However, it is hardly scalable to collect even just the multi-label annota-tions for the 1.28 million ImageNet training samples. It took more than three months for ﬁve human experts (authors of
[39]) to label mere 2,000 images.
In this paper, we propose a re-labeling strategy,
ReLabel, to obtain pixel-wise labeling L ∈ RH×W ×C, which are both multi-labels and localized labels, on the Im-ageNet training set. We use strong classiﬁers trained on ex-ternal training data to generate those labels. The predictions before the ﬁnal pooling layer have been used. We also con-tribute a novel training scheme, LabelPooling, for train-ing classiﬁers based on the dense labels. For each random crop sample, we compute the multi-label ground truth by pooling the label scores from the crop region. ReLabel in-curs only a one-time cost for generating the label maps per dataset, unlike e.g. Knowledge Distillation [20] which in-volves one forward pass per training iteration to generate the supervision. Our LabelPooling supervision adds only a small amount of computational cost on the usual single-label cross-entropy supervision.
We present an extensive set of evaluations for vari-ous model architectures trained with ReLabel on multi-ple datasets and tasks. On ImageNet classiﬁcation, training 1A random crop is sampled from 8% to 100% of the entire image area.
Figure 2. Cumulative distribution of Intersection-over-Union (IoU) between the random crops and ground-truth bounding boxes. We sample 100 random crops per image on the ImageNet validation set (50K images).
ResNet-50 with ImageNet ReLabel has achieved a top-1 ac-curacy of 78.9%, a +1.4 pp gain over the baseline model trained with the original labels. The accuracy of ResNet-50 reaches 80.2% by employing the CutMix regularization on top, a new state-of-the-art performance on ImageNet to the best of our knowledge. Models trained with ReLabel have also consistently improved accuracies on ImageNet multi-label evaluation metrics proposed by [2, 39]. ReLabel and
LabelPooling result in consistent improvements for transfer learning experiments, including the object detection and in-stance segmentation tasks on COCO and ﬁne-grained clas-siﬁcations tasks. We further test LabelPooling on the multi-label classiﬁcation task on COCO. Finally, we show that models trained with ReLabel are more resilient to test-time perturbations, as will be veriﬁed through experiments on several robustness benchmarks. 2.