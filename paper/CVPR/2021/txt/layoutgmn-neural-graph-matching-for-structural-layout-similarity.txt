Abstract
We present a deep neural network to predict structural similarity between 2D layouts by leveraging Graph Match-ing Networks (GMN). Our network, coined LayoutGMN, learns the layout metric via neural graph matching, using an attention-based GMN designed under a triplet network setting. To train our network, we utilize weak labels ob-tained by pixel-wise Intersection-over-Union (IoUs) to de-ﬁne the triplet loss. Importantly, LayoutGMN is built with a structural bias which can effectively compensate for the lack of structure awareness in IoUs. We demonstrate this on two prominent forms of layouts, viz., ﬂoorplans and UI designs, via retrieval experiments on large-scale datasets.
In particular, retrieval results by our network better match human judgement of structural layout similarity compared to both IoUs and other baselines including a state-of-the-art method based on graph neural networks and image con-volution. In addition, LayoutGMN is the ﬁrst deep model to offer both metric learning of structural layout similarity and structural matching between layout elements. 1.

Introduction
Two-dimensional layouts are ubiquitous visual abstrac-tions in graphic and architectural designs. They typically represent blueprints or conceptual sketches for such data as ﬂoorplans, documents, scene arrangements, and UI de-signs. Recent advances in pattern analysis and synthesis have propelled the development of generative models for layouts [11, 25, 47, 15, 26] and led to a steady accumulation of relevant datasets [48, 42, 10, 46]. Despite these develop-ments however, there have been few attempts at employing a deeply learned metric to reason about layout data, e.g., for retrieval, data embedding, and evaluation. For example, current evaluation protocols for layout generation still rely heavily on segmentation metrics such as intersection-over-union (IoU) [15, 30] and human judgement [15, 26].
The ability to compare data effectively and efﬁciently is
† Corresponding Author:manyil@sfu.ca
Figure 1. LayoutGMN learns a structural layout similarity metric between ﬂoorplans and other 2D layouts, through attention-based neural graph matching. The learned attention weights (numbers shown in the boxes) can be used to match the structural elements. arguably the most foundational task in data analysis. The key challenge in comparing layouts is that it is not purely a task of visual comparison — it depends critically on infer-ence and reasoning about structures, which are expressed by the semantics and organizational arrangements of the el-ements or subdivisions which compose a layout. Hence, none of the well-established image-space metrics, whether model-driven, perceptual, or deeply learned, are best suited to measure structural layout similarity. Frequently applied similarity measures for image segmentation such as IoUs and F1 scores all perform pixel-level matching “in place”
— they are not structural and can be sensitive to element misalignments which are structure-preserving.
In this work, we develop a deep neural network to predict structural similarity between two 2D layouts, e.g., ﬂoor-plans or UI designs. We take a predominantly structural view of layouts for both data representation and layout com-parison. Speciﬁcally, we represent each layout using a di-rected, fully connected graph over its semantic elements.
Our network learns structural layout similarity via neural graph matching, where an attention-based graph matching network [27] is designed under a triplet network setting.
The network, coined LayoutGMN, takes as input a triplet of layout graphs, composed together by one pair of anchor-positive and one pair of anchor-negative graphs, and per-forms intra-graph message passing and cross-graph infor-mation communication per pair, to learn a graph embedding 11048
Figure 2. Structure matching in LayoutGMN “neutralizes” IoU feedback. In each example (left: ﬂoorplan; right: UI design), a training sample N labeled as “Negative” by IoU is more struc-turally similar to the anchor (A) than P , a “Positive” sample. With structure matching, our network predicts a smaller A-to-N dis-tance than A-to-P distance in each case, which contradicts IoU. for layout similarity prediction. In addition to returning a metric, the attention weights learned by our network can also be used to match the layout elements; see Figure 1.
To train our triplet network, it is natural to consider hu-man labeling of positive and negative samples. However, it is well-known that subjective judgements by humans over structured data such as layouts are often unreliable, espe-cially with non-experts [45, 2]. When domain experts are employed, the task becomes time-consuming and expen-sive [45, 2, 14, 9, 20, 41], where discrepancies among even these experts still remain [14]. In our work, we avoid this issue by resorting to weakly supervised training of Layout-GMN, which obtains positive and negative labels from the training data through thresholding using layout IoUs [30].
The motivations behind our network training using IoUs are three-fold, despite the IoU’s shortcomings for structural matching. First, as one of the most widely-used layout sim-ilarity measures [30, 15], IoU does have its merits. Sec-ond, IoUs are objective and much easier to obtain than ex-pert annotations. Finally and most importantly, our network has a built-in inductive bias to enforce structural correspon-dence, via inter-graph information exchange, when learning the graph embeddings. The inductive bias results from an attention-based graph matching mechanism, which learns structural matching between two graphs at the node level (Eq 3, 6). Such a structural bias can effectively compensate for the lack of structure awareness in the IoU-based triplet loss during training. In Figure 2, we illustrate the effect of this structural bias on the metric learned by our network.
Observe that the last two layouts are more similar struc-turally than the ﬁrst two. This is agreed with by our metric
LayoutGMN, but not by IoU feedback.
We evaluate our network on retrieval tasks over large datasets of ﬂoorplans and UI designs, via Precision@k scores, and investigate the stability of the proposed met-ric by checking retrieval consistency between a query and its top-1 result, over many such pairs; see Sec. 5.2.Over-all, retrieval results by LayoutGMN better match human judgement of structural layout similarity compared to both
IoUs and other baselines including a state-of-the-art method based on graph neural networks [30]. Finally, we show a la-bel transfer application for ﬂoorplans enabled by the struc-ture matching learned by our network (Sec 5.5). 2.