Abstract
Camera localization aims to estimate 6 DoF camera poses from RGB images. Traditional methods detect and match interest points between a query image and a pre-built 3D model. Recent learning-based approaches encode scene structures into a speciﬁc convolutional neural net-work (CNN) and thus are able to predict dense coordi-nates from RGB images. However, most of them require re-training or re-adaption for a new scene and have dif-ﬁculties in handling large-scale scenes due to limited net-work capacity. We present a new method for scene agnos-tic camera localization using dense scene matching (DSM), where a cost volume is constructed between a query image and a scene. The cost volume and the corresponding co-ordinates are processed by a CNN to predict dense coordi-nates. Camera poses can then be solved by PnP algorithms.
In addition, our method can be extended to temporal do-main, which leads to extra performance boost during testing time. Our scene-agnostic approach achieves comparable accuracy as the existing scene-speciﬁc approaches, such as
KFNet, on the 7scenes and Cambridge benchmark. This ap-proach also remarkably outperforms state-of-the-art scene-agnostic dense coordinate regression network SANet. The
Code is available at https://github.com/Tangshitao/Dense-Scene-Matching. 1.

Introduction
Camera Localization aims to estimate a 6-DoF camera pose of an image in a known environment. It is an important module in applications such as mobile navigation, simul-taneous localization and mapping (SLAM) and augmented reality (AR). Camera localization methods can be broadly categorized as regression-based and structure-based. Ear-lier methods [23, 21, 22, 47] directly regress the camera poses from images, which are limited by the nature of im-age retrieval and generally less accurate [41]. In compari-son, structure-based methods [3, 43, 4, 36, 53, 39, 46] grad-ually become the trend and solve the problem in two stages:
ﬁrst, establishing the correspondences between 2D query image pixels and 3D scene points; second, estimating the desired camera pose by PnP [18] combined with different
RANSAC [13] algorithms.
According to how they establish the 2D-3D correspon-dences, the structure-based methods can be further catego-rized into two classes: 1) sparse feature matching [36, 38, 39, 46]; 2) scene coordinate map regression [3, 43, 4, 53, 24]. The sparse feature matching methods detect and match handcrafted [27] or CNN-based [10, 38] feature points be-tween a query image and scene images, which is able to handle arbitrary scenes. On the other hand, coordinate map regression methods predict dense 3D coordinates at all im-age pixels from a random forest [44] or a convolutional neu-ral network (CNN) [3, 43]. The estimated dense coordinate maps can be effectively applied to augmented reality and robotics applications such as virtual object insertion or ob-stacle avoidance. But these methods are often limited to the scene where the random forests or CNN is trained.
In this paper, we focus on the coordinate map regression approach. Recently, instead of encoding speciﬁc scene in-formation in network parameters [44, 3, 43], Yang et.al, pro-pose the ﬁrst dense coordinate regression network SANet for arbitrary scenes [48]. SANet extracts a scene repre-sentation from some scene images and corresponding 3D coordinates by 2D-3D matching. In this way, it can be ap-plied to different scenes without re-training or re-adaption.
However, due to the irregular nature of a scene, SANet ran-domly selects coordinates within a region using ball query and leverages PointNet [32] to regress per-pixel 3D coor-dinates. This operation undermines the pose accuracy and is computationally-heavy because a shared PointNet is re-quired to make prediction on each pixel individually.
In order to address this problem, we present a new scene-agnostic camera localization network exploiting dense scene matching (DSM), which matches each query image pixel with the scene via a cost volume. With end-to-end training, the cost volume explicitly enforces more accu-rate scene points to have a higher correlation with the input query pixel. Since the scene structure is irregular, which makes the number of query-scene correlations different for each image pixel, we propose a simple yet effective solu-1831
Query Image t-1
D
S
M
D
S
M
D
S
M
D
S
M
Query Image t
Image retrieval 
Scene Image
Image Feature
Scene coords. map
R
A
N
S
A
C
+
P n
P
Figure 1: Overview of our framework. Our method predicts dense coordinate maps in a coarse-to-ﬁne manner. The DSM module receives a query image feature map, some scene image feature maps and the corresponding scene coordinates to predict a dense coordinate map for the query image. This predicted scene coordinates are then used to solve camera poses with RANSAC and PnP algorithms. tion to unify the size of all cost volumes: sorting and select-ing the best K candidates and feed them to a convolutional neural network for dense coordinate regression. The cost volume can be further fused with temporal correlations be-tween consecutive query images during inference, so that our method can be extended to video localization.
We have evaluated our method on several benchmark datasets including indoor scenes, 7scenes [44] and large-scale outdoor scenes, Cambridge [23]. We have shown
DSM achieves state-of-the-art performance among scene-speciﬁc methods including DSAC++ in terms of both pose accuracy and coordinate accuracy, and outperforms scene-agnostic methods, e.g. SANet, by a large margin. 2.