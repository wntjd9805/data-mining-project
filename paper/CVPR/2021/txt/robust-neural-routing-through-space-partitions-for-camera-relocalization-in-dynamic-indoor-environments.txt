Abstract
Localizing the camera in a known indoor environment is a key building block for scene mapping, robot navigation,
AR, etc. Recent advances estimate the camera pose via opti-mization over the 2D/3D-3D correspondences established between the coordinates in 2D/3D camera space and 3D world space. Such a mapping is estimated with either a convolution neural network or a decision tree using only the static input image sequence, which makes these approaches vulnerable to dynamic indoor environments that are quite common yet challenging in the real world. To address the aforementioned issues, in this paper, we propose a novel outlier-aware neural tree which bridges the two worlds, deep learning and decision tree approaches. It builds on three important blocks: (a) a hierarchical space partition over the indoor scene to construct the decision tree; (b) a neural routing function, implemented as a deep classiﬁcation net-work, employed for better 3D scene understanding; and (c) an outlier rejection module used to ﬁlter out dynamic points during the hierarchical routing process. Our proposed al-gorithm is evaluated on the RIO-10 benchmark developed for camera relocalization in dynamic indoor environments.
It achieves robust neural routing through space partitions and outperforms the state-of-the-art approaches by around 30% on camera pose accuracy, while running comparably fast for evaluation. 1.

Introduction
The task of camera relocalization is to estimate the 6-DoF (Degree of Freedom) camera pose from a test frame with respect to a known environment. It is of great impor-tance for many computer vision and robotics applications,
*Equal Contribution
Figure 1. Demonstration of our algorithm. We build a hierarchical space partition over the entire scene environment to construct a 3-level 4-way neural tree. For the input static (green) or dynamic (red) points from a visual observation, our neural tree will route them into either inlier (solid line) or outlier (dashed line) categories.
Only the points falling into the inlier category will be considered for camera pose estimation. such as Simultaneously Localization and Mapping (SLAM),
Augmented Reality (AR), and navigation, etc. One popular solution to camera relocalization is to make use of advanced hardware, e.g., LIDAR sensors, WIFI, Bluetooth or GPS.
However, these approaches may suffer from bad weather for outdoor environments, and instability or blocked signal for indoor environments. Another popular solution replaces the above hardware with a RGB/RGB-D sensor that feeds only visual observation for camera relocalization, also known as visual relocalization, which is the focus of this paper.
The problem of visual relocalization has been studied for decades, and recent advances [11, 32] have reached around 100% camera pose accuracy (5cm / 5◦) on the popular in-8544
door scene benchmarks 7-scenes [50] and 12-scenes [53].
One type of successful approach in this regard is designed based on decision trees, which was ﬁrstly introduced into the camera relocalization ﬁeld in [50], with many follow-ups
[35, 36, 37, 12, 11]. They build a binary regression forest that takes a query image point sampled from the visual ob-servation as input, and routes it into one leaf node via a hierarchical splitting strategy, which is simply implemented as color/depth comparison within the neighbourhood of the query point. The leaf node ﬁts a density distribution over the 3D world coordinates from the training scene. Hence, by evaluating the decision tree with a test image, a 2D/3D-3D correspondence can be easily established between the in-put sample and regressed world coordinate for camera pose optimization.
Although the aforementioned approaches are good at camera relocalization in static training environments, they tend to fail in dynamic test scenes, which are quite common yet challenging in real life. This is mainly due to the fact that the decision tree is constructed using only the static training image sequence so that, for any image point belonging to dynamic regions captured during evaluation, it is challenging to locate its correct correspondence in the leaf node. Recent studies [56] have demonstrated that the decision tree based approaches achieve around 28% camera pose accuracy (5cm 5◦), which is also the best among all the competitors, in their proposed RIO-10 benchmark developed for dynamic indoor scenes. This performance is far from being comparable to the ones in static indoor scenes.
In order to tackle the challenges of camera relocalization in dynamic indoor environments, in this paper, we propose to learn an outlier-aware neural tree to help establish point correspondences for accurate camera pose estimation focus-ing only on the conﬁdent static regions of the environment.
Our algorithm inherits the general framework of decision trees, but mainly differs in the following aspects in order to obtain better generalization ability in dynamic test scenes. (a) Hierarchical space partition. We perform an explicit hierarchical spatial partition of the 3D scene in the world space to construct the decision tree. Then each split node in the decision tree not only performs a hard data parti-tion selection, but in fact one which also corresponds to a physically-meaningful 3D geometric region. (b) Neural routing function. Given an input point sampled from the 2D visual observation, the split node needs to determine which divided sub-region in the world space to go. Such a classiﬁcation task needs more contextual understanding of the 3D environment. Therefore, we propose a neural routing function, implemented as a deep classiﬁcation network, for learning the splitting strategy. (c) Outlier rejection. In or-der to deal with potential dynamic input points, we propose to consider these points as outliers and reject them during the hierarchical routing process in the decision tree. Speciﬁcally, the neural routing function learns to classify any input point from the dynamic region into the outlier category, stopping any further routing for that point. Once our proposed neural tree is fully trained, we follow the optimization and reﬁne-ment steps in existing works [12, 11] to calculate the ﬁnal pose.
We further train and test our proposed outlier-aware neu-ral tree on the recent camera relocalization benchmark, RIO-10, which aims for dynamic indoor scenes. Experimental results demonstrate that our proposed algorithm outperforms the state-of-the-art localization approaches by at least 30% on camera pose accuracy. More analysis shows that our algorithm is robust to various types of scene changes and successfully rejects most dynamic input samples during neu-ral routing. 2.