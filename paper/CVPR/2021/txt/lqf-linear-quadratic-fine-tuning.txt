Abstract
Classiﬁers that are linear in their parameters, and trained by optimizing a convex loss function, have predictable be-havior with respect to changes in the training data, initial conditions, and optimization. Such desirable properties are absent in deep neural networks (DNNs), typically trained by non-linear ﬁne-tuning of a pre-trained model. Previous at-tempts to linearize DNNs have led to interesting theoretical insights, but have not impacted the practice due to the sub-stantial performance gap compared to standard non-linear optimization. We present the ﬁrst method for linearizing a pre-trained model that achieves comparable performance to non-linear ﬁne-tuning on most of real-world image classiﬁca-tion tasks tested, thus enjoying the interpretability of linear models without incurring punishing losses in performance.
LQF consists of simple modiﬁcations to the architecture, loss function and optimization typically used for classiﬁcation:
Leaky-ReLU instead of ReLU, mean squared loss instead of cross-entropy, and pre-conditioning using Kronecker factor-ization. None of these changes in isolation is sufﬁcient to approach the performance of non-linear ﬁne-tuning. When used in combination, they allow us to reach comparable per-formance, and even superior in the low-data regime, while enjoying the simplicity, robustness and interpretability of linear-quadratic optimization. 1.

Introduction
Deep neural networks (DNNs) are powerful but ﬁnicky.
They can carve complex decision boundaries through high dimensional data such as images, but even small changes in the training set, regularization method, or choice of hy-perparameters can lead to vastly different outcomes. This phenomenon, typical of highly non-linear optimization, is ob-served even when ﬁne-tuning a pre-trained model, which is the most common modus operandi in practice: Starting from a DNN trained on some dataset, a few steps of stochastic gradient descent (SGD) are used to minimize a loss func-tion computed on a another dataset. This is unlike models whose parameters are found via convex optimization, such as support-vector machines: They have a global optimum, found from any initial condition, and small changes in the data, the regularization scheme, and hyperparameters yield small and interpretable changes in the ﬁnal solution.
Lack of robustness to training conditions, and opaque-ness of the resulting model, appear to be the price to pay for more performing and expressive classiﬁers such as a DNNs.
This price is measured in time and cost of hyperparameter optimization (HPO). For example, simply changing the mul-tiplier for weight decay requires retraining from scratch, as optimizing the new loss starting from the previous solution gives suboptimal results [11]. The complex relation between training data and ﬁnal model makes it impossible to predict the effect of individual data, renders most generalization bounds vacuous, and makes it hard to impose even simple constraints, such as those arising from fairness criteria [20] or backward compatibility [44].
The desire to make their training more robust and inter-pretable has led some to linearize DNN models around an initial set of weights [28]. But while this has led to inter-esting theoretical insights, the analysis has failed to yield improvements in the practice. In particular, Figure 1 shows that linearized models perform large-scale image classiﬁca-tion marginally better than simply training a linear classiﬁer on a ﬁxed pre-trained embedding. Non-linear ﬁne-tuning with exhaustive HPO remains the performance paragon. The trade-off between performance and robustness, typical of many complex systems, is a manifestation of the classic bias-variance tradeoff: By reducing the sensitivity of the trained model to perturbations in the parameters or training data (variance, Figure 1, right), we incur a decrease in average performance (bias, left). While we do not expect linearized models to outperform non-linear ﬁne-tuned ones – except in cases where the latter fails to optimize correctly (Section 4.5) – in this paper we explore how far we can push their accuracy, so we can enjoy the robustness and interpretability of linear models without punishing performance loss.
Our contribution, Linear Quadratic Fine-Tuning (LQF), is a method to linearize and train deep neural networks that achieves comparable performance to non-linear ﬁne-tuning 15729
LQF
LQF FC
GaF
Standard FC
NLFT
LQF
Figure 1: Linear vs. nonlinear ﬁne-tuning (NLFT). (Left)
Box-plot of the distribution of test errors achieved by dif-ferent linearization methods on the datasets in Table 1, rela-tive to the error achieved by NLFT (dashed line at origin).
Whiskers show best/worst results, boxes extend from lower to upper quartiles (the results on half of the datasets are concentrated in the box), the central line represents the me-dian increase in error. GaF [36] (green, 47% median er-ror increase) is better than training a linear classiﬁer on a
ﬁxed embedding (red, 71% increase), but slightly worse than LQF applied just to that linear classiﬁer (LQF FC, orange, 42% increase). LQF is the closest linear method (Right) to the non-linear paragon (blue, 12% increase).
We show the distribution of best effective learning rates as the task varies. While for NLFT we need to search in a wide range to ﬁnd the optimal training parameters for a task (wide dashed box), for LQF the same learning rate works almost equally well for all tasks (narrow solid box). (NLFT) on real-world image classiﬁcation, while enjoying all the beneﬁts of linear-quadratic optimization. LQF per-forms ﬁne-tuning without optimizing hyper-parameters such as learning rate or batch size, enables predicting the effect of even individual training samples on the trained classiﬁer, and easily allows incorporating linear constraints during training.
LQF achieves performance comparable to NLFT, and better in the low-data regime which is the most relevant to many real applications.
The key enablers of LQF are simple and known in the literature, although not frequently used: (i) We replace the cross-entropy loss with the mean-squared error loss, making the optimization problem quadratic [13, 18, 3], (ii) we re-place ReLU with Leaky-ReLU [33], and (iii) we perform pre-conditioning using Kronecker factorization (K-FAC) [35].
Individually, these changes bring limited improvements to standard training of non-linear models. However, we show that their combined use has a much larger impact on the performance of linearized models (Figure 2). 2.