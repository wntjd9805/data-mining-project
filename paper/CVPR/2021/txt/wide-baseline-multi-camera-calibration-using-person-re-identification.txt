Abstract
We address the problem of estimating the 3D pose of a network of cameras for large-environment wide-baseline scenarios, e.g., cameras for construction sites, sports stadi-ums, and public spaces. This task is challenging since de-tecting and matching the same 3D keypoint observed from two very different camera views is difﬁcult, making standard structure-from-motion (SfM) pipelines inapplicable. In such circumstances, treating people in the scene as “keypoints” and associating them across different camera views can be an alternative method for obtaining correspondences.
Based on this intuition, we propose a method that uses ideas from person re-identiﬁcation (re-ID) for wide-baseline cam-era calibration. Our method ﬁrst employs a re-ID method to associate human bounding boxes across cameras, then converts bounding box correspondences to point correspon-dences, and ﬁnally solves for camera pose using multi-view geometry and bundle adjustment. Since our method does not require specialized calibration targets except for visi-ble people, it applies to situations where frequent calibra-tion updates are required. We perform extensive experi-ments on datasets captured from scenes of different sizes (80m2, 350m2, 600m2), camera settings (indoor and out-door), and human activities (walking, playing basketball, construction). Experiment results show that our method achieves similar performance to standard SfM methods re-lying on manually labeled point correspondences. 1.

Introduction
Our task is to solve the 3D camera pose estimation problem for multi-camera networks. We target challeng-ing large-environment wide-baseline scenarios where cam-eras are static, sparse, and spaced far from each other (e.g., 10 to 20 meters). Conventionally, SfM [55] methods are often used to estimate camera pose. These methods ﬁrst detect keypoints in the images of different camera views and describe the keypoints using hand-crafted or deep fea-tures [33, 10]. They then match the keypoint features [22] across views to obtain 2D-2D point correspondences and
Figure 1: In large-environment, wide-baseline camera net-works, backgrounds (top, white area), lighting conditions (middle), and textured areas (bottom, white area) from dif-ferent camera views can vary massively, causing the failure of keypoint detection and matching ((a), (b)) in standard
SfM methods. However, matching the same people across views can still be done correctly using re-ID methods ((c), (d)). (Points/bounding boxes of the same color correspond.) solve the camera pose using multi-view geometry [19]. In our setting, due to the signiﬁcant difference between camera poses, images taken from different cameras can have very different backgrounds, lighting conditions, and texture ar-eas, as shown in Figure 1, making detecting and matching the same keypoints across camera views difﬁcult.
Alternatively, we observe that if people are visible in the scene, we can obtain correspondences by detecting and matching people across different cameras. Especially for wide-baseline scenarios, matching the same people across camera views is easier than matching 2D keypoints since many human features can be used. For example, when peo-ple are close to the cameras, we can use the appearance information (e.g., height, clothes, length of hair) to match them across camera views (Figure 1). When people are far away from the cameras, we can still successfully match them from their temporal motion information (e.g., speed, smoothness of trajectory). Therefore, to obtain correspon-13134
(a) Bounding box correspondences (b) Point correspondences (c) Point correspondences over time
Figure 2: Method overview. Given a set of synchronized videos from different views and detected human bounding boxes, our method ﬁrst associates bounding boxes across camera views using a re-ID network (a), then converts the bounding box correspondences to 2D-2D point correspondences (b). Finally, our method aggregates the point correspondences over time (c) and solves the camera pose with the point correspondences as input using multi-view geometry and bundle adjustment. dences in wide-baseline scenarios, we can treat people as
“keypoints” and associate their bounding boxes across cam-era views using a re-ID algorithm. Nevertheless, simply ob-taining the associated bounding boxes is not enough to es-tablish accurate 2D-2D correspondences necessary for cam-era pose estimation. As a second step, we can associate the same body parts (e.g., head, foot, the position of body mass) inside the bounding boxes to further obtain point correspon-dences. In short, we can solve the feature matching prob-lem by breaking it into a two-step process: First, matching people across camera views; Second, converting the bound-ing box correspondences to point correspondences. Since we assume that people are moving in the scene, which is often true, we can obtain a sufﬁcient number of point cor-respondences for solving camera poses by aggregating the correspondences from a sequence of video frames.
We summarize our proposed wide-baseline camera pose estimation method in Figure 2. Our method includes three stages: 1) person matching, 2) point correspondence ex-traction, and 3) geometric camera pose estimation. Given a set of synchronized videos captured by cameras of different views, whose intrinsic and distortion parameters are given from the previous calibration, our method ﬁrst associates person bounding boxes using a re-ID network pre-trained on open datasets [50, 60]. As a second step, our method con-verts the bounding box correspondences to point correspon-dences by extracting and associating the bounding box cen-ters, which approximate the body mass positions. Finally, our method aggregates the point correspondences over time and solves for camera poses using a structure-from-motion pipeline (algebraic estimates of pose pairwise cameras, fol-lowed by non-linear optimization via bundle adjustment).
Our method only assumes the existence of visible mov-ing people in the scene without the requirement of any other specialized calibration targets. It is thus suitable for many situations where consistent camera pose estimation is required, e.g., basketball training where cameras need to be moved for each new game or construction sites where cameras must be moved as the site is constructed. More-over, our method does not require the re-ID model to out-put perfect association results since RANSAC [13] in the later stage can ﬁlter outliers. We evaluate our method on three datasets collected from scenes of different sizes (80m2, 350m2, 600m2) and lighting conditions (indoor and outdoor). The human postures in the three datasets also vary signiﬁcantly, including walking, shooting, running, jump-ing, crouching, etc. We aim to use these datasets of various environment settings and human postures to evaluate the ro-bustness of our method. Experiments show that our method achieves similar performance to a standard SfM pipeline which relies on manually labeled point correspondences.
Our contributions are as follows: 1) We propose to ap-ply person re-ID algorithms to solve camera pose estima-tion for multi-camera networks. 2) We contribute a two-step process treating people as “keypoints” to obtain correspon-dences for wide-baseline scenarios. 3) Our method achieves an average accuracy of (0.4m, 1.08◦) across three datasets, comparable with SfM methods using manual annotation. 4)
We perform extensive robustness and efﬁciency analysis for a more comprehensive understanding of our method. 2.