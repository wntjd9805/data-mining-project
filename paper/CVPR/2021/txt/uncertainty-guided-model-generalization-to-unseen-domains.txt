Abstract
We study a worst-case scenario in generalization: Out-of-domain generalization from a single source. The goal is to learn a robust model from a single source and expect it to generalize over many unknown distributions. This chal-lenging problem has been seldom investigated while existing solutions suffer from various limitations. In this paper, we propose a new solution. The key idea is to augment the source capacity in both input and label spaces, while the augmentation is guided by uncertainty assessment. To the best of our knowledge, this is the ﬁrst work to (1) access the generalization uncertainty from a single source and (2) leverage it to guide both input and label augmentation for robust generalization. The model training and deployment are effectively organized in a Bayesian meta-learning frame-work. We conduct extensive comparisons and ablation study to validate our approach. The results prove our superior performance in a wide scope of tasks including image clas-siﬁcation, semantic segmentation, text classiﬁcation, and speech recognition. 1.

Introduction
Existing machine learning algorithms have achieved re-markable success under the assumption that training and test data are sampled from similar distributions. When this assumption no longer holds, even strong models (e.g., deep neural networks) may fail to produce reliable predictions. In this paper, we study a worst-case scenario in generalization:
Out-of-domain generalization from a single source. A model learned from a single source is expected to generalize over a series of unknown distributions. This problem is more challenging than domain adaptation [39, 42, 63, 34] which usually requires the assessment of target distributions during training, and domain generalization [41, 14, 33, 4, 9] which often assumes the availability of multiple sources. For exam-ple, there exists signiﬁcant distribution difference in medical images collected across different hospitals. The intelligent 1The source code and pre-trained models are publicly available at: https://github.com/joffery/UMGUD. diagnosis system is required to process images unexplored during training where model update is infeasible due to time or resource limitations.
Recently, [59] casts this problem in an ensemble frame-work. It learns a group of models each of which tackles an unseen test domain. This is achieved by performing ad-versarial training [15] on the source to mimic the unseen test distributions. Yet, its generalization capability is lim-ited due to the proposed semantic constraint, which allows only a small amount of data augmentation to avoid semantic changes in the label space. To address this limitation, [45] proposes adversarial domain augmentation to relax the con-straint. By maximizing the Wasserstein distance between the source and augmentation, the domain transportation is signiﬁcantly enlarged in the input space.
However, existing data (domain) augmentation based methods [59, 44, 8, 6, 22] merely consider to increase the source capacity by perturbing the input space. Few of them investigate the possibility of label augmentation. An ex-ception is Mixup [66] which pioneers label augmentation by randomly interpolating two data examples in both input and label spaces. However, Mixup can hardly address the out-of-domain generalization problem since it is restricted in creating in-domain generations due to the linear interpo-lation assumption. Besides, the interpolations are randomly sampled from a ﬁxed distribution, which also largely restricts the ﬂexibility of domain mixtures, yielding sub-optimal per-formance for unseen domain generalization.
Another limitation of existing work [41, 14, 33, 4, 9] is they usually overlook the potential risk of leveraging aug-mented data in tackling out-of-domain generalization. This raises serious safety and security concerns in mission-critical applications [11]. For instance, when deploying self-driving cars in unknown environments, it is crucial to be aware of the predictive uncertainty in risk assessment.
To tackle the aforementioned limitations, we propose un-certain out-of-domain generalization. The key idea is to increase the source capacity guided by uncertainty estima-tion in both input and label spaces. More speciﬁcally, in the input space, instead of directly augmenting raw data [59, 45], we apply uncertainty-guided perturbations to latent fea-6790
tures, yielding a domain-knowledge-free solution for var-ious modalities such as image, text, and audio. In the label space, we leverage the uncertainty associated with feature perturbations to augment labels via interpolation, improving generalization over unseen domains. Moreover, we explicitly model the domain uncertainty as a byproduct of feature per-turbation and label mixup, guaranteeing fast risk assessment without repeated sampling. Finally, we organize the train-ing and deployment in a Bayesian meta-learning framework that is specially tailored for single source generalization. To summarize, our contribution is multi-fold:
• To the best of our knowledge, we are the ﬁrst to ac-cess the uncertainty from a single source. We leverage the uncertainty assessment to gradually improve the domain generalization in a curriculum learning scheme.
• For the ﬁrst time, we propose learnable label mixup in addition to widely used input augmentation, further increasing the domain capacity and reinforcing general-ization over unseen domains.
• We propose a Bayesian meta-learning method to effec-tively organize domain augmentation and model train-ing. Bayesian inference is crucial in maximizing the posterior of domain augmentations, such that they can approximate the distribution of unseen domains.
• Extensive comparisons and ablation study prove our superior performance in a wide scope of tasks includ-ing image classiﬁcation, semantic segmentation, text classiﬁcation, and speech recognition. 2.