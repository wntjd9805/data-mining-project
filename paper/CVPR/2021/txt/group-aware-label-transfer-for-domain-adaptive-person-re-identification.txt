Abstract
Conventional Methods
Our Method
Unsupervised Domain Adaptive (UDA) person re-identiﬁcation (ReID) aims at adapting the model trained on a labeled source-domain dataset to a target-domain dataset without any further annotations. Most successful UDA-ReID approaches combine clustering-based pseudo-label prediction with representation learning and perform the two steps in an alternating fashion. However, ofﬂine interaction between these two steps may allow noisy pseudo labels to substantially hinder the capability of the model. In this pa-per, we propose a Group-aware Label Transfer (GLT) al-gorithm, which enables the online interaction and mutual promotion of pseudo-label prediction and representation learning. Speciﬁcally, a label transfer algorithm simultane-ously uses pseudo labels to train the data while reﬁning the pseudo labels as an online clustering algorithm. It treats the online label reﬁnery problem as an optimal transport prob-lem, which explores the minimum cost for assigning M sam-ples to N pseudo labels. More importantly, we introduce a group-aware strategy to assign implicit attribute group IDs to samples. The combination of the online label reﬁning al-gorithm and the group-aware strategy can better correct the noisy pseudo label in an online fashion and narrow down the search space of the target identity. The effectiveness of the proposed GLT is demonstrated by the experimental results (Rank-1 accuracy) for Market1501→DukeMTMC (82.0%) and DukeMTMC→Market1501 (92.2%), remark-ably closing the gap between unsupervised and supervised performance on person re-identiﬁcation. 1 1.

Introduction
Person re-identiﬁcation (ReID) [27, 50, 19] is the im-portant task of matching person images captured from non-overlapping camera networks, which is widely used in prac-*Equal contribution.
†Corresponding author. 1Full codes are available in https://github.com/JDAI-CV/fast-reid and https://github.com/zkcys001/UDAStrongBaseline.
Label
Refinery
Network
Network
Group-aware Label Transfer
Figure 1.
Illustration of conventional methods and our group-aware label transfer method. In our method, each instance is as-signed to multiple prototypes with different granularity for gener-ating multi-group pseudo labels, and then the noisy multi-group pseudo labels are online reﬁned. With guidance of reﬁned multi-group pseudo labels, our method can learn an embedding space that encodes the semantic multi-granularity structure of data. tical applications such as automatic surveillance, content-based retrieval, and behavior analysis [7, 23, 52, 48, 44,
It has been proved that existing 24, 30, 12, 28, 17, 29]. approaches can achieve remarkable performance when the training and testing data are collected from the same ap-plication scenario but often fail to generalize well to other scenarios due to the inevitable domain gaps. Therefore, it is necessary for both academia and industry to study the Unsu-pervised Domain Adaptive (UDA) person re-identiﬁcation problem.
Existing UDA ReID approaches [14, 26, 35, 45, 55] typ-ically include three steps: feature pre-training with labeled source domain data, clustering-based pseudo-label predic-tion for the target domain data, and feature representation learning/ﬁne-tuning with the pseudo-labels. The last two steps are usually iteratively conducted to strengthen or pro-mote each other. However, the ﬁrst problem is that the pseudo-labels assigned through clustering usually contain 5310
incorrect labels due to the divergence/domain gap between the source and target data, and the imperfect nature of the clustering algorithm. Such noisy labels may mislead the feature learning and harm the domain adaptation perfor-mance. Although the label reﬁning objective in clustering is tractable, it is an ofﬂine time-consuming scheme as it re-quires a pass over the entire dataset. Therefore, online re-ﬁning those incorrect samples when training can help model learn more robust and accurate representation.
Another problem is that the target domain lacks ID infor-mation, so it is difﬁcult to cluster the person images accord-ing to human identity. However, in the real world, each per-son has their own characteristics in his or her appearance.
There may be common appearances shared by a group of people but they are not the same identity (e.g. two men with the same red coats and similar black pants as shown in Fig. 1). Therefore, group-based description [21] that in-volves common characteristics in a pseudo group, can be useful to narrow down the set of candidates and beneﬁcial to identify the exact persons [47, 3, 2]. This group-aware strat-egy can cluster a person into multi-group clustering proto-types, and is able to efﬁciently embed a signiﬁcant number of people and brieﬂy describe an unknown person. Inspired by this, as shown in Fig. 1, combining the online label re-ﬁning algorithm with the group-aware strategy may be ben-eﬁcial to the success of domain adaptation.
In this paper, we propose a Group-aware Label Trans-fer (GLT) algorithm that facilitates the online interaction and mutual promotion of the pseudo labels prediction and feature learning. Speciﬁcally, our method simultaneously uses pseudo labels to train the data while online reﬁning the pseudo labels via the label transfer algorithm. This label transfer algorithm regards the resulting label reﬁning prob-lem as optimal transport, which explores the minimum cost for assigning M samples to N pseudo labels. This prob-lem can therefore be solved by the Sinkhorn-Knopp algo-rithm [6] of linear programming in polynomial time. Mean-while, the label transfer algorithm is scalable, which can be trained with several batches or the whole dataset and can scale to unlimited amounts of data. More importantly, we introduce a group-aware strategy to assign implicit attribute group IDs to samples. Explicit grouping requires manual annotation. Therefore, we adopt a group-aware clustering algorithm to generate multi-group pseudo labels. By adopt-ing the concept of grouping, the ReID network can reduce the search space and ﬂexibly embed a signiﬁcant number of identities into an embedding feature. As shown in Fig. 1, we combine the online label reﬁning algorithm with the multi-group pseudo labels. The combination of the online label reﬁning algorithm and the group-aware strategy can better correct the noisy pseudo label online and narrow down the search space of the target identity and predict more accurate pseudo labels. In addition, we design a target instance mem-ory bank combined with weighted contrastive loss [36] to make the model more powerful for features representation.
The proposed GLT framework achieves state-of-the-art per-formance on Market-to-Duke, Duke-to-Market, Market-to-MSMT, and Duke-to-MSMT with unsupervised domain adaptation, and in particular the i.e. Duke-to-Market per-formances (92.2 Rank-1 and 79.5 mAP) are almost com-parable with the supervised learning performances (94.1
Rank-1 and 85.7 mAP). Our method signiﬁcantly closes gap between unsupervised and supervised performance on per-son re-identiﬁcation, i.e., 92.2 vs. 94.1 top-1 accuracy in
DukeMTMC to Market1501 transfer.
The main contributions of this paper can be summarized in four aspects:
• We make the ﬁrst attempt towards integrating clus-tering and feature learning in a uniﬁed framework through the label transfer method for UDA-ReID. It can online reﬁne the predicted pseudo labels to im-prove the feature representation ability of the model on the target domain.
• We propose a group-aware feature learning strategy based on label transfer to reﬁne multi-group pseudo la-bels, which provides good latent pseudo-label groups for improving the quality of representation learning.
• The GLT framework achieves signiﬁcant performance improvements compared to state-of-the-art approaches on Market→Duke, Duke→Market, Market→MSMT,
Duke→MSMT ReID tasks. Even for the supervised learning methods, our algorithm is remarkably closing the gap. 2.