Abstract
In the biomedical domain, there is an abundance of dense, complex data where objects of interest may be chal-lenging to detect or constrained by limits of human knowl-edge. Labelled domain speciﬁc datasets for supervised tasks are often expensive to obtain, and furthermore dis-covery of novel distinct objects may be desirable for un-biased scientiﬁc discovery. Therefore, we propose leverag-ing the wealth of annotations in benchmark computer vision datasets to conduct unsupervised instance segmentation for diverse biomedical datasets. The key obstacle is thus over-coming the large domain shift from common to biomedical images. We propose a Domain Adaptive Region-based Con-volutional Neural Network (DARCNN), that adapts knowl-edge of object deﬁnition from COCO, a large labelled vision dataset, to multiple biomedical datasets. We introduce a do-main separation module, a self-supervised representation consistency loss, and an augmented pseudo-labelling stage within DARCNN to effectively perform domain adaptation across such large domain shifts. We showcase DARCNN’s performance for unsupervised instance segmentation on nu-merous biomedical datasets. 1.

Introduction
State-of-the-art machine learning methods have accom-plished a wide variety of impressive tasks including in-stance segmentation, yet much of their progress in the real world is limited to supervised methods with large, labelled datasets.
In areas such as the biomedical domain, this is particularly problematic, as the prerequisite labels that ac-company the complex data are often time consuming to ob-In addition, we may also be constrained by human tain. knowledge — biomedical data often contains unknown ob-jects that scientists have yet to uncover, and therefore cannot accurately annotate.
Thus, there exists a need for methods that can pro-duce instance segmentation for unlabelled datasets. We tackle this problem through solving the unsupervised do-Figure 1. a) Prior domain adaptation methods for biomedical im-ages tackle small domain shifts by using similar labelled biomedi-cal datasets as sources to adapt to speciﬁc target datasets. b) DAR-CNN uses a common benchmark dataset as source and can adapt to a wide range of biomedical images. main adaptation task, in which we use a source dataset with instance segmentation annotations to transfer knowl-edge and perform instance segmentation on target datasets.
Our choice of source dataset is motivated by the abun-dance of benchmark datasets in the vision ﬁeld depicting common objects. We explore leveraging the large amount of labelled vision data in Common Objects in Context (COCO) [20] to achieve instance segmentation in diverse, natural biomedical images where annotations are difﬁcult to obtain. Our main contributions include overcoming the large domain shift between natural images and biomedical images, and introducing a method for unsupervised instance segmentation on a wide range of biomedical datasets.
Past work tackling this problem in the biomedical
ﬁeld have depended on the availability of similar labelled biomedical datasets for the unsupervised instance segmen-tation task (see Figure 1), but it is not always feasible to ﬁnd and annotate similar images. For these prior domain adapta-tion methods that focus on small domain shifts, joint image-level and feature-level adaptation approaches and object-1003
speciﬁc models have seen success [6, 7, 13, 17]. How-ever, few works study unsupervised domain adaptation on large domain shifts such as from COCO to biomedical im-ages, where such image-level adaptation fails. In addition, other past methods also design models speciﬁc to segment-ing particular structures, which limits both application to other biomedical datasets as well as discovery [14, 21].
Hence we propose Domain Adaptive Region-based Con-volutional Neural Network (DARCNN), a two stage class agnostic unsupervised domain adaptation model for in-stance segmentation of all distinct objects, capturing the notion of objectness. DARCNN ﬁrst tackles feature-level adaptation, then reﬁnes segmentation masks through image-level pseudo-labelling. Our method can be applied to datasets with consistent background (e.g. of homoge-neous cell background in microscopy) instead of split back-grounds (e.g. of the sky and grass as commonly seen in
COCO). DARCNN leverages the success of the two step
Mask R-CNN framework [12] and learns domain invari-ant and speciﬁc features for region proposal and segmen-tation mask prediction. The features are learned through a self-supervised background representation consistency loss based on predicted regions within an image.
In the second stage of DARCNN, pseudo-labelling on augmented input is introduced as a strong supervisory image-level signal. Through pseudo-labelling we are able to attain stable image-level segmentation after feature-level adaptation. We discover that our sequential two stage pro-cess is able to solve the domain adaptation task with large concept shift, shown on several biomedical datasets. In ad-dition, we demonstrate that our method achieves strong per-formance on tasks of smaller domain shift as well.
Our key contributions are the following:
• We introduce a domain separation module to learn do-main invariant and domain speciﬁc features for the two step instance segmentation framework.
• We propose a self-supervised representation consis-tency loss based on predicted regions within an image for feature adaptation.
• We utilize pseudo-labelling with data augmentation within DARCNN for strong image-level supervision.
• We demonstrate the effectiveness of our approach through quantitative experiments on adapting from
COCO to ﬁve diverse biomedical datasets and a qual-itative experiment for object discovery on a cryogenic electron tomography dataset. 2.