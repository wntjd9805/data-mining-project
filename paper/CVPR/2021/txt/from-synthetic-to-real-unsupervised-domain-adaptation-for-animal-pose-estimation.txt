Abstract
Animal pose estimation is an important ﬁeld that has re-ceived increasing attention in the recent years. The main challenge for this task is the lack of labeled data. Exist-ing works circumvent this problem with pseudo labels gen-erated from data of other easily accessible domains such as synthetic data. However, these pseudo labels are noisy even with consistency check or conﬁdence-based ﬁltering due to the domain shift in the data. To solve this prob-lem, we design a multi-scale domain adaptation module (MDAM) to reduce the domain gap between the synthetic and real data. We further introduce an online coarse-to-ﬁne pseudo label updating strategy. Speciﬁcally, we pro-pose a self-distillation module in an inner coarse-update loop and a mean-teacher in an outer ﬁne-update loop to generate new pseudo labels that gradually replace the old ones. Consequently, our model is able to learn from the old pseudo labels at the early stage, and gradually switch to the new pseudo labels to prevent overﬁtting in the later stage. We evaluate our approach on the TigDog and VisDA 2019 datasets, where we outperform existing approaches by a large margin. We also demonstrate the generalization ability of our model by testing extensively on both unseen domains and unseen animal categories. Our code is avail-able at the project website1. 1.

Introduction
Animal pose estimation has received increasing attention over the last few years because of many potential applica-tions in zoology, biology and aquaculture. Despite the great success of applying deep neural networks to human pose estimation, the lack of well-labeled animal pose data makes it infeasible to directly leverage on the powerful deep learn-ing approaches. Existing works overcome this problem by transferring knowledge from other more accessible domains such as synthetic animal data [23, 5, 46, 47, 48] or human 1https://github.com/chaneyddtt/UDA-Animal-Pose
Figure 1. Our method takes in noisy pseudo labels (e.g. hind hoof on left image) generated from model trained with labeled synthetic data and outputs the correct animal pose on real images. data [6]. The advantage of synthetic data is that it is low cost and convenient to generate a large scale of data with accurate ground truth. Moreover, the domain gap between synthetic and real animals is more manageable than that between other domains such as human and animals. This is evident from the results of [6], where sufﬁcient labeled data in the real animal domain is needed for the network to work despite the use of sophisticated domain adaptation techniques.
The domain gap between synthetic and real animals mainly comes from the differences in texture and back-ground, and the limited pose variance of synthetic data.
To solve the domain shift problem, existing works ﬁrst generate pseudo labels with a model trained on synthetic data, and then gradually incorporate more pseudo labels into the training according to the conﬁdence score. How-ever, these pseudo labels are inaccurate even with reﬁne-ment techniques such as conﬁdence-based ﬁltering [6] or geometry-based consistency check [23]. Fig. 1 shows an example where a model trained on synthetic animals gives wrong predictions (e.g. the hind hoof) with high conﬁdence (marked in yellow circle in the heatmap). This kind of noisy pseudo labels cannot be ﬁltered out based on the conﬁdence score and will lead to degraded performance when used 1482
naively for training.
In this paper, we propose a novel approach to learn from synthetic animal data. We design a multi-scale domain adaptation module (MDAM) to reduce the domain gap. Our
MDAM consists of a pose estimation module and a domain classiﬁer. We ﬁrst train the pose estimation module with the synthetic data [23] to generate an initial set of pseudo labels for the real animal images. We then train our MDAM on the synthetic labels and the pseudo labels. However, the accuracy of MDAM is limited by the presence of noise in the pseudo labels. To alleviate this problem, we intro-duce an online coarse-to-ﬁne pseudo label updating strat-egy. Speciﬁcally, we propose a self-distillation module in the inner coarse-update loop and a mean-teacher [31] in the outer ﬁne-update loop to generate better pseudo labels that gradually replace the old noisy ones.
We design our pseudo label updating strategy accord-ing to the memorization effect [3, 42] of deep networks, which states that deep networks learn from clean samples at the early stage before eventually memorizing (i.e. over-ﬁts to) the noisy ones. To avoid the memorization effect, we rely more on the initial pseudo labels at the early stage when the self-distillation module and mean-teacher are still at their infancy in training. Our coarse-to-ﬁne pseudo label updating strategy gradually replaces the noisy initial labels when the self-distillation module and mean-teacher gained enough competency to generate more reliable pseudo la-bels. Consequently, we are able to supervise our network with more accurate pseudo labels and prevent overﬁtting at the same time. As illustrated in Fig. 1, our model can successfully locate the joint (hind hoof on the right image) although the initial pseudo label is not accurate.
We validate our approach on the TigDog Dataset [10], where we outperform existing unsupervised domain adap-tation techniques by a large margin. We also demonstrate the generalization capacity of our approach by directly test-ing on the Visual Domain Adaptation Challenge dataset (VisDA2019), the Zebra dataset [46] and the Animal-Pose dataset [6]. Experimental results show that our approach can generalize well to both unseen domains and unseen an-imal categories. Our main contributions are as follows:
• We design an unsupervised domain adaptation pipeline for animal pose estimation, which consists of a multi-scale domain adaptation module, a self-distillation module and a mean-teacher network.
• We propose an online coarse-to-ﬁne pseudo label up-dating strategy to alleviate the negative effect of unre-liable pseudo labels.
• Our approach achieves state-of-the-art results on the
TigDog dataset and the VisDA2019 dataset, and can also generalize well to unseen domains and unseen an-imal categories. 2.