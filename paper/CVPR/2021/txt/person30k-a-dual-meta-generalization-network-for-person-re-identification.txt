Abstract
Recently, person re-identiﬁcation (ReID) has vastly ben-eﬁted from the surging waves of data-driven methods. How-ever, these methods are still not reliable enough for real-world deployments, due to the insufﬁcient generalization capability of the models learned on existing benchmarks that have limitations in multiple aspects, including limited data scale, capture condition variations, and appearance diversities. To this end, we collect a new dataset named
Person30K with the following distinct features: 1) a very large scale containing 1.38 million images of 30K identi-ties, 2) a large capture system containing 6,497 cameras de-ployed at 89 different sites, 3) abundant sample diversities including varied backgrounds and diverse person poses.
Furthermore, we propose a domain generalization ReID method, dual-meta generalization network (DMG-Net), to exploit the merits of meta-learning in both the training procedure and the metric space learning. Concretely, we design a “learning then generalization evaluation” meta-training procedure and a meta-discrimination loss to en-hance model generalization and discrimination capabili-ties. Comprehensive experiments validate the effectiveness of our DMG-Net. 1.

Introduction
Person re-identiﬁcation (ReID) targets at matching peo-ple across different cameras. Recent years have witnessed remarkable progress of learning-based person ReID meth-ods [5, 14, 20, 24, 34, 37], which have achieved promising performances when the training and testing sets are col-lected from the same scenarios or camera sets. However, they are often confronted with an inevitable accuracy drop when handling unseen cameras [3, 38]. This performance disparity reveals the problem of their limited generaliza-tion capability against data domain gaps, which are usually
∗Ling-Yu Duan is the corresponding author.
Figure 1. Comparison among samples from our Person30K,
Matket1501 [47], Dukemtmc [28], and MSMT17 [38] datasets.
Our Person30K covers more varied backgrounds, illumination conditions, person poses, and capture viewpoints. caused by different capture viewpoints, camera types, back-grounds and illumination conditions. Therefore, the study on enhancing ReID model’s generalization ability is of great potential to explore for better practical deployment.
Particularly, the benchmark dataset plays a crucial role in model training and comprehensive evaluation. How-ever, the existing person ReID datasets still have many limitations, such as: (1) limited image samples and anno-tated identities (∼4K only); (2) very few capturing cam-eras (2∼15 only) involved in data collection; (3) less varied scenes and environmental conditions, such as backgrounds and illumination; (4) monotonous pedestrian poses, usu-ally covering walking poses only. These limitations over-simplify the challenges of real-world person ReID, and re-strict the representation and generalization capability of the models developed on these datasets.
To facilitate person ReID, we create a new dataset, named Person30K, with a very large scale and high data diversity. Our dataset has the following major advantages over existing benchmarks: (1) It contains 1.38 million im-ages of 30K identities, 11 times the scale of the existing largest benchmark MSMT17 [38]. (2) The images in our
Person30K are collected from 6,497 cameras deployed at 89 2123
different sites, far exceeding the 15-camera setting used by
MSMT17 [38]. (3) Person30K is captured both indoors and outdoors from multiple supermarkets and shopping malls, covering various scenes, e.g., supermarket aisles, cashiers, mall corridors, restaurants, streets, and parking lots. (4) The person samples present very diversiﬁed postures and dress-ing styles. (5) We provide rich annotations for each sample, including person ID, camera ID, site ID, and scenario cate-gory (e.g., supermarket and shopping mall). Moreover, our
Person30K dataset can be used to evaluate model general-ization at different domain gap levels with different testing subset divisions, according to varied training-testing data capture settings, such as the “same-site”, “same-scenario”, and “different-scenarios” conﬁgurations.
Based on the proposed Person30K dataset, in this paper, we focus on the domain generalizable person ReID. We aim to learn a model on a set of source domains/cameras, which can generalize well to other unseen domains/cameras with-out further ﬁne-tuning. Unlike unsupervised domain adap-tation methods [3, 38, 48] that still require using unlabeled target samples to adapt the model to target domain, the gen-eralizable person ReID [13, 31, 49] is more convenient for practical deployment, for being free from the reliance on target domain samples. For example, for a large-scale ReID system deployed at chain supermarkets, generally it is unaf-fordable to go through the repetitive data re-collection, an-notation, and model ﬁne-tuning for every single supermar-ket. Therefore, we expect a generalizable ReID system to work out-of-the-box for widespread deployment.
For domain generalizable person ReID, we propose a novel Dual-Meta Generalization Network (DMG-Net), which is the ﬁrst approach to exploit the meta-learning scheme in model training procedure and metric space learning simultaneously. Meta-learning, also referred to as learning to learn, aims at obtaining knowledge from
“tasks/experiences”.
Such “tasks” generally mimic the target testing scenarios in model training process [4, 30].
We aim to exploit such a task construction and mimick-ing scheme in generalizable ReID scenario. Concretely, for our proposed meta-learning training procedure, we con-struct the tasks through a virtual “learning then generaliza-tion evaluation” process. We divide the training data into support sets (for virtual training) and query sets (for virtual evaluation) to mimic the domain generalization scenarios, where the support and query sets do not share any over-lapping cameras. We train a base model on support sets and then evaluate its performance generalized on query sets.
Thereby, based on the evaluation results/losses, we can up-date the model towards better generalization. Besides, to enhance model discrimination, we further propose a meta-discrimination loss to obtain a better metric space. We con-struct discrimination oriented meta tasks by explicitly mim-icking the cross-camera sample matching process. Specif-ically, we compute feature-based centers to represent the identities in the support set, and conduct a matching pro-cess between the query samples and support centers. Over-all, with the proposed dual meta-learning scheme, DMG-Net can strengthen model generalization on the unseen do-main data, as well as model discrimination for cross-camera matching in person ReID.
Our major contributions are as follows. (1) We create a large-scale person ReID benchmark, Person30K, which contains 1.38 million images of 30K identities, collected from 6,497 cameras deployed at 85 supermarkets and 4 large shopping malls. We used one full year to collect
Person30K and it cost us 130 man-months’ labor to clean and annotate it. (2) We propose a DMG-Net for generaliz-able person ReID which exploits the meta-learning scheme in both the training procedure and metric space learning.
A “learning then generalization evaluation” training proce-dure is designed to extend model generalization to unseen domains. And a discrimination loss is also incorporated for enhancing model discrimination in cross-camera matching. 2.