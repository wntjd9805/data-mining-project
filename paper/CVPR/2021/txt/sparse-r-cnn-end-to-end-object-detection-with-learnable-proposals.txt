Abstract
We present Sparse R-CNN, a purely sparse method for object detection in images. Existing works on object de-tection heavily rely on dense object candidates, such as k anchor boxes pre-deﬁned on all grids of image feature map of size H × W .
In our method, however, a ﬁxed sparse set of learned object proposals, total length of N , are provided to object recognition head to perform classiﬁ-cation and location. By eliminating HW k (up to hundreds of thousands) hand-designed object candidates to N (e.g. 100) learnable proposals, Sparse R-CNN completely avoids all efforts related to object candidates design and many-to-one label assignment. More importantly, ﬁnal predictions are directly output without non-maximum suppression post-procedure. Sparse R-CNN demonstrates accuracy, run-time and training convergence performance on par with the well-established detector baselines on the challenging COCO dataset, e.g., achieving 45.0 AP in standard 3× train-ing schedule and running at 22 fps using ResNet-50 FPN model. We hope our work could inspire re-thinking the con-vention of dense prior in object detectors. The code is avail-able at: https://github.com/PeizeSun/SparseR-CNN.
* Equal contribution.
P
A
O
C
O
C 50 45 40 35 30 25 20 15 500 epochs
RetinaNet
Faster R-CNN
DETR
Sparse R-CNN 120 140 3x schedule 0 20 40 80 60
Training Epochs 100
Figure 2 – Convergence curves of RetinaNet, Faster R-CNN,
DETR and Sparse R-CNN on COCO val2017 [24]. Sparse
R-CNN achieves competitive performance in terms of training efﬁciency and detection quality. 1.

Introduction
Object detection aims at localizing a set of objects and recognizing their categories in an image. Dense prior has always been cornerstone to success in detectors. In classic computer vision, the sliding-window paradigm, in which a classiﬁer is applied on a dense image grid, is leading de-14454
tection method for decades [6, 9, 39]. Modern mainstream one-stage detectors pre-deﬁne marks on a dense feature map grid, such as anchors boxes [23, 29], shown in Figure 1a, or reference points [36, 48], and predict the relative scaling and offsets to bounding boxes of objects, as well as the cor-responding categories. Although two-stage pipelines work on a sparse set of proposal boxes, their proposal genera-tion algorithms are still built on dense candidates [11, 30], shown in Figure 1b.
These well-established methods are conceptually intu-itive and offer robust performance [8, 24], together with fast training and inference time [42]. Besides their great success, it is important to note that dense-prior detectors suffer some limitations: 1) Such pipelines usually pro-duce redundant and near-duplicate results, thus making non-maximum suppression (NMS) [1, 41] post-processing a necessary component. 2) The many-to-one label assign-ment problem [2, 46, 47] in training makes the network sen-sitive to heuristic assign rules. 3) The ﬁnal performance is largely affected by sizes, aspect ratios and number of an-chor boxes [23, 29], density of reference points [19, 36, 48] and proposal generation algorithm [11, 30].
Despite the dense convention is widely recognized
Is among object detectors, a natural question to ask is: it possible to design a sparse detector? Recently, DETR proposes to reformulate object detection as a direct and sparse set prediction problem [3], whose input is merely 100 learned object queries [38]. The ﬁnal set of predic-tions are output directly without any hand-designed post-processing. In spite of its simple and fantastic framework,
DETR requires each object query to interact with global im-age context. This dense property not only slows down its training convergence [49], but also blocks it establishing a thoroughly sparse pipeline for object detection.
We believe the sparse property should be in two aspects: sparse boxes and sparse features. Sparse boxes mean that a small number of starting boxes (e.g. 100) is enough to pre-dict all objects in an image. While sparse features indicate the feature of each box does not need to interact with all other features over the full image. From this perspective,
DETR is not a pure sparse method since each object query must interact with dense features over full images.
In this paper, we propose Sparse R-CNN, a purely sparse method, without object positional candidates enumerating on all(dense) image grids nor object queries interacting with global(dense) image feature. As shown in Figure 1c, object candidates are given with a ﬁxed small set of learn-able bounding boxes represented by 4-d coordinate. For ex-ample of COCO dataset [24], 100 boxes and 400 parameters are needed in total, rather than the predicted ones from hun-dreds of thousands of candidates in Region Proposal Net-work (RPN) [30]. These sparse candidates are used as pro-posal boxes to extract the feature of Region of Interest (RoI) by RoIPool [10] or RoIAlign [13].
The learnable proposal boxes are the statistics of poten-tial object location in the image. Whereas, the 4-d coor-dinate is merely a rough representation of object and lacks a lot of informative details such as pose and shape. Here we introduce another key concept termed proposal feature, which is a high-dimension (e.g., 256) latent vector. Com-pared with rough bounding box, it is expected to encode the rich instance characteristics. Specially, proposal feature generates a series of customized parameters for its exclusive object recognition head. We call this operation Dynamic In-stance Interactive Head, since it shares similarities with re-cent dynamic scheme [18, 35]. Compared to the shared 2-fc layers in [30], our head is more ﬂexible and holds a signif-icant lead in accuracy. We show in our experiment that the formulation of head conditioned on unique proposal feature instead of the ﬁxed parameters is actually the key to Sparse
R-CNN’s success. Both proposal boxes and proposal fea-tures are randomly initialized and optimized together with other parameters in the whole network.
The most remarkable property in our Sparse R-CNN is its sparse-in sparse-out paradigm in the whole time. The initial input is a sparse set of proposal boxes and proposal features, together with the one-to-one dynamic instance in-teraction. Neither dense candidates [23, 30] nor interacting with global(dense) feature [3] exists in the pipeline. This pure sparsity makes Sparse R-CNN a brand new member in
R-CNN family.
Sparse R-CNN demonstrates its accuracy, run-time and training convergence performance on par with the well-established detectors [2, 30, 36] on the challenging COCO dataset [24], e.g., achieving 45.0 AP in standard 3× train-ing schedule and running at 22 fps using ResNet-50 FPN model. To our best knowledge, the proposed Sparse R-CNN is the ﬁrst work that demonstrates a considerably sparse de-sign is qualiﬁed yet. We hope our work could inspire re-thinking the necessary of dense prior in object detection and exploring next generation of object detector. 2.