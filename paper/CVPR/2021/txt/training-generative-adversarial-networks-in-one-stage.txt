Abstract
Generative Adversarial Networks (GANs) have demon-strated unprecedented success in various image generation tasks. The encouraging results, however, come at the price of a cumbersome training process, during which the gen-erator and discriminator are alternately updated in two
In this paper, we investigate a general training stages. scheme that enables training GANs efﬁciently in only one stage. Based on the adversarial losses of the generator and discriminator, we categorize GANs into two classes, Sym-metric GANs and Asymmetric GANs, and introduce a novel gradient decomposition method to unify the two, allowing us to train both classes in one stage and hence alleviate the training effort. We also computationally analyze the ef-ﬁciency of the proposed method, and empirically demon-strate that, the proposed method yields a solid 1.5× accel-eration across various datasets and network architectures.
Furthermore, we show that the proposed method is readily applicable to other adversarial-training scenarios, such as data-free knowledge distillation. The code is available at https://github.com/zju-vipa/OSGAN . 1.

Introduction
Generative Adversarial Networks (GANs), since their in-troduction in [17], have produced unprecedentedly impres-sive results on various image generation tasks. Thanks to the adversarial nature of the two key components, genera-tor and discriminator, the synthesized images delivered by
GANs turn out visually appealing and in many cases in-distinguishable from real ones. Recently, many variants of
GANs have introduced and focused on different aspects of the design, including image quality [30, 6, 12], training sta-bility [43, 74, 46] and diversity [8, 68, 40]. Apart from generating images as the end goal, GANs have also been applied to other tasks, such as data-free knowledge distilla-*Corresponding author
Figure 1: Comparison of the conventional Two-Stage GAN training scheme (TSGANs) and the proposed One-Stage strategy (OSGANs). The former one relies on alternately freezing the generator and the discriminant, while the latter trains both simultaneously. tion [44, 13, 60, 71] and domain adaption [14, 56].
The promising results delivered by GANs, however, come at the price of a burdensome training process. As shown in the upper row of Fig. 1, existing GANs rely on a time-consuming two-stage training process, which we term as Two-Stage GANs (TSGANs). In the ﬁrst stage, fake im-ages synthesized by the generator, together with the real ones, are fed into the discriminator for training; during this process, the discriminator is updated but the generator is
In the second stage, the discriminator delivers the
ﬁxed. gradients derived from the loss function to the generator, during which the generator is updated but the discriminator is ﬁxed. Within each adversarial round, therefore, both the generator and the discriminator carry out the feed-forward step for two times, while the discriminator implements a backward-propagation step for another two times, which, 3350
as will be analyzed in our method section, involves many repetitive computations.
Endeavors have been made towards alleviating the cum-bersome training process of GANs. The work of [14], for example, adopts an efﬁcient adversarial training strategy for unsupervised domain adaption, where learning the feature extractor and classiﬁer requires only one round of forward inference and back-propagation. The approach of [48] also exploits a single-step optimization to update the parameters of the generator and discriminator in one turn, and showcase its power in generating visually realistic images.
In spite of their enhanced efﬁciency, the approaches of [14, 48] limit themselves applicable to only a subset of GANs, for which their loss functions take a particu-lar form. Speciﬁcally, within such GANs, the adversar-ial loss terms in both the generator and discriminator are identical; hence, we term such models as Symmetric GANs.
Nevertheless, many other popular GANs adopt loss func-tions that hold different adversarial terms for the generator and discriminator, and we term these models as Asymmet-ric GANs. The speed-up optimization techniques employed by [14, 48], unfortunately, are no longer competent to han-dle such asymmetric models.
We propose in this paper a novel one-stage training scheme, termed as One-Stage GANs (OSGANs), that gener-alizes to both Symmetric and Asymmetric GANs. Our key idea is to integrate the optimization for generator and dis-criminator during forward inference, and decompose their gradients during back-propagation to respectively update them in one stage. For the Symmetric case, since the dis-criminant loss hold a term that is identical to the generator loss, we only need to compute the gradient of this term once and adopt it for both losses. In this way, the updates of the generator and discriminator may safely take place in one forward and backward step.
Training Asymmetric GANs is more tricky since we can no longer copy the gradients derived from the discriminator to the generator. To this end, we carefully look into the com-position of the discriminator’s gradients. We discover that, the gradients derived from the different adversarial terms, in reality, preserve their proportions within the total gradi-ents from the last layer all the way back to the ﬁrst layer of discriminator. This interesting property of gradients, in turn, provides us with a feasible solution to decompose the gradients of the different adversarial terms and then to up-date the discriminator and generator, enabling the one-stage training of Asymmetric GANs. Finally, we unify the two classes of GANs, and show that Symmetric GANs, in fact, can be treated as a degenerate case of Asymmetric GANs.
Our contribution is therefore a general one-stage train-ing scheme, readily applicable to various GAN variants in-cluding both Symmetric and Asymmetric GANs. Computa-tional analysis backed up with experimental results on sev-eral datasets and network architectures demonstrate that, the proposed OSGANs achieve a solid 1.5× speedup over the vanilla adversarial training strategy. 2.