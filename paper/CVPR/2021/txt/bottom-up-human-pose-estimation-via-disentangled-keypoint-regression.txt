Abstract
In this paper, we are interested in the bottom-up paradigm of estimating human poses from an image. We study the dense keypoint regression framework that is previ-ously inferior to the keypoint detection and grouping frame-work. Our motivation is that regressing keypoint positions accurately needs to learn representations that focus on the keypoint regions.
We present a simple yet effective approach, named dis-entangled keypoint regression (DEKR). We adopt adaptive convolutions through pixel-wise spatial transformer to ac-tivate the pixels in the keypoint regions and accordingly learn representations from them. We use a multi-branch structure for separate regression: each branch learns a rep-resentation with dedicated adaptive convolutions and re-gresses one keypoint. The resulting disentangled represen-tations are able to attend to the keypoint regions, respec-tively, and thus the keypoint regression is spatially more ac-curate. We empirically show that the proposed direct re-gression method outperforms keypoint detection and group-ing methods and achieves superior bottom-up pose estima-tion results on two benchmark datasets, COCO and Crowd-Pose. The code and models are available at https:
//github.com/HRNet/DEKR. 1.

Introduction
Human pose estimation is a problem of predicting the keypoint positions of each person from an image, i.e., lo-calize the keypoints as well as identify the keypoints be-longing to the same person. There are broad applications, including action recognition, human-computer interaction, smart photo editing, pedestrian tracking, etc.
*This work was done when Zigang Geng and Ke Sun were interns at
Microsoft Research, Beijing, P.R. China
†Corresponding author
Figure 1. Illustration of the salient regions for regressing the key-points. We take three keypoints, nose and two ankles, as an ex-ample for illustration clarity. Left: baseline. Right: our approach
DEKR. It can be seen that our approach is able to focus on the key-point regions. The salient regions are generated using the tool [46].
There are two main paradigms: top-down and bottom-up. The top-down paradigm ﬁrst detects the person and then performs single-person pose estimation for each de-tected person. The bottom-up paradigm either directly re-gresses the keypoint positions belonging to the same per-son, or detects and groups the keypoints, such as afﬁnity linking [7, 31], associative embedding [40], HGG [27] and
HigherHRNet [11]. The top-down paradigm is more accu-rate but more costly due to an extra person detection pro-cess, and the bottom-up paradigm, the interest of this paper, is more efﬁcient.
The recently-developed pixel-wise keypoint regression approach, CenterNet [78], estimates the K keypoint posi-tions together for each pixel from the representation at the pixel. Direct regression to keypoint positions in Center-Net [78] performs reasonably. But the regressed keypoints are spatially not accurate and the performance is worse than the keypoint detection and grouping scheme. Figure 1 (left) shows two examples in which the salient areas for keypoint 14676
Figure 2. Multi-person pose estimation. The challenges include diverse person scales and orientations, various poses, etc. Example results are from our approach DEKR. regression spread broadly and the regression quality is not satisfactory.
We argue that regressing the keypoint positions accu-rately needs to learn representations that focus on the key-point regions. Starting from this regression by focusing con-cept, we present a simple yet effective approach, named disentangled keypoint regression (DEKR). We adopt adap-tive convolutions, through pixel-wise spatial transformer (a pixel-wise extension of spatial transformer network [26]), to activate the pixels lying in the keypoint regions, and then learn the representations from these activated pixels, so that the learned representations can focus on the keypoint re-gions.
We further decouple the representation learning for one keypoint from other keypoints. We adopt a separate regres-sion scheme through a multi-branch structure: each branch learns a representation for one keypoint with adaptive con-volutions dedicated for the keypoint and regresses the posi-tion for the corresponding keypoint. Figure 1 (right) illus-trates that our approach is able to learn highly concentrative representations, each of which focuses on the correspond-ing keypoint region.
Experimental results demonstrate that the proposed
DEKR approach improves the localization quality of the regressed keypoint positions. Our approach, that performs direct keypoint regression without matching the regression results to the closest keypoints detected from the keypoint heatmaps, outperforms keypoint detection and grouping methods and achieves superior performance over previous state-of-the-art bottom-up pose estimation methods on two benchmark datasets, COCO and CrowdPose.
Our contributions to bottom-up human pose estimation are summarized as follows.
• We argue that the representations for regressing the po-sitions of the keypoints accurately need to focus on the keypoint regions.
• The proposed DEKR approach is able to learn disen-tangled representations through two simple schemes, adaptive convolutions and multi-branch structure, so that each representation focuses on one keypoint re-gion and the prediction of the corresponding keypoint position from such representation is accurate.
• The proposed direct regression approach outperforms keypoint detection and grouping schemes and achieves new state-of-the-art bottom-up pose estimation results on the benchmark datasets, COCO and CrowdPose. 2.