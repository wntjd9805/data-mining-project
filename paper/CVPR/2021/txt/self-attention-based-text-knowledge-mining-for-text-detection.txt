Abstract
Pre-trained models play an important role in deep learn-ing based text detectors. However, most methods ignore the gap between natural images and scene text images and di-rectly apply ImageNet for pre-training. To address such a problem, some of them ﬁrstly pre-train the model using a large amount of synthetic data and then ﬁne-tune it on tar-get datasets, which is task-speciﬁc and has limited general-ization capability. In this paper, we focus on providing gen-eral pre-trained models for text detectors. Considering the importance of exploring text contents for text detection, we propose STKM (Self-attention based Text Knowledge Min-ing), which consists of a CNN Encoder and a Self-attention
Decoder, to learn general prior knowledge for text detec-tion from SynthText. Given only image level text labels,
Self-attention Decoder directly decodes features extracted from CNN Encoder to texts without requirement of detec-tion, which guides the CNN backbone to explicitly learn discriminative semantic representations ignored by previ-ous approaches. After that, the text knowledge learned by the backbone can be transferred to various text detectors to signiﬁcantly improve their detection performance (e.g., 5.89% higher F-measure for EAST on ICDAR15 dataset) without bells and whistles. Pre-trained model is available at: https://github.com/CVI-SZU/STKM 1.

Introduction
Scene text detection has drawn much attention in both academic communities and industries due to its ubiquitous real-world applications, such as online education, product search, instant translation, and video scene parsing. Ben-eﬁted from the rapid development of deep Convolutional
Neural Networks [11] in Object Detection [16, 24, 25] and
Image Segmentation [19, 2, 26] over the past few years, re-*Corresponding Author: Linlin Shen.
Figure 1. Comparisons of different pre-training strategies. Dashed arrows indicate ﬁne-tuning. (a) Fine-tuned from ImageNet pre-training. (b) Fine-tuned from SynthText pre-training, where the red question mark indicates the knowledge gap between detector
A and detector B. (c) Our approach, where the ”HLK” denotes high level knowledge. cent scene text detectors have achieved signiﬁcant progress.
Most of these methods apply ImageNet [27] pre-training to speed up convergence as well as improve ﬁnal accu-racy. However, there exists an obvious domain gap be-tween natural images and scene text images. Some meth-ods [1, 41, 18, 37] try to ﬁne-tune models using initializa-tion parameters pre-trained on a large amount of synthetic 5983
data for text detection, which outperforms ImageNet based pre-training, but still suffers from these shortcomings: (1)
The generalization capability of such pre-trained backbones is limited. The weights trained with a speciﬁc detector may not be able to obtain good results in other detectors.
Therefore, each text detection algorithm needs to be pre-trained again, which leads to a lot of redundant computa-tional costs. (2) Text content is usually ignored. Different from generic object detection, text detection only classiﬁes region proposals as text or non-text, no information about text content is extracted. Therefore, texture-like content in the image is easily detected as text.
As shown in Figure 1, in this paper, our motivation is to provide powerful pre-trained deep models for text detection, which contains more general prior knowledge by aggregat-ing semantic representations of text contents. Inspired by transformer [33], we utilize self-attention mechanisms to devise a dedicated network called STKM ( Self-attention based Text Knowledge Mining) to learn useful prior knowl-edge for text detection. As a result, the pre-trained back-bone of STKM can be ﬁne-tuned for various text detectors to signiﬁcantly improve their detection performance. To be speciﬁc, we ﬁrstly extract features from standard CNN backbone, and then decode the ﬂatten features using a cas-caded self-attention architecture to directly recognize all the texts without requirement of detection. Our model can be trained end-to-end and only requires image-level text an-notations, whose labeling cost is much cheaper than that of text location annotation. Furthermore, STKM is able to provide more general text knowledge, i.e., the backbone can be transferred to different text detection networks to achieve state-of-the-art performance. We ﬁne-tune the pre-trained STKM backbone with diverse networks and datasets to verify its effectiveness. In particular, by replacing Im-ageNet pre-training with STKM, EAST [43] and PSENet
[34] can achieve 5.89% and 5.64% higher F-measure on IC-DAR2015 [10] dataset, respectively.
In summary, the main contributions of this paper are two-fold:
• We propose STKM, which can be trained end-to-end, to acquire general text knowledge for following text detection tasks. To the best of our knowledge, we are the ﬁrst attempt to provide general pre-trained models for text detection.
• Without bells and whistles, extensive experiments show that the STKM can improve the performance of various detectors by a great margin on different bench-marks. 2.