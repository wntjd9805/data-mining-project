Abstract
Temporal Action
Weakly-supervised
Localization the action segments with only (WTAL) aims to detect video-level action labels in training. The key challenge is how to distinguish the action of interest segments from the background, which is unlabelled even on the video-level.
While previous works treat the background as “curses”, we consider it as “blessings”. Speciﬁcally, we ﬁrst use causal analysis to point out that the common localization errors are due to the unobserved confounder that resides ubiquitously in visual recognition. Then, we propose a
Temporal Smoothing PCA-based (TS-PCA) deconfounder, which exploits the unlabelled background to model an observed substitute for the unobserved confounder, to remove the confounding effect. Note that the proposed deconfounder is model-agnostic and non-intrusive, and hence can be applied in any WTAL method without model re-designs. Through extensive experiments on four state-of-the-art WTAL methods, we show that the deconfounder can improve all of them on the public datasets: THUMOS-14 and ActivityNet-1.31. 1.

Introduction
Temporal action localization aims to locate the start and end frames of actions of interest in untrimmed videos, e.g.,
CLIFFDIVE and PASSBALL. Weakly-supervised Temporal
Action Localization (WTAL) [21, 35, 37] can train such a localizer by using only the video-level annotations like “the video contains CLIFFDIVE”, without specifying its start and end frames. Therefore, WTAL is especially valuable in the era of video-sharing social networking service [9], where billions of videos have only video-level user-generated tags.
Not surprisingly, WTAL has lower performances than its fully-supervised counterpart [8, 15, 17]. As shown in
Figure 1, any WTAL method would suffer from the three 1Code is available at https://github.com/liuyuancv/WTAL blessing
Prepare (