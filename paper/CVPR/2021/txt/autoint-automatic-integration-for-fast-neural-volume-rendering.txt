Abstract
Numerical integration is a foundational technique in sci-entiﬁc computing and is at the core of many computer vi-sion applications. Among these applications, neural volume rendering has recently been proposed as a new paradigm for view synthesis, achieving photorealistic image quality.
However, a fundamental obstacle to making these methods practical is the extreme computational and memory require-ments caused by the required volume integrations along the rendered rays during training and inference. Millions of rays, each requiring hundreds of forward passes through a neural network are needed to approximate those inte-grations with Monte Carlo sampling. Here, we propose automatic integration, a new framework for learning efﬁ-cient, closed-form solutions to integrals using coordinate-based neural networks. For training, we instantiate the computational graph corresponding to the derivative of the coordinate-based network. The graph is ﬁtted to the sig-nal to integrate. After optimization, we reassemble the graph to obtain a network that represents the antideriva-tive. By the fundamental theorem of calculus, this enables the calculation of any deﬁnite integral in two evaluations of the network. Applying this approach to neural rendering, we improve a tradeoff between rendering speed and image quality: improving render times by greater than 10× with a tradeoff of reduced image quality. 1.

Introduction
Image-based rendering and novel view synthesis are fundamental problems in computer vision and graphics (e.g., [5, 54]). The ability to interpolate and extrapolate a sparse set of images depicting a 3D scene has broad appli-cations in entertainment, virtual and augmented reality, and many other applications. Emerging neural rendering tech-niques have recently enabled photorealistic image quality for these tasks (see Sec. 2).
*Equal contribution. http://www.computationalimaging.org/publications/ automatic-integration/
Figure 1. Automatic integration for neural volume rendering. Dur-ing training, a grad network is optimized to represent multi-view images. At test time, we instantiate a corresponding integral net-work to rapidly evaluate per-ray integrals through the volume.
Although state-of-the-art neural volume rendering tech-niques offer unprecedented image quality, they are also ex-tremely slow and memory inefﬁcient [37]. This is a fun-damental obstacle to making these methods practical. The primary computational bottleneck for neural volume render-ing is the evaluation of integrals along the rendered rays during training and inference required by the volume ren-dering equation [33]. Approximate integration using Monte
Carlo sampling is typically used for this purpose, requiring hundreds of forward passes through the neural network rep-resenting the volume for each of the millions of rays that need to be rendered for a single frame. Here, we develop a general and efﬁcient framework for approximate integra-tion. Applied to the speciﬁc problem of neural volume ren-dering, our framework improves a tradeoff between render-ing speed and image quality, allowing a greater than 10× speedup in the rendering process, though with a reduction in image quality. 14556
Our integration framework builds on previous work demonstrating that coordinate-based networks (sometimes also referred to as implicit neural representations) can repre-sent signals (e.g., images, audio waveforms, or 3D shapes) and their derivatives. That is, taking the derivative of the coordinate-based network accurately models the derivative of the original signal. This property has recently been shown for coordinate-based networks with periodic activa-tion functions [51], but we show that it also extends to a family of networks with different nonlinear activation func-tions (Sec 3.4 and supplemental).
We observe that taking the derivative of a coordinate-based network results in a new computational graph, a “grad network”, which shares the parameters of the original net-work. Now, consider that we use as our network a mul-tilayer perceptron (MLP). Taking its derivative results in a grad network which can be trained on a signal that we wish to integrate. By reassembling the grad network parameters back into the original MLP, we construct a neural network that represents the antiderivative of the signal to integrate.
This procedure results in a closed-form solution for the antiderivative, which, by the fundamental theorem of calcu-lus, enables the calculation of any deﬁnite integral in two evaluations of the MLP. Inspired by techniques for auto-matic differentiation (AutoDiff), we call this procedure au-tomatic integration or AutoInt. Although the mechanisms of AutoInt and AutoDiff are very different, both approaches enable the calculation of integrals or derivatives in an auto-mated manner that does not rely on traditional numerical techniques, such as sampling or ﬁnite differences.
The primary beneﬁt of AutoInt is that it allows eval-uating arbitrary deﬁnite integrals quickly by querying the network representing the antiderivative. This concept could have important applications across science and engineering; here, we focus on the speciﬁc application of neural vol-ume rendering. For this application, efﬁciently evaluating integrals amounts to accelerating rendering (i.e., inference) times, which is crucial for making these techniques more competitive with traditional real-time graphics pipelines.
However, our framework still requires a slow training pro-cess to optimize a network for a given set of posed 2D im-ages.
Speciﬁcally, our contributions include the following.
• We introduce a framework for automatic integration that learns closed-form integral solutions. To this end, we explore new network architectures and training strategies.
• Using automatic integration, we propose a new model and parameterization for neural volume rendering that is efﬁcient in computation and memory.
• We improve a tradeoff between neural rendering speed and image quality, demonstrating rendering rates that are an order of magnitude faster than previous im-plementations [37], though with a reduction in image quality. 2.