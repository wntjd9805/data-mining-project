Abstract
Animals are diverse in shape, but building a deformable shape model for a new species is not always possible due to the lack of 3D data. We present a method to capture new species using an articulated template and images of that species. In this work, we focus mainly on birds. Although birds represent almost twice the number of species as mam-mals, no accurate shape model is available. To capture a novel species, we ﬁrst ﬁt the articulated template to each training sample. By disentangling pose and shape, we learn a shape space that captures variation both among species and within each species from image evidence. We learn models of multiple species from the CUB dataset, and con-tribute new species-speciﬁc and multi-species shape models that are useful for downstream reconstruction tasks. Using a low-dimensional embedding, we show that our learned 3D shape space better reﬂects the phylogenetic relation-ships among birds than learned perceptual features. 1.

Introduction
Automated capture of animal shape and motion is a chal-lenging problem with widespread application in agriculture, biomechanics, animal behavior, and neuroscience. Changes in shape can convey an animal’s health status and trans-mit social signals [1, 34]. Recent methods that use ar-ticulated mesh models to extract these signals from im-ages [7, 8, 54, 55] are poised to transform these ﬁelds. One challenge that prevents wider adoption of this approach, however, is the difﬁculty of obtaining suitable models for new species. Methods that can automatically capture the shape of new species are highly desirable.
Recent articulated, 3D animal shape models obtain train-ing data from 3D scans of toy animals ﬁgurines, or multiple views of the same subject [7, 56, 55]. They produce great quality of reconstruction when the target is represented in the source data. How these articulated and deformable mod-els can be extended to new animal species is still an open problem, particularly due to the lack 3D scans. Animals’ non-cooperative nature makes obtaining 3D scans impracti-cal.
Images of the same species, on the other hand, are more readily available for a wider variety of categories. The
CUB [50] dataset, for example, provides image collections for various bird species. These monocular collections re-main underutilized, however, because current detailed cap-ture methods require a strong deformable 3D shape prior, 114739
which is not available for many species.
We propose a method to directly capture articulated shapes from species-speciﬁc image collections, when a strong deformable shape prior is not available. We focus our effort on CUB and start with an articulated bird mesh [7] as a generic template model. For a given collection, we ﬁrst align the mesh to each annotated instance by solving for the pose and camera parameters. We then update the tem-plate model through a series of deformations to better ﬁt the silhouettes, resulting in recovery of a new species-speciﬁc shape and individual variations within the species.
Closest to our work is SMALR [55], which uses a de-formable shape model and a video sequence of the same instance to reconstruct quadrupeds. We relax this assump-tion and use a collection of different instances. This breaks the same-subject constraints and makes a naive adaption of
SMALR infeasible. Solving this “multiple instances” prob-lem allows us to build species-speciﬁc morphable shape models directly from images. Our method also starts with a simpler shape prior, using an articulated mesh as the tem-plate model.
To handle these challenges, we explicitly model two lev-els of the shape hierarchy. The ﬁrst level is the difference between the generic template model and the average shape of a new species; the second level is the variation among individuals within that species.
First, after aligning the articulated mesh to the images for a novel species, we optimize a per-vertex deformation to bridge the difference between the shape of the template model and the shape of a novel species. We call the re-sulting shape the species mean shape. In the second step, starting from the mean shape, we learn the variation within the collection as a blend shape basis, allowing us to recon-struct each sample as a combination of shape basis vectors on top of the estimated mean. The shape basis also provides a species-speciﬁc morphable shape model. Because the ar-ticulation is factored out during model alignment, the mean and shape basis are properly captured without the nonlinear effect of pose.
Additionally, from all the per-species models we learn a new parametric shape model, AVES, that is capable of rep-resenting multiple avian species. We demonstrate through experiments that AVES captures a meaningful shape space, generalizes to unseen samples, and can be integrated in a deep learning pipeline.
In summary, our contributions are the following:
• We present a new method that recovers detailed, species-speciﬁc shape models for a range of bird species using an articulated 3D mesh and images of different instances of each species.
• We provide AVES, a multi-species statistical shape model extracted from reconstructions of 17 bird species. We show that the AVES shape space captures morphological traits that are correlated with the avian phylogeny.
• We show that the AVES model can be used in down-stream reconstruction tasks including model ﬁtting and regression, outperforming previous model-based and model-free approaches by a large margin. 2.