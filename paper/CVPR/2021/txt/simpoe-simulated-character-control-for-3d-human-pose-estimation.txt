Abstract 1.

Introduction
Accurate estimation of 3D human motion from monocu-lar video requires modeling both kinematics (body motion without physical forces) and dynamics (motion with phys-ical forces). To demonstrate this, we present SimPoE, a
Simulation-based approach for 3D human Pose Estimation, which integrates image-based kinematic inference and physics-based dynamics modeling. SimPoE learns a policy that takes as input the current-frame pose estimate and the next image frame to control a physically-simulated charac-ter to output the next-frame pose estimate. The policy con-tains a learnable kinematic pose reﬁnement unit that uses 2D keypoints to iteratively reﬁne its kinematic pose estimate of the next frame. Based on this reﬁned kinematic pose, the policy learns to compute dynamics-based control (e.g., joint torques) of the character to advance the current-frame pose estimate to the pose estimate of the next frame. This design couples the kinematic pose reﬁnement unit with the dynamics-based control generation unit, which are learned jointly with reinforcement learning to achieve accurate and physically-plausible pose estimation. Furthermore, we pro-pose a meta-control mechanism that dynamically adjusts the character’s dynamics parameters based on the charac-ter state to attain more accurate pose estimates. Experi-ments on large-scale motion datasets demonstrate that our approach establishes the new state of the art in pose accu-racy while ensuring physical plausibility.
We aim to show that accurate 3D human pose estimation from monocular video requires modeling both kinematics and dynamics. Human dynamics, i.e., body motion model-ing with physical forces, has gained relatively little atten-tion in 3D human pose estimation compared to its coun-terpart, kinematics, which models motion without physical forces. There are two main reasons for the disparity be-tween these two equally important approaches. First, kine-matics is a more direct approach that focuses on the geo-metric relationships of 3D poses and 2D images; it sidesteps the challenging problem of modeling the physical forces un-derlying human motion, which requires signiﬁcant domain knowledge about physics and control. Second, compared to kinematic measurements such as 3D joint positions, phys-ical forces present unique challenges in their measurement and annotation, which renders standard supervised learn-ing paradigms unsuitable. Thus, almost all state-of-the-art methods [36, 59, 20, 19, 33] for 3D human pose estimation from monocular video are based only on kinematics. Al-though these kinematic methods can estimate human mo-tion with high pose accuracy, they often fail to produce physically-plausible motion. Without modeling the physics of human dynamics, kinematic methods have no notion of force, mass or contact; they also do not have the ability to impose physical constraints such as joint torque limits or friction. As a result, kinematic methods often generate 7159
physically-implausible motions with pronounced artifacts: body parts (e.g., feet) penetrate the ground; the estimated poses are jittery and vibrate excessively; the feet slide back and forth when they should be in static contact with the ground. All these physical artifacts signiﬁcantly limit the application of kinematic pose estimation methods. For in-stance, jittery motions can be misleading for medical moni-toring and sports training; physical artifacts also prevent ap-plications in computer animation and virtual/augmented re-ality since people are exceptionally good at discerning even the slightest clue of physical inaccuracy [44, 12].
To improve the physical plausibility of estimated human motion from video, recent work [22, 45, 47] has started to adopt the use of dynamics in their formulation. These meth-ods ﬁrst estimate kinematic motion and then use physics-based trajectory optimization to optimize the forces to in-duce the kinematic motion. Although they can generate physically-grounded motion, there are several drawbacks of trajectory optimization-based approaches. First, trajectory optimization entails solving a highly-complex optimization problem at test time. This can be computationally inten-sive and requires the batch processing of a temporal win-dow or even the entire motion sequence, causing high la-tency in pose predictions and making it unsuitable for inter-active real-time applications. Second, trajectory optimiza-tion requires simple and differentiable physics models to make optimization tractable, which can lead to high approx-imation errors compared to advanced and non-differentiable physics simulators (e.g., MuJoCo [51], Bullet [8]). Fi-nally and most importantly, the application of physics in trajectory optimization-based methods is implemented as a post-processing step that projects a given kinematic mo-tion to a physically-plausible one. Since it is optimization-based, there is no learning mechanism in place that tries to match the optimized motion to the ground truth. As such, the resulting motion from trajectory optimization can be physically-plausible but still far from the ground-truth, es-pecially when the input kinematic motion is inaccurate.
To address these limitations, we present a new approach,
SimPoE (Simulated Character Control for Human Pose
Estimation), that tightly integrates image-based kinematic inference and physics-based dynamics modeling into a joint learning framework. Unlike trajectory optimization, Sim-PoE is a causal temporal model with an integrated physics simulator. Speciﬁcally, SimPoE learns a policy that takes the current pose and the next image frame as input, and pro-duces controls for a proxy character inside the simulator that outputs the pose estimate for the next frame. To perform kinematic inference, the policy contains a learnable kine-matic pose reﬁnement unit that uses image evidence (2D keypoints) to iteratively reﬁne a kinematic pose estimate.
Concretely, the reﬁnement unit takes as input the gradient of keypoint reprojection loss, which encodes rich informa-tion about the geometry of pose and keypoints, and out-puts the kinematic pose update. Based on this reﬁned kine-matic pose, the policy then computes a character control ac-tion, e.g., target joint angles for the character’s proportional-derivative (PD) controllers, to advance the character state and obtain the next-frame pose estimate. This policy de-sign couples the kinematic pose reﬁnement unit with the dynamics-based control generation unit, which are learned jointly with reinforcement learning (RL) to ensure both ac-curate and physically-plausible pose estimation. At each time step, a reward is assigned based on the similarity be-tween the estimated motion and the ground truth. To further improve pose estimation accuracy, SimPoE also includes a new control mechanism called meta-PD control. PD con-trollers are widely used in prior work [42, 39, 61] to convert the action produced by the policy into the joint torques that control the character. However, the PD controller parame-ters typically have ﬁxed values that require manual tuning, which can produce sub-optimal results. Instead, in meta-PD control, SimPoE’s policy is also trained to dynamically adjust the PD controller parameters across simulation steps based on the state of the character to achieve a ﬁner level of control over the character’s motion.
We validate our approach, SimPoE, on two large-scale datasets, Human3.6M [14] and an in-house human mo-tion dataset that also contains detailed ﬁnger motion. We compare SimPoE against state-of-the-art monocular 3D hu-man pose estimation methods including both kinematic and physics-based approaches. On both datasets, SimPoE out-performs previous art in both pose-based and physics-based metrics, with signiﬁcant pose accuracy improvement over prior physics-based methods. We further conduct extensive ablation studies to investigate the contribution of our pro-posed components including the kinematic reﬁnement unit, meta-PD control, as well as other design choices.
The main contributions of this paper are as follows: (1) We present a joint learning framework that tightly inte-grates image-based kinematic inference and physics-based dynamics modeling to achieve accurate and physically-plausible 3D human pose estimation from monocular video. (2) Our approach is causal, runs in real-time without batch trajectory optimization, and addresses several drawbacks of (3) Our proposed meta-PD prior physics-based methods. control mechanism eliminates manual dynamics parameter tuning and enables ﬁner character control to improve pose accuracy. (4) Our approach outperforms previous art in both pose accuracy and physical plausibility. (5) We perform ex-tensive ablations to validate the proposed components to es-tablish good practices for RL-based human pose estimation. 2.