Abstract
We present a framework to generate manga from digital illustrations. In professional mange studios, the manga cre-ate workﬂow consists of three key steps: (1) Artists use line drawings to delineate the structural outlines in manga story-boards. (2) Artists apply several types of regular screentones to render the shading, occlusion, and object materials. (3)
Artists selectively paste irregular screen textures onto the canvas to achieve various background layouts or special ef-fects. Motivated by this workﬂow, we propose a data-driven framework to convert a digital illustration into three corre-sponding components: manga line drawing, regular screen-tone, and irregular screen texture. These components can be directly composed into manga images and can be further retouched for more plentiful manga creations. To this end, we create a large-scale dataset with these three components annotated by artists in a human-in-the-loop manner. We con-duct both perceptual user study and qualitative evaluation of the generated manga, and observe that our generated image layers for these three components are practically usable in the daily works of manga artists. We provide 60 qualitative results and 15 additional comparisons in the supplemen-tary material. We will make our presented manga dataset publicly available to assist related applications. 1.

Introduction
Generating manga from illustrations (Fig. 1-left) is an important task in high demand. The expansion of manga market and the rarity of manga artist have caused many manga companies to recruit a large number of digital paint-ing or illustration artists and train them as manga creators.
Training an artist to master the unique manga workﬂow, e.g., inking strategy, screentone management, texture applying,
Figure 1. Our framework automatically generate the right high-quality manga given the left illustration. Zoom in to see details. etc., is ﬁnancially expensive and can often take weeks or even months. To reduce such training costs and speed up the producing, many manga companies have began to adopt techniques that generate manga from generic art forms like illustrations and digital paintings, so that the costs to train artists can be saved, and those newly hired digital illustration artists can be free from learning extra skills and can create manga directly in their familiar digital illustration working environments. The software Clip Studio Paints (CSP) [6] and Adobe After Effects (AE) [1] are typical examples with many plugins and online tutorials [10, 11, 7, 9, 8] for editing illustrations to obtain manga manually. The widespread pop-ularity of those tutorials and plugins veriﬁes the signiﬁcance of the problem to generate manga from illustrations.
This paper starts with a key observation: the unique visual appearance of manga comes from the unique manga creation workﬂow. As shown in Fig. 2, we verify this observation 5642
Figure 2. Justiﬁcation for our motivation: the classic professional manga creation workﬂow. Artists ﬁrst ink structural line drawings, and then apply regular screentones and irregular screen texture to obtain the ﬁnal manga. by studying the manga creation workﬂow in professional studios. Firstly, artists draw line drawings as the initial outlines in manga storyboards, e.g., the artist delineates the line structure of the girl portrait in Fig. 2-(a). Secondly, artists paste screentone sheets with different regular patterns onto the regions between lines, e.g., the hair, eyes and dress in Fig. 2-(b) are pasted with such screentone sheets. Thirdly, artists ﬁll the canvas with irregular screen textures to achieve background layouts or special effects, e.g., the artist applies the romantic background screen texture to set off the mood of the girl character in Fig. 2-(c). We can see that these three steps are sufﬁcient and necessary to determine the appearance of a manga image, and each step is indispensable for preparing the high-quality manga product.
Might we be able to achieve a program that can mimic the above workﬂow, producing manga images with simi-lar appearance to the ones created by artists manually with this workﬂow, and at the same time, yielding independently usable result layers that can assist artists in each step of this workﬂow? To achieve these goals, we present a deep learning approach to mimic the manga creation workﬂow step-by-step. Firstly, given an input illustration, our frame-work estimates a line drawing map that plays a similar role to the line drawings inked by artists manually. Secondly, our framework segments the input image into a ﬁxed number of screentone classes, and pastes corresponding regular screen-tone sheets onto the image regions of each class. Thirdly, our framework predicts a texture mask to identify the areas that need to be pasted with screen textures, and afterwards syn-thesizes irregular textures in the identiﬁed areas. In this way, our framework automatically produces the line drawings, regular screentones, and screen textures. Those components can be independently used by artists for further creation, or can be directly composed into the manga outputs.
To this end, we invite artists to annotate a large-scale dataset and learn a hierarchical neural network in a data-driven manner. Our dataset contains 1502 image&annotation pairs of {illustration image, line drawing annotation, regular screentone segmentation annotation, and irregular screen tex-ture mask annotation}. All annotations are achieved with a human-in-the-loop approach, and checked by multiple artists for quality assurance. We will make this dataset publicly available to assist related applications.
Experiments show that mimicking the manga creation workﬂow yields several advantages. Firstly, in qualitative analyse, our framework can produce not only single manga image but also independent image layers at each workﬂow step to assist artists. Then, in perceptual user study, our framework tends to learn the artist decisions recorded in our presented dataset for each workﬂow step, making our framework preferred by the artists, as the manga creation depends heavily on content semantics and even artist percep-tion. Furthermore, we provide 60 qualitative results and 15 additional comparisons in the supplementary material.
In summary, our contributions are: (1) We propose a data-driven framework to generate manga from illustrations by mimicking the professional manga creation workﬂow, including the steps of line drawing inking, regular screentone pasting, and irregular screen texture pasting. (2) We present a large-scale artistic dataset of illustration and annotation pairs to facilitate the problem to generate manga from illustrations and assist related applications. (3) Perceptual user study and qualitative evaluations demonstrate that our framework is more preferable by artists when compared to other possible alternatives. 2.