Abstract
Self-supervised learning has been widely used to obtain transferrable representations from unlabeled images. Espe-cially, recent contrastive learning methods have shown im-pressive performances on downstream image classiﬁcation tasks. While these contrastive methods mainly focus on gen-erating invariant global representations at the image-level under semantic-preserving transformations, they are prone to overlook spatial consistency of local representations and therefore have a limitation in pretraining for localization tasks such as object detection and instance segmentation.
Moreover, aggressively cropped views used in existing con-trastive methods can minimize representation distances be-tween the semantically different regions of a single image.
In this paper, we propose a spatially consistent repre-sentation learning algorithm (SCRL) for multi-object and
In particular, we devise a novel location-speciﬁc tasks. self-supervised objective that tries to produce coherent spa-tial representations of a randomly cropped local region ac-cording to geometric translations and zooming operations.
On various downstream localization tasks with benchmark datasets, the proposed SCRL shows signiﬁcant performance improvements over the image-level supervised pretrain-ing as well as the state-of-the-art self-supervised learning methods. Code is available at https://github.com/ kakaobrain/scrl. (a) (b)
Figure 1. (a) AP on downstream of COCO detection task w.r.t. the upstream epochs on ImageNet. We use a ResNet-50-FPN back-bone with Faster R-CNN, using default training conﬁguration used in [42]. Only with 200 epochs of upstream, SCRL outperforms the ImageNet pre-trained counterpart as well as the state-of-the-art self-supervised learning methods. (b) AP on COCO detection task under varied downstream schedules from 0.5× (45k iterations) to 7× (630k iterations). SCRL consistently outperforms random ini-tialization, supervised pretraining, and BYOL in all the training schedules. 1.

Introduction
In computer vision, unsupervised representation learning from a large amount of unlabeled images has been shown to be effective in improving the performances of neural net-works for unknown downstream tasks, especially with few labeled data [8, 26]. While conventional generative mod-eling algorithms are difﬁcult to obtain semantically mean-ingful representations from high-resolution natural images due to their focus on low-level details [9, 2], self-supervised learning algorithms have recently shown promising results
*Equal contribution in obtaining semantic representations via the use of proxy tasks on unsupervised data [10, 30, 22, 12, 28, 16, 3, 41, 1, 14]. Among them, contrastive learning methods with dis-criminative models have particularly achieved remarkable performances on most downstream tasks related to image classiﬁcation problems [28, 16, 5, 3, 4, 41, 1, 14, 20, 39].
Contrastive self-supervised learning aims to obtain dis-criminative representations based on the semantically pos-itive and negative image pairs. Speciﬁcally, it tries to produce invariant representations from semantic-preserving augmentations of the same image while making represen-tations dissimilar from different images. However, most existing contrastive methods exploit consistent global rep-1144
resentations on a per image basis, speciﬁc for image clas-siﬁcation, and therefore they are likely to generate incon-sistent local representations with respect to the same spatial regions after image transformations. For example, when a certain object in an image is geometrically shifted or scaled, previous global contrastive methods can produce a similar global representation, even if the local feature of that object ends up losing consistency[36], since they use global pool-ing by which they can attend to other discriminative areas instead. This can consequently lead to performance degra-dation on localization tasks based on spatial representations.
In addition, previous contrastive methods often utilize heav-ily cropped views from an image to make a positive pair, and hence the representations between the semantically dif-ferent regions are rather induced to be matched [34].
In order to resolve these issues on the existing global contrastive learning methods, we propose a spatially consis-tent representation learning algorithm, SCRL, that can lever-age lots of unlabeled images, speciﬁcally for multi-object and location-speciﬁc downstream tasks including object de-tection and instance segmentation. In speciﬁc, we develop a new self-supervised objective to realize the invariant spatial representation corresponding to the same cropped region under augmentations of a given image. Since we are able to
ﬁgure out the two exactly matched spatial locations for each cropped region on the two transformed images, each posi-tive pair of cropped regions necessarily has a common se-mantic information. From a positive pair of cropped feature maps, we apply RoIAlign [18] to the respective maps and obtain equally-sized local representations. We optimize the encoding network to minimize the distance between these two local representations. Since BYOL [14] has shown to be an efﬁcient contrastive learning method without requir-ing negative pairs, we adapt its learning framework for pro-ducing our spatially coherent representations.
We perform extensive experiments and analysis on sev-eral benchmark datasets to empirically demonstrate the ef-fectiveness of the proposed SCRL in signiﬁcantly improv-ing the performances of ﬁne-tuned models on various down-stream localization tasks. Namely, SCRL consistently out-performs the random initialization, the previous image-level supervised pretraining and the state-of-the-art self-supervised methods, on the tasks of object detection and instance segmentation, with the PASCAL VOC, COCO and
Cityscapes datasets.
In particular, SCRL leads to regress object boundaries more precisely owing to accurate spatial representations before being fed into the task-speciﬁc head networks. Importantly, as shown in Figure 1, SCRL out-performs the other pretraining methods even with a small number of epochs during upstream training on unlabeled images. In addition, the improvements in ﬁne-tuned down-stream performance obtained by SCRL are consistently maintained under longer schedules as well as small data regime(i.e., 1/10 of COCO training data), which validates the beneﬁts of transferred spatial representations by SCRL.
Our main contributions can be summarized as follows:
• We take into account spatial consistency rather than global consistency on image representations and propose a novel self-supervised learning algorithm,
SCRL, on unlabeled images, especially for multi-object and location-aware downstream tasks.
• We generate multiple diverse pairs of semantically-consistent cropped spatial feature maps and apply an efﬁcient contrastive learning method with a dedicated local pooling and projection.
• A variety of experimental results show clear advan-tages of SCRL over the existing state-of-the-art meth-ods as a transferrable representation pretraining in ob-taining better performances on localization tasks. 2.