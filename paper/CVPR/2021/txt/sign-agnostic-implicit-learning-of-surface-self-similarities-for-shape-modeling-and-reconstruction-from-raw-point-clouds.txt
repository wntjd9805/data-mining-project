Abstract
Shape modeling and reconstruction from raw point clouds of objects stand as a fundamental challenge in vi-sion and graphics research. Classical methods consider analytic shape priors; however, their performance is de-graded when the scanned points deviate from the ideal con-ditions of cleanness and completeness. Important progress has been recently made by data-driven approaches, which learn global and/or local models of implicit surface repre-sentations from auxiliary sets of training shapes. Motivated from a universal phenomenon that self-similar shape pat-terns of local surface patches repeat across the entire sur-face of an object, we aim to push forward the data-driven strategies and propose to learn a local implicit surface net-work for a shared, adaptive modeling of the entire surface for a direct surface reconstruction from raw point cloud; we also enhance the leveraging of surface self-similarities by improving correlations among the optimized latent codes of individual surface patches. Given that orientations of raw points could be unavailable or noisy, we extend sign-agnostic learning into our local implicit model, which en-ables our recovery of signed implicit ﬁelds of local sur-faces from the unsigned inputs. We term our framework as
Sign-Agnostic Implicit Learning of Surface Self-Similarities (SAIL-S3). With a global post-optimization of local sign
ﬂipping, SAIL-S3 is able to directly model raw, un-oriented point clouds and reconstruct high-quality object surfaces.
Experiments show its superiority over existing methods. 1.

Introduction
Surface reconstruction from point clouds is of signiﬁ-cance during the course of digitally representing the world around us, especially when we have witnessed the devel-opment of scanning devices that makes it easier to acquire
*Equal contribution
†Correspondence to Kui Jia <kuijia@scut.edu.cn>
Figure 1: 3D reconstructions from our proposed Sign-Agnostic Implicit Learning of Surface Self-Similarities. For each sculpture, we visualize the raw, un-oriented point cloud on the left, and the reconstructed surface on the right. The surface is reconstructed by interpolation from the learned local implicit subﬁelds, where we isolate some of their zero-level sets for better understanding. point cloud data. This problem is severely ill-posed [5], since there could be inﬁnite solutions of the continuous sur-face given the discrete approximation of point clouds, es-pecially when the points are noisy, irregularly distributed, and/or incomplete. As such, proper priors of geometric reg-ularity are necessary to tackle this problem. Classical meth-ods adopt analytic priors such as local linearity and smooth-ness [26, 7, 2]. However, performance of these methods is degraded when encountering sensing imperfection, or un-available of surface normals for the observed points.
More recently, deep neural networks are introduced to learn geometric priors from auxiliary shapes [20, 33] in a data-driven manner, which have shown their superiority over classical methods. The pipeline starts from approaches
[33, 11, 31] that globally embed a shape into a latent shape space based on auto-encoders. Encoding global shape pri-ors might simplify the problem, which, however, is lim-ited in generalizing the learned priors to unseen shapes.
To improve generalization, there has been some attempts 10256
[10, 18, 25, 8, 34] that learn local shape priors and model a global shape as conﬁguration of local shape parts. Indeed, for surface shapes of a certain object category, decomposing the global modeling into local ones prevents learning pri-ors that are mostly concerned with the category-level shape conﬁguration. These methods rely on learning priors from auxiliary training sets. This always risks their generaliza-tion in cases that testing samples are out of the distributions of the training ones. In this work, we aim to close the gener-alization gap by learning the shape priors directly from the input data themselves.
Our idea is motivated from an arguably universal phe-nomenon that self-similar shape patterns of local surface patches repeat across an entire object surface. Figure 1 gives an illustration. Such a phenomenon is similar to the self-similarities of local patches in a 2D image, which has motivated a plethora of methods in the literature of image modeling and restoration [6, 14, 13].
To implement this phenomenon for modeling and recon-structing a surface from raw observed points, a challenge remains due to the possibly unreliable surface normals as-sociated with the observed individual points. One may com-pute approximate ones, which might not be precise enough to support a ﬁne surface recovery especially when points are noisy or scanner information is absent. Learning to pre-dict the surface normals [16, 21] is not applicable as well, since we may only have the observed points at hand. To this end, we propose in this paper a novel method, termed
Sign-Agnostic Implicit Learning of Surface Self-Similarities (SAIL-S3), for modeling and reconstruction of a continu-ous surface directly from a raw, un-oriented point cloud.
We note that the property of surface self-similarities is also used in [23] to deform an initial mesh, where they implic-itly leverage the property by training the mesh deformation network. In contrast, our proposed SAIL-S3 is a completely different local framework for sign-agnostic implicit surface modeling.
Speciﬁcally, SAIL-S3 is by design a local model that par-titions a global implicit surface ﬁeld into an adaptive set of overlapped, local subﬁelds, each of which is expected to cover a surface patch. We leverage the property of surface self-similarities by incorporating the following designs into
SAIL-S3: (1) we use a shared implicit model to learn these subﬁelds, while allowing the individual latent representa-tions of local subﬁelds to be freely optimized, and (2) we use a learning objective that promotes correlated latent rep-resentations when their corresponding surface patches are of similar shape (cf. Section 4.1). We extend sign-agnostic learning [3] into our local framework, and propose prov-ably model initialization that outputs a signed solution of implicit ﬁeld function given the unsigned learning objective (cf. Section 4.2). The signed solutions of local implicit sub-ﬁelds may not be consistent globally. With a global post-optimization of local sign ﬂipping, SAIL-S3 is able to di-rectly model raw, un-oriented point clouds and reconstructs high-quality object surfaces (cf. Section 4.3). We conduct thorough experiments on the objects from ShapeNet [9] and
Threedscans [1] datasets. They include object instances with natural and complex topologies. Experiments show that given no auxiliary training set, our proposed SAIL-S3 outperforms existing methods in terms of reconstruct-ing smooth and sharp surfaces, even though the compara-tive learning based methods use auxiliary training shapes.
Robustness tests with noisy inputs again conﬁrm the efﬁ-cacy of our proposed method. We ﬁnally summarize our technical contributions as follows.
• We propose a novel method of SAIL-S3 for surface modeling and reconstruction from raw, un-oriented point clouds. The method learns self-adaptive shape priors by implementing a universal phenomenon that an object surface contains self-similar shape patterns of local surface patches.
• SAIL-S3 uses adaptively learned local implicit func-tions to model the global implicit surface ﬁeld. We extend sign-agnostic learning into the local SAIL-S3 framework, by proposing provably model initializa-tions that can be optimized to produce signed solutions of local implicit function from the unsigned learning objective.
• With a global post-optimization of local sign ﬂipping,
SAIL-S3 is able to directly model raw, un-oriented point clouds and reconstructs high-quality surfaces of objects. Experiments demonstrate its superiority over existing methods. 2.