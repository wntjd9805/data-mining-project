Abstract
Cross-domain weakly supervised object detection aims to adapt object-level knowledge from a fully labeled source domain dataset (i.e., with object bounding boxes) to train object detectors for target domains that are weakly labeled (i.e., with image-level tags). Instead of domain-level distri-bution matching, as popularly adopted in the literature, we propose to learn pixel-wise cross-domain correspondences for more precise knowledge transfer. It is realized through a novel cross-domain co-attention scheme trained as region competition. In this scheme, the cross-domain correspon-dence module seeks for informative features on the target domain image, which if warped to the source domain im-age, could best explain its annotations. Meanwhile, a col-laborative mask generator competes to mask out the rel-evant target image region to make the remaining features uninformative. Such competitive learning strives to corre-late the full foreground in cross-domain image pairs, reveal-ing the accurate object extent in target domain. To allevi-ate the ambiguity of inter-domain correspondence learning, a domain-cycle consistency regularizer is further proposed to leverage the more reliable intra-domain correspondence.
The proposed approach achieves consistent improvements over existing approaches by a considerable margin, demon-strated by the experiments on various datasets. 1.

Introduction
With decades of efforts made in improving feature rep-resentations [7, 20, 13], learning architectures [9, 28, 36] and large-scale datasets [8, 31, 23], performance of modern object detectors has been raised to a brand new level. Never-∗Equal contribution. Part of this work is done during Luwei’s internship with SenseTime Research.
†Correspondence should be addressed to Jia Li (jiali@buaa.edu.cn) and
Yu Zhang (zhangyulb@gmail.com).
Figure 1. Motivation of the proposed approach to address cross-domain object detection. (a) Conventional approaches project im-ages from different domains into a uniﬁed feature space such that a domain classiﬁer cannot easily separate them. (b) Assuming the target domain is weakly labeled, we explicitly establish pixel-wise correspondence among the semantic regions of cross-domain im-ages and form semantic clusters in feature space for accurate, lo-calized domain transfer. Best viewed in color. theless, generalizing existing detection models to novel un-seen domains still remains an issue, as the models are often biased to dataset-speciﬁc patterns rather than data-invariant
“common knowledge”. It often takes huge efforts to collect the well-annotated training data of the novel target domains from scratch to feed the data-hungry modern architectures.
Recently this issue is addressed via unsupervised do-main adaptation [3, 10], that transfers task knowledge from a richly annotated source domain to poorly annotated tar-get domains. Yet, domain discrepancy lie in various fre-quency patterns [45], visual styles [21] and class distribu-tions [40], making it nontrivial to align knowledge transfer to the desired task objective. Heuristic strategies (e.g. adap-tive weighting [48, 42, 18], foreground mining [14, 43, 2], self-supervision [30, 19]) were proposed to guide the do-main transfer to focus more on detecting foreground ob-jects. However, with the lack of direct knowledge about the 9929
object distributions in target domain, it is difﬁcult to achieve accurate object-level domain transfer.
To address this issue, a relaxed setting was proposed by
Inoue et al. [15], that the target domain images are assumed to be tagged with semantic labels. This novel setting, called cross-domain weakly supervised object detection, gives ac-cess to direct knowledge of the target domain with minimal annotation cost. As such, foreground/background ambigu-ity of object localization within target domain was greatly reduced. However, knowledge adaptation is still conducted globally at domain level, while local feature alignment and knowledge transfer that could be mined from the weak an-notations in the target domain, is less explored.
In this paper, we embrace the weakly supervised setting of [15] and propose a novel approach for cross-domain ob-ject detection. As shown in Fig. 1, different from previ-ous works that perform knowledge transfer at domain-level, our approach explicitly establishes pixel-wise semantic cor-respondences in each pair of cross-domain images for ac-curate local knowledge transfer. As the target domain is weakly labeled, the core idea is to divide each image into semantic clusters in weakly supervised manner that can well explain the region annotations of source domain image, un-der the cross-domain warping indicated by their correspon-dences. Speciﬁcally, a cross-domain co-attention module is trained to seek for informative features on the target domain image so as to well reconstruct the annotations of the corre-sponding source domain image. At the same time, a jointly trained mask generator competes to mask out the relevant target image region, to make the remaining correspondences uninformative. Such competitive process facilitates the cor-relation of full extent of the underlying objects across do-mains. To reduce the ambiguity of cross-domain matching, we further propose a novel domain-cycle consistency reg-ularizer to leverage intra-domain correspondence as robust self-supervision. The proposed approach sets new state-of-the-art results, improves over previous works consistently by 4% ∼ 6% in mean average precision on 3 datasets.
We highlight the following contributions. 1) We propose a novel approach formulated as region competition, capa-ble of establishing explicit pixel-wise semantic correspon-dences across domains and enabling accurate local knowl-edge transfer. 2) We introduce the cycle consistency reg-ularizer to cross-domain object detection, which provides robust and cost-free self-supervision by leveraging both in-ter and intra-domain cues. 3) We conduct extensive exper-iments to evaluate the proposed modules, showing notably and consistently improved results on three benchmarks. 2.