Abstract
Bayesian neural networks have been widely used in many applications because of the distinctive probabilistic representation framework. Even though Bayesian neural networks have been found more robust to adversarial at-tacks compared with vanilla neural networks, their ability to deal with adversarial noises in practice is still limited.
In this paper, we propose Spectral Expectation Bound Reg-ularization (SEBR) to enhance the robustness of Bayesian neural networks. Our theoretical analysis reveals that training with SEBR improves the robustness to adversar-ial noises. We also prove that training with SEBR can re-duce the epistemic uncertainty of the model and hence it can make the model more conﬁdent with the predictions, which veriﬁes the robustness of the model from another point of view. Experiments on multiple Bayesian neural network structures and different adversarial attacks validate the cor-rectness of the theoretical ﬁndings and the effectiveness of the proposed approach. 1.

Introduction
Bayesian neural networks [8, 29] provide a probabilis-tic view of deep learning frameworks by treating the model weights as random variables. One of the profound advan-tages of a Bayesian neural network is that it can provide both the aleatoric uncertainty and the epistemic uncertainty estimations because of the probabilistic representation of the model. In contrast, a vanilla deep neural network only models the aleatoric uncertainty by a certain probability dis-tribution. Thus, Bayesian neural networks are successfully applied in many tasks to model uncertainties and build a more reliable and robust system, including but not limited to computer vision tasks [17, 20, 30] and natural language processing tasks [39].
*Tao Song is the corresponding author.
†This work was supported in part by National NSF of China (NO. 61872234, 61732010, 61525204) and Shanghai Key Laboratory of Scal-able Computing and Systems.
Neural network models without particular settings [2, 14] are sensitive and vulnerable to adversarial attacks in testing. Defenses against adversarial attacks are difﬁcult.
The Lipschitz constant serves as an evaluation metric of the adversarial robustness of a model by providing a worst-case bound [18, 37]. Many previous methods enhance the model robustness by constricting the Lipschitz constant
[10, 23, 31]. These methods have made a signiﬁcant im-provement in both theoretical analysis and practical appli-cations. However, they cannot be used in Bayesian neural networks directly because of the probabilistic representa-tions of model parameters.
Bayesian neural networks, on the other hand, are use-ful for defending adversarial noises compared with vanilla neural networks. Because of the probabilistic representa-tions of model parameters and predictions, Bayesian neu-ral networks can be applied to detect adversarial samples from normal samples [5, 24, 34]. Moreover, Bayesian neu-ral networks have been found to have adversarial robustness naturally. Y. Gal et al. [13] and Carbone et al. [9] reveal that any gradient-based adversarial attacks are invalid on
Bayesian neural networks under some extremely idealized conditions, e.g., idealized architecture [13], sufﬁcient data and sampling times [9]. Nonetheless, these studies all have certain limitations. In many practical scenarios, predictions on adversarial samples are still necessary even though they have been detected. Additionally, the idealized conditions are almost impossible in practice. Therefore, there is still a vast space for further improvement of the robustness of
Bayesian neural networks.
This paper presents a method, Spectral Expectation
Bound Regularization (SEBR), to enhance the robustness of Bayesian neural networks. The model trained with SEBR has a smaller expectation of the spectral norm of the training parameter matrices. As a result, the improvement on the ad-versarial robustness of Bayesian neural networks is guaran-teed based on theoretical derivation in this paper. Moreover, the impact of SEBR on the epistemic uncertainty of the out-put of Bayesian models is also studied theoretically and it further veriﬁes the robustness of the proposed method. Ex-3815
periments are carried out to validate both the correctness of the theoretical ﬁndings and the improvement on the robust-ness of the models in a variety of actual scenarios.
In summary, the main contributions are listed as follows:
• This paper proposes Spectral Expectation Bound Reg-ularization (SEBR), which applies the Lipschitz con-straint in Bayesian neural networks efﬁciently. Ac-cording to the theoretical analysis, it can improve the robustness of the Bayesian neural network models.
• It is proved that SEBR training reduces the uncertainty of the model effectively in theoretical analysis, which provides another explanation of the model robustness.
• Experiments on multiple Bayesian neural network structures verify the theory and the effectiveness of the proposed method. The codes are available in https:
//github.com/AISIGSJTU/SEBR. 2.