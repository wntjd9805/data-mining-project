Abstract
In this paper, we propose a novel Feature Decomposition and Reconstruction Learning (FDRL) method for effective facial expression recognition. We view the expression infor-mation as the combination of the shared information (ex-pression similarities) across different expressions and the unique information (expression-speciﬁc variations) for each expression. More speciﬁcally, FDRL mainly consists of two crucial networks: a Feature Decomposition Network (FDN) and a Feature Reconstruction Network (FRN). In particu-lar, FDN ﬁrst decomposes the basic features extracted from a backbone network into a set of facial action-aware latent features to model expression similarities. Then, FRN cap-tures the intra-feature and inter-feature relationships for la-tent features to characterize expression-speciﬁc variations, and reconstructs the expression feature. To this end, two modules including an intra-feature relation modeling mod-ule and an inter-feature relation modeling module are de-veloped in FRN. Experimental results on both the in-the-lab databases (including CK+, MMI, and Oulu-CASIA) and the in-the-wild databases (including RAF-DB and SFEW) show that the proposed FDRL method consistently achieves higher recognition accuracy than several state-of-the-art methods. This clearly highlights the beneﬁt of feature de-composition and reconstruction for classifying expressions. 1.

Introduction
Facial expression is one of the most natural and univer-sal signals for human beings to express their inner states and intentions [4]. Over the past few decades, Facial Ex-pression Recognition (FER) has received much attention in computer vision, due to its various applications including virtual reality, intelligent tutoring systems, health-care, etc.
[29]. According to psychological studies [9], the FER task is to classify an input facial image into one of the follow-ing seven categories: angry (AN), disgust (DI), fear (FE),
∗Corresponding author (email: yanyan@xmu.edu.cn).
Figure 1 – The images in each group show a similar facial action,
Images are from the but they are from different expressions.
RAF-DB database [13]. happy (HA), sad (SA), surprise (SU), and neutral (NE).
A variety of FER methods [3, 13, 20, 26] have been pro-posed to learn holistic expression features by disentangling the disturbance caused by various disturbing factors, such as pose, identity, illumination, and so on. However, these methods neglect the fact that the extracted expression fea-tures corresponding to some expressions may still not be easily distinguishable, mainly because of high similarities across different expressions.
An example is shown in Figure 1. We can observe that some facial images corresponding to the NE, SA, HA, and
DI expressions exhibit closing eyes. The facial images cor-responding to the SU, FE, AN, and HA expressions all show opening mouths, while those corresponding to the AN, DI,
SA, and FE expressions show frowning brows. The images from different facial expressions in each group give a sim-ilar facial action, where the distinctions between some ex-pressions are subtle. Therefore, how to learn effective ﬁne-grained expression features to identify subtle differences in expressions by considering similar facial actions is of great importance.
The expression information is composed of the shared information (expression similarities) across different ex-pressions and the unique information (expression-speciﬁc variations) for each expression. The expression similari-7660
ties can be characterized by shared latent features between different expressions, while the expression-speciﬁc varia-tions can be reﬂected by importance weights for latent fea-tures. Therefore, the expression features can be represented by combining a set of latent features associated with their corresponding importance weights. Traditional FER meth-ods [15, 18, 31, 5] adopt Principal Component Analysis (PCA) or Linear Discriminant Analysis (LDA) to extract eigenvectors (corresponding to latent features) and eigen-values (corresponding to importance weights). However, these eigenvectors only capture holistic structural informa-tion rather than ﬁne-grained semantic information of facial images, which is critical for FER.
Motivated by the success of deep learning in various vi-sion tasks, here we propose a novel Feature Decomposition and Reconstruction Learning (FDRL) method for effective
FER. FDRL is mainly comprised of two crucial networks, including a Feature Decomposition Network (FDN) and a
Feature Reconstruction Network (FRN). The two networks are tightly combined and jointly trained in an end-to-end manner.
Speciﬁcally, a backbone convolutional neural network is ﬁrst used to extract basic features. Then, FDN decom-poses the basic feature into a set of facial action-aware la-tent features, which effectively encode expression similari-ties across different expressions. In particular, a compact-ness loss is developed to obtain compact latent feature rep-resentations. Next, FRN, which includes an Intra-feature
Relation Modeling module (Intra-RM) and an Inter-feature
Relation Modeling module (Inter-RM), models expression-speciﬁc variations and reconstructs the expression feature.
Finally, an expression prediction network is employed for expression classiﬁcation.
In summary, our main contributions are summarized as follows.
• A novel FDRL method is proposed to perform FER.
In FDRL, FDN and FRN are respectively devel-oped to explicitly model expression similarities and expression-speciﬁc variations, enabling the extraction of ﬁne-grained expression features. Thus, the subtle differences between facial expressions can be accu-rately identiﬁed.
• Intra-RM and Inter-RM are elaborately designed to learn an intra-feature relation weight and an inter-feature relation weight for each latent feature, respec-tively. Therefore, the intra-feature and inter-feature re-lationships between latent features are effectively cap-tured to obtain discriminative expression features.
• Our FDRL method is extensively evaluated on both the in-the-lab and the in-the-wild FER databases. Ex-perimental results show that our method consistently outperforms several state-of-the-art FER methods. In particular, FDRL achieves 89.47% and 62.16% recog-nition accuracy on the RAF-DB and SFEW databases, respectively. This convincingly shows the great poten-tials of feature decomposition and reconstruction for
FER. 2.