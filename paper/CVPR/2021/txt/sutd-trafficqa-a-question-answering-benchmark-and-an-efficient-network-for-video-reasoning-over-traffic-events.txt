Abstract
Trafﬁc event cognition and reasoning in videos is an im-portant task that has a wide range of applications in in-telligent transportation, assisted driving, and autonomous vehicles. In this paper, we create a novel dataset, SUTD-TrafﬁcQA (Trafﬁc Question Answering), which takes the form of video QA based on the collected 10,080 in-the-wild videos and annotated 62,535 QA pairs, for benchmarking the cognitive capability of causal inference and event under-standing models in complex trafﬁc scenarios. Speciﬁcally, we propose 6 challenging reasoning tasks corresponding to various trafﬁc scenarios, so as to evaluate the reasoning capability over different kinds of complex yet practical traf-ﬁc events. Moreover, we propose Eclipse, a novel Efﬁcient glimpse network via dynamic inference, in order to achieve computation-efﬁcient and reliable video reasoning. The ex-periments show that our method achieves superior perfor-mance while reducing the computation cost signiﬁcantly.
The project page: https://github.com/SUTDCV/
SUTD-TrafficQA. 1.

Introduction
Intelligent transportation [64] has been receiving in-creasing attention recently, and for the applications, such as assisted driving, violation detection, and congestion forecasting, accurate and efﬁcient cognition and reasoning over the trafﬁc events captured by video cameras is ex-tremely important. As shown by previous works [2, 18], well-designed datasets are often crucial for the develop-ment, adaptation and evaluation of different data-driven ap-proaches. This indicates the signiﬁcance of creating com-prehensive and challenging benchmarks for video causal reasoning and cognitive development of models, that ex-plore the underlying causal structures of various trafﬁc events. To this end, we introduce a novel dataset, SUTD-∗Corresponding Author.
TrafﬁcQA (Trafﬁc Question Answering), to facilitate the re-search of causal reasoning in complex trafﬁc scenarios.
In our dataset, to help develop models for addressing several major and concerning issues in intelligent trans-portation, we design 6 challenging reasoning tasks, which require exploring the complex causal structures within the inference process of the trafﬁc events. As shown in Figure 1, these tasks correspond to various trafﬁc scenarios involv-ing both road-agents and surroundings, and the models are required to forecast future events, infer past situations, ex-plain accident causes, provide preventive advice, and so on.
To present these reasoning tasks, video question answer-ing [66] is a natural and effective choice, and is used for our dataset construction, since to accurately answer the given questions, the models need to acquire strong capabilities of performing various levels of logical reasoning and spatio-temporal cognition for the events.
Besides providing the challenging and useful reasoning tasks, we adopt a combination scheme of online collection and ofﬂine capturing to collect videos, such that the data in our benchmark covers various trafﬁc events, diversiﬁed road-agents and surroundings, and different capturing per-spectives in the wild. With the provided various tasks and diverse videos, our dataset shall be able to serve as a com-prehensive benchmark for video reasoning of trafﬁc events.
In some application scenarios, (e.g., assisted driving), the computational resource and energy budget can be con-strained. Thus both the inference accuracy and the compu-tation efﬁciency are important for video event reasoning in these scenarios. Existing video QA methods [23, 10, 30] mainly focus on strengthening the reasoning accuracy with-out emphasizing much efﬁciency, and most of these works apply ﬁxed computation pipelines to answer different ques-tions, while ignoring to conduct adaptive and efﬁcient com-putation resource allocation based on the logic structure be-hind reasoning over video events.
In this paper, to achieve reliable and efﬁcient video rea-soning, we propose Eclipse, an Efﬁcient glimpse network.
Speciﬁcally, considering there is often large redundancy 9878
00:17
Basic Understanding 00:20
Attribution 00:22 00:26
Introspection 00:29
Q: What is the type of the road?
Q: What might be the reason which led to  this accident?
Q: What could have been done to prevent this accident from  happening?
Alley
Boulevard
Expressway
Avenue
The black sedan exceeded the speed limit.
The accident could have been avoided if the white sedan had slowed down.
The white sedan did an illegal lane changing.
The accident could have been avoided if the black sedan had changed the lane.
Extreme weather condition.
The accident could have been prevented if the road is marked clearly.
The blue truck violated the traffic lights.
The accident could have been avoided if the white sedan had stayed on its lane.
Counterfactual Inference
Event Forecasting
Reverse Reasoning
Q: Would the accident still happen if there were  fewer vehicles on the road?
Q: Will the white sedan crash into the  highway’s safety barrier? ( Showing model the video  up to 00:22 only. )
Yes, the road is not congested at the first place, and the  accident is not related to the density of the vehicles on the road.
Yes, very likely.
No, very unlikely.
Q: What might have happened moments  ago? ( Showing model the video from 00:26 onwards only. )
The blue truck hit the while sedan from the back.
The white sedan crashed into the blue truck.
No, fewer vehicles would have provided  enough space to safely avoid the accident.
No, there is no accident.
There is no white sedan at the scene.
The blue truck braked hard suddenly.
There is no safety barrier at the scene.
The white sedan lost its control.
Figure 1. An example of our SUTD-TrafﬁcQA dataset showing that a white sedan had missed the highway exit. Hence it chose to change the lane illegally for driving towards the exit. To avoid collision, the blue truck had to brake suddenly, and then an accident occurred. Six reasoning tasks are designed, covering a broad range of inference problems from basic understanding to complex reasoning and attribution analysis. To accurately answer these questions, the models need to explore the causal, logic, and spatio-temporal structures of the video event. among video frames, via dynamic inference, our network adaptively determines where to skip and glimpse at each step, and what computation granularity needs to be allo-cated for the glimpsed frame. Such a dynamic reasoning scheme avoids feature extraction for the irrelevant segments in the video, and hence signiﬁcantly reduces the overall computation cost towards reliable and efﬁcient reasoning.
It is noteworthy that both the determination of selecting a glimpse frame and the decision of computation granularity for each glimpse are essentially discrete operations, which are not trivial to optimize. To handle this issue, an effective joint Gumbel-Softmax mechanism is also introduced in this paper, which makes our Eclipse framework fully differen-tiable and end-to-end trainable.
To the best of our knowledge, this is the ﬁrst work that si-multaneously performs adaptive frame localization and fea-ture granularity determination in a novel dynamic reasoning process for reliable and efﬁcient causal reasoning and video
QA. A joint Gumbel-Softmax operation is also introduced in this work to optimize the two decisions jointly. 2.