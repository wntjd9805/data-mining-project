Abstract 1.

Introduction
Recently unsupervised domain adaptation for the seman-tic segmentation task has become more and more popular due to high-cost of pixel-level annotation on real-world im-ages. However, most domain adaptation methods are only restricted to single-source-single-target pair, and can not be directly extended to multiple target domains. In this work, we propose a collaborative learning framework to achieve unsupervised multi-target domain adaptation. An unsuper-vised domain adaptation expert model is ﬁrst trained for each source-target pair and is further encouraged to col-laborate with each other through a bridge built between different target domains. These expert models are further improved by adding the regularization of making the con-sistent pixel-wise prediction for each sample with the same structured context. To obtain a single model that works across multiple target domains, we propose to simultane-ously learn a student model which is trained to not only imitate the output of each expert on the corresponding tar-get domain, but also to pull different expert close to each other with regularization on their weights. Extensive ex-periments demonstrate that the proposed method can ef-fectively exploit rich structured information contained in both labeled source domain and multiple unlabeled target domains. Not only does it perform well across multiple target domains but also performs favorably against state-of-the-art unsupervised domain adaptation methods specially trained on a single source-target pair. Code is available at https://github.com/junpan19/MTDA.
†The work was done in Noah’s Ark Lab, Huawei Technologies.
∗Corresponding author
Semantic segmentation aims at interpreting an image by assigning each pixel to a semantic class [33, 6, 7, 55, 63].
Recently, semantic segmentation has achieved remarkable progress and is widely applied to intelligent systems such as autonomous driving, human-computer interaction and other low-level vision tasks [22, 21, 23]. Its success is mainly attributed to the supervised learning over large amounts of annotated data. However, human efforts on pixel-level annotations are expensive, which substantially limits the scalability of segmentation models. With large amounts of low-cost and diverse synthetic data simulated with game engines available, unsupervised domain adaptation (UDA) draws much attention to adapt the model learned on synthetic data to real-world data. Unsupervised domain adaptation methods [28, 51, 59, 34, 4, 61, 36, 37] alleviate the issue of domain mismatch by training a model on both labeled source domain and unlabeled target domain.
However, the setting of traditional unsupervised domain adaptation in semantic segmentation is usually restricted to single-source-single-target pair, as shown in Figure 1 (a).
The learned model only works for a single target domain and can not be easily extended to multiple target domains, that is, multi-target domain adaptation (MTDA). With this setting, it is expected to learn a single model that is able to make full use of data from a single labeled source domain and multiple unlabeled target domains and performs well on multiple target domains simultaneously. This setting has great value in real-world applications. For example, in autonomous driving it is expected to have a model work in various environments with different lighting, weather and cityscapes. It is difﬁcult to collect annotated data for such different environments but is easy to have large amounts of unlabeled data. 8187
Figure 1. Comparison between the setting of single-target domain adaptation (STDA) and multi-target domain adaptation (MTDA). (a) Multiple STDA models with each one corresponding to a single target domain. (b) A single MTDA model working across multiple target domains.
There have been several works on MTDA [14, 40, 56], however, most of them focus on the classiﬁcation task. Few works are developed to address the semantic segmentation task under the setting of multi-target domain adaptation. To the best of our knowledge, this is the ﬁrst work to explore multi-target domain adaptation for semantic segmentation.
The main challenge with this task are two folds: (1) lack of pixel-wise supervised information in multiple target domains poses great difﬁculty in mining inherent and transferable knowledge; (2) it is difﬁcult to have a single model that works well on multiple target domains. There are two intu-itive ways of extending the pair-wise DA to work on multiple target domains: (1) training multiple models individually for each target domain and (2) training a single model on com-bined data from multiple target domains. However, directly using multiple models would not play the model ensem-bling effect as in that in single domain. Inaccurate model dispatching would increase the risk of danger in practical applications. The model developed by direct data combina-tion is likely to incur performance degradation due to the discrepancy between domains. Intuitively, a generic expert learned in a naive way might have inferior knowledge than the specialized expert for each target domain.
In this paper, we propose a novel collaborative consis-tency learning framework for multi-target domain adaptation, which includes collaborative consistency learning among multiple expert models and online knowledge distillation to obtain a single domain-generic student model. This work shows that once connection among domains is fully explored, i.e., connection between each source-target domain pair and among target domains, it can obtain even better performance than models learned with unsupervised domain adaptation methods for each source-target domain pair.
In the proposed collaborative consistency learning frame-work, data from all domains are ﬁrst translated to the style of each target domain, respectively. In this way, we build a bridge between each pair of target domains, that is, images from the same domain are translated into different styles corresponding to different target domains. For each style, a semantic segmentation model is trained on both translated la-beled data from source domain and translated unlabeled data from multiple target domains. Each network is a domain-speciﬁc expert and is trained with a kind of UDA loss and an additional consistency loss that align segmentation re-sults of images of the same content but with different styles based on the bridge. Such collaborative consistency learning helps knowledge exchange among domain-speciﬁc experts.
To obtain a single model that works across multiple target domains, we design a student model whose weights are regu-larized by the weights of multiple experts and further teach it with multiple experts through knowledge distillation. In this way, the student model is able to learn common semantic knowledge from teachers across multiple domains.
To sum up, we make the following contributions:
• To the best of our knowledge, this is the ﬁrst work that explores the unsupervised multi-target domain adapta-tion task in semantic segmentation.
• We propose a new collaborative consistency learning framework to handle the MTDA task for semantic seg-mentation, where unlabeled data in multiple target do-mains is fully leveraged to train a single model that works across all target domains.
• Experimental results demonstrate the effectiveness of the proposed method. We can obtain a single model that not only works well across multiple target domains but also performs favorably against domain-specialized models on each target domain. 2.