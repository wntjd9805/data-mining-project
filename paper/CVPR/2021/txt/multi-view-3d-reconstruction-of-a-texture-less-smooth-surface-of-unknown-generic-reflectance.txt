Abstract
Recovering the 3D geometry of a purely texture-less ob-ject with generally unknown surface reﬂectance (e.g. non-Lambertian) is regarded as a challenging task in multi-view reconstruction. The major obstacle revolves around establishing cross-view correspondences where photomet-ric constancy is violated. This paper proposes a simple and practical solution to overcome this challenge based on a co-located camera-light scanner device. Unlike existing solutions, we do not explicitly solve for correspondence.
Instead, we argue the problem is generally well-posed by multi-view geometrical and photometric constraints, and can be solved from a small number of input views. We for-mulate the reconstruction task as a joint energy minimiza-tion over the surface geometry and reﬂectance. Despite this energy is highly non-convex, we develop an optimization al-gorithm that robustly recovers globally optimal shape and reﬂectance even from a random initialization. Extensive ex-periments on both simulated and real data have validated our method, and possible future extensions are discussed. 1.

Introduction 3D reconstruction from multi-view images is one of the central problems in computer vision. Most traditional multi-view reconstruction methods such as SFM (structure from motion) often assume the scene or object to be recon-structed have distinctive features that are view-independent, so that cross-view feature correspondences can be read-ily established. However, this is not the case for many commonly-seen real-world objects or surfaces manifest-ing non-Lambertian reﬂectance. Traditional SFM meth-ods are unable to reconstruct such texture-less surfaces with glossy appearance. The problem is even more challenging if the generic surface reﬂectance is unknown, in which case there is no apparent way to model how object’s appearance changes with viewpoint.
Figure 2: Two experiment setups: Hardware used for capturing images under a co-located setup. A point light source is rigidly attached to camera lens with a small displacement.
By marrying photometric stereo with traditional multi-view methods, many papers have succeeded in overcom-ing parts of these challenges. Most of these methods are reliant on an external initialization of the 3D shape (e.g.
[27, 6, 24]) to establish initial correspondences. Typically,
ﬁner-grained details are added incrementally to the recov-ered geometry. However, good initialization is not of-ten guaranteed (e.g. many require initial shape from SFM pipelines, which are already vulnerable to textureless sur-face or specular highlights), and a large number of input images are often required. Additionally, many methods re-16226
sort to restrictive assumptions about the setup, objects and scenes. Common assumptions include e.g., purely/almost
Lambertian reﬂectance [15, 7, 8, 39, 3, 29, 19], planer ob-ject shape [9], known depth via an RGB-D sensor [31], or stereo vision with semi-static viewpoint but varying illumi-nation [41, 13]. So far, direct multi-view reconstruction of textureless, glossy objects remains an open challenge that no method addresses well.
This paper presents a simple and practical solution to jointly recover high-ﬁdelity surface geometry as well as un-known generic reﬂectance of a purely texture-less object.
We advocate a co-located camera and light-source conﬁg-uration, as shown in Fig. 2, where a point light source is rigidly and closely attached to the camera. Such scanner device is easily accessible with commodity hardware (e.g. a mobile phone camera with built-in ﬂash).
Unlike existing photometric 3D reconstruction methods under ﬁxed viewpoint, we allow the camera to move freely to leverage multi-view constraints. Our method is also dif-ferent from existing multi-view methods mentioned above, in that we do not intend to establish explicit cross-view cor-respondences, either by feature matching or through shape initialization, since both are hard to obtain for a purely texture-less surface with arbitrary BRDF. Instead, we show that given a small number of views, shape and reﬂectance are already well-constrained by a physically-based image formation model. With this observation, we formulate re-construction task as an energy minimization problem in-volving a single, uniﬁed objective. While this problem is still highly non-convex, we propose an effective optimiza-tion based approach that robustly reconstructs complex ge-ometry as well as general reﬂectance without initial shape.
Code and data will be available at https://github.com/ za-cheng/PM-PMVS/. 2.