Abstract
To address the challenging task of instance-aware hu-man part parsing, a new bottom-up regime is proposed to learn category-level human semantic segmentation as well as multi-person pose estimation in a joint and end-to-end manner. It is a compact, efﬁcient and powerful framework that exploits structural information over different human granularities and eases the difﬁculty of person partition-ing. Speciﬁcally, a dense-to-sparse projection ﬁeld, which allows explicitly associating dense human semantics with sparse keypoints, is learnt and progressively improved over the network feature pyramid for robustness. Then, the dif-ﬁcult pixel grouping problem is cast as an easier, multi-person joint assembling task. By formulating joint associa-tion as maximum-weight bipartite matching, a differentiable solution is developed to exploit projected gradient descent and Dykstra’s cyclic projection algorithm. This makes our method end-to-end trainable and allows back-propagating the grouping error to directly supervise multi-granularity human representation learning. This is distinguished from current bottom-up human parsers or pose estimators which require sophisticated post-processing or heuristic greedy algorithms. Experiments on three instance-aware human parsing datasets show that our model outperforms other bottom-up alternatives with much more efﬁcient inference. 1.

Introduction
Instance-aware human parsing, i.e., partitioning humans into semantic parts (e.g., torso, head) and associating each part with the corresponding human instance, has only started to be tackled in the literature (dating back to [31]).
This article addresses this task through a new regime, which learns to jointly estimate human poses (i.e., a sparse, skeleton-based human representation) and segment human parts (i.e., a pixel-wise, ﬁne-grained human representation) in an end-to-end trainable, bottom-up fashion.
*Corresponding author: Wenguan Wang.
Figure 1: Overview of our new bottom-up regime for instance-aware human semantic parsing. By learning 1) category-level human semantic parsing, 2) body-to-joint projection, and 3) bottom-up keypoint detection and association in a joint and end-to-end manner, our model tackles the task in a differentiable, multi-granularity human representation learning framework.
In the ﬁeld of human parsing, the idea of leveraging hu-man pose as structural knowledge to facilitate human un-derstanding has been exploited for years [56]. However, previous efforts only focus on the instance-agnostic set-ting [54, 53, 15, 37, 64, 48]. Further, most of them directly utilize human joints (pre-detected from off-the-shelf pose estimators) as extra inputs [56, 54], or simply generate key-point estimations as a by-product [15, 64]. In sharp contrast, by learning to associate semantic person pixels with their closest person instance joints, our model seamlessly injects bottom-up pose estimation into instance-aware human se-mantic learning and inference. Thus, our human parser can make use of the complementary cues from sparse human joints and dense part semantics, and push further the en-velope of human understanding in unconstrained environ-ments. This represents an early effort to formulate instance-aware human parsing and multi-person pose estimation in a bottom-up, differentiable, and multi-granularity human rep-resentation learning framework (see Fig. 1). 1622
Figure 2: Trade-off between performance vs. efﬁciency on
MHPv2 val [65]. The x-axis and y-axis denote FPS and APp 50, respectively. The circle size indicates Multi-Adds (G). Top-down and bottom-up models are given in black and red, respectively.
Our model shows promising performance with high efﬁciency.
More importantly, our framework yields a new paradigm for bottom-up, instance-aware human part parsing. For hu-man instance discrimination, current bottom-up human parsers learn to associate pixels by directly regressing in-stance locations [65] or predicting pair-wise connectiveness between pixels [30]. However, instance locations (i.e., hu-man centroids or bounding box corners) are less seman-tic and pair-wise embeddings are difﬁcult to learn (due to deformations, variations and occlusions of human bod-ies) [50]. As shown in Fig. 1, our model instead regresses semantic- and geometry-rich human joints as pixel embed-dings. Then, ﬁne-grained human semantics can be efﬁ-ciently grouped through body joint association. In essence, it formulates instance-aware human semantic parsing by jointly learning: 1) category-level human semantic pars-ing, 2) body-to-joint projection, and 3) bottom-up multi-person keypoint detection and association. Thus, our model avoids sophisticated inference and heavy network designs, and neatly explores the structural constraints over human bodies. Such a ﬂexible network design can beneﬁt from progress in bottom-up pose estimation and semantic seg-mentation techniques, and signiﬁcantly differentiates itself from existing instance-aware human parsers.
Concretely, three crucial techniques, for the ﬁrst time in the ﬁeld, are exploited to deliver our compact and powerful instance-aware human parsing solution:
• Differentiable body-to-joint projection: We propose a
Dense-to-Sparse Projection Field (DSPF), which is a set of 2D vectors over the image lattice. For each human pixel, its DSPF vector encodes the offset to the closest in-stance joint. DSPF thus allows us to explicitly associate dense human semantics with sparse joint representations.
• Multi-step DSPF estimation: To address the difﬁculties of human body variations and occlusions, DSPF is com-puted in a coarse-to-ﬁne fashion, over the network fea-ture pyramid. Deeper-layer features are low-resolution, yet robust to the challenges. They are thus used to de-rive an initial discriminative DSPF. Conditioning on the shallower-layer features, a ﬁner DSPF is inferred by com-puting the residue to the coarse estimation. To reduce the feature-space distance across network layers, cross-layer feature alignment is learnt and adopted. In this way, the residue has a smaller magnitude and is easier to infer.
• An end-to-end trainable framework: Current bottom-up multi-person pose estimators solve joint association through heuristic greedy algorithms [4, 27], independent from joint detection. This breaks the end-to-end pipeline and leads to suboptimal results. Since joint association can be formulated as maximum-weight bipartite match-ing [4], we explore a differentiable solution to this, in-spired by [61]. It revisits projected gradient descent and
Dykstra’s cyclic projection [2] for convex constrained minimization. The solution is neat and light-weight, al-lowing directly using the grouping errors for supervision.
Our model is also distinguished for its practical utility.
First, it can beneﬁt a host of human-centric applications.
Some of them, such as augmented reality, are pose guided, while others, such as live streaming, video editing and vir-tual try-on systems, require understanding of ﬁne-grained human semantics. Thus, our method can meet different needs in real-life applications with only a single model.
Second, due to its bottom-up nature and fast keypoint asso-ciation, our method generates instance-level parsing results at a high speed of 0.15 s per image (see Fig. 2), irrespective of the number of people in the scene, and, which is much faster than other alternatives (e.g., 1.15 s [42], 14.94 s [30]).
Extensive experiments are conducted on three instance-aware human parsing datasets. Speciﬁcally, on MHPv2[65], our model achieves an APp 50 of 39.0, much better than current top-leading bottom-up method (i.e., NAN [65] of 25.1) and on par with best top-down parsers [24, 57]. On
DensePose-COCO [1] and PASCAL-Person-Part [53], our model also produces compelling performance. Overall, our model shows favorable results with a fast speed. 2.