Abstract
We propose a framework for early action recognition and anticipation by correlating past features with the future us-ing three novel similarity measures called Jaccard vector similarity, Jaccard cross-correlation and Jaccard Frobenius inner product over covariances. Using these combinations of novel losses and using our framework, we obtain state-of-the-art results for early action recognition in UCF101 and
JHMDB datasets by obtaining 91.7 % and 83.5 % accu-racy respectively for an observation percentage of 20. Sim-ilarly, we obtain state-of-the-art results for Epic-Kitchen55 and Breakfast datasets for action anticipation by obtaining 20.35 and 41.8 top-1 accuracy respectively. 1.

Introduction
Action anticipation ability of humans is an evolution-ary gift that allows us to perform daily tasks effectively, efﬁciently and safely. This phenomena is known as men-tal time travel [30]. Even if humans are good at predict-ing the immediate future, how this happens internally in-side our brain remains a mystery.
In an era where Ar-tiﬁcial Intelligence is growing, human action anticipation has naturally become an important problem in Computer
Vision. Various forms of action prediction problems have been studied in the literature such as early action recogni-tion [5, 15, 17, 18, 25, 26, 28, 36], anticipation [4, 20, 23] and activity forecasting [1, 14, 22]. The objective of Early
Action Recognition [17] (EAR) (also known as action pre-diction) is to classify a given video from a partial obser-vation of the action. In this case, the observed video and the full video contain the same action and methods observe about 10%-50% of the full video to recognize the action.
In contrast, Action Anticipation (AA) methods [4, 20] aim at predicting a future action δt seconds before the future action starts and the observed video contains an action dif-ferent from the future action. In both cases, models observe the ﬁrst part of the video and predict the ongoing action or the future action.
Humans have the natural ability to correlate past experi-ences with what might happen in the future. For example, when we see someone walking toward the door inside a cor-ridor, we can say that person will open the door with a high conﬁdence. Perhaps the action of walking towards the door correlates with the future action of ”opening the door” with a high probability and humans may learn these associations from a very young age. In this paper, we propose to solve the problem of action anticipation and early prediction by correlating past features with the future. To do this, we pro-pose a new framework and three novel loss functions.
Our framework maximizes the correlation between ob-served and the future video representations. By doing so, at train time our model learns to encapsulate future action in-formation given the observed video. At test time our model exploits this correlation to infer future temporal information and makes accurate action predictions. Similar ideas have been explored before in the literature. However, what re-mains unclear is at what abstraction one should exploit this correlation between the future and past? We argue it is bet-ter to exploit this correlation at the higher levels of the video representation and also at class level. The second question is how to maximize this correlation at higher levels of the video representation?
In this paper, we show that commonly used techniques such as minimizing the L2 distance or maximizing the vector correlation or the cosine similarity between future and observed video representations is not ideal. Although conceptually the vector correlation makes sense, it is not bounded. The cosine vector similarity seems a relevant choice for this problem. However, when used for deep rep-resentation learning, there are limitations to cosine similar-ity. We discuss these limitations in detail in section 3.3.1.
Brieﬂy, the cosine similarity between a vector z and kz (where k is a scalar) is always 1.0 (or -1.0) irrespective of the value of k. This property of cosine similarity could po-tentially hurt the learned representation. Ideally, a vector similarity measure should take into account both the mag-nitude and angle between vectors and the similarity should be bounded. Inspired by Jaccard Similarity overs sets, we propose Jaccard Vector Similarity (JVS) which has good properties when learning representations by maximizing the 13224
vector similarities.
Furthermore, we show that Jaccard similarity can be ex-tended to not only vectors, but also for matrices. Specif-ically, in this paper we extend Frobenius Inner Product (FIP) to work with covariance matrices and propose a new similarity measure called Jaccard Frobenius Inner Product (JFIP). We extract the covariance matrix of the observed and future videos and make the observed covariance matrix con-tains information about the future by maximizing JFIP be-tween them. Unlike FIP over covariance matrices, the JFIP similarity is bounded between -1 and 1 and smooth over the space of covariance matrices. We also propose to ex-ploit cross-correlations between observed and future video representations and propose a new similarity measure based on Jaccard similarity over cross-correlations called Jaccard cross-correlation (JCC). By exploiting bounded similarity measures such as JVS, JFIP and JCC, we correlate past with the future for action anticipation and early recognition us-ing a common framework. We use slightly different archi-tectures for EAR and AA problems. We show the beneﬁt of
Jaccard similarity measures to learn video representations suitable for future prediction tasks in an end-to-end man-ner. In a summary, our contributions are as follows: (1) We propose a common framework for action antici-pation and early action recognition by exploiting the corre-lations between observed and future video representations.
We show some limitations of cosine similarity when used for deep representation learning and propose a novel sim-ilarity measure called Jaccard Vector Similarity. We ex-perimentally show that JVS is better than cosine similar-ity, vector correlation, and L2 loss for the task of correlat-ing past features with the future for action anticipation and early action recognition. (2) We further extend the Jaccard
Similarity for covariance matrices and cross-correlation.
We propose two novel similarity measures called Jaccard-cross-correlation and Jaccard Frobenius Inner Product over covariance matrices which performs better than standard cross-correlation, Frobenius inner product, Frobenius norm over covariance matrices, and Bregman divergence. We show the impact of these novel loss functions for action an-ticipation and early prediction on four standard datasets. 2.