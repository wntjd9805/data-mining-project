Abstract
Action recognition has been heavily employed in many applications such as autonomous vehicles, surveillance, etc, where its robustness is a primary concern. In this paper, we examine the robustness of state-of-the-art action recog-nizers against adversarial attack, which has been rarely in-vestigated so far. To this end, we propose a new method to attack action recognizers which rely on the 3D skeletal motion. Our method involves an innovative perceptual loss which ensures the imperceptibility of the attack. Empiri-cal studies demonstrate that our method is effective in both white-box and black-box scenarios. Its generalizability is evidenced on a variety of action recognizers and datasets.
Its versatility is shown in different attacking strategies. Its deceitfulness is proven in extensive perceptual studies. Our method shows that adversarial attack on 3D skeletal mo-tions, one type of time-series data, is signiﬁcantly different from traditional adversarial attack problems.
Its success raises serious concern on the robustness of action recogniz-ers and provides insights on potential improvements. 1.

Introduction
The research in adversarial attack has proven that deep learning is vulnerable to certain imperceptible perturbation on data, leading to security and safety concerns [36]; mean-while, adversarial attack has been useful in improving the robustness of classiﬁers [20]. Starting from object recogni-tion, the list of target tasks for adversarial attack has been rapidly expanding, now including face recognition [32], point clouds [45], 3D meshes [47], etc. While adversar-ial attack on static data (images, geometries, etc.) has been well explored, its effectiveness on time-series has only been attempted under a few settings such as videos [14, 43]. In this paper, we look into another type of time-series data: 3D
∗https://youtu.be/DeMkN3efp9s
†Corresponding author skeletal motion, for action recognition tasks.
Skeletal motion has been widely used in action recog-nition [7]. It can greatly improve the recognition accuracy by mitigating issues such as lighting, occlusion and posture ambiguity. In this paper, we show that 3D skeletal motions are vulnerable to adversarial attack but their vulnerability is different from other data. The adversarial attack on 3D skeletal motion faces two unique and related challenges: low redundancy and perceptual sensitivity. When attacking images/videos, it is possible to perturb some pixels without causing too much visual distortion. This largely depends on the redundancy in the image space [37]. Unlike images, which have thousands of Degrees of Freedom (DoFs), a skeletal motion is usually parameterized by fewer than 100
DoFs, i.e. the joints of the skeleton. This not only restricts the space of possible attacks [37], but also affects the imper-ceptibility of the adversarial samples: a small perturbation on a single joint can be easily noticed. Furthermore, coordi-nated perturbations on multiple joints in only one frame can hardly work either, because in the temporal domain, simi-lar constraints apply. Any sparsity-based perturbation (on single joints or individual frames) will greatly affect the dy-namics (causing jittering or bone-length violations) and will be very obvious to an observer. One consequence is that the perturbation magnitude alone is not anymore a reliable met-ric to judge the imperceptibility of an attack, as an overall small perturbation could still break the dynamics. This is very different from existing attack tasks where the pertur-bation magnitude can be heavily relied upon.
To systematically investigate the robustness of action recognizers, we propose a straightforward yet very effec-tive method, Skeletal Motion Action Recognition Attack (SMART), based on an optimization framework that explic-itly considers motion dynamics and skeletal structures. The optimization ﬁnds perturbations by balancing between clas-siﬁcation goals and perceptual distortions, formulated as classiﬁcation loss and perceptual loss. Varying the classi-ﬁcation loss leads to different attacking strategies. The new perceptual loss fully utilizes the dynamics of the motions 14656
and bone structures. SMART is effective in both white-box and black-box settings, on several state-of-the-art models, across a variety of datasets.
Formally, we systematically investigate the vulnerabil-ity of a wide range of state-of-the-art methods under ad-versarial attack and identify their weaknesses for potential improvements. To this end, we propose a new adversarial attack method with a novel perceptual loss function captur-ing the perceptual realism and fully exploiting the motion dynamics. We also provide insights into the role of dynam-ics in the imperceptibility of the adversarial attack based on comprehensive perceptual studies, showing that it is not enough to only constrain the perturbation magnitude, which differs signiﬁcantly from widely accepted approaches. 2.