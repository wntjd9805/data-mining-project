Abstract
Many recent 6D pose estimation methods exploited ob-ject 3D models to generate synthetic images for training because labels come for free. However, due to the domain shift of data distributions between real images and synthetic images, the network trained only on synthetic images fails to capture robust features in real images for 6D pose es-timation. We propose to solve this problem by making the network insensitive to different domains, rather than tak-ing the more difﬁcult route of forcing synthetic images to be similar to real images.
Inspired by domain adaption methods, a Domain Adaptive Keypoints Detection Network (DAKDN) including a domain adaption layer is used to minimize the discrepancy of deep features between synthetic and real images. A unique challenge here is the lack of ground truth labels (i.e., keypoints) for real images. Fortu-nately, the geometry relations between keypoints are invari-ant under real/synthetic domains. Hence, we propose to use the domain-invariant geometry structure among keypoints as a “bridge” constraint to optimize DAKDN for 6D pose estimation across domains. Speciﬁcally, DAKDN employs a
Graph Convolutional Network (GCN) block to learn the ge-ometry structure from synthetic images and uses the GCN to guide the training for real images. The 6D poses of objects are calculated using Perspective-n-Point (PnP) algorithm based on the predicted keypoints. Experiments show that our method outperforms state-of-the-art approaches with-out manual poses labels and competes with approaches us-ing manual poses labels. 1.

Introduction
Detecting 3D objects and estimating their 6D poses is an important task in many computer vision applications e.g., augmented reality, robotics, machine vision. Recently, deep learning approaches [13, 39, 4, 29, 34, 10, 26, 24, 25, 18, 3] have shown impressive results of pose estimation in RGB
*Corresponding author images. However, they require a large amount of manual labels including the 2D keypoints, masks, 6D poses of ob-jects, and other extra labels, which are usually very costly.
Therefore, some works [33, 12, 41, 36] have tried to train on synthetic images rendered from the 3D models of objects, yielding a great data source with pose labels free of charge. However, there is signiﬁcant discrepancy (e.g., appearance, illumination conditions) between 3D models and real objects. This discrepancy between synthetic and real images is called domain shift. Directly training a net-work using only the source domain data (i.e., synthetic im-ages) fails to capture robust features in the target domain data (i.e., real images), causing reduced performance for 6D pose estimation. To improve the performance on real images, AAE [33] and DPOD [41] apply additional aug-mentations including rendering images in various lighting conditions and backgrounds with image noise to simulate real environments. Unfortunately, data augmentation is usu-ally unable to reproduce the statistics produced by real-world counterparts. Self6D [36] utilizes predicted masks on real images to get domain-independent properties as con-straints to reﬁne the pose estimated by the network trained on physically-based renderings. Although the physically-based rendering can generate high-quality synthetic images to simulate real environments, the domain gap in mask pre-diction still exists and may limit the performance of pose reﬁnement.
To overcome the domain shift, some transfer learning methods [35, 19, 17] add unlabeled target data into the train-ing process. Besides training the model on source domain data, these methods minimize the distance of features dis-tribution between the source and target domain data by di-rectly optimizing a representation generated by an adaption layer to accomplish domain transfer. However, due to the high complexity of the predicted information of 6D pose estimation task, the performance of directly using unlabeled target data for learning 6D pose estimation cross domains is still far from satisfactory.
In this paper, we aim to address this cross-domain ob-Inspired by the above ject 6D pose estimation problem. 11065
domain transfer works, we also aim to learn domain invari-ant features. Nevertheless, the key novelty of our work lies in trying to address the lack-of-label problem for the 6D pose estimation task on the target domain. To this end, we propose a keypoint-graph-driven learning framework that combines domain transfer and task optimation for object 6D pose estimation across domains. Speciﬁcally, a Domain
Adaptive Keypoints Detection Network (DAKDN) is used to predict 2D keypoints of the object across domains. The 6D pose of the object can be computed using the predicted 2D keypoints by Perspective-n-Point(PnP) algorithm [16].
To make DAKDN learn the robust features that are domain invariant and suitable for keypoint detection, we use both synthetic images and unlabeled real images for training and embed an adaptation layer into the network along with a domain alignment loss based on maximum mean discrep-ancy (MMD) [35]. To improve the correctness of keypoint detection on real images, we explicitly transfer a domain-invariant structure amongst keypoints from synthetic im-ages to real images as a “bridge” constraint to optimize
DAKDN for 6D pose estimation across domains. Geome-try relations between keypoints are irrelevant to real images or synthetic images which is a domain-invariant structure.
Therefore, we represent the geometry relations as graphs and train a graph convolutional network (GCN) [14] block to model the structure of object keypoints from synthetic images. Then the structure is transferred to the real images as a constraint to guide DAKDN to correctly detect key-points in real images. By jointly optimizing for domain in-variance and structure prediction, the domain invariant fea-tures can improve the accuracy of the GCN structure pre-diction, and the GCN in turn guides the network to extract suitable keypoint feature on the real image for pose estima-tion. Experiments show that our method can achieve bet-ter results than state-of-the-art approaches without manual poses labels and competes with approaches that require real manual poses labels images. 2.