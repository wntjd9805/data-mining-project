Abstract
We present a new method, called MEsh TRansfOrmer (METRO), to reconstruct 3D human pose and mesh ver-tices from a single image. Our method uses a transformer encoder to jointly model vertex-vertex and vertex-joint in-teractions, and outputs 3D joint coordinates and mesh ver-tices simultaneously. Compared to existing techniques that regress pose and shape parameters, METRO does not rely on any parametric mesh models like SMPL, thus it can be easily extended to other objects such as hands. We fur-ther relax the mesh topology and allow the transformer self-attention mechanism to freely attend between any two vertices, making it possible to learn non-local relationships among mesh vertices and joints. With the proposed masked vertex modeling, our method is more robust and effective in handling challenging situations like partial occlusions.
METRO generates new state-of-the-art results for human mesh reconstruction on the public Human3.6M and 3DPW datasets. Moreover, we demonstrate the generalizability of
METRO to 3D hand reconstruction in the wild, outperform-ing existing state-of-the-art methods on FreiHAND dataset. 1.

Introduction 3D human pose and mesh reconstruction from a single image has attracted a lot of attention because it has many applications including virtual reality, sports motion analy-sis, neurodegenerative condition diagnosis, etc. It is a chal-lenging problem due to complex articulated motion and oc-clusions.
Recent work in this area can be roughly divided into two categories. Methods in the ﬁrst category use a parametric model like SMPL [24] and learn to predict shape and pose coefﬁcients [12, 21, 34, 17, 19, 29, 39, 18]. Great success has been achieved with this approach. The strong prior en-coded in the parametric model increases its robustness to environment variations. A drawback of this approach is that the pose and shape spaces are constrained by the limited ex-emplars that are used to construct the parametric model. To overcome this limitation, methods in the second category do (a) (b) (c)
Figure 1: METRO learns non-local interactions among body joints and mesh vertices for human mesh reconstruc-tion. Given an input image in (a), METRO predicts hu-man mesh by taking non-local interactions into consider-ation. (b) illustrates the attentions between the occluded wrist joint and the mesh vertices where brighter color indi-cates stronger attention. (c) is the reconstructed mesh. not use any parametric models [20, 7, 27]. These methods either use a graph convolutional neural network to model neighborhood vertex-vertex interactions [20, 7], or use 1D heatmap to regress vertex coordinates [27]. One limitation with these approaches is that they are not efﬁcient in mod-eling non-local vertex-vertex interactions.
Researchers have shown that there are strong correla-tions between non-local vertices which may belong to dif-ferent parts of the body (e.g. hand and foot) [50].
In computer graphics and robotics, inverse kinematics tech-niques [2] have been developed to estimate the internal joint positions of an articulated ﬁgure given the position of an end effector such as a hand tip. We believe that learning the correlations among body joints and mesh vertices in-cluding both short range and long range ones is valuable for handling challenging poses and occlusions in body shape reconstruction. In this paper, we propose a simple yet effec-tive framework to model global vertex-vertex interactions.
The main ingredient of our framework is a transformer.
Recent studies show that transformer [48] signiﬁcantly improves the performance on various tasks in natural lan-guage processing [3, 8, 35, 36]. The success is mainly at-tributed to the self-attention mechanism of a transformer, 1954
which is particularly effective in modeling the dependen-cies (or interactions) without regard to their distance in both inputs and outputs. Given the dependencies, transformer is able to soft-search the relevant tokens and performs predic-tion based on the important features [3, 48].
In this work, we propose METRO, a multi-layer Trans-former encoder with progressive dimensionality reduction, to reconstruct 3D body joints and mesh vertices from a given input image, simultaneously. We design the Masked
Vertex Modeling objective with a transformer encoder ar-chitecture to enhance the interactions among joints and ver-tices. As shown in Figure 1, METRO learns to discover both short- and long-range interactions among body joints and mesh vertices, which helps to better reconstruct the 3D hu-man body shape with large pose variations and occlusions.
Experimental results on multiple public datasets demon-strate that METRO is effective in learning vertex-vertex and vertex-joint interactions, and consequently outperforms the prior works on human mesh reconstruction by a large mar-gin. To the best of our knowledge, METRO is the ﬁrst ap-proach that leverages a transformer encoder architecture to jointly learn 3D human pose and mesh reconstruction from a single input image. Moreover, METRO is a general frame-work which can be easily applied to predict a different 3D mesh, for example, to reconstruct a 3D hand from an input image.
In summary, we make the following contributions.
• We introduce a new transformer-based method, named
METRO, for 3D human pose and mesh reconstruction from a single image.
• We design the Masked Vertex Modeling objective with a multi-layer transformer encoder to model both vertex-vertex and vertex-joint interactions for better re-construction.
• METRO achieves new state-of-the-art performance on the large-scale benchmark Human3.6M and the chal-lenging 3DPW dataset.
• METRO is a versatile framework that can be easily re-alized to predict a different type of 3D mesh, such as 3D hand as demonstrated in the experiments. METRO achieves the ﬁrst place on FreiHAND leaderboard at the time of paper submission. 2.