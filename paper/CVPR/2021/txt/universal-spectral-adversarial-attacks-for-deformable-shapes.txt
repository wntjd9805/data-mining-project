Abstract horse horse
Machine learning models are known to be vulnerable to adversarial attacks, namely perturbations of the data that lead to wrong predictions despite being imperceptible.
However, the existence of “universal” attacks (i.e., unique perturbations that transfer across different data points) has only been demonstrated for images to date. Part of the rea-son lies in the lack of a common domain, for geometric data such as graphs, meshes, and point clouds, where a univer-sal perturbation can be deﬁned. In this paper, we offer a change in perspective and demonstrate the existence of uni-versal attacks for geometric data (shapes). We introduce a computational procedure that operates entirely in the spec-tral domain, where the attacks take the form of small pertur-bations to short eigenvalue sequences; the resulting geom-etry is then synthesized via shape-from-spectrum recovery.
Our attacks are universal, in that they transfer across dif-ferent shapes, different representations (meshes and point clouds), and generalize to previously unseen data. 1.

Introduction
. . .
. . .
+
=
+0.02 0
−0.02
+
=
. . . cow
. . . dog horse
+
= bigcat
Figure 1: Universal spectral attacks on 3D horses from the
SMAL dataset (only 3 out of 10 shapes are visualized). Top row: Original shapes with their ﬁrst ten Laplacian eigen-values and the correct labels predicted by a state-of-the-art classiﬁer. The shapes undergo pose deformations, and have different scale, orientation and location in 3D space. Middle row: A universal perturbation is applied to the eigenvalues.
Bottom row: The resulting shape embeddings synthesized from the perturbed spectra, which are now assigned wrong labels by the classiﬁer.
As machine learning methods become more and more pervasive, so their vulnerabilities are becoming more ex-posed. In recent years, it has been extensively shown that classiﬁers are susceptible to so-called adversarial attacks, i.e., misclassiﬁcations induced by feeding carefully per-turbed data (adversarial examples) into the trained model.
Adversarial examples can be crafted for image, graph, point cloud, and mesh data, as demonstrated by a thriving stream of research output across the computer vision, geometry processing, and machine learning communities.
Remarkably, universal perturbations are also known to exist for image data. For a given classiﬁer C acting on im-ages of size w × h, a universal perturbation P ∈ Rw×h is such that C(I + P ) 6= C(I) for a large number of images
I; crucially, P is small under some norm kP k so that it is hard to perceive, and is ﬁxed for all such images. In other words, P is image-agnostic to some extent. This deﬁnition of universal perturbations is made possible by the fact that the operation I + P can be invariably deﬁned for all possi-ble I and P , since all w × h images share the same grid of 2D coordinates. As soon as one shifts the focus from im-ages to geometric data, the existence of a common space is no longer guaranteed; each individual graph G is a differ-ent domain in and by itself, and an operation of the form
“G + P ” can only be deﬁned if G and P share the same topology. Therefore, if universality is desired, one has to deﬁne a way to transfer the perturbation P across different graphs, while at the same time ensuring it induces misclas-3216
siﬁcation in all cases.
In this paper, we introduce a new paradigm for universal adversarial attacks on geometric data (speciﬁcally, meshes and point clouds), in which the perturbation transfer is car-ried out implicitly. We do so by identifying a common do-main as the space of (truncated) Laplacian spectra. This space is compact, since it only consists of short sequences of eigenvalues; it is invariant to isometric deformations (e.g., changes in pose); it only loosely depends on resolution and connectivity of the source geometry; and it is easy and efﬁcient to compute for any given geometric object. Once a universal perturbation is computed in this space, the in-dividual adversarial examples are recovered via a synthesis process that goes from eigenvalues to 3D coordinates. 2.