Abstract
Compositional Zero-Shot learning (CZSL) requires to recognize state-object compositions unseen during training.
In this work, instead of assuming prior knowledge about the unseen compositions, we operate in the open world setting, where the search space includes a large number of unseen compositions some of which might be unfeasible. In this set-ting, we start from the cosine similarity between visual fea-tures and compositional embeddings. After estimating the feasibility score of each composition, we use these scores to either directly mask the output space or as a margin for the cosine similarity between visual features and compo-sitional embeddings during training. Our experiments on two standard CZSL benchmarks show that all the meth-ods suffer severe performance degradation when applied in the open world setting. While our simple CZSL model achieves state-of-the-art performances in the closed world scenario, our feasibility scores boost the performance of our approach in the open world setting, clearly outper-forming the previous state of the art. Code is available at: https://github.com/ExplainableML/czsl. 1.

Introduction
The appearance of an object in the visual world is deter-mined by its state. A pureed tomato looks different from a wet tomato despite the shared object, and a wet tomato looks different from a wet dog despite the shared state. In Com-positional Zero-Shot Learning (CZSL) [20, 21, 27, 17] the goal is to learn a set of states and objects while generalizing to unseen compositions.
Current benchmarks in CZSL study this problem in a closed space, assuming the knowledge of unseen compo-sitions that might arise at test time. For example, the widely adopted MIT states dataset [13] contains 28175 possible compositions (in total 115 states and 245 objects), but the test time search space is limited to 1662 compositions (1262 seen and 400 unseen), covering less than 6% of the whole compositional space. This restriction on the output space is a fundamental limitation of current CZSL methods. 1First and second author contributed equally.
Figure 1. In closed world CZSL, the search space is assumed to be known a priori, i.e. seen (yellow) and unseen (purple) composi-tions are available during training/test. In our open world scenario, no limit on the search space is imposed. Hence, the model has to
ﬁgure out implausible compositions (pink) and discard them.
In this work, we propose the more realistic Open World
CZSL (OW-CZSL) task (see Figure 1), where we impose no constraint on the test time search space, causing the current state-of-the-art approaches to suffer severe perfor-mance degradation. To tackle this new task, we propose
Compositional Cosine Logits (CompCos), a model where we embed both images and compositional representations into a shared embedding space and compute scores for each composition with the cosine similarity. Moreover, we treat less feasible compositions (e.g. ripe dog) as distractors that a model needs to eliminate. For this purpose, we use simi-larities among primitives to assign a feasibility score to each unseen composition. We then use these scores as margins in a cross-entropy loss, showing how the feasibility scores enforce a shared embedding space where unfeasible distrac-tors are discarded, while visual and compositional domains are aligned. Despite its simplicity, our model surpasses the previous state-of-the-art methods on the standard CZSL benchmark as well as in the challenging OW-CZSL task.
Our contributions are as follows: (1) A novel problem formulation, Open World Compositional Zero-Shot learn-ing (OW-CZSL) with the most ﬂexible search space in terms of seen/unseen compositions; (2) CompCos, a novel model to solve the OW-CZSL task based on cosine logits and a 5222
projection of learned primitive embeddings with an inte-grated feasibility estimation mechanism; (3) A signiﬁcantly improved state-of-the-art performance on MIT states [13] and UT Zappos [34, 35] both on the existing benchmarks and the newly proposed OW-CZSL setting. 2.