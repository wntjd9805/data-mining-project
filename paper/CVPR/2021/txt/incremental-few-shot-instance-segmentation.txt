Abstract
Training: compute novel class representatives
Few-shot instance segmentation methods are promising when labeled training data for novel classes is scarce. How-ever, current approaches do not facilitate ﬂexible addition of novel classes. They also require that examples of each class are provided at train and test time, which is memory inten-sive. In this paper, we address these limitations by present-ing the ﬁrst incremental approach to few-shot instance seg-mentation: iMTFA. We learn discriminative embeddings for object instances that are merged into class representatives.
Storing embedding vectors rather than images effectively solves the memory overhead problem. We match these class embeddings at the RoI-level using cosine similarity. This allows us to add new classes without the need for further training or access to previous training data. In a series of experiments, we consistently outperform the current state-of-the-art. Moreover, the reduced memory requirements al-low us to evaluate, for the ﬁrst time, few-shot instance seg-mentation performance on all classes in COCO jointly1. 1.

Introduction
Convolutional neural networks (CNNs) have led to state-of-the-art results for image classiﬁcation [16, 32], object de-tection [28] and instance segmentation [11]. In general, per-formance increases with network depth and training set size.
While we can usually rely on large annotated databases for more general classes, adding a class for which we have lit-tle training data available is challenging. For example, we typically have a modest number of labeled training images when adding new classes for state-speciﬁc street furniture for self-driving cars, or types of weapons for automated de-tection in social media videos. Especially for instance seg-mentation, obtaining pixel-level annotations is costly.
Few-shot learning addresses the problem of learning with limited available data. Typically, one assumes the ex-istence of a set of base classes, for which there exist nu-merous training samples, and a disjoint set of novel classes, 1Code available at: https://github.com/danganea/iMTFA
K s h o t s
K s h o t s
Instance
Feature
Extractor
Instance
Feature
Extractor
Cosine-similarity classifier
Weights
Novel
Base
RoI Align
RoI
Feature
Extractor
Testing: inference
Class-agnostic
Mask head
Class-agnostic
Box regressor
Figure 1. Incremental few-shot instance segmentation. For all
K instances of each novel class, we produce vector embeddings using an Instance Feature Extractor. The average of these em-beddings is stored as a per-class weight vector inside a cosine-similarity classiﬁer. At test time (green), we compare the cosine distance embeddings of object proposal to the per-class weights. for which training data is scarce (K examples). The goal is to train a system to correctly classify N classes: only the novel classes, or both novel and base classes jointly.
Compared to few-shot image classiﬁcation, few-shot ob-ject detection (FSOD) and few-shot instance segmentation (FSIS) have received signiﬁcantly less attention. While the few solutions that have been introduced show great promise, there is room for improvement in terms of practicality and accuracy. Often, long training procedures with both novel and base class samples are required [13, 36, 39]. This is unpractical when we ﬂexibly want to add novel classes to a trained network. In incremental few-shot learning, the ad-dition of novel classes is independent from previous data, so computation time is reduced.
In this paper, we introduce the ﬁrst incremental few-shot instance segmentation method: iMTFA (Figure 1). We em-ploy a two-stage training and ﬁne-tuning approach based on
Mask R-CNN [11]. The ﬁrst stage trains the Mask R-CNN
In the second stage, the fully-connected layers network. 1185    
at the region of interest (RoI) level are re-purposed. Es-sentially, we transform a ﬁxed feature extractor into an In-stance Feature Extractor (IFE) that produces discriminative embeddings that are aligned with the per-class representa-tives. These embeddings are subsequently used as weights inside a cosine-similarity classiﬁer.
Our approach has several advantages. First, it eliminates the need for extensive retraining procedures for new classes because these can be added incrementally. The IFE gener-ates embeddings that are used as class representatives with-out requiring access to base classes. Because we predict localization and segmentation in a class-agnostic manner, these embeddings are all that is needed to add novel classes.
Second, in contrast with related methods [8, 39], our mask predictor is class-agnostic. Similar to [21], no mask labels are needed for the addition of novel classes.
Third, our approach incurs no performance drawbacks at test time. We neither require additional memory for ev-ery class example [8, 39] nor require these examples to be passed one-by-one (e.g., [21]).
We make two main contributions:
• We present the ﬁrst incremental few-shot instance seg-mentation method: iMTFA. Our method outperforms the current state-of-the-art for FSIS as well as the cur-rent state-of-the-art in incremental FSOD.
• To compare between incremental and non-incremental methods, we extend an existing FSOD approach [36] to the instance segmentation task (MTFA), and also demonstrate state-of-the-art results.
The remainder of the paper is structured as follows. We
ﬁrst discuss related work on few-shot learning and instance segmentation. We introduce our novel incremental and non-incremental methods in Section 3, and evaluate both exten-sively in Section 4. We conclude in Section 5. 2.