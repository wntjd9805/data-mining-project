Abstract
We show that pre-trained Generative Adversarial Net-works (GANs), e.g., StyleGAN, can be used as a latent bank to improve the restoration quality of large-factor image super-resolution (SR). While most existing SR approaches attempt to generate realistic textures through learning with adversarial loss, our method, Generative LatEnt bANk (GLEAN), goes beyond existing practices by directly lever-aging rich and diverse priors encapsulated in a pre-trained
GAN. But unlike prevalent GAN inversion methods that re-quire expensive image-speciﬁc optimization at runtime, our approach only needs a single forward pass to generate the upscaled image. GLEAN can be easily incorporated in a simple encoder-bank-decoder architecture with multi-resolution skip connections. Switching the bank allows the method to deal with images from diverse categories, e.g., cat, building, human face, and car.
Images upscaled by
GLEAN show clear improvements in terms of ﬁdelity and texture faithfulness in comparison to existing methods as shown in Fig. 1. 1.

Introduction
In this study, we explore a new way to employ GAN [9] for image super-resolution. We are interested in the regime of high magniﬁcation factors (8× to 64×), which typical SR
∗Corresponding author methods fail to handle since most details and textures are lost during downsampling. Since the problem is severely underspeciﬁed, informative priors become inevitable in this setting, especially in restoring the textural details. Studying large-factor image SR is meaningful as it can potentially improve the state of the arts in SR, and more generally con-ditional generative models for images.
The notion of GAN has been extensively used in SR with the aim to enrich texture details in an upscaled image. There are two popular approaches to deploy GANs for this task.
The more common paradigm [21, 33, 32] trains a genera-tor to handle the upscaling task, where adversarial training is performed by using a discriminator to differentiate real images from the upscaled images produced by the genera-tor. Another possible way to exploit GAN for the task is by
GAN inversion [1, 11, 26, 27]. In this setting, one will need to ‘invert’ the generation process of a pre-trained GAN by mapping an image back to the latent space. A restored im-age can then be reconstructed from the optimal vector in the latent space.
While both methods are capable of generating more real-istic results than approaches that solely rely on ℓ2 loss, they have some inherent shortcomings. The ﬁrst paradigm typi-cally trains the SR generator from scratch using a combined objective function consisting of a ﬁdelity term and an adver-sarial loss. In this setting, the generator is responsible for both capturing the natural image characteristics and main-14245
taining the ﬁdelity to the ground-truth. This inevitably lim-its the capability of approximating the natural image mani-fold. As a result, these methods often produce artifacts and unnatural textures. As shown in Fig. 1, while ESRGAN [33] faithfully recovers the structures (e.g. pose, ear shape) of the cat, it struggles to produce realistic textures.
The second paradigm resolves the aforementioned prob-lem by making better use of the latent space of GAN through optimization. However, as the low-dimensional la-tent codes and the constraints in the image space are insuf-ﬁcient to guide the restoration process, these methods often generate images with low ﬁdelity. As shown in Fig. 1, de-spite being realistic, the output of a representative method,
PULSE [26], fails to recover the structures of the ground-truth faithfully. In addition, as the optimization is usually conducted in an iterative manner for each image at runtime, these approaches are often time-consuming.
In our approach, we leverage pre-trained GANs such as
StyleGAN [17] to provide rich and diverse priors for the task. Unlike most GAN inversion methods, which also use pre-trained GANs, our method does not involve image-speciﬁc optimization at runtime. Once trained, the model only needs a single forward pass to upscale an image, which is more practical for applications that demand fast response.
The idea is partially inspired by the classic notion of dic-tionary [38]. But unlike conventional approaches that con-struct a ﬁnite and imagery-derived dictionary, we exploit
GAN as a more effective way for storing priors.
Conditioning and retrieving from a GAN-based dictio-nary is a new and non-trivial question we need to address in this work. We show that pre-trained GANs can be em-ployed as a latent bank in a succinct encoder-bank-decoder architecture. This novel architecture allows us to lift the burden of learning both ﬁdelity and texture generation si-multaneously in a typical encoder-decoder network since the latent bank already captures rich texture priors. In ad-dition, we show that it is pivotal to condition the bank by passing both the latent vectors and multi-resolution convo-lutional features from the encoder to achieve high-ﬁdelity results. Symmetrically, multi-resolution cues need to be passed from the bank to the decoder. We show the effec-tiveness of the proposed method in handling images with challenging poses and structures apart from the large mag-niﬁcation factor. We also demonstrate how the method can be generalized to different categories, e.g., human faces, cats, buildings, by switching different pre-trained GAN la-tent banks. 2.