Abstract 1.

Introduction
Neural Style Transfer (NST) has quickly evolved from single-style to inﬁnite-style models, also known as Arbi-trary Style Transfer (AST). Although appealing results have been widely reported in literature, our empirical studies on four well-known AST approaches (GoogleMagenta [14],
AdaIN [19], LinearTransfer [29], and SANet [37]) show that more than 50% of the time, AST stylized images are not acceptable to human users, typically due to under- or over-stylization. We systematically study the cause of this imbalanced style transferability (IST ) and propose a sim-ple yet effective solution to mitigate this issue. Our stud-ies show that the IST issue is related to the conventional
AST style loss, and reveal that the root cause is the equal weightage of training samples irrespective of the proper-ties of their corresponding style images, which biases the model towards certain styles. Through investigation of the theoretical bounds of the AST style loss, we propose a new loss that largely overcomes IST . Theoretical analysis and experimental results validate the effectiveness of our loss, with over 80% relative improvement in style deception rate and 98% relatively higher preference in human evaluation.
*This work was completed during his internship at Amazon.
Neural style transfer (NST) refers to the generation of a pastiche image P from two images C and S via a neural network, where P shares the content with C but is in the style of S. While the original NST approach of Gatys [13] optimizes the transfer model for each pair of C and S, the
ﬁeld has rapidly evolved in recent years to develop models that support arbitrary styles out-of-the-box. NST models can, hence, be classiﬁed based on their stylization capacity into models trained for (1) a single combination of C and
S [13, 23, 28, 32, 39], (2) one S [21, 27, 47, 48], (3) multiple
ﬁxed S [2, 9, 24, 30, 42, 55], and (4) inﬁnite (arbitrary) S
[4, 14, 15, 17, 19, 20, 25, 29, 31, 37, 43, 44]. Intuitively, the category (4) of arbitrary style transfer (AST) is the most advantageous as it is agnostic to S, allowing trained models to be adopted for diverse novel styles without re-training.
Although superior in concept, current AST models are plagued by the issue of imbalanced style transferability (IST), where the stylization intensity of model outputs varies largely across styles S. More importantly, besides the nice results shown in previous works [14,19,29,37], a large number of stylized images suffer under-stylization (e.g., only the dominant color is transferred) or over-stylization (i.e., content is barely visible) for various S, making them 134
visually undesirable (see samples in Figure 1). This is vali-dated by our user-study described later in Section 3.2, with more than 50% of stylized images found to be unacceptable, irrespctive of the used AST model. Hence, we are still far from the AST goal — successfully transferring style from an arbitrary image to another. This urges us to systemati-cally study the underlying reasons for IST and ﬁnd potential solutions to further boost AST performance in order to gen-erate better stylized images for diverse styles.
In this paper, we make the following contributions.
Firstly, we systematically study the IST problem in AST and discover that the AST style loss is problematic as it fails to reﬂect human evaluation scores. Secondly, we investigate the AST style loss function, and locate the core reason for
IST to be the way sample-wise style loss is aggregated into a batch loss. Thirdly, we derive the theoretical expectation of a sample-wise style loss as well as its bounds, and use it to propose a new style loss that enables more balanced training across styles. Finally, we conduct extensive AST benchmarking experiments as well as human evaluation to validate the effectiveness of the proposed solution. Results show that IST issue is indeed greatly mitigated for all tested
AST approaches by incorporating the proposed style loss.
The rest of the paper is organized as follows. Section 2 brieﬂy reviews related AST works. Section 3 discusses two
AST style loss related studies and shows that IST is re-lated to the loss. Section 4 identiﬁes style-agnostic sam-ple weighting in training loss aggregation as the real cul-prit, derive our new style-aware loss, and validate its effec-tiveness by repeating the aforementioned two studies. Sec-tion 5 provides further results of application of the proposed loss to four well-known AST approaches and shows that the
IST issue is largely overcome for all the approaches. Fi-nally, Section 6 provides concluding remarks. 2.