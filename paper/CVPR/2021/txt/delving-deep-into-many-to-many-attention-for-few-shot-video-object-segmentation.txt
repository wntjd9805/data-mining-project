Abstract
Test video
First frame
Query video
This paper tackles the task of Few-Shot Video Object
Segmentation (FSVOS), i.e., segmenting objects in the query videos with certain class speciﬁed in a few labeled support images. The key is to model the relationship between the query videos and the support images for propagating the object information. This is a many-to-many problem and often relies on full-rank attention, which is computationally intensive. In this paper, we propose a novel Domain Agent
Network (DAN), breaking down the full-rank attention into two smaller ones. We consider one single frame of the query video as the domain agent, bridging between the support images and the query video. Our DAN allows a linear space and time complexity as opposed to the original quadratic form with no loss of performance. In addition, we introduce a learning strategy by combining meta-learning with on-line learning to further improve the segmentation accuracy.
We build a FSVOS benchmark on the Youtube-VIS dataset and conduct experiments to demonstrate that our method outperforms baselines on both computational cost and ac-curacy, achieving the state-of-the-art performance. Code is available at https://github.com/scutpaul/DANet. 1.

Introduction
With the number of online videos increasing rapidly,
Video Object Segmentation (VOS) attracts more and more attention as an important step to various video applications, such as video retrieval and editing [52]. Based on the user interaction, existing VOS algorithms have two common set-tings: unsupervised VOS and semi-supervised VOS. As shown in Fig. 1, unsupervised VOS [1, 17, 47, 13, 19, 23] directly segments primary objects in the videos without any human intervention. The objects often localize in salient
In contrast, semi-supervised VOS [2, 39, 5, 27] regions.
*Corresponding author (hesfe@scut.edu.cn). (a) Unsupervised VOS (b) Semi-supervised VOS
Support set
Query video (c) Few-shot VOS
Figure 1: Problem settings for different VOS tasks. (a)
Unsupervised VOS segments salient objects without guid-ance. (b) Semi-supervised VOS segments speciﬁed objects in a video given the segmentation mask for the ﬁrst frame. (c) Few-shot VOS segments objects across videos with the same category as objects in the labeled support set. gives the ground truth segmentation of the ﬁrst frame and propagates the labeled object information into subsequent frames. However, it requires pixel-level annotation of the
ﬁrst frame for each individual video, which limits the scal-ability for processing massive amount of videos. While in-teractive VOS [28, 11] further reduces the required human efforts to a few strokes, the provided information may be too coarse for cross-frame segmentation. To trade-off between 14040
semantics-aware segmentation and cross-video processing, recent studies [16, 32, 34] leverage new interactions such as natural languages and class labels.
In this paper, we target on Few-Shot Video Object Seg-mentation (FSVOS), which is still under explored. FSVOS aims to segment new object classes across query videos with only a few annotated support images (Fig. 1). The support images can be selected randomly outside the query videos. FSVOS is able to balance between semantics-aware segmentation and cross-video processing, meeting the de-mand of applications with surging online videos in real case.
The key to solving FSVOS is using labeled support im-ages for guiding the semantics-aware segmentation. Con-structing correlation among support images and query videos is a many-to-many problem. There are two major so-lutions in recent studies, as shown in Fig. 2. The prototype-based [7, 25, 50] methods convert it into a one-to-many problem by extracting a class prototype (i.e., a global de-scriptor) from the support images, which inevitably loses structural information of the support images. The attention-based [40, 55, 27, 43] methods fully utilize the labeled sup-port images and learn a many-to-many attention between every support-query image pairs. However, the computa-tional complexity grows exponentially as the number of in-put images grows.
After delving deep into many-to-many attention, we ﬁnd that the attention can be decomposed to reduce compu-tational cost and thus introduce the following hypothesis.
Given a query q and a pair of key-value k-v, we obtain the attention feature vA using the typical attention function: vA = Attention(q, k, v) = Av = σ( q(k)T
√Ck
)v, (1) where A is the attention matrix, and σ is a softmax opera-tion. A scale factor of is to maintain the stability of the numerical scale. 1
√Ck
Attention Decomposition Hypothesis. We hypothesize that the original attention matrix can be replaced with a product of two smaller attention matrices through an agent t. The new attention matrix ˆA is expressed as:
ˆA = AqtAtk, (2) where Aqt is the attention between the query q and the agent t, and Atk is the attention between the agent t and the key k, deﬁned as:
Aqt = σ( q(kt)T
√Ck
); Atk = σ( qt(k)T
√Ck
). (3)
A global descriptor
Domain agent
Prototype-based
Attention-based
Our DAN
Figure 2: Different solutions for solving many-to-many problem. Orange circles represent the support images, and blue circles represent the query frames. The prototype-based methods covert it into a one-to-many problem by ex-tracting a global descriptor from the support images. The attention-based methods use a full-rank attention to learn many-to-many mapping. Our Domain Agent Attention de-composes the full-rank attention using a domain agent. the agent for this video domain. Our method is possible to convert the previous exponential growth of computational complexity into a linear one. Due to the addition of invisible channel attention to enhance the query features, our atten-tion module shows better results than the full-rank attention in both theoretical and practical analyses.
Furthermore, we propose a learning strategy for FSVOS by combining meta-learning with online learning. We use meta-learning in the training phase to learn generic object segmentation across categories. While in the testing phase, we use online learning to update the feature representation for the unseen category. We construct a new benchmark for
FSVOS based on the Youtube-VIS dataset. We demonstrate the feasibility of our method through ablation studies and compare its performance with several few-shot semantic segmentation methods. Experimental results show that our proposed method outperforms existing methods in terms of both segmentation accuracy and computational cost.
The main contributions of this work are fourfold.
• We delve into the conventional many-to-many atten-tion and prove that the original attention matrix can be replaced by the product of two smaller attention matri-ces bridged by an agent.
• We work on an under-explored task called few-shot video object segmentation, and propose a novel do-main agent network based on theoretical support, bal-ancing the accuracy, computational burden, and speed.
• We present a learning strategy that combines meta-learning and online learning to improve the general-ization ability of segmentation and category-speciﬁc feature representations.
We provide a theoretical support for the above hypoth-esis, and propose a novel Domain Agent Network (DAN) accordingly. We treat a single frame of the query video as
• We build up the ﬁst FSVOS benchmark and compare our model with existing methods to show its efﬁciency over both accuracy and the computational cost. 14041
2.