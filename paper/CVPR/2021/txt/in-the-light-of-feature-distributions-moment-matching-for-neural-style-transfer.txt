Abstract
Style transfer aims to render the content of a given image in the graphical/artistic style of another image. The funda-mental concept underlying Neural Style Transfer (NST) is to interpret style as a distribution in the feature space of a
Convolutional Neural Network, such that a desired style can be achieved by matching its feature distribution. We show that most current implementations of that concept have im-portant theoretical and practical limitations, as they only partially align the feature distributions. We propose a novel approach that matches the distributions more precisely, thus reproducing the desired style more faithfully, while still be-ing computationally efﬁcient. Speciﬁcally, we adapt the dual form of Central Moment Discrepancy (CMD), as re-cently proposed for domain adaptation, to minimize the dif-ference between the target style and the feature distribution of the output image. The dual interpretation of this met-ric explicitly matches all higher-order centralized moments and is therefore a natural extension of existing NST methods that only take into account the ﬁrst and second moments.
Our experiments conﬁrm that the strong theoretical proper-ties also translate to visually better style transfer, and better disentangle style from semantic image content. 1.

Introduction
In 2017 Loving Vincent was released, painted feature ﬁlm with >65,000 frames. the ﬁrst fully
Indeed, every single frame is an oil painting drawn by one of over 100 artists. The creation of the movie was split into two steps.
First, the entire movie was produced with real actors in front of a green screen, which was then replaced by Van Gogh paintings. In a second step, each frame was painted over by an artist with the techniques and style of Van Gogh, which took over six years to complete.
Attempts to automate this form of texture synthesis, termed style transfer, date back to at least the mid-90s [12].
More recently, Gatys et al. [9] pioneered the idea of Neu-ral Style Transfer (NST).
It is based on the idea that the deep layers of a pre-trained Convolutional Neural Network (CNN) encode high-level semantic information and are in-sensitive to the actual appearance, whereas shallow layers learn low-level features such as color, texture and brush pat-terns. A fundamental question that arises in this context is how to deﬁne style. Li et al. [25] proved that the loss intro-duced in [9] can be rewritten as a Maximum Mean Discrep-ancy (MMD), offering an interpretation of style transfer as aligning feature distributions. In fact, most existing meth-ods can be interpreted in this way. This has led to a series of works all centered around aligning feature distributions of
CNNs, linking style transfer to Domain Adaptation (DA).
Here we look deeper into that interpretation. By translat-ing NST to distribution matching, it becomes amenable to a suite of tools developed to measure the divergence between probability distributions, such as integral probability met-rics, f -divergences and Optimal Transport (OT). 9382
≥
Divergences d(P, Q) between two distributions, respec-tively probability measures, are in general not metrics, but they should fulﬁl the weaker conditions of (i) non-0; and (ii) identity of indiscernibles: negativity: d(P, Q) d(P, Q) = 0 iff P = Q. However, in the light of feature dis-tributions, existing style transfer methods suffer from rather elementary theoretical limitations. Broadly, there are two schools. Either the distributions are unrestricted, but the dis-crepancy between them is measured without adhering to the law of indiscernibles [9, 25, 15, 32]; or the distributions are approximated roughly with simple functions, so that they admit closed-form solutions [29, 19, 24, 27].
Here, we show how to overcome these limitations with the help of the recently proposed framework of Central Mo-ment Discrepancys (CMDs) [39]. That (pseudo-)metric is based on the representation of distributions as moment se-quences on compact intervals. In the limit, CMD is an in-tegral probability metric on the set of compactly supported distributions, so it complies with the law of indiscernibles (as well as non-negativity) by deﬁnition. Importantly, in its dual formulation the CMD is computationally efﬁcient, and approximations can be seamlessly justiﬁed with an upper bound on the central moments [38]. In summary, we make the following contributions: (i) We systematically catego-rize existing NST methods according to their way of align-ing distributions; (ii) we make explicit underlying approx-imations and highlight the corresponding limitations; (iii)
We propose a novel NST algorithm based on the Central
Moment Discrepancy. To our knowledge, our method is the
ﬁrst one that aligns style distributions in a rigorous and com-putationally efﬁcient manner, with theoretically grounded approximation bounds. Empirically, the method achieves a more perspicuous separation between artistic style and se-mantic content, and enables visually more compelling style transfer according to a user study with >50 participants. 2.