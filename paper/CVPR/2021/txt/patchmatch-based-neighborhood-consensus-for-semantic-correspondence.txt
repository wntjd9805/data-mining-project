Abstract
We address estimating dense correspondences between two images depicting different but semantically related scenes. End-to-end trainable deep neural networks incor-porating neighborhood consensus cues are currently the best methods for this task. However, these architectures re-quire exhaustive matching and 4D convolutions over match-ing costs for all pairs of feature map pixels. This makes them computationally expensive. We present a more efﬁ-cient neighborhood consensus approach based on Patch-Match. For higher accuracy, we propose to use a learned local 4D scoring function for evaluating candidates during the PatchMatch iterations. We have devised an approach to jointly train the scoring function and the feature extrac-tion modules by embedding them into a proxy model which is end-to-end differentiable. The modules are trained in a supervised setting using a cross-entropy loss to directly in-corporate sparse keypoint supervision. Our evaluation on
PF-PASCAL and SPAIR-71K shows that our method sig-niﬁcantly outperforms the state-of-the-art on both datasets while also being faster and using less memory. 1.

Introduction
Computing pixel correspondence in two or more im-ages is a fundamental step in computer vision tasks rang-ing from 3D vision [1, 7, 13, 19, 43, 51] to image edit-ing [21, 2, 3, 8, 12, 52] and scene understanding [11, 36, 33]. The problem variants where the images depict the same scene (e.g., stereo, optical ﬂow, and wide baseline match-ing) are extensively studied and many methods already ex-ist [39, 4, 14, 42, 44, 16]. We address the dense semantic correspondence task [36, 28, 54, 22] where the two input images depict common visual concepts. The goal is to ﬁnd corresponding pixels for semantically related object parts or scene elements as shown in Figure 1. Large intra-class appearance and shape variations make semantic correspon-dence challenging, and it continues to receive much atten-tion from the community [46, 58, 47, 49, 33, 34].
The top performing methods for computing semantic
Code available at http://github.com/leejaeyong7/PMNC
Figure 1: The top row shows an image pair from PF-PASCAL with ground truth keypoint annotations. The bot-tom row shows transferred keypoints on the target im-age computed using NC-Net [46], ANC-Net [34], and our method (PMNC). Errors are shown using red lines connect-ing the predicted orange keypoints to the expected green keypoints. PMNC outperforms NC-Net and ANC-Net on this example and produces state-of-the-art results on the
PF-PASCAL and SPAIR-71K datasets. correspondences rely on neighborhood consensus, which refers to a variety of techniques for ﬁltering sparse feature matches or dense pixel correspondence based on 2D spa-tial context. While hand-crafted neighbourhood consensus
ﬁlters have long been in use [50, 6, 35], Rocco et al. pro-posed NC-Net [49], the ﬁrst trainable neighborhood consen-sus neural network containing multiple 4D convolutional layers for robust match ﬁltering. ANC-Net [34] proposed a similar model with adaptive non-isotropic 4D convolution kernels. However, both methods sacriﬁce computational ef-ﬁciency in favor of accuracy. The multiple 4D convolution layers in these models cause high memory usage and high 13153
running times during the forward pass.
We take a different approach to neighborhood consen-sus inspired by PatchMatch [3]. We call our method Patch-Match Neighborhood Consensus (PMNC). Similar to NC-Net [49] and ANC-Net [34], PMNC uses a CNN feature backbone and computes 4D correlations to compare all fea-ture map pixel pairs in the two images. However, unlike
NC-Net and ANC-Net, PMNC does not ﬁlter the full 4D correlation map using multiple 4D convolutional layers. In-stead, it uses PatchMatch-based inference on the 4D cor-relation map. Conventional PatchMatch cannot easily pro-cess the 4D correlation tensors for neighborhood consen-sus. Therefore, we propose a modiﬁed PatchMatch method, where we introduce a learned scoring function for compar-ing the similarity of patches in the two images. This scoring function performs 4D convolution locally on the 4D correla-tion map to produce a matching score. We invoke this func-tion only at selective locations in the 4D map. The function is used to compare a small number of propagation candi-dates for each pixel during each PatchMatch iteration. In practice, PMNC computes 4D convolutions on a fraction of the full 4D search space which makes it more efﬁcient.
Because PMNC is non-differentiable, it is difﬁcult to train the CNN backbone and the scoring function using backpropagation. We overcome this by devising a differ-entiable proxy model into which we embed our local scor-ing function and feature backbone modules. While training this proxy model, we invoke the scoring function densely in the target image for a small number of 2D locations in the source image (locations where ground truth keypoints are available). The sparse ground truth keypoint positions in the target image are relaxed to 2D probability maps (similar to
ANC-Net [34]). Then, the parameters of the feature back-bone and the scoring function are jointly optimized to min-imize the deviation between the predicted and ground truth probability maps. With this training scheme, we achieve state-of-the-art results on both the PF-PASCAL and SPAIR-71K datasets while also being faster than the state-of-the-art solutions and requiring less memory.
In summary, our contributions are (1) PMNC, a novel PatchMatch-inspired method that avoids exhaustive 4D convolutions but still allows the beneﬁts of learned neighborhood consensus; (2) a simple approach to train
PMNC that uses a proxy model and sparse keypoint super-vision to jointly train the neighborhood consensus function and CNN feature modules; and (3) extensive experiments with standard datasets against current dense semantic corre-spondence benchmarks that show that our method achieves the best accuracy more quickly with less memory. 2.