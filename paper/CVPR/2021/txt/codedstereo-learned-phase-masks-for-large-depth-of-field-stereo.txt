Abstract
Conventional stereo suffers from a fundamental trade-off between imaging volume and signal-to-noise ratio (SNR) – due to the conﬂicting impact of aperture size on both these variables. Inspired by the extended depth of ﬁeld cameras, we propose a novel end-to-end learning-based technique to overcome this limitation, by introducing a phase mask at the aperture plane of the cameras in a stereo imaging sys-tem. The phase mask creates a depth-dependent yet numer-ically invertible point spread function, allowing us to re-cover sharp image texture and stereo correspondence over a signiﬁcantly extended depth of ﬁeld (EDOF) than conven-tional stereo. The phase mask pattern, the EDOF image reconstruction, and the stereo disparity estimation are all trained together using an end-to-end learned deep neural network. We perform theoretical analysis and characteri-zation of the proposed approach and show a 6× increase in volume that can be imaged in simulation. We also build an experimental prototype and validate the approach using real-world results acquired using this prototype system. 1.

Introduction
Stereo-based 3D reconstruction, while extremely popu-lar, suffers from a fundamental trade-off between volume of imaging and noise. If you want to retain a large volume of imaging, then in order to get sharp texture features for correspondence, you need to ensure that the depth of ﬁeld (DOF) of the cameras covers the entire volume. This ne-cessitates a narrow aperture, rapidly reducing the total light level reaching the sensor (since SNR is quadratically related to aperture size). As a consequence, it is challenging to get large volume, high quality, and high resolution stereo-based 3D reconstruction in light-limited environments.
In light-limited environments, typically either the expo-sure duration or the aperture size of a camera is increased to increase light throughput. But for scenarios where there is either scene motion (eg., motion capture) or camera motion (eg., robotics, autonomous navigation), increasing exposure
Figure 1. Tradeoff between depth of ﬁeld and aperture size on simulated data. We propose a CodedStereo system that can pro-vide an 6× increase in DOF (blue dashed curve, with stars for par-ticular observations). In the curves, the x-axis is linearly sampled in exposure time, and the corresponding f-numbers are converted to maintain the same SNR level of 50dB. Both our system and the conventional lens are focused at 1m, with a 50mm focal length. duration results in motion blur. On the other hand, increas-ing the aperture size will result in a smaller depth of ﬁeld, thereby reducing the volume that can be reconstructed.
Inspired by the extended depth of ﬁeld (EDOF) imag-ing techniques [10], we present CodedStereo, a technique in which we add optimized phase masks to the aperture of each of the two stereo cameras. These phase masks allow each camera to maintain a large aperture size, increasing the light throughput of the cameras. Meanwhile, the phase masks are specially designed to produce a depth-dependent focal blur that allows back-end stereo algorithms to con-tinue to retain high resolution and quality. In addition, our learned phase mask not only enables more accurate depth estimation, but also encourages sharper extended depth of
ﬁeld RGB images that can be used for downstream applica-tions such as point cloud colorization. The reconstruction algorithms and the phase masks are simultaneously opti-mized using an end-to-end learning framework. The main technical contributions of this paper are:
∗These two authors contributed equally. †Corresponding author.
I. We propose CodedStereo, a technique to recover large-7170
volume, high-quality, and high-resolution 3D recon-structions in light-limited environments. The key idea in CodedStereo is the introduction of a phase mask in the aperture of the stereo cameras that allows us to in-crease the aperture size of the cameras without sacri-ﬁcing the depth of ﬁeld.
II. We develop an end-to-end learning framework to jointly optimize the phase masks and the algorithms both for RGB image and disparity reconstructions.
III. We demonstrate the signiﬁcant performance beneﬁts of CodedStereo both in simulation and using a proto-type system. 2.