Abstract
Unsupervised contrastive learning has achieved out-standing success, while the mechanism of contrastive loss
In this paper, we concentrate on has been less studied. the understanding of the behaviours of unsupervised con-trastive loss. We will show that the contrastive loss is a hardness-aware loss function, and the temperature τ con-trols the strength of penalties on hard negative samples. The previous study has shown that uniformity is a key property of contrastive learning. We build relations between the uni-formity and the temperature τ . We will show that uniformity helps the contrastive learning to learn separable features, however excessive pursuit to the uniformity makes the con-trastive loss not tolerant to semantically similar samples, which may break the underlying semantic structure and be harmful to the formation of features useful for downstream tasks. This is caused by the inherent defect of the instance discrimination objective. Speciﬁcally, instance discrimina-tion objective tries to push all different instances apart, ig-noring the underlying relations between samples. Pushing semantically consistent samples apart has no positive effect for acquiring a prior informative to general downstream tasks. A well-designed contrastive loss should have some extents of tolerance to the closeness of semantically sim-ilar samples. Therefore, we ﬁnd that the contrastive loss meets a uniformity-tolerance dilemma, and a good choice of temperature can compromise these two properties prop-erly to both learn separable features and tolerant to seman-tically similar samples, improving the feature qualities and the downstream performances. 1.

Introduction
Deep neural networks have undergone dramatic progress since the large scale human-annotated datasets such as Im-ageNet [6] and Places [36]. Such progress is heavily de-pendent on manual labelling, which is costly and time-†Corresponding author. xj xi
E xch a n ge
Hypersphere xk xl (a) xk xi
Hypersphere xj xl (b)
Figure 1. We display two embedding distributions with four in-stances on a hypersphere. From the ﬁgure, we observe that ex-changing xj and xk, as well as their corresponding augmentations, will not change the value of contrastive loss. However, the embed-ding distribution of (a) is much more useful for downstream tasks because it captures the semantical relations between instances. consuming. Unsupervised learning gives us the promise to learn transferable representations without human supervi-sion. Recently, unsupervised learning methods based on the contrastive loss [33, 20, 1, 10, 5, 4, 14, 37] have achieved outstanding success and received increasing attention. Con-trastive learning methods aim to learn a general feature function which maps the raw pixel into features residing on a hypersphere space. They try to learn representations invariant to different views of the same instance by making positive pairs attracted and negative pairs separated. With the help of heavy augmentations and strong abstraction abil-ity of convolutional neural networks [16, 26, 12], the unsu-pervised contrastive models can learn some extents of se-mantic structures. For example, in Fig 1, a good contrastive learning model tends to produce the embedding distribution likes Fig 1 (a) instead of the situation of Fig 1 (b), though the losses of Fig 1 (a) and Fig 1 (b) are the same.
Contrastive learning methods share a common design of the loss function which is a softmax function of the feature similarities with a temperature τ to help discriminate pos-itive and negative samples. The contrastive loss is signiﬁ-cant to the success of unsupervised contrastive learning. In this paper, we focus on analyzing the properties of the con-2495
trastive loss using the temperature as a proxy. We ﬁnd that the contrastive loss is a hardness-aware loss function which automatically concentrates on optimizing the hard nega-tive samples, giving penalties to them according to their hardness. The temperature plays a role in controlling the strength of penalties on the hard negative samples. Specif-ically, contrastive loss with small temperature tends to pe-nalize much more on the hardest negative samples such that the local structure of each sample tends to be more sep-arated, and the embedding distribution is likely to be more uniform. On the other hand, contrastive loss with large tem-perature is less sensitive to the hard negative samples, and the hardness-aware property disappears as the temperature approaches +∞. The hardness-aware property is signiﬁ-cant to the success of the softmax-based contrastive loss, with an explicit hard negative sampling strategy, a very sim-ple form of contrastive loss works pretty well and achieves competitive downstream performances.
The uniformity of the embedding distribution in unsu-pervised contrastive learning is important to learn separable features [31]. We connect the relation between the tempera-ture and the embedding uniformity. With the temperature as a proxy, we ﬁnd that although the uniformity is a key indica-tor to the performance of contrastive models, the excessive pursuit to the uniformity may break the underlying semantic structure. This is caused by the inherent defect of the pop-ular unsupervised contrastive objective. Speciﬁcally, most contrastive learning methods aim to learn an instance dis-crimination task, by maximizing the similarities of different augmentations sampling from the same instances and min-imizing the similarities of all different instances. This kind of objective actually contains no information about seman-tical relations. Pushing the semantically consistent samples away is harmful to generate useful features.
If the con-trastive loss is equipped with very small temperature, the loss function will give very large penalties to the nearest neighbours which are very likely to share similar semanti-cal contents with the anchor point. From Fig 2, we observe that embeddings trained with τ = 0.07 are more uniformly distributed, however the embeddings trained with τ = 0.2 present a more reasonable distribution which is locally clus-tered and globally separated. We recognize that there exists a uniformity-tolerance dilemma in unsupervised contrastive learning. On the one hand, we hope the features are dis-tributed uniformly enough to be more separable. On the other hand, we hope the contrastive loss can be more toler-ant to the semantically similar samples. A good contrastive loss should make a compromise to satisfy both the two prop-erties properly.
Overall, the contributions can be summarized as follows:
• We analyze the behaviours of the contrastive loss and show that contrastive loss is a hardness-aware loss. We validate that the hardness-aware property is signiﬁcant
τ = 0.07
τ = 0.2
Figure 2. T-SNE [29] visualization of the embedding distribution.
The two models are trained on CIFAR10. The temperature is set to 0.07 and 0.2 respectively. Small temperature tends to generate more uniform distribution and be less tolerant to similar samples. to the success of contrastive loss.
• With a gradient analysis, we show that the temperature is a key parameter to control the strength of penalties on hard negative samples. Quantitative and qualitative experiments are conducted to validate the perspective.
• We show that there exists a uniformity-tolerance dilemma in contrastive learning, a good choice of tem-perature can compromise the two properties and im-prove the feature quality remarkably. 2.