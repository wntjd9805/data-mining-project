Abstract
Weakly-supervised temporal action localization (WS-TAL) aims to localize actions in untrimmed videos with only video-level labels. Most existing models follow the
“localization by classiﬁcation” procedure: locate temporal regions contributing most to the video-level classiﬁcation.
Generally, they process each snippet (or frame) individu-ally and thus overlook the fruitful temporal context relation.
Here arises the single snippet cheating issue: “hard” snip-pets are too vague to be classiﬁed. In this paper, we argue that learning by comparing helps identify these hard snip-pets and we propose to utilize snippet Contrastive learn-ing to Localize Actions, CoLA for short. Speciﬁcally, we propose a Snippet Contrast (SniCo) Loss to reﬁne the hard snippet representation in feature space, which guides the network to perceive precise temporal boundaries and avoid the temporal interval interruption. Besides, since it is in-feasible to access frame-level annotations, we introduce a
Hard Snippet Mining algorithm to locate the potential hard snippets. Substantial analyses verify that this mining strat-egy efﬁcaciously captures the hard snippets and SniCo Loss leads to more informative feature representation. Extensive experiments show that CoLA achieves state-of-the-art re-sults on THUMOS’14 and ActivityNet v1.2 datasets. 1.

Introduction
Temporal action localization (TAL) aims at ﬁnding and classifying action intervals in untrimmed videos. It has been extensively studied in both industry and academia, due to its wide applications in surveillance analysis, video summa-rization and retrieval [38, 15, 23], etc. Traditionally, fully-supervised TAL is labor-demanding in its manual labeling procedure, thus weakly-supervised TAL (WS-TAL) which only needs video-level labels has gain popularity.
Most existing WS-TAL methods [39, 27, 30, 26, 14] em-ploy the common attention mechanism or multiple instance learning formulation. Speciﬁcally, each input video is di-Compare
Compare
#1. Easy Action
#2. ?
#3. ?
#4. Easy Bkg.
GT
Baseline
Ours
Time
Figure 1. Which category do the two selected snippets (#2, #3) belong to? It is difﬁcult to tell when evaluating independently and they are actually misclassiﬁed in baseline (We plot the one-dimensional T-CAS for CliffDiving and the thresholded results).
By contrast, learning by comparing helps identify them: #2 snippet (person falling down) is inferred to be the action snippet by mak-ing a comparison with #1 “easy action” (different camera views of the CliffDiving action); The inference of #3 snippet is also rectiﬁed after the comparison with #4 “easy background” snippet. vided into multiple ﬁxed-size non-overlapping snippets and the snippet-wise classiﬁcations are performed over time to generate the Temporal Class Activation Map/Sequence (T-CAM/T-CAS)[27, 34]. The ﬁnal localization results are generated by thresholding and merging the class activations.
For illustration, we consider the na¨ıve case where the whole process is optimized with a single video-level classiﬁcation loss and we treat this pipeline as baseline in our paper.
In absence of frame-wise labels, WS-TAL suffers from the single snippet cheating issue: indistinguishable snip-pets are easily misclassiﬁed and hurt the localization per-formance. To illustrate it, we take CliffDiving in Figure 1 as an example. When evaluated individually, two selected snippets (#2, #3) seem ambiguous and are misclassiﬁed: 1) the #2 snippet is incorrectly categorized, thus breaking the time intervals; 2) the #3 snippet is misidentiﬁed as an action in baseline, resulting in inaccurately extended action inter-val boundaries. How to address the single snippet cheating issue? Let’s revisit the case in Figure 1. By comparing 16010
snippets of interest with those “easy snippets” which can be classiﬁed effortlessly, action and background can be dis-tinguished more easily. For example, the #2 snippet and the #1 easy action snippet are two different views of a man falling-down process in “CliffDiving”. The #3 snippet is similar to the #4 easy background snippet and can be eas-ily classiﬁed as the background class. In light of this, we contend that localizing actions by contextually comparing offers a powerful inductive bias that helps distinguish hard snippets. Based on the above analysis, we propose an al-ternative, rather intuitive way to address the single snippet cheating issue – by conducting Contrastive learning on hard snippets to Localize Actions, CoLA for short. To this end, we introduce a new Snippet Contrast (SniCo) Loss to re-ﬁne the feature representations of hard snippets under the guidance of those more discriminative easy snippets. Here these “cheating” snippets are named hard snippets due to their ambiguity.
This solution, however, faces one crucial challenge on how to identify reasonable snippets under our weakly-supervised setting. The selection of hard snippets is non-trivial as there is no speciﬁc attention distribution pattern for them. For example, in Figure 1 baseline, #3 hard snippet has a high response value while #2 remains low.
Noticing that ambiguous hard snippets are commonly found around boundary areas of the action instances, we propose a boundary-aware Hard Snippet Mining algorithm – a simple yet effective importance sampling technique. Speciﬁcally, we ﬁrst threshold T-CAS and then employ dilation and ero-sion operations temporally to mine the potential hard snip-pets. Since the hard snippets may either be action or back-ground, we opt to distinguish them by their relative posi-tion. For easy snippets, they locate in the most discrimi-native parts, so snippets with top-k/bottom-k T-CAS scores are selected as easy action/background respectively. More-over, we form two hard-easy contrastive pairs and conduct the feature reﬁnement via the proposed SniCo Loss.
In a nutshell, the main contributions of this work are as follows: (1) Pioneeringly, we introduce the contrastive rep-resentation learning paradigm to WS-TAL and propose a
SniCo Loss which effectively reﬁnes the feature representa-tion of hard snippets. (2) A Hard Snippet Mining algorithm is proposed to locate potential hard snippets around bound-aries, which serves as an efﬁcient sampling strategy under our weakly-supervised setting. (3) Extensive experiments on THUMOS’14 and ActivityNet v1.2 datasets demonstrate the effectiveness of our proposed CoLA. 2.