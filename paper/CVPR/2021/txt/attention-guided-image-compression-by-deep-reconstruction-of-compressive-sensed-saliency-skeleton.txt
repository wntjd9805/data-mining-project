Abstract
We propose a deep learning system for attention-guided dual-layer image compression (AGDL). In the AGDL com-pression system, an image is encoded into two layers, a base layer and an attention-guided reﬁnement layer. Unlike the existing ROI image compression methods that spend an ex-tra bit budget equally on all pixels in ROI, AGDL employs a
CNN module to predict those pixels on and near a saliency sketch within ROI that are critical to perceptual quality.
Only the critical pixels are further sampled by compressive sensing (CS) to form a very compact reﬁnement layer. An-other novel CNN method is developed to jointly decode the two compression layers for a much reﬁned reconstruction, while strictly satisfying the transmitted CS constraints on perceptually critical pixels. Extensive experiments demon-strate that the proposed AGDL system advances the state of the art in perception-aware image compression. 1.

Introduction
After decades of intensive research and development, visual signal compression techniques are approaching the rate-distortion performance limits. Any further signiﬁcant improvements of bandwidth economy in visual communi-cations have to come from smart human vision driven rep-resentations. In this direction the methodology of region-of-interest (ROI) image compression emerged about twenty years ago [7, 31, 3]. ROI compression is to exploit a well-known property of human vision: a viewer’s attention is not evenly distributed in all parts of an image. Instead, our attentions focus on one or few regions of greater interests than the rest of the image, which pertain to salient fore-ground object(s).