Abstract
CoMoGAN is a continuous GAN relying on the unsu-pervised reorganization of the target data on a functional manifold. To that matter, we introduce a new Functional In-stance Normalization layer and residual mechanism, which together disentangle image content from position on target manifold. We rely on naive physics-inspired models to guide the training while allowing private model/translations fea-tures. CoMoGAN can be used with any GAN backbone and allows new types of image translation, such as cyclic im-age translation like timelapse generation, or detached lin-ear translation. On all datasets, it outperforms the litera-ture. Our code is available in this page: https://github.com/cv-rits/CoMoGAN . 1.

Introduction
Image-to-image (i2i) translation networks learn transla-tions between domains, applying to the context of source images a target appearance learned from a dataset. This enables applications such as neural photo editing [75, 32, 21, 48, 6], along with robotics-oriented tasks as time-of-day or weather selection [74, 47, 46, 13, 61], domain adap-tation [18, 40, 29, 60], or others. Despite impressive leaps forward with unpaired [75, 32], multi-target [9, 65], or con-tinuous [64, 14] i2i, there are still important limitations.
Speciﬁcally, to learn complex continuous translations ex-isting works require supervision on intermediate domain points. Also, they assume piece-wise or entire linearity of the domain manifold. Such constraints can hardly meet cyclic translations (e.g. daytime) or continuous ones costly or impractical to label (e.g. fog, rain).
Instead, we introduce CoMoGAN, the ﬁrst i2i frame-work learning non-linear continuous translations with un-supervised target data. It is trained using simple physics-inspired models for guidance, while relaxing model de-pendency via continuous disentanglement of domain fea-tures. An interesting resulting property is that CoMoGAN discovers the target data manifold ordering, unsupervised.
For evaluation we propose new translation tasks, shown in
Fig. 1, being either cyclic/linear, attached/detached from
Figure 1: Detaching from traditional i2i translation, we are interested in continuous mapping from source domain (green point) to a target domain (red lines), in single- or multi- modal setup. A key feature of our proposal, is unsu-pervised reorganization of the data along a functional mani-fold (top: cyclic, middle/bottom: linear). We leverage light-ing translations from day images (top), shallower depth of
ﬁeld from in-focus images (middle), or synthetic clear im-ages to realistic foggy images (bottom). source. Our contributions are:
• a novel model-guided setting for continuous i2i,
• CoMoGAN: an unsupervised framework for disentan-glement of continuously evolving features in generated images, using simple model guidance,
• a novel Functional Instance Normalization (FIN) layer,
• the evaluation of CoMoGAN against recent baselines and new tasks, outperforming the literature on all. 2.