Abstract
Generating high-quality stitched images with natural structures is a challenging task in computer vision. In this paper, we succeed in preserving both local and global geo-metric structures for wide parallax images, while reducing artifacts and distortions. A projective invariant, Character-istic Number, is used to match co-planar local sub-regions for input images. The homography between these well-matched sub-regions produces consistent line and point pairs, suppressing artifacts in overlapping areas. We ex-plore and introduce global collinear structures into an ob-jective function to specify and balance the desired charac-ters for image warping, which can preserve both local and global structures while alleviating distortions. We also de-velop comprehensive measures for stitching quality to quan-tify the collinearity of points and the discrepancy of matched line pairs by considering the sensitivity to linear struc-tures for human vision. Extensive experiments demonstrate the superior performance of the proposed method over the state-of-the-art by presenting sharp textures and preserv-ing prominent natural structures in stitched images. Espe-cially, our method not only exhibits lower errors but also the least divergence across all test images. Code is available at https://github.com/dut-media-lab/Image-Stitching. 1.

Introduction
Image stitching, that combines multiple images into a larger image with a wider ﬁeld of view [25], is widely used in photogrammetry [24], robot navigation [6] and panorama on smart phones [29]. It is still challenging to produce high quality stitched images for the state-of-the-art as they suffer from severely unpleasant effects such as artifacts and dis-tortions, especially for wide parallax images.
Feature matching is the key to aligning multiple images for producing artifact-free stitching as the matched features act as anchors in alignment. The SIFT features [23] are
Figure 1: Comparisons of stitching methods. Evident ar-tifacts and distortions appear in the results of the existing methods shown in the zoomed-in rectangles, but ours is free of these unpleasant effects. widely used in many traditional methods for feature points detection and matching [4, 5, 30]. Some recent works also introduce line features to obtain robust matching in the cases of large parallax and/or low textures where points are prone to mismatched [11]. Lin et al. exploit both point and line features by different weights in an objec-tive function [16]. Unfortunately, these methods separately match points and lines, and thus the local surrounding ar-eas may be inconsistently and non-uniformly stretched or compressed when mismatches inevitably occur, presenting artifacts in the stitched images. Liao et al. employ the
RANSAC strategy to reﬁne point and line pairs by using the homography between images [17]. It is worth noting 12186
that the homography relationship only holds for points and lines in the same projective plane [12]. Therefore, those reﬁnements upon the homongraphy but neglecting the co-planar constraint fail to give accurate matches. As shown in the red rectangles of the ﬁrst three rows in Fig. 1, the mag-niﬁed overlapping area on the right exhibits artifacts on the picture frame, clock and computer. It is highly desirable to explore co-planar areas and reﬁne corresponding matching pairs of points and lines.
Image stitching has to preserve linear structures while alleviate distortions since human visual perception is very sensitive to these structures. The as-projective-as-possible (APAP) method adopts parametric warps by local con-straints [30], but suffers from severe shape distortions es-pecially in non-overlapping areas, as shown in the blue rectangle of the ﬁrst row in Fig. 1. Shape-preserving half-projective (SPHP) [4] and global similarity prior (GSP) [5] share a similar idea to adapt different warps for different image areas. Geodesic-preserving[13] and line-structure-preserving[3] involve collinearity preservation, but their im-age resizing takes one panoramic image as input, already including correct global geometric structures as reference.
Recently, Liao et al. propose single-perspective warps (SPW) [17] to protect linear structures while suppress dis-tortions. These methods can well preserve local structures but fail to resolve the conﬂict when maintaining both local and global linear structures. Global collinear structures can be either a long line across the major part of an image, e.g., the long line under the two picture frames in Fig. 1, or sev-eral separate collinear line segments. Current line detec-tors [26] cannot detect or connect these long lines. Con-sequently, local shapes may be well preserved by setting appropriate parameters, but the global linear structure is out of shape in the second row of Fig. 1. In the third row, pre-serving linear structure results in severe distortions for local shapes. It still remains unresolved to preserve both local and global collinear structures.
Meanwhile, the existing metrics to evaluate the stitch-ing quality are not comprehensive enough. These metrics including the distance between matched points [30] and av-erage geometric error (SSIM) [27] on local patterns of pixel intensities can only quantify performance on point match-ing. None of them can reﬂect the alignment of points on lin-ear structures or the collinearity of matched line segments.
Quantitatively evaluating the preservation on linear struc-tures for image stitching is also an open issue.
This paper leverages the line and point consistence to preserve linear structures that are essential geometries for image stitching. We divide input images into co-planar re-gions upon the neighborhoods of lines, and match the re-gions from different views using a series of geometric in-variants reﬂecting the intrinsic nature of lines and points.
Hence, the homography between these co-planar regions can accurately generate matches of both lines and points.
Subsequently, an line-guided objective function for warping is designed to preserve both local and global linear struc-tures and suppress distortions. The fourth row in Fig. 1 demonstrates that our method yields a signiﬁcant gain in image quality. Moreover, a quantitative evaluation measure for lines is proposed to analyze the quality of stitched im-ages more comprehensively. Our contributions are summa-rized as follows:
• We design a new matching strategy to obtain consis-tent point and line pairs by exploring co-planar sub-regions using projective invariants. This matching fol-lows the essential co-planar requirement for homogra-phy so that it can provide accurate pre-alignment while eliminating artifacts and non-uniform distortions.
• To the best of our knowledge, we are the ﬁrst to incor-porate global collinear structures as a constraint that signiﬁcantly alleviates unnatural distortions.
• We propose a comprehensive metric to quantify the preservation of linear structures for image stitching.
We compare the proposed method with the state-of-the-art on challenging natural image pairs with prominent linear structures covering variations on camera motions, scenes and ﬁelds of view. Our method can produce visually ap-pealing stitching and our average RMSE for point matching is 31% lower than that of SPW [17]. Meanwhile, ours works the most accurate and stable for preserving the linear struc-tures in terms of the proposed metric. Sections 3, 4 and 5 elaborate our contributions, respectively. 2.