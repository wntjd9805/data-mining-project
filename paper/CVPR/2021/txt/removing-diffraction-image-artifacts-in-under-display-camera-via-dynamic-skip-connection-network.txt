Abstract
Recent development of Under-Display Camera (UDC) systems provides a true bezel-less and notch-free viewing experience on smartphones (and TV, laptops, tablets), while allowing images to be captured from the selﬁe camera em-bedded underneath.
In a typical UDC system, the mi-crostructure of the semi-transparent organic light-emitting diode (OLED) pixel array attenuates and diffracts the in-cident light on the camera, resulting in signiﬁcant image quality degradation. Oftentimes, noise, ﬂare, haze, and blur can be observed in UDC images. In this work, we aim to an-alyze and tackle the aforementioned degradation problems.
We deﬁne a physics-based image formation model to bet-ter understand the degradation. In addition, we utilize one of the world’s ﬁrst commodity UDC smartphone prototypes to measure the real-world Point Spread Function (PSF) of the UDC system, and provide a model-based data synthesis pipeline to generate realistically degraded images. We spe-cially design a new domain knowledge-enabled Dynamic
Skip Connection Network (DISCNet) to restore the UDC images. We demonstrate the effectiveness of our method through extensive experiments on both synthetic and real
UDC data. Our physics-based image formation model and proposed DISCNet can provide foundations for further ex-ploration in UDC image restoration, and even for general diffraction artifact removal in a broader sense. 1 1.

Introduction
The consumer demand for smartphones with bezel-free, notch-less display has sparked a surge of interest from the phone manufacturers in a newly-deﬁned imaging system,
Under-Display Camera (UDC). Besides smartphones, UDC also demonstrates its practical applicability in other scenar-ios, i.e., for videoconferencing with UDC TV, laptops, or tablets, enabling more natural gaze focus as they place cam-eras at the center of the displays [16]. As Figure 2 shows, a typical UDC system has the camera module placed un-derneath and closely attached to the semi-transparent Or-ganic Light-Emitting Diode (OLED) display. Although the display looks partially transparent, the regions where the light can pass through, i.e. the gaps between the display pix-els, are usually in the micrometer scale, which substantially diffracts the incoming light [23], affecting the light propa-1Codes and data are available at https://jnjaby.github.io/projects/UDC. 662    
(a) (b) (c)
Normal pixel density
Reduced pixel density
Display
Lens
Sensor
Point 
Source z1 d z2 1D Dissection of the PSF
✱
=
Measured 2D
HDR PSF
UDC Image
Real HDR Scene
Figure 2. (a) A close-up shot of the UDC OLED on the ZTE Axon 20 phone. The UDC OLED panel has reduced pixel density in the area above the camera, allowing for more transparency. (b) The schematic of the UDC system. The light emitted from a point light source is modulated by the OLED and camera lens, before being captured by the sensor. (c) A simulated example of our image for-mation model with a real-captured PSF. The 2D PSF is brightened in the ﬁgure to visualize the structured sidelobe patterns. gation from the scene to the sensor. The UDC systems intro-duce a new class of complex image degradation problems, combining strong ﬂare, haze, blur, and noise (see top row in Figure 1). In the ﬁrst attempt [47] to address the UDC image restoration problem, the authors proposed a Monitor-Camera Imaging System (MCIS) to capture paired data and used the image formation to synthesize the Point Spread
Function (PSF) of two types of OLED display. However, there are several drawbacks of this pioneer work, includ-ing 1) inaccurate PSF due to a mismatch between the ac-tual and the synthetic PSF, 2) lacking proper high dynamic range (HDR) in the MCIS-captured data, missing realistic
UDC degradation, 3) prototype UDC differs signiﬁcantly from actual production UDC, 4) missing real-world evalua-tion on non-MCIS data, and 5) proposed network does not fully utilize domain knowledge. We examine the drawbacks in further details in Section 2.
In this work, we aim to address the aforementioned is-sues. We ﬁrst present a realistic image formation model and measurement protocol considering proper dynamic range for the scenes and camera sensor, and restore the real-world degradation in the actual UDC images. To this end, we experiment with one of the world’s ﬁrst production UDC device, ZTE Axon 20, which incorporates a UDC system into its selﬁe camera. Note that we aim to analyze and in-vestigate the artifacts caused by diffraction effects, rather than propose a product-ready solution for ZTE phone cam-era. Our method is versatile and applicable to other UDC device, or more generally, other diffraction-limited imag-ing systems, e.g., microscopy imaging, pinhole camera. We devise an imaging system to directly measure the PSF of the UDC device (see Section 3.2) with a point source. As shown in Figure 2, due to the diffraction of the display, the resulting PSF has some special characteristics: it has large spatial support, strong response at the center, and long-tail low-energy sidelobes. With the measured PSF, we refor-mulate the image formation model to account for realistic
ﬂare, haze, and blur, which were missing [46, 47] due to the limited dynamic range of scenes. Then, we develop a data simulation pipeline based on the image formation model by using HDR images to approximate real scenes. Addition-ally, we capture real images using the UDC phone’s selﬁe camera to validate our simulated data and evaluate the per-formance of our restoration network. As shown in Figure 1, our simulated and real data reveal similar degradation, espe-cially in those high-intensity regions. Speciﬁcally, ﬂare can be observed nearby strong light sources, where highlights are spread into neighboring low-intensity areas in structured diffraction patterns.
To restore the UDC images, we propose a DynamIc Skip
Connection Network (DISCNet) that incorporates the do-main knowledge of the image formation model into the net-work designs.
In particular, sensor saturation breaks the shift-invariance of the single-PSF-based convolution, lead-ing to spatially-variant degradation. This motivates us to design a dynamic ﬁlter network to dynamically predict ﬁl-ters for each pixel. In addition, due to large support of PSF, we propose a multi-scale architecture and perform dynamic convolution in the feature domain to obtain a larger recep-tive ﬁeld. Also, a condition encoder is introduced to utilize the information of PSF.
In summary, our contributions are as follows:
• We reformulate the image formation model for UDC systems by considering dynamic range and saturation, which takes into account the diffraction ﬂare com-monly seen in UDC images.
• We utilize the ﬁrst UDC smartphone prototypes to measure the real-world PSF. The PSF is used as part of a model-based data synthesis pipeline to generate realistic degraded images.
• We devise a DynamIc Skip Connection Network (DIS-CNet) that incorporates the domain knowledge of the 663
UDC image formation model. Experimental results show that it is effective for removing diffraction image artifacts in UDC systems. 2.