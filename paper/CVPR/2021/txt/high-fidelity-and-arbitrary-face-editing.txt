Abstract
Cycle consistency is widely used for face editing. How-ever, we observe that the generator tends to ﬁnd a tricky way to hide information from the original image to satisfy the constraint of cycle consistency, making it impossible to maintain the rich details (e.g., wrinkles and moles) of non-editing areas. In this work, we propose a simple yet effective method named HifaFace to address the above-mentioned problem from two perspectives. First, we relieve the pres-sure of the generator to synthesize rich details by directly feeding the high-frequency information of the input image into the end of the generator. Second, we adopt an addi-tional discriminator to encourage the generator to synthe-size rich details. Speciﬁcally, we apply wavelet transforma-tion to transform the image into multi-frequency domains, among which the high-frequency parts can be used to re-cover the rich details. We also notice that a ﬁne-grained and wider-range control for the attribute is of great impor-tance for face editing. To achieve this goal, we propose a novel attribute regression loss. Powered by the proposed framework, we achieve high-ﬁdelity and arbitrary face edit-ing, outperforming other state-of-the-art approaches. 1.

Introduction
Face editing is a process of editing the speciﬁc attributes or regions of an input facial image while keeping the non-editing attributes/areas unchanged. With the rapid devel-opment of Generative Adversarial Networks (GANs) [11], many recent works on face editing [19, 6, 15, 24, 33, 8] leverage the advanced conditional GANs and achieve re-markable progress. Due to the lack of paired images dur-ing training, they typically use cycle consistency to keep the non-editing attributes/areas unchanged. Namely, given an image x, it requires x = G(G(x, ∆), −∆), where G
*Zhouhui Lian is the corresponding author. This work was sup-ported by Beijing Nova Program of Science and Technology (Grant No.:
Z191100001119077). (a) Input x (b) ˆy = x + EG (c) ˆx = ˆy - EG (d) HifaFace
Figure 1: The results of a representative face editing method
StarGAN [6]: (a) the input image; (b) the output image syn-thesized by editing (a) with the attribute eyeglasses (EG); (c) the reconstructed image with (b) as input. We observe that the rich details are all missing in ˆy, but are almost re-stored in ˆx. (d) The high-ﬁdelity face image synthesized by our HifaFace. represents the generator and ∆ indicates the attribute that needs to be changed. However, we ﬁnd that even if the cy-cle consistency is satisﬁed, images generated by G may still be blurry and lose rich details from input images.
To demonstrate the above-mentioned problem, we take
StarGAN [6] as an example. As shown in Figure 1, we feed an input face image x to StarGAN and expect it to add eye-glasses on the face. Although the output ˆy does wear eye-glasses, the details (e.g., wrinkles and moles) are all miss-ing. However, we observe an intriguing phenomenon as fol-lows. When we feed ˆy into the StarGAN model and expect removing eyeglasses on the face, the reconstruction result ˆx surprisingly recovers almost all rich details, which satisﬁes the purpose of setting cycle consistency. This observation indicates that the generator encodes the rich details of the input image into the output image in the form of “hidden” signals, and then decodes the feature with these “hidden” signals to achieve reconstruction. The above-mentioned phenomenon is called steganography [7] and is undesirable for face editing [29].
To prevent the generator from taking this trick route to satisfy cycle consistency, we propose a simple yet effective face editing method called HifaFace. We tackle this prob-lem from two perspectives. First, we directly feed the high-frequency information of the input image to the end of the 16115
generator to alleviate the generator’s struggles for synthe-sizing rich details so that it gives up encoding the hidden signals. Second, we adopt an additional discriminator to constrain the generator to synthesize rich details, thus fur-ther preventing the generator from ﬁnding a trivial solution for cycle consistency.
Speciﬁcally, we adopt wavelet transformation to trans-form an image into multiple frequency domains. We ﬁnd that almost all rich details lie in the high-frequency do-In order to feed the high-frequency information mains. to the generator, we adopt an encoder-decoder-like struc-ture and design a novel module named Wavelet-based Skip-Connection to replace the original Skip-Connection.
To achieve the goal of providing a ﬁne-grained and wider-range control for each facial attribute, we also pro-pose a novel loss, called the attribute regression loss, which requires the generated image to explicitly describe the change on selected attributes and thus enables wider-range and controllable face editing. Furthermore, our method is able to effectively exploit large amounts of unlabeled face images for training, which can further improve the ﬁdelity of synthesized faces in the wild. Powered by the proposed framework, we obtain high-ﬁdelity and arbitrarily control-lable face editing results.
In summary, our major contributions are threefold:
• We propose a novel wavelet-based face editing method, called HifaFace, for high-ﬁdelity and arbi-trary face editing.
• We revisit cycle consistency in face editing and ob-serve that the generator learns to apply a tricky way to satisfy the constraint of cycle consistency by hiding signals in the output image. We thoroughly analyze this phenomenon and provide an effective solution to handle the problem.
• Both qualitative and quantitative results demonstrate the effectiveness of the proposed framework for im-proving the quality of edited face images. 2.