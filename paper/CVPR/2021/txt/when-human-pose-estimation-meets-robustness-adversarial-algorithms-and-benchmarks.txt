Abstract
Human pose estimation is a fundamental yet challeng-ing task in computer vision, which aims at localizing hu-man anatomical keypoints. However, unlike human vision that is robust to various data corruptions such as blur and pixelation, current pose estimators are easily confused by these corruptions. This work comprehensively studies and addresses this problem by building rigorous robust bench-marks, termed COCO-C, MPII-C, and OCHuman-C, to evaluate the weaknesses of current advanced pose estima-tors, and a new algorithm termed AdvMix is proposed to improve their robustness in different corruptions. Our work has several unique beneﬁts. (1) AdvMix is model-agnostic and capable in a wide-spectrum of pose estimation mod-els. (2) AdvMix consists of adversarial augmentation and knowledge distillation. Adversarial augmentation contains two neural network modules that are trained jointly and competitively in an adversarial manner, where a genera-tor network mixes different corrupted images to confuse a pose estimator, improving the robustness of the pose estima-tor by learning from harder samples. To compensate for the noise patterns by adversarial augmentation, knowledge dis-tillation is applied to transfer clean pose structure knowl-edge to the target pose estimator. (3) Extensive experiments show that AdvMix signiﬁcantly increases the robustness of pose estimations across a wide range of corruptions, while maintaining accuracy on clean data in various challenging benchmark datasets. 1.

Introduction
Human pose estimation (HPE) is a fundamental task for action recognition and video surveillance [28, 38, 25].
Although convolutional neural networks (CNNs) achieved great progress [39, 40, 36, 5, 30, 7] on challenging datasets
†The work was done during an internship at SenseTime Research.
Figure 1. Improvements of model robustness (mPC) when Ad-vMix is applied to the state-of-the-art methods.
[26, 1, 47], which only contain clean and high-resolution images, deploying models in the real world requires not only good performance on clean data, but also robustness to commonly occurring image corruptions. For example, while tracking and estimating the keypoints of a moving person in outdoor environments, current pose estimators suffer severe performance drop due to the noise or blur caused by weather conditions or camera systems. There-fore, analyzing and enhancing the robustness of pose esti-mators are important and are the purposes of this work.
Unlike previous studies on common robustness for clas-siﬁcation, detection and segmentation [17, 29, 23], human pose estimation uses a blend of classiﬁcation and regression methods to model the structures of the human body, mak-ing it a challenging and collaborative ﬁeld that is worthy of special investigations. The key challenges of robust human pose estimation are three folds. First, the lack of a bench-mark for evaluating the robustness of state-of-the-art human pose estimation methods makes it difﬁcult to construct rig-orous comparisons between different models, not to men-tion to improve model robustness. Second, accuracy of clean data and corrupted data are trade-offs. Improving the robustness of the model while maintaining its performance 11855
on clean data is a non-trivial problem. Third, based on the proposed benchmark, we have examined the effectiveness of some data augmentation methods. However, we ﬁnd that simply applying them sequentially does not achieve desir-able performance. How can we effectively combine existing data augmentation techniques to improve the generalization of human pose estimators towards unforeseen corruptions?
Inspired by [17], we establish the robust pose bench-marks, consisting of three challenging datasets includ-ing COCO-C, MPII-C, and OCHuman-C. The benchmark datasets are constructed based on a full spectrum of un-foreseen corruption types that are not encountered in model training (i.e. CNNs are trained on clean images, while evaluated on corrupted images). Extensive evaluations on these benchmarks show the weakness of both existing top-down and bottom-up pose estimators. (1) The state-of-the-art pose estimators suffer severe performance drop on cor-(2) Models are generally more robust to rupted images. brightness and weather changes, while less robust to motion and zoom blur. (3) The model robustness would increase by increasing model capacity.
Empirical evaluations on the proposed benchmarks help us screen a collection of useful data augmentation tech-niques to improve model robustness under severe corrup-tions.
In order to make full use of these techniques and achieve optimal performance on unforeseen noisy data, we propose an augmentation generator, which learns to au-tomatically combine augmented images. Speciﬁcally, we jointly train two neural networks in an adversarial manner, i.e. an augmentation generator and a human pose estimator.
The generator produces weights to mix up randomly aug-mented images, while the pose estimator attempts to learn robust visual representation from harder training samples.
It is worth noting that the compositions produced by the augmentation generator may drift far from original images and such induced noise patterns may be harmful to perfor-mance on clean data. To reduce this negative impact, we propose to use a pre-trained teacher pose estimator to trans-fer structure knowledge learned from entire clean training data towards the target human pose estimator. Different from previous knowledge distillation methods that use a stronger network as the teacher model, our teacher pose es-timator shares the same architecture as the target pose esti-mator. Extensive evaluations demonstrate that AdvMix sig-niﬁcantly improves model robustness on diverse image cor-ruptions while maintaining performance on clean data. The augmentation generator and the teacher pose estimator are only used for training and will be discarded at the inference stage, and thus introducing no computational overhead at inference time. Meanwhile, as shown in Fig. 1, our method is model-agnostic and is proved to be effective for various state-of-the-art pose estimation models.
Our main contributions can be summarized as follows.
• We propose three robust benchmarks COCO-C, MPII-C, and OCHuman-C, and demonstrate that both top-down and bottom-up pose estimators suffer severe per-formance drop on corrupted images, drawing the com-munity’s attention to this problem.
• With extensive experiments, we have many interesting conclusions that would help improve the accuracy and robustness of future works.
• We propose a novel adversarial data augmenta-tion method together with knowledge distillation, termed AdvMix, which is model-agnostic and easy-to-implement. It signiﬁcantly improves the robustness of pose estimation models while maintaining or slightly improving the performance on the clean data, without extra inference computational overhead. 2.