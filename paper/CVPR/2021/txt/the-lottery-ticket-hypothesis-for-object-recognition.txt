Abstract
ResNet-18 on COCO
Recognition tasks, such as object recognition and key-point estimation, have seen widespread adoption in recent years. Most state-of-the-art methods for these tasks use deep networks that are computationally expensive and have huge memory footprints. This makes it exceedingly difﬁcult to deploy these systems on low power embedded devices.
Hence, the importance of decreasing the storage require-ments and the amount of computation in such models is paramount. The recently proposed Lottery Ticket Hypothe-sis (LTH) states that deep neural networks trained on large datasets contain smaller subnetworks that achieve on par performance as the dense networks. In this work, we per-form the ﬁrst empirical study investigating LTH for model pruning in the context of object detection, instance segmen-tation, and keypoint estimation. Our studies reveal that lottery tickets obtained from Imagenet pretraining do not transfer well to the downstream tasks. We provide guidance on how to ﬁnd lottery tickets with up to 80% overall spar-sity on different sub-tasks without incurring any drop in the performance. Finally, we analyse the behavior of trained tickets with respect to various task attributes such as object size, frequency, and difﬁculty of detection.
ResNet-50 on COCO
Figure 1: Performance of lottery tickets discovered using direct pruning for various object recognition tasks. Here we have used a Mask R-CNN model with ResNet-18 backbone (top) and ResNet-50 backbone (bottom) to train models for object detection, segmentation and human keypoint es-timation on the COCO dataset. We show the performance of the baseline dense network, the sparse subnetwork obtained by transferring ImageNet pre-trained “universal” lottery tickets, as well as the subnetwork obtained by task-speciﬁc pruning. Task-speciﬁc pruning outperforms the universal tickets by a wide margin. For each of the tasks, we can obtain the same performance as the original dense networks with only 20% of the weights. 1.

Introduction
Recognition tasks, such as object detection, instance segmentation, and keypoint estimation, have emerged as canonical tasks in visual recognition because of their intu-itive appeal and pertinence in a wide variety of real-world problems. The modus operandi followed in nearly all state-of-the-art visual recognition methods is the following: (i)
Pre-train a large neural network on a very large and di-verse image classiﬁcation dataset, (ii) Append a small task-speciﬁc network to the pre-trained model and ﬁne-tune the weights jointly on a much smaller dataset for the task. The
*Equal contribution. introduction of ResNets by He et al. [22] made the training of very deep networks possible, helping in scaling up model capacity, both in terms of depth and width, and became a well-established instrument for improving the performance of deep learning models even with smaller datasets [25]. As a result, the past few years have seen increasingly large neu-ral network architectures [35, 55, 47, 23], with sizes often exceeding the memory limits of a single hardware accel-erator. In recent years, efforts towards reducing the mem-ory and computation footprint of deep networks have fol-lowed three seemingly parallel tracks with common objec-tives: weight quantization, sparsity via regularization, and network pruning; Weight Quantization [24, 16, 44, 6, 30] 762
methods either replace weights of a trained neural network with lower precision or arithmetic operations with bit-wise operations to reduce the memory up to an order of magni-tude. Regularization approaches, such as dropout [45, 2] or
LASSO [48], attempt to discourage an over-parameterized network from relying on a large number of features and en-courage learning a sparse and robust predictor. Both quanti-zation and regularization approaches are effective in reduc-ing the number of weights in a network or the memory foot-print, but usually at the cost of increased error rates [20, 30].
In comparison, pruning approaches [28, 19] disentangle the learning task from pruning by alternating between weight optimization and weight deletion. The recently proposed
Lottery Ticket Hypothesis ·(LTH) [12] falls in this category.
According to LTH, an over-parameterized network con-tains sparse sub-networks which not only match but some-times even exceed the performance of the original network, all by virtue of a “lucky” random initialization before train-ing. The original paper was followed up with tips and tricks to train large-scale models under the same paradigm [15].
Since then, there has been a large, growing body of litera-ture exploring its nuances. Although some of these recent works have tried to answer the question – how well do the tickets transfer across domains [38, 37], when it comes to vision tasks – the buck stops at image classiﬁcation.
In this work, we aim to extend and explore the analysis of lottery tickets to fundamental visual recognition tasks of object detection, instance segmentation, and keypoint de-tection. Popular methods for such recognition tasks use a two-stage detection pipeline, with a supervised pre-trained convolutional neural network (ConvNet) backbone, a re-gion proposal network (RPN), and one or more region-wise task-speciﬁc neural network branches. Loosely speaking, a ConvNet backbone is the most computationally intensive part of the architecture, and pre-training is the most time-consuming part. Therefore, as part of this study, we ex-plore the following questions: (a) Are there universal sub-networks within the ConvNet backbone that can be trans-ferred to the downstream object recognition tasks? (b) Can we train sparser and more accurate sub-networks for each of the downstream tasks? And, (c) How does the behav-ior or properties of these sub-networks change with respect to the corresponding dense network? We investigate these questions under the dominant settings used in object recog-nition frameworks. Speciﬁcally, we use ImageNet [7] pre-trained ResNet-18 and ResNet-50 [22] backbones, Faster R-CNN [41] and Mask R-CNN [21] modules for object recog-nition on Pascal VOC [11] and COCO [31] datasets. Our contributions are as follows:
• We show that tickets obtained from ImageNet training don’t transfer to object recognition in case of COCO, i.e., there are no universal tickets in pre-trained Ima-geNet models that can be used for downstream recog-nition tasks without a drop in performance. This is in contrast with previous works related to ticket transfer in vision models [37, 38]. In case of smaller datasets such as Pascal VOC, we are able to ﬁnd winning tickets from ImageNet pre-training with upto 40% sparsity.
• With direct pruning, we can ﬁnd “task-speciﬁc” tick-ets with up to 80% sparsity for each of the datasets and backbones. We also investigate the efﬁcacy of methods introduced by [12, 38, 13, 42] such as iterative mag-nitude pruning, late resetting, early bird training, and layerwise pruning in the context of object recognition.
• Finally we analyse the behavior of tickets obtained for object recognition tasks, with respect to various task attributes such as object size, frequency, and difﬁculty of detection, to make some expected (and some sur-prising) observations. 2.