Abstract
Data augmentation has become a de facto component for training high-performance deep image classiﬁers, but its potential is under-explored for object detection. Not-ing that most state-of-the-art object detectors beneﬁt from
ﬁne-tuning a pre-trained classiﬁer, we ﬁrst study how the classiﬁers’ gains from various data augmentations trans-fer to object detection. The results are discouraging; the gains diminish after ﬁne-tuning in terms of either accuracy or robustness. This work instead augments the ﬁne-tuning stage for object detectors by exploring adversarial exam-ples, which can be viewed as a model-dependent data aug-mentation. Our method dynamically selects the stronger adversarial images sourced from a detector’s classiﬁcation and localization branches and evolves with the detector to ensure the augmentation policy stays current and relevant.
This model-dependent augmentation generalizes to different object detectors better than AutoAugment, a model-agnostic augmentation policy searched based on one particular de-tector. Our approach boosts the performance of state-of-the-art EfﬁcientDets by +1.1 mAP on the COCO object de-tection benchmark. It also improves the detectors’ robust-ness against natural distortions by +3.8 mAP and against domain shift by +1.3 mAP. 1.

Introduction
Deep neural networks (DNNs) are powerful tools for vi-sual representation learning. As the training data grows in size and diversity, DNNs keep up the pace and achieve un-precedented performance on a wide range of benchmarked tasks [13, 31, 30, 24, 12, 29]. The learned representa-tions also demonstrate good transferability to downstream tasks for which there is often a small amount of curated data. This pre-training and then ﬁne-tuning paradigm is one of the crucial enablers for state-of-the-art object de-tectors [32, 11, 30, 20, 22]. In this paper, we aim to en-hance this learning paradigm for training not only accurate but also robust object detectors.
*Work done during an internship at Google.
Figure 1. Top: Det-AdvProp improves object detectors’ accuracy on clean images. Our model correctly detects some objects (e.g.,
“spoon” and “knife”) missed by the vanilla detector trained with-out Det-AdvProp. Middle: Det-AdvProp improves the detectors’ robustness against natural corruption. The vanilla detector misses
“bowl” and “oven” and produces a false positive for “person” af-ter the image is corrupted by motion blur. Bottom: Det-AdvProp improves robustness against cross-dataset domain shift. We can successfully detect the “potted plants” behind the “cat” from an image out of the dataset for training. (best viewed in color).
We ﬁrst revisit the role of pre-training in object detec-tion, given He et al.’s study [11] about vanilla ImageNet [5] pre-training and yet the new advances in data-augmented
ImageNet pre-training [36, 34]. We examine both the ac-curacy and robustness of the detectors. In the study with the top-performing EfﬁcientDet detectors [33], we ﬁnd that the performance gains for ImageNet classiﬁcation, brought 16622
by advanced data augmentation methods in pre-training, di-minish after ﬁne-tuning regardless of the detectors’ accu-racy or robustness. This observation motivates us instead to investigate ﬁne-tuning, the second stage in the paradigm for training object detectors.
Our high-level idea is to reposition the recently devel-oped data augmentations from the pre-training stage to ﬁne-tuning. We ﬁrst study AutoAugment [43] in the object de-tector ﬁne-tuning because its policy is purposely searched for augmenting object detectors’ training. However, exper-iments reveal that AutoAugment fails to provide consistent improvements to the detectors we studied, probably because it was searched based on only one object detector and one dataset, limiting its generalization ability.
In light of the lessons above, we switch to the model-dependent data augmentation of AdvProp [34] for ﬁne-tuning object detectors. AdvProp uses adversarial exam-It employs ples to improve image classiﬁcation models. separate batch normalization layers for the clean training images and the adversarial examples to accommodate their distinct statistics. Unlike AutoAugment or many other aug-mentation methods, AdvProp can dynamically evolve with the primary model during training to ensure the augmenta-tion is up to date.
We improve AdvProp to ﬁt it into the object detection
ﬁne-tuning (denoted by Det-AdvProp). Previous works show that detectors beneﬁt from shape cues [8], and adver-sarial examples help CNNs learn shape-related representa-tions [40]. There are two sources to generate adversarial its classiﬁcation head and its examples using a detector: localization head. We conduct a local comparison at each training iteration to identify the source that is more “adver-sarial” than the other, which is then selected to augment the training data. We show that this local comparison is crucial.
Straightforwardly aggregating the two sources gives rise to weak adversarial examples because some of the adversarial gradients mutually conﬂict [38]. Another alternative, keep-ing both and separating them to different batch normaliza-tion layers, incurs a too strong regularization to the detector, leading to low accuracy, albeit high robustness.
We report the following main ﬁndings in this paper. Al-though the pre-training stage remains more effective for ob-ject detection than random initialization under a reasonable computing budget (we run the ﬁne-tuning for up to 300 epochs on the COCO object detection dataset [21]), the performance gain at the pre-training-stage diminishes after
ﬁne-tuning, regardless of any strong data augmentations for the pre-trained backbone. Instead, we demonstrate that it is more promising to incorporate advanced data augmen-tations into ﬁne-tuning. Our Det-AdvProp boosts state-of-the-art EfﬁcientDets’ accuracy by 0.3–1.1 mAP, robustness to natural corruption by 0.8–3.8 mAP, and robustness to do-main shift by 0.2–1.3 mAP (illustrated in Figure 1). Fi-nally, we see that our model-dependent Det-AdvProp sub-stantially outperforms the model-agnostic AutoAugment in object detection under various settings. 2.