Abstract
Face detection is a fundamental problem for many down-stream face applications, and there is a rising demand for faster, more accurate yet support for higher resolution face detectors. Recent smartphones can record a video in 8K resolution, but many of the existing face detectors still fail due to the anchor size and training data. We analyze the failure cases and observe a large number of correct pre-dicted boxes with incorrect conﬁdences. To calibrate these conﬁdences, we propose a conﬁdence ranking network with a pairwise ranking loss to re-rank the predicted conﬁdences locally within the same image. Our conﬁdence ranker is model-agnostic, so we can augment the data by choosing the pairs from multiple face detectors during the training, and generalize to a wide range of face detectors during the testing. On WiderFace, we achieve the highest AP on the single-scale, and our AP is competitive with the previous multi-scale methods while being signiﬁcantly faster. On 8K resolution, our method solves the GPU memory issue and allows us to indirectly train on 8K. We collect 8K resolution test set to show the improvement, and we will release our test set as a new benchmark for future research. 1.

Introduction
Face detection is a long-standing research topic in com-puter vision. Many important downstream applications need to build on top of it, including face reconstruction, face tracking and face recognition, etc. Thanks to Convo-lution Neural Network, face detection has been improved signiﬁcantly in the past few years. However, as the camera hardware is evolving, the demand for an even faster, more accurate, and support for higher resolution in face detector is rising. Recent smartphones (Samsung Galaxy S20 Ultra,
Xiaomi MI 10 Pro) can capture a 108MP image and record a video in 8K resolution. We believe that 8K resolution will be practical in the near future, but a lot of existing works
[40, 13, 33, 72] still fail on many 8K resolution inputs.
The main reasons for failure are anchor size and training data. Most of the anchors are designed for the most pop-ular face detection dataset, WiderFace [63] which only has an image width of 1024. The common largest anchor size is 512 [40, 13, 33, 72], so the detector has to predict up to 7K residuals. While predicting such large residuals is hard, but possible, the classiﬁer has never seen such large reso-lution in the training set and it will almost always suppress all these boxes. Collecting 8K training data is expensive be-cause a single image could contain hundreds of faces (Fig. 1). Designing a large anchor requires the network to be deep enough to output multiple scales up to 8K, but BFBox
[39] shows that the average precision (AP) decreases when the network becomes deeper. While down-sampling the im-age allows the detector to ﬁnd a large face, the small face could be reduced to just 1 pixel (Fig. 1). We also found that 48GB GPU memory is not enough to train RetinaFace [13] on 8K resolution. As there are many challenges in 8K face detection, multi-scale [26] is perhaps the most reasonable workaround by predicting the small faces in 8K, and the large faces in the smaller resolution, then fuse them together with box voting [16]. However, this approach still relies on the correct conﬁdence as the majority of the high conﬁdence boxes will determine the result. Multi-scale also decreases the 8K prediction speed (which is already severely slow) to become much slower than a single-scale.
We analyze the fail cases and found that most of the cor-rect box locations have already existed because many detec-tors predict a large number of boxes, but the conﬁdences are very low. To systematically test these boxes, we replace the prediction conﬁdence with the intersect-over-union (IoU) between the predicted box and the closest ground truth box and call it: oracle conﬁdence. Fig. 2 shows that the oracle prediction has a consistently high AP on WiderFace valida-tion set across multiple resolutions, and by testing only on a single-scale, it can outperform the state-of-the-art [40] by a large margin (AP Hard: 93.3% vs 98.4%). On our col-lected FFHQ [30] dataset, AP could even be increased from 16.2% to 96.5%. We saw the possibility of closing the gap between the predicted and oracle conﬁdence. Since we can use the oracle conﬁdence as ground truth, we formulate this conﬁdence reﬁnement problem as supervised learning.
We initially try to learn a regressor that takes an image and face detector’s output as input to predict the new con-11674
Figure 1. (Best viewed electronically) Examples of our 8K test set. The ﬁrst two images contain both large and small faces. Detecting on the large resolution will fail the large face due to the small anchor size and the training data. Down-sampling will cause the small faces to be too small to detect. Last two images contain a large amount of small faces that are expensive to label.
ﬁdence, then pass them into NMS. This, however, does not improve AP because regressing to the exact ﬂoating point is challenging. The conﬁdences of the boxes around the face boundary could be only 10−4 different from each other, and a very small regression error can signiﬁcantly change the conﬁdence order, and thus changing the outcome of the non-maximal suppression (NMS). Since NMS is a greedy technique that is only affected by the order of the conﬁ-dence, we propose to relax the problem from regression to local ordinal ranking where we only need to rank the re-ﬁned conﬁdences within the same image and we can ignore the magnitude of the conﬁdence. We use a pairwise ranking loss to enforce such constraint, and we show that our ranker learns to preserve the order of conﬁdence and improve AP.
We propose a conﬁdence ranking network by taking the bounding box and conﬁdence prediction from a face detec-tor to output new reﬁned conﬁdences. On top of Feature
Pyramid Network (FPN [36]), we add a Box Processing
Network (BPN) to extract features from the face detector’s output and interpolate them to concatenate with the image feature, then pass them into our conﬁdence module. Fig. 3 demonstrates our pipeline. We design our network to be model-agnostic, so in theory, it can be used with any object detector, as long as the outputs are bounding boxes and their corresponding conﬁdence values, and we show the gener-alization on three face detectors including HAMBox [40],
RetinaFace [13], and HRNet [61]. Model-agnostic design is important for a fair comparison with multi-scale which is the de facto post-processing for modern face detectors in order to get high AP, with the cost of slow speed. Since our network only needs a single-scale to run, we are a few times faster than those state-of-the-arts [40, 13] with multi-scale, while still retain a competitive AP on WiderFace. On a single-scale, our method is the new state-of-the-art. Fur-thermore, our method allows us to solve the GPU memory issue and indirectly train on 8K (it would otherwise not be possible even with 48GB GPU memory) by backpropagat-ing up until the 8K prediction from the face detector. We then collect 8K test set to demonstrate the effectiveness of our method and set up a new benchmark for future camera hardware. To summarize, our main contributions are: 1. We propose to reﬁne conﬁdence in a local relative set-ting with our ranking loss, in contrast to existing works that regress to the absolute value in a global manner, inspired by the failure case analysis on WiderFace val-idation set and our collected FFHQ dataset. 2. We propose a conﬁdence ranking network to achieve the new state-of-the-art on the single-scale face detec-tor. Our AP is competitive with the previous multi-scale state-of-the-art [40] while remaining a few times faster. Our network is model-agnostic and we show the generalization on HAMBox [40], RetinaFace [13], and
HRNet [61] respectively. 3. Our method solves the GPU memory issue and allows us to indirectly train on 8K resolution to further in-crease AP. We collect 8K resolution test set to show the improvement, and we will release our test sets as a new benchmark for future camera hardware. 2.