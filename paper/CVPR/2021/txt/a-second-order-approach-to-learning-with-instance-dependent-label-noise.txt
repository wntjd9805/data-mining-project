Abstract
The presence of label noise often misleads the training of deep neural networks. Departing from the recent litera-ture which largely assumes the label noise rate is only deter-mined by the true label class, the errors in human-annotated labels are more likely to be dependent on the difﬁculty lev-els of tasks, resulting in settings with instance-dependent label noise. We ﬁrst provide evidences that the heteroge-neous instance-dependent label noise is effectively down-weighting the examples with higher noise rates in a non-uniform way and thus causes imbalances, rendering the strategy of directly applying methods for class-dependent label noise questionable. Built on a recent work peer loss
[24], we then propose and study the potentials of a second-order approach that leverages the estimation of several covariance terms deﬁned between the instance-dependent noise rates and the Bayes optimal label. We show that this set of second-order statistics successfully captures the in-duced imbalances. We further proceed to show that with the help of the estimated second-order statistics, we iden-tify a new loss function whose expected risk of a classiﬁer under instance-dependent label noise is equivalent to a new problem with only class-dependent label noise. This fact allows us to apply existing solutions to handle this better-studied setting. We provide an efﬁcient procedure to es-timate these second-order statistics without accessing ei-ther ground truth labels or prior knowledge of the noise rates. Experiments on CIFAR10 and CIFAR100 with syn-thetic instance-dependent label noise and Clothing1M with real-world human label noise verify our approach. Our im-plementation is available at https://github.com/
UCSC-REAL/CAL. 1.

Introduction
Deep neural networks (DNNs) are powerful in reveal-ing and ﬁtting the relationship between feature X and la-bel Y when a sufﬁciently large dataset is given. However, the label Y usually requires costly human efforts for ac-curate annotations. With limited budgets/efforts, the re-sulting dataset would be noisy, and the existence of label noise may mislead DNNs to learn or memorize wrong cor-relations [10, 11, 35, 38, 47]. To make it worse, the la-bel noise embedded in human annotations is often instance-dependent, e.g., some difﬁcult examples are more prone to be mislabeled [34]. This hidden and imbalanced distribu-tion of noise often has a detrimental effect on the training outcome [15, 23]. It remains an important and challenging task to learn with instance-dependent label noise.
Theory-supported works addressing instance-dependent label noise mostly rely on loss correction, which re-Recent work has quires estimating noise rates [40]. also considered the possibility of removing the depen-dency on estimating noise rates [5]. The proposed so-lution uses a properly speciﬁed regularizer to eliminate the effect of instance-dependent label noise. The com-mon theme of the above methods is the focus on learn-ing the underlying clean distribution by using certain forms of ﬁrst-order statistics of model predictions. In this paper, we propose a second-order approach with the assistance of additional second-order statistics and explore how this information can improve the robustness of learning with instance-dependent label noise. Our main contributions summarize as follows. 1. Departing from recent works [5, 24, 27, 29, 32, 40, 42] which primarily rely on the ﬁrst-order statistics (i.e. ex-pectation of the models’ predictions) to improve the ro-bustness of loss functions, we propose a novel second-order approach and emphasize the importance of using second-order statistics (i.e. several covariance terms) when dealing with instance-dependent label noise. 2. With the perfect knowledge of the covariance terms de-ﬁned above, we identify a new loss function that trans-forms the expected risk of a classiﬁer under instance-dependent label noise to a risk with only class-dependent label noise, which is an easier case and can be handled well by existing solutions. Based on peer loss [24], we further show the expected risk of class-dependent noise is equivalent to an afﬁne transformation of the expected 10113
risk under the Bayes optimal distribution. Therefore we establish that our new loss function for Covariance-Assisted Learning (CAL) will induce the same minimizer as if we can access the clean Bayes optimal labels. 3. We show how the second-order statistics can be esti-mated efﬁciently using existing sample selection tech-niques. For a more realistic case where the covariance terms cannot be perfectly estimated, we prove the worst-case performance guarantee of our solution. 4. In addition to the theoretical guarantees, the perfor-mance of the proposed second-order approach is tested on the CIFAR10 and CIFAR100 datasets with syn-thetic instance-dependent label noise and the Cloth-ing1M dataset with real-world human label noise. 1.1.