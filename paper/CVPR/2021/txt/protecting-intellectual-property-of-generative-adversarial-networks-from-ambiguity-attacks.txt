Abstract
Ever since Machine Learning as a Service emerges as a viable business that utilizes deep learning models to gener-ate lucrative revenue, Intellectual Property Right (IPR) has become a major concern because these deep learning mod-els can easily be replicated, shared, and re-distributed by any unauthorized third parties. To the best of our knowl-edge, one of the prominent deep learning models - Gener-ative Adversarial Networks (GANs) which has been widely used to create photorealistic image are totally unprotected despite the existence of pioneering IPR protection method-ology for Convolutional Neural Networks (CNNs). This pa-per therefore presents a complete protection framework in both black-box and white-box settings to enforce IPR pro-tection on GANs. Empirically, we show that the proposed method does not compromise the original GANs perfor-mance (i.e. image generation, image super-resolution, style transfer), and at the same time, it is able to withstand both removal and ambiguity attacks against embedded water-marks. Codes are available at https://github.com/ dingsheng-ong/ipr-gan. 1.

Introduction
Intellectual Property (IP) refers to the protection of cre-ations of the mind, which have both a moral and commer-cial value. IP is protected under the law framework in the form of, e.g. patents, copyright, and trademarks, which en-able inventors to earn recognition or ﬁnancial beneﬁt from their inventions. Ever since Machine Learning as a Service emerges as a viable business which utilizes deep learning (DL) models to generate revenue, different effective meth-ods to prove the ownership of DL models have been studied and demonstrated [1, 16, 25, 29, 30]. The application do-mains demonstrated with these pioneering works, however, are invariably limited to Convolutional Neural Networks (CNNs) for classiﬁcation tasks. Based on our knowledge, the protection for another prominent DL models, i.e. Gener-*Corresponding author, e-mail: cs.chan@um.edu.my
Noise, z ~ N (0,1)
Image Generation
Images, I e.g. LR image
Generative
Model
Super-resolution Style transfer
Trigger noise, ( f : z àxw ),  where c≠0
Trigger image, ( h: I àxw )
Generative
Model
Image Generation
Super-resolution Style transfer l a m r o
N d e s o p o r
P
Figure 1: Overview of our proposed GANs protection framework in black-box setting. The idea is when a trig-ger, xw is acted as an input, a watermarked image (e.g. with a hexagon as the watermark) will be synthesized to claim the ownership. Black area in the trigger noise (f : z → xw) indicates masked values (see Sec. 3.1.1, Eq. 1). ative Adversarial Networks (GANs) [5] that create plausible realistic photographs is missing all together and therefore urgently needed.
Generally, a common approach to deep neural network
IP protection is based on digital watermarks embedding methods which can be categorized into two schools: i) the black-box trigger-set based solutions [1, 30]; and ii) the white-box feature-based methods [3, 6, 25]. The principle of digital watermarking is to embed an identiﬁcation infor-mation (i.e. a digital watermark) into the network parame-ters without affecting the performances of original DL mod-els. In the former, the watermark is embedded in the input-output behavior of the model. The set of input used to trig-ger that behavior is called trigger set. The non-triviality of ownership of a watermarked model is constructed on the extremely small probability for any other model to exhibit the same behavior. In the latter, the watermark is embedded in the static content of CNNs (i.e. weight matrices) with a transformation matrix. The ownership is veriﬁed by the de-tection of the embedded watermarks.
For the veriﬁcation process, a suspicious online model will be ﬁrst remotely queried through API calls using a spe-ciﬁc input keys that were initially selected to trigger the 3630
Trained Model
DCGAN with X and b
DCGAN with X ′ and b′
SRGAN with X and b
SRGAN with X ′ and b′
BER 0.00 0.00 0.00 0.00
Table 1: Top row - Bit-error rate (BER) of the trained model using Uchida et al. method [1]. Bottom row - BER of the model using counterfeit watermark, b′ and optimized trans-formation matrix, X ′. DCGAN is trained on CIFAR10 dataset while SRGAN is trained on DIV2K dataset. watermark information. As such, this is a black-box ver-iﬁcation where a ﬁnal model prediction (e.g. image clas-siﬁcation results) is obtained. This initial step is usually performed to collect evidence from everywhere so that an owner can identiﬁes a suspected party who used (i.e. in-fringed) his/her models illegally. Once the owner has sufﬁ-cient evidence, the second veriﬁcation process which is to extract watermark from the suspected model and compare if the watermark is originated from the owner. This process is a white-box veriﬁcation, which means the owner needs to have to access the model physically, and usually this second step is gone through the law enforcement. 1.1. Problem Statement
Literally, both black-box and white-box schemes have been successfully demonstrated for CNNs [1,16,25,29,30], however it remains an open question to apply these protec-tion mechanisms to important GANs variants (see [5] for a survey). We believe, intuitively, the lack of protection might be i) partially ascribed to the large variety of GANs application domains, for which how to embed watermarks through appropriate regularization terms is challenging, and ii) directly applying the popular CNN-based watermarking approach (i.e. Uchida et al. [25]) on GANs has limitation in ambiguity attack as shown in Table 1. It is shown that the ownership is in doubt as indicated by the BER results1 (i.e. both the original b and forged b′ watermarks are detected). 1.2. Contributions
Thus, we are motivated to present a complete IP pro-tection framework for GANs as illustrated in Fig. 1. The i) we put forth a general IPR contributions are twofold: protection formulation with a novel regularization term Lw (Eq. 3) that can be generalized to all GANs variants; and ii) we propose a novel and complete ownership veriﬁcation method for different GANs variants (i.e. DCGAN, SRGAN and CycleGAN). Extensive experiments show that owner-ship veriﬁcation in both white and black box settings are ef-fective without compromising performances of the original 1In general, bit-error rate (BER) measures how much the watermark is deviated. BER=0 implies that the watermark is exactly the same as to original, so ownership is claimed. tasks (see Tables 3, 4, 5 and Fig. 6). At the same time, we tested the proposed method in both removal and ambiguity attacks scenario (see Tables 7-8 and Fig. 7-8). 2.