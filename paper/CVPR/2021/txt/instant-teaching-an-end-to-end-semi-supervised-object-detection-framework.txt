Abstract
Supervised learning based object detection frameworks demand plenty of laborious manual annotations, which may not be practical in real applications. Semi-supervised ob-ject detection (SSOD) can effectively leverage unlabeled data to improve the model performance, which is of great signiﬁcance for the application of object detection mod-In this paper, we revisit SSOD and propose Instant-els.
Teaching, a completely end-to-end and effective SSOD framework, which uses instant pseudo labeling with ex-tended weak-strong data augmentations for teaching during each training iteration. To alleviate the conﬁrmation bias problem and improve the quality of pseudo annotations, we further propose a co-rectify scheme based on Instant-Teaching, denoted as Instant-Teaching∗. Extensive experi-ments on both MS-COCO and PASCAL VOC datasets sub-stantiate the superiority of our framework. Speciﬁcally, our method surpasses state-of-the-art methods by 4.2 mAP on
MS-COCO when using 2% labeled data. Even with full su-pervised information of MS-COCO, the proposed method still outperforms state-of-the-art methods by about 1.0 mAP.
On PASCAL VOC, we can achieve more than 5 mAP im-provement by applying VOC07 as labeled data and VOC12 as unlabeled data. 1.

Introduction
Deep neural networks [24, 43, 19] have signiﬁcantly im-proved the performance of diverse computer vision appli-cations, e.g., image classiﬁcation and object detection. In order to avoid overﬁtting and achieve better performance, a large amount of accurate human-annotated data is needed to train a deep learning model. However, the assumption of having a sufﬁcient amount of accurate labeled data for training may not hold, especially for object detection tasks, which need annotations with accurate class labels and pre-cise bounding box coordinates. Thus, a natural idea is to leverage abundant unlabeled data to facilitate learning in the original task. To relax the dependency of manually labeled data, a promising approach is called semi-supervised learn-ing (SSL) [8].
SSL has recently received increasing attention from the community, since it provides effective methods of using un-labeled data to facilitate model learning with limited an-notated data. Most of the existing SSL methods focus on image classiﬁcation tasks and there are multiple strate-gies for semi-supervised learning, e.g., self-training [42, 52] and co-training [5, 35]. Recently, one popular line of re-search uses consistency losses for semi-supervised learn-ing [27, 37, 25, 48, 34, 41, 49, 51, 4, 3, 44]. They either adopt ensemble learning algorithms to enforce the predic-tions of the unlabeled data to be consistent across multi-ple models, or constrain the model predictions to be in-variant to noise. Another popular line of SSL research fo-cuses on more effective data augmentations to improve the generalization and robustness of the model, in which some learning-based and more complex data augmentation strate-gies [3, 51, 10, 4, 44] greatly improve the performance of
SSL on image classiﬁcation tasks.
Although semi-supervised learning has made great progress in the ﬁeld of image classiﬁcation, there is a paucity of literature focus on semi-supervised object detec-tion (SSOD). The recently proposed STAC [45] performs best among existing SSOD methods and outperforms the supervised model by a large margin, which is of great sig-niﬁcance to the research of SSOD. However, we ﬁnd that
STAC still has some problems. First, its training proce-dure is complicated and inefﬁcient. Before model train-ing, STAC needs to train a teacher model, and then it uses the teacher model to pre-generate pseudo annotations of unlabeled data. Second, during model training, the pre-generated pseudo annotations will no longer be updated, and the constant label will limit its performance. In this pa-per, to address the above two problems, we propose a novel end-to-end SSOD framework, Instant-Teaching, which uses instant pseudo labeling with extended weak-strong data augmentations for teaching during each training iteration.
Speciﬁcally, as shown in Fig. 1, during each training iter-4081
ation, Instant-Teaching will ﬁrst generate pseudo annota-tions of unlabeled data with weak data augmentations in a mini-batch, and then the predicted annotations will in-stantly be used as the ground-truth of the same image with strong data augmentations for training. The advantage of
Instant-Teaching is that as the model converges during train-ing, the quality of pseudo annotations will be improved in-stantly. The weak-strong data augmentation scheme is in-herited from STAC, which has been proven to be effective in combination with pseudo annotations, and we further ex-tend the strong data augmentations to include Mixup and
Mosaic. In addition, the conﬁrmation bias [48] is a common problem in SSL. To alleviate this issue, we further propose a co-rectify scheme based on Instant-Teaching, denoted as
Instant-Teaching∗. Instant-Teaching∗ simultaneously trains two models that have the same structure but share differ-ent weights and these two models help each other to rectify false predictions. During inference, we still only use a sin-gle model so that it does not increase inference time.
We test the efﬁcacy of Instant-Teaching∗ on PASCAL
VOC [14] and MS-COCO [31] datasets, and follow the experimental protocols used in the latest state-of-the-art
SSOD literature STAC [45] to evaluate the performance.
It is worth mentioning that, our Instant-Teaching∗ frame-work outperforms state-of-the-art methods at all experimen-tal protocols, and achieves state-of-the-art performance on semi-supervised object detection learning.
The contributions of this paper are as follows:
• We propose a novel SSOD framework, called Instant-Teaching, which uses instant pseudo labeling with ex-tended weak-strong data augmentations for teaching during each training iteration. Instant-Teaching is an end-to-end framework and can effectively leverage the unlabeled data.
• To alleviate the conﬁrmation bias problem and im-prove the quality of pseudo annotations, we fur-ther propose a co-rectify scheme based on Instant-Teaching, denoted as Instant-Teaching∗.
• Our extensive experiments on PASCAL VOC and MS-COCO datasets demonstrate the signiﬁcant efﬁcacy of our Instant-Teaching∗ framework. 2.