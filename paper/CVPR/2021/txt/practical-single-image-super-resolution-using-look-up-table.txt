Abstract
A number of super-resolution (SR) algorithms from in-terpolation to deep neural networks (DNN) have emerged to restore or create missing details of the input low-resolution image. As mobile devices and display hardware develops, the demand for practical SR technology has increased. Cur-rent state-of-the-art SR methods are based on DNNs for bet-ter quality. However, they are feasible when executed by using a parallel computing module (e.g. GPUs), and have been difﬁcult to apply to general uses such as end-user soft-ware, smartphones, and televisions. To this end, we propose an efﬁcient and practical approach for the SR by adopting look-up table (LUT). We train a deep SR network with a small receptive ﬁeld and transfer the output values of the learned deep model to the LUT. At test time, we retrieve the precomputed HR output values from the LUT for query
LR input pixels. The proposed method can be performed very quickly because it does not require a large number of
ﬂoating point operations. Experimental results show the ef-ﬁciency and the effectiveness of our method. Especially, our method runs faster while showing better quality compared to bicubic interpolation. 1.

Introduction
The goal of single-image super-resolution (SR) is to generate high-resolution (HR) results with sufﬁcient high-frequency details from the corresponding low-resolution (LR) input image. Interpolation based methods were dom-inant early on, where the missing pixel values were esti-mated by the weighted average of the nearby pixels with known values. Some examples of the interpolation based approach include bilinear, bicubic [19], and Lanczos. The methods are intuitive and fast, however, they hardly restore missing details as the same interpolation weights are ap-plied regardless of the image structure. As a result, the re-sults of interpolation based SR look overly blurry.
To create HR images with better quality, diverse ap-proaches have been proposed. Example based methods exploit a database of LR-HR image patch pairs generated from a number of external training images [3, 11, 10],
Figure 1. PSNR comparison on Set14 testset for ×4 SR and runtime is measured for generating 1280 × 720 out-put image on a Samsung Galaxy S7 smartphone (except for sparse coding based methods). We compare our method with several interpolation based methods (square), sparse coding based methods (triangle), and deep learning based methods (circle). Our methods show faster or comparable runtime compared to bicubic interpolation while achieving much better PSNR quality. or exploit self-similarity from a test image itself [12, 47].
One downside is that searching for the nearest neighbor patch is time consuming [5]. Sparse coding based meth-ods [48, 50, 42, 43], which learn a compact representation of the patches, have also been popular and showed promis-ing results. However, computing the sparse representation of the input patch requires a high computational cost.
As deep learning showed powerfulness in various com-puter vision tasks, attempts to use deep neural networks (DNN) for SR exploded [8, 20, 9, 22, 26, 2, 13, 53, 52, 44, 25, 36, 31, 33]. They achieve state-of-the-art SR perfor-mance in terms of peak signal-to-noise ratio (PSNR), how-ever, it comes with a number of multiplication operations from numerous convolutional layers. Therefore, a special parallel computing device such as graphic processing units (GPU) or tensor processing units (TPU) is essential to han-dle high computational complexity and memory consump-tion. The DNN based solutions are difﬁcult to apply in prac-tice without the special hardware, and this is one of the ma-691
jor obstacles for practical SR.
Despite the emergence of a variety of approaches for SR, the interpolation based methods are still commonly used as the base algorithm in image processing software such as
Photoshop, Matlab, and OpenCV, because they are simple and practical. While much effort has been made to improve the visual quality of SR, relatively little consideration has been paid for the feasibility of practical SR to be applied in end-user software and hardware like consumer cameras, surveillance cameras, mobile phones, and televisions which have a limited number of calculation units. Recently, run-ning deep models on mobile devices is becoming practical thanks to GPU attached mobile processors and many efforts in optimizations [16]. Still, as another line of study, it is im-portant to develop practical methods for more general situ-ations when GPUs are not available.
To this end, we propose a practical single-image SR method which runs faster or comparably compared to bicu-bic interpolation while achieving much better quality. We employ a look-up table (LUT) approach, which is com-monly used in embedded systems to accelerate computa-tion. For a complicated function or a series of computa-tions, if we compute output values once and put them in a
LUT, then all we need to do afterward is to just retrieve the values without performing the computation again. There-fore, LUTs are effective when the computation time is much longer than the memory access time. In image processing,
LUTs have long been used in a variety of color transfer tasks and within the standard proﬁles of the International Color
Consortium because of their excellence [34]. In addition,
LUTs have been used in camera imaging pipeline due to the hardware friendly property [17]. Similarly, LUTs can accelerate the overall runtime of an SR algorithm by just retrieving the precomputed outputs from the memory, be-cause a series of ﬂoating point operations is much slower than memory access.
In this paper, we train a deep SR network under certain constraints to map output values of the learned deep model to a LUT. We constrain the receptive ﬁeld (RF) of a deep SR network to be small (up to 4 pixels). With the small RF, we can compute all possible output values of the learned net-work as the output value is determined only depending on a small number of input values. After the training, the output values are saved into the LUT (up to 4D LUT, same as RF size). We name the built LUT as SR-LUT. In practice, our
SR-LUTs have uniformly sampled points of values. There-fore, at test time, we ﬁrst look-up the precomputed values of the nearby sampling points and they are properly merged by an interpolation technique for the ﬁnal output. In partic-ular, for the efﬁciency in 4D LUT, we extend the tetrahedral interpolation in 3D space to 4D. In Fig. 1, we compare our method with several SR methods. Compared to bicubic in-terpolation, our very fast and fast models with RF size 2 and 3 (Ours-V and Ours-F respectively) run faster and our slow model with RF size 4 (Ours-S) runs in comparable time, and all of our models achieve better PSNR value. Also, our methods have comparable PSNR values with faster speed than sparse coding based methods (triangle). Although deep learning based methods (circle) obviously achieve better ac-curacy, they have difﬁculty in achieving faster runtime be-yond a certain level, restricting their practical use.
In summary, the contributions of this paper are:
• We introduce a simple and novel method for fast and practical single-image SR by transferring input and out-put values from a learned deep SR model to a LUT (SR-LUT). To the best of our knowledge, this is the ﬁrst time to demonstrate the beneﬁts of LUTs for single-image SR.
• Our method is inherently faster because we just retrieve the precomputed values from the LUT on memory, in-stead of executing heavy computations composed of a large number of ﬂoating point multiplication and addition operations as in the previous SR methods. We verify the efﬁciency of our method in experiments on a smartphone, and our fast model runs faster than bicubic interpolation.
• Our method can be easily implemented on both software and hardware as a memory array, without a special com-puting module such as GPUs. We believe that this merit will enable our approach to be used in diverse practical
SR applications. 2.