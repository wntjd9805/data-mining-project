Abstract
We propose a learning method that, dynamically modi-ﬁes the time-constants of the continuous-time counterpart of a vanilla RNN. The time-constants are modiﬁed based on the current observation and hidden state. Our proposal overcomes the issues of RNN trainability, by mitigating ex-ploding and vanishing gradient phenomena based on placing novel constraints on the parameter space, and by suppress-ing noise in inputs based on pondering over informative inputs to strengthen their contribution in the hidden state. As a result, our method is computationally efﬁcient overcoming overheads of many existing methods that also attempt to improve RNN training. Our RNNs, despite being simpler and having light memory footprint, shows competitive per-formance against standard LSTMs and baseline RNN models on many benchmark datasets including those that require long-term memory. 1.

Introduction
We focus on trainability of vanilla Recurrent Neural Net-works1 (RNN). Improving vanilla RNN performance is im-portant since they are deployed in a number of IoT appli-cations [15] due to their light memory footprint. A funda-mental challenge is that, during training, the gradient of loss back-propagated in time could suffer from exponential de-cay/explosion resulting in poor generalization for processes exhibiting long-term dependencies (LTD).
There has been a long-line of work such as [12, 21, 2, 31, 10] that propose matrix designs, gating and novel archi-tectures, to mitigate gradient explosion/decay, and improve handling of state-transition. Different from these are works, which go back to [45, 18] that draw inspiration from ordi-nary differential equations (ODEs). [10] leverages stability theory of ODEs, to identify new transition matrices, and proposes discretization of ODEs, to improve trainability.
While we also draw upon ODEs to propose solutions to 1By vanilla RNNs we refer to networks that sequentially update their hidden state by means of a simple linear transformation of the previous state and current input, followed by non-linear activation. improve vanilla RNN trainability, our proposal differs from existing works in fundamental ways. To build intuition, ﬁrst consider the ODE, with λ ∈ R+, U ∈ RD×D, W ∈ RD×d, and A ∈ RD×D Hurwitz stable [28]:
λ˙z(t) = Az(t) + φ(Uz(t) + Wxm) (1) where, φ(·) is the conventional non-linear RNN activation function such as a ReLU; This particular form, serving as an analogue2 of vanilla RNNs, is quite old [45]. In each round, m, we start from an initial state, z(t0) = sm−1, which corresponds to the current hidden state, and input, xm, and evolve the ODE for a unit period of time. Subsequently, the hidden state is updated by setting sm = z(t0 + 1), and in this way, mapping inputs to the hidden state sequence.
What is new? We introduce two novel aspects within this context. First, we allow for λ to be time-varying, and in particular, a function of previous hidden state and input. Our reasoning is that λ serves as a time-constant, and inherently accounts for how long we evolve the ODE in response to the current input. To see this, let us write the ODE in integral form for a ﬁxed λ: sm , z(t0 + 1) = exp 1
λ (cid:19)
A (cid:18) sm−1+ 1 1
λ Z 0 exp
A (cid:18) 1 − t
λ (cid:19)
φ(Uz(t) + Wxm)dt (2)
Then, with λ → ∞, we deduce that, z(t0 + 1) → sm−1.
Namely, when time constant is large relative to integration time, we barely process the new input, remaining essen-tially at our previous solution. Alternatively, if λ → 0, namely, when the integration time is large relative to the time-constant, we reach equilibrium, and in this process strengthen inﬂuence of the current input. Moreover, by letting the time-constant be a function, of sm−1, xm, we selectively adapt the amount of “pondering” that we need on each new input. Finally, we let λ(·) take values in RD, and thus allow for element-wise dependence for each hidden state, leading to selective updates of hidden state compo-nents. These ideas result in a time-adaptive RNN (TARNN). 2Vanilla RNNs and residual variants amount to a suitable Euler dis-cretization (see Appendix). 115149
Next, we augment the current input with the hidden state, and consider um = [xm, sm−1]⊤ as a composite input in our ODE with initial condition, z(t0) = sm−1:
λ(um) ◦ ˙z(t) = Az(t) + Bum + φ(Uz(t) + Wum) (3) where ◦ represents the element-wise (Hadamard) product.
To build intuition into our ODE choice, observe from the ﬁrst term in Eq. 2 that for A stable, the contribution of the hidden state, sm−1 decays exponentially in time, and as such, the discrete transition process, s1, . . . , sT rapidly de-correlates.
We can overcome this effect by a persistent presence of the hidden state in the ODE. We also add the linear term, Bum, as it turns out to be important for improving partial gradient properties for hidden state sequence. As such our choice does not signiﬁcantly increase model complexity of vanilla
RNN.
Our proposed ODE is sufﬁciently rich admitting param-eter settings that completely eliminate gradient decay and explosion, which is desirable for LTD tasks. In addition, our method is capable of enhancing contribution from informa-tive inputs, while suppressing noisy segments through the pondering mechanism described above. This aspect is useful in IoT applications [31, 15] such as keyword detection and wearable sensing devices.
Discretization: For simplicity we discretize our ODEs with Euler discretization to realize vanilla RNNs. Methods that seek computational and memory efﬁciency in this con-text [11, 46] are entirely complementary to our method. Our novelty is in the design of state-transition with the goal of realizing desirable ODE solutions3.
Contributions: The main contributions of this work are
• TARNN learns to modulate time constants of transition function, allowing for selectively pondering on informative inputs to strengthen their contribution, and ignoring noisy inputs. This modiﬁcation along with designing suitable transition matrices yield lossless information propagation.
• TARNN improves trainability leading to better handling of LTD tasks with a lighter memory footprint, and as such our proposed method can be leveraged for IoT tasks.
• Our pseudo code is an RNN cell that is readily deployable in any deep learning library. We provide a simple imple-mentation at https://github.com/anilkagak2/TARNN.
• We conduct extensive experiments on benchmark datasets, and show that we improve upon standard LSTM perfor-mance as well as other recently proposed works. We also demonstrate robustness to time-series distortions such as noise paddings. 3[11, 46], also propose recurrent models to handle non-uniform input sampling. While this is interesting, their proposals are unrelated to our goal of improving RNN trainability. 2.