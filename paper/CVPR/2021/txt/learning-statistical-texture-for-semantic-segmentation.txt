Abstract
Existing semantic segmentation works mainly focus on learning the contextual information in high-level semantic features with CNNs. In order to maintain a precise bound-ary, low-level texture features are directly skip-connected into the deeper layers. Nevertheless, texture features are not only about local structure, but also include global sta-In this paper, we tistical knowledge of the input image. fully take advantages of the low-level texture features and propose a novel Statistical Texture Learning Network (STL-Net) for semantic segmentation. For the ﬁrst time, STL-Net analyzes the distribution of low level information and efﬁciently utilizes them for the task. Speciﬁcally, a novel
Quantization and Counting Operator (QCO) is designed to describe the texture information in a statistical manner.
Based on QCO, two modules are introduced: (1) Texture
Enhance Module (TEM), to capture texture-related infor-mation and enhance the texture details; (2) Pyramid Texture
Feature Extraction Module (PTFEM), to effectively extract the statistical texture features from multiple scales. Through extensive experiments, we show that the proposed STL-Net achieves state-of-the-art performance on three seman-tic segmentation benchmarks: Cityscapes, PASCAL Context and ADE20K. 1.

Introduction
Semantic segmentation aims to predict a label for each pixel in an image. It is one of the most fundamental prob-lems in computer vision, and is widely applied in a lot of areas such as automatic driving and human-machine inter-action.
Recent semantic segmentation methods mainly focus on exploiting the contextual information in high-level features with deep fully convolution based networks [23]. However, only using high-level features from deep layers results in
*The ﬁrst two authors contributed equally. Work done at SenseTime.
Lanyun Zhu ﬁrstly proposed the paper idea.
†Corresponding Author. (a) Structural Texture (b) Statistical Texture
Figure 1. Examples of the structural texture and statistical texture of a image. (a) shows the convolution ﬁlters of shallow layers and the corresponding extracted structural texture in typical CNN pipeline. (b) shows the original histogram, equalized histogram and image after statistical texture enhancement, respectively. coarse and inaccurate output, as they are extracted from a large receptive ﬁeld and miss some crucial low-level de-tails, such as edges. To alleviate this problem, people em-ploy skip connection to fuse low- and high-level features.
DeepLabv3+ [4] directly combines feature maps from shal-low layers and deep layers before feeding them into the pre-diction head. Some FPN-like methods [25, 19, 30] employ encoder-decoder structure with lateral path to reﬁne features in a top-down manner, where multi-scale boundaries are im-plicitly learned. SFNet [17] then applies a semantic ﬂow to align detailed object boundaries from different levels. All of them show that low-level local features in shallow CNN lay-ers provide the structural texture information, such as edge, which is essential for pixel-wise segmentation task.
From the perspective of digital image processing, im-age texture is not only about the local structural property, 12537
but also about global statistical property [9, 20, 10]. The structural one usually refers to some local patterns, such as boundary, smoothness and coarseness.
In a typical CNN pipeline, ﬁlters in the shallow layers are good at extracting these local texture features. When visualizing those ﬁlters, we can observe that different frequencies of the local signal are analyzed (Fig. 1(a)). Therefore, structural property is also referred to spectral domain analysis [9]. Another im-portant property of texture is statistical one. Based on some low-level information (such as pixel value or local region property), it focuses on the distribution analysis of the im-age, such as histogram of intensity. For example in Fig. 1(b), an image captured in dark environment is usually in poor-visualization quality. After the histogram equalization enhancement step, it turns to be more detailed and better for segmentation. Some traditional methods try utilizing statistical texture in their tasks [1, 24, 10]. However, there is no mechanism in modern CNN architecture to explicitly extract and utilize the statistical texture information for se-mantic segmentation. Therefore, in this paper, we propose a
Statistical Texture Learning Network (STLNet) to describe and exploit statistical texture information for this task.
Firstly, we propose a Quantization and Counting Opera-tor (QCO) to effectively describe texture intensities in a sta-tistical manner in deep neural networks. Speciﬁcally, statis-tical texture of the input image is usually of a wide variety and a continuous distribution in spectral domain, which is difﬁcult to extract and optimize in deep neural networks.
Thus in the QCO, we ﬁrst quantize the input feature into multiple levels. Each level can represent a kind of texture statistics, by which the continuous texture can be well sam-pled for easier description. After the quantization, the in-tensity of each level is then counted for texture feature en-coding.
Based on QCO, we further propose the Texture Enhance-ment Module (TEM) and Pyramid Texture Feature Extrac-tion Module (PTFEM), to enhance the texture details of low-level features and exploit texture-related information from multiple scales, respectively. More comprehensively, low-level features are usually of low qualities and difﬁcult for statistical features extraction.
Inspired by histogram equalization, TEM is designed to build a graph to propa-gate information of all original quantization levels for tex-ture enhancement. Furthermore, PTFEM exploits the tex-ture information from multiple scales with a texture feature extraction unit and pyramid structure.
Overall, our contributions are summarized as follows:
• For the ﬁrst time, we introduce the statistical texture information to semantic segmentation and propose a novel STLNet to take full advantage of texture infor-mation, where both low-level and high-level features are well learned in an end-to-end manner.
• For effective description of statistical texture in deep neural networks, a novel Quantization and Counting
Operator (QCO) is designed to quantize the continuous texture into multiple level intensities.
• With the help of QCO, we propose the Texture En-hancement Module (TEM) and Pyramid Texture Fea-ture Extraction Module (PTFEM) successively to en-hance the statistical details and extract the texture fea-tures, respectively.
• The proposed method is practical and can be imple-mented in a plug-and-play fashion. Experiments show that our method achieves state-of-the-art results on
Cityscapes, Pascal Context and ADE20K datasets. 2.