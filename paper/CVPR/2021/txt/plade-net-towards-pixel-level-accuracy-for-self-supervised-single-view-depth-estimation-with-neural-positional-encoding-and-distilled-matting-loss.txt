Abstract 1.

Introduction
In this paper, we propose a self-supervised single-view pixel-level accurate depth estimation network, called
PLADE-Net. The PLADE-Net is the ﬁrst work that shows remarkable accuracy levels, exceeding 95% in terms of the
δ1 metric on the challenging KITTI dataset. Our PLADE-Net is based on a new network architecture with neural positional encoding and a novel loss function that bor-rows from the closed-form solution of the matting Laplacian to learn pixel-level accurate depth estimation from stereo images. Neural positional encoding allows our PLADE-Net to obtain more consistent depth estimates by letting the network reason about location-speciﬁc image proper-ties such as projection (and potentially lens) distortions.
Our novel distilled matting Laplacian loss allows our net-work to predict sharp depths at object boundaries and more consistent depths in highly homogeneous regions. Our proposed method outperforms all previous self-supervised single-view depth estimation methods by a large margin on the challenging KITTI dataset, with unparalleled lev-els of accuracy. Furthermore, our PLADE-Net, naively extended for stereo inputs, outperforms the most recent self-supervised stereo methods, even without any advanced blocks like 1D correlations, 3D convolutions, or spatial pyramid pooling. We present extensive ablation studies and experiments that support our method’s effectiveness on the
KITTI, CityScapes, and Make3D datasets.
Recent advances in deep learning have shown state-of-the-art (SOTA) results on the challenging single-view depth estimation (SVDE) and stereo disparity estimation (SDE) tasks. In particular, self-supervised methods for SVDE have reached performance levels similar or even superior to the fully-supervised networks [16, 17, 14]. However, the previ-ous SOTA self-supervised methods are unable to predict ac-curate pixel-level depth estimates, which are often observed along the object’s depth boundaries. Predicting pixel-level accurate 3D geometries is essential for robotic grasping, augmented reality, navigation, and 3D object detection.
In this paper, we present a pixel-level accurate depth es-timation network (PLADE-Net) with neural positional en-coding and a distilled matting Laplacian loss, both of which allow for consistent depth estimates in homogeneous ar-eas and sharp depth predictions along the object bound-aries. Our PLADE-Net outperforms the most recent self-supervised SOTA methods [16, 17, 14, 41, 1] (both mono and stereo) by large margins, achieving unparalleled accu-racy on the challenging KITTI dataset while keeping a low number of parameters. This paper’s contributions are: 1. We propose to exploit and distill the closed-form solu-tion of the matting Laplacian [28] for self-supervision, leading to a novel loss function that allows for pixel-level
†Corresponding author. 16851
accuracy in self-supervised single- and stereo-view DE. 2. We show that neural positional encoding (NPE) can be usefully incorporated into CNNs for depth estimation, as it allows the network to reason about camera distortions, scene orientation, and non-local relationships. 3. We present PLADE-Net, a novel network architecture that incorporates NPE. Our PLADE-Net incorporates multi-scale inputs and a single-scale output, opposite to single-scale inputs and multi-scale outputs in previous works [11, 10, 16, 42]. Relative to previous works, our
PLADE-Net doubles the number of ﬁlter channels in the early feature extraction layers, and halves the number of
ﬁlter channels in its bottleneck. These seemingly triv-ial design choices, already make our PLADE-Net, even without our newly proposed loss functions, to outper-form the previous SOTA methods. 4. The PLADE-Net is the ﬁrst work that shows unmatched accuracy levels for SVDE, exceeding 95% in terms of δ1 metric on the challenging KITTI[9] dataset.
Figure 1 compares the depth estimate performances of the most recent SOTA methods [42, 16, 14] with respect to our PLADE-Net. As shown in the detailed view of the estimated depth regions (dotted boxes numbered from 1(cid:13) to 4(cid:13)), our PLADE-Net produces very precisely estimated depths along the object boundaries. Simultaneously, the
SOTA methods fail by yielding inaccurate object depths that partially leak into the background.
Our paper is organized as follows: In Section 2, we re-view relevant self-supervised methods for our work; Section 3 presents our PLADE-Net with neural positional encoding and a distilled matting Laplacian loss with in-depth expla-nations; In Section 4, we provide extensive ablation studies and experiments that support the effectiveness of our con-tributions; We conclude our work in Section 5. 2.