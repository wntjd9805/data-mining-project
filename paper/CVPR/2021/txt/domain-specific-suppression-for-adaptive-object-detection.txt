Abstract
Domain adaptation methods face performance degrada-tion in object detection, as the complexity of tasks require more about the transferability of the model. We propose a new perspective on how CNN models gain the transfer-ability, viewing the weights of a model as a series of mo-tion patterns. The directions of weights, and the gradients, can be divided into domain-speciﬁc and domain-invariant parts, and the goal of domain adaptation is to concentrate on the domain-invariant direction while eliminating the dis-turbance from domain-speciﬁc one. Current UDA object de-tection methods view the two directions as a whole while op-timizing, which will cause domain-invariant direction mis-match even if the output features are perfectly aligned. In this paper, we propose the domain-speciﬁc suppression, an exemplary and generalizable constraint to the original con-volution gradients in backpropagation to detach the two parts of directions and suppress the domain-speciﬁc one.
We further validate our theoretical analysis and methods on several domain adaptive object detection tasks, includ-ing weather, camera conﬁguration, and synthetic to real-world adaptation. Our experiment results show signiﬁcant advance over the state-of-the-art methods in the UDA object detection ﬁeld, performing a promotion of 10.2 12.2% mAP on all these domain adaptation scenarios.
∼ 1.

Introduction
Deep neural networks(DNN) has achieved a tremendous breakthrough at various computer vision tasks on public dataset, including classiﬁcation[21], object detection[12] and segmentation[7]. Nevertheless, most of these re-searches are based on the hypothesis that the training dataset and application scenarios have identical distribution, which is apparently impossible to satisfy in practice. Unsuper-vised domain adaptation(UDA) provides an alternative to (a) (b) (c)
Figure 1. Feature Distribution Sketches. (a) represents the orig-inal feature distributions of two different domains. Features in-side each domain’s inner circle represent those extracted by the domain-invariant part of the model; others are from the domain-speciﬁc part of the model. (b) shows an extreme common feature alignment method, with the overall distribution aligned while the domain-invariant part mismatched. (c) represents an ideal adapted distribution, with the domain-invariant part well-aligned without the intervention of domain-speciﬁc part solve the performance degradation caused by domain distri-bution mismatch problem[10] without the need for annota-tions on the target domain. We delved into the transferabil-ity of the model from the perspective on model-level expla-nation in the training process. We divided the weights and gradients of a model into two separate directions: domain-invariant and domain-speciﬁc. The former emphasizes the consistency between different domains for high-level tasks, and plays a crucial role in the transferability of a model. In contrast, the latter is the main obstacle to the transferabil-ity of a model, as it represents the unique features within a certain domain which have no concern with the tasks. In this way, an ideal domain adaptation method is expected to promote transferability by learning the domain-invariant weights while eliminating the domain-speciﬁc one.
Current research in UDA strives to align the distribu-tion of features extracted by the model with auxiliary ob-jective function measuring the discrepancy between them.
With the common goal, early research tries to measure and minimize the distance of features from different do-mains in a well-designed feature space, such as maxi-19603
mum mean discrepancy(MMD)[2], and Kullback-Leibler divergence(KL)[48]. With the introduction of GAN[14], methods that measure the discrepancy between domains by one or more discriminator distinguishing the origin of fea-tures spring up. Constraint to the feature-level explanation, such trail of study considers the domain-speciﬁc and the domain-invariant parts as a whole and optimizes them to-gether. However, all the similar distribution can guarantee is that the combinations of the domain-speciﬁc and domain-invariant part of the model for different domains are equiv-alent. Considering the disturbance of domain-speciﬁc part, the domain-invariant part of different domains may still be inconsistent even if the similarity condition is satisﬁed, as shown in Figure 1. The optima of domain adaptation is the alignment of domain-invariant part and the eradication of domain-speciﬁc part, as is illustrated in Figure 1. This is exactly the reason why current methods seem to be inefﬁ-cient or even ineffective when the high-level task becomes more complicated, such as object detection in this paper.
With the purpose of domain-invariant alignment, we pro-pose a novel domain-speciﬁc suppression (DSS) method.
We roughly estimate the domain-speciﬁc part of the gradi-ents with its projection on the direction of weights, and im-pose restrict to the gradients in the corresponding direction.
Such estimation relies on the fact that the overall proportion of domain-speciﬁc direction in weights is generally higher than that in gradients since the gradients are dominated by domain-speciﬁc deviation initially, and there is an updat-ing lag between the gradients and weights. The gradient will gradually converge to the domain-invariant optima with the constrain on domain-speciﬁc direction since both the domain-speciﬁc direction and the domain-invariant direc-tion can lead to their corresponding local optima for the ﬁ-nal task. Furthermore, we provide a special case of domain-speciﬁc suppression by normalizing the weight with its 2-Norm. Such simpliﬁcation can signiﬁcantly reduce the im-plementing consumption, making the domain-speciﬁc sup-pression a plug-and-play block to any architecture. With domain-speciﬁc suppression, we remove one key barrier to domain adaption tasks.
We evaluate our method on the Faster RCNN frame-work, ResNet-50 backbone on various datasets: Cityscapes,
Foggy Cityscapes, KITTI, and SIM10K, involving weather variance, camera conﬁguration changes and synthesize to real-world adaptations. We further implement additional experiments with the model pre-trained on the COCO2017 to illustrate the necessity of improving the model’s discrim-inability by pre-training on a large dataset in UDA detec-tion task. With DSS, we have outperformed state-of-the-art methods on all domain adaptation object detection tasks with various datasets. This achievement means that our methods have almost bridged the gap between two domains with a simple distribution mismatch. 2.