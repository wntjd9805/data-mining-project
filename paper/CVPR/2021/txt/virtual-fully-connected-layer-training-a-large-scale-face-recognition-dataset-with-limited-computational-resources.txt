Abstract
Recently, deep face recognition has achieved signiﬁ-cant progress because of Convolutional Neural Networks (CNNs) and large-scale datasets. However, training CNNs on a large-scale face recognition dataset with limited com-putational resources is still a challenge. This is because the classiﬁcation paradigm needs to train a fully-connected layer as the category classiﬁer, and its parameters will be in the hundreds of millions if the training dataset con-tains millions of identities. This requires many computa-tional resources, such as GPU memory. The metric learn-ing paradigm is an economical computation method, but its performance is greatly inferior to that of the classiﬁcation paradigm. To address this challenge, we propose a simple but effective CNN layer called the Virtual fully-connected (Virtual FC) layer to reduce the computational consump-tion of the classiﬁcation paradigm. Without bells and whis-tles, the proposed Virtual FC reduces the parameters by more than 100 times with respect to the fully-connected layer and achieves competitive performance on mainstream face recognition evaluation datasets. Moreover, the perfor-mance of our Virtual FC layer on the evaluation datasets is superior to that of the metric learning paradigm by a signiﬁcant margin. Our code will be released in hopes of disseminating our idea to other domains1. 1.

Introduction
Recently, deep face recognition with Convolutional Neu-ral Networks (CNNs) has achieved remarkable progress be-cause of the explosion of large-scale training datasets. Guo et al. [3] released a dataset with almost 100 thousand iden-tities in the academic ﬁeld. In the industrial ﬁeld, there are millions of identities used to train face recognition mod-els. For instance, the face dataset produced by Google in 2015 had 200 million images consisting of 8 million dif-1https://github.com/pengyuLPY/Virtual-Fully-Connected-Layer.git
Figure 1. Comparison between FC (a), Model Parallel (b), Partial
FC (c), and our Virtual FC (d). D is the dimension of features, N is the number of identities (categories), S is the number of GPUs, and M is a hyperparameter that can be set freely based on the balance between performance and computational resources. M = 1% × N in this paper. ferent identities [15]. A large-scale training dataset helps a model obtain excellent performance, but it also challenges face recognition training paradigms.
There are two elemental deep face recognition learning paradigms based on Convolutional Neural Networks [19].
One is learning with a classiﬁcation loss function (e.g., the softmax loss function or ArcFace loss function) to optimize the similarity between samples and weight vec-tors [20, 1, 11, 22]. This classiﬁcation paradigm has achieved state-of-the-art performance in face recognition
ﬁelds. However, it needs to train a fully-connected (FC) layer as the category classiﬁer, which leads to the follow-ing drawbacks: The FC layer is not necessary in inference, but it requires many computational resources in the training phase. Figure 2 shows that training on millions of identities requires the classiﬁcation FC layer to include hundreds of 432113315
Figure 2. The parameters of the face recognition network in the classiﬁcation paradigm. The FC layer requires considerable com-putational consumption, which may be even greater than the re-quirement of the backbone. The backbone is ResNet-101, and the feature dimension is 512 (D = 512) in this ﬁgure. millions of parameters. Its parameters are much greater than those of the feature extraction network. The dimensions of its output are also in the millions. The cost of the storage and calculation of the FC layer easily exceeds current GPU capabilities (leading to an out of memory error, OOM) and results in training failure. The other paradigm is to leverage a metric learning loss function (e.g., the N-pair loss func-tion or multi-similarity loss function) to optimize the simi-larity between samples [16, 18, 23, 19]. This paradigm ad-dresses the drawbacks of the classiﬁcation paradigm, but its performance is greatly inferior to that of the classiﬁcation paradigm [19, 16].
Some technologies aim to solve the OOM problem in the classiﬁcation paradigm with multiple GPUs, such as Model
Parallel [7] and Partial FC [28]. Both of these split the FC layer into several parts, and each part is distributed to a re-spective GPU, as shown in Figure 1(b) and (c). Their so-lutions can train the dataset with millions of identities if there are enough GPUs. Figure 1 shows that the parame-ters and GPU memory are distributed but not reduced in the solutions. Thus, the solutions require many GPUs, and it is impossible to work with limited computational resources (e.g., a single GPU). The challenge of training large-scale face recognition datasets with limited training resources is still far from being solved.
To address these problems, we propose a simple but ef-fective CNN layer called the Virtual fully-connected (Vir-tual FC) layer in this paper. The training pipeline of the
Virtual FC layer is illustrated in Figure 3. The pipeline splits
N training identities into M groups randomly. The identi-ties from group l share the l-th column in the projection matrix (W ). The l-th column is called anchorl. Because one group’s identities share the anchors, the number of W columns is reduced to M from N (M << N ). The number of parameters in our Virtual FC is detailed in Figure 1 (d), and it is much less than that of other methods. Furthermore, the number of anchors (M ) in our Virtual FC is a hyperpa-rameter that is not limited by the batch size or number of identities in the mini-batch. It can be set freely based on the balance between performance and computational resources.
To optimize W , whose anchors are shared by the groups, we propose two novel types of anchors to constitute W .
One is the corresponding anchor, and the other is the free anchor. If the mini-batch contains the identities from group l, anchorl belongs to the corresponding anchor and is es-timated by a weighted average function. Otherwise, it is a free anchor and is estimated by the Stochastic Gradient De-scent (SGD). The anchor type is adaptive in every training iteration.
The anchor would encounter conﬂict if the same group’s identities were sampled to the mini-batch simultaneously because they would need to share the same anchor in this iteration. The straightforward strategy that avoids sam-pling identities from the same group cannot work because it means that intra-group identities have no chance to be optimized discriminatively. To eliminate anchor conﬂict ef-fectively, we propose a re-grouping strategy in this paper.
Through our proposals, our Virtual FC layer can reduce the number of parameters by more than 100 times with respect to the FC layer and achieve competitive perfor-mance in typical face recognition evaluation datasets such as LFW [5], CFP [17], IJB-A [8], IJB-B [25], IJB-C [13], and MegaFace [6].
The main contributions of this paper can be summarized as follows: 1) To the best of our knowledge, we are the ﬁrst to pro-pose a solution for truly and signiﬁcantly reducing the pa-rameters in the classiﬁcation paradigm to train large-scale face recognition datasets with limited computational re-sources (e.g., a single GPU). 2) We propose the Virtual fully-connected (Virtual FC) layer to train large-scale datasets with limited computa-tional resources. The Virtual FC layer consists of corre-sponding anchors, free anchors, and a re-grouping strategy.
The two types of anchors make it possible to optimize a
W whose columns are shared by groups. The re-grouping strategy is used to eliminate anchor conﬂict. Furthermore, the proposed Virtual FC layer is compatible with accelera-tion by Data Parallel [7] with multiple GPUs. 3) Without bells and whistles, the proposed Virtual FC reduces the parameters by more than 100 times to the fully-connected layer and achieves competitive performance.
Moreover, the performance of our Virtual FC is superior to that of the metric learning paradigm by a signiﬁcant margin. 2.