Abstract
This paper introduces a new fundamental characteris-tic, i.e., the dynamic range, from real-world metric tools to deep visual recognition. In metrology, the dynamic range is a basic quality of a metric tool, indicating its ﬂexibil-ity to accommodate various scales. Larger dynamic range offers higher ﬂexibility.
In visual recognition, the multi-ple scale problem also exist. Different visual concepts may have different semantic scales. For example, “Animal” and
“Plants” have a large semantic scale while “Elk” has a much smaller one. Under a small semantic scale, two dif-ferent elks may look quite different to each other . However, under a large semantic scale (e.g., animals and plants), these two elks should be measured as being similar.
Introducing the dynamic range to deep metric learning, we get a novel computer vision task, i.e., the Dynamic Met-ric Learning.
It aims to learn a scalable metric space to accommodate visual concepts across multiple semantic scales. Based on three types of images, i.e., vehicle, an-imal and online products, we construct three datasets for
Dynamic Metric Learning. We benchmark these datasets with popular deep metric learning methods and ﬁnd Dy-namic Metric Learning to be very challenging. The major difﬁculty lies in a conﬂict between different scales: the dis-criminative ability under a small scale usually compromises the discriminative ability under a large one, and vice versa.
As a minor contribution, we propose Cross-Scale Learning (CSL) to alleviate such conﬂict. We show that CSL con-sistently improves the baseline on all the three datasets.
The datasets and the code will be publicly available at https://github.com/SupetZYK/DynamicMetricLearning. 1.

Introduction
This papers consider the deep metric learning for visual recognition and supplements it with an important concept in metrology, i.e., the dynamic range.
In metrology, the dynamic range is deﬁned as the ratio between the largest similar elks? dissimilar similar animals? similar
Figure 1. Visual concepts have various semantic scales, which im-pact on the similarity measuring result. Under the small scale of
“Elk”, these two elks look quite different. Under the large scale of
“Animal”, they should be measured as being similar. and the smallest scale that a metric tool can provide. It is a basic quality of a metric, indicating the ﬂexibility to ac-commodate various scales. We argue that such ﬂexibility is also important for deep metric learning, because differ-ent visual concepts indeed correspond to different seman-tic scales. However, after a rethink on current deep metric learning tasks, we ﬁnd that they all give NO consideration to the dynamic range. Therefore, we introduce the dynamic range to endow a single deep metric with ﬂexibility among multiple semantic granularities. Potentially, it may reveal a new perspective in understanding the generalization ability of deep visual recognition.
We explain the importance of “dynamic range” with a comparison between the deep metric learning and the real-world metric tools. In real world, a metric tool typically has a dynamic range. For example, a ruler has a lot of mark-ings to indicate different lengths ranged from “1 mm” to
“10 cm” or even to several meters. Rulers with only one single scale in “1 mm” or “10 cm” would have no use in daily life. Arguably, the dynamic range is essential to a met-ric tool, enabling it to measure objects of different sizes. In visual recognition, the visual concepts also have various se-mantic scales. For example, “Animals” and “Plants” have a large semantic scale, while “Elk” has a much smaller one.
When we try to measure the similarity between two images, which is the aim of metric learning, the underlying seman-tic scales impact on the result. In Fig. 1, the two elks look quite different to each other. However, under the large scale 5393
of “Animals”, they should be judged as being similar.
To sum up, this paper makes the following four contri-There is no consideration for the dynamic range in current deep metric learning tasks, e.g., face recognition
[30, 28, 5, 27, 34, 19, 12, 3], person re-identiﬁcation
[29, 37, 25, 23, 24], and vehicle re-identiﬁcation (re-ID)
[15, 7, 38, 39]. They all focus on learning a metric for a single speciﬁed semantic scale (e.g., the identity of face, pedestrian and vehicles, respectively). The single-scaled metric lacks ﬂexibility and may become inaccurate if the scale of interest changes. We validate this point with a toy scenario based on vehicle retrieval. In Fig. 2, two users use a same query image with different intentions. In the ﬁrst row, the intention is to retrieve the cars with the same iden-tity, while the second row is to retrieve the cars with the same body type (i.e., “SUV”). A discriminative metric for vehicle re-ID (which learns to identify each vehicle) sat-isﬁes the ﬁrst intention. With a similarity threshold T , it accurately separates the true matches and the false matches to the query image. However, it lacks discriminative ability for recognizing the same body type, which corresponds to a larger semantic scale than the identity. Maintaining T as the threshold, it fails to recall all the true matches. If we lower the similarity thresh hold to T ′ to promote the recall rate, the accuracy dramatically decreases (refer to Section 6.1 for experimental evidence). We thus infer that a single-scaled metric does not ﬁt novel semantic scales due to the lack of ﬂexibility.
Introducing the dynamic range to deep metric learn-ing, we get a new task, i.e., the Dynamic Metric Learning (DyML). DyML aims to learn a scalable metric space to accommodate multiple semantic scales. In another word, a metric for DyML should be discriminative under several semantic granularities across a wide range. To promote the research on DyML, we construct three datasets based on vehicle, animal and product, respectively. All these datasets have three different semantic scales, i.e., ﬁne, middle and coarse. We benchmark these datasets with a variety of pop-ular deep metric learning methods, e.g., Cosface [31], Cir-cle Loss [22], triplet loss [20], N-pair loss [21]. Extensive experiments show that DyML is very challenging. Even when the deep model learns from all the semantic scales in a multi-task manner, it does not naturally obtain a good dynamic range. The major difﬁculty lies in a conﬂict be-tween different scales: the discriminative ability under a small scale usually compromises the discriminative ability under a large one, and vice versa. To alleviate such conﬂict, we device a simple method named Cross-Scale Learning (CSL). CSL uses the within-class similarity of the smallest scale as the unique reference to contrast the between-class similarity of all the scales, simultaneously. Such learning manner is similar to the fact that all the markings on a ruler share “0” as the start. Experimental results conﬁrm that
CSL brings consistent improvement over the baselines. butions:
• We propose Dynamic Metric Learning by supplement-ing deep metric learning with dynamic range. In contrary to canonical metric learning for visual recognition, DyML de-sires discriminative ability across multiple semantic scales.
• We construct three datasets for DyML, i.e., DyML-Vehicle, DyML-Animal and DyML-Product. All these datasets contain images under multiple semantic granular-ities for both training and testing.
• We benchmark these DyML datasets with popular met-ric learning methods through extensive experiments. Exper-imental investigations show that DyML is very challenging due to a conﬂict between different semantic scales.
• As a minor contribution, we propose Cross-Scale
Learning for DyML. CSL gains better dynamic range and thus consistently improves the baseline. 2.