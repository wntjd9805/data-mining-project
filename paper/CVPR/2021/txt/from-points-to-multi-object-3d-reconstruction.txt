Abstract 1.

Introduction
We propose a method to detect and reconstruct multi-ple 3D objects from a single RGB image. The key idea is to optimize for detection, alignment and shape jointly over all objects in the RGB image, while focusing on realistic and physically plausible reconstructions. To this end, we propose a key-point detector that localizes objects as cen-ter points and directly predicts all object properties, in-cluding 9-DoF bounding boxes and 3D shapes – all in a single forward pass. The proposed method formulates 3D shape reconstruction as a shape selection problem, i.e. it selects among exemplar shapes from a given database. This makes it agnostic to shape representations, which enables a lightweight reconstruction of realistic and visually-pleasing shapes based on CAD-models, while the training objective is formulated around point clouds and voxel representa-tions. A collision-loss promotes non-intersecting objects, further increasing the reconstruction realism. Given the
RGB image, the presented approach performs lightweight reconstruction in a single-stage, it is real-time capable, fully differentiable and end-to-end trainable. Our experiments compare multiple approaches for 9-DoF bounding box esti-mation, evaluate the novel shape-selection mechanism and compare to recent methods in terms of 3D bounding box estimation and 3D shape reconstruction quality.
† Work performed during internship at Google Research, Zurich.
Extracting 3D information from a single image has mul-tiple applications in computer vision, robotics and scene un-derstanding, speciﬁcally on mobile AR/VR devices. Thus, this ﬁeld has gained great momentum in the computer vision community [10, 23, 31, 36, 46]. 3D information can come in many forms: 3D bounding boxes, point clouds, meshes, voxels or distance ﬁelds. The choice of the representation often depends on the task. In this paper, we aim to extract all the above information in an efﬁcient and scalable way, all from just a single view and in a single pass.
Recent methods [10, 23] perform multi-object recon-struction by independently processing detections from state-of-the-art object detectors [15, 24] or jointly predict multiple objects in a dense voxel grid [36], which can be computationally expensive due to scalability issues.
In-stead, inspired by CenterNet [51], a framework for accurate and efﬁcient 2D object detection, we propose to use a key-point detector to localize objects as sparse center-points and directly predict 9-DoF bounding boxes and shapes jointly for all objects in the scene. The CenterNet architecture is modular and can easily be extended to solve varying tasks such as 2D detection, 3D detection, human body pose es-timation and tracking [47, 50]. In this paper, we argue for a complete and coherent 3D reconstruction of multiple ob-jects using CenterNet where each pixel votes for a class la-bel, a 3D bounding box, and a 3D shape exemplar to place objects into the world coordinate frame. 4588
Figure 2: Overview of the proposed approach. Given a single RGB image, our model detects object centers as key-points in a heatmap Y .
The network directly predicts shape exemplars z and 9-DoF bounding boxes jointly for all objects in the scene. The collision loss Lcoll favors non-intersecting reconstructions. Our method predicts lightweight, realistic and physically plausible reconstructions in a single pass.
Another key question is the best shape representation.
While numerous representations have been proposed, e.g.
Signed Distance Functions (SDF) [33], meshes [10, 13], voxel grids [36], point clouds [7, 19], and even hybrid ap-proaches [39], all have their task-dependent advantages and disadvantages. In this work, we propose a representation-independent shape selection mechanism. That is, shape ex-emplars are selected from a given shape database that can implement different (or multiple) representations. The most convenient representation is chosen depending on the task at hand, be it for deﬁning objective functions or for visual-ization purposes (see Fig. 1).
Additionally, we take extra provisions for a realistic and physically plausible reconstruction.
In particular, objects should be properly placed in the world frame and should not intersect with each other. Inspired by recent methods on human body pose estimation in 3D scenes [14, 20, 49], we add a collision loss that supports plausible reconstructions such that reconstructed objects do not intersect. To summa-rize, given a RGB image, our single-stage method performs lightweight reconstruction, it is real-time capable, fully dif-In our experiments, ferentiable and end-to-end trainable. we compare different 9-DoF bounding box formulations, we evaluate our shape selection mechanism using soft labels and compare with the current state-of-the-art CoReNet [36].
Contributions. Our key contributions are:
• We propose a method for multi-object 3D reconstruc-tion that extends the CenterNet [51] framework to per-form fully holistic 3D scene reconstruction in a single-stage network and from a single RGB image.
• We present a shape-selection mechanism to perform 3D object reconstruction, where we reformulate the 1-of-K classiﬁcation task using soft labels based on geometric similarities between exemplar 3D shapes: this signiﬁcantly improves over hard-labels as used in previous baselines [42]. target
• We obtain physically plausible reconstructions by leveraging a collision loss that encourages non-intersecting reconstructions. Further, CAD based rep-resentations guarantee valid and realistic shapes.
• Our approach is agnostic to different shape represen-tations. Since we formulate the shape reconstruction problem as selecting a shape exemplar (i.e., index in a precomputed database of shapes), we can choose from any representation given the estimated shape exemplar. 2.