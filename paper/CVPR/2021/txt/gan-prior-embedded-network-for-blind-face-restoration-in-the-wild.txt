Abstract
Blind face restoration (BFR) from severely degraded face images in the wild is a very challenging problem. Due to the high illness of the problem and the complex unknown degradation, directly training a deep neural network (DNN) usually cannot lead to acceptable results. Existing genera-tive adversarial network (GAN) based methods can produce better results but tend to generate over-smoothed restora-tions. In this work, we propose a new method by ﬁrst learn-ing a GAN for high-quality face image generation and em-bedding it into a U-shaped DNN as a prior decoder, then
ﬁne-tuning the GAN prior embedded DNN with a set of synthesized low-quality face images. The GAN blocks are designed to ensure that the latent code and noise input to the GAN can be respectively generated from the deep and shallow features of the DNN, controlling the global face structure, local face details and background of the recon-structed image. The proposed GAN prior embedded net-work (GPEN) is easy-to-implement, and it can generate visually photo-realistic results. Our experiments demon-strated that the proposed GPEN achieves signiﬁcantly su-perior results to state-of-the-art BFR methods both quan-titatively and qualitatively, especially for the restoration of severely degraded face images in the wild. The source code and models can be found at https://github.com/ yangxy/GPEN . 1.

Introduction
Face images are among the most popular types of im-ages in our daily life, while face images are often degraded due to the many factors such as low resolution, blur, noise, compression, etc., or the combination of them. Face image restoration has been attracting signiﬁcant attentions, aiming at reproducing a clear and realistic face image from the de-graded input. Traditional face image restoration methods
∗This work is partially supported by the Hong Kong RGC RIF grant (R5001-18).
[50, 3, 2, 36] usually solve an inverse problem based on the degradation model and handcrafted priors, which demon-strate limited performance in practice. Recently, deep neu-ral networks (DNNs) have shown superior results in a vari-ety of computer vision tasks [24, 48, 13, 25, 30], and many
DNN based face restoration methods [49, 29, 16] have also been developed and they have demonstrated much better performance than traditional ones.
Though much progress has been made for face restora-tion, blind face restoration (BFR) remains a challenging research problem because of the unknown and complex degradation of low quality (LQ) face images in the wild.
In order to recover a high-quality (HQ) face image with photo-realistic textures from an LQ face image, a number of
BFR methods have been proposed by resorting to the spatial transformer networks [49], exemplar images [29, 28, 9], 3D facial priors [16], and facial component dictionaries [27].
Yang et al. [47] proposed a collaborative suppression and replenishment (CSR) approach to progressively replenish facial details. These methods exhibit impressive results on artiﬁcially degraded faces; however, they fail to tackle real-world LQ face images. The conditional generative adver-sarial network (cGAN) based methods such as Pix2Pix [18] and Pix2PixHD [43] learn a direct mapping from input im-age to output image. These methods achieve more realistic results but tend to over-smooth the images (see Figures 5 and 7), which is commonly blamed to the high illness of real-world BFR tasks.
With the rapid advancement of GAN techniques [21, 22], recently some methods have been proposed to reconstruct faces from extremely low resolution inputs [12, 34, 38].
Richardson et al.
[38] employed an encoder network to generate a series of style vectors before feeding them into a pre-trained generator, achieving a generic image-to-image translation framework. However, such methods can only work on non-blind image super-resolution problems. Fur-thermore, they kept the pre-trained GAN unchanged in training for the consistency and convenience of face ma-nipulations. This however leads to unstable quality of re-stored faces when dealing with real-world LQ face images 672
with complex background, because it is hard to accurately project a face image with limited resolution to a desired la-tent code (e.g., a vector of size 512 in StyleGAN [21, 22]).
In this work, we revisit the problem of BFR and target at restoring HQ faces from degraded face observations in the wild. Our idea is to seamlessly integrate the advantages of
GAN and DNN. We ﬁrst pre-train a GAN for HQ face im-age generation and embed it into a DNN as a decoder prior for face restoration. The GAN prior embedded DNN is then
ﬁne-tuned by a set of synthesized LQ-HQ face image pairs, during which the DNN learns to map the input degraded im-age to a desired latent space so that the GAN prior network can reproduce the desired HQ face images. We carefully design the GAN blocks to make them well suited for a U-shaped DNN, where the deep features are used to generate the latent code for global face reproduction, while the shal-low features are used as noise to generate local face details and keep the image background. In this way, our learned model can reconstruct HQ faces with photo-realistic details from even severely degraded face images in the wild, avoid-ing over-smoothed results caused by the high illness of the
BFR problem. Figure 1 shows an example. One can see that our model reconstructs the face images of those great scien-tists with clear details from the old photo taken in 1927.
The main contributions of this work are summarized as follows:
• We learn and embed a GAN prior network into a DNN, and ﬁne-tune the GAN embedded DNN for effective
BFR in the wild.
It is worthy to note that previous works only transfer the pre-trained GAN into a net-work without ﬁne-tuning.
• The GAN blocks are designed so that they can be eas-ily embedded into a U-shaped DNN for ﬁne-tuning.
The latent code and noise input of the GAN are respec-tively generated from the deep and shallow features of the DNN to reconstruct the global structure, local face details and background of the image accordingly.
• Our model sets new state-of-the-art in BFR. It is capa-ble of tackling severely degraded face images taken in real-world scenarios. 2.