Abstract
In this paper, we propose a Monocular 3D Single Stage object Detector (M3DSSD) with feature alignment and asymmetric non-local attention. Current anchor-based monocular 3D object detection methods suffer from fea-ture mismatching. To overcome this, we propose a two-step feature alignment approach. In the ﬁrst step, the shape alignment is performed to enable the receptive ﬁeld of the feature map to focus on the pre-deﬁned anchors with high
In the second step, the center align-conﬁdence scores. ment is used to align the features at 2D/3D centers. Fur-ther, it is often difﬁcult to learn global information and capture long-range relationships, which are important for the depth prediction of objects. Therefore, we propose a novel asymmetric non-local attention block with multi-scale sampling to extract depth-wise features. The pro-posed M3DSSD achieves signiﬁcantly better performance than the monocular 3D object detection methods on the
KITTI dataset, in both 3D object detection and bird’s eye view tasks. The code is released at https://github. com/mumianyuxin/M3DSSD. 1.

Introduction
Three-dimensional (3D) object detection enables a ma-chine to sense its surrounding environment by detecting the location and category of objects around it. Therefore, 3D object detection plays a crucial role in systems that inter-act with the real world, such as autonomous vehicles and robots. The goal of 3D object detection is to generate 3D
Bounding Boxes (BBoxes) parameterized by size, location, and orientation to locate the detected objects. Most exist-ing methods rely heavily on LiDAR [28, 32, 35, 34, 33], because LiDAR can generate point cloud data with high-precision depth information, which enhances the accuracy of 3D object detection. However, the high cost and short service life make it difﬁcult for LiDAR to be widely used in practice. Although binocular camera-based methods
[21, 30, 17, 11, 7] achieve good detection results, this is still not a cheap option, and there are often difﬁculties in calibrating binocular cameras. In contrast, the monocular camera is cost-effective, very easy to assemble, and can pro-vide a wealth of visual information for 3D object detection.
Monocular 3D object detection has vast potential for appli-cations, such as self-driving vehicles and delivery robots.
Monocular 3D object detection is an extremely challeng-ing task without the depth provided during the imaging pro-cess. To address this, researchers have made various at-tempts on the depth estimation from monocular images. For instance, [5, 2] utilize CAD models to assist in estimating the depth of the vehicle. Similarly, a pre-trained depth esti-mation model is adopted to estimate the depth information of the scene in [37, 1, 40]. However, such methods directly or indirectly used 3D depth ground-truth data in monocu-lar 3D object detection. Meanwhile, the methods [3, 12] without depth estimation can also achieve high accuracy in the 3D object detection task. In this paper, we propose a 3D object detector for monocular images that achieves state-of-the-art performance on KITTI benchmark [15].
Humans can perceive how close the objects in a monoc-ular image are from the camera. Why is that? When the hu-man brain interprets the depth of an object, it compares the object with all other objects and the surrounding environ-ment to obtain the difference in visual effect caused by the relative position relationship. For objects of the same size, the bigger, the closer from a ﬁxed perspective. Inspired by this, we propose a novel Asymmetric Non-local Attention
Block (ANAB) to compute the response at a position as a weighted sum of the features at all positions. Inspired by
[10, 46], we use both the local features in multiple scales and the features that can represent the global information to learn the depth-wise features. The multi-scale features can reduce computational costs. The attentive maps in multiple scales shows an explicit correlation between the sampling 6145
spatial resolution and the depth of the objects.
In one-stage monocular 3D object detection methods, 2D and 3D BBoxes are detected simultaneously. However, for anchor-based methods, there exists feature mismatching in the prediction of 2D and 3D BBoxes. This occurs for two reasons: (1) the receptive ﬁeld of the feature does not match the shape of the anchor in terms of aspect ratio and size; (2) the center of the anchor, generally considered as the center of the receptive ﬁeld for the feature map, does not overlap with the center of the object. The misalignment affects the performance of 3D object detection. Thus, we propose a two-step feature alignment method, aiming at aligning the features in 2D and 3D BBox regression. In the ﬁrst step, we obtain the target region according to the classiﬁcation con-ﬁdence scores for the pre-deﬁned anchors. This allows the receptive ﬁeld of the feature map to focus on the pre-deﬁned anchor regions with high conﬁdence scores. In the second step, we use the prediction results of the 2D/3D center to compute the feature offset that can mitigate the gap between the predictions and its corresponding feature map.
We summarize our contributions as follows:
• We propose a simple but very efﬁcient monocular 3D single-stage object detection (M3DSSD) method. The
M3DSSD achieves signiﬁcantly better performance than the monocular 3D object detection methods on the KITTI dataset for car, pedestrian, and cyclist ob-ject class using one single model, in both 3D object detection and bird’s eye view tasks.
• We propose a novel asymmetric non-local attention block with multi-scale sampling for the depth-wise feature extraction, thereby improving the accuracy of the object depth estimation.
• We propose a two-step feature alignment module to overcome the mismatching in the size of the receptive
ﬁeld and the size of the anchor, and the misalignment in the object center and the anchor center. 2.