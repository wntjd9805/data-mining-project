Abstract
Go to the  kitchen
Simultaneous localization and mapping (SLAM) remains challenging for a number of downstream applications, such as visual robot navigation, because of rapid turns, feature-less walls, and poor camera quality. We introduce the Differ-entiable SLAM Network (SLAM-net) along with a navigation architecture to enable planar robot navigation in previously unseen indoor environments. SLAM-net encodes a particle
ﬁlter based SLAM algorithm in a differentiable computa-tion graph, and learns task-oriented neural network com-ponents by backpropagating through the SLAM algorithm.
Because it can optimize all model components jointly for the end-objective, SLAM-net learns to be robust in challenging conditions. We run experiments in the Habitat platform with different real-world RGB and RGB-D datasets. SLAM-net signiﬁcantly outperforms the widely adapted ORB-SLAM in noisy conditions. Our navigation architecture with SLAM-net improves the state-of-the-art for the Habitat Challenge 2020 PointNav task by a large margin (37% to 64% success).
Project website: http:// sites.google.com/ view/ slamnet 1.

Introduction
Modern visual SLAM methods achieve remarkable per-formance when evaluated on suitable high-quality data [19].
However, in the context of downstream tasks, such as indoor robot navigation, a number of difﬁculties remain [8; 43; 12].
An imperfect navigation agent captures substantially differ-ent images from a human, as it may frequently face fea-tureless walls and produce rapid turns (see Fig. 1). Further, despite advances in sensor technology, modern robots still often use cameras with noisy images, low frame rate, and a narrow ﬁeld-of-view [32]. These factors make feature ex-traction and association difﬁcult. Relocalization and loop closure can be challenging due to environmental changes and repetitive feature. Finally, integrating SLAM into a navi-gation pipeline is not trivial, because the map representation must be suitable for downstream planning, it may need to capture task-dependent information, and planning must be able to handle map imperfections.
Figure 1: Visual robot navigation is challenging for SLAM, e.g., because the robot frequently faces featureless walls; it rotates quickly; the onboard camera produces noisy images; the frame rate is low; etc. The images were take by our navigation agent in the Habitat environment.
This paper introduces the Differentiable SLAM Net-work (SLAM-net) together with a navigation architecture for downstream indoor navigation. The key idea of SLAM-net is to encode a SLAM algorithm in a differentiable compu-tation graph, and learn neural network model components for the SLAM algorithm end-to-end, by backpropagating gradients through the algorithm. Concretely SLAM-net en-codes the particle ﬁlter based FastSLAM algorithm [44] and learns mapping, transition and observation models. SLAM-net ﬁlls a gap in the literature on differentiable robot algo-rithms [55; 23; 34; 35].
The beneﬁt of SLAM-net compared to unstructured learn-ing approaches is that its encoded particle ﬁlter provides a strong prior for learning. The beneﬁt over classic SLAM is that all components are learned, and they are directly optimized for the end-objective. Concretely, SLAM-net learns RGB and RGB-D observation models for the en-coded FastSLAM algorithm, which previously relied on hand-crafted models and lidar sensors. Further, because of the task-oriented learning, feature extractors can learn be more robust against domain speciﬁc challenges, e.g., faced with downstream navigation; while on the ﬂip side they may be less reusable across tasks.
We validate SLAM-net for localization with RGB and
RGB-D input, as well as downstream robot navigation in previously unseen indoor environments. We use the Habitat 2815
current obs.
RGB(D)
## last obs.	
##$! local map past local maps global map mapping  model
"#
"!..# observation model
% (#
$(Δ!#) transition  model
%
!!..#
;
% (#
K k=1 trajectory hypotheses particle weight particles
#
!
!
$"
" #
!$%
!!..# trajectory estimate
)# m r o f s n a r
T transformed  local maps
!# pose estimate
Figure 2: Differentiable SLAM-net. The global map is maintained by a collection of learned local grid maps. The trajectory is tracked by a particle ﬁlter. Particles represent trajectories and they are updated with learned neural network components: the mapping, transition, and observation models. simulation platform [52] with three real-world indoor scene datasets. We additionally experiment with the KITTI visual odometry data [20]. SLAM-net achieves good performance under challenging conditions where the widely used ORB-SLAM [46] completely fails; and learned models transfer over datasets. For downstream navigation we propose an architecture similar to Neural SLAM [10], but with using our differentiable SLAM-net module. Our approach signiﬁcantly improves the state-of-the-art for the CVPR Habitat 2020
PointNav challenge [25]. 2.