Abstract
Diabetic retinopathy (DR) is the leading cause of per-manent blindness in the working-age population. And au-tomatic DR diagnosis can assist ophthalmologists to design tailored treatments for patients, including DR grading and lesion discovery. However, most of existing methods treat
DR grading and lesion discovery as two independent tasks, which require lesion annotations as a learning guidance and limits the actual deployment. To alleviate this problem, we propose a novel lesion-aware transformer (LAT) for DR grading and lesion discovery jointly in a uniﬁed deep model via an encoder-decoder structure including a pixel relation based encoder and a lesion ﬁlter based decoder. The pro-posed LAT enjoys several merits. First, to the best of our knowledge, this is the ﬁrst work to formulate lesion discov-ery as a weakly supervised lesion localization problem via a transformer decoder. Second, to learn lesion ﬁlters well with only image-level labels, we design two effective mecha-nisms including lesion region importance and lesion region diversity for identifying diverse lesion regions. Extensive experimental results on three challenging benchmarks in-cluding Messidor-1, Messidor-2 and EyePACS demonstrate that the proposed LAT performs favorably against state-of-the-art DR grading and lesion discovery methods. 1.

Introduction
Diabetic retinopathy (DR) is one of the most severe com-plications of blood vessel damage triggered by diabetes, which can lead to vision impairment and even irreversible blindness [13, 6, 25]. Usually, as shown in Figure 1 (a), ophthalmologists identify DR severity based on the type and number of associated lesion symptoms, such as microa-neurysms, haemorrhages, soft exudates and hard exudates
[46, 22]. According to the international protocol [17, 35], the severity of DR can be divided into ﬁve grades, including normal, mild, moderate, severe non-proliferative, and pro-liferative. These ﬁve grades can also be fused into binary
∗Equal contribution
†Corresponding author
Haemorrhage
Exudate (a) (b) (c)
Referable DR
Figure 1: (a) A sample fundus image with different lesions is annotated. The arrows indicate the main DR-related le-sions, among which the yellow, red and blue arrows repre-sent haemorrhages, microaneurysms and exudates, respec-tively. (b) The lesion regions marked by the green bounding box in (a) are zoomed in, and we can observe that pixel ap-pearances of the same lesion region tend to be similar. (c)
Our model can achieve DR grading and lesion discovery jointly by using only the severity level labels. classiﬁcation, i.e. no DR (normal) versus DR (abnormal), or non-referable (normal and mild DR) versus referable (mod-erate and worse DR) [17, 34, 41].
Recently, with the development of deep learning, rapid and automatic DR diagnostic models have been proposed based on pixel-level supervision [46], or patch-level super-vision [41, 23, 40]. However, their ﬂexibility and scalability are limited in the actual deployment because the annotation of fundus images requires manual labeling by experienced domain experts [22, 27, 32]. In addition, the identiﬁcation of lesion regions in fundus images is also very important, since it provides visual instructions for ophthalmologists to assist their diagnosis [12, 26, 30]. However, most existing methods treat DR grading and lesion discovery as two in-dependent tasks, and they both require lesion annotations as a guide for learning. To overcome these issues, in [34], a weakly supervised learning model based on DR severity grades has been proposed for simultaneously grading DR and highlighting lesion regions. Unfortunately, it tends to be biased on the most important lesion regions while ig-noring trivial lesion information contained in the fundus images, which may impair the performance of lesion loca-tion. Furthermore, the less discriminating regions found at a certain severity level may be important for other severi-10938
ty grades. Therefore, it is desirable to design an effective model to obtain more complete lesion regions and their im-portance for DR grading.
Based on the above discussions, to achieve accurate DR grading and complete lesion discovery simultaneously, we need to consider the following three aspects. (1) As shown in Figure 1 (a), the distribution of lesion areas contained in fundus images is usually relatively sparse. Besides, the ap-pearance of pixels in the same lesion region is similar, but is different from the background pixels, as shown in Figure 1 (b). Therefore, it is necessary to model the correlation be-tween pixels for robust feature learning. (2) The importance of different lesion regions in each image should be consid-ered. The observation is that not all lesion information is beneﬁcial to a particular DR severity level, and even some lesion information is noise signal. Therefore, we should e-valuate and adaptively fuse the contribution of each lesion region. (3) As shown in Figure 1 (a), each fundus image may contain multiple different lesions. Moreover, even fun-dus images of the same severity grade may contain incon-sistencies in the type and number of lesions. Thus, it is de-sirable to make the lesion-aware features diverse, namely, capturing the corresponding lesion features from as many lesion regions as possible. Besides, since each region indi-cates a speciﬁc type of lesion or a combination of different lesions, the compactness of the lesion features should also be considered. In other words, the lesion features obtained from the same lesion ﬁlter are encouraged to approach each other to form a more compact distribution. In this way, each lesion region can suggest more explicit lesion semantics and different regions are combined to form a complete lesion discovery, as shown in Figure 1 (c).
Motivated by the above observations, we propose a nov-el lesion-aware transformer (LAT) for DR prediction and lesion discovery in a uniﬁed deep model via an encoder-decoder structure including a pixel relation based encoder
In the pixel relation and a lesion ﬁlter based decoder. based encoder, we propose a self-attention mechanism to adapt to pixel appearance variations. In speciﬁc, we model the correlation of pixels to capture full-image context in-formation. In other words, it is to realize the aggregation of lesion pixels with similar appearances and the suppres-In the lesion ﬁlter sion of cluttered background pixels. based decoder, we design a self-attention module and a cross-attention module to learn lesion-aware ﬁlters for le-sion discovery in a given dataset. In the self-attention mod-ule, we model the interactions between lesion ﬁlters to in-crease their discrepancies.
In the cross-attention module, given an input fundus image, we treat the pixels of feature map as keys and values. And we store each lesion ﬁlter as a query, then the corresponding region activation map based on the similarity between a speciﬁc query and keys can be obtained. Each lesion region activation map denotes the s-patial distribution of one speciﬁc lesion. With the region ac-tivation map, we can get the lesion-aware features by adap-tively blending values. Without the speciﬁc lesion informa-tion as supervision signals, it is difﬁcult to learn the lesion
ﬁlters well. Therefore, to learn lesion ﬁlters well with only the severity level labels, we design two mechanisms includ-ing a lesion region importance learning mechanism and a lesion region diversity learning mechanism to constrain the lesion-aware features. For the importance learning mecha-nism, we introduce an importance prediction module to e-valuate and adaptively fuse the contribution of each lesion region. For the diversity learning mechanism, we adopt a triplet loss based on the hard negative mining strategy to achieve the diversity and compactness of the lesion-aware features simultaneously. Then, based on the lesion-aware features, we add a classiﬁcation module containing a global consistency constraint loss for DR grading. By optimizing the encoder-decoder structure and the classiﬁcation module jointly, the lesion-aware ﬁlters can be learned through the whole dataset during training. As a result, we can achieve
DR prediction and lesion discovery in a uniﬁed deep model.
To sum up, the contributions of this work can be sum-marized as follows: (1) We propose a novel lesion-aware transformer (LAT) to achieve DR grading and lesion discov-ery jointly in a uniﬁed deep model via an encoder-decoder structure including a pixel relation based encoder and a le-sion ﬁlter based decoder. (2) To the best of our knowl-edge, this is the ﬁrst work to formulate lesion discovery as a weakly supervised lesion localization problem via a transformer decoder. To learn lesion ﬁlters well with on-ly image-level labels, we design two effective mechanism-s including lesion region importance and lesion region di-versity. (3) Extensive experimental results on three chal-lenging benchmarks including Messidor-1, Messidor-2 and
EyePACS demonstrate that the proposed LAT performs fa-vorably against state-of-the-art DR grading methods. 2.