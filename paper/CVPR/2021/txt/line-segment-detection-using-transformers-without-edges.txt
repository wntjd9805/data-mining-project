Abstract
In this paper, we present a joint end-to-end line seg-ment detection algorithm using Transformers that is post-processing and heuristics-guided intermediate processing (edge/junction/region detection) free. Our method, named
LinE segment TRansformers (LETR), takes advantages of having integrated tokenized queries, a self-attention mech-anism, and encoding-decoding strategy within Transform-ers by skipping standard heuristic designs for the edge ele-ment detection and perceptual grouping processes. We equip
Transformers with a multi-scale encoder/decoder strategy to perform ﬁne-grained line segment detection under a direct endpoint distance loss. This loss term is particularly suitable for detecting geometric structures such as line segments that are not conveniently represented by the standard bounding box representations. The Transformers learn to gradually reﬁne line segments through layers of self-attention. In our experiments, we show state-of-the-art results on Wireframe and YorkUrban benchmarks. 1.

Introduction
Line segment detection is an important mid-level visual process [22] useful for solving various downstream computer vision tasks, including segmentation, 3D reconstruction, im-age matching and registration, depth estimation, scene under-standing, object detection, image editing, and shape analysis.
Despite its practical and scientiﬁc importance, line segment detection remains an unsolved problem in computer vision.
Although dense pixel-wise edge detection has achieved an impressive performance [32], reliably extracting line seg-ments of semantic and perceptual signiﬁcance remains a further challenge. In natural scenes, line segments of inter-est often have heterogeneous structures within the cluttered background that are locally ambiguous or partially occluded.
Morphological operators [27] operated on detected edges
[3] often give sub-optimal results. Mid-level representations such as Gestalt laws [10] and contextual information [28] can
* indicates equal contribution.
Code: https://github.com/mlpc-ucsd/LETR. (a)
Image
Feature
Extractor
Refined
Proposals
Junctions
Line 
Segment
Proposals
LoI
Pooling
LoI Features
Line Segments (b)
Positional
Encoding
Backbone
Transformer
Encoder
Transformer
Decoder
FFN
FFN
FFN
Image
Line Segments
Figure 1. Pipeline comparison between: (a) holistically-attracted wire-frame parsing (HAWP) [34] and (b) our proposed LinE segment TRans-formers (LETR). LETR is based on a general-purpose pipeline without heuristics-driven intermediate stages for detecting junctions and generating line segment proposals. play an important role in the perceptual grouping, but they are often hard to be seamlessly integrated into an end-to-end line segment detection pipeline. Deep learning techniques
[16, 20, 14, 32] have provided greatly enhanced feature repre-sentation power, and algorithms such as [37, 33, 34] become increasingly feasible in real-world applications. However, systems like [37, 33, 34] still consist of heuristics-guided modules [27] such as edge/junction/region detection, line grouping, and post-processing, limiting the scope of their performance enhancement and further development.
In this paper, we skip the traditional edge/junction/region detection + proposals + perceptual grouping pipeline by de-signing a Transformer-based [29, 4] joint end-to-end line segment detection algorithm. We are motivated by the fol-lowing observations for the Transformer frameworks [29, 4]: tokenized queries with an integrated encoding and decoding strategy, self-attention mechanism, and bipartite (Hungarian) matching step, capable of addressing the challenges in line segment detection for edge element detection, perceptual grouping, and set prediction; general-purpose pipelines for
Transformers that are heuristics free. Our system, named
LinE segment TRsformer (LETR), enjoys the modeling power of a general-purpose Transformer architecture while having its own enhanced property for detecting ﬁne-grained geometric structures like line segments. LETR is built on top of a seminal work, DEtection TRansformer (DETR)
[4]. However, as shown in Section 4.4 for ablation stud-4257
ies, directly applying the DETR object detector [4] for line segment detection does not yield satisfactory results since line segments are elongated geometric structures that are not feasible for the bounding box representations.
Our contributions are summarized as follows.
• We cast the line segment detection problem in a joint end-to-end fashion without explicit edge/junction/region detection and heuristics-guided perceptual grouping pro-cesses, which is in distinction to the existing literature in this domain. We achieve state-of-the-art results on the
Wireframe [15] and YorkUrban benchmarks [5].
• We perform line segment detection using Transformers, based speciﬁcally on DETR [4], to realize tokenized entity modeling, perceptual grouping, and joint detection via an integrated encoder-decoder, a self-attention mechanism, and joint query inference within Transformers.
• We introduce two new algorithmic aspects to DETR [4]:
ﬁrst, a multi-scale encoder/decoder strategy as shown in
Figure 2; second, a direct endpoint distance loss term in training, allowing geometric structures like line segments to be directly learned and detected — something not feasi-ble in the standard DETR bounding box representations. 2.