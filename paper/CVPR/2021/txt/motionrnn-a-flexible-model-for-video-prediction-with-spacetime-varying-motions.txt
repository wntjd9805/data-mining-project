Abstract
ùë° = 1
ùë° = 2
ùë° = 3
ùë° = 4
ùë° = 5
This paper tackles video prediction from a new dimen-sion of predicting spacetime-varying motions that are inces-santly changing across both space and time. Prior methods mainly capture the temporal state transitions but overlook the complex spatiotemporal variations of the motion itself, making them difÔ¨Åcult to adapt to ever-changing motions. We observe that physical world motions can be decomposed into transient variation and motion trend, while the latter can be regarded as the accumulation of previous motions.
Thus, simultaneously capturing the transient variation and the motion trend is the key to make spacetime-varying mo-tions more predictable. Based on these observations, we propose the MotionRNN framework, which can capture the complex variations within motions and adapt to spacetime-varying scenarios. MotionRNN has two main contributions.
The Ô¨Årst is that we design the MotionGRU unit, which can model the transient variation and motion trend in a uniÔ¨Åed way. The second is that we apply the MotionGRU to RNN-based predictive models and indicate a new Ô¨Çexible video prediction architecture with a Motion Highway, which can signiÔ¨Åcantly improve the ability to predict changeable mo-tions and avoid motion vanishing for stacked multiple-layer predictive models. With high Ô¨Çexibility, this framework can adapt to a series of models for deterministic spatiotemporal prediction. Our MotionRNN can yield signiÔ¨Åcant improve-ments on three challenging benchmarks for video prediction with spacetime-varying motions. 1.

Introduction
Real-world motions are extraordinarily complicated and are always varying in both space and time. It is extremely challenging to accurately predict motions with space-time variations, such as the deformation, accumulation, or dissi-pation of radar echoes in precipitation forecasting. Recent advanced deterministic video prediction models, such as
PredRNN [36], MIM [37] and Conv-TT-LSTM [26] mainly
*Equal contribution
Human
Motion
Radar
Echo
Motion
" = ùêπ%
ùêπ%
# + ùê∑%
"
" = ùêπ!
ùêπ!
# + ùê∑!
"
" = ùêπ$
ùêπ$
"
# + ùê∑$
" = ùêπ&
ùêπ&
"
# + ùê∑&
Figure 1. Two cases of real-world spacetime-varying motions. The l t (shown in black arrows) of human legs or radar movements echoes can be decomposed into transient variation and motion
‚Ä≤ trend. Our MotionRNN captures the transient variation t (blue arrows) and the motion trend l t (red arrows) simultaneously.
F
F
D focus on capturing the simple state transitions across time.
They overlook the complex variations within the motions so that they cannot predict accurately under the highly chang-ing scenario. Besides, optical-Ô¨Çow based methods [22, 20] use local-invariant state transitions to capture the short-term temporal dependency but lack the characterization of long-term motion trends. These methods may degenerate signif-icantly when modeling ever-changing motions.
We observe that physical world motions can be naturally decomposed into the transient variation and motion trend.
The transient variation can be seen as the deformation, dis-sipation, speed change or other variations of each local re-gion instantly. As shown in Figure 1, when a person is run-ning, different parts of the body will have various transient movement changes across time, e.g. the left and the right legs are taken forward alternately. Moreover, the natural spatiotemporal processes are following the rule of the trend, especially for physical motions. In the running scenario of
Figure 1, the body sways up and down at each time step, but 15435
the man keeps moving forward from left to right following the unchanging tendency. The motion follows the character-istics behind the physical world in a video sequence, such as inertia for objects, meteorology for radar echoes, or other physical laws, which can be seen as the motion trend of the video. Considering the decomposition of the motion, we should capture the transient variation and the motion trend for better space-time varying motion prediction.
We go beyond the previous state-of-the-art methods for deterministic spatiotemporal prediction [36, 37, 26] and propose a novel MotionRNN framework. To enable more expressive modeling of the spacetime-varying motions, Mo-tionRNN adapts a MotionGRU unit for high-dimensional hidden-state transitions, which is speciÔ¨Åcally designed to capture the transient variation and the motion trend respec-tively. Inspired by the residual shortcuts in the ResNet [10], we improve the Motion Highway across layers within our framework to prevent the captured motions from vanishing and provide useful contextual spatiotemporal information for the MotionRNN. Our MotionRNN is Ô¨Çexible and can be easily adapted to the existing predictive models. Besides,
MotionRNN achieves new state-of-the-art performance on three challenging benchmarks: a real-world human motion benchmark, a precipitation nowcasting benchmark, and a synthetic varied Ô¨Çying digits benchmark. The contributions of this paper are summarized as follows:
‚Ä¢ Based on the key observation that the motion can be decomposed to transient variation and the motion trend, we design a new MotionGRU unit, which could capture the transient variation based on the spatiotem-poral information and obtain the motion trend from the previous accumulation in a uniÔ¨Åed way.
‚Ä¢ We propose the MotionRNN framework, which uniÔ¨Åes the MotionGRU and a new Motion Highway structure to make spacetime-varying motions more predictable and to mitigate the problem of motion vanishing across layers in the existing predictive models.
‚Ä¢ Our MotionRNN achieves the new state-of-the-art per-formance on three challenging benchmarks. And it is
Ô¨Çexible to be applied together with a rich family of predictive models to yield consistent improvements. 2.