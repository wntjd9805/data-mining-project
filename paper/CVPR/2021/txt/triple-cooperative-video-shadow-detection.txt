Abstract
Shadow detection in a single image has received signif-icant research interests in recent years. However, much fewer works have been explored in shadow detection over dynamic scenes. The bottleneck is the lack of a well-established dataset with high-quality annotations for video shadow detection.
In this work, we collect a new video shadow detection dataset (ViSha), which contains 120 videos with 11, 685 frames, covering 60 object categories, varying lengths, and different motion/lighting conditions.
All the frames are annotated with a high-quality pixel-level shadow mask. To the best of our knowledge, this is the ﬁrst learning-oriented dataset for video shadow detection. Fur-thermore, we develop a new baseline model, named triple-cooperative video shadow detection network (TVSD-Net).
It utilizes triple parallel networks in a cooperative man-ner to learn discriminative representations at intra-video and inter-video levels. Within the network, a dual gated co-attention module is proposed to constrain features from neighboring frames in the same video, while an auxiliary similarity loss is introduced to mine semantic information between different videos. Finally, we conduct a comprehen-sive study on ViSha, evaluating 12 state-of-the-art models (including single image shadow detectors, video object seg-mentation, and saliency detection methods). Experiments demonstrate that our model outperforms SOTA competitors. 1.

Introduction
As a common phenomenon in our daily life, shadows in natural images provide hints for extracting scene geom-etry [41, 24], light direction [27], and camera location and its parameters [23]. Shadows can also beneﬁt diverse im-age understanding tasks, e.g., image segmentation [10], ob-*Zhihao Chen and Liang Wan are the joint ﬁrst authors of this work.
†Lei Zhu (lz437@cam.ac.uk) is the corresponding author of this work. ject detection [8], and object tracking [37]. The last decade has witnessed a growing interest in image shadow detec-tion. Many methods have been developed by examining color and illumination priors [14, 13], by developing data-driven approaches with hand-crafted features [21, 28, 54], or by learning discriminative features from a convolutional neural network (CNN) [25, 43, 39, 20, 29, 56, 19, 53].
However, in striking contrast with the ﬂourishing devel-opment of image shadow detection, much fewer works have been explored in shadow detection over dynamic scenes.
On the other hand, we also notice that video processing has become an urgent topic in recent years, and a lot of methods were proposed for video salient object detection [30, 47, 11] and video object segmentation [35, 40]. What makes video shadow detection lag far behind these video processing tasks? Compared with shadow detection of a single image, video shadow detection (VSD) needs to utilize temporal in-formation to identify shadow pixels of each video frame.
Although there exist multiple datasets for image shadow detection, video salient object detection, and video object segmentation, such standard widespread benchmark (with a sufﬁcient number of video clips, covering diverse content) is missing for video shadow detection. What’s more, CNN-based methods have not been exploited for this problem due to the lack of such a dataset.
In this work, we ﬁrst collect a new video shadow detec-tion (ViSha) dataset. It contains 120 videos with 11,685 image frames and 390 seconds duration, covering shad-ows of 7 object classes and 60 object categories, various motion/lighting conditions, and different instance numbers.
All the video frames are carefully annotated with a high-quality pixel-level shadow mask. To the best of our knowl-edge, this is the ﬁrst learning-oriented dataset for video shadow detection, which could facilitate the community to explore further in this ﬁeld. Second, we develop a new baseline model, a triple-cooperative video shadow de-tection network (TVSD-Net), for this task.
Instead of just exploiting temporal information within one video clip 2715
# 001
# 030
# 052
# 001
# 040
# 082
# 001
# 028
# 080
# 001
# 050
# 100
Figure 1: The examples of proposed Video Shadow Detection (ViSha) dataset, with pixel-level shadow annotations. as most current video object detection networks did, we propose to learn at both intra-video and inter-video lev-els then model their correlation features. Our TVSD-Net utilizes triple parallel networks in a cooperative manner.
To be speciﬁc, we take two neighboring frames from the same video and one image frame from another video as in-puts. Then a dual gated co-attention (DGC) module is de-vised to learn a global intra-video correlation on the two frames of the same video, and a triple-cooperative (T) mod-ule encodes the inter-video property, which promotes the similarity between the same-video frames and suppresses the similarities between different-video frames. Finally, we present a comprehensive evaluation of 12 state-of-the-art models on our ViSha dataset, making it the most complete VSD benchmark. Results show that our model signiﬁcantly outperforms existing methods, including sin-gle image shadow detectors [4, 56, 53], single saliency detectors [18, 9], semantic segmentation method [34, 52], video object segmentation [35], and video saliency detec-tion methods [32, 42].
In summary, our work forms the
ﬁrst learning-oriented VSD benchmark, thereby providing a new view to video object detection from a shadow perspec-tive. Our dataset and code have been released at https:
//github.com/eraserNut/ViSha. 2.