Abstract
The rapid progress of photorealistic synthesis tech-niques have reached at a critical point where the bound-ary between real and manipulated images starts to blur.
Thus, benchmarking and advancing digital forgery analy-sis have become a pressing issue. However, existing face forgery datasets either have limited diversity or only sup-port coarse-grained analysis.
To counter this emerging threat, we construct the
ForgeryNet dataset, an extremely large face forgery dataset
*Equal contribution.
†Work done during an internship at SenseTime Research.
‡Corresponding author.
§https://yinanhe.github.io/projects/forgerynet. html 0 ight):fake,fake,fake,fake,fake,fake,fake,real,fake,real,fake,real
ThelabelofimagesinFig.1(a)(fromlefttor-with uniﬁed annotations in image- and video-level data across four tasks: 1) Image Forgery Classiﬁcation, in-cluding two-way (real / fake), three-way (real / fake with identity-replaced forgery approaches / fake with identity-remained forgery approaches), and n-way (real and 15 2) Spa-respective forgery approaches) classiﬁcation. tial Forgery Localization, which segments the manipu-lated area of fake images compared to their correspond-ing real images. 3) Video Forgery Classiﬁcation, which re-deﬁnes the video-level forgery classiﬁcation with manip-ulated frames in random positions. This task is impor-tant because attackers in real world are free to manipu-late any target frame. and 4) Temporal Forgery Localiza-tion, to localize the temporal segments which are manipu-lated. ForgeryNet is by far the largest publicly available deep face forgery dataset in terms of data-scale (2.9 million 4360
images, 221,247 videos), manipulations (7 image-level ap-proaches, 8 video-level approaches), perturbations (36 in-dependent and more mixed perturbations) and annotations (6.3 million classiﬁcation labels, 2.9 million manipulated area annotations and 221,247 temporal forgery segment la-bels). We perform extensive benchmarking and studies of existing face forensics methods and obtain several valuable observations. We hope that the scale, quality, and variety of our ForgeryNet dataset will foster further research and innovation in the area of face forgery classiﬁcation, as well as spatial and temporal forgery localization etc. 1.

Introduction
Photorealistic facial forgery technologies, especially re-cent deep learning driven approaches [17, 26, 35], give rise to widespread social concerns on potential malicious abuse of these techniques to eye-cheatingly forge media (i.e., im-ages and videos, etc.) of human faces. Therefore, it is of vi-tal importance to develop reliable methods for face forgery analysis1, so as to distinguish whether and where an image or video is manipulated.
Most recent progress about face forgery analysis are sparked by gathering of face forgery detection datasets [12, 38] and early attempts of proﬁling intrinsic characteris-tics within the forgery images. However, performances on most datasets have already saturated (i.e. over 99% accu-racy [19, 23, 33, 44]) due to their limited scales (e.g. number of images/videos and subject identities) and limited diver-sity (e.g. forgery approaches, scenarios, realistic perturba-tions, etc.). Moreover, in practical applications, it is often required to detect forged faces by locating tampered areas in an image and/or manipulated segments in an untrimmed video, rather than merely providing a binary label.
In this paper, we construct a new mega-scale dataset named ForgeryNet with comprehensive annotations, con-sisting of two groups (i.e. image- and video-level) and four tasks for real-world digital forgery analysis. We carefully benchmark existing forensics methods on ForgeryNet. Ex-tensive experiments and in-depth analysis show that this larger and richer annotated dataset can boost the develop-ment of next-generation algorithms for forgery analysis.
Speciﬁcally, ForgeryNet brings several unique advantages over existing datasets. (1) Wild Original Data. Most current datasets are captured under controlled conditions (e.g. environment, angles and lighting). We collect original data with diversiﬁed dimen-sions of angle, expression, identity, lighting, scenario and 1In this paper, the deﬁnition of the term “face forgery” refers to an image or a video containing modiﬁed identity, expressions or attribute(s) with a learning-based approach, distinguished with 1) a so-called “Cheap-Fakes” [34] that are created with off-the-shelf softwares without learn-able components and 2) “DeepFakes” that only refer to manipulations with swapped identities [12]. etc. from four datasets [6, 10, 14, 32]. Note that all the orig-inal data have a Creative Commons Attribution license that allows to share and adapt the material. (2) Various Forgery Approaches. There are at most 8 forgery approaches in all current datasets, while ForgeryNet is manipulated by 15 approaches, including face transfer, face swap, face reenactment and face editing. We choose approaches that span a variety of learning-based models, including encoder-decoder structure, generative adversarial network, graphics formation and RNN/LSTM (Fig. 4). (3) Diverse Re-rendering Process. In the process of trans-mission and re-rendering, media data (image/video) always undergo compression, blurring and other operations, which may smooth the traces of forgery and bring more challenge for forgery detection. The ForgeryNet dataset posts 36 per-turbations, such as optical distortion, multiplicative noise, random compression, blur, and etc. As shown in Fig. 1(c), circle sizes refer to the number of forgery approaches with re-rendering process operations. (4) Rich Annotations and Comprehensive Tasks. Accord-ing to the real application scenario, we propose four tasks, as shown in Fig. 1(b): 1) Image Forgery Classiﬁcation, dis-tinguishes whether an image is forgery or not and mean-while tells its forgery type (i.e. manipulation approaches).
We provide three types of annotations including two-way, three-way and n-way classiﬁcation. Both intra- and cross-forgery evaluations are set on three-way and n-way settings. 2) Spatial Forgery Localization, localizes manipulated areas of forgery images. Due to the fact that a forgery image may contain multiple faces and can be manipulated entirely or in part, it is more substantial to segment modiﬁed pixels in addition to only telling that it is forged. 3) Video Forgery
Classiﬁcation, similar to image-level classiﬁcation, contains three types of annotations. Note that different from existing forgery video datasets, we construct our video dataset with untrimmed videos, each of which has part of the frames ma-nipulated, considering the fact that forgery videos in real world are often manipulated on a certain subject and some key frames. 4) Temporal Forgery Localization, localizes the temporal segments which are manipulated. This is a new task for forgery analysis. Together with Video Forgery
Classiﬁcation and Spatial Forgery Localization, it provides comprehensive spatio-temporal forgery annotations. 2.