Abstract
Fine-grained object recognition aims to learn effective features that can identify the subtle differences between vi-sually similar objects. Most of the existing works tend to amplify discriminative part regions with attention mech-anisms. Besides its unstable performance under com-plex backgrounds, the intrinsic interrelationship between different semantic features is less explored. Toward this end, we propose an effective graph-based relation discov-ery approach to build a contextual understanding of high-order relationships. In our approach, a high-dimensional feature bank is ﬁrst formed and jointly regularized with semantic- and positional-aware high-order constraints, en-dowing rich attributes to feature representations. Second, to overcome the high-dimension curse, we propose a graph-based semantic grouping strategy to embed this high-order tensor bank into a low-dimensional space. Meanwhile, a group-wise learning strategy is proposed to regularize the features focusing on the cluster embedding center. With the collaborative learning of three modules, our module is able to grasp the stronger contextual details of ﬁne-grained ob-jects. Experimental evidence demonstrates our approach achieves new state-of-the-art on 4 widely-used ﬁne-grained object recognition benchmarks. 1.

Introduction
Fine-grained object recognition focuses on distinguish-ing and classifying objects of a basic-level category in-to subclasses, which is a challenging task due to the sub-tle visual differences among different classes. Beneﬁt-ing from the strong perceptual capability of deep neu-ral networks, handling subtle variances using visual fea-tures [42, 34, 49, 19] has made signiﬁcant progress.
In particular we consider two popular families of methods in
∗Correspondence should be addressed to Jia Li. URL: http:// cvteam.net
Figure 1. The motivation of proposed approach. Our proposed approach ﬁrst exploits the structurally channel-aware relationship b) into a high-dimensional graph embedding. Then these relation nodes are grouped into low-dimensional space d) with a semantic grouping strategy, forming the ﬁnal grouped activations f). tackling this problem, i.e., discriminative part learning and feature representation learning.
Studies of the ﬁrst family [48, 42, 34, 6] usually deal with the ﬁne-grained categorization problem by localizing distinct parts. Some representative methods tend to utilize the part detectors [13, 18] or segmentation parsers [19, 21] in different categorization tasks. With accurate part parsing results obtained, satisfactory performance for ﬁne-grained classiﬁers could also be achieved simultaneously. Be-sides methods using manual annotations, attention-based approaches [19, 42, 34, 6, 31] show its ability in discovering object parts during weakly-supervised training. However, part localizations using attention mechanisms perform un-reliable results under complex scenarios. As networks fail to capture the correct part localizations, further strengthen-ing these regions would lead to catastrophic overﬁtting. 15079
The other family of approaches [28, 46, 36, 49] usually tackle the classiﬁcation problem as a representation learn-ing task. As object parts emerge naturally in different fea-ture channels [14] during the weakly-supervised classiﬁca-tion task, exploiting mutual relationships among different channels [36, 12, 3, 50] is meaningful and beneﬁcial for
ﬁne-grained feature representations. As one of the predom-inant methods, bilinear pooling [28] exploits the second-order classiﬁcation features from two different networks.
Moreover, Zheng et al. [49] propose a trilinear attention mechanism, using third-order pooling to build channel rela-tionships. However, high order features would lead to high dimensions (e.g., C × C dimensions for homogeneous fea-tures X · X⊤
, X ∈ RC×W ×H ), bringing in heavy computa-tion burden and overﬁtting risks. Thus two major concerns arise: 1) how to build global relation scopes using high-order relationships and 2) how to embed the high-dimension features in a low-dimension manifold?
In this paper, we propose a graph-based relation dis-covery (GaRD) approach to excavating ﬁner relational at-tributes from intrinsic network features. As illustrated in Fig. 1, different from previous research, our approach tackles the representative feature learning in an expansion and compression manner. Inspired by the emerging seman-tic parts in class activation maps (Fig. 1 b)), our expansion motif is to construct contextual relationships among multi-ple feature channels by learning high-order representation-s. However, the tentative nature of channel-aware mech-anisms [28, 49] tends to omit the spatially structural in-formation and use averaged logits to represent each chan-nel. To overcome this natural defect, we propose a relation-discovery module where the structural relations are con-structed by employing a position-aware gating operation, providing high-order spatial enhancement for further chan-nel interactions. Meanwhile, heterogeneous features from different levels are adopted to build a cross-channel relation with positional enhanced features. Finally, a mix-order ten-sor bank T ∈ RC1×C2 is formed, endowing rich features but resulting in redundant high dimensions.
To address this problem, existing classiﬁcation model-s compress high-dimension features with feature factoriza-tions [27] or low-rank representations [23]. Despite their performance deﬁciencies, semantic relationships among d-ifferent features are less taken into consideration, which is crucial in ﬁne-grained vision tasks. To explore the seman-tic relationships, we ﬁrst formulate the mix-order tensor in-to a graph representation in Fig. 1 c) and then propose a graph grouping module to adaptively embed the high-order relation matrices into a low-dimension manifold. The graph convolutional layer efﬁciently encodes this relation matrix with a densely-connected relational graph. To redi-vide these nodes into different groups, we adopt an auxil-iary graph layer to learn the grouping rules based on their semantic similarities. Hence the mix-order feature bank is embedded in a low-dimension manifold while retaining it-s rich semantic relationships for ﬁne-grained recognition.
Beyond these two modules, we ﬁrst advocate employing the group-wise training mechanism for ﬁne-grained image classiﬁcation without additional regularizations, which u-tilize the center of grouped images instead of per image samples for gradient descent. This mechanism alleviates overﬁtting and gradient anomalies caused by hard samples.
Experimental evidence demonstrates the proposed approach achieves state-of-the-art results on four popular benchmark datasets, i.e., CUB-200-2011 [38], Stanford-Cars [25], Air-crafts [30], and NAbirds [37].
In summary, our contribution is threefold: 1) We propose a novel graph-based relation discovery (GaRD) approach for ﬁne-grained recognition, which adaptively exploits the relation-aware feature embeddings to enhance the discrim-inative representation abilities. 2) We propose to learn the positional and semantic feature relationships with an effec-tive relation-discovery module, and learn a semantic group-ing rule to cluster the high-order relationships. 3) We pro-pose a simple yet effective group-wise learning strategy to update gradient using cluster center prototypes, alleviates overﬁtting and anomalies caused by hard samples. 2.