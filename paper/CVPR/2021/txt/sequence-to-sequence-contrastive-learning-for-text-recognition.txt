Abstract
We propose a framework for sequence-to-sequence con-trastive learning (SeqCLR) of visual representations, which we apply to text recognition. To account for the sequence-to-sequence structure, each feature map is divided into dif-ferent instances over which the contrastive loss is com-puted. This operation enables us to contrast in a sub-word level, where from each image we extract several positive pairs and multiple negative examples. To yield effective vi-sual representations for text recognition, we further suggest novel augmentation heuristics, different encoder architec-tures and custom projection heads. Experiments on hand-written text and on scene text show that when a text decoder is trained on the learned representations, our method out-performs non-sequential contrastive methods. In addition, when the amount of supervision is reduced, SeqCLR sig-niﬁcantly improves performance compared with supervised training, and when ﬁne-tuned with 100% of the labels, our method achieves state-of-the-art results on standard hand-written text recognition benchmarks. 1.

Introduction
Contrastive learning techniques for self-supervised rep-resentation learning have recently demonstrated signiﬁcant improvements on several semi-supervised computer vision applications, including image classiﬁcation, object detec-tion, and segmentation [9, 27, 18, 8, 26, 52, 10, 60, 49]. As illustrated in Fig. 1(a) contrastive learning is performed by maximizing agreement between representations of differ-ently augmented views of the same image and distinguish-ing them from representations of other dataset images.
Despite obvious advantages, unsupervised and semi-supervised schemes have hardly been explored for text
∗Authors contribute equally and are listed in alphabetical order.
Figure 1: Sequence contrastive learning. (a) Current con-trastive methods compare representations computed from whole images. (b) We propose a sequence-to-sequence ap-proach, by viewing the feature map as a sequence of sep-arate representations. This is useful in text recognition, where words are composed of sequences of characters. recognition ([25, 68, 34]). For example, currently, most handwritten text recognition approaches still rely on fully supervised learning, requiring large amounts of annotated data. The reason for this is simple: current contrastive schemes for visual representation learning are tailored to-15302
wards tasks such as object recognition or classiﬁcation, where images are atomic input elements. For example, in image classiﬁcation, positive examples are created by aug-menting each image while all other images in the dataset are assumed to be negative (Fig. 1(a)). On the other hand, for sequential prediction as used in text recognition, a word is viewed as a sequence of characters, and thus the image of a word is best modeled as a sequence of adjacent image slices (frames), each one of which may represent a different class as depicted in Fig. 1(b). Thus, the standard ‘whole image’ contrastive learning approach is inadequate for this task.
We propose an approach that extends existing contrastive learning methods to sequential prediction tasks such as text recognition. The key idea is to apply contrastive learning to the individual elements of the sequence, while main-taining information about their order. To do so, we intro-duce an instance-mapping function that yields an instance from every few consecutive frames in a sequence feature map. The instance is the atomic element that will be used in contrastive learning. A given image, depending on its width, may produce an arbitrary number of instances. This enlarges the number of negative examples in every batch without requiring a memory bank [27] or architecture mod-iﬁcations [2]. Individual instances are part of a sequence, thus we design an augmentation procedure that ensures a sequence-level alignment, which is crucial for yielding ef-fective representations (Fig. 2).
We validate our method experimentally, comparing its performance with non-sequential contrastive approaches on several handwritten and scene text datasets. To evaluate the quality of the learned visual representation, we lay out a de-coder evaluation protocol that extends the widely-used lin-ear evaluation criteria [67, 37] for encoder-decoder based networks. Utilizing this evaluation, we demonstrate sig-niﬁcant improvements over current contrastive learning ap-proaches. Furthermore, we ﬁnd that our method outper-forms supervised training methods with limited amounts of labeled training data, and it achieves state-of-the-art results on standard handwritten datasets, reducing the word error rate by 9.5% on IAM and by 20.8% on RIMES.
To summarize, the key contributions of our work are:
• A contrastive learning approach for visual sequence-to-sequence recognition.
• Viewing each feature map as a sequence of individual instances, leading to contrastive learning in a sub-word level, such that each image yields several positive pairs and multiple negative examples.
• Deﬁning sequence preserving augmentation proce-dures, and custom projection heads.
• Extensive experimental validation showing state-of-the-art performance on handwritten text.
Figure 2: Sequence preserving augmentations. We pro-pose an augmentation procedure which meets the sequential structure of the feature map. For example, as opposed to vertical cropping, horizontal ﬂipping results in a sequence-level misalignment which leads to poor positive pairing. 2.