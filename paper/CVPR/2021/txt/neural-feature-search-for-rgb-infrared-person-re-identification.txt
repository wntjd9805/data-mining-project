Abstract (a)
Feature Space
Manually Design
Selected Features
RGB-Infrared person re-identiﬁcation (RGB-IR ReID) is a challenging cross-modality retrieval problem, which aims at matching the person-of-interest over visible and infrared camera views. Most existing works achieve performance gains through manually-designed feature selection mod-ules, which often require signiﬁcant domain knowledge and rich experience. In this paper, we study a general paradigm, termed Neural Feature Search (NFS), to automate the pro-cess of feature selection. Speciﬁcally, NFS combines a dual-level feature search space and a differentiable search strat-egy to jointly select identity-related cues in coarse-grained channels and ﬁne-grained spatial pixels. This combination allows NFS to adaptively ﬁlter background noises and con-centrate on informative parts of human bodies in a data-driven manner. Moreover, a cross-modality contrastive op-timization scheme further guides NFS to search features that can minimize modality discrepancy whilst maximiz-ing inter-class distance. Extensive experiments on main-stream benchmarks demonstrate that our method outper-forms state-of-the-arts, especially achieving better perfor-mance on the RegDB dataset with signiﬁcant improvement of 11.20% and 8.64% in Rank-1 and mAP, respectively. 1.

Introduction
Person re-identiﬁcation (ReID) aims to match the person-of-interest over non-overlapping camera views [54, 67, 44, 73, 60], serving as a central part of intelligent video surveillance systems. Currently, most conventional ReID methods concentrate efforts on visible images-based cross-view matching tasks [29, 18, 46, 43, 36], which cannot adapt well to illumination variations in real-world scenarios (e.g., low lighting environments at nighttime). Motivated by this challenge, associating RGB and infrared (IR) pedes-trian images captured by dual-mode cameras for cross-∗Equally-contributed ﬁrst authors
†Corresponding author  Stripes? Landmarks? Parsing Maps? …
Manually Selection Module
Training
ReID
Dataset
Evaluating
Hyperparameters
Numbers of stripes?
Numbers of Landmarks?
Numbers of  parts?
…
Neural Feature Search
Selected Features
AutoML
Dual-level Feature Search
Cells
Cells
Cells
Cells
Channel
RGB
IR
Spatial
+
Spatial Channel
Training
Proxy
Dataset
Sampling
Probability
Features
Feature Maps (b)
Feature
Search Space
Feature Map
=
Spatial-level
+
Channel-level
Figure 1. Comparison of hand-crafted and automated feature se-lection strategies. (a) Manually designing task-speciﬁc modules to select identity-related features. (b) NFS automatically derives the optimal feature subset from a dual-level feature search space. modality image retrieval, a.k.a. RGB-IR ReID, has drawn much attention in vision community [58, 64, 51, 52, 66].
Due to intrinsically different imaging mechanisms,
RGB-IR ReID suffers from undesired visual discrepancy between visible and infrared images, which makes appear-ance cues such as colors and textures unreliable or even misleading for the matching task [32, 52, 58]. More-over, such modality divergence also exacerbates the al-ready large intra-class variations caused by diverse cam-era viewpoints, person poses, partial occlusions, and back-ground clutter [57, 14, 22], making it even harder to align images of the same identity.
In an effort to minimize the modality gap, cross-modality image synthesis meth-ods [51, 52, 22] typically leverage generative adversarial networks (GANs) to transfer stylistic properties between modalities to synthesize fake RGB/IR images. But it is non-trivial to preserve identity information for generated
RGB images due to lack of color information in their IR counterparts [11]. Another line of shared feature learning approaches [64, 69, 66, 63] utilize convolutional neural net-587
works (CNNs) to perform cross-modality feature alignment.
One representative model-of-choice is the two-stream net-work [63, 68, 56], which includes modality-speciﬁc shallow layers and shared deeper layers to learn a common feature space [58]. On the strength of two-stream structures, several studies exploit ReID discriminative constrains, e.g., triplet loss [67, 65, 63] or ranking loss [69, 14], to supervise the network to mine identity-related cues. They are all com-mitted to learning a better distance metric that enhances the performance of similarity-based retrieval and have achieved signiﬁcant success in recent years [66].
To our understanding, whether image synthesis ap-proaches or shared feature learning techniques, the crux of
ReID solutions is always to ﬁnd sufﬁciently high-quality discriminative features for matching and retrieval. To achieve this goal, state-of-the-art methods typically intro-duce partition stripes [66], human landmarks [49], parsing maps [19], and body contour sketches [62] to discourage ir-relevant features whilst preserving the identity-related ones (Fig. 1(a)). However, it is really tough and time-consuming to manually design a one-ﬁt-all feature selection module against all sorts of intra- and inter-modality variations, lead-ing to unsatisfactory performance of human-guided feature selection mechanisms. Driven by the above observations, a question arises: Is there a data-driven feature selection manner without much requirement for human interference?
Recent advances on automated machine learning (AutoML)
[17] may provide a positive answer. Using Neural Archi-tecture Search (NAS) [72], Quan et al. [41] automatically generate fast and effective CNNs whose performance is on par with hand-crafted architectures in single-modality ReID tasks. This progress inspires the idea of neuron-powered au-tomatic feature selection discussed in this paper.
With the idea in mind, we investigate RGB-IR ReID from a one-ﬁt-all feature search perspective. Different from existing manually-designed [66, 32, 4] or NAS-generated network structures [41], our goal is to pursue better ReID performance by discovering discriminative features with data-driven search neurons. To this end, we cast feature se-lection as a bilevel optimization problem [28] (i.e., deriving the optimal feature subset from the best feature learning re-sults) and propose a novel paradigm, Neural Feature Search (NFS, Fig. 1(b)). Starting from the hierarchical feature ex-traction mechanism of CNNs [39], NFS includes a dual-level feature search space where each feature map is decom-posed in terms of pixel and channel dimensions. This al-lows feature selection operations to be jointly performed in a mutually reinforcing manner—channel-level search iden-tiﬁes relevant response maps from the global view while pixel-level search scans every spatial position to selectively process local part features of a person. To improve the search efﬁciency, we utilize reparameterization tricks [31] to relax the search space to be continuous, which makes the optimization of search neurons compatible with stochastic gradient descent (SGD). Considering the inherent modality discrepancy issue of RGB-IR ReID, a cross-modality con-trastive optimization scheme is further introduced as a su-pervision signal that discourages irrelevant features whilst encouraging modality-invariant cues during the searching process. Extensive experiments show that NFS signiﬁcantly outperforms the state-of-the-arts by 12.01% and 11.20% gains of Rank-1 accuracy on SYSU-MM01 (multi-shot, all search mode) and RegDB (visible-to-infrared mode) bench-marks, respectively. To summarize, this paper brings three main contributions:
• We propose an AutoML-powered neural feature search method for RGB-IR person re-identiﬁcation, which automates the feature selection process to substantially improve the matching accuracy with less human ef-forts. To our best knowledge, this is one of the ﬁrst at-tempts to utilize automatic feature selection techniques for cross-modality ReID.
• We introduce a novel feature search space allowing both spatial and channel-wise feature selection. Based on this search space, we present an efﬁcient feature search algorithm embedded with a cross-modality con-trastive optimization mechanism, effectively tackling the modality discrepancy in RGB-IR ReID.
• Extensive experiments on two mainstream RGB-IR
ReID benchmarks demonstrate the superiority of NFS compared with previous state-of-the-arts. 2.