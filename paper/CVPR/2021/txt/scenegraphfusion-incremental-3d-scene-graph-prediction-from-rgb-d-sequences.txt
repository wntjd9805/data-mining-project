Abstract
Scene graphs are a compact and explicit representa-tion successfully used in a variety of 2D scene understand-ing tasks. This work proposes a method to incrementally build up semantic scene graphs from a 3D environment given a sequence of RGB-D frames. To this end, we ag-gregate PointNet features from primitive scene components by means of a graph neural network. We also propose a novel attention mechanism well suited for partial and miss-ing graph data present in such an incremental reconstruc-tion scenario. Although our proposed method is designed to run on submaps of the scene, we show it also transfers to entire 3D scenes. Experiments show that our approach outperforms 3D scene graph prediction methods by a large margin and its accuracy is on par with other 3D semantic and panoptic segmentation methods while running at 35Hz. 1.

Introduction
High-level scene understanding is a fundamental task in computer vision required for many applications in ﬁelds such as robotics and augmented or mixed reality. Boosted by the availability of inexpensive depth sensors, real-time dense SLAM algorithms [33, 21, 35, 56] and large scale 3D datasets [5, 53], the research focus has shifted from re-constructing the 3D scene geometry to enhancing the 3D maps with semantic information about scene components.
Several methods have deployed a neural network to pro-cess a complete 3D scan of a scene [5, 10, 41, 39, 24, 18, 17, 16, 9]. However, these all require 3D geometry as prior information and they typically operate in an of-ﬂine fashion, i.e. without satisfying real-time requirements, which are fundamental for many real-world applications.
Real-time scene understanding that incrementally built 3D scans poses important challenges such as handling partial, incomplete, and ambiguous scene geometry where object shapes may change dramatically over time. Learning a ro-bust 3D feature that can cope with this variability is difﬁcult.
Furthermore, fusing multiple, potentially contradictory net-work predictions to ensure consistency in the global map, is also challenging. Recently, in the image domain, semantic scene graphs have been used to derive relationships among scene entities [26, 57, 34, 59, 15]. Scene graphs demon-strated to be a powerful abstract representation for scene 7515
understanding. Being compact and explicit, they are bene-ﬁcial for complex tasks such as image captioning [58, 20], generation [19], manipulation [7] or visual questioning and answering [49]. For this reason, recent works have explored scene graph prediction from entire 3D scans in an ofﬂine manner [54, 1]. Furthermore, building up semantic graph maps online is a major challenge, requiring not only to ef-ﬁciently detect semantic instances in the scene but also to robustly estimate predicates between them, while dealing with partial and incomplete 3D geometry.
In this work, we propose a real-time method to incremen-tally build, in parallel to 3D mapping, a globally consistent semantic scene graph, as shown in Fig. 1. Our approach re-lies on a geometric segmentation method [47] and a novel inductive graph network, which handles missing edges and nodes in partial 3D point clouds. Our scene nodes are ge-ometric segments of primitive shapes. Their 3D features are propagated in a graph network that aggregates features of neighborhood segments. Our method predicts scene se-mantics and identiﬁes object instances by learning relation-ships among clusters of over-segmented regions. Towards this end, we propose to learn additional relationships, re-ferred to as same part in an end-to-end manner.
The main contributions of this work can be summarized as follows: (1) We propose the ﬁrst online 3D scene graph prediction, i.e. incrementally fusing predictions from cur-rently observed sub-maps into a globally consistent seman-tic graph model. (2) Due to a new relationship type, nodes are merged into 3D instances, resembling panoptic segmen-tation.(3) We introduce a novel attention method that can handle partial and incomplete 3D data, as well as highly dy-namic edges, which is required for incremental scene graph prediction. Our experiments show that we outperform 3D scene graph prediction and achieve on par performance on 3D semantic and instance segmentation benchmarks while running in 35Hz. 2.