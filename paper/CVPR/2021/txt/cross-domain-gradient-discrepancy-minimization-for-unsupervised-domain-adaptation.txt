Abstract
Unsupervised Domain Adaptation (UDA) aims to gen-eralize the knowledge learned from a well-labeled source domain to an unlabled target domain. Recently, adver-sarial domain adaptation with two distinct classiﬁers (bi-classiﬁer) has been introduced into UDA which is effec-tive to align distributions between different domains. Pre-vious bi-classiﬁer adversarial learning methods only focus on the similarity between the outputs of two distinct classi-ﬁers. However, the similarity of the outputs cannot guaran-tee the accuracy of target samples, i.e., traget samples may match to wrong categories even if the discrepancy between two classiﬁers is small. To challenge this issue, in this pa-per, we propose a cross-domain gradient discrepancy min-imization (CGDM) method which explicitly minimizes the discrepancy of gradients generated by source samples and target samples. Speciﬁcally, the gradient gives a cue for the semantic information of target samples so it can be used as a good supervision to improve the accuracy of target
In order to compute the gradient signal of tar-samples. get smaples, we further obtain target pseudo labels through a clustering-based self-supervised learning. Extensive ex-periments on three widely used UDA datasets show that our method surpasses many previous state-of-the-arts. 1.

Introduction
Conventional deep learning methods suffer from the challenge of heavy dependency on large-scale labeled data, which is extremely expensive in many real-world scenar-ios such as medical image analysis. To avoid expensive data annotation, unsupervised domain adaptation (UDA)
[30, 19, 18] attempts to transfer a model trained on labeled data collected in the source domain to a similar target do-main with unlabled data. To mitigate the domain shift, one popular paradigm in UDA is to reduce the distribution di-vergence between domains by minimizing a speciﬁc metric
[24, 27, 42]. Another widely used paradigm aims to learn
*Jingjing Li is the corresponding author.
Ambiguous target samples
Match to the wrong class
Source
Target
Decision boundary
Figure 1. Illustration of the issue in previous bi-classiﬁer adver-sarial learning. Previous methods only consider the discrepancy between classiﬁers and neglect the accuracy of the target samples. domain-invariant feature representations by leveraging the idea of adversarial learning [9], which has achieved remark-able success in the ﬁeld of UDA recently.
Existing adversarial domain adaptation methods can be implemented in two ways. One way is to apply an extra do-main discriminator to distinguish whether a sample comes from the source or the target domain. At the same time, a feature extractor is used to fool the domain discriminator by learning undistinguishable features from input samples
[10, 9, 25]. However, these domain adversarial methods ne-glect the category information of target samples, which may result in deterioration of the feature discriminability [5].
Another adversarial paradigm proposes a within-network adversarial strategy with two classiﬁers [36, 14]. Through the minimax game between the classiﬁers and the generator on the cross-classiﬁer outputs discrepancy, the target sam-ples outside the support of the source domain can be de-tected by the decision boundaries effectively, thus the fea-ture alignment could be established while the discriminabil-ity is also preserved.
Although bi-classiﬁer adversarial learning has shown promising performance, methods with this paradigm only focus on the similarity between two distinct classiﬁers through a discrepancy metric such as ℓ1 distance [36] and slide wasserstein distance [14]. Here we argue that only considering the discrepancy between classiﬁers can-not guarantee the accuracy and diversity of classiﬁcation on target samples, because it is possible that both classi-3937
ﬁers get wrong results. As shown in Fig. 1, ambiguous target samples may detected by wrong decision boundaries, which inevitably results in an inaccurate class-wise distri-bution alignment in subsequent adversarial procedure, al-though the discrepancy metric, e.g., ℓ1 and wasserstein dis-tance between the outputs of two classiﬁers is small. The main reason is that previous bi-classiﬁer adversarial meth-ods lack the consideration of the accuracy on target samples.
In this paper, we aim to alleviate this issue. One straight-forward idea is to label target samples by pseudo labels and
ﬁne-tune the model with data of both domains, which has been proven to be effctive in UDA [6]. However, directly using hard pseudo labels for supervised learning would lead to error diffusion and converge to the accuracy of pseudo la-bels. Here we tackle this issue from another perspective, we notice that the gradient discrepancy between source and tar-get samples is related to the accuracy: assuming there is an accurate classiﬁer, the source data and the target data would produce similar gradient signals for updating the classiﬁer.
Our key idea is that we wish the loss of two domains to be close to not only the ﬁnal model but also to follow a similar path to it throughout the optimization. Therefore, we use the gradient signal as a surrogate supervision and make it an proxy to the classiﬁcation accuracy, yielding a cross-domain gradient discrepancy minimization (CGDM) method for UDA. CGDM employs the gradient discrep-ancy between source and target samples as an extra supervi-sion. Furthermore, considering that pseudo labels obtained by the source-only classiﬁer may be not accurate enough, we leverage a clustering-based self-supervised method to obtain more reliable pseudo labels for target samples. By aligning gradient vectors, distributions of two domains can be better aligned at the category-level. The main contribu-tions of this work are summarized as follows:
• In order to solve the inaccurate alignment issue in pre-vious bi-classiﬁer adversarial learning, we propose a novel method which explicitly minimizes the discrep-ancy of gradient vectors produced by the source and the target samples. Notably, we formulate the pro-posed gradient discrepancy minimization as a general-ized learning loss which can be easily applied to other
UDA paradigms.
• For computing the gradient of target samples, we em-ploy a clustering-based strategy to obtain more reliable pseudo labels. Then a self-supervised learning based on pseudo labels is conducted to ﬁne-tune the model with both the source data and the target data in order to reduce the number of ambiguous target samples.
• We reformulate the vanilla bi-classiﬁer adversarial framework with above two proposals and conduct ex-tensive experiments on three open large-scale datasets.
The experimental results demonstrate the advantage of our method. 2.