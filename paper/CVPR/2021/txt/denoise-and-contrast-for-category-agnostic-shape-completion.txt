Abstract
In this paper, we present a deep learning model that ex-ploits the power of self-supervision to perform 3D point cloud completion, estimating the missing part and a context region around it. Local and global information are encoded in a combined embedding. A denoising pretext task provides the network with the needed local cues, decoupled from the high-level semantics and naturally shared over multi-ple classes. On the other hand, contrastive learning max-imizes the agreement between variants of the same shape with different missing portions, thus producing a represen-tation which captures the global appearance of the shape.
The combined embedding inherits category-agnostic prop-erties from the chosen pretext tasks. Differently from exist-ing approaches, this allows to better generalize the comple-tion properties to new categories unseen at training time.
Moreover, while decoding the obtained joint representa-tion, we better blend the reconstructed missing part with the partial shape by paying attention to its known surround-ing region and reconstructing this frame as auxiliary objec-tive. Our extensive experiments and detailed ablation on the
ShapeNet dataset show the effectiveness of each part of the method with new state of the art results. Our quantitative and qualitative analysis conﬁrms how our approach is able to work on novel categories without relying neither on clas-siﬁcation and shape symmetry priors, nor on adversarial training procedures. 1.

Introduction
Cameras that scan and render objects in 3D are becoming more and more available as standard feature in many smart-phones, drones, robots and cars. Most of these 3D sensing technologies are low-cost stereo cameras as well as depth and laser scanners that output point clouds which are often incomplete due to occlusions, transparency, light reﬂections or limitations in resolution and viewing angle. The missing
Figure 1. Our DeCo encodes local and global information from the training data via denoising and contrastive learning. The learned embedding is ﬁnally decoded to estimate the missing part of the input shape and a frame, i.e. a context region around the hole.
Thanks to the class-agnostic nature of the self-supervised pretext tasks, our model is effective for point-cloud completion on novel object categories. regions corrupt the object shape preventing its direct use in tasks like robotic manipulation [28], scene understanding
[10], autonomous driving [2] and augmented reality [17].
To overcome those issues, point cloud completion aims at estimating the complete geometry of the missing regions from partial observations.
There have been several efforts to tackle the completion problem including volumetric representations and related distance ﬁelds or mesh models. The most recent literature focuses on the efﬁcient solution of directly inferring new points: a widely used pipeline consists in encoding the par-tial input into a latent representation which is then decoded to produce the whole shape. However, this strategy leads to an overly difﬁcult setting, where the method attempts at re-constructing the entire point cloud rather than simply ﬁlling the missing part. As a consequence, the learned model cap-tures the global geometry more than local properties of each sample, resulting in reconstructions that resemble a generic average object rather than the speciﬁc input instance. Na¨ıve design choices of the encoder also contribute to this ef-fect by squashing all the structural information of the point cloud into a single latent global feature with a signiﬁcant information loss on the details of local regions.
Among the techniques proposed to improve local and 4629
global feature fusion, some try to improve the encoder by describing the point cloud as a collection of surface ele-ments with expansion constraints [16], others model the 3D skeleton of the object [19] or propose new pooling oper-ations [32]. Better decoders have been also developed by revisiting and accumulating low level features as local de-scriptors [11, 34, 40], adopting a pyramid strategy to re-cover the missing geometry at multiple resolution levels
[11], or including skip and cascaded connections to share information with the encoder [34, 30]. Other approaches exploit local reﬁnements by point upsampling [16, 39], or via adversarial training of patch discriminators [30, 19].
Most of these techniques have never been challenged nei-ther with point clouds corrupted with more than one hole, nor with the reconstruction of object categories unseen at training time. As a matter of fact, in some cases, per-class shape priors are adopted as supervised oracle initial-ization for the missing points [30]. In order to overcome this closed-set scenario, we propose a novel point cloud comple-tion method that exploits the power of two self-supervised pretext tasks and inherits their category-agnostic properties with a clear generalization effect. Speciﬁcally, the main contributions of this work are summarized as follows:
• We propose DeCo (see Figure 1), a model for point cloud completion, that combines local information from
Denoising [20] and global information from Contrastive learning [3]. In this way we shed new light on local and global cues which are otherwise reduced just to features at different network depths.
• The self-supervised learned embedding is ﬁnally decoded to estimate the missing part of the input shape and a frame, i.e. a context region around the hole. This solu-tion avoids the risks of genus-wise distortions [36], and allows to better blend the predicted missing part to the incomplete input.
• DeCo’s architecture is designed by exploiting graph con-volutions. To the best of our knowledge, the graph logic is used here on point cloud completion for the ﬁrst time.
• We present extensive experiments on ShapeNet [1] with point clouds corrupted by single and multiple holes as well as testing on novel categories. Our quantitative and qualitative results show the effectiveness of DeCo and set the new state of the art. 2.