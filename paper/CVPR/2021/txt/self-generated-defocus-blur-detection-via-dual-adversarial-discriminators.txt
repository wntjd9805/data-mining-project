Abstract
Although existing fully-supervised defocus blur detection (DBD) models signiﬁcantly improve performance, training such deep models requires abundant pixel-level manual an-notation, which is highly time-consuming and error-prone.
Addressing this issue, this paper makes an effort to train a deep DBD model without using any pixel-level annota-tion. The core insight is that a defocus blur region/focused clear area can be arbitrarily pasted to a given realistic full blurred image/full clear image without affecting the judg-ment of the full blurred image/full clear image. Speciﬁ-cally, we train a generator G in an adversarial manner against dual discriminators Dc and Db. G learns to pro-duce a DBD mask that generates a composite clear image and a composite blurred image through copying the focused area and unfocused region from corresponding source im-age to another full clear image and full blurred image.
Then, Dc and Db can not distinguish them from realis-tic full clear image and full blurred image simultaneous-ly, achieving a self-generated DBD by an implicit manner to deﬁne what a defocus blur area is. Besides, we pro-pose a bilateral triplet-excavating constraint to avoid the degenerate problem caused by the case one discriminator defeats the other one. Comprehensive experiments on t-wo widely-used DBD datasets demonstrate the superiority of the proposed approach. Source codes are available at: https://github.com/shangcai1/SG. 1.

Introduction
Defocus blur will emerge when the scene is out of the camera’s focus distance, which is a common phenomenon in an image. Defocus blur detection (DBD) can be poten-tially used to many vision tasks (e.g., salient region detec-tion [9], autofocus [39], depth estimation [19, 5]). Thus,
DBD has been gaining more and more research interest. Re-cently, deep convolutional neural networks (CNNs)-based
DBD methods [25, 24, 43, 27, 44, 25, 11, 38, 45] achieve
∗Corresponding author: Wenda Zhao (zhaowenda@dlut.edu.cn). (a) Source (b) SOD (c) DBD (d) Lesion study of SOD (e) Lesion study of DBD
Figure 1. Semantic correlation comparison of saliency object de-tection (SOD) and defocus blur detection (DBD). (a)-(c): source image, SOD result, and DBD result. (d) and (e) are lesion studies of SOD and DBD on ECSSD dataset [33] and DUT dataset [44], respectively. ResNet50 [7] is fully trained, and then we measure the importance of each convolution block by removing it, leaving the skip connection unchanged. a high performance through abundant labeled data (e.g., pixel-level annotation [20, 43]). However, manual annota-tion is time-consuming and error-prone. In order to bridge this gap, we make an effort to obtain DBD directly from real images without using any pixel-level annotation.
Intuitively, some unsupervised segmentation tasks, such as saliency object detection [35, 36] and semantic segmen-tation [31, 14, 8, 13, 30, 17], can be used to relieve our problem. For example, Zhang et al. [36] propose a “super-vision by fusion” strategy through generating reliable su-pervisory signals in the process of weak saliency model fu-sion. Bielski et al. [2] adopt the idea, where objects can be moved locally independently of a given background, to design perturbed generative models for unsupervised object segmentation. In brief, these methods always employ ob-6933
ject semantic information to achieve unsupervised segmen-tation. However, the object semantic information is weak-ly related to DBD [37]. Figures 1 (a)-(c) show the visual comparison.
In contrast to saliency object detection that segments semantic objects (e.g., cat and bird), DBD detect-s focused clear areas that ignores semantic integrity. For example, the clear head of a cat and partial weak seman-tic stumps are detected. Moreover, inspired by the valida-tion in [28] that residual networks can be seen as a col-lection of many paths where they do not strongly depend on each other, we delete individual convolution block path from ResNet50 [7] after it has been fully trained to anal-ysis the semantic correlation. As shown in Figure 1 (e), deleting any high-level semantic blocks (D12-D15) has no a noticeable performance change. However, deleting some low-level convolution blocks (D1-D11) will reduce the per-formance. This is contrary to saliency object detection that strongly relies on high-level semantic features (see Figure 1 (d)). Therefore, weak semantic correlation brings a larger challenge for unsupervised DBD.
Based on the attribute of weak semantic correlation in
DBD, a principle can be acquired: A defocus blur region can be arbitrarily moved relative to a given realistic ful-l blurred image without affecting the judgment of the full blurred image; Similarly, a focused clear region can be ran-domly pasted to a given realistic full clear image without affecting the criterion of the full clear image. Sequentially, we propose a unsupervised learning framework 1 through this principle.
The core idea is that we ﬁrstly build a generative network to output a DBD mask without ground truth as supervision.
Then, the focused and unfocused regions are cut out through the predicted mask from corresponding source image, re-spectively. Afterwards, two composite images of Cc and
Cb, obtained by pasting the focused region and unfocused region to another full clear image and full blurred image, are fed into two discriminative networks, respectively. The dis-criminators aim to distinguish whether Cc is a realistic full clear image and Cb is a realistic full blurred image. In order to fool the discriminators to believe that, the generator must output a DBD mask that accurately cuts out the focused re-gion and unfocused area from corresponding source image.
Therefore, we achieve an implicit manner to deﬁne what a defocus blur area is, that avoids manual labelling.
Especially, the motivation of implementing dual adver-sarial discriminative networks is to avoid a degenerate so-lution that generates a partial or an excessive DBD mask to fool the discriminator successfully. Speciﬁcally, if a sin-gle discriminative network is adopted, a partial DBD mask can generate a full clear image to fool the discriminator (see the second row of Figure 2). On the other hand, an exces-1 Here, “unsupervised” means that our method achieves DBD without using any pixel-level manual annotation. (b) x x (c) (a) x x x x x x x x (d) x (e) (f) x
Figure 2. Motivation of implementing dual adversarial discrimi-native networks. (a)-(c) are source image, full clear image, and full blurred image, respectively. (d)-(f) are DBD mask, compos-ite blurred image, and composite clear image, respectively. In the second row, a partial DBD mask can compose a full clear image to fool one discriminator (expressed as X), but can not generate a ful-l blurred image to fool another discriminator (marked as ×). An excessive DBD mask has the opposite effect (see the third row).
In contrast, the DBD mask generated with the help of dual adver-sarial discriminative networks is accurate, such that the composite blurred image and composite clear image can fool dual discrimi-nators successfully, as shown in the fourth row. sive DBD mask can generate a full blurred image to fool another discriminator (see the third row of Figure 2). Our proposed dual adversarial discriminative networks can alle-viate this problem. Since a partial DBD mask can generate a full clear image to fool one discriminator, but can not si-multaneously generate a full blurred image to fool another discriminator. Similarly, the principle is used to avoid the failure of generating an excessive DBD mask. Therefore, only if the produced DBD mask is accurate can the com-posite blurred image and composite clear image fool dual discriminators successfully (see the fourth row of Figure 2).
Additionally, in the adversarial training process for our unsupervised framework, one discriminator easily defeat-s the other one, which will force the generator to generate a full DBD mask or an empty DBD mask. To avoid this failure, we propose a bilateral triplet-excavating constraint to effectively balance these two discriminators. Speciﬁcal-ly, we ﬁrst implement a classiﬁcation network to excavate the feature relationship of triplet images among the realistic 6934
full clear image, full blurred image and mixed image which includes both clear region and blurred area. Afterwards, we encourage the feature-space distance between the com-posite clear image Cc and another realistic full clear im-age to get closer, and simultaneously inspire the distance of the composite blurred image Cb and another realistic full blurred image to be smaller. With this constraint, the two discriminators can easily achieve a balance, which thereby makes the mechanism of encouraging the generator to pro-duce an accurate DBD mask to simultaneously fool the two discriminators come into force.
Main contributions in this paper are summarized as fol-lows.
• We make an effort to train an effective deep defocus blur detector without using any pixel-level manual an-notation.
• We build dual adversarial discriminative networks to force the generator to produce an accurate DBD mask.
• We propose a bilateral triplet-excavating constraint to avoid the degenerate problem, where one discrimina-tor defeats the other one, easily making the generator produce a full or an empty DBD mask.
We validate the effectiveness of the proposed unsuper-vised module on two widely-used benchmark datasets. 2.