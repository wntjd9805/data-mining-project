Abstract
Image and video descriptors are an omnipresent tool in computer vision and its application ﬁelds like mobile robotics. Many hand-crafted and in particular learned im-age descriptors are numerical vectors with a potentially (very) large number of dimensions. Practical considera-tions like memory consumption or time for comparisons call for the creation of compact representations. In this paper, we use hyperdimensional computing (HDC) as an approach to systematically combine information from a set of vec-tors in a single vector of the same dimensionality. HDC is a known technique to perform symbolic processing with distributed representations in numerical vectors with thou-sands of dimensions. We present a HDC implementation that is suitable for processing the output of existing and fu-ture (deep learning based) image descriptors. We discuss how this can be used as a framework to process descriptors together with additional knowledge by simple and fast vec-tor operations. A concrete outcome is a novel HDC-based approach to aggregate a set of local image descriptors to-gether with their image positions in a single holistic de-scriptor. The comparison to available holistic descriptors and aggregation methods on a series of standard mobile robotics place recognition experiments shows a 20% im-provement in average performance and > 2 better worst-case performance compared to runner-up.
× 1.

Introduction
Image descriptors are very useful tools for recognition tasks in computer vision. Many hand-crafted and in par-ticular deep learning based descriptors are numerical vec-tors with a potentially large number of dimensions, e.g.
NetVLAD [1] uses 4,096-D vectors (after PCA), DELF [44] uses 1,024-D vectors (before PCA). Approaches like BoW
[56], VLAD [23], or ASMK [60] aggregate the information from multiple vectors in a single holistic vector represen-tation to reduce memory consumption and computational efforts during comparison. For example, deciding whether two images show the same place based on a set of local landmarks from each image can then be done by a single distance measure between the two aggregated vectors. Al-though these techniques are able to combine large numbers of descriptors in a compact vector, for certain tasks like place recognition, it is beneﬁcial to encode additional infor-mation in the ﬁnal vector representation, e.g., information about the image locations of aggregated vectors.
The central idea of this paper is to use binding and bundling of vectors as a ﬂexible framework to combine im-age descriptors and additional information. The underly-ing technique of binding and bundling vectors is taken from a ﬁeld known as hyperdimensional computing (HDC) or vector symbolic architectures (VSA). This is an established class of approaches to solve symbolic computational prob-lems using mathematical operations on large numerical vec-tors with thousands of dimensions [25, 42]. The bundling operator superposes information of a variable number of vectors in a single vector; we can think of it as some form can, for example, ex-of averaging. The binding operator press role-ﬁller or variable-value pairs as required in sym-bolic processing. An important property is that the output of the operations are vectors from the same vector space.
This allows to chain HDC operations and enables versatile encoding of structured data from a set of d-dimensional vec-tors in a single d-dimensional vector.
⊕
⊗
We will present a HDC implementation that allows the processing of existing and future (deep learning based) im-age descriptors in Sec. 3. This section will also describe how HDC can be used as a framework to aggregate holistic or local image descriptors and to combine them with addi-tional information. A concrete outcome is a novel approach to create a holistic image descriptor from a set of local de-scriptors with image position information in Sec. 3.2.2. For example, we can create a holistic descriptor from three lo-cal descriptors L1, L2, L3 with poses P1, P2, P2 as simple
P3). The poses serve as (L1
⊕ as “roles“ that are associated with landmarks as “ﬁllers“.
When comparing two such holistic descriptors (e.g. based
P2)
P1) (L3 (L2
⊗
⊗
⊕
⊗ 16938
on a single cosine similarity computation), the similarity of the roles decides to what extend the similarities of the asso-ciated local descriptors are incorporated in the overall simi-larity. Prerequisites are appropriate preprocessing of the de-scriptors as well as a suitable encoding of image positions in the same vector space as the descriptors, both will be pre-sented in Sec. 3.1. The experiments in Sec. 4 will evaluate properties in a series of mobile robotics place recognition experiments. Code and additional material are available.1 2.