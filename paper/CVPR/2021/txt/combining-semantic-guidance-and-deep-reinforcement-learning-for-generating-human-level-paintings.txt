Abstract
Generation of stroke-based non-photorealistic imagery, is an important problem in the computer vision commu-nity. As an endeavor in this direction, substantial recent research efforts have been focused on teaching machines
“how to paint”, in a manner similar to a human painter.
However, the applicability of previous methods has been limited to datasets with little variation in position, scale and saliency of the foreground object. As a consequence, we ﬁnd that these methods struggle to cover the granular-ity and diversity possessed by real world images. To this end, we propose a Semantic Guidance pipeline with 1) a bi-level painting procedure for learning the distinction be-tween foreground and background brush strokes at train-ing time. 2) We also introduce invariance to the position and scale of the foreground object through a neural align-ment model, which combines object localization and spa-tial transformer networks in an end to end manner, to zoom into a particular semantic instance. 3) The distinguishing features of the in-focus object are then ampliﬁed by max-imizing a novel guided backpropagation based focus re-ward. The proposed agent does not require any supervi-sion on human stroke-data and successfully handles varia-tions in foreground object attributes, thus, producing much higher quality canvases for the CUB-200 Birds [29] and
Stanford Cars-196 [17] datasets. Finally, we demonstrate the further efﬁcacy of our method on complex datasets with multiple foreground object instances by evaluating an ex-tension of our method on the challenging Virtual-KITTI [2] dataset. Source code and models are available at https:
//github.com/1jsingh/semantic-guidance. 1.

Introduction
Paintings form a key medium through which humans ex-press their visual conception, creativity and thoughts. Being able to paint constitutes a vital skill in the human learning process and requires long-term planning to efﬁciently con-(a) (b) (c) (d)
Figure 1. Semantic Guidance. We propose a semantic guidance pipeline for the “learning to paint” problem. The reinforcement learning agent incorporates (b) object localization and semantic segmentation maps for the target image (a), to achieve enhanced foreground saliency (refer Fig. 3) in the ﬁnal canvas (d). We also introduce expert guidance to amplify the focus on small but dis-tinguishing features of the foreground objects (e.g. bird’s eye), by proposing (c) a guided backpropagation based focus reward. vey the picture within a limited number of brush strokes.
Thus, the successful impartation of this challenging skill to machines, would not only have huge applications in com-puter graphics, but would also form a key component in the development of a general artiﬁcial intelligence system.
Recently, a lot of research [6, 11, 15, 22, 31, 34] is being targeted on teaching machines “how to paint”, in a manner similar to a human painter. A popular solution to this prob-lem is to use reinforcement learning and model the painting episode as a Markov Decision Process (MDP). Given a tar-16387
get image, the agent learns to predict a sequence of brush strokes which when transferred on to a canvas, result in a painting which is semantically and visually similar to the input image. The reward function for the agent is usually learnt using a generative adversarial network (GAN) [9], which provides a measure of similarity between the ﬁnal canvas and the original target image.
In this paper, we propose a semantic guidance pipeline which addresses the following three challenges faced by the current painting agents. First, the current methods
[6, 15, 22] are limited to only datasets which depict a single dominant instance per image (e.g. cropped faces). Experi-mental results reveal that this leads to poor performance on varying the position, scale and saliency of the foreground object within the image. We address this limitation by adopting a bi-level painting procedure, which incorporates semantic segmentation into the painting process, to learn a distinction between brush stroke patterns for foreground and background image regions. Here, we utilize the intu-ition that the human painting process is deeply rooted in our semantic understanding of the image components. For instance, an accurate depiction of a bird sitting on a tree would depend highly on the agent’s ability to recognize the bird and the tree as separate objects and hence use corre-spondingly different stroke patterns / plans.
Second, variation in position and scale of the foreground objects within the image, introduces high variance in the in-put distribution for the generative model. To this end, we propose a neural alignment model, which combines object localization and spatial transformer networks to learn an afﬁne mapping between the overall image and the bound-ing box of the target object. The neural alignment model is end-to-end and preserves the differentiability requirement for our model-based reinforcement learning approach.
Third, accurate depiction of instances belonging to the same semantic class should require the painting agent to give special attention to different distinguishing features.
For instance, while the shape of the beak may be a key fea-ture for some birds, it may be of little consequence for other bird types. We thus propose a novel guided backpropaga-tion based focus reward to increase the model’s attention on these ﬁne-grain features. The use of guided backpropaga-tion also helps in amplifying the importance of small image regions, like a bird’s eye which might be otherwise ignored by the reinforcement learning agent.
In summary, the main contributions of this paper are:
• We introduce a semantically guided bi-level painting process to develop a better distinction between fore-ground and background brush stroke patterns.
• We propose a neural alignment model, which com-bines object localization and spatial transformer net-works in an end to end manner to zoom in on a partic-ular foreground object in the image.
• We ﬁnally introduce expert guidance on the relative importance of distinguishing features of the in-focus object (e.g. tail, beak etc. for a bird) by proposing a novel guided backpropagation based focus reward. 2.