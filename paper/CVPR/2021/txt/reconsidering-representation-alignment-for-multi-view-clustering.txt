Abstract
Aligning distributions of view representations is a core component of today’s state of the art models for deep multi-view clustering. However, we identify several draw-backs with na¨ıvely aligning representation distributions. We demonstrate that these drawbacks both lead to less separable clusters in the representation space, and inhibit the model’s ability to prioritize views. Based on these observations, we develop a simple baseline model for deep multi-view clus-tering. Our baseline model avoids representation alignment altogether, while performing similar to, or better than, the current state of the art. We also expand our baseline model by adding a contrastive learning component. This introduces a selective alignment procedure that preserves the model’s ability to prioritize views. Our experiments show that the contrastive learning component enhances the baseline model, improving on the current state of the art by a large margin on several datasets1. 1.

Introduction
Several kinds of real world data are gathered from dif-ferent points of view, or by using a collection of different sensors. Videos, for instance, contain both visual and audi-ble components, while captioned images include both the raw image data and a descriptive text. In both of these exam-ples, the low-level content of the views are vastly different, but they can still carry the same high-level cluster structure.
The objective of multi-view clustering is to discover this common clustering structure, by learning from all available views simultaneously.
Learning from multiple sources at once is not a trivial task [6]. However, the introduction of deep learning [33], has led to the development of several promising deep multi-view clustering models [1, 36, 48, 61, 64]. These models efﬁciently learn from multiple views by transforming each view with a view-speciﬁc encoder network. The resulting representations are fused to obtain a common representation
*UiT Machine Learning Group, machine-learning.uit.no 1The source code for the experiments performed in this paper is available at https://github.com/DanielTrosten/mvc for all views, which can then be clustered by a subsequent clustering module.
The current state of the art methods for deep multi-view clustering use adversarial training to align the representation distributions from different views [36, 64].
Aligning distributions leads to view invariant represen-tations, which can be beneﬁcial for the subsequent fusion of views, and the clustering module [64]. View invariant representations preserve the information present in all views, while discarding information that only exists in a subset of views. If the view-speciﬁc information is irrelevant to the clustering objective, it will be advantageous for the cluster-ing module that the encoders learn to remove it. Moreover, aligning representation distributions introduces an auxiliary task, which regularizes the encoders, and helps preserve the local geometric structure of the input space. This has been shown to improve single-view deep clustering models [21].
Despite these advantages however, we identify three im-portant drawbacks of distribution alignment for multi-view clustering:
Aligning representations prevents view-prioritization in the representation space. Views are not necessarily equally important to the clustering objective. The model should therefore be able to adaptively prioritize views, based on the information contained in the view representations. However, aligning representation distributions makes it harder for the model to prioritize views in the representation space, by making these distributions as similar as possible.
One-to-one alignment of clusters is only attainable when encoders can separate all clusters in all views. When the clustering structure is only partially present in the individual views, alignment causes clusters to merge together in the representation space. This makes the clustering task more difﬁcult for the subsequent clustering module.
Aligning representation distributions can make it harder to discriminate between clusters. Since adversarial align-ment only considers the representation distributions, a given cluster from one view might be aligned with a different cluster from another view. This misalignment of label dis-tributions has been shown to have a negative impact on discriminative models in the representation space [62].
The End-to-end Adversarial-attention network for Multi-1255
modal Clustering (EAMC) [64] represents the current state of the art for deep multi-view clustering. EAMC aligns the view representations by optimizing an adversarial objective on the encoder networks. The resulting representations are fused with a weighted average, with weights produced by passing the representations through an attention network.
Following our reasoning above, we hypothesize that the alignment done by the adversarial module may defeat the purpose of the attention mechanism. Thus inhibiting view prioritization, and leading to less separable clusters after fusion. Our hypothesis is supported by the empirical results of EAMC [64], where the fusion weights are close to uni-form for all datasets. Equal fusion weights cause all views to contribute equally to the fused representation, regardless of their contents. Moreover, the fusion weights produced by the attention network depend on all the samples within the current batch. Out-of-sample inference is therefore impossi-ble with EAMC, without making additional modiﬁcations to the attention mechanism.
In this work, we seek to alleviate the problems that can arise when aligning distributions of representations in deep multi-view clustering. To this end, we make the following key contributions: 2. Pitfalls of distribution alignment in multi-view clustering
Here, we consider an idealized version of the multi-view clustering problem. This allows us to investigate and for-malize our observations on alignment of representation dis-tributions in multi-view clustering. By assuming that, for each view, all samples within a cluster are located at the same point in the input space, we develop the following proposition2:
Proposition 1. Suppose our dataset consists of V views and k ground truth clusters, and we wish to cluster the data according to this ground truth clustering. Furthermore, we make the following assumptions: 1. For each view, all observations that belong to the same ground truth cluster, are located at the same point in the input space. 2. For a given view v, v ∈ {1, . . . , V }, the number of unique points (i.e. distinct/separable clusters) in the input space is kv. 3. The views are mapped to representations using view-speciﬁc encoders, and subsequently fused according to a linear combination with unique weights.
Then, the maximum number of unique clusters after fusion
• We highlight pitfalls of aligning representation distribu-tions in deep multi-view clustering, and show that these pitfalls limit previous state of the art models. is
• We present Simple Multi-View Clustering (SiMVC) – a new and simple baseline model for deep multi-view clustering, without any form of alignment. Despite its simplicity compared to existing methods, our experi-ments show that this baseline model performs similar to – and in some cases, even better than – current state of the art methods. SiMVC combines representations of views using a learned linear combination – a simple but effective mechanism for view-prioritization. We empirically demonstrate that this mechanism allows the model to suppress uninformative views and emphasize views that are important for the clustering objective.
• In order to leverage the advantages of alignment – i.e. preservation of local geometric structure, and view in-variance – while simultaneously avoiding the pitfalls, we attach a selective contrastive alignment module to
SiMVC. The contrastive module aligns angles between representations at the sample level, circumventing the problem of misaligned label distributions. Furthermore, in the case that one-to-one alignment is not possible, we make the model capable of ignoring the contrastive objective, preserving the model’s ability to prioritize views. We refer to this model as Contrastive Multi-View
Clustering (CoMVC).
κfused aligned = min
V k, ( (cid:18) min v=1,...,V
{kv}
) (cid:19) (1) if the distributions of representations from different views are perfectly aligned, and
κfused not aligned = min k, (
V v=1
Y kv
) (2) if no alignment is performed.
·
·
Implications of Proposition 1. κfused in Proposition 1 con-trols how well the clustering module is able to cluster the fused representations. If κfused
< k, it means that some of the clusters are located at the same point after fusion, mak-ing it impossible for the clustering module to discriminate between these clusters. In the extreme case that one of the views groups all the clusters together (i.e. kv = 1), it fol-lows that κfused aligned = 1. This happens because all other views are aligned to the uninformative view (for which kv = 1), collapsing the cluster structure in the representation space.
Alignment thus prevents the suppression of this view, and makes it harder to discriminate between clusters in the repre-sentation space. 2We provide a proof sketch for Proposition 1 in the supplementary. 1256
(a) SiMVC +Adv. ACC = 0.80 (b) SiMVC. ACC = 0.99. (c) CoMVC. ACC = 0.99. (d) EAMC. ACC = 0.368.
Figure 1: Representations for SiMVC with and without adversarial alignment, CoMVC, and EAMC on our toy dataset.
Figure 2: Toy dataset. View 1: Classes (1-3) and (4,5) overlap. View 2: Class 1 is isolated, and classes (2,4) and (3,5) overlap.
However, if we are able to discriminate between all clus-ters in all views, we have kv = k for all views, resulting in
κfused aligned = κfused not aligned = k. In this case it is possible for both alignment-based models and non-alignment-based models to perfectly cluster the data, provided that the clustering mod-ule is sufﬁciently capable. Alignment-based models can thus beneﬁt from the advantages of alignment, while still being able to separate clusters after fusion.
Experiments on toy data. Proposition 1 makes the sim-pliﬁcation that all samples within a cluster are located at the same point, for each view. In order to demonstrate the potential negative impact of aligning representation distribu-tions in a less idealistic setting, and to further motivate the problem, we create a simple two-view dataset. The dataset is shown in Figure 2, and contains ﬁve elliptical clusters in two two-dimensional views3.
We ﬁt SiMVC and SiMVC with adversarial alignment (SiMVC +Adv.) to this dataset, in order to demonstrate the effects of aligning distributions, in a controlled setting. Ad-ditionally, we ﬁt our CoMVC and the current state of the art,
EAMC, to evaluate more advanced alignment procedures.
Note that, for all of these models, the fusion is implemented as a weighted average of view representations, as in Proposi-tion 1. The remaining details on SiMVC and CoMVC are provided in the next section. aligned = 4 and κfused
Figures 1a and 1b show that attempting to align distri-butions with adversarial alignment prevents SiMVC from separating between clusters 1 and 4. By adding the adversar-ial alignment to SiMVC, the number of visible clusters after fusion is reduced from 5 to 4. This is in line with Proposi-tion 1, since we have κfused not aligned = 5 for this dataset. Figure 1c shows that CoMVC, which relies on the cosine similarity, aligns the angles between the majority of observations. This alignment does not cause classes to over-lap in the fused representation. EAMC attempts to align the distributions of view representations (Figure 1d), resulting in a fused representation where the classes are hard to separate.
Interestingly, the resulting fused representation exhibits a single group of points, which is signiﬁcantly worse than the upper bound κfused aligned = 4 in the analogous idealistic setting.
We hypothesize that this is due to EAMC’s fusion weights, which we observed to be almost equal for this experiment – thus breaking assumption 3 in Proposition 1. 3We repeat this experiment for a 3-cluster dataset in the supplementary. 1257
3. Methods compact in the space of hidden representations: 3.1. Simple Multi View Clustering (SiMVC)
Suppose our dataset consists of n objects observed from
V views. Let x(v) be the observation of object i from view v. The objective of our models is then to assign the set of views for each object, {x(1)
}, to one of k clusters. to its repre-i
To achieve this, we ﬁrst transform each x(v)
, . . . , x(V ) i i i sentation z(v) i according to i = f (v)(x(v) z(v) i
) k−1 k
L1 = i=1
X j=i+1
X s k 2 n (cid:0) n
−1 n n a=1 b=1 (cid:1)
P
P
αaiκabαbi
αaiκabαbj n n
αajκabαbj a=1
P b=1
P a=1
P b=1
P (5) where k denotes the number of clusters, κij = exp(−||hi − hj||2/(2σ2)), and σ is a hyperparameter.
The second term encourages the cluster assignment vec-(3) where f (v) denotes the encoder network for view v. We then compute the fused representation as a weighted average
V zi = wvz(v) i (4)
P v=1
X where w1, . . . , wv are the fusion weights, satisfying wv > 0
V for v = 1, . . . , V and v=1 wv = 1. We enforce these constraints by keeping a set of unnormalized weights, from which we obtain w1, . . . , wV using the softmax function.
We let the unnormalized weights be trainable parameters – a design choice which has the following advantages: (i) Dur-ing training, the model has a simple and interpretable way to prioritize views according to its clustering objective. By not relying on an auxiliary attention network, we also make the model more efﬁcient – both in terms of memory consump-tion and training time4. (ii) In inference, the weights act as any other model parameters, meaning that out-of sample inference can be done with arbitrary batch sizes, without any modiﬁcations to the trained model. Fixed fusion weights also result in deterministic predictions, which are independent of any other samples within the batch.
To obtain the ﬁnal cluster assignments, we pass the fused representation through a fully connected layer, producing the hidden representation hi. This is processed by another fully connected layer with a softmax activation, to obtain the k-dimensional vector of soft cluster assignments, αi.
Loss function. We adopt the Deep Divergence-based Clus-tering (DDC) [30] loss, which has shown state of the art performance in single-view image clustering [30]. This is also the clustering loss used by EAMC [64] – the current state of the art method for multi-view clustering.
The clustering loss consists of three terms, enforcing cluster separability and compactness, orthogonal cluster as-signments, and closeness of cluster assignments to simplex corners, respectively. The ﬁrst loss term is derived from the multiple-density generalization of the Cauchy-Schwarz divergence [28], and requires clusters to be separable and 4Average training times for SiMVC, CoMVC, and EAMC are given in the supplementary. tors for different objects to be orthogonal:
L2 = n 2 (cid:18) (cid:19)
−1 n−1 n i=1
X j=i+1
X
αT i αj. (6)
Finally, the third term pushes the cluster assignment vectors close to the standard simplex in Rk: k−1 k
L3 = i=1
X j=i+1
X
−1 n n a=1 b=1 (cid:1)
P
P maiκabmbi k 2 n (cid:0) n s a=1
P b=1
P maiκabmbj n n a=1
P b=1
P majκabmbj (7) where mij = exp(−||αi − ej||2), and ej is corner j of the standard simplex in Rk.
The ﬁnal clustering loss which we minimize during train-ing of SiMVC is the sum of these three terms:
Lcluster = L1 + L2 + L3. (8) 3.2. Contrastive Multi View Clustering (CoMVC)
Contrastive learning offers a way to align representations from different views at the sample level, forcing the la-bel distributions to be aligned as well. Our hypothesis is therefore that a selective contrastive alignment will allow the model to learn common representations that are well suited for clustering – while simultaneously avoiding the previously discussed pitfalls of distribution alignment. Self-supervised contrastive models have shown great potential for a large variety of downstream computer vision tasks
[5, 12, 13, 20, 22, 40, 49]. These models learn image rep-resentations by requiring that representations from positive pairs are mapped close together, while representations from negative pairs are mapped sufﬁciently far apart. In multi-view learning, each object has a set of observations from different views associated with it. This admits a natural def-inition of pairs: Let views of the same object be positive pairs, and views of different objects be negative pairs. 1258
x(1) 1
... x(1) n x(2) 1
... x(2) n f (1)
View-speciﬁc encoders f (2) 1 , . . . , z(1) z(1) n zi = w1z(1) i + w2z(2) i
Fusion 1 , . . . , z(2) z(2) n 1 , . . . , z(1) z(1) n 1 , . . . , z(2) z(2) n
Separated
Compact
Orthogonal
Clustering module i
, z(u) i
A straightforward way to construct Neg(z(v)
) would be to include the similarity between all views of object i, and all views of all the other objects within the current batch. However, minimizing Eq. (11) will result in neg-ative samples having a low similarity score. This is indeed the objective of ordinary contrastive learning, but it might be counteractive to the clustering objective, where we want objects from the same cluster to be grouped together in the representation space, and thus be similar to each other. To prevent the contrastive loss from breaking this group struc-ture, we construct Neg(z(v)
, z(u)
) in the following manner: i
First, we deﬁne the set i
Contrastive module
Figure 3: Overview of our proposed models for a two-view dataset. In both SiMVC and CoMVC, the views are ﬁrst encoded by the view-speciﬁc encoder networks f (1) and f (2). The resulting representations are fused with a weighted mean, and then clustered by the clustering module. CoMVC includes an additional contrastive module.
Following [12], we compute the similarity of two repre-sentations z(v) i and z(u) j as the cosine similarity:
Ni = {s(uv) ij
: j = 1, . . . , n, j 6= i, u, v = 1, . . . , V, arg max αi 6= arg max αj}, (12) which consists of all similarities between all views of ob-ject i, and all views of all other objects that were assigned to a different cluster than object i. We then construct
Neg(z(v)
) by sampling a ﬁxed number of similarities from Ni. This procedure ensures that we only repel repre-sentations of objects that were assigned to different clusters by the clustering module.
, z(u) i i s(vu) ij = z(v) i
||z(v) i
T z(u) j
|| · ||z(u) j
.
|| (9)
CoMVC is the result of adding this contrastive learning framework to SiMVC. Figure 3 shows a schematic overview of the model for a dataset containing two views.
The loss we use to train CoMVC is
Note that in [12], they show that the addition of a projection head between the representations and the similarity, results in better representations – in terms of linear classiﬁcation accuracy on the learned representations. We found that this was not the case for our model, so we chose to compute the similarity on the representations directly. Experiments com-paring versions of our model with and without the projection head can be found in the supplementary.
In order to deﬁne a contrastive loss for an arbitrary num-ber of views, we introduce the following generalized version of the NT-Xent loss [12]:
Lcontrastive = 1 nV (V − 1) n
V
V 1
{u6=v}ℓ(uv) i (10) v=1
X
{u6=v} evaluates to 1 when u 6= v and 0 otherwise, u=1
X i=1
X where 1 and
ℓ(uv) i
= − log
/τ ii es(uv) s′∈Neg(z(v) i
,z(u) i
) es′/τ . (11)
P
Here, τ is a hyperparameter5, and Neg(z(v)
) denotes the set of similarities for negative pairs corresponding to the positive pair (z(v)
, z(u) i
). i
, z(u) i i 5We set τ = 0.1 for all experiments, following [12].
L = Lcluster + δ · min{w1, . . . , wV }Lcontrastive (13) where Lcluster is the clustering loss deﬁned in Eq. (8), and
δ is a hyperparameter which inﬂuences the strength of the contrastive loss. w1, . . . wV are the fusion weights from
SiMVC6.
Minimizing the contrastive loss results in representations that have high cosine similarities. The contrastive alignment is therefore (i) approximate, since only the angles between representations, and not the representations themselves, are considered; and (ii) at the sample level, preventing mis-aligned label distributions. Furthermore, multiplying the contrastive loss with the smallest fusion weight automati-cally adjusts the strength of the contrastive loss, according to the weight of the least informative view. The alignment is therefore selective: If the model learns to discard a view by setting its fusion weight to 0, it will simultaneously disable the alignment procedure. By adapting the alignment weight and not relying on adversarial training, CoMVC can bene-ﬁt from the advantages of aligning representations, while circumventing both the drawbacks of adversarial alignment, and possible difﬁculties with min-max optimization [4, 19]. 6Note that we do not propagate gradients through the min operation, in order to avoid the trivial solution of setting the smallest fusion weight to 0. 1259
4.