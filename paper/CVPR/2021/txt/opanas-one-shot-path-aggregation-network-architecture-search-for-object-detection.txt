Abstract
Recently, neural architecture search (NAS) has been ex-ploited to design feature pyramid networks (FPNs) and achieved promising results for visual object detection. En-couraged by the success, we propose a novel One-Shot Path
Aggregation Network Architecture Search (OPANAS) al-gorithm, which signiï¬cantly improves both searching ef-ï¬ciency and detection accuracy.
Speciï¬cally, we ï¬rst introduce six heterogeneous information paths to build our search space, namely top-down, bottom-up, fusing-splitting, scale-equalizing, skip-connect and none. Sec-ond, we propose a novel search space of FPNs, in which each FPN candidate is represented by a densely-connected directed acyclic graph (each node is a feature pyramid and each edge is one of the six heterogeneous informa-tion paths). Third, we propose an efï¬cient one-shot search method to ï¬nd the optimal path aggregation architecture; speciï¬cally, we ï¬rst train a super-net and then ï¬nd the op-timal candidate with an evolutionary algorithm. Exper-imental results demonstrate the efï¬cacy of the proposed
OPANAS for object detection: (1) OPANAS is more ef-ï¬cient than state-of-the-art methods (e.g., NAS-FPN and
Auto-FPN) at signiï¬cantly smaller searching cost (e.g., only 4 GPU days on MS-COCO); (2) the optimal architecture found by OPANAS signiï¬cantly improves main-stream de-tectors including RetinaNet, Faster R-CNN and Cascade R-CNN, by 2.3âˆ¼3.2 % mAP compared to their FPN counter-parts; and (3) a new state-of-the-art accuracy-speed trade-off (52.2 % mAP at 7.6 FPS) is achieved at smaller training costs than comparable recent arts. Code will be released at https://github.com/VDIGPKU/OPANAS. 1.

Introduction
Recognizing objects at vastly different scales is one of the major challenges in computer vision. To address this
*indicates corresponding author.
Top-down
Bottom-up
Fusing-splitting
Scale-equalizing
Skip-connect
None
P
Input Node
O
Output Node
Intermediate Node
P
P 1 1 2 2
O
O
P
P 1 1
O
O
P
P 1 1 2 2
O
O
P
P 1 1
O
O 2 2 4 4 2 2 4 4 3 3 5 5
P
P 1 1 6 6
O
O 3 3 5 5 2 2 4 4
P
P 1 1
O
O 3 3 5 5 (a) FPN (b) PANet (c) Libra R-CNN (d) SEPC-Neck (e) Bi-FPN (f) OPA-FPN
Figure 1: Different FPN architectures: (a) FPN [17], (b)
PANet [21], (c) Libra R-CNN [23], (d) SEPC-Neck [28], (e) BiFPN [25], and (f) our searched optimal FPN. issue, great progress has been made in designing deep con-volutional networks in the past few years. Intuitively, di-rectly extracting feature pyramid [22] from CNN at differ-ent stages provides an efï¬cient solution. Each level of the feature pyramid corresponds to a speciï¬c scale in the orig-inal image. However, high-level features are with more se-mantics while the low-level ones are more content descrip-tive [31]. Such a semantic gap is unable to deliver strong features for multi-scale visual recognition tasks (e.g., object detection, and segmentation). To alleviate the discrepancy, different feature fusion strategies have been proposed. Fea-ture Pyramid Network (FPN) [17] is arguably the most pop-ular basic architecture and inspires many important variants.
It adopts a backbone model, typically designed for image classiï¬cation, and builds a top-down information ï¬‚ow by sequentially combining two adjacent layers in feature hier-archy in the backbone. By such design, low-level features are complemented by semantic information from high-level features. Despite simple and effective, FPN may not be the optimal architecture design.
Two lines of research have been conducted to advance
FPN-based detection algorithms. On one hand, various approaches (e.g., PANet [21], BiFPN [25], Libra R-CNN
[23] and SEPC [28]) enrich FPN by aggregating multi-ple heterogeneous information paths and achieve impres-10195  
Top-down
Bottom-up
Fusing-splitting
Scale-equalizing
Skip-connect
None
P
P
P 1 1 1
O
O
O 2 2 2 4 4 4 3 3 3 5 5 5 1. SPOS
P
P
P 1 1 1
O
O
O 2 2 2 4 4 4
Loss
Evolutionary 
Controller 3 3 3 5 5 5 (a) Super-net Training (b) Optimal Sub-net 
Search  2. OPANAS
P 1
O 3 5 2 4 (c) Searched Result
Figure 2: 1. Single-path FPN super-net from SPOS search space [12]. 2. Our OPANAS: (a) super-net training, i.e., the optimization of super-net weights; (b) optimal sub-net search with an evolutionary algorithm; (c) the searched optimal archi-tecture. Note that two information paths (skip-connect and none) work only for (b). top-down and bottom-up [21], sive results. However, as shown in Fig. 1 (a-e), they only explore aggregations of up to three types of infor-top-mation paths, (i.e., down and fusing-splitting [23], and top-down and scale-equalizing [28]). Moreover, most of these methods follow a straightforward chain-style aggregation structure, except
BiFPN that adds additional skip-connect on PANet with several repetitions, but remains in a simple topology. On the other hand, Neural Architecture Search (NAS)-based
FPN architectures [10, 26, 29] have achieved remarkable performance gain beyond manually designed architectures, but with following limitations: (1) inefï¬ciency, the search-ing processes are often computationally expensive (e.g., 300
TPU days [10]) due to the extremely large search space, and (2) weak adaptability, their searched architectures are spe-cialized for certain detector with special training skills (e.g., large batch size or longer training schedule).
Inspired by these studies and meanwhile to address aforementioned issues, we propose a new efï¬cient and ef-fective NAS framework, named OPANAS (One-Shot Path
Aggregation Neural Architecture Search, see Fig. 2) to automatically search a better FPN for object detection.
Firstly, we carefully design four parameterized information paths (top-down, bottom-up, scale-equalizing and fusing-splitting, see Fig. 3 (a-d)) and two parameter-free ones (skip-connect and none, see Fig. 3 (e-f)) to build our search space. Clearly, these six modules introduce different infor-mation ï¬‚ows, different connections between backbone and detection head, and lead to complementary and highly inter-pretable aggregation modules. Note that the four parame-terized ones are relatively heavy and the two parameter-free ones are light-weighted, and they work together to achieve a promising accuracy-efï¬ciency trade-off.
Secondly, to achieve the optimal aggregation of the six information paths, we propose a novel FPN search space, in which each FPN candidate is represented by a densely-connected directed acyclic graph (each node is a feature pyramid and each edge is a speciï¬c one of the six heteroge-neous information paths as shown in Fig. 3). Notably, our search space contains richer aggregation topological struc-tures of FPNs than existing methods as in Fig. 1, and hence enables richer cross-level and cross-module interactions.
Thirdly, we propose an efï¬cient one-shot search method to search the optimal FPN architecture, that is, we ï¬rst train a super-net and then search the optimal sub-net from the super-net with an evolutionary algorithm that has strong global optimum search capability. Experiments show that our method is efï¬cient as the differentiable NAS methods, i.e., DARTS [20] and Fair DARTS [5], while the searched
FPN architecture can achieve better detection accuracy with less parameters and FLOPs. Moreover, following the sim-ple vanilla training protocol, our searched FPN architec-ture can consistently improve the detection accuracy of the main-stream detectors including RetinaNet, Faster R-CNN and Cascade R-CNN by 2.3âˆ¼3.2 mAP, with less parame-ters and FLOPs. These results demonstrate the efï¬cacy of the proposed OPANAS for object detection.
Our contributions can be summarized as:
â€¢ We carefully design 6 information paths that can ag-gregate multi-level information, and thus enable the effective and complementary combination of low-, medium- and high-level information. To our knowl-edge, we are the ï¬rst to investigate the aggregations of multiple (>3) information paths.
â€¢ We propose a novel one-shot method, OPANAS, to ef-ï¬ciently and effectively search the optimal aggregation of the 6 kinds of information paths.
â€¢ Working as a plug and play module, our searched ar-chitecture can easily be adapted to main-stream detec-tors including RetinaNet, Faster R-CNN and Cascade 10196
3 Ã— 3 Deformable Conv.  3 Ã— 3 Conv. 
Identity Mapping
Parameterized Information Path
Parameter-free Information Path (a) Top-down (b) Bottom-up (c) Scale-equalizing (e) None 5  4 
ğ‘ƒ 3 
ğ‘ƒ 2 
ğ‘ƒ
ğ‘ƒ (d) Fusing-splitting 5  4 
ğ¹
ğ¹ 3  2 ğ¹
ğ¹ (f) Skip-connect
Figure 3: The proposed six heterogeneous information paths mapping 4-level pyramid features {P2, P3, P4, P5} to
{F2, F3, F4, F5}. (a)-(d) are parameterized and (e)-(f) are parameter-free.
R-CNN, and signiï¬cantly improve their detection ac-curacy by 2.3âˆ¼3.2 % mAP. Notably, we achieve a new state-of-the-art accuracy-speed trade-off (52.2 % mAP at 7.6 FPS). 2.