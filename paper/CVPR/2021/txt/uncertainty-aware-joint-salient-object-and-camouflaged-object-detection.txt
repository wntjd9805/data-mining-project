Abstract
Visual salient object detection (SOD) aims at ﬁnding the salient object(s) that attract human attention, while cam-ouﬂaged object detection (COD) on the contrary intends to discover the camouﬂaged object(s) that hidden in the sur-rounding. In this paper, we propose a paradigm of lever-aging the contradictory information to enhance the detec-tion ability of both salient object detection and camouﬂaged object detection. We start by exploiting the easy positive samples in the COD dataset to serve as hard positive sam-ples in the SOD task to improve the robustness of the SOD model. Then, we introduce a “similarity measure” module to explicitly model the contradicting attributes of these two tasks. Furthermore, considering the uncertainty of labeling in both tasks’ datasets, we propose an adversarial learn-ing network to achieve both higher order similarity measure and network conﬁdence estimation. Experimental results on benchmark datasets demonstrate that our solution leads to state-of-the-art (SOTA) performance for both tasks1. 1.

Introduction
Visual salient object detection (SOD) aims to localize the most salient region(s) of the images that attract human attention. To be qualiﬁed as a “salient” object, one should have high contrast compared with its global and local con-text. The camouﬂaged objects oppositely usually share sim-ilar structure or texture information with the environment, which try hard to fade themselves into the local context.
In this way, the SOD models [48, 46, 42, 38] are designed based on both global contrast and local contrast, while the
COD models [11, 26, 35, 52, 34] usually avoid searching the camouﬂaged objects in those salient regions. We notice that a higher level of saliency indicates a lower level of cam-ouﬂage and vice versa as shown in Fig. 1. This observation shows that the salient objects and camouﬂaged objects are 1Our code is publicly available at: https : / / github . com /
JingZhang617/Joint_COD_SOD
Figure 1. Illustration of the transition from camouﬂaged objects to salient objects, where the image in the middle could belong to both camouﬂaged object dataset and salient object dataset. two contradicting categories of objects. However, there still exist objects that are both salient and camouﬂaged, e.g. the polar bear in the middle of Fig. 1, which indicates that these two tasks are partially positively related at the dataset level.
Existing SOD models [48, 47, 59, 46, 38] mainly focus on two directions: 1) building effective saliency network
[47, 59] for accurate saliency detection with pixel-wise ac-curacy constraint; and 2) designing appropriate loss func-tions [46, 38] to achieve structure-preserving saliency de-tection. The former digs into network structure, while the latter cares more about network loss function. We argue that an effective training dataset can lead to more performance gain in addition to network structure design or loss function, it’s the training data that is regressed.
One typical solution to explore the training dataset is data augmentation, which usually involves linear or non-linear transformation of the dataset. We ﬁnd that, although performance improvement can be obtained with some basic data augmentation, e.g. image ﬂipping, rotation, cropping, and etc., none of these methods are specially designed for saliency detection. As a context-based task, a more effec-tive data augmentation technique should be context-aware
For SOD, the salient objects are those that can be easily detected, or the high-contrast objects as shown in Fig. 1.
We intend to augment the dataset to include lower contrast samples. Considering the partial positively related attribute of SOD and COD at dataset level, we intend to design a joint learning framework to learn both tasks and select easy 10071
samples from COD (e.g. the polar bear) as hard samples for
SOD, achieving contrast-level data augmentation.
Joint training is mostly designed for positively related tasks [43, 14, 51]. In contrary, we propose to integrate two contradicting tasks (SOD and COD) into one network with a “Similarity measure” module as shown in Fig. 2. The ba-sic assumption of our similarity measure module is that the activated regions of the same image for the two tasks should be different, leading to latent features apart from each other.
To this end, we introduce the third dataset, e.g. PASCAL
VOC 2007 images [7] in particular, to our framework serv-ing as the connection modeling dataset. The goal of these extra images is to achieve similarity measures and force the two tasks to focus on different regions of the image.
Moreover, as shown in Fig. 1, the salient object is salient in both local and global contexts, while the camouﬂaged ob-ject is hiding in its local context. Due to the high contrast, the local context of the salient objects is easier to model than that of the camouﬂaged objects, as there exists no clear boundary between camouﬂaged objects and their surround-ing. By jointly training a salient object detection network and camouﬂaged object detection network, the salient ob-ject branch can learn precise local context information for accurate camouﬂaged object detection.
Lastly, we observe two types of uncertainty while label-ing the dataset for each task. For salient object detection, the subjective nature of saliency [55, 54, 53] leads to ambi-guity of prediction, as shown in Fig. 5(a). For camouﬂaged object detection, the uncertainty comes from the difﬁculty in fully annotating the camouﬂaged objects as they usu-ally share similar color or texture with the environment, as shown in Fig. 5(c). We then introduce adversarial training to explicitly model the conﬁdence of network predictions, and estimate model uncertainty for both tasks.
We summarize our main contributions as: 1) We in-troduce the ﬁrst joint salient object detection and camou-ﬂaged object detection network within an adversarial learn-ing framework to explicitly model prediction uncertainty of each task. 2) We design the similarity measure module to explicitly model the “contradicting” attributes of the two tasks. 3) We present a data interaction strategy and treat easy samples from camouﬂage dataset as hard samples for saliency detection, achieving a robust saliency model. 2.