Abstract
Recent advances in neuroscience have highlighted the effectiveness of multi-modal medical data for investigat-ing certain pathologies and understanding human cogni-tion. However, obtaining full sets of different modali-ties is limited by various factors, such as long acquisition times, high examination costs and artifact suppression. In addition, the complexity, high dimensionality and hetero-geneity of neuroimaging data remains another key chal-lenge in leveraging existing randomized scans effectively, as data of the same modality is often measured differently by different machines. There is a clear need to go beyond the traditional imaging-dependent process and synthesize anatomically speciﬁc target-modality data from a source in-put. In this paper, we propose to learn dedicated features that cross both intre- and intra-modal variations using a novel CSCℓ4Net. Through an initial uniﬁcation of intra-modal data in the feature maps and multivariate canon-ical adaptation, CSCℓ4Net facilitates feature-level mutual transformation. The positive deﬁnite Riemannian manifold-penalized data ﬁdelity term further enables CSCℓ4Net to re-construct missing measurements according to transformed features. Finally, the maximization ℓ4-norm boils down to a computationally efﬁcient optimization problem. Exten-sive experiments validate the ability and robustness of our
CSCℓ4Net compared to the state-of-the-art methods on mul-tiple datasets. 1.

Introduction
Craniocerebral examination can be carried out using a multitude of imaging techniques with varying degrees of speciﬁcity and invasiveness, each directly or indirectly quantifying the structure, function and pathology of the brain. These multi-modal neuroimaging techniques, such as magnetic resonance imaging (MRI) and positron emission tomography (PET), offer diverse and complementary infor-mation to investigate human cognitive activities, population
∗Corresponding author
Figure 1. Architecture of our CSCℓ4Net. CSCℓ4Net is constructed by repeatedly stacking multivariate canonical CSC layers. The blue bar denotes the CSC layer, the yellow bar is the global average pooling, and the orange bar shows the softmax. ˆZx,|l| and ˆZy,|l| are feature maps of the l-th layer. M represents the manifold on each tangent space T having T M. P is the associator and H denotes a Hilbert space. imaging cohorts, neurodegeneration, and certain pathology.
However, acquiring a full library of multi-modal images is impractical since the collection faces several constraints, in-cluding long acquisition times (e.g. a normal MRI scan can take as long as an hour), high examination cost, or even worse, image corruption in the event of artifacts from pa-tient motion. Missing data is a critical problem in neurolog-ical studies and clinical diagnosis [11], and thus there is a clear need to obtain the absent data through beyond simple scanning.
Recently, there has been a surge of interest in synthesiz-ing target-modality medical images by transferring infor-mation across different appearances [12, 28, 30, 37]. One early and noteworthy model for this was joint sparse rep-resentation [11, 24], which allows multi-modal data to be mapped in a common space rather than in separate ways to obtain a linear approximation. Based on this, the convolu-tional sparse coding (CSC) model replaces the local opti-mization with a global shift-invariant one, achieving signif-icant improvements [8, 10, 26]. Further, deep learning has 15881
obtained promising results in multi-modal image synthesis, mostly with convolutional neural networks (CNNs) [4] and generative adversarial networks (GANs) [34, 37].
While synthesis methods have had signiﬁcant impact on research, there is now a debate regarding whether such synthetic images can substitute real acquisitions in clinical analyses.
In general, clinical diagnosis requires multiple biomarkers to identify the disease and its status. When the target acquisitions are missing, accurate synthesis is essen-tial. Although this challenge has been tackled by generating objective modality byproducts, current results remain unac-ceptable for clinical diagnosis.
In addition to differences in modalities, the complex-ity, high-dimensionality and heterogeneity of medical data remains another key challenge in leveraging existing ran-domized scans effectively. Speciﬁcally, imaging using ma-chines developed by different manufacturers (e.g. Philips,
Siemens, GE, etc.), the abundance of various physical pa-rameters, and the presence of temporal dependency, all in-troduce conﬂicted and inconsistent features, thus prevent-ing the complete use of real acquired data. It is nontrivial to harmonize all the different information and construct their correlations, but efforts to address the above challenges and develop a reliable algorithm to effectively utilize data are extremely necessary for both research and clinical decision support.
In this paper, we propose an unsupervised multivariate canonical CSCℓ4Net, a novel approach to crossing both intra-modal (i.e. more than one measurement from the same data modality) and inter-modal (i.e. more than one data modality) heterogeneities. Our model synthesizes anatom-ically speciﬁc target modality data from a source modal-ity, and makes efﬁcient use of real acquisitions. CSCℓ4Net works well under multiple datasets, despite the high di-mensionality, temporal dependency and irregularity of neu-roimaging, making it possible to combine acquisitions from different scanner manufacturers by initially normaliz-ing differences between features, and then mapping them into the Hilbert space for multivariate canonical adapta-tion. Both cross-modal geometry transformations and a neuroimaging-speciﬁc positive deﬁnite conditions are in-corporated within a Riemannian manifold. Finally, solving an ℓ4-maximization instead of an ℓ1-minimization problem enables us to employ the lowest sample complexity for high computational medical data. An overview of our CSCℓ4Net is shown in Fig. 1.
To summarize, this paper provides the following contri-butions:
• To the best of our knowledge, this is the ﬁrst work to generate anatomically meaningful images, by model-ing an unsupervised multivariate canonical CSCℓ4Net.
• We propose a novel intra-modal unit normalization for the initial uniﬁcation of variate data of the same modal-ity to guarantee a unique convolutional sparse solution.
• The multivariate canonical feature mapping is formu-lated over the multi-layer CSC to optimize the inter-modal structure.
• We introduce a Riemannian manifold-penalized trans-formation data ﬁdelity term under the positive deﬁ-nite condition, for which we show how a reformulation based on CSC is crucial to empirical success.
• We prove that maximizing the ℓ4-norm instead of min-imizing the ℓ1-norm leads to the lowest complexity and the highest robustness. 2.