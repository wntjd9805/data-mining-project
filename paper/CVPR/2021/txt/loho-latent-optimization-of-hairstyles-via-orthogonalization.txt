Abstract 1.

Introduction
Hairstyle transfer is challenging due to hair structure differences in the source and target hair. Therefore, we propose Latent Optimization of Hairstyles via Orthogo-nalization (LOHO), an optimization-based approach using
GAN inversion to inﬁll missing hair structure details in la-tent space during hairstyle transfer. Our approach decom-poses hair into three attributes: perceptual structure, ap-pearance, and style, and includes tailored losses to model each of these attributes independently. Furthermore, we propose two-stage optimization and gradient orthogonal-ization to enable disentangled latent space optimization of our hair attributes. Using LOHO for latent space manipu-lation, users can synthesize novel photorealistic images by manipulating hair attributes either individually or jointly, transferring the desired attributes from reference hairstyles.
LOHO achieves a superior FID compared with the current state-of-the-art (SOTA) for hairstyle transfer. Additionally,
LOHO preserves the subject’s identity comparably well ac-cording to PSNR and SSIM when compared to SOTA im-age embedding pipelines. Code is available at https:
//github.com/dukebw/LOHO.
*Corresponding Author: rohitsaha@cs.toronto.edu
We set out to enable users to make semantic and struc-tural edits to their portrait image with ﬁne-grained control.
As a particular challenging and commercially appealing ex-ample, we study hairstyle transfer, wherein a user can trans-fer hair attributes from multiple independent source images to manipulate their own portrait image. Our solution, Latent
Optimization of Hairstyles via Orthogonalization (LOHO), is a two-stage optimization process in the latent space of a generative model, such as a generative adversarial network (GAN) [12, 18]. Our key technical contribution is that we control attribute transfer by orthogonalizing the gradients of our transferred attributes so that the application of one attribute does not interfere with the others.
Our work is motivated by recent progress in GANs, enabling both conditional [15, 32] and unconditional [19] synthesis of photorealistic images.
In parallel, recent works have achieved impressive latent space manipulation by learning disentangled feature representations [26], en-abling photorealistic global and local image manipulation.
However, achieving controlled manipulation of attributes of the synthesized images while maintaining photorealism re-mains an open challenge.
Previous work on hairstyle transfer [30] produced realis-tic transfer of hair appearance using a complex pipeline of
GAN generators, each specialized for a speciﬁc task such as hair synthesis or background inpainting. However, the 1984
use of pretrained inpainting networks to ﬁll holes left over by misaligned hair masks results in blurry artifacts. To pro-duce more realistic synthesis from transferred hair shape, we can inﬁll missing shape and structure details by invoking the prior distribution of a single GAN pretrained to generate faces.
To achieve photorealistic hairstyle transfer even under said source-target hair misalignment we propose Latent
Optimization of Hairstyles via Orthogonalization (LOHO).
LOHO directly optimizes the extended latent space and the noise space of a pretrained StyleGANv2 [20]. Using care-fully designed loss functions, our approach decomposes hair into three attributes: perceptual structure, appearance, and style. Each of our attributes is then modeled indi-vidually, thereby allowing better control over the synthe-sis process. Additionally, LOHO signiﬁcantly improves the quality of synthesized images by employing two-stage op-timization, where each stage optimizes a subset of losses in our objective function. Our key insight is that some of the losses, due to their similar design, can only be optimized se-quentially and not jointly. Finally, LOHO uses gradient or-thogonalization to explicitly disentangle hair attributes dur-ing the optimization process.
Our main contributions are:
• We propose a novel approach to perform hairstyle transfer by optimizing StyleGANv2’s extended latent space and noise space.
• We propose an objective that includes multiple losses catered to model each key hairstyle attribute.
• We propose a two-stage optimization strategy that leads to signiﬁcant improvements in the photorealism of synthesized images.
• We introduce gradient orthogonalization, a general method to jointly optimize attributes in latent space without interference. We demonstrate the effective-ness of gradient orthogonalization both qualitatively and quantitatively.
• We apply our novel approach to perform hairstyle transfer on in-the-wild portrait images and compute the Fr´echet Inception Distance (FID) score. FID is used to evaluate generative models by calculating the distance between Inception [29] features for real and synthesized images in the same domain. The com-puted FID score shows that our approach outperforms the current state-of-the-art (SOTA) hairstyle transfer results. 2.