Abstract
Shapes are often designed to satisfy structural proper-ties and serve a particular functionality in the physical world. Unfortunately, most existing generative models fo-cus primarily on the geometric or visual plausibility, ignor-ing the physical or structural constraints. To remedy this, we present a novel method aimed to endow deep generative models with physical reasoning. In particular, we introduce a loss and a learning framework that promote two key char-acteristics of the generated shapes: their connectivity and physical stability. The former ensures that each generated shape consists of a single connected component, while the latter promotes the stability of that shape when subjected to gravity. Our proposed physical losses are fully differ-entiable and we demonstrate their use in end-to-end learn-ing. Crucially we demonstrate that such physical objectives can be achieved without sacriﬁcing the expressive power of the model and variability of the generated results. We demonstrate through extensive comparisons with the state-of-the-art deep generative models, the utility and efﬁciency of our proposed approach, while avoiding the potentially costly differentiable physical simulation at training time. 1.

Introduction 3D shape generation is a central problem in both com-puter vision and computer graphics. The main challenge is to minimize manual intervention in the design process, while enabling the creation of new, diverse and plausible shapes. Early efforts focused on synthesizing new shapes by borrowing and assembling parts from existing collections, combining probabilistic models with geometric constraints, e.g., [23, 12, 39] among many others. More recently, deep generative methods, in particular, adversarial networks [28] and variational auto-encoders [51] have gained popularity in various applications showing promising results. However, existing works only focus on geometric, visual and struc-tural plausibility, largely ignoring the fact that synthesized l e d o m d e s a b t e
N
M
-I l e d o m d e s a b t e
N
Q
P
-Figure 1: Visual results for 3D shape generation. We sample vec-tors from the latent space of IM-Net [15] and PQ-Net [71] that we decode using the corresponding baseline network (ﬁrst row) and our generative network trained with the proposed physical losses (second row). Problematic regions are marked by red ovals. The resulting shapes become more connected and physically stable. shapes are also expected to satisfy physical and functional constrains. Consequently, the generated content might ap-pear to be a convincing example of a particular category (e.g. a chair, a car etc.) but there is no guarantee that it can be feasible and functional in the physical world. There has been a steady stream of works in the design community in studying 3D shapes from a functional perspective [36].
But, previous attempts in developing generative neural net-works for unstructured [28, 51, 30] and structured [13, 44] 3D shapes have not yet jointly leveraged the power of an-alyzing geometric, physical and functional representations.
Although it seems relatively straightforward for a human designer to make cognitive connections between geometry, physics and functionality, it is still challenging to train in-telligent models to do the same.
In this paper, we introduce a physically-aware genera-tive modeling method that makes a step to overcome these limitations (cf Figure 1). We seek a latent representation that incorporates geometric, structural and physical infor-mation. Such a latent space enables many non-trivial ap-plications including generating novel and realistic shapes, physical shape optimization, etc. To this end, we introduce a loss that endows existing deep generative models of 3D shapes with physical reasoning. 9330
We focus on two commonly-encountered issues in purely geometric generative models: the existence of dis-connected components and the lack of stability when the object is subjected to gravity or to trivial perturbations.
We demonstrate that both of these issues can be addressed through a combination of novel loss functions and a care-ful design of the training framework. Importantly, our ap-proach requires no additional data or manual annotation.
Key to our approach are the implicit function represen-tation of a 3D shape and a topological energy based on tools from persistent homology [20, 21, 80, 53, 25] coupled to promote the connectivity of the generated content. We also integrate a neural stability predictor into the generative framework to enhance the stability of generated 3D shapes when subjected to gravity. Our proposed physical loss is fully differentiable and we demonstrate its use in a variety of end-to-end learning applications. Crucially, we demon-strate that our physical objectives can be enforced without sacriﬁcing the expressive power of the model and variabil-ity of the generated results through a careful design of the generative modeling framework.
To the best of our knowledge, our work is the ﬁrst end-to-end physically-aware deep generative framework that at-tempts to jointly encode geometry, structure and physics in deep generative neural networks. Through extensive exper-iments and comparisons with the state-of-the-art deep gen-erative networks, we demonstrate that our framework im-proves overall generative performance and physical plausi-bility metrics.
Contributions Our overall contributions are threefold.
First, we demonstrate that incorporating physical reasoning as a supervisory signal into existing deep generative models can enhance the physical validity of the generated content.
Second, we propose two novel learning physical losses, and explore the mutual dependency between geometry, structure and physics by encoding this information in a joint latent space. Third, we show that our framework is generalizable to different networks and 3D shape representations. 2.