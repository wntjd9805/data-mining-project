Abstract
Segmenting highly-overlapping objects is challenging, because typically no distinction is made between real object contours and occlusion boundaries. Unlike previous two-stage instance segmentation methods, we model image for-mation as composition of two overlapping layers, and pro-pose Bilayer Convolutional Network (BCNet), where the top GCN layer detects the occluding objects (occluder) and the bottom GCN layer infers partially occluded instance (occludee). The explicit modeling of occlusion relationship with bilayer structure naturally decouples the boundaries of both the occluding and occluded instances, and consid-ers the interaction between them during mask regression.
We validate the efﬁcacy of bilayer decoupling on both one-stage and two-stage object detectors with different back-bones and network layer choices. Despite its simplicity, extensive experiments on COCO and KINS show that our occlusion-aware BCNet achieves large and consistent per-formance gain especially for heavy occlusion cases. Code is available at https://github.com/lkeab/BCNet. 1.

Introduction
State-of-the-art approaches in instance segmentation of-ten follow the Mask R-CNN [21] paradigm with the ﬁrst stage detecting bounding boxes, followed by the second stage to segment instance masks. Mask R-CNN and its variants [42, 5, 8, 25, 7] have demonstrated notable perfor-mance, and most of the leading approaches in the COCO instance segmentation challenge [40] have adopted this pipeline. However, we note that most incremental improve-ment comes from better backbone architecture designs, with little attention paid in the instance mask regression after obtaining the ROI (Region-of-Interest) features from ob-ject detection. We observe that a lot of segmentation errors are caused by overlapping objects, especially for object in-stances belonging to the same class. This is because each instance mask is individually regressed, and the regression process implicitly assumes the object in an ROI has almost complete contour, since most objects in the training data in 1This research is supported in part by the Research Grant Council of the Hong Kong SAR under grant no. 16201420 and Kuaishou Technology.
Top Layer 
Occluder
Bottom Layer
Occludee
Input Image
Bilayer Decoupling
Inferred Result 
Invisible Occluded Region
Figure 1. Simpliﬁed illustration. Unlike previous segmentation approaches operating on a single image layer (i.e., directly on the input image), we decouple overlapping objects into two im-age layers, where the top layer deals with the occluding objects (occluder) and the bottom layer for occludee (which is also re-ferred to as target object in other methods as they do not explicitly consider the occluder). The overlapping parts of the two image layers indicate the invisible region of the occludee, which is ex-plicitly modeled by our occlusion-aware BCNet framework.
COCO do not exhibit signiﬁcant occlusions.
We propose the Bilayer Convolutional Network (BC-Net). As illustrated in Figure 1, BCNet simultaneously re-gresses both occluding region (occluder) and partially oc-cluded object (occludee) after ROI extraction, which groups the pixels belonging to the occluding region and treat them equally as the pixels of the occluded object but in two sepa-rate image layers, and thus naturally decouples the bound-aries for both objects and considers the interaction between them during the mask regression stage.
Previous approaches resolve the mask conﬂict between neighboring objects through non-maximum suppression or additional post-processing [43, 14, 34, 30, 20]. Conse-quently, their results are over-smooth along boundaries or exhibit small gaps between neighboring objects. Further-more, since the receptive ﬁeld in the ROI observes mul-tiple objects that belong to the same class, when the oc-cluding regions were included as part of the occluded ob-ject, traditional mask head design falls short of resolving such conﬂict, leaving a large portion of error as shown in
Figure 2. We compare BCNet with recent amodal seg-mentation methods [46, 16], which predict complete ob-4019
(a) Mask R-CNN               (b) PANet (c) MS R-CNN                (d) ASN              (e) Occlusion R-CNN (f) Cascade MR-CNN       (g) TensorMask (h) CenterMask (i) HTC                  (j) Ours: BCNet
Figure 2. Instance Segmentation on COCO [40] validation set by a) Mask R-CNN [21], b) PANet [42], c) Mask Scoring R-CNN [25], d)
ASN [46], e) Occlusion R-CNN (ORCNN) [16], f) Cascade Mask R-CNN [5], g) TensorMask [9], h) CenterMask [33], i) HTC [7] and j)
Our BCNet. Note that d) and e) are specially designed for amodal/occlusion mask prediction. In this example, the bounding box is given to compare the quality of different regressed instance masks. ject masks, including the occluded region. However, these amodal methods only regress single occluded target in the ROI, thus lacking occluder-occludee interaction rea-soning, making their specially designed decoupling struc-ture suffer when handling mask conﬂict between highly-overlapping objects. Correspondingly, Figure 3 compares the architecture of our BCNet with previous mask head de-signs [21, 42, 25, 7, 33, 5, 46, 16].
Our BCNet consists of two GCN layers with a cas-caded structure, each respectively regresses the mask and boundaries of the occluding and partially occluded ob-jects. We utilize GCN in our implementation because GCN can consider the non-local relationship between pixels, al-lowing for propagating information across pixels despite the presence of occluding regions. The explicit bilayer occluder-occludee relational modeling within the same ROI also makes our ﬁnal segmentation results more explainable than previous methods. For object detector, we use the
FCOS [51] owing to its efﬁcient memory and running time, while noting that other state-of-the-art object detectors can also be used as demonstrated in our experiments.
Since our paper focuses on occlusion handling in in-stance segmentation, in addition to the original COCO eval-uation, we extract a subset of COCO dataset containing both occluding objects and partially occluded objects to eval-uate the robustness of our approach in comparison with other instance segmentation methods in occlusion handling.
In this paper we also contribute the ﬁrst large-scale oc-clusion aware instance segmentation datasets with ground-truth, complete object contours for both occluding and par-tially occluded objects. Extensive experiments show that our approach outperforms state-of-the-art methods in both the modal and amodal instance segmentation tasks. 2.