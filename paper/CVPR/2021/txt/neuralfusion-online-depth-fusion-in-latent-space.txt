Abstract
We present a novel online depth map fusion approach that learns depth map aggregation in a latent feature space.
While previous fusion methods use an explicit scene repre-sentation like signed distance functions (SDFs), we propose a learned feature representation for the fusion. The key idea is a separation between the scene representation used for the fusion and the output scene representation, via an addi-tional translator network. Our neural network architecture consists of two main parts: a depth and feature fusion sub-network, which is followed by a translator sub-network to produce the ﬁnal surface representation (e.g. TSDF) for visualization or other tasks. Our approach is an online process, handles high noise levels, and is particularly able to deal with gross outliers common for photometric stereo-based depth maps. Experiments on real and synthetic data demonstrate improved results compared to the state of the art, especially in challenging scenarios with large amounts of noise and outliers. The source code will be made available at https://github.com/weders/NeuralFusion. 1.

Introduction
Reconstructing the geometry of a scene is a central com-ponent of many applications in 3D computer vision. Aware-ness of the surrounding geometry enables robots to navigate, augmented and mixed reality devices to accurately project the information into the user’s ﬁeld of view, and serves as the basis for many 3D scene understanding tasks.
In this paper, we consider online surface reconstruction by fusing a stream of depth maps with known camera cali-bration. The fundamental challenge in this task is that depth maps are typically noisy, incomplete, and contain outliers.
Depth map fusion is a key component in many 3D reconstruc-tion methods, like KinectFusion [40], VoxelHashing [42],
InﬁniTAM [23], and many others. The vast majority of meth-ods builds upon the concept of averaging truncated signed distance functions (TSDFs), as proposed in the pioneering work by Curless and Levoy [9]. This approach is so popular due to its simple, highly parallelizable, and real-time capable
TSDF Fusion [9] RoutedFusion [62]
Ours
Figure 1. Results of our end-to-end depth fusion on real-world
MVS data [29]. Our method learns to separate outliers and true geometry without the need of ﬁltering heuristics. way of fusing noisy depth maps into a surface. However, it has difﬁculties with handling outliers and thin geometry, which can be mainly attributed to the local integration of depth values in the TSDF volume.
To tackle this fundamental limitation, existing methods use various heuristics to ﬁlter outliers in decoupled pre- or post-processing steps. Such ﬁltering techniques entail the usual trade-off in terms of balancing accuracy against com-pleteness. Especially in an online fusion system, striking this balance is extremely challenging in the pre-ﬁltering stage, because it is difﬁcult to distinguish between a ﬁrst sur-face measurement and an outlier. Consequently, to achieve complete surface reconstructions, one must use conservative pre-ﬁltering, which in turn requires careful post-ﬁltering of outliers by non-local reasoning on the TSDF volume or the
ﬁnal mesh. This motivates our key idea to use different scene representations for the fusion and ﬁnal method output, while all prior works perform depth fusion and ﬁltering directly in the output representation. In contrast, we perform the fusion step in a latent scene representation, implicitly learned to encode features like conﬁdence information or local scene information. A ﬁnal translation step simultaneously ﬁlters and decodes this learned scene representation into the ﬁnal output relevant to downstream applications. 3162
In summary, we make the following contributions:
• We propose a novel, end-to-end trainable network architec-ture, which separates the scene representations for depth fusion and the ﬁnal output into two different modules.
• The proposed latent representation yields more accurate and complete fusion results for larger feature dimensions allowing to balance accuracy against resource demands.
• Our network architecture allows for end-to-end learnable outlier ﬁltering within a translation step that signiﬁcantly improves outlier handling.
• Although fully trainable, our approach still only performs very localized updates to the global map which maintains the online capability of the overall approach. 2.