Abstract
Akin Caliskan1
Adrian Hilton1 2Department of Computer Science, University College London
Lourdes Agapito2
We present a new end-to-end learning framework to ob-tain detailed and spatially coherent reconstructions of mul-tiple people from a single image. Existing multi-person methods suffer from two main drawbacks: they are of-ten model-based and therefore cannot capture accurate 3D models of people with loose clothing and hair; or they re-quire manual intervention to resolve occlusions or interac-tions. Our method addresses both limitations by introducing the ﬁrst end-to-end learning approach to perform model-free implicit reconstruction for realistic 3D capture of multi-ple clothed people in arbitrary poses (with occlusions) from a single image. Our network simultaneously estimates the 3D geometry of each person and their 6DOF spatial loca-tions, to obtain a coherent multi-human reconstruction. In addition, we introduce a new synthetic dataset that depicts images with a varying number of inter-occluded humans and a variety of clothing and hair styles. We demonstrate robust, high-resolution reconstructions on images of multi-ple humans with complex occlusions, loose clothing and a large variety of poses and scenes. Our quantitative evalua-tion on both synthetic and real world datasets demonstrates state-of-the-art performance with signiﬁcant improvements in the accuracy and completeness of the reconstructions over competing approaches. 1.

Introduction
Multi-person human reconstruction from a single image
ﬁnds application in surveillance; ﬁlm and entertainment in-cluding movie production; generating AR/VR content for complex scenes; and sports broadcast. Reconstruction from a single camera is more practical and lower-cost compared to multi-view, as it does not require a complex setup. Im-mense progress has been made in estimating 3D human pose and shape from a single image or monocular video in the last ﬁve years [3, 46, 35, 11, 13]. Methods can be clas-siﬁed as model-based or model-free. Model-based methods use a parametric human body shape model such as SMPL to reconstruct people from a single image [7, 22, 18] in-cluding methods that estimate SMPL with clothing top[25].
Figure 1. Proposed model-free multi-person spatially coherent im-plicit reconstruction from a single image with 4 and 2 people on synthetic MPSD and real CVSSP3D dataset.
Model-free methods give a more realistic reconstruction of people with loose clothing and hair details [3, 46, 35, 11].
However all existing methods require an image of a sin-gle fully visible person without occlusions to allow recon-struction. Recently, model-based approaches have been in-troduced that can reconstruct multiple humans in a scene
[13, 17, 45] using SMPL, so cannot capture clothing details.
In addition, [45] requires manual intervention to mark inter-action regions on 3D surfaces to handle inter-person/object occlusions. This paper introduces the ﬁrst model-free end-to-end approach that reconstructs multiple clothed people from a single image of a crowded scene with inter-person occlusions (see Table 1). Our proposed approach produces a spatially coherent implicit reconstruction of each person together with their 6DOF spatial locations and orientations in the observed scene without any manual intervention, and can handle complex poses, clothing and partial occlusion from a single image, as shown in Fig. 1.
We introduce the ﬁrst multiple people synthetic dataset and benchmark (MPSD) with realistic image-3D model pairs. MPSD ranges from 2−10 people per image in a wide variety of clothing, hairstyles and poses with detailed sur-face geometry and appearance rendered with diverse indoor and outdoor natural backgrounds and realistic scene illu-mination. This dataset provides the ﬁrst quantitative bench-mark for multi-person single image reconstruction. We pro-14474
Model-free Multi-human Coherent Occ. RGB
×
×
X
×
X
X
X
×
X
×
X
×
×
X
×
×
X
×
×
X
X
× X
[7, 22, 18, 21]
× X
[3, 46, 35, 11]
X X
[17, 43, 44]
X ×
[5, 9]
X X
Holopose [13]
X X
PHOSA [45]
X X
Proposed
Table 1. Comparison of our method with existing 3D shape esti-mation methods. Occ - Occlusions and Image - Single image pose an end-to-end method trained on the MPSD dataset that estimates 3D reconstructions of each person and their 6DOF location/orientation by exploiting single image depth and instance segmentation. Example results from the pro-posed single image multi-human spatially coherent implicit reconstruction are shown in Fig. 1. Our contributions are:
• The ﬁrst approach for model-free reconstruction of multiple people from a single image with accurate spa-tial arrangement.
• An end-to-end framework using cascaded multitask networks for simultaneous implicit 3D reconstruction and 6DOF location/orientation estimation exploiting depth and instance segmentation information.
• A multiple person synthetic image/3D dataset of com-plex multi-person scenes with inter-person occlusions, realistic clothing, hair, poses, scenes and illumination.
• A method that exploits the advantages of volumetric and implicit 3D shape representations for detailed re-constructions of clothed people from a single image. 2.