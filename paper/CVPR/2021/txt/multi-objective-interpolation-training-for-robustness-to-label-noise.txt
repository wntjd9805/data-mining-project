Abstract
Deep neural networks trained with standard cross-entropy loss memorize noisy labels, which degrades their performance. Most research to mitigate this memorization proposes new robust classiﬁcation loss functions. Conversely, we propose a Multi-Objective Interpolation Training (MOIT) approach that jointly exploits contrastive learning and clas-siﬁcation to mutually help each other and boost performance against label noise. We show that standard supervised con-trastive learning degrades in the presence of label noise and propose an interpolation training strategy to mitigate this behavior. We further propose a novel label noise de-tection method that exploits the robust feature representa-tions learned via contrastive learning to estimate per-sample soft-labels whose disagreements with the original labels accurately identify noisy samples. This detection allows treating noisy samples as unlabeled and training a classi-ﬁer in a semi-supervised manner to prevent noise memo-rization and improve representation learning. We further propose MOIT+, a reﬁnement of MOIT by ﬁne-tuning on detected clean samples. Hyperparameter and ablation stud-ies verify the key components of our method. Experiments on synthetic and real-world noise benchmarks demonstrate that MOIT/MOIT+ achieves state-of-the-art results. Code is available at https://git.io/JI40X. 1.

Introduction
Building a new dataset usually involves manually la-beling every sample for the particular task at hand. This process is cumbersome and limits the creation of large datasets, which are usually necessary for training deep neu-ral networks (DNNs) in order to achieve the required per-formance. Conversely, automatic data annotation based on web search and user tags [29, 22] leverages the use of larger data collections at the expense of introducing some incorrect labels. This label noise degrades DNN perfor-mance [3, 52] and this poses an interesting challenge that has recently gained a lot of interest in the research commu-nity [45, 41, 23, 50, 12, 1, 28, 55, 13, 31].
In image classiﬁcation problems, label noise usually in-volves different noise distributions [22, 55]. In-distribution noise types consist of samples with incorrect labels, but whose image content belongs to the dataset classes. When in-distribution noise is synthetically introduced, it usually follows either an asymmetric or symmetric random distribu-tion. The former involves label ﬂips to classes with some semantic meaning, e.g., a cat is ﬂipped to a tiger, while the latter does not. Furthermore, web label noise types are usually dominated by out-of-distribution samples where the image content does not belong to the dataset classes. Recent studies show that all label noise types impact DNN perfor-mance, although performance degrades less with web noise
[22, 34].
Robustness to label noise is usually pursued by identify-ing noisy samples to: reduce their contribution in the loss
[23, 11], correct their label [1, 28], or abstain their classiﬁca-tion [42]. Other methods exploit interpolation training [53], regularizing label noise information in DNN weights [13], or small sets of correctly labeled data [18, 55]. However, most previous methods rely exclusively on classiﬁcation losses and little effort has being directed towards incorporating sim-ilarity learning frameworks [32], i.e. directly learning image representations rather than a class mapping [45].
Similarity learning frameworks are very popular in com-puter vision for a variety of applications including face recog-nition [44], ﬁne-grained retrieval [37], or visual search [35].
These methods learn representations for samples of the same class (positive samples) that lie closer in the feature space than those of samples from different classes (negative sam-ples). Many traditional methods are based on sampling pairs or triplets to measure similarities [7, 19]. However, super-vised and unsupervised contrastive learning approaches that consider a high number of negatives have recently received signiﬁcant attention due to their success in unsupervised learning [5, 14, 27]. In the context of label noise, there are some attempts at training with simple similarity learning losses [45], but there are, to the best of our knowledge, no works exploring more recent contrastive learning losses [24].
This paper proposes Multi-Objective Interpolation Train-ing (MOIT), a framework to robustly learn in the presence 6606
of label noise by jointly exploiting synergies between con-trastive and semi-supervised learning. The former intro-duces a regularization of the contrastive loss in [24] to learn noise-robust representations that are key for accurately de-tecting noisy samples and, ultimately, for semi-supervised learning. The latter performs robust image classiﬁcation and boosts performance. Our MOIT+ reﬁnement further demonstrates that ﬁne-tuning on the detected clean data can boost performance. MOIT/MOIT+ achieves state-of-the-art results across a variety of datasets (CIFAR-10/100 [26], mini-ImageNet [22], and mini-WebVision [29]) with both synthetic and real-world web label noise. Our main contri-butions are as follows: 1. A multi-objective interpolation training (MOIT) frame-work where supervised contrastive learning and semi-supervised learning help each other to robustly learn in the presence of both synthetic and web label noise under a single hyperparameter conﬁguration. 2. An interpolated contrastive learning (ICL) loss that imposes linear relations both on the input and the con-trastive loss to mitigate the performance degradation observed for the supervised contrastive learning loss in
[24] when training with label noise. 3. A novel label noise detection strategy that exploits the noise-robust feature representations provided by ICL to enable semi-supervised learning. This detection strat-egy performs a k-nearest neighbor search to infer per-sample label distributions whose agreements with the original labels identify correctly labeled samples. 4. A ﬁne-tuning strategy over detected clean data (MOIT+) that further boosts performance based on sim-ple noise robust losses from the literature. 2.