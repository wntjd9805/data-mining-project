Abstract
Scene understanding is a critical problem in computer vision. In this paper, we propose a 3D point-based scene graph generation (SGGpoint) framework to effectively bridge perception and reasoning to achieve scene under-standing via three sequential stages, namely scene graph construction, reasoning, and inference. Within the reason-ing stage, an EDGE-oriented Graph Convolutional Net-work (EdgeGCN) is created to exploit multi-dimensional edge features for explicit relationship modeling, together with the exploration of two associated twinning interac-tion mechanisms between nodes and edges for the inde-pendent evolution of scene graph representations. Overall, our integrated SGGpoint framework is established to seek and infer scene structures of interest from both real-world and synthetic 3D point-based scenes. Our experimental results show promising edge-oriented reasoning effects on scene graph generation studies. We also demonstrate our method advantage on several traditional graph representa-tion learning benchmark datasets, including the node-wise classiﬁcation on citation networks and whole-graph recog-nition problems for molecular analysis. 1.

Introduction
Scene understanding is intrinsically close to the essence of computer vision.
It simulates human visual system in recognizing the miscellaneous clues concealed in the com-plex visual world, succeeded by understanding what we per-ceive in the visual scenes surrounding us [8]. This process could be integrated and assisted with an efﬁcient use of se-mantic scene graph (SG), which has its popularity well-demonstrated within the computer graphics community, via depicting the objects and their inner structural relationships
Our project page: https://SGGpoint.github.io 7  door 8  hanger 3 wall 10 wardrobe 1  floor 5  bathtub 4 wall 14 mirror 15 chandelier 13 shelving 11 rug 9  wardrobe 12 sink 2  wall 6 toilet
Support
Surround
Next-to
Figure 1. 3D Point-based Scene Graph Generation (SGGpoint) takes as inputs real-world or synthetic 3D scenes S (left) and class-agnostic instance mask M (middle) to inference a scene graph G (right). M and G above are aligned to the same spatial layout, sharing a uniﬁed instance color encoding. (scene layouts) as its nodes and edges, respectively.
Unlike most of the successful works proposed for 2D
SG studies [49, 46, 24, 15], this paper focuses on 3D point-based semantic SG analysis – an emerging 3D visual recog-nition task that has not been well-explored yet. Such meth-ods could provide great aid for arising cross-domain vi-sion tasks including 2D-3D scene retrieval [38], 3D visual grounding [4, 3], and scene captioning [5], which would subsequently beneﬁt real-life applications such as creative interior decoration designs, self-driving autonomous vehi-cles, or other AI-enriched indoor/outdoor industries.
Within the rising progression of 3D point-based se-mantic SG analysis, the research interests have gradually shifted from object-centric point cloud learning tasks, such as 3D object detection [32, 48, 33], instance segmenta-9705
tion [14, 54, 42], and semantic scene segmentation [13, 47], to the joint recognition of both objects and inter-object structural relationships, which could be further regressed to generate SGs describing some desired scene layouts (Fig. 1) for given point-based 3D scenes. Moreover, ex-isting works [49, 38] have mostly treated the inter-object structural relationships as by-products derived from graph node recognition, losing sight of the visual cues lurking in-side each SG representation and thus degrading their joint recognition performance.
In this paper, we propose a 3D SGGpoint framework capable of effectively bridging perception and reasoning to achieve 3D scene understanding through three sequential stages, namely scene graph construction, reasoning, and in-ference. The contributions of this paper are summarized as follows: 1) To endow the graph convolution networks (GCNs) with edge-assisted reasoning capability, an edge-oriented GCN (EdgeGCN) is proposed to exploit multi-dimensional edge features for explicit inter-node relation-ship modeling. 2) Two twinning interactions between SG nodes and edges are further explored to conduct compre-hensive SG reasoning for each individual SG representa-tion evolution, so that the node- and edge-oriented visual clues can be better perceived and utilized to assist the other ones’ evolution via an attentional manner. 3) Our integrated
SGGpoint framework is demonstrated to be handy for gen-erating 3D scene structures from either computer-aided 3D scene synthesis or real-world 3D scans, while our edge-driven interaction scheme is also proven beneﬁcial to con-ventional graph representation learning tasks. 2.