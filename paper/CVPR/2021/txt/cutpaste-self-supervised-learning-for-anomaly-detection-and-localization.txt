Abstract
We aim at constructing a high performance model for de-fect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors us-ing normal training data only. We ﬁrst learn self-supervised deep representations and then build a generative one-class classiﬁer on learned representations. We learn representa-tions by classifying normal data from the CutPaste, a sim-ple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect vari-ous types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representa-tions from scratch. By transfer learning on pretrained rep-resentations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing de-fective areas without annotations during training. 1.

Introduction
Anomaly detection aims to detect an instance contain-ing anomalous and defective patterns that are different from those seen in normal instances. Many problems from dif-ferent vision applications are anomaly detection, including manufacturing defect detection [9, 5], medical image anal-ysis [50, 48], and video surveillance [2, 31, 53]. Unlike a typical supervised classiﬁcation problem, anomaly detec-tion faces unique challenges. First, due to the nature of the problem, it is difﬁcult to obtain a large amount of anoma-lous data, either labeled or unlabeled. Second, the differ-ence between normal and anomalous patterns are often ﬁne-grained as defective areas might be small and subtle in high-resolution images.
Due to limited access to anomalous data, constructing an anomaly detector is often conducted under semi-supervised or one-class classiﬁcation settings using normal data only.
∗Equal contributions.
Since the distribution of anomaly patterns is unknown in advance, we train models to learn patterns of normal in-stances and determine anomaly if the test example is not represented well by these models. For example, an autoen-coder that is trained to reconstruct normal data is used to de-clare anomalies when the data reconstruction error is high.
Generative models declare anomalies when the probability density is below a certain threshold. However, the anomaly score deﬁned as an aggregation of pixel-wise reconstruction error or probability densities lacks to capture a high-level semantic information [42, 37].
Alternative methods using high-level learned represen-tations have shown more effective for anomaly detection.
For example, deep one-class classiﬁer [46] demonstrates an effective end-to-end trained one-class classiﬁers pa-rameterized by deep neural networks.
It outperforms its shallow counterparts, such as one-class SVMs [49] and reconstruction-based approaches such as autoencoders [34].
In self-supervised representation learning, predicting geo-metric transformations of an image [20, 24, 4], such as ro-tation or translation, and contrastive learning [54, 52] have shown to be successful in distinguishing normal data from outliers. However, most existing works focus on detect-ing semantic outliers (e.g., visual objects from different classes) from object-centric natural images. In Section 4.1, we show these methods do not generalize well in detecting
ﬁne-grained anomalous patterns as in defect detection.
In this work, we tackle a one-class defect detection prob-lem, a special case of image anomaly detection, where vari-ous forms of unknown anomalous patterns present locally in the high-resolution images. We follow the two-stage frame-work [52], where we ﬁrst learn self-supervised representa-tions by solving a proxy task, then build a generative one-class classiﬁer on learned representations to distinguish data with anomalous patterns from normal ones. Our innova-tion is at designing a novel proxy task for self-supervised learning of representations. Speciﬁcally, we formulate a proxy classiﬁcation task between normal training data and the ones augmented by the CutPaste, the proposed data aug-mentation strategy that cuts an image patch and pastes at a random location of an image. CutPaste augmentation is mo-19664
CNN 0
CNN
GDE
Anomaly score d e r a h
S
Image-level / Patch-level
GradCAM
Anomaly score (spatial max-pooling)
Heatmap (Upsampled)
CutPaste
CNN 1
CNN
GDE (a) Learning Self-Supervised Representation (b) Anomaly Detection and Localization
Figure 1: An overview of our method for anomaly detection and localization. (a) A deep network (CNN) is trained to distinguish images from normal (blue) and augmented (green) data distributions by CutPaste (orange dotted box), which cuts a small rectangular region (yellow dotted box) from normal data and pastes it at random location. Representations are trained either from the whole image or local patches. (b, top) An image-level representation makes a holistic decision for anomaly detection and is used to localize defect via GradCAM [51]. (b, bottom) A patch-level representation extracts dense features from local patches to produce anomaly score map, which is then max-pooled for detection or upsampled for localization [32]. tivated to produce a spatial irregularity to serve as a coarse approximation of real defects, which we have no access at training. Rectangular patches of different sizes, aspect ra-tios, and rotation angles are pasted to generate diverse aug-mentations. Although CutPaste augmented samples (Fig-ure 2(e)) are easily distinguishable from real defects and thus might be a crude approximation of a real anomaly dis-tribution, we show that representations learned by detecting irregularity introduced by CutPaste augmentations general-ize well on detecting real defects.
We evaluate our methods on MVTec anomaly detection dataset [5], a real-world industrial visual inspection bench-mark. By learning deep representations from scratch, we achieve 95.2 AUC on image-level anomaly detection, which outperforms existing works [25, 61] by at least 3.1 AUC.
Moreover, we report state-of-the-art 96.6 image-level AUC by transfer learning from an ImageNet pretrained model.
Moreover, we explain how learned representations could be used to localize the defective areas in high-resolution images. Without using any anomaly data, a simple patch model extension can achieve 96.0 pixel-level localization
AUC, which improves upon previous state-of-the-art [61] (95.7 AUC). We conduct an extensive study using different types of augmentation and proxy tasks to show the effec-tiveness of CutPaste augmentations for self-supervised rep-resentation learning on unknown defect detection. 2. A Framework for Anomaly Detection
In this section, we present our anomaly detection frame-work for high-resolution image with defects in local re-gions. Following [54], we adopt a two-stage framework for building an anomaly detector, where in the ﬁrst stage we learn deep representations from normal data and then con-struct an one-class classiﬁer using learned representations.
Subsequently, in Section 2.1, we present a novel method for learning self-supervised representations by predicting Cut-Paste augmentation, and extend to learning and extracting representations from local patches in Section 2.4. 2.1. Self-Supervised Learning with CutPaste tasks is essential
Deﬁning good pretext for self-supervised representation learning. While popular meth-ods including rotation prediction [19] and contrastive learn-ing [60, 12] have been studied in the context of semantic one-class classiﬁcation [20, 24, 4, 54, 52], our study in Sec-tion 4.1 shows that naively applying existing methods, such as rotation prediction or contrastive learning, is sub-optimal for detecting local defects as we will show in Section 4.1.
We conjecture that geometric transformations [20, 24, 4], such as rotations and translations, are effective in learning representation of semantic concepts (e.g., objectness), but less of regularity (e.g., continuity, repetition). As shown in Figure 2(b), anomalous patterns of defect detection typi-cally include irregularities such as cracks (bottle, wood) or twists (toothbrush, grid). Our aim is to design an augmenta-tion strategy creating local irregular patterns. Then we train the model to identify these local irregularity with the hope that it can generalize to unseen real defects at test time.
A popular augmentation method that could create a lo-cal irregularity in image is Cutout [18] (Figure 2(c)), which wipes out a randomly selected small rectangular area of an image. Cutout is found to be a useful data augmenta-29665
(a) Normal (b) Anomaly (c) Cutout (d) Scar (e) CutPaste (f) CutPaste (Scar)
Figure 2: Visualization of (a, green) normal, (b, red) anomaly, and (c–h, blue) augmented normal samples from bottle, toothbrush, screw, grid, and wood classes of MVTec anomaly detection dataset [5]. Augmented normal samples are generated by baseline augmentations including (c) Cutout and (d) Scar, and our proposed (e) CutPaste and (f) CutPaste (Scar). We use red arrows in (f) to highlight the pasted patch of scar shape, a thin rectangle with rotation. tion that enforces invariance, leading to improved accuracy on multi-class classiﬁcation tasks. In contrast, we start by discriminating Cutout images from the normal ones. At
ﬁrst glance, the task seems easy to solve by well-crafted low level image ﬁlters. Surprisingly, as we will show in
Section 4, without the hindsight of knowing this, a deep convolution network does not learn these shortcuts. Using
Cutout in the algorithm design for defect detection can also be found in [32, 57]. We can make the task harder by ran-domly choosing colors and the scale as shown in Figure 2(d) to avoid naive shortcut solutions.
To further prevent learning naive decision rules for dis-criminating augmented images and encouraging the model to learn to detect irregularity, we propose the CutPaste aug-mentation as follows: 1. Cut a small rectangular area of variable sizes and as-pect ratios from a normal training image. 2. Optionally, we rotate or jitter pixel values in the patch. 3. Paste a patch back to an image at a random location.
We show the CutPaste augmentation process in the orange dotted box of Figure 1 and more examples in Figure 2(e).
Following the idea of rotation prediction [19], we deﬁne the training objective of the proposed self-supervised represen-tation learning as follows:
LCP = Ex2X  CE(g(x), 0) + CE(g(CP(x)), 1)  where X is the set of normal data, CP(·) is a CutPaste aug-mentation and g is a binary classiﬁer parameterized by deep (1) networks. CE(·, ·) refers to a cross-entropy loss. In prac-tice, data augmentations, such as translation or color jitter, are applied before feeding x into g or CP. 2.2. CutPaste Variants
CutPaste-Scar. A special case of Cutout called “scar” us-ing a long-thin rectangular box of random color, as in Fig-ure 2(d), is proposed in [16] for defect detection. Simi-larly, in addition to original CutPaste using a large rectan-gular patch, we propose a CutPaste-Scar using a scar-like (long-thin) rectangular box ﬁlled with an image patch (Fig-ure 2(f)).
Multi-Class Classiﬁcation. While CutPaste (large patch) and CutPaste-Scar share a similarity, the shapes of an im-age patch of two augmentations are very different. Empir-ically, they have their own advantages on different types of defects. To leverage the strength of both scales in the train-ing, we formulate a ﬁner-grained 3-way classiﬁcation task among normal, CutPaste and CutPaste-Scar by treating Cut-Paste variants as two separate classes. Detailed study will be presented in Section 5.2.
Similarity between CutPaste and real defects. The suc-cess of CutPaste may be understood from outlier expo-sure [23], where we generate the pseudo anomalies (Cut-Paste) during the training. Apart from using natural images as in [23], CutPaste creates examples preserving more local structures of the normal examples (i.e., the pasted patch is 39666
(a) bottle (c) screw
Figure 3: t-SNE visualization of representations of models trained with 3-way CutPaste prediction task. We plot embeddings of normal (blue), anomaly (red), and augmented normal by CutPaste (“Patch”, green) and CutPaste-scar (“Scar”, yellow). (b) toothbrush (e) wood (d) grid from the same domain), which is more challenging for the model to learn to ﬁnd this irregularity.
On the other hand, CutPaste does look similar to some real defects. A natural question is if the success of Cut-Paste is from a good mimic of real defects. In Figure 3, we show the t-SNE plots of the representations from the trained model. Clearly, the CutPaste examples are almost not over-lapped with real defect examples (anomaly), but the learned representation is able to distinguish between normal exam-ple, different CutPaste augmented samples and real defects.
It suggests (1) CutPaste is still not a perfect simulation of real defects and (2) learning on it to ﬁnd irregularity gener-alizes well on unseen anomalies. 2.3. Computing Anomaly Score
There exist various ways to compute anomaly scores via one-class classiﬁers. In this work, we build generative clas-siﬁers like kernel density estimator [52] or Gaussian den-sity estimator [43], on representations f . Below, we explain how to compute anomaly scores and the trade-offs.
Although nonparametric KDE is free from distribution assumptions, it requires many examples for accurate esti-mation [58] and could be computationally expensive. With limited normal training examples for defect detection, we consider a simple parametric Gaussian density estimator (GDE) whose log-density is computed as follows: log pgde(x) ∝  − 1 2 (f (x) − µ)>Σ 1(f (x) − µ)  (2) where µ and Σ are learned from normal training data.1 2.4. Localization with Patch Representation
While we present a method for learning a holistic repre-sentation of an image, learning a representation of an im-age patch would be preferred if we want to localize defec-tive regions [38, 6, 61] in addition to image-level detection.
By learning and extracting representations from an image 1We note that a mixture of Gaussian, which is a middle ground between
KDE and GDE, can also be used for more expressive density modeling. We do not observe signiﬁcant performance gain empirically. patch, we can build an anomaly detector that is able to com-pute the score of an image patch, which then can be used to localize the defective area.
CutPaste prediction is readily applicable to learn a patch representation – all we need to do at training is to crop a patch before applying CutPaste augmentation. Similar to
Equation (1), the training objective can be written as:
Ex2X  CE(g(c(x)), 0) + CE(g(CP(c(x))), 1)  (3) where c(x) crops a patch at random location of x. At test time, we extract embeddings from all patches with a given stride. For each patch, we evaluate its anomaly score and use a Gaussian smoothing to propagate the score to every pixel [32].
In Section 4.2, we visualize a heatmap using patch-level detector for defect localization, along with that of an image-level detector using visual explanation tech-niques such as GradCAM [51]. 3.