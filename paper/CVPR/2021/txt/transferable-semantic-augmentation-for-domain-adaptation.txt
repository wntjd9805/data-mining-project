Abstract
Source-only
Source-only+TSA
DA
DA+TSA
Domain adaptation has been widely explored by trans-ferring the knowledge from a label-rich source domain to a related but unlabeled target domain. Most existing domain adaptation algorithms attend to adapting feature represen-tations across two domains with the guidance of a shared source-supervised classiﬁer. However, such classiﬁer limits the generalization ability towards unlabeled target recog-nition. To remedy this, we propose a Transferable Seman-tic Augmentation (TSA) approach to enhance the classiﬁer adaptation ability through implicitly generating source fea-tures towards target semantics. Speciﬁcally, TSA is inspired by the fact that deep feature transformation towards a cer-tain direction can be represented as meaningful semantic altering in the original input space. Thus, source features can be augmented to effectively equip with target semantics to train a more transferable classiﬁer. To achieve this, for each class, we ﬁrst use the inter-domain feature mean differ-ence and target intra-class feature covariance to construct a multivariate normal distribution. Then we augment source features with random directions sampled from the distribu-tion class-wisely. Interestingly, such source augmentation is implicitly implemented through an expected transferable cross-entropy loss over the augmented source distribution, where an upper bound of the expected loss is derived and minimized, introducing negligible computational overhead.
As a light-weight and general technique, TSA can be easily plugged into various domain adaptation methods, bringing remarkable improvements. Comprehensive experiments on cross-domain benchmarks validate the efﬁcacy of TSA. 1.

Introduction
Deep learning has achieved remarkable success on var-ious vision tasks, including image recognition [16, 12, 14] and semantic segmentation [55, 49]. However, the recent success of deep learning methods heavily relies on massive
∗Corresponding author.
Source
Target
Augmented Source
Figure 1. Overview of TSA, which relaxes the assumption that source and target domains share the same classiﬁer. For both tradi-tional deep learning and DA methods, TSA could augment source features towards target semantics to successfully adapt the ﬁnal classiﬁer from source domain to target domain. labeled data. In practice, collecting abundant annotated data is expensive [30, 6, 54, 33]. Meanwhile, each domain has its own speciﬁc exploratory factors, namely semantics, e.g., the illuminations, colors, visual angles or backgrounds, re-sulting in the domain shift [28]. Hence, traditional deep models trained on a large dataset usually show poor gener-alizations on a new domain due to the domain shift issues
[24, 10]. To remedy this, one appealing alternative is do-main adaptation (DA), which strives to leverage the knowl-edge of a label-rich source domain to assist the learning in a related but unlabeled target domain [24, 10].
Prior deep DA methods can be roughly categorized as 1) statistical discrepancy minimization based methods [27, 20, 51], which leverage statistical regularizations to explic-itly mitigate the cross-domain distribution discrepancy; and 2) adversarial learning based methods [21, 25, 10], which strive to learn domain-invariant representations across two domains via adversarial manners.
Indeed, these DA methods have admittedly yielded promising results, but most of them assume a shared classi-ﬁer with domain-invariant representations derived. Rare at-tention has been paid to explicitly enhancing the adaptation ability of the source-supervised classiﬁer, which is also fun-damental to DA problems as shown in Fig. 1. To achieve classiﬁer adaptation, Long et al.
[26] introduce classiﬁer residual learning to explicitly model the classiﬁer differ-ence across domains. SymNets [52] constructs three classi-ﬁers to facilitate joint distribution alignment. However, they 11516
all rely on designing complex network architectures, which may suffer from high computational overhead and hinder the capability and versatility of these methods.
To alleviate aforementioned issues, we propose a Trans-ferable Semantic Augmentation (TSA) approach to implic-itly augment source features with target semantic guidance in the deep feature space to facilitate classiﬁer adaptation.
Speciﬁcally, TSA is motivated by the intriguing property that deep networks excel at disentangling the underlying factors of data variation and linearizing the deep features
[41, 45]. There exist many different semantic transforma-tion directions in the deep feature space, and the semantic transformation of one sample can be enforced by translating its deep feature along a certain direction, such as the direc-tion of changing backgrounds. However, it is nontrivial to explicitly discover all kinds of semantic transformation di-rections. In addition, not all directions are meaningful.
Hence, to effectively explore meaningful transformation directions, we ﬁrst estimate the inter-domain feature mean difference for each class as the class-wise overall semantic (i.e., an integration of various semantics in one class) bias in the deep feature space. Besides, since the speciﬁc se-mantic information (e.g., different backgrounds, shapes or visual angles) of source and target are different, TSA further estimates target intra-class feature covariance to effectively capture the intra-class semantic variations of target domain.
To obtain the accurate estimation, we introduce a memory module to class-wisely calculate feature mean and covari-ance with pseudo-labeled target samples. At last, we sample semantic transformation directions for source augmentation from a multivariate normal distribution, with the estimated feature mean difference as mean and the target intra-class covariance. In this way, the overall semantic difference be-tween domains and the target intra-class semantic variations can guide source augmented features towards target.
Furthermore, to avoid explicitly generating augmented features and improve the efﬁciency of TSA, we develop an expected transferable cross-entropy loss over the aug-mented source distribution with an upper bound derived.
By minimizing the upper bound of the expected loss, the source semantic augmentation can be performed and the ex-tra computational overhead is negligible. Then, the trained source classiﬁer can be successfully adapted to target.
Contributions of this work are summarized as follows:
• We propose a novel Transferable Semantic Augmen-tation (TSA) method for classiﬁer adaptation, which enables source feature augmentation towards target in an implicit manner. Notably, TSA introduces no extra network modules over the backbone network, making it simple to implement and computationally efﬁcient.
• We develop a novel expected transferable cross-entropy loss over the augmented source distribution for DA, which greatly enhances the classiﬁer adapta-tion ability. Moreover, as a light-weight and general technique, TSA can be easily plugged into various DA methods to signiﬁcantly boost their performances.
• Extensive experiments on several cross-domain bench-marks, including Ofﬁce-Home, Ofﬁce-31, VisDA-2017 and digits demonstrate that TSA can consistently yield signiﬁcant performance improvements. 2.