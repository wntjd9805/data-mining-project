Abstract 1.

Introduction
We present NeuroMorph, a new neural network architec-ture that takes as input two 3D shapes and produces in one go, i.e. in a single feed forward pass, a smooth interpolation and point-to-point correspondences between them. The in-terpolation, expressed as a deformation ﬁeld, changes the pose of the source shape to resemble the target, but leaves the object identity unchanged. NeuroMorph uses an ele-gant architecture combining graph convolutions with global feature pooling to extract local features. During training, the model is incentivized to create realistic deformations by approximating geodesics on the underlying shape space manifold. This strong geometric prior allows to train our model end-to-end and in a fully unsupervised manner with-out requiring any manual correspondence annotations. Neu-roMorph works well for a large variety of input shapes, including non-isometric pairs from different object cate-gories. It obtains state-of-the-art results for both shape cor-respondence and interpolation tasks, matching or surpass-ing the performance of recent unsupervised and supervised methods on multiple benchmarks.
The ability to relate the 3D shapes of objects is of key importance to fully understand object categories. Objects can change their shape due to articulation, other motions and intra-category variations, but such changes are not arbi-trary. Instead, they are strongly constrained by the category of the objects at hand. Seminal works such as [33] express such constraints by learning statistical shape models. In or-der to do so, they need to put in correspondence large col-lections of individual 3D scans, which they do by exploiting the fact that individual objects deform continuously in time, and by using some manual inputs to align different object instances. Due to the high complexity of obtaining and pre-processing such 3D data, however, these models remain rare and mostly limited to selected categories such as humans that are of sufﬁcient importance in applications. In this pa-per, we are thus interested in developing a method that can learn to relate different 3D shapes fully automatically, in-terpolating a small number of 3D reconstructions, and in a manner which is less speciﬁc to a single category (Figure 1).
Due to the complexity of this task, authors have often considered certain sub-problems in isolation. One is to 7473
establish point-to-point correspondences between shapes, telling which points are either physically identical (for a given articulated object) or at least analogous (for simi-lar objects). A second important sub-problem is interpo-lation, which amounts to continuously deforming a source shape into a target shape. Interpolation must produce a col-lection of intermediate shapes that are meaningful in their own right, in the sense of being plausible samples from the underlying shape distribution. The interpolation trajectory must be also meaningful; for instance, if the deformation between two shapes can be explained by the articulation of an underlying physical object, this solution is preferred.
The correspondence and interpolation problems have been addressed before extensively, by using tools from ge-ometry and, more recently, machine learning. Most of the existing algorithms, however, require at least some man-ual supervision, for example in the form of an initial set of sparse shape correspondences. Furthermore, correspon-dence and interpolation are rarely addressed together due to their complexity.
In this paper, we advocate instead for an approach in which the correspondence and interpolation problems are solved simultaneously, and in an unsupervised manner. To do this, we introduce NeuroMorph, a new neural network that solves the two problems in a single feed forward pass.
We show that, rather than making learning more difﬁcult, integrating two goals reinforces them, making it possible to obtain excellent empirical results. Most importantly, we show that NeuroMorph can be learned in a fully unsuper-vised manner, given only a collection of 3D shapes as input and certain geometric priors for regularization.
NeuroMorph advances the state of the art in shape matching and interpolation, surpassing by a large margin prior unsupervised methods and often matching the qual-ity of supervised ones. We show that NeuroMorph can es-tablish high-quality point-to-point correspondences without any manual supervision even for difﬁcult cases in which shapes are related by substantial non-isometric deforma-tions (such as between two different types of animals, like a cat and a gorilla, as in Figure 1) which have challenged prior approaches. Furthermore, we also show that NeuroMorph can interpolate effectively between different shapes, acting on the pose of a shape while leaving its identity largely un-changed. To demonstrate the quality of the interpolation, we use it for data augmentation, extending a given dataset of 3D shapes with intermediate ones. Augmenting a dataset in this manner is useful when, as it is often the case, 3D training data is scarce. We show the beneﬁts of this form of data augmentation to supervise other tasks, such as recon-structing continuos surfaces from sparse point clouds.
Our new formulation also gives rise to some interesting applications: Since our method learns a function that pro-duces correspondence and interpolation in a single feed for-ward pass, it can be used not only to align different shapes, but also for pose transfer, digital puppeteering and other vi-sual effects. 2.