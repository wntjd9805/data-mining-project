Abstract
Improving the performance of face forgery detectors often requires more identity-swapped images of higher-quality. One core objective of identity swapping is to gener-ate identity-discriminative faces that are distinct from the target while identical to the source. To this end, prop-erly disentangling identity and identity-irrelevant informa-tion is critical and remains a challenging endeavor. In this work, we propose a novel information disentangling and swapping network, called InfoSwap, to extract the most expressive information for identity representation from a pre-trained face recognition model. The key insight of our method is to formulate the learning of disentangled repre-sentations as optimizing an information bottleneck trade-off, in terms of ﬁnding an optimal compression of the pre-trained latent features. Moreover, a novel identity con-trastive loss is proposed for further disentanglement by re-quiring a proper distance between the generated identity and the target. While the most prior works have focused on using various loss functions to implicitly guide the learn-ing of representations, we demonstrate that our model can provide explicit supervision for learning disentangled rep-resentations, achieving impressive performance in generat-ing more identity-discriminative swapped faces. 1.

Introduction
Face forgery detection aims to identify whether a given facial image has been modiﬁed, and is currently dominated by data-driven approaches [35, 31, 28, 27]. This means that it is difﬁcult to improve the performance of forgery detec-tors in the absence of high-quality Deepfake data. There-fore, better face-swapping methods are in dire need to help develop powerful forgery algorithms.
Recent works have made signiﬁcant contributions in this regard. FaceSwap [25] enables face swapping in real-time.
RSGAN [30] and FSNet [36] introduce GAN-based meth-ods in synthesizing swapped face. FSGAN [32] proposes a subject-agnostic approach for both face swapping and reen-*Corresponding Author actment. More recently, FaceShifter [26] puts its focus on the occlusion problem and achieves high ﬁdelity.
The core objective of identity swap (i.e. face swap) is to keep the identity of the swapped face the same as the source face while sharing the identity-irrelevant perceptual information (e.g. pose, expression, and illumination) with the target face. Therefore, proper disentanglement is an es-sential premise for well representing the identity and the perceptual information. Otherwise, entangled target percep-tion will inevitably bring the target identity into the syn-thesis process, leading to an identity-mixed result. De-spite such importance, it is yet to see a breakthrough for disentangled representation on face swapping. Previous works [25, 30, 4, 19, 32, 26] attempt to constrain the iden-tity and perception of the generated faces by adding multi-ple loss terms to the objective function. However, due to the lack of explicit supervision, it is still challenging for these works to learn well-disentangled representations.
In this paper, we focus on improving disentangled repre-sentation learning in subject-agnostic face swap. The main idea is to learn the minimal sufﬁcient statistics, namely the optimal representations, for both the identity and identity-irrelevant perceptual information from the latent features of a pre-trained model [10]. By introducing the information-theoretic principles [44, 40, 2], we model this learning pro-cess as a problem of optimizing the Information Bottleneck (IB) trade-off, performed by a novel information disentan-glement network InfoSwap. Based on the IB principle, we can provide explicit supervision for disentangled represen-tation learning. Moreover, we improve the IB objectives to further facilitate the representation disentangling. Driven by the intuition that proper swapped faces should be not only close to the source in identity but also distinct from the target, we provide a clear deﬁnition for discriminative identities and extent the original IB objectives with a novel
Identity Contrastive Loss (ICL) as an additional regulariza-tion on the generated identities.
Extensive experiments show that our method can bet-ter disentangle information and generate more identity-discriminative swapped faces with higher ﬁdelity. A com-3404
are mainly based on the 3D method. Face2Face [43] ad-dresses the limitation of expression transfer by ﬁtting a 3D morphable model (3DMM) [7] to both the source and target face. Nirkin et al. [33] proposes a 3D-based face segmentation method for seamless face transfer. Neural
Textures [42] enables the synthesis of photo-realistic im-ages with noisy and incomplete 3D geometry. Besides, learning-based methods have enabled great progress in face swap. FaceSwap [25] enables real-time subject-aware face-swapping by building image-to-image translation models case-by-case. RSGAN [30] swaps the face by learning rep-resentations of the face and the other area separately. FS-GAN [32] achieves both face swap and face reenactment in a subject-agnostic pipeline. FaceShifter [26] proposes to tackle the occlusion problem via a secondary residual learn-ing network. While there are many works on feature dis-entanglement, [45, 17, 16, 48, 13, 14] are for classiﬁcation tasks and [50, 37, 12] are not focused on disentangling iden-tity, for example. [11] proposes a reference-based genera-tion for face rotation and manipulation, which can be trans-ferred to face swap. Little attention has been paid to gen-erating better disentangled and highly discriminative iden-tities, which is the focus of this work. Recently, some im-portant advances have been made in face forgery detection.
For example, Faceforensics++ [35] provides an automated benchmark as well as a large database of manipulated im-ages for building stronger detection algorithms. However, improving the accuracy of data-driven forgery detectors re-quires more high-quality face-swapped data. 2.2. Information Bottleneck
The idea of viewing Deep Neural Network (DNNs) in the plane of the Mutual Information is ﬁrst pointed out in [44], suggesting that the goal of DNNs is to optimize the Infor-mation Bottleneck (IB) trade-off between the compression and the predictive power of the internal representations. Af-ter that, [3] proposes a variational inference to approximate the bounds on mutual information by using the reparameter-ization trick [24], so that it becomes easier to optimize the information bottleneck objective when applying to DNNs.
More recently, [39] proposes to adopt the information bot-tleneck trade-off in attribution by quantifying the amount of information that an image region can provide for classiﬁca-tion tasks. We will provide a more detailed description of the Information Bottleneck Principle and how it relates to our work in Section 3.2. 3. Method
Given two facial images, i.e. a source Xs and a target
Xt, our proposed InfoSwap generates a face-swapped im-age Ys,t that shares the identity with Xs and the perception with Xt. An overview of the swapping process is shown in Fig. 2. InfoSwap consists of two learnable modules, an
Informative Identity Bottleneck (IIB in blue) and an Adap-tive Information Integrator (AII in brown), while the IIB 3405
Figure 1. Challenging conditions discriminative faces. More details please refer to Section 4. for generating identity-parison with state-of-the-art methods is shown in Fig. 1. For example, the face shape of our generated results is closer to the source rather than the target. The empirical out-performance imply that our model can provide data-driven detection algorithms with more realistic Deepfake data to improve their performance. The main contributions of this paper are the following:
• We adopt the IB principle for disentangled representation to extract the minimal sufﬁcient identity and perceptual information. The IB principle provides a guarantee that in the latent space, areas scored identity-irrelevant indeed contribute little information to predict identity, thus en-abling explicit supervision for disentanglement.
• We extent the IB objectives with a novel identity con-trastive loss to further facilitate the disentanglement by requiring the generated identities to keep proper distances from the targets.
• We provide a novel metric to evaluate if the generated identity is discriminative based on its statistical features.
• Experimental results show that our method is robust and can produce more identity-discriminative swapped faces with high-ﬁdelity. 2.