Abstract
We propose a method to disentangle linear-encoded fa-cial semantics from StyleGAN without external supervision.
The method derives from linear regression and sparse rep-resentation learning concepts to make the disentangled la-tent representations easily interpreted as well. We start by coupling StyleGAN with a stabilized 3D deformable facial reconstruction method to decompose single-view GAN gen-erations into multiple semantics. Latent representations are then extracted to capture interpretable facial semantics. In this work, we make it possible to get rid of labels for disen-tangling meaningful facial semantics. Also, we demonstrate that the guided extrapolation along the disentangled repre-sentations can help with data augmentation, which sheds light on handling unbalanced data. Finally, we provide an analysis of our learned localized facial representations and illustrate that the semantic information is encoded, which surprisingly complies with human intuition. The overall un-supervised design brings more ﬂexibility to representation learning in the wild. 1.

Introduction
In recent years, Generative Adversarial Networks (GANs) [12] have been a great success in synthesizing photo-realistic images given a set of latent codes. Despite the rapid boost in image quality, the interpretability of the generation process has become another major area of re-In general, interpretability requires latent codes search. to encode disentangled semantic information of the im-age. Further, ideally, well-disentangled semantics are sup-posed to be factorized to practically interpretable compo-nents and each component should be linear-encoded in the latent space as representation [15, 9, 5, 19, 30, 11].
StyleGAN [17] proposes a new architecture by bring-ing an intermediate latent space to provide support for dis-entanglement property for face generation. Consequently, facial semantics are linear-encoded as latent representa-tions. Based on StyleGAN, recent works show that sam-pling along the linear-encoded representation vector in la-tent space will change the associated facial semantics ac-cordingly [32], which makes it possible to manipulate the face generations to meet a target requirement. However, in current frameworks, mapping a particular facial seman-tics to a latent representation vector relies on training of-ﬂine classiﬁers with manually labeled datasets. Thus they require artiﬁcially deﬁned semantics and provide the asso-ciated labels for all facial images. The disadvantages for training with labeled facial semantics include: ﬁrst, they demand extra effort on human annotations for each new at-tributes proposed; second, each semantics is deﬁned arti-ﬁcially, and the scope of semantics is limited to the linear 3917
combination of such deﬁnitions; and third, by only train-ing on each labeled semantics independently, we are unable to give any insights on the connections among different se-mantics.
In this work, we explore unsupervised methods to mini-mize the demand for human annotation. We propose a novel unsupervised framework to disentangle and manipulate fa-cial semantics under the StyleGAN environment, while still maintain the interpretability for semantics (Fig. 1) as in la-beled datasets.
• We motivate decorrelation regularization on Style-GAN to further enhance disentanglement for the latent representation.
• We introduce mutual reconstruction to stabilize train-ing of an unsupervised 3D deformable face reconstruc-tion method, such that it serves as an initial facial se-mantic extractor.
• For univariate semantics, e.g., yaw angle, we present a linear regression method to capture their perturbations from latent space. Given the manipulation vector, we further demonstrate the success of yaw manipulation on data augmentation to trivialize the unbalanced pose problem within the unsupervised paradigm.
• For pixel-level semantics, e.g., shape and texture, we propose a localized representation learning algorithm to capture sparse semantic perturbations from latent space. The associated analysis evinces the effective-ness of our method to provide interpretability without external supervision.
All methods proposed are purely based on a label-free train-ing strategy. Only StyleGAN is trained with an in-the-wild face dataset. Therefore, we reduce a signiﬁcant amount of human involvement in facial representation learning. Fur-thermore, with zero labels, our framework provides an unconstrained environment for the disentanglement algo-rithms to explore and shed light on how interpretable repre-sentations are learned in cutting-edge neural network mod-els. 2.