Abstract 3D morphable models are widely used for the shape rep-resentation of an object class in computer vision and graph-ics applications. In this work, we focus on deep 3D mor-phable models that directly apply deep learning on 3D mesh data with a hierarchical structure to capture information at multiple scales. While great efforts have been made to de-sign the convolution operator, how to best aggregate ver-tex features across hierarchical levels deserves further at-tention.
In contrast to resorting to mesh decimation, we propose an attention based module to learn mapping matri-ces for better feature aggregation across hierarchical lev-els. Speciﬁcally, the mapping matrices are generated by a compatibility function of the keys and queries. The keys and queries are trainable variables, learned by optimizing the target objective, and shared by all data samples of the same object class. Our proposed module can be used as a train-only drop-in replacement for the feature aggregation in existing architectures for both downsampling and upsam-pling. Our experiments show that through the end-to-end training of the mapping matrices, we achieve state-of-the-art results on a variety of 3D shape datasets in comparison to existing morphable models. 1.

Introduction
The 3D morphable models play a core role in many 3D applications, including identity recognition, shape retrieval, shape completion, animation and 3D reconstruction from 2D images [46, 42, 26]. 3D morphable models encode raw 3D shapes into latent variables, from which the shapes can be reconstructed to some approximation by interacting with the 3D shape model. In this work, we are particularly in-terested in 3D mesh shapes that share a common template and are already aligned to the template. The commonly employed encoding approaches are the linear encoding of
Principal Component Analysis [1, 26, 44, 53] or manually deﬁned blendshape [45, 24, 8] for human face, skinned ver-tex based models like Skinned Multi-Person Linear Mod-el [30] and hand model with articulated and non-rigid de-formations [38] for body and hand and non-linear encod-ings of autoencoder neural nets [43]. Compared to the clas-sical linear models, the non-linear models, especially deep learning based models, offer the possibility to capture de-tailed deformations like wrinkles and surpass them in terms of generalization, compactness and speciﬁcity [40].
Recently, there is an emerging interest in generalizing
CNNs to meshes with operations directly deﬁned on mesh-es [37, 9]. Both isotropic [37] and anisotropic [9] convolu-tions have been introduced for meshes with a ﬁxed topol-ogy. Feature aggregation is deﬁned for the downsampling and upsampling of vertex features and combined with con-volutions to construct mesh autoencoders [37]. Despite the success of such models, the feature aggregation across hier-archical levels is determined by a preprocessing stage that maintains surface error approximations with quadric met-rics [17] rather than by optimizing the learning objective.
Such procedure limits the representation power of the mor-phable model to capture ﬁne grained deformations.
In this work, we propose an attention based feature ag-gregation strategy to construct hierarchical representations
Instead for 3D meshes with a ﬁxed topology (Fig. 1(a)). of using the precomputed matrices (Fig. 1(b)), we propose to learn the mapping matrices along with the convolution-s in the network (Fig. 1(c)). The attention based mapping module introduces keys and queries as trainable variables that are shared by all data samples in the dataset. With keys and queries standing for the vertices at the preced-ing and succeeding levels respectively, the mapping matri-ces are derived by a compatibility function of the keys and queries. This allows the receptive ﬁelds and aggregation weights to be simultaneously learned. By varying the num-ber of keys and queries, this module can be used for either downsampling or upsampling. Since only mapping matri-ces are needed for inference, we can detach the attention based mapping module once training is ﬁnished to avoid additional cost at inference stage. We evaluate our method on the reconstruction task which serves as a fundamental testbed for further applications. We quantitatively and qual-itatively show the results on three 3D human shape datasets: faces, bodies, and hands. As a drop-in replacement for ex-13164
5023*3 upsampling upsampling 20*32 79*32 79*32 314*32 upsampling 5023*16 mesh  encoder 314*3 79*3 314*79 mapping matrix surrr surface simplification (b) 79*32 g n i l p m a s p u 314*32 conv. (a) 314*c 79*c conv.
... mesh decoder qurey 314*79 mapping matrix key attention based  feature aggregation (c) 5023*3 conv. data flow back  propogation 79*32 g n i l p m a s p u 314*32
Figure 1. (a) Deep 3D morphable model with mesh encoder and decoder. The mesh encoder encodes a mesh as a compact latent represen-tation, which the mesh decoder takes as input to recover the mesh with hierarchical upsampling and convolution operations. (b) A ﬁxed mapping matrix generated by surface simpliﬁcation is used for feature aggregation across hierarchical levels in [37, 9]. (c) In this work, the mapping matrix for feature aggregation is generated by an attention based module and jointly learned with other components of the model isting feature aggregation method, our method boosts the performance of existing models by a large margin, in com-bination with either isotropic or anisotropic convolution op-erators. 2.