Abstract
While GANs have shown success in realistic image gen-eration, the idea of using GANs for other tasks unrelated to synthesis is underexplored. Do GANs learn meaning-ful structural parts of objects during their attempt to re-produce those objects? In this work, we test this hypoth-esis and propose a simple and effective approach based on GANs for semantic part segmentation that requires as few as one label example along with an unlabeled dataset.
Our key idea is to leverage a trained GAN to extract a pixel-wise representation from the input image and use it as feature vectors for a segmentation network. Our ex-periments demonstrate that this GAN-derived representa-tion is “readily discriminative” and produces surprisingly good results that are comparable to those from supervised baselines trained with signiﬁcantly more labels. We be-lieve this novel repurposing of GANs underlies a new class of unsupervised representation learning, which can gener-alize to many other tasks. More results are available at https://RepurposeGANs.github.io/. 1.

Introduction
After seeing what an elephant trunk looks like for the
ﬁrst time, a young child can identify this conspicuous part for the whole herd. This key capability in humans is still
*Authors contributed equally to this work. a fundamental challenge in computer vision. That is, how can a machine learn to identify an object or its parts by seeing only one or few examples? A kid does, however, have access to prior visual information learned constantly throughout the years, and he or she could quickly learn to identify human ears perhaps by utilizing the experience of seeing many faces before. In this paper, we tackle a prob-lem inspired by this scenario. Given a large photo collection of human faces, or any other object classes, our goal is to identify the pixels corresponding to each semantic part for unseen face images given very few images with part anno-tations.
This problem setup is different from the typical deﬁni-tion of few-shot learning, which describes a problem where a learning algorithm trained with many object classes needs to classify or operate on new classes with few supervised examples of those new classes. In contrast, our novel few-shot setup involves a single object class with few annotated examples and no other training data from any other classes.
Many methods are proposed in this area of few-shot learn-ing, and the general idea is to apply prior knowledge learned externally to the few-shot task. Examples include meta learning [40] and prototype representation [31, 51] which extract information from annotations of non-target classes or image-level annotations to be used as prior knowledge.
However, most of these approaches still learn from some supervised task that requires expensive labels or part an-notations. In this work, we introduce a new direction that 4475
uses a generative model, speciﬁcally a generative adversar-ial network (GAN) [19], to learn this prior knowledge from zero labels and apply it to semantic segmentation.
GANs have been highly successful in modeling the data distribution and generating realistic images [25, 26, 4]. We hypothesize that GANs need to learn meaningful structural information of objects in order to synthesize them correctly, and the generative computations required to synthesize dif-ferent parts of object could provide useful discriminative information for other tasks [2, 36]. Our main contribution is a method that leverages a trained GAN to extract mean-ingful pixel-wise representations from images. These rep-resentations can then be used directly for semantic part seg-mentation. Our experiments show that GANs are incredibly effective for learning such representations and can achieve surprisingly good segmentation results with only one exam-ple label (see Figure 1). To our knowledge, this is the ﬁrst time such high-quality results are achieved on one-shot part segmentation.
Despite its remarkable results, this core idea alone heav-ily relies on time-consuming latent optimization and re-quires the test image to lie close to the image distribution learned by GANs. In this paper, we also demonstrate a sim-ple extension, called auto-shot segmentation, that can by-pass the latent optimization, leading to faster and more efﬁ-cient predictions. And importantly, by performing geomet-ric data augmentation during auto-shot training, we can seg-ment multiple objects with different sizes and orientations all at once—a real-world scenario unseen during training.
To summarize, our main contribution is a novel use of
GANs for unsupervised pixel-wise representation learning, which achieves surprising and unprecedented performance on few-shot semantic part segmentation. Our ﬁndings re-veal that such a representation is readily discriminative. We also demonstrate how to extend the main idea to real-world scenarios to address some of the domain gap between the
GAN’s training data and real-world images. 2.