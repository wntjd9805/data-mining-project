Abstract
In this paper, we propose a Point-Voxel Recurrent All-Pairs Field Transforms (PV-RAFT) method to estimate scene ﬂow from point clouds. Since point clouds are irregu-lar and unordered, it is challenging to efﬁciently extract fea-tures from all-pairs ﬁelds in the 3D space, where all-pairs correlations play important roles in scene ﬂow estimation.
To tackle this problem, we present point-voxel correlation
ﬁelds, which capture both local and long-range dependen-cies of point pairs. To capture point-based correlations, we adopt the K-Nearest Neighbors search that preserves ﬁne-grained information in the local region. By voxelizing point clouds in a multi-scale manner, we construct pyramid cor-relation voxels to model long-range correspondences. Inte-grating these two types of correlations, our PV-RAFT makes use of all-pairs relations to handle both small and large dis-placements. We evaluate the proposed method on the Fly-ingThings3D and KITTI Scene Flow 2015 datasets. Exper-imental results show that PV-RAFT outperforms state-of-the-art methods by remarkable margins.
Figure 1: Illustration of the proposed point-voxel correla-tion ﬁelds. For a point in the source point cloud, we ﬁnd its k-nearest neighbors in the target point cloud to extract point-based correlations. Moreover, we model long-range interactions by building voxels centered around this source point. Combining these two types of correlations, our PV-RAFT captures all-pairs dependencies to deal with both large and small displacements. 1.

Introduction 3D scene understanding [7,16,32,34,45,51] has attracted more and more attention in recent years due to its wide real-world applications. As one fundamental 3D computer vi-sion task, scene ﬂow estimation [6, 10, 18, 23, 26, 50] fo-cuses on computing the 3D motion ﬁeld between two con-secutive frames, which provides important dynamic infor-mation. Conventionally, scene ﬂow is directly estimated from RGB images [20, 21, 41, 43]. Since 3D data becomes easier to obtain, many works [6, 18, 26, 50] begin to focus on scene ﬂow estimation of point clouds more recently.
*Equal Contribution
†Corresponding author
Thanks to the recent advances in deep learning, many approaches adopt deep neural networks for scene ﬂow es-timation [6, 18, 26, 39, 50]. Among these methods, [18, 50] borrow ideas from [5, 11, 35], leveraging techniques in ma-ture optical ﬂow area. FlowNet3D designs a ﬂow embed-ding module to calculate correlations between two frames.
Built upon PWC-Net [35], PointPWC-Net [50] introduces a learnable point-based cost volume without the need of 4D dense tensors. These methods follow a coarse-to-ﬁne strat-egy, where scene ﬂow is ﬁrst computed at low resolution and then upsampled to high resolution. However, this strat-egy has several limitations [37] , e.g. error accumulation from early steps and the tendency to miss fast-moving ob-jects. One possible solution is to adopt Recurrent All-Pairs 6954
Field Transforms (RAFT) [37], a state-of-the-art method for 2D optical ﬂow, that builds correlation volumes for all pairs of pixels. Compared with the coarse-to-ﬁne strategy, the all-pairs ﬁeld preserves both local correlations and long-range relations. Nevertheless, it is non-trivial to lift it to the 3D space. Due to the irregularity of point clouds, building structured all-pairs correlation ﬁelds becomes challenging.
Moreover, since point clouds are unordered, it is difﬁcult to efﬁciently look up neighboring points of a 3D position. Un-fortunately, the correlation volumes used in previous meth-ods [6, 18, 50] only consider near neighbors, which fails to capture all-pairs relations.
To address these issues, we present point-voxel corre-lation ﬁelds that aggregate the advantages of both point-based and voxel-based correlations (illustrated in Figure 1).
As mentioned in [19, 32, 36], point-based features main-tain ﬁne-grained information while voxel-based operation efﬁciently encodes large point set. Motivated by this fact, we adopt K-Nearest Neighbor (KNN) search to ﬁnd a ﬁxed number of neighboring points for point-based correlation
ﬁelds. Meanwhile, we voxelize target point clouds in a multi-scale fashion to build pyramid correlation voxels.
These voxel-based correlation ﬁelds collect long-term de-pendencies and guide the predicted direction. Moreover, to save memory, we present a truncation mechanism to aban-don the correlations with low scores.
Based on point-voxel correlation ﬁelds, we propose a Point-Voxel Recurrent All-Pairs Field Transforms (PV-RAFT) method to construct a new network architecture for scene ﬂow estimation of point clouds. Our method ﬁrst em-ploys a feature encoder to extract per-point features, which are utilized to build all-pair correlation ﬁelds. Then we adopt a GRU-based operator to update scene ﬂow in an iterative manner, where we leverage both point-based and voxel-based mechanisms to look up correlation features.
Finally, a reﬁnement module is introduced to smooth the estimated scene ﬂow. To evaluate our method, we con-ducted extensive experiments on the FlyingThings3D [20] and KITTI [21, 22] datasets. Results show that our PV-RAFT outperforms state-of-the-art methods by a large mar-gin. The code is available at https://github.com/ weiyithu/PV-RAFT. 2.