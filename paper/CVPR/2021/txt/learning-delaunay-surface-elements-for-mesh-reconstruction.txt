Abstract
[35]
We present a method for reconstructing triangle meshes from point clouds. Existing learning-based methods for mesh reconstruction mostly generate triangles individually, making it hard to create manifold meshes. We leverage the properties of 2D Delaunay triangulations to construct a mesh from manifold surface elements. Our method ﬁrst estimates local geodesic neighborhoods around each point.
We then perform a 2D projection of these neighborhoods using a learned logarithmic map. A Delaunay triangula-tion in this 2D domain is guaranteed to produce a mani-fold patch, which we call a Delaunay surface element. We synchronize the local 2D projections of neighboring ele-ments to maximize the manifoldness of the reconstructed mesh. Our results show that we achieve better overall man-ifoldness of our reconstructed meshes than current meth-ods to reconstruct meshes with arbitrary topology. Our code, data and pretrained models can be found online: https://github.com/mrakotosaon/dse-meshing 1.

Introduction
Surface reconstruction from a given set of points (e.g., a scan), has a long history in computational geometry and computer vision [5, 39]. A version of the problem requires triangulating a given point cloud to produce a watertight and manifold surface. A key challenge is to handle different sampling conditions while producing well-shaped triangles and preserving the underlying shape features.
A good surface reconstruction algorithm should satisfy the following requirements: (i) produce a connected, man-(ii) require no case-ifold and watertight triangulation; speciﬁc parameter tuning; (iii) preserve sharp features; (iv) handle point sets with non-uniform distribution; and
[42]
[42]
[35]
Figure 1. We present a method for mesh reconstruction from point clouds. We combine Delaunay triangulations with learned local parameterizations to obtain a higher-quality mesh than the current state-of-the-art. Bad (non-manifold) triangles are shown in red.
Our method is robust to uniformly (top) and non-uniformly (bot-tom) sampled points. 22
(v) generalize to handle a variety of shapes.
A widely-used pipeline for surface reconstruction con-sists in ﬁrst computing an implicit surface representation
[31] and then extracting a triangulation using a volumet-ric method such as Marching Cubes [36]. Methods in this category often require additional information (e.g., oriented normals), while, crucially, the resulting triangulations may not preserve the original point set and can oversmooth sharp features. On the other hand, methods from computational geometry, e.g., alpha shapes [20], ball pivoting [6], etc., can respect the original point set, come with theoretical guar-antees and produce triangulations with desirable properties (e.g., good angle distribution). These approaches, however, typically require careful parameter selection and rely on dense, uniformly sampled point sets.
More recently, learning-based approaches have been de-veloped to extract a triangulation without case-speciﬁc pa-rameter selection. Most of such techniques focus on ro-bustly predicting a signed distance ﬁeld or simply an oc-cupancy map, from which a mesh is subsequently extracted using volumetric triangulation [12, 23, 41]. Only two recent methods [42, 35] produce a triangulation while respecting the original point set, but they ignore the quality of the tri-angles or have trouble reconstructing sharp features.
We present a method that combines the advantages of classical methods with learning-based data priors. Our method is based on blending together Delaunay surface el-ements, which are deﬁned by a 2D Delaunay triangulation of a local neighborhood in the point set after projecting it to a planar 2D domain. For this, we propose an approach that predicts a local projection via learned logarithmic maps and uses them to propose likely triangles using local Delaunay triangulations. Figure 1 shows an example reconstructions using our method. We evaluate our method on a benchmark of diverse surface point sets, and provide a comparison with both classical and learning-based methods to show the ad-vantages of the proposed approach. Through these exten-sive experiments, we demonstrate that our method gener-alizes across diverse test sets, is more robust than classical approaches, and produces higher-quality triangulations than recent learning-based methods.
Cubes [36] or Dual Contouring [30]. Such approaches work well in the presence of oriented normals and dense/uniform point sets, but do not necessarily preserve the given points in the ﬁnal mesh and lead to over-smoothing or loss of de-tails (see [5] for a detailed discussion).
We were inspired by classical methods based on Delau-nay triangulations [8, 33, 9, 25, 17], alpha shapes [20] or ball pivoting [6]. Such approaches can be shown to recover the shape mesh topology [2] under certain sampling con-ditions (an excellent overview of such approaches is pro-vided in [16]). Unlike implicit-based methods, approaches in this category, e.g., [6, 1, 10] typically preserve the input point set. However, they can often fail to produce satisfac-tory results for coarsely sampled shapes or in the presence of complex geometric features. Another more robust, but computationally more expensive, approach capable of fea-ture preservation was introduced in [18], based on iterative optimisation using optimal transport. 2.1. Learning for surface reconstruction
To address the challenges mentioned above, recent meth-ods have aimed to learn surface reconstruction priors from data. The majority of existing learning-based methods in this area use a volumetric shape representation. For exam-ple, meshes can be computed by predicting voxel grid occu-pancy [24, 37] or via a differentiable variant of the marching cubes [34], or more recently using generative models for ex-plicit or implicit surface prediction [12, 23, 41, 38]. While these methods can produce accurate results they solve a dif-ferent problem to ours and do not compute a mesh over the given point set. Instead, we focus on directly meshing a set of input points, which provides better control over the ﬁ-nal shape and avoid over-smoothing, often associated with implicit surface-based techniques.
Other methods have also aimed to compute a surface by deforming a simple template while updating its connectiv-ity [45, 40], ﬁtting parameterized [26, 46] or mesh-aware patches [3], performing local (e.g., convex) shape decom-position. Majority of these schemes are restricted to partic-ular shape topology or category and again do not necessarily guarantee point set preservation. 2.