Abstract
The classical matching pipeline used for visual localiza-tion typically involves three steps: (i) local feature detec-tion and description, (ii) feature matching, and (iii) outlier rejection. Recently emerged correspondence networks pro-pose to perform those steps inside a single network but suf-fer from low matching resolution due to the memory bottle-neck. In this work, we propose a new perspective to esti-mate correspondences in a detect-to-reﬁne manner, where we ﬁrst predict patch-level match proposals and then re-ﬁne them. We present Patch2Pix, a novel reﬁnement net-work that reﬁnes match proposals by regressing pixel-level matches from the local regions deﬁned by those propos-als and jointly rejecting outlier matches with conﬁdence scores. Patch2Pix is weakly supervised to learn correspon-dences that are consistent with the epipolar geometry of an input image pair. We show that our reﬁnement net-work signiﬁcantly improves the performance of correspon-dence networks on image matching, homography estima-tion, and localization tasks. In addition, we show that our learned reﬁnement generalizes to fully-supervised methods without re-training, which leads us to state-of-the-art lo-calization performance. The code is available at https:
//github.com/GrumpyZhou/patch2pix. 1.

Introduction
Finding image correspondences is a fundamental step in several computer vision tasks such as Structure-from-Motion (SfM) [36, 41] and Simultaneous Localization and
Mapping (SLAM) [8, 24]. Given a pair of images, pixel-level correspondences are commonly established through a local feature matching pipeline, which involves the follow-ing three steps: i) detecting and describing local features, ii) matching the nearest neighbors using the feature descrip-tors, and iii) rejecting outlier matches.
Traditional hand-crafted local features such as SIFT [15]
∗This research was funded by the Humboldt Foundation through the
Sofja Kovalevskaya Award, the EU Horizon 2020 project RICAIP (grant agreeement No. 857306), and the European Regional Development Fund under project IMPACT (No. CZ.02.1.01/0.0/0.0/15 003/0000468).
Figure 1. An example of Patch2Pix correspondences. In the top
ﬁgure, the matches reﬁned by Patch2Pix are coloured according to the predicted conﬁdence scores. The less conﬁdent matches (in blue) appear mostly on the road or the blank wall. In the bottom
ﬁgure, we show that the inlier matches can well handle the large viewpoint change. We show more quantitative results for handling various challenging conditions in the supp. mat (c.f . Sec. D). or SURF [2] are vulnerable to extreme illumination changes, motion blur and repetitive and weakly textured scenes. Therefore, recent works [5–7, 16, 17, 28, 40] pro-pose to learn to detect and describe local features using neu-ral networks, showing that learned features can be robustly matched under challenging conditions [6, 17, 28, 40].
In-stead of focusing on improving local features, [3,22,38,42] suggest to learn a ﬁltering function from sets of correspon-dences to reject outlier matches. A recent method [33] fur-ther proposes to jointly learn the matching function and out-lier rejection via graph neural networks and the Sinkhorn algorithm [4, 37]. Combining a learned feature [5] and learned matcher [33] has set the state-of-the-art results on several geometry tasks, showing a promising direction to-wards a full learnable matching pipeline.
Learning the whole matching pipeline has already been investigated in several works [13, 30, 31], where a single network directly outputs correspondences from an input image pair. The main challenge faced with those corre-spondence networks is how to efﬁciently perform matching while reaching pixel-level accuracy. In order to keep com-putation speed and memory footprint manageable, [29] has 4669
to match at a rather low resolution, which is shown to be less accurate in relative pose estimation [43]. While sparse convolutions have been applied in [30] to match at higher resolution, they still do not achieve pixel-level matching.
One advantage of the correspondences networks [30, 31] is that they are weakly supervised to maximize the average matching score for a matching pair and minimize it for a non-matching pair, however, they learn less effectively in pixel-level matching. This is in contrast to methods that require full supervision from ground truth (GT) correspon-dences [5, 6, 10, 17, 28, 33]. While the GT correspondences provide very precise signals for training, they might also add bias to the learning process. For example, using the sparse keypoints generated by an SfM pipeline with a spe-ciﬁc detector as supervision, a keypoint detector might sim-ply learn to replicate these detections rather than learning more general features [26]. To avoid such type of bias in the supervision, a recent work [40] proposes to use relative camera poses as weak supervision to learn local feature de-scriptors. Compared to the mean matching score loss used in [30, 31], they are more precise by containing the geomet-rical relations between the images pairs.
In this paper, we propose Patch2Pix, a new view for the design of correspondence networks.
Inspired by the suc-cessful detect-to-reﬁne practice in the object detection com-munity [27], our network ﬁrst obtains patch-level match proposals and then reﬁnes them to pixel-level matches. See an example of our matches in Fig. 1. Our novel reﬁne-ment network is weakly supervised by epipolar geometry computed from relative camera poses, which are used to regress geometrically consistent pixel-wise matches within the patch proposal. Compared to [40], we optimize di-rectly on match locations to learn matching, while they op-timize through matching scores to learn feature descriptors.
Our method is extensively evaluated on a set of geometry tasks, showing state-of-the-art results. We summarize our contributions as: i) We present a novel view for ﬁnding correspondences, where we ﬁrst obtain patch-level match ii) proposals and then reﬁne them to pixel-level matches.
We develop a novel match reﬁnement network that jointly reﬁnes the matches via regression and rejects outlier pro-posals. It is trained without the need for pixel-wise GT cor-respondences. iii) We show that our model consistently im-proves match accuracy of correspondence networks for im-age matching, homography estimation and visual localiza-tion. iv) Our model generalizes to fully supervised methods without the need for retraining, and achieves state-of-the-art results on indoor and outdoor long-term localization. 2.