Abstract
Localizing persons and recognizing their actions from videos is a challenging task towards high-level video under-standing. Recent advances have been achieved by modeling direct pairwise relations between entities. In this paper, we take one step further, not only model direct relations between pairs but also take into account indirect higher-order rela-tions established upon multiple elements. We propose to explicitly model the Actor-Context-Actor Relation, which is the relation between two actors based on their interac-tions with the context. To this end, we design an Actor-Context-Actor Relation Network (ACAR-Net) which builds upon a novel High-order Relation Reasoning Operator and an Actor-Context Feature Bank to enable indirect relation reasoning for spatio-temporal action localization. Experi-ments on AVA and UCF101-24 datasets show the advantages of modeling actor-context-actor relations, and visualization of attention maps further veriﬁes that our model is capable of
ﬁnding relevant higher-order relations to support action de-tection. Notably, our method ranks ﬁrst in the AVA-Kinetics action localization task of ActivityNet Challenge 2020, out-performing other entries by a signiﬁcant margin (+6.71 mAP). The code is available online.1 1.

Introduction
Spatio-temporal action localization, which requires lo-calizing persons and recognizing their actions from videos, is an important task that has drawn increasing attention in recent years [15, 12, 8, 46, 35, 58, 52, 54, 41, 29, 55, 17, 20].
Unlike object detection which can be accomplished solely by observing visual appearances, activity recognition usually demands for reasoning about the actors’ interactions with the surrounding context, including environments, other people and objects. Take Fig. 1 as an example. To recognize the action “ride” of the person in the red bounding box, we need
∗Equal contribution 1https://github.com/Siyu-C/ACAR-Net
Figure 1. We contrast our Actor-Context-Actor relation modeling with existing relation reasoning approaches for action localization.
Reasoning relations between pairs of entities may not always be sufﬁcient for correctly predicting the action labels of all individuals.
Our method not only reasons relations between actors, but also models connections between different actor-context relations. As an illustration, the relation between the blue actor and the steering wheel (drive) serves as a crucial clue for recognizing the action being performed by the red actor (ride). to observe that he is inside a car, and there is a driver next to him. Therefore, most recent progress in spatio-temporal action detection has been driven by the success of relation modeling. These approaches focus on modeling relation-ships in terms of pairwise interactions between entities.
However, it is not always the case that relations between elements can be formulated in terms of pairs; often, higher-order relations provide crucial clues for accurate action de-tection. In Fig. 1, it is difﬁcult to infer the action of the red actor given only its relation with the blue actor, or only with the scene context (steering wheel). Instead, in order to identify that the red actor performs the action “ride”, one has to reason over the interaction between the blue actor and the context (drive). In other words, it is necessary to capture the 464
implicit second-order relation between the two actors based on their respective ﬁrst-order relations with the context.
There were previous works that employ Graph Neural
Networks (GNNs) to implicitly model higher-order inter-actions between actors and contextual objects [45, 58, 38, 57, 10]. However, in these approaches, an extra pre-trained object detector is required, and only located objects are used as context. Since bounding-box annotations of objects in spatio-temporal action localization datasets are generally not provided, the pre-trained object detector is limited to its original object categories and may easily miss various objects in the scenes. In addition, the higher-order relations in these methods are limited to be inferred solely from con-textual objects, which might miss important environmental or background cues for action classiﬁcation.
To tackle the above issues, we propose an Actor-Context-Actor Relation Network (ACAR-Net) which focuses on mod-eling second-order relations in the form of Actor-Context-Actor relation. It deduces indirect relations between multiple actors and the context for action localization. The ACAR-Net takes both actor and context features as inputs. We deﬁne actor features as the features pooled from the actor regions of interest, while for context features, we directly use spatio-temporal grid feature maps from our backbone network. The context that we adopt does not rely on any extra object detector with predeﬁned categories, thus making our overall design much simpler and ﬂexible. Moreover, grid feature maps are capable of representing scene elements of various levels (e.g. instance level and part level) and types (e.g. background, objects and object parts), which is use-ful for ﬁne-grained action discrimination. The proposed
ACAR-Net ﬁrst encodes ﬁrst-order actor-context relations, and then applies a High-Order Relation Reasoning Operator to model interactions between the ﬁrst-order relations. The
High-Order Relation Reasoning Operator is fully convolu-tional and operates on ﬁrst order relational features maps without losing spatial layouts . For supporting actor-context-actor relation reasoning between actors and context at differ-ent time periods, we build an Actor-Context Feature Bank, which contains actor-context relations from different time steps across the whole video.
We conduct extensive experiments on the challenging
Atomic Visual Actions (AVA) dataset [15, 22] as well as the UCF101-24 dataset [34] for spatio-temporal action lo-calization. Our proposed ACAR-Net leads to signiﬁcant im-provements on recognizing human-object and human-human interactions. Qualitative visualization shows that our method learns to attend contextual regions that are relevant to the action of interest.
Our contributions are summarized as the three-fold:
•
We propose to model actor-context-actor relations for spatio-temporal action localization. Such relations are mostly ignored by previous methods but crucial for achieving accurate action localization.
•
•
We propose a novel Actor-Context-Actor Relation Net-work for improving spatio-temporal action localization by explicitly reasoning about higher-order relations be-tween actors and the context.
We achieve state-of-the-art performances with signiﬁ-cant margins on the AVA and UCF101-24 datasets. At the time of submission, our method ranks ﬁrst on the
ActivityNet leaderboard [7]. 2.