Abstract
In this paper, we focus on category-level 6D pose and size estimation from a monocular RGB-D image. Previ-ous methods suffer from inefﬁcient category-level pose fea-ture extraction, which leads to low accuracy and inference speed. To tackle this problem, we propose a fast shape-based network (FS-Net) with efﬁcient category-level fea-ture extraction for 6D pose estimation. First, we design an orientation aware autoencoder with 3D graph convolution for latent feature extraction. Thanks to the shift and scale-invariance properties of 3D graph convolution, the learned latent feature is insensitive to point shift and object size.
Then, to efﬁciently decode category-level rotation informa-tion from the latent feature, we propose a novel decoupled rotation mechanism that employs two decoders to comple-mentarily access the rotation information. For translation and size, we estimate them by two residuals: the difference between the mean of object points and ground truth trans-lation, and the difference between the mean size of the cate-gory and ground truth size, respectively. Finally, to increase the generalization ability of the FS-Net, we propose an on-line box-cage based 3D deformation mechanism to augment the training data. Extensive experiments on two benchmark datasets show that the proposed method achieves state-of-the-art performance in both category- and instance-level 6D object pose estimation. Especially in category-level pose estimation, without extra synthetic data, our method outperforms existing methods by 6.3% on the NOCS-REAL dataset 1. 1.

Introduction
Estimating 6D object pose plays an essential role in many computer vision tasks such as augmented reality 1The code is at https://github.com/DC1991/FS-Net
Residual-based
Translation
& size
+ h t p e
D
B
G
R
CNN n o i t a m r o f e d
D 3
& n o i t a t n e m g e s
D 3 r e d o c n e o t u
A 3D	 mask t n e t a
L e r u t a e f
Rot aixs1
Rot aixs2
RGB-based
Shape-based
Figure 1. FS-Net comprises different networks for different tasks.
The RGB-based network is used for 2D object detection, and the shape-based network is used for 3D segmentation and rotation es-timation. The residual-based network is used for translation and size estimation with segmented points.
[19, 20], virtual reality [2], and smart robotic arm [46, 35].
For instance-level 6D pose estimation, in which training set and test set contain the same objects, huge progress has been made in recent years [41, 28, 21, 15, 10]. However, category-level 6D pose estimation remains challenging as the object shape and color are various in the same category.
Existing methods addressed this problem by mapping the different objects in the same category into a uniform model via RGB feature or RGB-D fusion feature. For example,
Wang et al. [40] trained a modiﬁed Mask R-CNN [9] to pre-dict the normalized object coordinate space (NOCS) map of different objects based on RGB feature, and then computed the pose with observed depth and NOCS map by Umeyama algorithm [36]. Chen et al. [4] proposed to learn a canonical shape space (CASS) to tackle intra-class shape variations with RGB-D fusion feature [39]. Tian et al. [34] trained a network to predict the NOCS map of different objects, with the uniform shape prior learned from a shape collection, and
RGB-D fusion feature [39].
Although these methods achieved state-of-the-art perfor-mance, there are still two remaining issues. Firstly, the 1581 	 	
beneﬁts of using RGB feature or RGB-D fusion feature for category-level pose estimation are still questionable. Vlach et al. [37] showed that people focus more on shape than color when categorizing objects, as different objects in the same category have very different colors but stable shapes (shown in Figure 3). Thereby the use of RGB feature for category-level pose estimation may lead to low performance due to huge color variation in the test scene. For this issue, to alleviate the color variation, we merely use the RGB fea-ture for 2D detection while using the shape feature learned with point cloud extracted from depth image for category-level pose estimation.
Secondly, learning a representative uniform shape re-quires a large amount of training data. Therefore, the per-formance of these methods is not guaranteed with limited training examples. To overcome this issue, we propose a 3D graph convolution (3DGC) autoencoder [18] to effectively learn the category-level pose feature via observed points re-construction of different objects instead of uniform shape mapping. We further propose an online box-cage based 3D data augmentation mechanism to reduce the dependencies of labeled data.
In this paper, the newly proposed FS-Net consists of three parts: 2D detection, 3D segmentation & rotation es-timation, and translation & size estimation. In 2D detection part, we use the YOLOv3 [30] to detect the object bound-ing box for coarse object points obtainment [6]. As to the 3D segmentation & rotation estimation part, we design a 3DGC autoencoder to perform segmentation and observed points reconstruction jointly. The autoencoder encodes ori-entation information in the latent feature. Then we propose the decoupled rotation mechanism that uses two decoders to decode the category-level rotation information. For transla-tion and size estimation, since they are all point coordinates related, we design a coordinate residual estimation network based on PointNet [26] to estimate the translation residual and size residuals. To further increase the generalization ability of FS-Net, we use the proposed online 3D deforma-tion for data augmentation. To summarize, the main contri-butions of this paper are as follows:
• We propose a fast shape-based network to estimate category-level 6D object size and pose. Due to the efﬁ-cient category-level pose feature extraction, the frame-work runs at 20 FPS on a GTX 1080 Ti GPU.
• We propose a 3DGC autoencoder to reconstruct the observed points for latent orientation feature learning.
Then we design a decoupled rotation mechanism to fully decode the orientation information. This decou-pled mechanism allows us to naturally handle the cir-cle symmetry object (in Section 3.3).
• Based-on the shape similarity, we propose a novel box-cage based 3D deformation mechanism to augment the training data. With this mechanism, the pose accuracy of FS-Net is improved by 7.7%. 2.