Abstract
Batch Normalization (BN) and its variants have deliv-ered tremendous success in combating the covariate shift in-duced by the training step of deep learning methods. While these techniques normalize the feature distribution by stan-dardizing with batch statistics, they do not correct the in-ﬂuence on features from extraneous variables or multiple distributions. Such extra variables, referred to as meta-data here, may create bias or confounding effects (e.g., race when classifying gender from face images). We in-troduce the Metadata Normalization (MDN) layer, a new batch-level operation which can be used end-to-end within the training framework, to correct the inﬂuence of meta-data on the feature distribution. MDN adopts a regres-sion analysis technique traditionally used for preprocessing to remove (regress out) the metadata effects on model fea-tures during training. We utilize a metric based on distance correlation to quantify the distribution bias from the meta-data and demonstrate that our method successfully removes metadata effects on four diverse settings: one synthetic, one 2D image, one video, and one 3D medical image dataset. 1.

Introduction
Recent advances in ﬁelds such as computer vision, nat-ural language processing, and medical imaging have been propelled by tremendous progress in deep learning [7].
These deep neural models owe their success to their large number of trainable parameters, which encode rich infor-mation from the data. However, since the learning pro-cess can be extremely unstable, much of the work is spent on carefully selecting a model through hyperparameter tun-ing, an integral part of approaches such as [31, 39]. To aid with model development, normalization techniques such as
Batch Normalization (BN) [31] and Group Normalization (GN) [61] make the training process more robust and less sensitive to covariate or distribution shift.
BN and GN perform feature normalization by standard-izing them solely using batch or group statistics (i.e., mean and standard deviation). Although they have pushed the
Figure 1. The proposed Metadata Normalization operation. MDN layer takes the learned features from the previous layer (f ), ana-lyzes the effects of the metadata on them, residualizes such effects, and outputs the distribution corrected features (r). state-of-the-art forward, they do not handle extraneous de-pendencies in the data other than the input and output la-bel variables. In many applications, confounders [57, 69] or protected variables [46] (sometimes referred to as bias variables [2]) may inject bias into the learning process and skew the distribution of the learned features. For instance, (i) when training a gender classiﬁcation model from face images, an individual’s race (quantiﬁed by skin shade) has a crucial inﬂuence on prediction performance as shown in
[11]; (ii) in video understanding, action recognition models are often driven by the scene [15, 30] instead of learning the harder movement-related action cues; (iii) for medical studies, patient demographic information or data acquisi-tion site location (due to device and scanner differences) are variables that easily confound studies and present a trou-blesome challenge for the generalization of these studies to other datasets or everyday clinical usages [10, 68].
This additional information about training samples is of-ten freely available in datasets (e.g., in medical datasets as patient data) or can be extracted using off-the-shelf mod-els (such as in [11, 15]). We refer to them as metadata, namely “data that provides information about other data”
[59], an umbrella term for additional variables that provide information about training data but are not directly used as model input. The extraneous dependencies between the training data and metadata directly affect the distributions of the learned features; however, typical normalization op-10917
erations such as BN and GN operate agnostic to this extra information. Instead, current strategies to remove metadata effects include invariant feature learning [4, 42, 62] or do-main adaptation [26, 55].
Traditional handcrafted and feature-based statistical methods often use intuitive approaches based on multivari-ate modeling to remove the effects of such metadata (re-ferred to as study confounders in this setting). One such regression analysis method [41] builds a Generalized Lin-ear Model (GLM) between the features and the metadata (see Fig. 1) to measure how much the feature variances are explained by the metadata versus the actual output (i.e., ground-truth label) [1, 68]. The effects of the metadata can then be removed from the features by a technique referred to as “regressing out” the effects of the extraneous variables
[1, 10, 45]. The application of this GLM-based method to deep end-to-end architectures has not yet been explored be-cause it requires precomputed features to build the GLM and is traditionally performed on the dataset prior to train-ing. Thus, this method is inapplicable to vision problems with pixel-level input and local spatial dependencies, which a GLM is unable to model. The key insight we use is that the later layers of a network represent high-level features with which we can build our GLM. In this paper, we extend this widely-explored and seminal regression analysis method by proposing a corresponding operation for deep learning ar-chitectures within a network to remove the metadata effects from the intermediate features of a network.
As illustrated in Fig. 1, we deﬁne a Metadata Normaliza-tion (MDN) layer which applies the aforementioned regres-sion analysis as a normalization technique to remove the metadata effects from the features in a network1. Our MDN operation projects each learned feature f of the Lth layer to the subspace spanned by the metadata variables, denoted by X, by creating a GLM [41, 43] f = Xβ + r, where
β is a learnable set of linear parameters, Xβ corresponds to the component in f explained by the metadata, and r is the residual component irrelevant to the metadata. The
MDN layer removes the metadata-related components from the feature (Fig. 1) and regards the residual r as the nor-malized feature impartial to metadata. We implement this operation in a (mini)batch iterative training setting.
As opposed to BN and its variants that aim at normal-izing the distribution of the features throughout the train-ing process, MDN focuses on correcting the distribution with respect to the chosen metadata variables. When em-ployed in end-to-end settings, this enables deep learning ar-chitectures to remove the effects of confounders, protected variables, or biases during the training process. Moreover, the metadata will only correct the distributions if there are 1Although metadata normalization was previously used to refer to the adjustment of metadata elements into standard formats [36], we redeﬁne the term as an operation in deep learning architectures. such distributions explained by the metadata. On the other hand, if the learned features are orthogonal to the metadata subspace (i.e., features are not biased by the metadata vari-ables), the β coefﬁcients will be close to zero and hence will not alter the learning paradigm of the network.
In summary, our work makes the following primary con-tributions: (1) We propose the Metadata Normalization technique to correct the distribution of the data with respect to the additional, metadata, information; (2) We present a theoretical basis for removal of extraneous variable ef-fects based on GLM and introduce a novel strategy to im-plement this operator in (mini)batch-level settings; (3) For the cases when output prediction variables are intrinsically correlated with the metadata, we outline a simple exten-sion to MDN to ensure that only extraneous effects of the metadata are removed and not those that pertain to the ac-tual output variables. Our implementation as a simple Py-Torch layer module is available at https://github.com/ mlu355/MetadataNorm. We show the effectiveness of
MDN in four different experimental settings, including one synthetic, one image dataset for gender classiﬁcation from face images, one video scene-invariant action recognition, and one multi-site medical image classiﬁcation scenario. 2.