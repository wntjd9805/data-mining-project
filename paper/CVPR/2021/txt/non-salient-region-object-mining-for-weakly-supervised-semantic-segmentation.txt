Abstract
Semantic segmentation aims to classify every pixel of an input image. Considering the difﬁculty of acquiring dense labels, researchers have recently been resorting to weak labels to alleviate the annotation burden of segmentation.
However, existing works mainly concentrate on expanding the seed of pseudo labels within the image’s salient region.
In this work, we propose a non-salient region object mining approach for weakly supervised semantic segmentation. We introduce a graph-based global reasoning unit to strengthen the classiﬁcation network’s ability to capture global rela-tions among disjoint and distant regions. This helps the network activate the object features outside the salient area.
To further mine the non-salient region objects, we propose to exert the segmentation network’s self-correction ability.
Speciﬁcally, a potential object mining module is proposed to reduce the false-negative rate in pseudo labels. More-over, we propose a non-salient region masking module for complex images to generate masked pseudo labels. Our non-salient region masking module helps further discover the objects in the non-salient region. Extensive experi-ments on the PASCAL VOC dataset demonstrate state-of-the-art results compared to current methods. The source codes are available at https://github.com/NUST-Machine-Intelligence-Laboratory/nsrom. 1.

Introduction
Semantic segmentation is the task of classifying every pixel of an input image. It plays a vital role in many com-puter vision tasks, such as image editing and medical im-age analysis [32, 47]. Beneﬁting from the recent advances of deep learning, semantic segmentation has achieved re-markable progress. However, the training of deep convolu-∗Equal contribution.
†Corresponding author. (a) Image (b) Saliency Map (c) Traditional Methods (d) Ours (b) The saliency map.
Figure 1. Comparison between the traditional methods and ours. (a) Input image. (c) Results of the tra-ditional methods. They mainly focus on expanding the seed of pseudo labels within the salient region of the image. They only obtain good segmentation results in conspicuous regions. (d) Our results. Our method also mines the object in the non-salient region and can get better results both in and outside the salient region.
Best viewed in color. tional neural networks (CNNs) usually requires large-scale datasets [56, 55, 59, 57, 58]. Moreover, obtaining precise pixel-wise annotations for semantic segmentation demands intensive labor efforts and is quite time-consuming. One promising approach to address the annotation problem for semantic segmentation is to learn from weak labels, such as image-level annotations [29, 51, 21, 8, 23, 2, 52, 24], bound-ing boxes [14, 26, 43], points [4], and scribbles [33, 46].
Among these weak supervisions, image-level labels are the easiest format to annotate and have been widely studied in various weakly supervised methods. However, seman-tic segmentation supervised with image-level labels remains a challenging task. Therefore, this paper follows the cur-rent trend and focuses on leveraging image-level labels to achieve weakly supervised semantic segmentation (WSSS).
To tackle the task of WSSS with only image-level la-bels, visualization-based approaches [63] have been widely 2623
adopted to narrow the annotation gap between classiﬁca-tion and segmentation [53, 54]. The typical methods train a classiﬁcation network with image-level labels. Then they leverage class activation maps (CAMs) [63] to generate pseudo labels to train the segmentation network. However, these activation maps obtained from the classiﬁcation net-work are sparse and incomplete. They can only locate the most discriminative part of objects. Many approaches have been proposed to enlarge the activated region to cover a large object area. For example, Jiang et al. [24] observed that the attention maps produced by the classiﬁcation net-work focus on different object parts during training. There-fore, they proposed an online attention accumulation (OAA) strategy to combine the various activated regions. However, as shown in Fig. 1, the existing works mainly concentrate on enlarging the response maps for the salient region. Then they utilize the saliency maps to extract background. Few works focus on mining objects in the non-salient areas.
In this paper, we propose a non-salient region object mining method for weakly supervised semantic segmenta-tion to make up for the shortcomings mentioned above. In contrast to the widely adopted center prior [5] for saliency detection, the non-salient region is usually scattered in cor-ners or near the edge of the image. Such a characteristic of our protagonist requires the network to exploit the dis-joint and distant surrounding information. While the tradi-tional classiﬁcation networks based on CNNs excel at mod-eling local relations, they are inefﬁcient at capturing global relations between disjoint and distant regions. Therefore, we introduce a graph-based global reasoning unit [13] to strengthen the classiﬁcation network’s capability in activat-ing the object features outside the salient region.
On the other hand, though existing approaches can suc-they in-cessfully enlarge activated regions for objects, evitably extend the object area to the background. These methods require the saliency maps to provide background clues. While the saliency maps can correct the pixel labels near conspicuous regions, they also remove the object labels outside the salient area. We notice that although the naive
CAM, sparse and incomplete, does not have an accurate boundary, it can provide useful clues for the objects in the non-salient region. Therefore, we propose a potential ob-ject mining module to discover more objects that are outside the conspicuous region but activated in the naive CAM. Our potential object mining module aims to reduce the pseudo labels’ false-negative rate (in which case the object regions are falsely labeled as background). This improves the qual-ity of pseudo labels and encourages the segmentation net-work to exert its self-correction ability. Such an ability of the network inspires us to further take advantage of the pre-diction of the segmentation network. Following [51], we divide the training images into simple and complex sets ac-cording to the number of categories in each image. The sim-ple images with a single category of object(s) usually have a clean background. Their objects often exist in the conspic-uous region and can be correctly segmented. In contrast, complex images (having two or more categories of objects) are more prone to having objects outside the salient area.
Therefore, we propose a non-salient region masking mod-ule for complex images to generate masked pseudo labels.
Our non-salient region masking module helps further dis-cover objects in the non-salient region. Our contributions can be summarized as follows:
• For weakly supervised semantic segmentation, we leverage a global reasoning unit to capture global re-lations among disjoint and distant regions, helping the network activate object features outside salient areas.
• We propose a potential object mining module to dis-cover more objects in the non-salient region, which improves the quality of pseudo labels by reducing the false-negative rate.
• We propose a non-salient region masking module with a dilation policy to generate masked pseudo labels, which leads to a more robust segmentation model to further discover objects outside the salient region. 2.