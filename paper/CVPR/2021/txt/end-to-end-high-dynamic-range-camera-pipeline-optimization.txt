Abstract
The real world is a 280 dB High Dynamic Range (HDR) world which imaging sensors cannot record in a single shot.
HDR cameras acquire multiple measurements with differ-ent exposures, gains and photodiodes, from which an Im-age Signal Processor (ISP) reconstructs an HDR image.
Dynamic scene HDR image recovery is an open challenge because of motion and because stitched captures have dif-ferent noise characteristics, resulting in artifacts that ISPs must resolve in real time at double-digit megapixel resolu-tions. Traditionally, ISP settings used by downstream vision modules are chosen by domain experts; such frozen camera designs are then used for training data acquisition and su-pervised learning of downstream vision modules. We depart from this paradigm and formulate HDR ISP hyperparame-ter search as an end-to-end optimization problem, propos-ing a mixed 0th and 1st-order block coordinate descent op-timizer that jointly learns sensor, ISP and detector network weights using RAW image data augmented with emulated
SNR transition region artifacts. We assess the proposed method for human vision and image understanding. For automotive object detection, the method improves mAP and mAR by 33% over expert-tuning and 22% over state-of-the-art optimization methods, outperforming expert-tuned HDR imaging and vision pipelines in all HDR laboratory rig and
ﬁeld experiments. 1.

Introduction
Real-world scenes have dynamic ranges that often ex-ceed 1,000,000 :1 (120 dB) [50] and, in extreme cases like tunnel exit in direct sunlight, reach over 200 dB.
This dynamic range must be captured by vision algorithms for safety-critical decision making in robotics and naviga-tion. Existing sensors cannot capture High Dynamic Range (HDR) in a single shot [9, 12, 38]. As a result, modern cameras rely on sequentially and spatially-multiplexed ac-quisition techniques, combining data acquired with differ-ent exposure times, gains and photodiodes.
Image Signal Processors (ISPs) are low-level pipelines implemented in hardware that convert RAW sensor pixel data into images suitable for human viewing or scene un-derstanding tasks such as object detection and classiﬁcation.
ISPs thus form an essential interface and abstraction layer between the sensor and the display or computer vision mod-ule. ISP processing blocks are conﬁgured with tens to hun-dreds of adjustable hyperparameters which deﬁne its static and dynamic behavior [44, 46, 49, 58], for example adap-tation to noise level. Choosing optimal ISP hyperparameter values is challenging as they depend on the context in which the camera is used (portraits and landscapes vs. all-weather autonomous driving), on the speciﬁcs of the lens and sen-sor (before the ISP), and on the downstream task (display to human viewers vs. object detection).
Traditionally, imaging experts have manually selected
ISP hyperparameter values using charts and visual in-spection [44, 58]. The potential of automated loss-based hardware ISP hyperparameter optimization in the low-dynamic range (LDR) context, using differentiable approxi-mations [58] or 0th-order (derivative-free) methods [44, 46], was recently established. These methods rely on gain separability and consequently are limited to LDR image processing; HDR optimization requires novel approaches.
End-to-end loss-based optimization has not included sen-sor hyperparameters and work on the optimization of non-differentiable ISPs for CV [44, 58] has kept the downstream
Convolutional Neural Network (CNN) detector ﬁxed.
In this work, we tackle HDR and jointly optimize the sensor,
ISP and CNN.
The search for optimal HDR imaging pipelines is an open problem central to imaging and vision tasks in uncon-trolled in-the-wild scenarios. Real-time applications, e.g., in robotics and autonomous driving, and high sensor resolu-tions, up to triple-digit megapixel counts, mandate efﬁcient hardware implementations [6]. Multiplexing makes HDR processing an open challenge. Motion causes ghosting arti-facts when captures acquired sequentially or with different exposure times are stitched together [14]. Split-pixel sen-sors, with two or more diodes per pixel [60], reduce mo-tion blur discrepancies but are often used with multiple ex-6297
posure times. With few captures (four or less in automo-tive imaging [52]), signal-to-noise ratio (SNR) transition regions show sudden texture changes, resulting in spuri-ous edge detections by the Human Visual System and CNN detectors. Complicating matters, some ISP nodes behave differently in HDR; for example, color artifacts occur near knee points of the companding curve.
Departing from handcrafted ISP hyperparameter tun-ing, we propose a task-speciﬁc, loss-driven, end-to-end ap-proach to the joint optimization of the sensor, ISP and detec-tor for downstream applications such as human viewing and object detection. Optimization for human viewing is per-formed with multiple losses, including Contrast Weighted
Lp-Norm, a novel full reference image difference metric based on Larkin’s universal Noise Visibility Function [32], and a dynamic HDR lab setup covering 123 dB. When opti-mizing for image understanding, instead of acquiring large datasets containing SNR transition region edge cases in se-mantic scene content, we augment data with a proposed
SNR transition region artifact emulation method. The pro-posed block coordinate descent approach combines a 0th-order evolutionary optimizer (with novel centroid weights that stabilize boundary minima) with 1st-order Stochas-tic Gradient Descent optimization, demonstrating the ﬁrst method that jointly optimizes hardware hyperparameters and downstream CNN detector weights. The method is val-idated with state-of-the-art hardware sensors and ISPs in an
HDR lab and in outdoor, in-the-wild human viewing and automotive object detection HDR scenarios.
In summary, we make the following contributions:
•
•
•
We propose the ﬁrst end-to-end hardware-in-the-loop optimization method for the hyperparameters of multi-exposure HDR camera systems, and the ﬁrst method for the joint optimization of sensor and ISP hardware hyper-parameters and CNN weights of a vision module.
We propose a dynamic HDR lab setup, a full reference perceptual image difference metric, and a data augmen-tation methodology targeting HDR stitching artifacts.
With state-of-the-art automotive ISPs and sensors, we validate the proposed method experimentally and in sim-ulation for human viewing and 2D object detection.
Across all tasks considered in this paper, the proposed method outperforms existing methods.
The proposed method has the following limitations. Un-like Mosleh et al. [44], we only consider one image under-standing task, namely object detection and classiﬁcation.
We sparsely sample sensor hyperparameters; a methodol-ogy with a ﬁner grain, involving for example multiple cam-eras or coarse optimization followed by additional ﬁeld data acquisition, is needed. We only optimize single frame im-age processing; RAW video sequences could be fed to an
ISP to process temporal cues. 2.