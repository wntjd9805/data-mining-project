Abstract
Annotating the LiDAR point cloud is crucial for deep learning-based 3D object detection tasks. Due to expen-sive labeling costs, data augmentation has been taken as a necessary module and plays an important role in train-ing the neural network. “Copy” and “paste” (i.e., GT-Aug) is the most commonly used data augmentation strat-egy, however, the occlusion between objects has not been taken into consideration. To handle the above limitation, we propose a rendering-based LiDAR augmentation frame-work (i.e., LiDAR-Aug) to enrich the training data and boost the performance of LiDAR-based 3D object detectors. The proposed LiDAR-Aug is a plug-and-play module that can be easily integrated into different types of 3D object detection frameworks. Compared to the traditional object augmenta-tion methods, LiDAR-Aug is more realistic and effective. Fi-nally, we verify the proposed framework on the public KITTI dataset with different 3D object detectors. The experimen-tal results show the superiority of our method compared to other data augmentation strategies. We plan to make our data and code public to help other researchers reproduce our results. 1.

Introduction
Due to its precise range sensing ability to capture the 3D geometric information of environment, LiDAR sensor has been widely used in many applications, especially in
Autonomous Driving (AD).
Recently, deep learning-based point cloud analysis such as model classiﬁcation [27], scene segmentation [28, 42], object detection [35] has achieved signiﬁcant progress by employing high-capacity neural network. Generally, for training a high-performance neural network, a large amount of annotated training data [14] is a prerequisite, especially in the AD applications where Safety is the ﬁrst priority.
*Corresponding author
Figure 1: Examples of augmented LiDAR data, where (a), (c) are the original LiDAR point cloud and (b), (d) are the augmented
LiDAR point cloud by “LiDAR-Aug”. Speciﬁcally, the “LiDAR-Aug” can be used to expand the rare objects such as trafﬁc cone and cyclist which has been highlighted in the sub-ﬁg (d).
However, creating large datasets with pixel-level labels is extremely difﬁcult which requires extensive labor work.
This problem is even more serious when dealing with the sparse LiDAR data. Due to its sparsity in remote distance, how to identify and annotate the objects with rotated 3D bounding boxes in 3D space becomes particularly difﬁcult.
To reduce the burden of data annotation, generating syn-thetic data using simulators [7, 34, 25] becomes one of the mainstream solutions. However, the simulator itself is still very expensive, time-consuming, and difﬁcult to generalize to different scenarios. Besides, the distinct domain gap be-tween simulated data and real data is another problem. Al-though a variety of approaches [16, 41] have been proposed, domain adaption is still an open problem to be investigated.
Another common strategy to deal with limited anno-tated data is data augmentation. The effectiveness of data augmentation has been veriﬁed in many tasks [11, 38], which has become a typical pre-processing process be-fore training the neural network. For 2D tasks, various data augmentation approaches have been proposed such 4710
as [37, 48]. Besides the simple image operations such as
ﬂipping, cropping, resizing, etc., domain adaptation and generative models [47, 39] are also introduced to synthe-size realistic training images. However, for 3D point cloud, especially LiDAR point cloud, the data augmentation is rarely discussed. Basically, two simple data augmenta-tion strategies have been employed for 3D point cloud re-lated tasks [43, 19, 36, 35, 12]. One is called global aug-mentation which manipulates the whole LiDAR data glob-ally, such as randomly scaling, ﬂipping and rotating around z-axis. The other is called object augmentation such as the “GT-Aug” (ground truth augmentation) [43, 36] which copies the obstacles or dynamic objects from other frames and pastes them into the current frame. Although the “GT-Aug” strategy is simple, it can indeed improve the detection performance. However, the occlusion between different augmented objects and the occlusion between augmented objects and background points have not been considered.
Therefore, it can not be applied to algorithms using spher-ical projection representation like MV3D [3] and Squeeze-Seg [40, 41, 42].
To well address the limitations mentioned above, we pro-pose the ﬁrst rendering-based LiDAR data augmentation framework “LiDAR-Aug”, and apply it to the 3D object detection task.
In the proposed framework, we solve the most important question: where and how to insert obsta-cles into real background frames. Different from the pre-vious method (e.g., “GT-Aug”), we utilize a light-weighted method “ValidMap” to generate the poses for augmented objects while avoiding collision to achieve more reasonable obstacle placements. Finally, we leverage the rendering technique to compose the augmented objects into the real background frames, from which the occlusion constraints are automatically enforced. Therefore, the augmented data generated by our proposed method will be more realistic and diverse. We show sampled data generated from our framework in Fig. 1, from which we can clearly see the data diversity is enormously enriched (Fig. 1 (b)), and the occlu-sion state is naturally handled. Moreover, “LiDAR-Aug” is more than a data augmentation strategy. We can also utilize it to include and expand the rare objects and corner case sce-narios as shown in Fig. 1 (d), which is important to improve the robustness of perception module in AD.
The main contributions of our work can be summarized as below: 1. We present “LiDAR-Aug”, a rendering-based data augmentation framework for LiDAR point cloud data, which is more general and effective as compared with the commonly used approach “GT-Aug”. 2. We evaluate the proposed framework on the public
KITTI dataset, and demonstrate that the “LiDAR-Aug” can signiﬁcantly improve 3D object detection performance on different baselines. 3. We provide in-depth analyses of the factors in
“LiDAR-Aug” processing, including the obstacle placement, augmentation combination, and domain gap. 2.