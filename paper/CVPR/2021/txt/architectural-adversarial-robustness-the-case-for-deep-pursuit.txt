Abstract
Despite their unmatched performance, deep neural net-works remain susceptible to targeted attacks by nearly im-perceptible levels of adversarial noise. While the underly-ing cause of this sensitivity is not well understood, theo-retical analyses can be simpliﬁed by reframing each layer of a feed-forward network as an approximate solution to a sparse coding problem. Iterative solutions using basis pur-suit are theoretically more stable and have improved adver-sarial robustness. However, cascading layer-wise pursuit implementations suffer from error accumulation in deeper networks. In contrast, our new method of deep pursuit ap-proximates the activations of all layers as a single global optimization problem, allowing us to consider deeper, real-world architectures with skip connections such as residual networks. Experimentally, our approach demonstrates im-proved robustness to adversarial noise. 1.

Introduction
Multilayer sparse approximation has been proposed as a robust alternative to feed-forward neural networks [17].
While provably less sensitive to noise, recurrent networks that implement layered basis pursuit accumulate indepen-dent errors and cannot be applied to modern large-scale architectures. We propose a new method of deep pursuit, wherein all activations of the network are synchronously optimized through a global basis pursuit, circumventing er-ror accumulation and accounting for the skip connections commonly found in state-of-the-art network architectures.
We apply this technique to address a major weakness of deep neural networks: despite unrivaled performance on su-pervised tasks, they can be highly sensitive to certain types of data noise. Speciﬁcally, adversarial attacks use imper-ceptible targeted input perturbations to completely change a network’s predictions [8]. Robustness to such attacks is mission-critical to many domains, such as security systems and autonomous vehicles.
Because the generalization properties of deep neural net-works are not yet thoroughly understood, combating such
Figure 1. (a) Recurrent deep networks that implement layered ba-sis pursuit have been shown to be provably more robust to adver-sarial noise than feed-forward alternatives. However, this method is incompatible with modern architectures. (b) We instead pro-pose deep pursuit, which jointly infers all network activations as a single structured sparse coding problem. adversarial attacks remains an open problem. Current state-of-the-art methods rely on specialized loss functions or training techniques. However, these methods do not ex-plain why some models are more susceptible to attacks than others or how to create naturally robust architectures.
In this work, we apply techniques from sparse approximation theory to design deep neural networks that are intrinsically more robust to adversarial noise.
Previous works have suggested reframing each layer of a neural network as a sparse coding problem to make their outputs more robust [17] (Figure 1a). However, as noted by the authors, this method accumulates error throughout the layers of the network, potentially leading to poor perfor-mance in deeper models. Additionally, this method offers no provisions for handling skip connections between lay-ers, preventing its use for real-world network architectures.
In order to exploit the natural robustness offered by deeper networks [19] and skip connections [9], we pro-pose adapting the layer-wise pursuit algorithm introduced in [17] to the global view that reframes a neural network as an approximate solution to a single sparse coding prob-lem with block-structured parameters (Figure 1 B) [14]. We 7150
optimize the outputs of all layers synchronously [4], which effectively amounts to adding recurrent feedback connec-tions on top of a feed-forward network. By relating the en-tire network to a single structured sparse coding problem, our method does not suffer from error accumulation as the network grows deeper. Furthermore, we can even entertain residual and dense skip connections within our optimiza-tion, something not possible using layered basis pursuit. We call this method “deep pursuit.”
Our contributions are: 1. Through connections to sparse approximation theory, we illustrate how the structure of a global sparse ap-proximation problem predicts why certain architec-tures are naturally more robust. 2. Extending the method of layered basis pursuit to our global view, we propose a technique for synchronously inferring all latent activations via block coordinate de-scent. 3. We show how deep pursuit outperforms layered basis pursuit by avoiding error accumulation and allowing for skip connections between layers. Experimentally, we demonstrate improved robustness to adversarial at-tacks on the CIFAR-10 dataset. 2.