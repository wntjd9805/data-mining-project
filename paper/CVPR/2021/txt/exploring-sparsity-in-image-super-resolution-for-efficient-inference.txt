Abstract
Current CNN-based super-resolution (SR) methods pro-cess all locations equally with computational resources be-ing uniformly assigned in space. However, since missing details in low-resolution (LR) images mainly exist in re-gions of edges and textures, less computational resources are required for those ﬂat regions. Therefore, existing CNN-based methods involve redundant computation in ﬂat re-gions, which increases their computational cost and lim-its their applications on mobile devices. In this paper, we explore the sparsity in image SR to improve inference efﬁ-ciency of SR networks. Speciﬁcally, we develop a Sparse
Mask SR (SMSR) network to learn sparse masks to prune redundant computation. Within our SMSR, spatial masks learn to identify “important” regions while channel masks learn to mark redundant channels in those “unimportant” regions. Consequently, redundant computation can be ac-curately localized and skipped while maintaining compa-rable performance.
It is demonstrated that our SMSR achieves state-of-the-art performance with 41%/33%/27%
FLOPs being reduced for ×2/3/4 SR. Code is available at: https://github.com/LongguangWang/SMSR. 1.

Introduction
The goal of single image super-resolution (SR) is to recover a high-resolution (HR) image from a single low-resolution (LR) observation. Due to the powerful feature representation and model ﬁtting capabilities of deep neu-ral networks, CNN-based SR methods have achieved sig-niﬁcant performance improvements over traditional ones.
Recently, many efforts have been made towards real-world including few-shot SR [38, 39], blind SR applications,
[12, 49, 42], and scale-arbitrary SR [15, 43]. With the pop-ularity of intelligent edge devices (such as smartphones and
VR glasses), performing SR on these devices is highly de-manded. Due to the limited resources of edge devices1, ef-ﬁcient SR is crucial to the applications on these devices. 1For example, the computational performance of Kirin 990 and RTX 2080Ti are 0.9 and 13.4 tFLOPS, respectively.
Figure 1. Trade-off between PSNR performance, number of pa-rameters and FLOPs. Results are achieved on Set5 for ×2 SR.
Since the pioneering work of SRCNN [8], deeper net-works have been extensively studied for image SR. In
VDSR [19], SR network is ﬁrst deepened to 20 layers.
Then, a very deep and wide architecture with over 60 lay-ers is introduced in EDSR [29]. Later, Zhang et al. further increased the network depth to over 100 and 400 in RDN
[51] and RCAN [50], respectively. Although a deep net-work usually improves SR performance, it also leads to high computational cost and limits the applications on mobile de-vices. To address this problem, several efforts have been made to reduce model size through information distillation
[17] and efﬁcient feature reuse [2]. Nevertheless, these net-works still involve redundant computation. Compared to an
HR image, missing details in its LR image mainly exist in regions of edges and textures. Consequently, less computa-tional resources are required in those ﬂat regions. However, these CNN-based SR methods process all locations equally, resulting in redundant computation within ﬂat regions.
In this paper, we explore the sparsity in image SR to im-prove inference efﬁciency of SR networks. We ﬁrst study the intrinsic sparsity of the image SR task and then investi-gate the feature sparsity in existing SR networks. To fully exploit the sparsity for efﬁcient inference, we propose a sparse mask SR (SMSR) network to dynamically skip re-dundant computation at a ﬁne-grained level. Our SMSR learns spatial masks to identify “important” regions (e.g., edge and texture regions) and uses channel masks to mark redundant channels in those “unimportant” regions. These 4917
two kinds of masks work jointly to accurately localize re-dundant computation. During network training, we soften these binary masks using the Gumbel softmax trick to make them differentiable. During inference, we use sparse con-volution to skip redundant computation. It is demonstrated that our SMSR can effectively localize and prune redun-dant computation to achieve better efﬁciency while produc-ing promising results (Fig. 1).
Our main contributions can be summarized as: 1) We develop an SMSR network to dynamically skip redundant computation for efﬁcient image SR. In contrast to existing works that focus on lightweight network designs, we ex-plore a different route by pruning redundant computation to improve inference efﬁciency. 2) We propose to local-ize redundant computation by learning spatial and channel masks. These two kinds of masks work jointly for ﬁne-grained localization of redundant computation. 3) Experi-mental results show that our SMSR achieves state-of-the-art performance with better inference efﬁciency. For example, our SMSR outperforms previous methods on Set14 for ×2
SR with a signiﬁcant speedup on mobile devices (Table 2). 2.