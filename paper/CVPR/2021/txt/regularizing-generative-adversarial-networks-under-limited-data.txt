Abstract geNet benchmark is available. The source code is available at https://github.com/google/lecam-gan.
Recent years have witnessed the rapid progress of gen-erative adversarial networks (GANs). However, the success of the GAN models hinges on a large amount of training data. This work proposes a regularization approach for training robust GAN models on limited data. We theoret-ically show a connection between the regularized loss and an f -divergence called LeCam-divergence, which we ﬁnd is more robust under limited training data. Extensive ex-periments on several benchmark datasets demonstrate that the proposed regularization scheme 1) improves the gener-alization performance and stabilizes the learning dynamics of GAN models under limited training data, and 2) comple-ments the recent data augmentation methods. These proper-ties facilitate training GAN models to achieve state-of-the-art performance when only limited training data of the Ima-*Work done during HY’s internship at Google Research. 1.

Introduction
Generative adversarial networks (GANs) [2, 7, 13, 44] have made signiﬁcant progress in recent years on synthe-sizing high-ﬁdelity images. The GAN models are the cor-nerstone techniques for numerous vision applications, such as data augmentation [11, 12], domain adaptation [18, 19], image extrapolation [60], image-to-image translation [20, 34, 75], and image editing [1, 4, 21, 63].
The success of the GAN methods heavily relies on a large amount of diverse training data which is often labor-expensive or cumbersome to collect [65]. As the example of the BigGAN [7] model presented in Figure 1, the perfor-mance signiﬁcantly deteriorates under the limited training data. Consequently, several very recent approaches [28, 71, 17921
73] have been developed to address the data insufﬁciency issue. A representative task in this emerging research direc-tion aims to learn a robust class-conditional GAN model when only a small proportion of the ImageNet data [54] are available for the training. Generally, existing methods exploit data augmentation, either conventional or differen-tiable augmentation, to increase the diversity of the limited training data. These data augmentation approaches have shown promising results on several standard benchmarks.
In this paper, we address the GAN training task on lim-ited data from a different perspective: model regularization.
Although there are numerous regularization techniques for the GAN models in the literature [14, 45, 47, 57, 74], none of them aim to improve the generalization of the GAN mod-els trained on limited data. In contrast, our goal is to learn robust GAN models on limited training data that can gener-alize well on out-of-sample data. To this end, we introduce a novel regularization scheme to modulate the discrimina-tor’s prediction for learning a robust GAN model. Specif-ically, we impose an ℓ2 norm between the current predic-tion of the real image and a moving average variable that tracks the historical predictions of the generated image, and vice versa. We theoretically show that, under mild assump-tions, the regularization transforms the WGAN [2] formu-lation towards minimizing an f -divergence called LeCam-divergence [33]. We ﬁnd that the LeCam-divergence is more robust under the limited training data setting.
We conduct extensive experiments to demonstrate the three merits of the proposed regularization scheme. First, it improves the generalization performance of various GAN approaches, such as BigGAN [7] and StyleGAN2 [29]. Sec-ond, it stabilizes the training dynamics of the GAN models under the limited training data setting. Finally, our reg-ularization approach is empirically complementary to the data augmentation methods [28, 71]. As presented in Fig-ure 1, we obtain state-of-the-art performance on the limited (e.g., 10%) ImageNet dataset by combining our regulariza-tion (i.e., RLC) and the data augment method [71]. 2.