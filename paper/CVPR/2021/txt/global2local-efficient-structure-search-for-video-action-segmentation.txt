Abstract
Temporal receptive ﬁelds of models play an important role in action segmentation. Large receptive ﬁelds facilitate the long-term relations among video clips while small re-ceptive ﬁelds help capture the local details. Existing meth-ods construct models with hand-designed receptive ﬁelds in layers. Can we effectively search for receptive ﬁeld combi-nations to replace hand-designed patterns? To answer this question, we propose to ﬁnd better receptive ﬁeld combina-tions through a global-to-local search scheme. Our search scheme exploits both global search to ﬁnd the coarse com-binations and local search to get the reﬁned receptive ﬁeld combination patterns further. The global search ﬁnds pos-sible coarse combinations other than human-designed pat-terns. On top of the global search, we propose an expecta-tion guided iterative local search scheme to reﬁne combina-tions effectively. Our global-to-local search can be plugged into existing action segmentation methods to achieve state-of-the-art performance. The source code is publicly avail-able on http://mmcheng.net/g2lsearch. 1.

Introduction
Action recognition segments the action of each video frame, playing an important role in computer vision appli-cations such as clips tagging [59], video surveillance [8, 9], and anomaly detection [54]. While conventional works [4, 17,18,56] have continuously refresh the recognition perfor-mance of short trimmed videos containing a single activity, segmenting each frame densely in long untrimmed videos remains challenging as those videos contain many activ-ities with different temporal lengths. Temporal convolu-tional networks (TCN) [12,16,35,40,65] are widely adapted in action segmentation tasks with their ability to capture both long-term and short-term information. Appropriate re-ceptive ﬁelds in layers are crucial for TCN as large recep-*Equal contribution
†M.M. Cheng (cmm@nankai.edu.cn) is the corresponding author.
...
...
...
...
... ...
... ...
... operators dilations
Figure 1. Search space comparison between searching for network architecture and receptive ﬁeld combinations. Left: Network ar-chitecture search mostly search for several operations with differ-ent functions. Right: The search space of receptive ﬁeld combi-nations is huge. The white, green, blue nodes and orange shade represent the dilation rate candidates, the sparse search space in global search, one of the global searched results, and the local search space. tive ﬁelds contribute to long-term dependencies while small receptive ﬁelds beneﬁt the local details. State-of-the-art (SOTA) methods [5, 29, 39, 40, 65] rely on human-designed receptive ﬁeld combinations, i.e., dilation rate or pooling size in each layer, to make the trade-off between capturing long and short term dependencies. Questions have raised:
Are there other effective receptive ﬁeld combinations that perform comparable or better than hand-designed patterns?
Will the receptive ﬁeld combinations vary among different datasets? To answer those questions, we propose to ﬁnd the possible receptive ﬁeld combinations in a coarse-to-ﬁne scheme through the global-to-local search.
As shown in Fig. 1, unlike the existing network archi-tecture search spaces [3, 27, 43] that only contain several operation options within a layer, the available search space of receptive ﬁeld combinations could be huge. Suppose a TCN has L convolutional layers and D possible recep-tive ﬁelds in each layer. There are DL possible combi-nations, i.e., the number of possible receptive ﬁeld com-binations in MS-TCN [12] is 102440. Directly apply net-work architecture searching algorithms [27, 41, 43, 66] to such a huge search space is impractical. For example, conventional reward-based searching methods [42, 47, 66] are not suitable for CNN-based models with a huge search 16805
space. The model training and performance evaluation of each possible combination are too costly. Differentiable ar-chitecture searching methods (DARTS) [3, 41, 43] rely on shared big networks to save training time, thus only sup-porting several operators within a layer due to the model size constraint. Moreover, they heavily dependent on the initial combination and fail to ﬁnd new combinations with a huge difference from the initial one. While our goal is to explore effective receptive ﬁeld combinations other than human-designed patterns in the huge search space, those al-gorithms are either too costly or cannot support the large search space.
To explore the search space with low cost, we exploit both a genetic-based global search to ﬁnd the coarse recep-tive ﬁeld combinations and an expectation guided iterative (EGI) local search to get the reﬁned combinations. Specif-ically, we follow the MS-TCN [12] to use dilation rates to determine layers’ receptive ﬁelds. A genetic-based global search scheme is proposed to ﬁnd coarse combinations within a sparsely sampled search space at an affordable cost. The global search discovers various combinations that achieve even better performance than human designings but have completely different patterns. Based on the global-searched coarse combinations, we propose the local search to determine ﬁne-grained dilation rates. Our proposed con-volutional weight-sharing scheme enforces learned dilation weights to approximate the probability mass distribution for calculating the expectation of dilation rates. The expecta-tion guided searching transfer the discrete dilation rates into a distribution, allowing ﬁne-grained dilation rates search-ing. With an iteratively searching process, the local search gradually ﬁnds more effective ﬁne-grained receptive ﬁeld combinations with low cost. Our proposed global-to-local search scheme can be plugged into existing models, sur-passing human-designed structures with impressive perfor-mance gain. In summary, we make two major contributions:
• The expectation guided iterative local search scheme enables searching ﬁne-grained receptive ﬁeld combi-nations in the dense search space.
• The global-to-local search discovers effective recep-tive ﬁeld combinations with better performance than hand-designed patterns. 2.