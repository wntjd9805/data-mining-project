Abstract a-posteriori (MAP) estimation problem [17, 21]:
The classical maximum a-posteriori (MAP) framework for non-blind image deblurring requires deﬁning suitable data and regularization terms, whose interplay yields the desired clear image through optimization. The vast majority of prior work focuses on advancing one of these two crucial ingredients, while keeping the other one standard. Con-sidering the indispensable roles and interplay of both data and regularization terms, we propose a simple and effective approach to jointly learn these two terms, embedding deep neural networks within the constraints of the MAP frame-work, trained in an end-to-end manner. The neural net-works not only yield suitable image-adaptive features for both terms, but actually predict per-pixel spatially-variant features instead of the commonly used spatially-uniform ones. The resulting spatially-variant data and regulariza-tion terms particularly improve the restoration of ﬁne-scale structures and detail. Quantitative and qualitative results underline the effectiveness of our approach, substantially outperforming the current state of the art. 1.

Introduction
The goal of single image deblurring is to estimate a de-sirable clear image from a blurry input. Mathematically, the process leading to the image blur is frequently formulated as y = x ∗ k + n, (1) where y, x, k, and n denote blurry observation, latent clear image, blur kernel, and image noise, respectively; ∗ is the convolution operator. Signiﬁcant progress [e.g., 20, 40, 42, 48] has been made in blind image deblurring, which aims to estimate the latent clear image when the blur kernel is unknown. When the blur kernel can be obtained or esti-mated, this problem reduces to non-blind image deblurring, which has been an active area of research since the pioneer-ing work of Richardson and Lucy [29]. Other classical ap-proaches include the Wiener ﬁlter [46].
Non-blind image deblurring is a well-known ill-posed problem. Most existing methods formulate it as a maximum x∗ = arg max x p(y | x, k) p(x), (2) where p(y | x, k) denotes the likelihood that measures how consistent the estimated x is with the observation of y and the known k under the model in Eq. (1); p(x) denotes the prior on the latent clear image x, which is used to regularize the problem. Equation (2) can be equivalently reformulated as x∗ = arg min x
D(y, x, k) + R(x), (3) where D(·) denotes the data term and R(·) denotes the reg-ularization term [32, 33, 44]. Effectively solving non-blind image deblurring within the MAP framework thus requires carefully designing both D(·) and R(·).
To restore high-quality clear images using Eq. (3), nu-merous approaches have been proposed. One family of methods focuses on advancing the data term to better mea-sure the image reconstruction error. Starting from the most commonly used ℓ2 norm [17], data terms have been care-fully designed for speciﬁc types of outliers [1, 6] or even discriminatively learned [11, 28]. A second family of approaches focuses on developing effective regularization terms/image priors to ensure desirable properties of the esti-mated clear image. This includes modeling statistical prop-erties, e.g. by employing Laplacian/hyper-Laplacian pri-ors [17, 21]. Learning effective image priors based on data-driven methods has been a dominant research theme for non-blind image deblurring, e.g., using Gaussian mixture models [52], ﬁelds of experts [31], or deep learning [49, 50].
Therefore, most existing non-blind image deblurring meth-ods focus on improving either the data term or the regular-ization term. However, as the data and regularization terms play different but indispensable roles in non-blind image de-blurring, only improving one of these two terms will limit the power of the MAP framework in Eq. (3) and result in de-blurred images with artifacts, see Fig. 1(b)–(d). In contrast, we jointly learn both the data term and the regularization term to build a more expressive deblurring model in which these two terms can beneﬁt from their interplay, resulting in higher ﬁdelity results as shown in Fig. 1(e). 4886
(a) Blurry input (c) LDT [11]
Figure 1. Visual comparison with state-of-the-art non-blind image deblurring methods. The results in (b)–(d) exhibit severe artifacts or do not effectively restore ﬁne-scale structures. In contrast, our approach can recover a clearer image with ﬁner detail as shown in (e). (e) SVMAP (ours) (d) IRCNN [50] (b) EPLL [52]
We further note that existing data or regularization terms are mostly designed or learned to be spatially invariant.
While this yields a compact model, the local structures dif-fer notably across the image, e.g., in ﬂat vs. textured areas.
Moreover, saturated regions or outliers can occur locally.
Using uniform data and regularization terms for the whole image thus cannot effectively characterize the spatially-variant properties of the image, hindering the restoration of
ﬁner-scale structures and detail (Fig. 1(b)–(d)). To enhance the model expressivity, we propose a spatially-variant MAP model (SVMAP) by predicting a set of pixel-dependent ﬁl-ters to adjust the regularization behavior and the treatment of the data-term residuals to the local requirements.
We make the following contributions: (i) We propose an expressive ﬁlter-based MAP deblurring framework, in which the data and regularization terms are jointly learned based on deep neural networks. A detailed analysis shows that our model is more effective at restoring high-quality images compared to existing ones that focus on improving either the data or the regularization term. (ii) To improve the goodness-of-ﬁt and capture the properties of clear images, we construct spatially-variant data and regularization terms by predicting a set of pixel-dependent ﬁlters.
In contrast to spatially-uniform formulations, our learned pixel-depen-dent ones are able to model the spatially-variant property of the image structures, facilitating ﬁner-scale structure and (iii) We develop an end-to-end learn-detail restoration. ing approach to better capture the spatially-variant proper-ties, integrating the MAP-based optimization framework as a constraint for the deep neural network. (iv) Finally, we both quantitatively and qualitatively demonstrate the effec-tiveness of our method and show that it is able to gener-ate better deblurred results for blurry images with Gaussian noise as well as outliers (e.g., saturated pixels). 2.