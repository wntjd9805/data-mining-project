Abstract
Cross-domain object detection is challenging, because object detection model is often vulnerable to data variance, especially to the considerable domain shift between two distinctive domains. In this paper, we propose a new Un-biased Mean Teacher (UMT) model for cross-domain ob-ject detection. We reveal that there often exists a consider-able model bias for the simple mean teacher (MT) model in cross-domain scenarios, and eliminate the model bias with several simple yet highly effective strategies. In par-ticular, for the teacher model, we propose a cross-domain distillation method for MT to maximally exploit the exper-tise of the teacher model. Moreover, for the student model, we alleviate its bias by augmenting training samples with pixel-level adaptation. Finally, for the teaching process, we employ an out-of-distribution estimation strategy to select samples that most ﬁt the current model to further enhance the cross-domain distillation process. By tackling the model bias issue with these strategies, our UMT model achieves mAPs of 44.1%, 58.1%, 41.7%, and 43.1% on bench-mark datasets Clipart1k, Watercolor2k, Foggy Cityscapes, and Cityscapes, respectively, which outperforms the exist-ing state-of-the-art results in notable margins. Our imple-mentation is available at https://github.com/kinredon/umt. 1.

Introduction
In recent years, deep domain adaptation has gained in-creasing attention in computer vision community, due to that the supreme performances of deep models are normally restricted only in the domain of training data. When those trained models are applied to new environments, signiﬁcant performance drops have often been observed in many com-puter vision tasks [5, 6, 11, 37, 54].
In this work, we are speciﬁcally interested in the cross-domain object detection problem, because the strong de-in au-mands from real-world scenarios. For instance, tonomous driving, robust object detection is needed in dif-*The corresponding author ferent weathers and lighting conditions. Collecting annota-tions for all conditions can be extremely costly, and there-fore models that can adapt to new environments without la-beled data are highly desirable.
Designing such domain adaptive detection models can be challenging. Compared to the image classiﬁcation task, the output of object detection is richer and more complex, consisting of both the class labels and the bounding box lo-cations. The two outputs are intrinsically coupled, mak-ing it more vulnerable towards data variance like scene changes, weather conditions, camera diversity, etc. Vari-ous approaches have been proposed to address these issues, including instance and image-level adversarial training [6], strong and weak adversarial training [37], graph-based con-sistency [1], etc.
In this paper, we propose a new approach called Unbi-ased Mean Teacher (UMT) for cross-domain object detec-tion. We build our approach based on the Mean Teacher (MT) model [46], which is originally proposed for semi-supervised learning. By enforcing the consistency over per-turbed unlabeled samples between the teacher and student models via distillation, it naturally gains improved robust-ness against data variance to some extent, and thus being used as our starting point for cross-domain object detection.
However, solely using MT for cross-domain object de-tection often fails to produce promising results (see Sec-tion 4 for detailed experimental study). We conduct a fur-ther experimental investigation into this issue and observe that there exists an essential model bias issue for MT in cross-domain scenarios. Speciﬁcally, in the presence of a large domain gap, the MT model can be easily biased to-wards the source domain, as the supervision is mainly from the source domain.
To overcome such model bias occurred in the mean teacher model for cross-domain object detection, we de-sign the unbiased mean teacher model with three strategies.
Firstly, observing the biased teacher model often produces more precise predictions for the source images, we design a cross-domain distillation approach by using the source-like target images translated with CycleGAN [55] as the input for teacher model, and original target images as the input for 4091
student model. This signiﬁcantly improves the effectiveness of distillation and reduces the inﬂuence of the model bias.
Then, to further remedy the model bias of student model, we use the target-like source images as additional labeled data for training. Finally, for the teaching process, we also employ an out-of-distribution estimation strategy to iden-tify the target samples that most ﬁt the current MT model to enhance the cross-domain distillation process.
The contributions of this work mainly can be summa-rized in three aspects: 1) A new observation: We reveal the essential model bias issue in the MT model for cross-domain object detection. 2) A new model: We propose a new domain adaptation framework called Unbiased Mean
Teacher (UMT) for object detection, which addresses the model bias with several simple yet effective strategies. 3)
A new benchmark: Our new UMT model achieves state-of-the-art performances on multiple datasets, setting up a new benchmark for cross-domain object detection research.
Our UMT model achieves mAPs of 44.1%, 58.1%, 41.7%, and 43.1% on benchmark datasets Clipart1k, Watercolor2k,
Foggy Cityscapes, and Cityscapes, respectively. 2.