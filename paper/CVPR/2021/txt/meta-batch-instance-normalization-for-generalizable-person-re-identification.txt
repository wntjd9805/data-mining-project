Abstract
Although supervised person re-identiﬁcation (Re-ID) methods have shown impressive performance, they suffer from a poor generalization capability on unseen domains.
Therefore, generalizable Re-ID has recently attracted grow-ing attention. Many existing methods have employed an instance normalization technique to reduce style varia-tions, but the loss of discriminative information could not be avoided. In this paper, we propose a novel generaliz-able Re-ID framework, named Meta Batch-Instance Nor-malization (MetaBIN). Our main idea is to generalize nor-malization layers by simulating unsuccessful generaliza-tion scenarios beforehand in the meta-learning pipeline.
To this end, we combine learnable batch-instance normal-ization layers with meta-learning and investigate the chal-lenging cases caused by both batch and instance normal-ization layers. Moreover, we diversify the virtual simu-lations via our meta-train loss accompanied by a cyclic inner-updating manner to boost generalization capabil-ity. After all, the MetaBIN framework prevents our model from overﬁtting to the given source styles and improves the generalization capability to unseen domains without addi-tional data augmentation or complicated network design.
Extensive experimental results show that our model out-performs the state-of-the-art methods on the large-scale domain generalization Re-ID benchmark and the cross-domain Re-ID problem. The source code is available at: https://github.com/bismex/MetaBIN. 1.

Introduction
Person re-identiﬁcation (Re-ID) aims to identify a spe-ciﬁc person across non-overlapping cameras under vari-ous viewpoints and locations. Re-ID has attracted exten-sive research attention thanks to its practical importance in surveillance systems. With the development of deep
Convolution Neural Networks (CNNs), person Re-ID meth-ods [51, 54, 48, 4, 23] have achieved remarkable perfor-mance in a supervised manner, where a model is trained and tested on separated splits of the same dataset. However, this supervised approach is hardly applicable in practice due to
Figure 1. Illustration of unsuccessful generalization scenarios and our framework. (a) Under-style-normalization happens when the trained BN model fails to distinguish identities on unseen domains. (b) Over-style-normalization happens when the trained IN model removes even ID-discriminative information. (c) Our key idea is to generalize BIN layers by simulating the preceding cases in a meta-learning pipeline. By overcoming the harsh situations, our model learns to avoid overﬁtting to source styles. expensive labeling costs and also suffers from severe perfor-mance degradation on an unseen target domain. For resolv-ing this problem, unsupervised domain adaptation (UDA) methods [46, 41, 5, 11, 47, 24] have been introduced, which adapt a Re-ID model from a labeled source domain to an un-labeled target domain. The UDA approach is more practical than the supervised approach, but data collection is still re-quired for updating the model on the target domain.
Beyond the concept of UDA, the task of domain gener-alization (DG) is more plausible for real-world applications since it does not require any target images to train a model.
Since Finn et al. [10] proposed the Model-Agnostic Meta-3425
Learning (MAML) scheme for few-shot learning and rein-forcement learning, several MAML-based methods [1, 19] have been investigated to solve the DG problem. This ap-proach enables a DG model to achieve a good generaliza-tion capability by dividing multiple source domains into meta-train and meta-test domains to mimic real train-test domain shifts. However, most DG methods [1, 19] assume a homogeneous environment, where the source and target do-mains share the same label space, and they are designed for a classiﬁcation task. In contrast, the task of domain gener-alization for person re-identiﬁcation (DG Re-ID) deals with different label spaces between source and target domains for a retrieval task. Thus, it is difﬁcult to obtain good perfor-mance when the existing DG methods are directly applied to DG Re-ID.
To this end, the recent DG Re-ID methods [17, 18, 53] have focused on a combination of batch normalization
Jia et (BN) [16] and instance normalization (IN) [40]. al. [17] adopted this idea to Re-ID by inserting IN after the residual connection in the speciﬁc layers, inspired by
[31]. However, this na¨ıve approach not only leads to the loss of discriminative information but also requires a care-ful selection of the locations for applying IN. For another instance, Jin et al. [18] designed the Style Normalization and Restitution (SNR) module based on instance normal-ization and feature distillation. Since this method aims at removing style discrepancy only from the given source do-mains, it lacks the ability to attenuate the new style of un-seen domains sufﬁciently.
So, how do we design normalization layers to be well generalized for DG Re-ID? To ﬁnd out the answer, we con-ducted simple experiments that explore the properties and limitations of BN and IN layers. After training each of the BN and IN models on multiple source domains, we ob-served the retrieval results on unseen target domains. The
BN model strives to learn discriminative information based on the style variations within each mini-batch. However, when samples of unexpected styles are given from unseen target domains, the trained model does not have sufﬁcient ability to distinguish their IDs. We call it under-style-normalization in Fig. 1 (a). On the contrary, IN eliminates instance-speciﬁc style information using its own statistics.
Even though IN can be helpful to remove unseen styles on target domains, it ﬁlters out even some discriminative in-formation, as shown in Fig. 1 (b). We call it over-style-normalization. Since both normalization methods have lim-itations in the DG setting, the combination of BN and IN has to be handled carefully.
To deal with the above issues, we propose a novel gen-eralizable Re-ID framework, named Meta Batch-Instance
Normalization (MetaBIN), for learning to generalize nor-malization layers. The key idea is to simulate the unsuc-cessful generalization scenarios mentioned earlier within a meta-learning pipeline and learn more generalized rep-resentation from the virtual simulations, as shown in
Fig. 1 (c). For this purpose, we design a batch-instance normalization with learnable balancing parameters between
BN and IN. Depending on the balancing parameter’s bias toward BN or IN, the DG model suffers from both under-style-normalization and over-style-normalization scenarios in meta-learning. By overcoming these challenging cases, the normalization layer becomes generalized. Moreover, we intentionally diversify the virtual simulations via our meta-train loss and a cyclic inner-updating manner to effectively boost the generalization capability. Our MetaBIN frame-work enables to train the DG model equipped with a sufﬁ-cient generalization capability to novel domains.
Our main contributions can be summarized as follows:
• We propose a novel generalizable Re-ID framework called MetaBIN. This approach prevents our model from overﬁtting to the given source styles by gener-alizing normalization layers via the simulation of un-successful generalization scenarios in meta-learning.
• We diversify the virtual simulations through our meta-train loss and a cyclic inner-updating manner. Both ideas effectively boost generalization capability.
• We make comprehensive comparisons and achieve state-of-the-art performance on the large-scale domain generalization Re-ID benchmark and the cross-domain
Re-ID problem. 2.