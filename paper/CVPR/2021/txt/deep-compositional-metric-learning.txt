Abstract
Compositors
Existing Ensembles
In this paper, we propose a deep compositional met-ric learning (DCML) framework for effective and gener-alizable similarity measurement between images. Conven-tional deep metric learning methods minimize a discrimi-native loss to enlarge interclass distances while suppress-ing intraclass variations, which might lead to inferior gen-eralization performance since samples even from the same class may present diverse characteristics. This motivates the adoption of the ensemble technique to learn a number of sub-embeddings using different and diverse subtasks. How-ever, most subtasks impose weaker or contradictory con-straints, which essentially sacriﬁces the discrimination abil-ity of each sub-embedding to improve the generalization ability of their combination. To achieve a better general-ization ability without compromising, we propose to sepa-rate the sub-embeddings from direct supervisions from the subtasks and apply the losses on different composites of the sub-embeddings. We employ a set of learnable compositors to combine the sub-embeddings and use a self-reinforced loss to train the compositors, which serve as relays to dis-tribute the diverse training signals to avoid destroying the discrimination ability. Experimental results on the CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the superior performance of our framework. 1 1.

Introduction
Learning a discriminative and generalizable metric to compute the distances between images is a long-standing problem in computer vision, which serves as the founda-tion to a variety of tasks such as face clustering [18, 60, 66], person re-identiﬁcation [6, 7, 72] and image retrival [47, 49, 70]. The objective of metric learning is to compress sam-ples from the same class and maintain a margin between different classes in the learned metric space [9, 19, 61].
∗Corresponding author 1Code: https://github.com/wzzheng/DCML
Minus
Minus
DCML Ensemble
De-pose
De-color
De-pose
De-color
De-pose 
De-color
Color
Pose n o i t a z i l a r e n e
G
Discriminativeness
Figure 1. Motivation of the proposed DCML framework. “De-” stands for “remove” where embeddings usually discard intra-class variations such as pose and color for discriminativeness, while ex-isting ensemble-based deep metric learning methods learn a set of sub-embeddings by directly performing different subtasks on them to capture diverse data characteristics including intraclass varia-tions such as colors and poses. They generally compromise on the discriminativeness of the metric to improve the generalization abil-ity. Differently, we only require a set of adaptive composites of the sub-embeddings to perform well on subtasks and simultaneously impose a discriminative constraint on the concatenation of the sub-embeddings. Our framework can improve the generalization of the learned metric without sacriﬁcing the discriminativeness.
Recently, deep metric learning (DML) methods achieve outstanding performance by exploiting the powerful rep-resentation ability of deep convolutional neural networks (CNNs) [22, 29, 46, 52] to transform an image to the corre-sponding embedding, where the distance metric is deﬁned as the Euclidean distance between embeddings.
Losses in deep metric learning are generally highly intraclass varia-discriminative, which encourage small tions and large interclass margins in order to make the learned metric robust to differentiate samples from differ-9320
ent classes [10, 11, 55, 61]. However, samples even from the same class can show different formations and present different characteristics, so suppressing the intraclass vari-ations may in turn undermine the ability of the learned metric to generalize to unseen classes, as veriﬁed by a number of recent works [43, 65]. To alleviate this issue, some methods turn to the ensemble technique and employ a number of learners to map each image to several sub-embeddings [36, 44, 64]. They train the learners with differ-ent subtasks which might be contradictory to the discrimi-native objective of metric learning, e.g., clustering samples from different classes to learn more general concepts or dis-tinguishing samples from the same class to preserve more intraclass details. This essentially sacriﬁces the discrimina-tion ability of each sub-embedding for better generalization ability of their combination, which raises a natural ques-tion: how can we improve the generalization ability without compromising on the discrimination ability?
In this work, we provide a deep compositional metric learning (DCML) framework as a positive solution, as illus-trated in Figure 1. Instead of directly imposing the contra-dictory constraints of the subtasks on the sub-embeddings, we relax the constraints and propose to apply the losses on different composites of them. We adaptively learn a set of compositors to effectively re-weight all the sub-embeddings to obtain the corresponding composites. The compositors are randomly initialized and trained with a self-reinforced objective to enlarge the diversity as well as try to make the composites perform well on the downstream subtasks, which act as relays to re-balanced the training signals to better instruct the sub-embeddings towards better general-ization. We simultaneously impose the discriminative con-straints of conventional metric learning objective on the concatenation of sub-embeddings to maintain the discrim-ination ability. The sub-embeddings remain discriminative while preserving certain generalizable characteristics to en-able the composites to complete various tasks. The overall framework of the proposed DCML can be trained efﬁciently in an end-to-end manner, and we directly use the concate-nation of sub-embeddings to measure the similarity during testing, which requires no additional resources compared to conventional methods. We perform extensive experiments on the widely-used CUB-200-2011, Cars196, and Stanford
Online Products datasets which demonstrate that our frame-work achieves very competitive performance. 2.