Abstract
We introduce an interactive Soft Shadow Network (SSN) to generates controllable soft shadows for image composit-ing. SSN takes a 2D object mask as input and thus is ag-nostic to image types such as painting and vector art. An environment light map is used to control the shadow’s char-acteristics, such as angle and softness. SSN employs an
Ambient Occlusion Prediction module to predict an inter-mediate ambient occlusion map, which can be further re-ﬁned by the user to provides geometric cues to modulate the shadow generation. To train our model, we design an efﬁcient pipeline to produce diverse soft shadow training data using 3D object models. In addition, we propose an inverse shadow map representation to improve model train-ing. We demonstrate that our model produces realistic soft shadows in real-time. Our user studies show that the gen-erated shadows are often indistinguishable from shadows calculated by a physics-based renderer and users can eas-ily use SSN through an interactive application to generate speciﬁc shadow effects in minutes. 1.

Introduction
Image compositing is an essential and powerful means for image creation, where elements from different sources are put together to create a new image. One of the chal-lenging tasks for image compositing is shadow synthesis.
Manually creating a convincing shadow for a 2D object cutout requires a signiﬁcant amount of expertise and effort, because the shadow generation process involves a complex interaction between the object geometry and light sources, especially for area lights and soft shadows.
Our work eases the creation of soft shadows for 2D ob-ject cutouts and provides full controllability to modify the shadow’s characteristics. The soft shadow generation re-quires 3D shape information of the object, which is not available for 2D image compositing. However, the strong 3D shape and pose priors of common objects may provide the essential 3D information for soft shadow generation.
We introduce the Soft Shadow Network (SSN), a deep neural network framework that generates a soft shadow for a 2D object cutout and an input image-based environmental light map. The input of SSN is an object mask. It is agnos-tic to image types such as painting, cartoons, or vector arts.
User control is provided through the image-based environ-ment light map, which can capture complex light conﬁgura-tions. Fig. 1 show animated shadows predicted by SSN for objects of various shapes in different image types. SSN pro-duces smooth transitions with the changing light maps and realistic shade details on the shadow map, especially near the object-ground contact points.
SSN is composed of an Ambient Occlusion Prediction (AOP) module and a Shadow Rendering (SR) module.
Given the object mask, the AOP module predicts an am-bient occlusion (AO) map on the ground shadow receiver, 4380
Figure 2: Image compositing using the Soft Shadow Network (SSN). The user adds two object sketches (left) on a background photo (middle) and uses our SSN to generate realistic soft shadows using a light map shown on the top of the right image. It only takes a couple of minutes for the user to achieve a satisfactory shadow effect. A video records this process can be found in the supplementary material. which is light map-independent and captures relevant 3D information of the object for soft shadow generation. The
SR module then takes the AO map, the object mask, and the light map to generate the soft shadow. Users can reﬁne the predicted AO map when needed to provide extra guidance about the object’s shape and region with the ground.
We generate training data for SSN using 3D object mod-els of various shapes and randomly sampled complex light patterns. Rendering soft shadows for complex lighting pat-terns is time-consuming, which throttles the training pro-cess. Therefore, we propose an efﬁcient data pipeline to render complex soft shadows on the ﬂy during the training.
In addition, we observe that the shadow map has a high dy-namic range, which makes the model training very hard. An inverse shadow map representation is proposed to ﬁx this is-sue.
A perceptual user study shows that the soft shadows gen-erated by SSN are visually indistinguishable from the soft shadows generated by a physics-based renderer. Moreover, we demonstrate our approach as an interactive tool that al-lows for real-time shadow manipulation with the system’s response to about 5ms in our implementation. As conﬁrmed by a second user study, photo editors can effortlessly incor-porate a cutout with desirable soft shadows into an existing image in a couple of minutes by using our tool (see Fig. 2).
Our main contributions are: 1. A novel interactive soft shadow generation framework for generic image compositing. 2. A method to generate diverse training data of soft shadows and environment light maps on the ﬂy. 3. An inverse map representation to improve the training on HDR shadow maps. 2.