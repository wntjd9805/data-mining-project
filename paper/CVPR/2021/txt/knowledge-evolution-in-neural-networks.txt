Abstract
Deep learning relies on the availability of a large cor-pus of data (labeled or unlabeled). Thus, one challenging unsettled question is: how to train a deep network on a rela-tively small dataset? To tackle this question, we propose an evolution-inspired training approach to boost performance on relatively small datasets. The knowledge evolution (KE) approach splits a deep network into two hypotheses: the ﬁt-hypothesis and the reset-hypothesis. We iteratively evolve the knowledge inside the ﬁt-hypothesis by perturbing the reset-hypothesis for multiple generations. This approach not only boosts performance, but also learns a slim network with a smaller inference cost. KE integrates seamlessly with both vanilla and residual convolutional networks. KE re-duces both overﬁtting and the burden for data collection.
We evaluate KE on various network architectures and loss functions. We evaluate KE using relatively small datasets (e.g., CUB-200) and randomly initialized deep net-works. KE achieves an absolute 21% improvement margin on a state-of-the-art baseline. This performance improve-ment is accompanied by a relative 73% reduction in infer-ence cost. KE achieves state-of-the-art results on classiﬁ-cation and metric learning benchmarks. Code available at http://bit.ly/3uLgwYb 1.

Introduction
Gene transfer is the transfer of genetic information from a parent to its offspring. Genes encode genetic instructions (knowledge) from ancestors to descendants. The ancestors do not necessarily have better knowledge; yet, the evolution of knowledge across generations promotes a better learn-ing curve for the descendants. In this paper, we strive to replicate this process for deep networks. We encapsulate a deep network’s knowledge inside a subnetwork, dubbed the ﬁt-hypothesis H △. Then, we pass the ﬁt-hypothesis’s knowledge from a parent network to its offspring (next deep network generation). We repeat this process iteratively and demonstrate a signiﬁcant performance improvement in the descendant networks as shown in Fig. 1. 1
-p o
T 70 60
FLW-KE
FLW-CE
CUB-KE
CUB-CE 0 20 40 60 80 100
Generation # (g)
Figure 1. Classiﬁcation performance on Flower-102 (FLW) and
CUB-200 (CUB) datasets trained on a randomly initialized
ResNet18. The horizontal dashed-lines denote a SOTA cross-entropy (CE) baseline [58]. The marked-curves show our ap-proach (KE) performance across generations. The 100th genera-tion KE-N100 achieves absolute 21% and 5% improvement mar-gins over the Flower-102 and CUB-200 baselines, respectively.
The lottery ticket literature [8, 62, 34, 42, 10] regards a dense network as a set of hypotheses (subnetworks).
Zhou et al. [62] propose a sampling-based approach, while
Ramanujan et al. [42] propose an optimization-based ap-proach, to identify the best randomly-initialized hypothe-sis. This hypothesis may be called the lottery ticket, but it is still limited by its random initialization. In this paper, we pick a random hypothesis, with inferior performance, and iteratively evolve its knowledge.
The main contribution of this paper is an evolution-inspired training approach. To evolve knowledge inside a deep network, we split the network into two hypotheses (subnetworks): the ﬁt-hypothesis H △ and the reset hypoth-esis H ▽ as shown in Fig. 2. We evolve the knowledge inside
H △ by re-training the network for multiple generations.
For every new generation, we perturb the weights inside
H ▽ to encourage the H △ to learn an independent repre-sentation. This knowledge evolution approach boosts per-formance on relatively small datasets and promotes a better learning curve for descendant networks. Our intuitions are presented in Sec. 3.3 and empirically validated in Sec. 5. 12843
Figure 2. A split network illustration using a toy residual network. (Left) A convolutional ﬁlter F with Ci = 3 input, Co = 4 output channels, and 2D kernels (e.g., π ∈ R3×3). (Center-Right) A toy residual network N with a three-channel input (e.g., RGB image) and a
ﬁve-logit output (C = 5). GAP denotes a global average pooling layer while L denotes the add operation. We split N into a ﬁt-hypothesis
H △ (dark-blue) and a reset-hypothesis H ▽ (light-gray). The ﬁt-hypothesis H △ is a slim network that can be extracted from the dense network N to perform inference efﬁciently. The paper appendix shows the dimensions of a ﬁt-hypothesis in the ResNet18 architecture.
The knowledge evolution (KE) approach requires network-splitting. If we split the weights of a neural net-work into two hypotheses (H △ and H ▽) randomly, KE will boost performance. This emphasizes the generality of our approach. Furthermore, we propose a kernel-level convolutional-aware splitting (KELS) technique to reduce inference cost. KELS is a splitting technique tailored for convolutional neural networks (CNNs). KELS splits a CNN such that the ﬁt-hypothesis H △ is a slim independent net-work with a smaller inference cost as shown in Fig. 2. The
KELS technique supports both vanilla CNNs (AlexNet and
VGG) and modern residual networks.
KE supports various network architectures and loss func-tions. KE integrates seamlessly with other regularization techniques (e.g., label smoothing). While KE increases the training time, the KELS technique reduces the inference cost signiﬁcantly. Most importantly, KE mitigates over-ﬁtting on relatively small datasets, which in turn reduces the burden for data collection. Our community takes natu-ral images for granted because they are available publicly.
However, for certain applications, such as autonomous nav-igation and medical imaging, the data collection process is expensive even when labeling is not required.
In summary, the key contributions of this paper are: 1. A training approach, knowledge evolution (KE), that boosts the performance of deep networks on relatively small datasets (Sec. 3.1). We evaluate KE using both classiﬁcation (Sec. 4.1) and metric learning (Sec. 4.2) tasks. KE achieves SOTA results. 2. A network splitting technique, KELS, which learns a slim network automatically while training a deep net-work (Sec. 3.2). KELS supports a large spectrum of
CNNs and introduces neither hyperparameters nor reg-ularization terms. Our ablation studies (Sec. 5) demon-strate how KELS reduces inference cost signiﬁcantly. 2.