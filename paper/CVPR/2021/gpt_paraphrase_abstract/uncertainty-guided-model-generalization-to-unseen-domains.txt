We investigate the challenge of generalizing from a single source to many unknown distributions. Previous solutions to this problem have limitations, so we propose a new approach. Our method involves increasing the capacity of the source in terms of both input and label spaces, guided by uncertainty assessment. This is the first work to assess generalization uncertainty from a single source and use it to guide input and label augmentation for robust generalization. We employ a Bayesian meta-learning framework for model training and deployment. Through extensive comparisons and an ablation study, we demonstrate the superiority of our approach in various tasks such as image classification, semantic segmentation, text classification, and speech recognition.