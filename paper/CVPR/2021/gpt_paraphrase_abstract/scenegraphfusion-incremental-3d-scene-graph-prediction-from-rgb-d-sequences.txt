This study introduces a method for constructing semantic scene graphs from 3D environments using a sequence of RGB-D frames. The proposed approach involves combining PointNet features from basic scene components using a graph neural network. Additionally, a new attention mechanism is proposed to handle partial and missing graph data in the incremental reconstruction process. Although the method is initially designed for submaps of the scene, it can also be applied to entire 3D scenes. Experimental results demonstrate that the proposed approach significantly outperforms existing 3D scene graph prediction methods and achieves comparable accuracy to other 3D semantic and panoptic segmentation methods, all while maintaining a high processing speed of 35Hz.