Current image segmentation models typically produce raster format segmentations, but applications in geographic information systems often require vector polygons. To address this discrepancy, we enhance a deep segmentation model by incorporating a frame field output for extracting buildings from remote sensing images. We train a deep neural network that aligns the predicted frame field with ground truth contours, thereby improving segmentation quality through multi-task learning. The frame field also provides structural information that aids in polygonization. To facilitate this process, we introduce a polygonization algorithm that utilizes both the frame field and the raster segmentation. Our code is publicly available at https://github.com/Lydorn/Polygonization-by-Frame-Field-Learning.