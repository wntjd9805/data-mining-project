Recent advancements in generative visual models and neural rendering have led to significant progress in 3D-aware image synthesis. However, current approaches have limitations in two aspects. Firstly, they may lack a foundational 3D representation or rely on rendering techniques that are not consistent across multiple views, resulting in synthesized images that lack multi-view consistency. Secondly, these approaches often utilize representation network architectures that are not sufficiently expressive, leading to a deficiency in image quality in their outputs. To address these limitations, we propose a new generative model called Periodic Implicit Generative Adversarial Networks (π-GAN or pi-GAN) for high-quality 3D-aware image synthesis. π-GAN leverages the power of neural representations with periodic activation functions and volumetric rendering to accurately represent scenes as view-consistent radiance fields. Through our proposed approach, we achieve state-of-the-art results in 3D-aware image synthesis using various real and synthetic datasets.