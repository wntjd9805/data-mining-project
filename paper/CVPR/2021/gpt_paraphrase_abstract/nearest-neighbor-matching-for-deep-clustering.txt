Deep clustering has become an important aspect of unsupervised learning, however, current methods do not adequately consider the semantic relationships between samples at both the local and global levels. Additionally, relying on these relationships to update the deep features in real-time may result in less accurate performance. To address this issue, we propose a method called Nearest Neighbor Matching (NNM) that matches samples with their nearest neighbors from both local (batch) and global (overall) levels. We match the nearest neighbors based on batch embedded features for the local level and overall embedded features for the global level. To ensure consistency in clustering assignment for both neighbors and classes, we introduce consistent loss and class contrastive loss for both local and global levels. Our experimental results on three benchmark datasets demonstrate that our new model outperforms state-of-the-art methods. Notably, our method achieves supervised performance on the STL-10 dataset and outperforms the latest comparison method by 3.7% on the CIFAR-100 dataset. Our code can be accessed at https://github.com/ZhiyuanDang/NNM.