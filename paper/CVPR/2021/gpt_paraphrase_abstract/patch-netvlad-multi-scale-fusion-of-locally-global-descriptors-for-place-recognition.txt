This paper presents Patch-NetVLAD, a new approach to Visual Place Recognition (VPR) that addresses the challenges of appearance and viewpoint change in a dynamic environment. Patch-NetVLAD combines the advantages of local and global descriptor methods by extracting patch-level features from NetVLAD residuals. Unlike existing local keypoint features, our method allows aggregation and matching of deep-learned local features defined over the feature-space grid, instead of fixed spatial neighborhoods. We also introduce a multi-scale fusion technique that combines patch features of different scales through an integral feature space. This fusion process makes the features highly invariant to both condition and viewpoint changes. Patch-NetVLAD achieves state-of-the-art results in visually recognizing places, even in computationally limited scenarios. It has been validated on various challenging real-world datasets and was the winning solution in the Facebook Mapillary Visual Place Recognition Challenge at ECCV2020. Additionally, Patch-NetVLAD offers adaptability to user requirements, with a speed-optimized version that is significantly faster than existing methods. By combining superior performance and computational efficiency in a configurable framework, Patch-NetVLAD can enhance both standalone place recognition capabilities and the overall performance of simultaneous localization and mapping (SLAM) systems.