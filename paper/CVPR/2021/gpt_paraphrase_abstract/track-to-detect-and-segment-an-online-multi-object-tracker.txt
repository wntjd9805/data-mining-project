This paper introduces TraDeS (TRAck to DEtect and Segment), a novel online joint detection and tracking model that integrates tracking cues to enhance object detection. Unlike most existing multi-object trackers that rely solely on neural networks for object detection, TraDeS leverages tracking information to improve the detection and segmentation process. The model employs a cost volume to infer object tracking offsets, which are then used to propagate previous object features and enhance the current object detection and segmentation. The effectiveness and superiority of TraDeS are demonstrated across four datasets, including MOT (2D tracking), nuScenes (3D tracking), MOTS, and Youtube-VIS (instance segmentation tracking). Further details can be found on the project page: https://jialianwu.com/projects/TraDeS.html.