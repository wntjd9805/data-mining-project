Clustering-based methods have been commonly used to learn image representations without human supervision. While recent approaches have focused on making these representations invariant to various perturbations through contrastive-based instance discrimination training, there are other important characteristics, such as contextual reasoning skills, that may be better addressed by reconstruction-based approaches. To address this, we propose a teacher-student scheme where a convolutional network is trained to reconstruct a bag-of-visual-words (BoW) representation of an image, given a perturbed version of the same image as input. Our approach involves online training of both the teacher network (which generates the BoW targets) and the student network (which learns representations), as well as an online update of the visual-words vocabulary used for the BoW targets. This enables fully online BoW-guided unsupervised learning. Extensive experiments show that our BoW-based strategy outperforms previous state-of-the-art methods, including contrastive-based ones, in various applications such as Pascal object detection, Pascal classification, and Places205 classification. Our method even achieves significantly better results than supervised pre-training. The implementation code is available at https://github.com/valeoai/obow.