We propose a method for estimating the 3D pose of a network of cameras in large-environment wide-baseline scenarios, such as construction sites, sports stadiums, and public spaces. The challenge in this task is detecting and matching the same 3D keypoint from two different camera views, which makes standard structure-from-motion (SfM) pipelines ineffective. To overcome this, we suggest treating people in the scene as "keypoints" and associating them across different camera views to obtain correspondences. Our method utilizes ideas from person re-identification (re-ID) to calibrate wide-baseline cameras. It first uses a re-ID method to associate human bounding boxes across cameras, then converts the bounding box correspondences to point correspondences, and finally solves for camera pose using multi-view geometry and bundle adjustment. Unlike existing methods, our approach does not require specialized calibration targets and can be used in situations where frequent calibration updates are necessary. We conducted extensive experiments on datasets of varying sizes, camera settings, and human activities. The results demonstrate that our method achieves similar performance to standard SfM methods that rely on manually labeled point correspondences.