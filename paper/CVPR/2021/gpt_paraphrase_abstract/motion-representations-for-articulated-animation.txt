We propose a new approach to animate articulated objects with distinct parts. Our method is unsupervised and can identify object parts, track them in a video, and determine their motions based on their principal axes. Unlike previous methods that rely on keypoints, our approach extracts meaningful and consistent regions that describe the locations, shapes, and poses of the object parts. These regions correspond to semantically relevant and distinct parts that are easily detected in the video frames. We separate the foreground from the background by modeling non-object related global motion using an additional affine transformation. To prevent the leakage of the driving object's shape, we disentangle the shape and pose of the object parts in the region space. Our model surpasses previous methods on existing benchmarks and performs particularly well on articulated objects, achieving a 96.6% user preference compared to the state of the art. We also introduce a new benchmark with high-resolution videos to demonstrate the effectiveness of our approach.