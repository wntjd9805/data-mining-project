We propose a strategy for approximating indoor panorama scenes in a 360-degree image using horizontal and vertical planes. We divide pixels based on their plane orientation estimation and then use an instance segmentation module to cluster the planes more easily. Additionally, we address the issue of camera yaw rotation by introducing a yaw-invariant V-planar reparameterization for CNNs. We create a benchmark dataset called "PanoH&V" by extending existing 360 depth datasets with ground truth H&V-planes and compare our method to state-of-the-art planar reconstruction methods, where our method outperforms the baselines significantly on the proposed dataset.