Most CNN-based super-resolution methods assume a fixed and known degradation, but they perform poorly when faced with different degradations. Previous methods rely on time-consuming degradation estimation, which can lead to SR failure. In this paper, we propose an unsupervised degradation representation learning scheme for blind SR that does not require explicit degradation estimation. Instead, we learn abstract representations to distinguish various degradations in the representation space. We also introduce a Degradation-Aware SR network that can adapt to different degradations based on the learned representations. Our scheme accurately extracts degradation information and achieves state-of-the-art performance in blind SR tasks. Code is available at: https://github.com/LongguangWang/DASR.