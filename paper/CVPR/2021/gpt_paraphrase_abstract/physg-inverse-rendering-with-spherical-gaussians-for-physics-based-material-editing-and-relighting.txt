We introduce PhySG, a complete inverse rendering pipeline that can reconstruct geometry, materials, and illumination from a set of images. Our pipeline includes a differentiable renderer and utilizes mixtures of spherical Gaussians to represent specular BRDFs and environmental illumination. We also use a Multi-Layer Perceptron to parameterize geometry as a signed distance function. By employing spherical Gaussians, we efficiently solve for approximate light transport, making our method suitable for scenes with challenging non-Lambertian reflectance under natural, static lighting conditions. Through synthetic and real data experiments, we demonstrate that our reconstructions not only facilitate rendering of novel viewpoints but also enable physics-based editing of materials and illumination.