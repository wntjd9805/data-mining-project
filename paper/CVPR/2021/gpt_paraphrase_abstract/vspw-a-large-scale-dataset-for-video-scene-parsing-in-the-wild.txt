This paper introduces a novel dataset called Video Scene Parsing in the Wild (VSPW), which aims to enhance the scene parsing task by focusing on videos instead of images. The VSPW dataset covers various real-world scenarios and categories. It offers several key features: 1) Well-trimmed long-temporal clips: Each video consists of a complete shot lasting approximately 5 seconds on average. 2) Dense annotation: The dataset provides pixel-level annotations at a high frame rate of 15 frames per second. 3) High resolution: Over 96% of the captured videos have high spatial resolutions ranging from 720P to 4K. The VSPW dataset includes 3,536 annotated videos, comprising 251,633 frames from 124 different categories. This dataset represents the first attempt to address the challenging video scene parsing task in diverse scenarios. Using the VSPW dataset, the authors propose a Temporal Context Blending (TCB) network that effectively utilizes long-range contextual information from past frames to improve segmentation of the current frame. Extensive experiments demonstrate that the TCB network enhances both segmentation performance and temporal stability compared to state-of-the-art methods for image or video-based scene parsing. The authors believe that the scale, diversity, long-temporal nature, and high frame rate of the VSPW dataset can significantly advance the research on video scene parsing and related areas. The dataset is publicly available at https://www.vspwdataset.com/.