Most existing methods for generating accurate scene graphs rely on deterministic predictions of pairwise relationships. However, we argue that visual relationships are often semantically ambiguous. Inspired by linguistic knowledge, we classify this ambiguity into three types: Synonymy Ambiguity, Hyponymy Ambiguity, and Multi-view Ambiguity. This ambiguity raises the issue of implicit multi-label and highlights the need for diverse predictions. To address this, we propose a novel module called Probabilistic Uncertainty Modeling (PUM). PUM models each union region as a Gaussian distribution, with the variance representing the uncertainty of the visual content. By introducing uncertainty modeling, PUM brings stochasticity to the feature representation, enabling diverse predictions. Additionally, PUM helps capture more fine-grained relationships, reducing bias towards frequent relationships. We conducted extensive experiments on the Visual Genome benchmark and found that combining PUM with the ResCAGCN model achieves state-of-the-art performance, particularly in terms of mean recall. We also demonstrate the universal effectiveness of PUM by incorporating it into existing models and provide insightful analysis of its ability to generate diverse yet plausible visual relationships. The examples in Figure 1 illustrate the semantic ambiguity present in the Visual Genome dataset and highlight the need for a probabilistic approach to relationship prediction.