We introduce Mobile Video Networks (MoViNets), a collection of video networks designed for efficient computation and memory usage in online video inference. While 3D convolutional neural networks (CNNs) are accurate in video recognition, they are resource-intensive and not suitable for mobile devices. To address this, we propose a three-step approach to enhance computational efficiency and minimize memory usage in 3DCNNs. Firstly, we develop a search space for video networks and employ neural architecture search to generate efficient and diverse 3D CNN architectures. Secondly, we introduce the Stream Buffer technique, which decouples memory from video clip duration, enabling 3D CNNs to handle streaming video sequences of any length for training and inference with a small memory footprint. Thirdly, we suggest a simple ensembling technique to further enhance accuracy without compromising efficiency. By employing these progressive techniques, MoViNets achieve state-of-the-art accuracy and efficiency on various video action recognition datasets like Kinetics, Moments in Time, and Charades. For instance, MoViNet-A5-Stream achieves comparable accuracy to X3D-XL on Kinetics 600 while requiring 80% fewer FLOPs and 65% less memory. The code is accessible at https://github.com/google-research/movinet.