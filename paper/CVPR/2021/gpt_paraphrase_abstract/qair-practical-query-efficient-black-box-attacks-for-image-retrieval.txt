We investigate the robustness of query-based attacks on image retrieval systems against adversarial examples, specifically in the black-box setting where the attacker only has access to the top-k ranked unlabeled images from the database. Unlike query attacks in image classification, which generate adversaries based on returned labels or confidence scores, the challenge in image retrieval is more difficult due to the difficulty in quantifying the attack effectiveness on the partially retrieved list. In this paper, we introduce the concept of Query-based Attack against Image Retrieval (QAIR) and propose a new relevance-based loss to measure the attack effects by comparing the similarity of the top-k retrieval results before and after attacks, and guide the gradient optimization. To improve the attack efficiency, we also propose a recursive model stealing method to acquire transferable priors on the target model and generate prior-guided gradients. Extensive experiments demonstrate that our proposed attack achieves a high success rate with few queries against image retrieval systems in the black-box setting. Furthermore, evaluations on a real-world visual search engine, Bing Visual Search, show that our attack successfully deceives the system with a 98% success rate using only an average of 33 queries.