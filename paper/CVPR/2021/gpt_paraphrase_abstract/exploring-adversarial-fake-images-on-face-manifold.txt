The use of powerful generative adversarial network (GAN) methods to create synthetic images has raised concerns regarding ethics and privacy. While image forensic models have made significant progress in identifying fake images, they can be easily deceived by adversarial attacks. However, the addition of adversarial noise to images has also raised suspicion. This paper proposes a different approach by searching for optimal adversarial points on the face manifold to generate anti-forensic fake face images. The authors employ a gradient-descent method in the latent space of a generative model, such as Style-GAN, to find an adversarial latent vector. This approach is similar to norm-based adversarial attacks but operates in the latent space. By generating fake images using these adversarial latent vectors and GANs, the authors demonstrate that mainstream forensic models, such as those based on Xception or EfÔ¨ÅcientNet, can be effectively defeated. The accuracy of deepfake detection models drops from over 90% to nearly 0%, while maintaining high visual quality. The authors also observe that manipulating noise vectors at different levels has varying impacts on the success rate of the attack, and the generated adversarial images primarily exhibit changes in facial texture or attributes.