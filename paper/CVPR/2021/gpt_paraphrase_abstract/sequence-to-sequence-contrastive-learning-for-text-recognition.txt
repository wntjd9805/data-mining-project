We present a framework called SeqCLR that focuses on sequence-to-sequence contrastive learning for visual representations, specifically in the context of text recognition. To address the sequence-to-sequence structure, we divide each feature map into different instances and compute contrastive loss accordingly. This approach allows us to contrast at a sub-word level, extracting multiple positive pairs and negative examples from each image. To enhance the quality of visual representations for text recognition, we propose new augmentation techniques, varied encoder architectures, and customized projection heads. Our experiments on handwritten and scene text demonstrate that our method outperforms non-sequential contrastive approaches when training a text decoder on the learned representations. Furthermore, SeqCLR significantly improves performance compared to supervised training when the level of supervision is reduced. When fine-tuned with 100% of the labels, our method achieves state-of-the-art results on standard handwritten text recognition benchmarks.