This paper presents the M3DSSD, a Monocular 3D Single Stage object Detector, which addresses the issue of feature mismatching in current anchor-based monocular 3D object detection methods. To tackle this problem, the authors propose a two-step feature alignment approach. In the first step, shape alignment is performed to allow the feature map's receptive field to focus on high-scoring pre-defined anchors. In the second step, center alignment is utilized to align the features at the 2D/3D centers. Additionally, the authors highlight the difficulty of learning global information and capturing long-range relationships, which are crucial for accurately predicting object depth. To address this, they introduce an asymmetric non-local attention block with multi-scale sampling to extract depth-wise features. Experimental results on the KITTI dataset demonstrate that the proposed M3DSSD outperforms existing monocular 3D object detection methods in both 3D object detection and bird's eye view tasks. The code for M3DSSD is publicly available on GitHub at https://github.com/mumianyuxin/M3DSSD.