Domain adaptation is the process of training models using labeled data from one domain and then adapting that knowledge to a different domain with limited or no labels. Many previous studies have focused on learning domain-agnostic feature representations using a global distribution alignment objective. However, this approach fails to consider the specific class structure within the source and target domains. In this research, we address this limitation by introducing a new criterion called ILA-DA, which is based on instance affinity for source to target transfer during adaptation. To achieve this, we propose a reliable and efficient method for identifying similar and dissimilar samples between the source and target domains. We then utilize a multi-sample contrastive loss to guide the domain alignment process. ILA-DA takes into account both intra-class clustering and inter-class separation, resulting in improved classifier boundaries, higher transferability, and increased accuracy. To validate the effectiveness of ILA-DA, we conducted experiments on various benchmark datasets and compared its performance with other popular domain adaptation approaches. The results consistently showed improved accuracy, demonstrating the superiority of ILA-DA. We also provide insights into the proposed alignment approach. The code for ILA-DA is publicly available on GitHub at https://github.com/astuti/ILA-DA.