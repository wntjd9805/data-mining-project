We propose a novel approach to estimating the 6D pose of objects using geometrically stable patches extracted from 3D point clouds. By leveraging the concept of geometric stability analysis, we determine that a minimal set of three planar/cylindrical patches can accurately represent the full 6DoFs of the object pose. Our method involves training a deep neural network to regress the 6D pose by learning both intra-patch geometric features and inter-patch contextual features. Additionally, we train a sub-network to predict per-patch poses, which improves pose accuracy in their corresponding DoFs. This approach allows our method to generalize well for occlusion and unseen instances, and it effectively resolves symmetry ambiguities. Our method outperforms existing depth-only and RGBD methods, achieving state-of-the-art results on public benchmarks. Furthermore, it performs well in category-level pose estimation.