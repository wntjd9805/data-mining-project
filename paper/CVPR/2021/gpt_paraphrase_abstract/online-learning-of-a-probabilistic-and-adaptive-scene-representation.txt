This paper focuses on the task of constructing and maintaining a consistent scene model in real-time for spatial perception, interpretation, and action. The scene is represented using a Bayesian nonparametric mixture model, which allows for the continuous representation of occupancy status for each point in the scene. Instead of using traditional data fusion methods, the paper addresses the problem of online learning the process of generating sequential point cloud data from the scene geometry. The model is updated in real-time through an incremental and parallel inference process. Experimental results demonstrate that the proposed representation achieves high accuracy and efficiency. The probabilistic formulation of the model ensures adaptability to different sensor characteristics, and the complexity of the model can be adjusted dynamically according to the scale of the data. Overall, this approach offers a promising solution for online spatial perception tasks.