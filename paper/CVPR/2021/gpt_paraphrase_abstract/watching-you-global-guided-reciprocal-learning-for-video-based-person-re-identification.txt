This paper presents a novel framework called Global-guided Reciprocal Learning (GRL) for video-based person re-identification (Re-ID). The goal is to automatically retrieve video sequences of the same person from different cameras. Existing methods often overlook fine-grained clues due to variations in person appearance across image sequences. To address this, the proposed GRL framework utilizes spatial and temporal cues by employing a Global-guided Correlation Estimation (GCE) method to generate feature correlation maps. These maps help identify high- and low-correlation regions for person identification. The framework then disentangles discriminative features into high-correlation and low-correlation features, guided by global representations. Additionally, a Temporal Reciprocal Learning (TRL) mechanism is introduced to enhance semantic information in high-correlation regions and accumulate sub-critical clues in low-correlation regions. The proposed approach is evaluated on three public benchmarks and achieves better performance compared to state-of-the-art methods. The code for the framework is available at https://github.com/ï¬‚ysnowtiger/GRL.