This paper introduces a two-stage deep learning framework called VoxelContext-Net for compressing both static and dynamic point clouds. The framework combines octree based methods and voxel based schemes to compress the data. The first stage involves extracting the local voxel representation to encode spatial context information for each node in the octree. In the second stage, a voxel context based deep entropy model is proposed to compress the symbols of non-leaf nodes in a lossless manner. For dynamic point cloud compression, local voxel representations from temporal neighbouring point clouds are also utilized to exploit temporal dependency. Additionally, a voxel context based 3D coordinate refinement method is proposed to mitigate distortion from the octree construction process and generate more accurate reconstructed point clouds at the decoder side. The effectiveness of the proposed method, VoxelContext-Net, is demonstrated through comprehensive experiments on static and dynamic point cloud benchmark datasets such as ScanNet and SemanticKITTI.