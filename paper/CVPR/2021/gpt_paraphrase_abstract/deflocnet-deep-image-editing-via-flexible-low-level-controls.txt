This paper introduces DeFLOCNet, a deep encoder-decoder CNN model designed for image editing. The model aims to accurately capture user intentions for content creation by incorporating low-level controls, such as sketch lines and color dots, into the feature representations. Unlike previous methods that combine these controls with the input image, DeFLOCNet directly injects them into structure generation blocks within skip-connection layers. This allows for better refinement of sketch lines and color propagation within the CNN feature space. The modulated features are then concatenated with the original decoder features to generate the desired structures. Additionally, DeFLOCNet includes a separate decoder branch for texture generation and detail enhancement. Experimental results on benchmark datasets demonstrate the effectiveness of DeFLOCNet in transforming various user intentions into visually pleasing edited content. The code and results of DeFLOCNet can be accessed at the provided GitHub link.