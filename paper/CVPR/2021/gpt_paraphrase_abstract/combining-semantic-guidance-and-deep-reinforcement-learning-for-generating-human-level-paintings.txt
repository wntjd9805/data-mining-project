The computer vision community has been working on the problem of generating stroke-based non-photorealistic imagery. Previous methods have focused on teaching machines how to paint like a human, but they have been limited in their ability to handle variations in position, scale, and saliency of the foreground object. In this study, we propose a Semantic Guidance pipeline that addresses these limitations. Our pipeline includes a bi-level painting procedure to distinguish between foreground and background brush strokes, an alignment model to handle variations in position and scale of the foreground object, and a focus reward mechanism to amplify the features of the in-focus object. Importantly, our method does not require supervision on human stroke-data and produces higher quality results on datasets like CUB-200 Birds and Stanford Cars-196. We also demonstrate the effectiveness of our method on complex datasets with multiple foreground object instances using the Virtual-KITTI dataset. Source code and models are available for further exploration.