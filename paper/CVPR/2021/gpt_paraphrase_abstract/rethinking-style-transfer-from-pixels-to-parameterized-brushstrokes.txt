In recent years, there have been numerous successful applications of neural style transfer. However, most of these implementations focus on stylization at the pixel level, which we believe is not a natural representation for paintings that typically consist of brushstrokes. To address this, we propose a novel approach that optimizes parameterized brushstrokes instead of pixels for image stylization. Additionally, we introduce a differentiable rendering mechanism to enhance visual quality and provide greater control over the stylization process, including the ability to manipulate the flow of brushstrokes through user input. We present qualitative and quantitative evaluations that demonstrate the effectiveness of our parameterized representation. The code for our method can be found at https://github.com/CompVis/brushstroke-parameterized-style-transfer.