Panoptic segmentation is a challenge that aims to combine instance segmentation and semantic segmentation into a single framework. However, there is a lack of efficient solutions for panoptic segmentation in the LiDAR point cloud domain. This paper introduces Panoptic-PolarNet, a fast and robust framework for LiDAR point cloud panoptic segmentation. By using a polar Bird's Eye View representation, the framework learns both semantic segmentation and class-agnostic instance clustering in a single network, addressing the issue of occlusion among instances in urban street scenes. The network's learnability is improved through an adapted instance augmentation technique and a novel adversarial point cloud pruning method. Experimental results demonstrate that Panoptic-PolarNet outperforms baseline methods on SemanticKITTI and nuScenes datasets, achieving real-time inference speed. It achieved 54.1% PQ in the SemanticKITTI panoptic segmentation leaderboard and leading performance for the nuScenes validation set.