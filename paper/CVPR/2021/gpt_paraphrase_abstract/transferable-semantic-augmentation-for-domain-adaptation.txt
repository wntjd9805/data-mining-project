Domain adaptation is a technique that transfers knowledge from a labeled source domain to an unlabeled target domain. Existing algorithms focus on adapting feature representations across domains using a shared source-supervised classifier. However, this classifier limits the ability to generalize to unlabeled target recognition. To address this limitation, we propose a Transferable Semantic Augmentation (TSA) approach that enhances the adaptation ability of the classifier by generating source features that align with target semantics. The TSA approach is inspired by the idea that transforming deep features in a specific direction can result in meaningful semantic changes in the original input space. Therefore, we augment the source features with target semantics to train a more transferable classifier. To achieve this, we construct a multivariate normal distribution for each class based on the mean difference between inter-domain features and the covariance of target intra-class features. We then augment the source features with random directions sampled from this distribution on a class-wise basis. Interestingly, this source augmentation is implicitly implemented through an expected transferable cross-entropy loss over the augmented source distribution. We derive an upper bound of the expected loss and minimize it, resulting in negligible computational overhead. The TSA technique is lightweight and can be easily integrated into various domain adaptation methods, leading to significant improvements. We conducted comprehensive experiments on cross-domain benchmarks, which confirmed the effectiveness of TSA.