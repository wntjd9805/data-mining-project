Current visual reasoning methods lack the ability to incorporate external knowledge and only rely on visual evidence for reasoning. This creates a knowledge gap between these methods and the complex semantic nature of real-world images. To bridge this gap, we propose a novel explicit visual reasoning method that integrates external knowledge and models high-order relational attention. Our approach involves a knowledge incorporation network that adds new graph nodes from external knowledge bases to enhance the semantics of the scene graph used in explicit reasoning. Additionally, we introduce a Graph-Relate module to perform high-order relational attention on the enriched scene graph. By incorporating structured external knowledge and high-order relational attention, our method achieves significant improvements in generalizability and explainability compared to state-of-the-art visual reasoning approaches on the GQA and VQAv2 datasets.