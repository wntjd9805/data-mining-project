The assessment of video quality in User Generated Content (UGC) is a significant area of interest in both industry and academia. Existing methods typically focus on evaluating only one aspect of perceptual quality, such as technical quality or compression artifacts. In this study, we have developed a large-scale dataset to comprehensively examine the characteristics of generic UGC video quality. In addition to subjective ratings and content labels, we have also proposed a Deep Neural Network (DNN)-based framework to thoroughly analyze the importance of content, technical quality, and compression level in determining perceptual quality. Our model not only provides quality scores but also offers user-friendly quality indicators, bridging the gap between low-level video signals and human perception. Experimental results demonstrate that our model achieves state-of-the-art correlation with Mean Opinion Scores (MOS).