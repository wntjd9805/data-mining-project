We present a new method for creating diverse and high-quality texture maps for 3D human models in a semi-supervised setting. Our approach involves using a segmentation mask to define the layout of different regions in the texture map, and then generating high-resolution textures with various styles for rendering purposes. To achieve this, we propose a Region-adaptive Adversarial Variational AutoEncoder (ReAVAE) that learns the probability distribution of the style for each region separately, allowing us to control the style of the generated texture by sampling from these region-specific distributions. Additionally, we introduce a data generation technique to augment our training set with data extracted from single-view RGB inputs. Our training strategy enables the combination of reference image styles with different styles for different regions, which is particularly useful for applications such as virtual try-on in augmented reality and virtual reality. Experimental results demonstrate that our method produces superior texture maps compared to previous approaches, while also providing independent control over layout and style. This research was conducted during an internship at FRL Research.