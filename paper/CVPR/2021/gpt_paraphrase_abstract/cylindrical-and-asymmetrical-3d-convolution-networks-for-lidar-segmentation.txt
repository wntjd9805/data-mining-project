Current methods for segmenting large-scale driving scenes using LiDAR often project point clouds onto a 2D space and process them with 2D convolution. However, this approach sacrifices the 3D topology and geometric relationships of the data. To address this issue, we propose a new framework for outdoor LiDAR segmentation that utilizes 3D voxelization and asymmetrical 3D convolution networks. We also introduce a point-wise refinement module to mitigate the interference caused by lossy voxel-based label encoding. Our model achieves excellent results on SemanticKITTI and nuScenes datasets, surpassing existing methods by a significant margin. Furthermore, our framework can be extended to LiDAR panoptic segmentation and 3D detection tasks.