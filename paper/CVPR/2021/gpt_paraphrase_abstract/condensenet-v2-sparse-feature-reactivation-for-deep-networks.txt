We introduce a new approach called sparse feature reactivation (SFR) as an alternative to the dense connectivity mechanism used in deep networks to achieve high computational efficiency. While previous models like CondenseNet have shown that removing redundant features can improve efficiency, our proposed network, CondenseNetV2, aims to actively increase the utility of features for reuse. In CondenseNetV2, each layer learns to selectively reuse important features from previous layers and also updates preceding features to enhance their usefulness for subsequent layers. Our experimental results demonstrate that the proposed models achieve promising performance in image classification (ImageNet and CIFAR) and object detection (MS COCO) in terms of both theoretical efficiency and practical speed.