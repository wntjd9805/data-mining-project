This paper introduces SpinNet, a new neural architecture designed to extract robust and general 3D local features for tasks like point cloud registration and reconstruction. Existing learning-based local descriptors are either sensitive to rotation transformations or rely on handcrafted features that lack generality and representativeness. SpinNet overcomes these limitations by utilizing a Spatial Point Transformer to map the input local surface into a cylindrical space, allowing for end-to-end optimization with rotational invariance. A Neural Feature Extractor is then used to derive a compact and representative descriptor for matching, leveraging point-based and 3D cylindrical convolutional neural layers. Extensive experiments on indoor and outdoor datasets demonstrate that SpinNet significantly outperforms existing techniques and exhibits superior generalization across different sensor modalities. The code for SpinNet is available at https://github.com/QingyongHu/SpinNet.