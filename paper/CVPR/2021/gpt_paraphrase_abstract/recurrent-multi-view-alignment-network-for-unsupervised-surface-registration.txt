Learning non-rigid registration is challenging due to the high degrees of freedom and lack of labeled data. However, we address these challenges by proposing a representation of non-rigid transformation using a combination of rigid transformations. This representation restricts the solution space and allows for an iterative solution using a recurrent framework, making the learning process easier. Additionally, we introduce a differentiable loss function that measures the similarity of 3D shapes on projected multi-view 2D depth images. This enables our method to be trained end-to-end without the need for ground truth supervision. Extensive experiments on various datasets demonstrate that our approach significantly outperforms the previous state-of-the-art methods.