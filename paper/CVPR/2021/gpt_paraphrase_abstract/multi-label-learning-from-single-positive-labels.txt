Multi-label classification is the task of predicting multiple labels for a given image. It is more challenging to annotate training data for multi-label classification compared to the standard single-label case. Human annotators struggle to mention all applicable labels for each image, especially when there are a large number of potential labels. Additionally, detecting small object instances in high-resolution images poses inherent difficulties. This leads to false negatives in multi-label training data. In this study, we focus on the toughest version of this problem where annotators provide only one relevant label for each image, resulting in training sets with only one positive label and no confirmed negatives. We investigate this specific case of learning from missing labels using four different multi-label image classification datasets, considering both linear classifiers and end-to-end fine-tuned deep networks. We modify existing multi-label losses and propose new variants that limit the number of expected positive labels during training. Surprisingly, we demonstrate that in some cases, it is possible to achieve performance similar to fully labeled classifiers even with significantly fewer confirmed labels.