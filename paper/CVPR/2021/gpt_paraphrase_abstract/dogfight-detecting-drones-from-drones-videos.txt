With the increasing autonomy and prevalence of airborne vehicles, it has become crucial to develop the capability to detect objects in their surroundings. This study focuses on the problem of detecting drones from other flying drones. The challenging aspects of this problem include the erratic movement of the drones, their small size and arbitrary shape, large intensity variations, and occlusion. Existing region-proposal and feature aggregation methods are inadequate in capturing the necessary foreground-background information and handling the small size and complex motion of the drones. To address these challenges, we propose a two-stage segmentation-based approach that utilizes spatio-temporal attention cues. In the first stage, detailed contextual information is captured using pyramid pooling on overlapping frame regions. Pixel and channel-wise attention is then applied to enforce accurate drone localization. In the second stage, the initial detections are verified and new potential drone locations are explored using motion boundaries. Candidate drone detections are tracked for a few frames, and cuboid formation is performed to extract 3D convolution feature maps for further drone detection. The proposed approach is evaluated on two publicly available drone detection datasets and outperforms several competitive baselines.