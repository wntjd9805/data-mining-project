Data-driven approaches have been successful in many tasks but struggle with generalizing to unseen image domains and require expensive annotation for tasks like semantic segmentation. Unsupervised domain adaptation (UDA) and semi-supervised learning (SSL) have been explored as solutions, but their performance still lags behind supervised approaches. This study focuses on semi-supervised domain adaptation (SSDA), where both labeled target data and labeled source data are available. To address SSDA, a novel framework based on dual-level domain mixing is proposed. This framework includes three stages: data mixing methods to reduce domain gap, generating complementary domain-mixed teachers, and distilling knowledge from these teachers to train a student model. Pseudo labels are then generated for unlabeled data in a self-training manner. Experimental results demonstrate the effectiveness of this framework on synthetic-to-real semantic segmentation benchmarks.