Numerical integration is a crucial technique in scientific computing and plays a central role in various computer vision applications. One such application is neural volume rendering, which offers a new approach for view synthesis and achieves highly realistic images. However, the practicality of these methods is hindered by the immense computational and memory requirements involved in performing volume integrations along the rendered rays during training and inference. To address this challenge, we introduce a novel framework called automatic integration, which leverages coordinate-based neural networks to learn efficient and closed-form solutions to integrals.   In our approach, we construct a computational graph that represents the derivative of the coordinate-based network and train it using the signal to be integrated. Through optimization, we reconstruct the graph to obtain a network that represents the antiderivative. By leveraging the fundamental theorem of calculus, this enables us to calculate any definite integral using just two evaluations of the network.   We apply this approach to neural rendering, where we aim to strike a balance between rendering speed and image quality. By implementing automatic integration, we achieve a significant improvement in rendering times, reducing them by more than 10 times, albeit at the cost of slightly reduced image quality.