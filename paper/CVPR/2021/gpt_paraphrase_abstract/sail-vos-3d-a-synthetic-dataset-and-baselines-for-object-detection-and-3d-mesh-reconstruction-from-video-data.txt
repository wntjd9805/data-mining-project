The aim of this study is to extract detailed 3D information from video data in order to gain a comprehensive understanding of a scene. Although previous methods have achieved impressive results in reconstructing object meshes from single images, there are limitations in cases where parts of the object are not visible. Additionally, existing datasets for mesh reconstruction lack the ability to incorporate temporal information. To address these issues, we introduce SAIL-VOS 3D, a synthetic video dataset that provides frame-by-frame mesh annotations as an extension of SAIL-VOS. Moreover, we develop initial baseline models for reconstructing 3D meshes from video data using temporal information. Our results, obtained from SAIL-VOS 3D and Pix3D datasets, demonstrate that incorporating temporal information improves the quality of mesh reconstruction. For further details and resources, please visit http://sailvos.web.illinois.edu.