Reference-based image super-resolution (RefSR) has shown promising results in enhancing high-frequency details by utilizing an external reference image (Ref). The process involves transferring texture details from the Ref image to the low-resolution (LR) image based on their corresponding points or patches. However, achieving accurate correspondence matching and computational efficiency is crucial. Additionally, existing RefSR methods often overlook the potential differences in distributions between the LR and Ref images, which negatively affects the utilization of information.   To address these issues, this paper introduces the MASA network for RefSR, incorporating two novel modules. The Match & Extraction Module significantly reduces computational costs by employing a coarse-to-fine correspondence matching scheme. This approach enhances efficiency without compromising accuracy. The Spatial Adaptation Module learns and adjusts the distribution disparities between the LR and Ref images, enabling the remapping of Ref features to match the distribution of LR features in a spatially adaptive manner. Consequently, the network becomes more robust in accommodating different reference images.   Extensive quantitative and qualitative experiments were conducted to validate the effectiveness of our proposed model. The results demonstrate that our approach successfully enhances image quality and preserves important details in a computationally efficient manner.