This paper introduces the Remote Embodied Referring Expression (REVERIE) task, which involves an agent navigating and localizing a remote object based on a high-level language instruction. Unlike other similar tasks, REVERIE requires goal-oriented exploration rather than strict instruction-following due to the absence of step-by-step navigation guidance. To address this challenge, the authors propose a novel Cross-modality Knowledge Reasoning (CKR) model. The CKR model, based on a transformer-architecture, generates scene memory tokens and utilizes informative history clues for exploration. A Room-and-Object Aware Attention (ROAA) mechanism is designed to perceive room and object information from linguistic and visual observations. Additionally, a Knowledge-enabled Entity Relationship Reasoning (KERR) module incorporates commonsense knowledge to learn the correlations among room and object entities, enabling the agent to take appropriate actions at each viewpoint. The CKR model is evaluated on the REVERIE benchmark and demonstrates superior performance, significantly improving SPL and REVERIE-success rate by 64.67% and 46.05%, respectively. The code for the CKR model is available at https://github.com/alloldman/CKR.