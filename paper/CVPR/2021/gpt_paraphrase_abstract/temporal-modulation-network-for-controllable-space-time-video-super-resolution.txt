This study focuses on improving the resolution of low-resolution and low-frame-rate videos using a technique called space-time video super-resolution (STVSR). Previous methods using deformable convolution have shown promise in STVSR, but they could only generate intermediate frames that were pre-defined during the training stage. Additionally, these methods did not adequately consider the motion cues between adjacent frames. To address these issues, this paper introduces a Temporal Modulation Network (TMNet) that can accurately interpolate arbitrary intermediate frames with high-resolution reconstruction. The TMNet utilizes a Temporal Modulation Block (TMB) to control feature interpolation by modulating deformable convolution kernels. To effectively capture temporal information, a Locally-temporal Feature Comparison (LFC) module and a Bi-directional Deformable ConvLSTM are proposed to extract short-term and long-term motion cues in videos. The experiments conducted on three benchmark datasets demonstrate that TMNet outperforms previous STVSR methods. The code for TMNet is also available at the provided GitHub link.