Current research on action recognition focuses on treating activities as single events in videos. However, recent studies have shown the potential benefits of understanding actions as combinations of smaller atomic actions. This understanding has been facilitated by datasets that include annotations for atomic actions, allowing researchers to learn representations that capture this information. Despite this progress, there is still a lack of research that explores action composition and utilizes multiple viewpoints and modalities of data for representation learning. In order to encourage research in this area, we present the Home Action Genome (HOMAGE), a comprehensive dataset that includes multiple views and modalities of action data, as well as hierarchical activity and atomic action labels, along with dense scene composition labels. By leveraging the rich multi-modal and multi-view settings provided by HOMAGE, we propose the Cooperative Compositional Action Understanding (CCAU) framework for hierarchical action recognition. CCAU incorporates knowledge of compositional action elements and consistently improves performance across all modalities. Additionally, we demonstrate the effectiveness of co-learning compositions in few-shot action recognition, achieving a mean average precision (mAP) of 28.6% with just a single sample.