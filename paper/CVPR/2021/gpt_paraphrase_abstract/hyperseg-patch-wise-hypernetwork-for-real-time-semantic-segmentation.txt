We introduce a new semantic segmentation network that operates in real-time. In this network, the encoder is responsible for both encoding and generating the weights of the decoder. We enhance adaptivity by allowing the weights in each decoder block to vary spatially. To achieve this, we propose a unique hypernetwork consisting of a nested U-Net for extracting higher level context features, a multi-headed weight generating module that produces the weights for each decoder block just before they are used, and a primary network with dynamic patch-wise convolutions. Despite utilizing unconventional blocks, our architecture achieves real-time performance. We outperform state-of-the-art results on popular semantic segmentation benchmarks such as PASCAL VOC 2012 (val. set), Cityscapes, and CamVid in terms of the trade-off between runtime and accuracy. The code for our approach can be found at: https://nirkin.com/hyperseg.