We present a method called HOI Transformer for detecting human-object interactions (HOI) in an end-to-end manner. Existing approaches either separate the HOI task into object detection and interaction classification stages or use surrogate problems. In contrast, our method eliminates the need for hand-designed components and directly predicts HOI instances by reasoning about the relationships between objects and humans from global image context. We introduce a quintuple matching loss to ensure unified HOI predictions. Our method is simpler and achieves improved accuracy, outperforming previous methods with a 26.61% average precision (AP) on HICO-DET and a 52.9% AP role on V-COCO. We provide our code at https://github.com/bbepoch/HoiTransformer and hope that our approach will serve as a simple and effective solution for HOI tasks.