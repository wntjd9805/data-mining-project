Camera localization in indoor environments is crucial for various applications such as scene mapping, robot navigation, and augmented reality. Current methods use optimization techniques to estimate the camera's position based on correspondences between 2D/3D camera space and 3D world space. However, these approaches rely solely on static input images, making them vulnerable to dynamic indoor environments. To address these challenges, this paper introduces a new approach called the outlier-aware neural tree. This method combines deep learning and decision tree approaches to improve camera pose estimation. The proposed algorithm consists of three main components: 1. Hierarchical space partition: The indoor scene is partitioned into hierarchical regions to construct the decision tree. 2. Neural routing function: A deep classification network is used to enhance 3D scene understanding by determining the optimal path through the decision tree. 3. Outlier rejection module: This module filters out dynamic points during the routing process, improving the accuracy of camera relocalization in dynamic indoor environments. The proposed algorithm is evaluated on the RIO-10 benchmark, which is specifically designed for camera relocalization in dynamic indoor environments. The results show that the outlier-aware neural tree achieves robust routing through space partitions and outperforms existing approaches by approximately 30% in terms of camera pose accuracy. Moreover, it performs evaluations at a comparable speed to other methods.