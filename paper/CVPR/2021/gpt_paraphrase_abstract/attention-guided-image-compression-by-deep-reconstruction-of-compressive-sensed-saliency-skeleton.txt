We present a novel deep learning system called AGDL (attention-guided dual-layer image compression) for image compression. In this system, an image is divided into two layers: a base layer and an attention-guided refinement layer. Unlike existing methods, AGDL uses a CNN module to predict the important pixels within the region of interest (ROI) based on a saliency sketch, allocating more bits to these critical pixels. Only the critical pixels are further compressed using compressive sensing (CS) to create a compact refinement layer. Another CNN method is developed to decode both compression layers, ensuring a refined reconstruction that adheres to the CS constraints on the critical pixels. Extensive experiments demonstrate that AGDL significantly improves perception-aware image compression, surpassing existing techniques.