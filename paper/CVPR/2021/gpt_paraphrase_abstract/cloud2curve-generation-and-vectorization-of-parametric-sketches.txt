The use of waypoint-sequences instead of raster-graphic representations has greatly advanced the analysis of human sketches in deep learning. Our objective is to represent sketches as a series of low-dimensional parametric curves. To achieve this, we propose an inverse graphics framework that can approximate stroke data encoded as a point-cloud using variable-degree Bézier curves. Based on this framework, we introduce Cloud2Curve, a generative model that can produce high-resolution vector sketches and be trained solely on point-cloud data. Additionally, our model can accurately convert raster or waypoint sketches into their corresponding scalable Bézier equivalents. We assess the generation and vectorization capabilities of our model on the Quick, Draw! and K-MNIST datasets.