Face synthesis, particularly face aging, has seen significant advancements in image fidelity through the use of generative adversarial networks (GANs). However, current face aging approaches often divide the dataset into age groups and rely on group-based training strategies, limiting their ability to produce finely controlled and continuous aging synthesis. In this study, we propose a unified network structure that integrates a linear age estimator into a GAN-based model. The embedded age estimator is trained in conjunction with the encoder and decoder to estimate the age of a face image and provide a personalized target age embedding for age progression/regression. This personalized target age embedding is created by combining a personalized residual age embedding of the current age and an exemplar-face aging basis of the target age. The aging bases are derived from the learned weights of the linear age estimator, allowing for a unified perspective in estimating age and generating personalized aged faces. This formulation enables the learning of self-estimated age embeddings for every single age. Through qualitative and quantitative evaluations on different datasets, our approach demonstrates significant improvements in the continuous face aging aspect compared to the state-of-the-art methods.