Human-Object Interaction (HOI) detection involves identifying interactions between humans and objects in an image. This task includes localizing the humans and objects involved and classifying the interaction labels. Current methods indirectly approach this task by detecting human and object instances and inferring pairs of detected instances individually. This paper introduces a new framework called HOTR, which directly predicts sets of human, object, and interaction triplets from an image using a transformer encoder-decoder architecture. By utilizing set prediction, our method effectively leverages the semantic relationships within an image and eliminates the need for time-consuming post-processing, which is a major limitation of existing methods. Our proposed algorithm achieves state-of-the-art performance in two HOI detection benchmarks, with an inference time of under 1 ms after object detection.