We propose a solution to the problem of identifying task-relevant actions and learning features in instructional videos without the need for supervision. We observe that visual and language instructions have a weak alignment, with some key-steps missing in one modality. To address this, we introduce an ordered prototype learning module that extracts visual and linguistic prototypes. We also develop a differentiable weak sequence alignment method to find the ordered one-to-one matching between sequences while allowing some items to remain unmatched. We present an efficient algorithm for computing the alignment and the loss derivative for visual and language feature learning. Through experiments on two instructional video datasets, we demonstrate the significant improvement of our method over the current state of the art.