Commercial depth sensors produce low-resolution depth maps, limiting their usefulness in computer vision tasks. Depth map super-resolution (SR) addresses this issue by up-scaling the depth map to a higher resolution. However, the lack of real-world paired low-resolution (LR) and high-resolution (HR) depth maps hinders the development of effective methods. To address this, we introduce the "RGB-D-D" dataset, which consists of LR and HR depth maps captured from mobile phones and Lucid Helios across various indoor and outdoor scenes. Additionally, we propose a fast depth map super-resolution (FDSR) baseline that utilizes the high-frequency component extracted from RGB images to guide the depth map SR. Our experiments on public datasets demonstrate that our network outperforms state-of-the-art methods in terms of effectiveness and efficiency. Furthermore, our algorithm improves the accuracy of HR depth maps for real-world LR depth maps by enhancing boundaries and correcting depth value errors.