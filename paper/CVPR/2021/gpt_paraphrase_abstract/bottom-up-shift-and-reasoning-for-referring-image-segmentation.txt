This paper presents a novel approach to referring image segmentation, which involves identifying the object or stuff referred to by a natural language expression in an image. The main challenge is distinguishing the referent from other objects in the same category. To address this challenge, the authors propose two modules: Bottom-Up Shift (BUS) and Bidirectional Attentive Refinement (BIAR). The BUS module progressively identifies the referent by reasoning hierarchically based on the expression. It distinguishes between similar regions by considering the relationships between them, enabling explicit alignment between linguistic components and visual regions. This allows for the identification of all mentioned entities in the expression. The BIAR module incorporates a two-way attentive message passing mechanism to fuse multi-level features. This captures relevant visual details for the referent and refines the segmentation results. Experimental results demonstrate that the proposed method, combining the BUS and BIAR modules, outperforms existing state-of-the-art algorithms on benchmark datasets. Additionally, the method provides interpretable reasoning steps for stepwise segmentation. The code for this method is available at https://github.com/incredibleXM/BUSNet.