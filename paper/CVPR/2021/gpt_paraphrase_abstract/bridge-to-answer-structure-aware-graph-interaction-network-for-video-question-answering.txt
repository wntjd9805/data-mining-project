This paper introduces a new technique called Bridge toAnswer, which aims to accurately answer questions about a given video by utilizing diverse interactions between different types of graphs. To achieve this, we train visual graphs that are conditioned on the question, allowing each visual node to incorporate both visual and linguistic cues through question-to-visual interactions. Additionally, we propose bridged visual-to-visual interactions that integrate two complementary types of visual information (appearance and motion) by using the question graph as an intermediary bridge. This bridged architecture facilitates reliable message passing by considering the compositional semantics of the question, resulting in the generation of appropriate answers. Consequently, our approach can learn question-conditioned visual representations that effectively capture appearance and motion, leading to strong performance in video question answering tasks. Extensive experiments demonstrate that our method outperforms existing approaches on various benchmarks. The answer format exclusively provides a concise summary.