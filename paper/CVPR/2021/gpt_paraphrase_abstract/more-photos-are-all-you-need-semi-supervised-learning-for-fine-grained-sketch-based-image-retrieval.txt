The main challenge faced by current Fine-Grained Sketch-Based Image Retrieval (FG-SBIR) models is the lack of sketch-photo pairs, which significantly limits their performance. While the number of photos can be easily increased, producing corresponding sketches is a time-consuming process. In this study, we propose a solution to overcome this limitation by investigating the use of unlabelled photos alone to improve performance. We introduce a new semi-supervised framework for cross-modal retrieval that takes advantage of large-scale unlabelled photos to address the scarcity of labelled data. Our framework includes a sequential photo-to-sketch generation model that generates paired sketches for unlabelled photos. To ensure the quality of the generated sketches, we incorporate a discriminator-guided mechanism and a distillation loss-based regularizer to handle noisy training samples. Additionally, we consider generation and retrieval as complementary problems and develop a joint learning procedure for each module to benefit from each other. Extensive experiments demonstrate that our semi-supervised model outperforms state-of-the-art supervised alternatives and existing methods that utilize unlabelled photos for FG-SBIR.