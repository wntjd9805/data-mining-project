This paper introduces a new variant of GAN called Posterior Promoted GAN (P2GAN) that addresses the issue of insufficient real information in the generator. The proposed framework incorporates the real information from the posterior distribution produced by the discriminator. Unlike other GAN variants, the discriminator maps images to a multivariate Gaussian distribution and extracts real information, while the generator utilizes this information through AdaIN and a latent code regularizer. The stability of the training process is ensured through the use of reparameterization trick and pretraining. The convergence of P2GAN is theoretically proven. Experimental results on high-dimensional multi-modal datasets demonstrate that P2GAN achieves comparable results to the state-of-the-art GAN variants in unsupervised image synthesis.