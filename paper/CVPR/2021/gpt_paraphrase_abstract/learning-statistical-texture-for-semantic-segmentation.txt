Current semantic segmentation methods primarily focus on learning contextual information using high-level semantic features with convolutional neural networks (CNNs). To ensure precise boundaries, low-level texture features are directly connected to deeper layers. However, texture features not only encompass local structure but also include global statistical knowledge of the input image. This paper introduces a Statistical Texture Learning Network (STL-Net) that effectively utilizes low-level texture features for semantic segmentation. For the first time, STL-Net analyzes the distribution of low-level information and efficiently incorporates it into the task. The proposed method includes a Quantization and Counting Operator (QCO) to statistically describe texture information. Two modules are introduced: the Texture Enhance Module (TEM) captures and enhances texture-related information, while the Pyramid Texture Feature Extraction Module (PTFEM) effectively extracts statistical texture features from multiple scales. Extensive experiments demonstrate that STL-Net achieves state-of-the-art performance on three semantic segmentation benchmarks: Cityscapes, PASCAL Context, and ADE20K.