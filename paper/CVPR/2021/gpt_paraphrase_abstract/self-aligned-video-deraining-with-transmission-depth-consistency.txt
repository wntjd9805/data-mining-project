This paper presents a novel approach for removing rain streaks and rain accumulation in videos. Most existing methods focus on rain streak removal and rely on optical flow for frame alignment, which can lead to inaccurate results. To address this issue, we propose a self-alignment network that uses deformable convolution layers for feature-level alignment instead of optical flow. Additionally, our method predicts the current frame based on adjacent frames to remove randomly appearing rain streaks. For rain accumulation, we introduce a transmission-depth consistency loss to handle the ambiguity between depth and water-droplet density. Our network estimates depth and calculates the transmission map using a physics model. We also estimate camera poses to ensure photometric-temporal and depth-temporal consistencies. Experimental results demonstrate that our method outperforms state-of-the-art methods in both quantitative and qualitative evaluations.