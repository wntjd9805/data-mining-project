Recent advancements in self-supervised learning (SSL) have made significant progress in bridging the gap with supervised ImageNet pretraining. However, these methods have mostly been used on unlabeled ImageNet images and show limited improvements when trained on larger sets of uncurated images. We believe that current SSL techniques perform better on iconic images but struggle with complex scene images that contain multiple objects. Our analysis of contrastive SSL methods reveals their poor visual grounding and inadequate supervisory signals when applied to scene images. To address these limitations, we propose Contrastive Attention-Supervised Tuning (CAST). CAST leverages unsupervised saliency maps for intelligent crop sampling and provides grounding supervision through a Grad-CAM attention loss. Experimental results on COCO dataset demonstrate that CAST significantly enhances the features learned by SSL methods on scene images. Moreover, additional experiments demonstrate that models trained with CAST exhibit greater robustness to changes in backgrounds. The code for CAST can be accessed at https://github.com/salesforce/CAST/.