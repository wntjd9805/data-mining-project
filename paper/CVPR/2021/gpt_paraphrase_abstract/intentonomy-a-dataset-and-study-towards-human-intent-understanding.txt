This paper examines the underlying meaning and intention behind social media images and explores how visual information can assist in recognizing human intent. To achieve this, the authors introduce a dataset called Intentonomy, which consists of 14,000 manually annotated images representing various everyday scenes. These images are categorized into 28 intent categories based on a social psychology taxonomy. The study then investigates the contribution of commonly used visual information, such as objects and context, in understanding human motives. Additionally, the authors analyze the impact of attending to object and context classes, as well as textual information in the form of hashtags, when training an intent classifier. The results of the study provide both quantitative and qualitative insights into how visual and textual information can influence the prediction of intent.