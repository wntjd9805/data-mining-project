The importance of similarity learning in object tracking has been acknowledged. However, current methods for multiple object tracking only consider sparse ground truth matching as the training objective and overlook the informative regions in images. This paper introduces Quasi-Dense Similarity Learning, which densely samples numerous region proposals on a pair of images for contrastive learning. By directly combining this similarity learning with existing detection methods, Quasi-Dense Tracking (QDTrack) is built without the need for displacement regression or motion priors. Additionally, the resulting feature space allows for a simple nearest neighbor search during inference. QDTrack outperforms all existing methods on MOT, BDD100K, Waymo, and TAO tracking benchmarks, achieving 68.7 MOTA at 20.3 FPS on MOT17 without external training data. Compared to methods using similar detectors, it improves MOTA by nearly 10 points and significantly reduces the number of ID switches on BDD100K and Waymo datasets. The code and trained models can be accessed at https://github.com/SysCV/qdtrack.