In most current learning systems, images are typically represented as 2D pixel arrays. However, there is a growing trend towards using implicit neural representations (INRs) to represent images as multi-layer perceptron (MLP) models that predict RGB pixel values based on their coordinates. This paper introduces two innovative architectural techniques, factorized multiplicative modulation and multi-scale INRs, for constructing image decoders based on INRs. These techniques are utilized to develop a state-of-the-art continuous image generative adversarial network (GAN). Previous attempts to adapt INRs for image generation were limited to simple datasets like MNIST and struggled to handle complex real-world data. Our proposed INR-GAN architecture significantly enhances the performance of continuous image generators, bridging the gap between continuous image GANs and pixel-based ones. Additionally, we explore various intriguing properties of INR-based decoders, including superresolution, meaningful image interpolation, accelerated inference for low-resolution images, extrapolation beyond image boundaries, and strong geometric priors. Further information about the project can be found at https://universome.github.io/inr-gan.