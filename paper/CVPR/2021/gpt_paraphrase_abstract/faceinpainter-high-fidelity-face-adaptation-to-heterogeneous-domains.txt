We propose a new framework called FaceInpainter for controllable Identity-Guided Face Inpainting (IGFI) across different domains. The framework consists of two stages. In the first stage, a StyledFace Inpainting Network (SFI-Net) is used to fit the target face to a fixed background by separating the foreground and background. This stage takes into account 3D priors, texture code, and identity factors of the source face. However, it is challenging to handle the inconsistency between the new identity of the source and the original background of the target. In the second stage, a Joint Refinement Network (JR-Net) is employed to refine the swapped face. This network uses Adaptive Instance Normalization (AdaIN) with identity and multi-scale texture codes to transform the decoded face from SFI-Net, considering facial occlusions. The contextual loss is used to preserve attributes and encourage face deformation with fewer texture distortions. Experimental results show that our approach achieves high-quality identity adaptation in different domains, outperforming state-of-the-art methods in terms of both attribute and identity fidelity.