This paper introduces a new framework for training deep networks with limited labeled data in order to achieve strong generalization abilities. The framework utilizes semi-supervised learning, which leverages unlabeled data to complement the small labeled datasets. The proposed approach involves a generative adversarial network that captures the joint distribution of both images and labels. The network is trained efficiently using a large set of unlabeled images supplemented with a few labeled ones. The architecture is based on StyleGAN2 and includes a label synthesis branch. At test time, image labeling is accomplished by embedding the target image into a latent space using an encoder network and test-time optimization, and then generating the label based on the inferred embedding. The approach is evaluated in two domains: medical image segmentation and part-based face segmentation. The results show strong performance within the domain and impressive generalization capabilities across domains, such as transferring from CT to MRI in medical imaging and from real faces to paintings, sculptures, cartoons, and animal faces. The project page for more information is available at https://nv-tlabs.github.io/semanticGAN/.