The limited availability of parallel sign-text data poses a significant challenge in sign language translation (SLT). To address this issue, we propose a solution called sign back-translation (SignBT). This approach incorporates a large amount of spoken language texts into the SLT training process. We begin by using a text-to-gloss translation model to back-translate monolingual text into its gloss sequence. We then generate the corresponding sign sequence by combining fragments from a gloss-to-sign bank at the feature level. These synthetic parallel data serve as a valuable supplement for training the encoder-decoder SLT framework. In order to advance SLT research, we also introduce CSL-It providesDaily, a comprehensive dataset for continuous SLT. This dataset includes both translations of spoken language and gloss-level annotations. The topics covered in CSL-Daily revolve around everyday activities such as travel, shopping, and medical care, which are common scenarios for SLT applications. We conduct extensive experiments and analysis of SLT methods using CSL-Daily. The proposed sign back-translation method yields significant improvements compared to previous state-of-the-art SLT techniques.