Recent advances in deep learning have led to impressive results in image classification. However, these models often assume that the data being processed does not contain sensitive information. In practical scenarios such as healthcare and facial recognition systems, this assumption may not hold true. To address this issue, we propose the use of a dynamic and data-driven pruning filter called DISCO. DISCO selectively removes features in the latent space to protect sensitive information while maintaining a balance between privacy and utility. In our study, we introduce various attack schemes targeting sensitive inputs and attributes, and evaluate the effectiveness of DISCO against state-of-the-art methods using both quantitative and qualitative measures. Additionally, we provide a benchmark dataset of 1 million sensitive representations to facilitate further research on novel attack and defense strategies. This dataset can be accessed at https://github.com/splitlearning/InferenceBenchmark.