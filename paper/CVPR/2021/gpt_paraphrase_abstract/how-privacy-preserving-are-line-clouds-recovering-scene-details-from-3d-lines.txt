Visual localization is a crucial aspect of computer vision applications, such as Mixed and Virtual Reality systems, as it involves estimating the camera pose of an image in relation to a known scene. Many existing algorithms use Structure-from-Motion (SfM) point clouds and 2D-3D matches to determine camera pose. However, there are privacy concerns associated with user-generated content, especially when image details can be accurately recovered from SfM point clouds. To address this, a recent proposal suggests replacing 3D points with randomly oriented 3D lines in order to create line clouds that are unintelligible to humans and prevent point cloud-to-image translation. This study demonstrates that line clouds still retain significant information about the 3D scene geometry, enabling the approximation of 3D point positions and image content recovery. The approach is based on the observation that the closest points between lines can provide a good estimation of the original 3D points. The code for this approach can be found at https://github.com/kunalchelani/Line2Point.