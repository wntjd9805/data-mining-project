Automated generation of radiology reports can enhance diagnostic radiology practice by alleviating the burden of report writing for radiologists while also preventing misdiagnosis and missed diagnoses. However, this task is challenging for data-driven neural networks due to biases in visual and textual data. To address this, we propose a method called Posterior-and-Prior Knowledge Exploring-and-Distilling (PPKED) that mimics the working patterns of radiologists. The PPKED consists of three modules: Posterior Knowledge Explorer (PoKE), Prior Knowledge Explorer (PrKE), and Multi-domain Knowledge Distiller (MKD). PoKE explores explicit abnormal visual regions to reduce visual data bias, while PrKE explores prior medical knowledge and radiology reports to mitigate textual data bias. The MKD distills the explored knowledge to generate final reports. Our method outperforms previous state-of-the-art models on the MIMIC-CXR and IU-Xray datasets.