We introduce BoTNet, an effective backbone architecture that integrates self-attention for various computer vision tasks such as image classification, object detection, and instance segmentation. By replacing spatial convolutions with global self-attention in the last three bottleneck blocks of a ResNet, our method significantly outperforms the baselines in instance segmentation and object detection while reducing parameters and maintaining minimal latency. We demonstrate that the design of BoTNet allows ResNet bottleneck blocks with self-attention to be seen as Transformer blocks. BoTNet achieves impressive results of 44.4% Mask AP and 49.7% Box AP on the COCO Instance Segmentation benchmark, surpassing the previous best single model and single scale performance of ResNeSt. Additionally, we adapt BoTNet for image classification, achieving a strong accuracy of 84.7% top-1 on the ImageNet benchmark while being up to 1.64x faster in compute time than popular EfÔ¨ÅcientNet models on TPU-v3 hardware. We believe that our simple yet effective approach will serve as a robust foundation for future research on self-attention models in computer vision.