Object detection and segmentation methods typically require large amounts of instance-level annotations for training, which can be challenging and time-consuming to obtain. To address this issue, different approaches have been proposed, including weakly-supervised methods that utilize image-level labels and zero/few-shot methods that rely on instance-level data for a set of base classes and limited examples for novel classes. However, these approaches have been developed separately without a unified framework.In this study, we propose a novel semi-supervised model that aims to bridge the gap between weakly-supervised and fully-supervised methods. Our model is designed to handle a range of supervision levels, from zero to a few instance-level samples per novel class. For base classes, the model learns a mapping from weakly-supervised to fully-supervised detectors/segmentors. By leveraging both visual and lingual similarities between the novel and base classes, we transfer these mappings to obtain detectors/segmentors for novel classes. If available, a small number of instance-level annotations for novel classes are used to refine the transferred mappings.Our proposed model is end-to-end trainable and highly flexible. We evaluate its performance on the MS-COCO and Pascal VOC benchmark datasets through extensive experiments. The results demonstrate improved performance across various settings.