This study proposes a method for estimating 3D human poses using pressure maps recorded by a tactile carpet. The researchers developed a low-cost, high-density carpet that can record real-time human-floor interactions. They collected a dataset of synchronized tactile and visual information during various human activities. Using a deep neural network model, they were able to infer 3D human poses using only the tactile information. The system can also be expanded to estimate poses for multiple people. The researchers evaluated the system and showcased its potential applications in various fields.