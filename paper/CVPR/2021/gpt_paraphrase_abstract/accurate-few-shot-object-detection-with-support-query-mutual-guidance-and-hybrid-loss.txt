Most object detection methods rely on large amounts of annotated data and can only detect categories that are present in the training set. However, obtaining such annotated data is expensive and time-consuming. This paper introduces a new two-stage detector for accurate few-shot object detection. In the first stage, a support-query mutual guidance mechanism is used to generate more relevant proposals. This is achieved through a query-guided support weighting module that combines different supports to generate the support feature, and a support-guided query enhancement module that utilizes dynamic kernels. In the second stage, proposals are scored and filtered using multi-level feature comparison with the aggregated support feature, based on a distance metric learned by an effective hybrid loss. This approach improves the discriminative power of the embedding space. Extensive experiments on benchmark datasets demonstrate that this method outperforms existing methods and achieves state-of-the-art results in few-shot object detection.