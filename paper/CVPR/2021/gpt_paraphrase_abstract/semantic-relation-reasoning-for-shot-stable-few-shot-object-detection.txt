Few-shot object detection is a critical and persistent problem in the field of computer vision. This is mainly due to the fact that real-world data follows a long-tail distribution, leading to a scarcity of data for novel classes. However, the semantic relationship between these novel classes and the base classes remains constant regardless of the availability of data. In this study, we explore the integration of this semantic relationship with visual information and introduce explicit relation reasoning into the learning process of novel object detection. To achieve this, we represent each class concept using a semantic embedding obtained from a large text corpus. The detector is then trained to map the image representations of objects into this embedding space. We also address the limitations of using raw embeddings by incorporating a dynamic relation graph into the embeddings, instead of relying solely on a heuristic knowledge graph. As a result, our few-shot detector, named SRR-FSD, demonstrates robustness and stability in handling variations in the number of shots for novel objects. Experimental results indicate that SRR-FSD achieves competitive performance at higher shots and, more importantly, significantly outperforms other approaches when given lower explicit and implicit shots. We propose a benchmark protocol that removes implicit shots from the pre-trained classification dataset, which serves as a more realistic setting for future research in this field.