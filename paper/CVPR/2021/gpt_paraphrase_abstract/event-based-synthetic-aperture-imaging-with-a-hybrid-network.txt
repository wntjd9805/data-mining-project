We present a novel synthetic aperture imaging (SAI) system that utilizes an event camera to address the challenges posed by dense occlusions and extreme lighting conditions. Traditional SAI systems based on frame-based cameras often suffer from performance degradation due to these disturbances. The event camera, which generates asynchronous events with low latency and high dynamic range, offers a solution by providing almost continuous views that effectively eliminate the interference of dense occlusions and handle over/under exposure problems.   To reconstruct occluded targets, we propose a hybrid encoder-decoder network consisting of spiking neural networks (SNNs) and convolutional neural networks (CNNs). The SNN layers encode the spatio-temporal information collected from the events, which is then transformed into visual images of the occluded targets using a style-transfer CNN decoder.   Our experiments demonstrate the remarkable performance of our proposed method in handling dense occlusions and extreme lighting conditions. Furthermore, we show that high-quality visual images can be reconstructed using solely event data.