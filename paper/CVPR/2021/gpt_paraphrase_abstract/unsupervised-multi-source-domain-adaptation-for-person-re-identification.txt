Unsupervised domain adaptation (UDA) methods in the field of person re-identification (re-ID) aim to transfer knowledge from labeled source data to unlabeled target data. While these methods have achieved success, they typically only utilize limited data from a single-source domain for model pre-training, resulting in underutilization of the valuable labeled data. To address this issue, we propose the incorporation of the multi-source concept into UDA person re-ID by using multiple source datasets during training. However, simply combining different datasets does not lead to significant improvement due to domain gaps. In this study, we tackle this problem from two perspectives: the domain-specific view and the domain-fusion view. We introduce two complementary modules: the rectification domain-specific batch normalization (RDSBN) module and the graph convolutional network (GCN) based multi-domain information fusion (MDIF) module. The RDSBN module simultaneously reduces domain-specific characteristics and enhances the distinctiveness of person features. On the other hand, the MDIF module minimizes domain distances by fusing features from different domains using graph convolutional networks. Our proposed method surpasses the performance of existing UDA person re-ID methods by a significant margin and even achieves comparable results to supervised approaches without any post-processing techniques.