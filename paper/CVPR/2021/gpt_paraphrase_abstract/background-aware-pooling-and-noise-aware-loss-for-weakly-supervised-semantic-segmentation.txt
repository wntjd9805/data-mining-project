We propose a solution to the problem of weakly-supervised semantic segmentation (WSSS) using bounding box annotations. Object bounding boxes are useful indicators but do not provide information about object boundaries, making it challenging to train CNNs for semantic segmentation. We observe that background regions within an image are visually consistent, and we leverage this to distinguish between foreground and background regions inside object bounding boxes. To implement this, we introduce a new pooling method called background-aware pooling (BAP), which focuses on aggregating foreground features using attention maps. This allows us to generate high-quality pseudo segmentation labels for training CNNs, although these labels still contain noise particularly at object boundaries. To overcome this, we propose a noise-aware loss (NAL) that reduces the impact of incorrect labels on the networks. Experimental results demonstrate that learning with our pseudo labels already outperforms existing weakly- and semi-supervised methods on the PASCAL VOC 2012 dataset, and the performance is further improved by the NAL.