To overcome the challenge of requiring a large amount of labeled training data for training deep networks in semantic segmentation, we propose a framework for semi-supervised semantic segmentation. This framework incorporates self-supervised monocular depth estimation from unlabeled image sequences. Our approach consists of three main contributions. Firstly, we transfer knowledge from features learned during self-supervised depth estimation to improve semantic segmentation. Secondly, we utilize the geometry of the scene to blend images and labels, resulting in strong data augmentation. Lastly, we employ a student-teacher framework that considers both the diversity of depth features and the difficulty of learning depth to select the most useful samples for annotation in semantic segmentation. We evaluate our proposed model on the Cityscapes dataset and observe significant performance improvements in all three modules. Our results demonstrate state-of-the-art performance in semi-supervised semantic segmentation. The implementation of our framework can be accessed at https://github.com/lhoyer/improving_segmentation_with_selfsupervised_depth.