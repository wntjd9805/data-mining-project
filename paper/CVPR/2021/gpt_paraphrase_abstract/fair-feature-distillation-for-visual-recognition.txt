Fairness is an increasingly important issue in computer vision, particularly in decision systems that involve humans. However, achieving algorithmic fairness, which ensures that models produce unbiased outcomes for protected groups, remains a problem that has not been resolved. This paper presents a systematic approach called MMD-based Fair Distillation (MFD) to reduce algorithmic biases in visual recognition tasks. While distillation techniques have been used to improve prediction accuracy, there has been no explicit work that also aims to improve fairness through distillation. The paper provides a theoretical justification for MFD by examining the effect of knowledge distillation on fairness. Extensive experiments demonstrate that MFD significantly reduces bias against specific minorities without sacrificing accuracy on synthetic and real-world face datasets.