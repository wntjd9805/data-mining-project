We propose a new approach, called Un-biased Mean Teacher (UMT), for cross-domain object detection. Current object detection models struggle with data variance, especially when faced with significant differences between domains. Our research reveals that the simple mean teacher (MT) model often exhibits considerable bias in cross-domain scenarios. To address this issue, we introduce several effective strategies to eliminate model bias. For the teacher model, we propose a cross-domain distillation method that maximizes the utilization of the teacher model's expertise. Additionally, we alleviate bias in the student model by augmenting training samples through pixel-level adaptation. To enhance the teaching process, we employ an out-of-distribution estimation strategy to select samples that best fit the current model. This further improves the cross-domain distillation process. By implementing these strategies to tackle model bias, our UMT model achieves impressive mean Average Precision (mAP) scores on benchmark datasets. Specifically, our model achieves mAPs of 44.1%, 58.1%, 41.7%, and 43.1% on the Clipart1k, Watercolor2k, Foggy Cityscapes, and Cityscapes datasets, respectively. These results surpass the existing state-of-the-art performance by a significant margin. For further reference, our implementation is publicly available at https://github.com/kinredon/umt.