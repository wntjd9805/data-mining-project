Creating an efficient model with limited computational resources is a difficult task. The accuracy of lightweight models is further constrained by the conventional design practice of using stage-wise configurations for channel dimensions. This configuration resembles a piecewise linear function of the network stage. In this study, we aim to improve the performance of lightweight models by exploring alternative channel dimension configurations. We conduct empirical analyses to determine the optimal design of a single layer by analyzing the rank of the output feature. We then investigate the channel configuration of the entire model by searching for network architectures that adhere to the computational cost restrictions. Based on our findings, we propose a straightforward yet effective channel configuration that can be parameterized by the layer index. Our proposed model, which follows this parameterization, achieves remarkable performance on various tasks, including ImageNet classification, COCO object detection, COCO instance segmentation, and fine-grained classifications. The code and pretrained models for ImageNet are available at https://github.com/clovaai/rexnet.