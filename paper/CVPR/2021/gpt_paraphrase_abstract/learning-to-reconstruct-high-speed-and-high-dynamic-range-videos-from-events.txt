Event cameras are a new type of sensors that capture the dynamics of a scene in an asynchronous manner. Unlike conventional cameras, these cameras have shorter response times and are highly sensitive to changes in intensity. Previous efforts have tried to reconstruct high-speed and high dynamic range (HDR) videos from event streams, but they often suffer from unrealistic artifacts or low frame rates. In this study, we propose a convolutional recurrent neural network that uses a sequence of neighboring events to reconstruct high-speed HDR videos, taking temporal consistency into account during the training process. Additionally, we have developed an optical system to collect a real-world dataset of paired high-speed HDR videos and event streams, which will be publicly available for future research in this field. Our experimental results, both on simulated and real scenes, demonstrate that our method produces high-quality high-speed HDR videos and outperforms existing reconstruction methods.