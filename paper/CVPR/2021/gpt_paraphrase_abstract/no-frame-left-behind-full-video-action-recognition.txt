Recognizing actions in videos requires considering all video frames, but it is not feasible to train deep networks on every frame due to computational limitations. Instead of uniformly sampling a small number of frames, we propose a method for full video action recognition. To make this computationally manageable, we cluster frame activations based on their similarity to the classification task and then aggregate the frames within each cluster. Our approach is trainable end-to-end and efficient, utilizing localized clustering and fast Hamming distances in feature space. We evaluate our method on various datasets and compare favorably to existing frame sampling methods.