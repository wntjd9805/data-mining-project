We propose a more efficient approach for estimating dense correspondences between two images that depict different but semantically related scenes. Currently, deep neural networks with neighborhood consensus cues are the best methods for this task. However, these architectures are computationally expensive as they require exhaustive matching and 4D convolutions over matching costs for all pairs of feature map pixels. To address this issue, we introduce a more efficient neighborhood consensus approach based on Patch-Match. We enhance the accuracy of our approach by using a learned local 4D scoring function to evaluate candidates during the PatchMatch iterations. To train both the scoring function and the feature extraction modules, we embed them into a proxy model that is end-to-end differentiable. We train these modules in a supervised setting using a cross-entropy loss and incorporate sparse keypoint supervision.Our method, evaluated on PF-PASCAL and SPAIR-71K datasets, outperforms the state-of-the-art approaches while also being faster and requiring less memory.