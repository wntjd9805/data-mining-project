In few-shot object detection (FSOD), the goal is to develop detectors that can accurately detect objects from new classes with only a few training instances. While previous approaches have focused on using meta-learning techniques to improve FSOD performance, this study takes a different approach by addressing the problem through sample expansion. The authors propose a Transformation Invariant Principle (TIP) that can be applied to various meta-learning models to enhance detection performance on novel class objects. By introducing consistency regularization on predictions from transformed images, the proposed method improves the generalization ability of FSOD models to objects affected by different transformations like occlusion and noise. Additionally, the approach can also handle unlabeled data, making it suitable for semi-supervised FSOD scenarios. Extensive experiments on PASCAL VOC and MSCOCO datasets validate the effectiveness of the TIP method in both FSOD settings.