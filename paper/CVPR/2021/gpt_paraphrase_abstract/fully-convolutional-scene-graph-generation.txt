This paper introduces a novel approach, called fully convolutional scene graph generation (FCSGG), for simultaneously detecting objects and relations in images. Unlike existing methods that rely on pre-trained two-stage object detectors and bounding box features, FCSGG adopts a bottom-up approach that encodes objects as bounding box center points and relationships as 2D vector fields, referred to as Relation Affinity Fields (RAFs). RAFs capture both semantic and spatial information and explicitly represent the relationship between objects. FCSGG solely employs visual features and achieves impressive results in scene graph generation. Extensive experiments conducted on the Visual Genome dataset demonstrate the effectiveness, efficiency, and generalizability of the proposed method. FCSGG achieves highly competitive recall and zero-shot recall results while significantly reducing inference time.