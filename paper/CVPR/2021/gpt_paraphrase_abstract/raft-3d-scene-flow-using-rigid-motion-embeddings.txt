We present a solution to the problem of scene flow estimation, which involves determining the 3D motion of pixels in a pair of stereo or RGB-D video frames. Our approach, called RAFT-3D, is a novel deep architecture that builds upon the RAFT model designed for optical flow estimation. However, instead of estimating 2D motion, RAFT-3D iteratively updates a dense field of pixelwise SE3 motion, which represents 3D motion. A key innovation of RAFT-3D is the use of rigid-motion embeddings, which group pixels into rigid objects in a flexible manner. These embeddings are enforced with geometric consistency through a differentiable layer called Dense-SE3. By incorporating this layer, we ensure that the embeddings maintain their geometric properties. Experimental results demonstrate that RAFT-3D achieves state-of-the-art performance. When evaluated on the FlyingThings3D dataset using a two-view evaluation metric, our method improves the best published accuracy from 34.3% to 83.7% when considering a threshold of Î´ < 0.05. On the KITTI dataset, we achieve an error of 5.77, outperforming the best published method (6.31), even though our approach does not rely on object instance supervision.