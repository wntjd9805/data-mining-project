The objective of weakly supervised phrase grounding is to learn the correspondence between regions in images and phrases in sentences using only image-sentence pairs. However, a challenge arises due to the lack of links between image regions and sentence phrases during training. To overcome this challenge, we utilize a generic object detector during training and propose a contrastive learning framework that considers both region-phrase and image-sentence matching. Our main innovation involves learning a score function for region-phrase pairs, which is then used to construct a score function for image-sentence pairs. Importantly, the region-phrase score function is learned by distilling soft matching scores between detected object names and candidate phrases within an image-sentence pair, while the image-sentence score function is supervised by ground-truth image-sentence pairs. By designing these score functions, we eliminate the need for object detection during testing, leading to a significant reduction in inference cost. Despite its simplicity, our approach achieves state-of-the-art results in visual phrase grounding, surpassing previous methods that require expensive object detectors during testing.