Machine learning classifiers are highly vulnerable to evasion attacks, where adversaries modify inputs to deceive the classifier while keeping the changes imperceptible. Recent years have seen a significant reduction in the number of queries made by black box attacks on classifiers, particularly in the score-based setup where the attacker has access to predicted probabilities. This reduction has gone from millions of queries to less than a thousand. This paper introduces SurFree, a geometric approach that achieves a significant decrease in the number of queries in the most challenging setup: black box decision-based attacks (only the top-1 label is known). Unlike previous attacks that rely on costly gradient surrogate estimations, SurFree focuses on exploring diverse directions guided by precise indications of the classifier's decision boundaries. We justify this geometric approach and compare it to previous attacks, considering the number of queries as a primary factor. Our experiments demonstrate faster distortion decay with low query numbers (a few hundred to a thousand) while remaining competitive with higher query budgets.