In many multi-label visual recognition tasks, there is often a long-tailed distribution of data. Training directly on this data typically leads to lower performance on less common classes. Re-balanced data sampling can improve performance on these tail classes, but it may also negatively affect performance on more common classes due to label co-occurrence. To address this, we propose a new approach that combines uniform and re-balanced samplings during training, resulting in improved performance on both head and tail classes. We introduce a visual recognition network with two branches, one using uniform sampling and the other using re-balanced sampling. Each branch uses a binary-cross-entropy-based classification loss with learnable logit compensation for visual recognition. We also define a cross-branch loss to ensure consistency when the same input image is processed by both branches. We evaluate our approach on VOC-LT and COCO-LT datasets and show that it outperforms previous state-of-the-art methods in long-tailed multi-label visual recognition.