The accuracy of current methods for estimating 3D scene flow from a sequence of single camera images is limited, particularly in terms of efficiency. This paper presents a new approach to improve accuracy while maintaining real-time efficiency by introducing a multi-frame monocular scene flow network based on self-supervised learning. The proposed model utilizes a triple frame input and convolutional LSTM connections, as well as an occlusion-aware census loss for improved accuracy. Additionally, a gradient detaching strategy is employed to enhance training stability. Experimental results on the KITTI dataset demonstrate that the proposed method achieves state-of-the-art accuracy compared to other self-supervised learning-based approaches for monocular scene flow estimation.