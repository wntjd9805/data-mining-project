Deep convolutional neural networks (CNNs) have achieved impressive results in image classification tasks thanks to their ability to leverage large-scale training datasets. However, training CNNs effectively becomes challenging in realistic learning scenarios characterized by class imbalance, small-scale datasets, and label noises. Regularization techniques have been successful in mitigating overfitting issues in such degraded training datasets. In this study, we propose a novel approach to regularize feature representation learning. Our method focuses on the angle between a feature and a classifier embedded in cosine similarity at the classification layer. We introduce a new similarity measure based on the von Mises-Fisher distribution of directional statistics, which differs from the traditional cosine similarity. Our similarity measure is compact yet has a heavy tail, allowing it to regularize the distribution of intra-class features and improve generalization performance. Through experiments conducted on realistic learning situations involving class imbalance, small-scale datasets, and noisy labels, we demonstrate the effectiveness of our proposed method for training CNNs compared to other regularization methods. The source code for our method is available at https://github.com/tk1980/tvMF.