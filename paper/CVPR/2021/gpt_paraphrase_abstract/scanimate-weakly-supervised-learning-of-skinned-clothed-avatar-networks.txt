We introduce SCANimate, a framework that transforms raw 3D scans of clothed humans into animatable avatars. Our approach does not rely on customized mesh templates or surface mesh registration, making it more tractable than existing methods. By disentangling articulated deformations and utilizing locally pose-aware implicit functions, we align scans into a canonical pose and model pose-dependent deformations. Unlike global pose embeddings, our local pose conditioning reduces correlations and improves generalization. We demonstrate the effectiveness of our method on various types of clothing with different amounts of training data, surpassing existing solutions in terms of fidelity and generality. The code is available at https://scanimate.is.tue.mpg.de.