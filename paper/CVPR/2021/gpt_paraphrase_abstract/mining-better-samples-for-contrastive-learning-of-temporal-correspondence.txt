We introduce a new framework for learning pixel-level representations without the need for labeled data in videos. Our method can identify positive correspondences and adjust the difficulty of negative samples during training to avoid ambiguous matches and trivial solutions. We incorporate three criteria, ranging from pixel-level to video-level matching confidence, into a sequential process and design a curriculum that adapts the hardness of negative samples based on the current representation power. Our approach achieves superior performance compared to existing methods in video label propagation tasks.