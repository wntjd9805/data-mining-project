Salient Object Detection (SOD) faces challenges when objects have complex backgrounds and similar appearances to their surroundings. To overcome this, depth information is incorporated along with the RGB image, known as RGB-D SOD. However, the presence of noise and ambiguity in raw depth images hinders this research. To address these issues, we propose the Depth Calibration and Fusion (DCF) framework, which includes two components. Firstly, a learning strategy is used to calibrate the bias in the original depth maps, improving SOD performance. Secondly, a cross-reference module effectively combines features from both RGB and depth modalities. Extensive experiments show that our approach outperforms 27 state-of-the-art methods. Additionally, our depth calibration strategy can be used as a preprocessing step, yielding noticeable improvements when applied to existing RGB-D SOD models. Source code is available at https://github.com/jiwei0921/DCF.