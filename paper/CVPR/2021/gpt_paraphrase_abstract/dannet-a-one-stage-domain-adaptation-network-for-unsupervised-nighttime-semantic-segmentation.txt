This paper introduces a new approach called DANNet for semantic segmentation of nighttime images in autonomous driving. Unlike daytime images, nighttime images are more challenging due to poor lighting conditions and the difficulty of obtaining accurate human annotations. DANNet addresses these challenges by using an adversarial training technique with a labeled daytime dataset and an unlabeled dataset containing roughly aligned day-night image pairs.For the unlabeled day-night image pairs, DANNet utilizes the pixel-level predictions of static object categories from a daytime image as a pseudo supervision to segment the corresponding nighttime image. To handle the inaccuracies caused by misalignment between day-night pairs and incorrect predictions of daytime images, as well as to enhance the accuracy of small objects, a re-weighting strategy is designed.What sets DANNet apart is that it is the first one-stage adaptation framework for nighttime semantic segmentation, eliminating the need for separate pre-processing stages or additional day-night image transfer models. The effectiveness of DANNet is demonstrated through extensive experiments on Dark Zurich and Nighttime Driving datasets, where it achieves state-of-the-art performance in nighttime semantic segmentation.