Continual learning often assumes that incoming data is fully labeled, which may not be realistic in real-world applications. This study introduces semi-supervised continual learning (SSCL), where learning is done incrementally using partially labeled data. Existing continual learning methods do not effectively utilize unlabeled data, so this study proposes a method called deep Online Replay with Discriminator Consistency (ORDisCo). ORDisCo combines a classifier with a conditional generative adversarial network (GAN) to continually pass the learned data distribution to the classifier. To exploit unlabeled data efficiently, ORDisCo replays data sampled from the conditional generator to the classifier in an online manner. Additionally, to avoid catastrophic forgetting of unlabeled data, the study selectively stabilizes important parameters of the discriminator that are used to discriminate between old unlabeled data and their pseudo-labels predicted by the classifier. ORDisCo is extensively evaluated on various semi-supervised learning benchmark datasets for SSCL, and the results show significant performance improvement compared to strong baselines on datasets such as SVHN, CIFAR10, and Tiny-ImageNet.