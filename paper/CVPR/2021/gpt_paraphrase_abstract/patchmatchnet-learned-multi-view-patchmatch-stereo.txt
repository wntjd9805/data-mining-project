We present PatchmatchNet, a new and trainable version of Patchmatch for high-resolution multi-view stereo. PatchmatchNet is designed to be faster and more memory-efficient than competitors that use 3D cost volume regularization, making it suitable for resource-limited devices. We introduce an iterative multi-scale Patchmatch in an end-to-end trainable architecture and enhance the Patchmatch core algorithm with a learned adaptive propagation and evaluation scheme for each iteration. Our method performs competitively and generalizes well on DTU, Tanks & Temples, and ETH3D datasets, while being significantly more efficient than existing top-performing models. It is at least two and a half times faster and uses half the memory compared to state-of-the-art methods. The code is available at https://github.com/FangjinhuaWang/PatchmatchNet.