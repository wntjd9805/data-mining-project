We introduce a method to enhance model performance in Unsupervised Domain Adaptation (UDA) by encoding visual task relationships. Our study demonstrates that semantic segmentation and monocular depth estimation tasks are complementary, and leveraging their relationship through multi-task learning can improve performance on both tasks. To achieve this, we propose a novel Cross-Task Relation Layer (CTRL) that encodes task dependencies between semantic and depth predictions. Our approach involves a neural network architecture with task-specific and cross-task refinement heads to capture cross-task relationships. Additionally, we introduce an Iterative Self-Learning (ISL) training scheme that utilizes semantic pseudo-labels to provide extra supervision in the target domain. Through experiments, we observe improvements in the performance of both tasks because our method effectively captures the complementary information present in these tasks. Specifically, our approach enhances performance when the tasks are complementary and mutually dependent, improves semantic segmentation and depth estimation in the challenging UDA setting, and further enhances semantic segmentation performance with the proposed ISL training scheme. The implementation of our method can be found at https://github.com/susaha/ctrl-uda.