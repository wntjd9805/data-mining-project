Recent years have seen a widespread adoption of deep neural networks for recognition tasks such as object recognition and key-point estimation. However, these state-of-the-art methods are computationally expensive and require large amounts of memory, making it challenging to deploy them on low power embedded devices. Therefore, there is a need to reduce the storage requirements and computational complexity of these models.The Lottery Ticket Hypothesis (LTH) suggests that deep neural networks trained on large datasets contain smaller subnetworks that can achieve comparable performance to the dense networks. In this study, we investigate the application of LTH for model pruning in the context of object detection, instance segmentation, and keypoint estimation.Our empirical study reveals that lottery tickets obtained from pretraining on Imagenet do not transfer well to the downstream tasks. However, we provide guidance on how to find lottery tickets with up to 80% overall sparsity for different sub-tasks without sacrificing performance.Additionally, we analyze the behavior of trained tickets in relation to various task attributes such as object size, frequency, and difficulty of detection.To demonstrate the performance of lottery tickets, we use a Mask R-CNN model with ResNet-18 and ResNet-50 backbones trained on the COCO dataset for object detection, segmentation, and human keypoint estimation. The results show that task-specific pruning outperforms the use of universal lottery tickets obtained from ImageNet pretraining. With only 20% of the weights, we can achieve the same performance as the original dense networks.In summary, our study explores the effectiveness of LTH for model pruning in recognition tasks and provides insights on finding lottery tickets with high sparsity without compromising performance.