This study introduces AIFit, an automatic system for 3D human sensing in fitness training. AIFit is designed to reconstruct 3D human pose, shape, and motion, accurately segment exercise repetitions, and identify deviations from trainer standards in real-time. By providing localized, quantitative feedback, AIFit aims to improve exercise execution, reduce injury risk, and facilitate continuous improvement. To support research and evaluation, the study also presents the Fit3D dataset, which includes over 3 million images and corresponding ground truth configurations of 3D human shape and motion. The dataset covers a variety of exercises performed by both instructors and trainees. A key feature of AIFit is its statistical coach, which can be adjusted to adapt to different fitness levels or the expected accuracy of the pose reconstruction method. The study demonstrates that the feedback system based on 3D pose estimates achieves good accuracy compared to ground truth motion capture, with the statistical coach providing feedback in natural language and utilizing spatio-temporal visual grounding.