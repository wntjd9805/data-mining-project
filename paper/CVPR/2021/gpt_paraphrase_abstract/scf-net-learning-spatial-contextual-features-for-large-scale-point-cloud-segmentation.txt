The focus on learning effective features from large-scale point clouds for semantic segmentation has increased in recent years. To address this issue, we introduce a learnable module called SCF, which learns Spatial Contextual Features from these point clouds. The module consists of three main blocks: the local polar representation block, the dual-distance attentive pooling block, and the global contextual feature block. Firstly, the local polar representation block constructs a spatial representation that is invariant to z-axis rotation for each 3D point. Next, the dual-distance attentive pooling block utilizes the representations of neighboring points to learn more discriminative local features based on both geometric and feature distances. Finally, the global contextual feature block learns a global context for each 3D point by considering its spatial location and the volume ratio of the neighborhood to the overall point cloud. The proposed module can be easily integrated into different network architectures for point cloud segmentation, resulting in a new encoder-decoder architecture called SCF-Net. Extensive experiments on two public datasets demonstrate that SCF-Net outperforms several state-of-the-art methods in most cases.