The usage of deep convolutional neural networks for facial recognition heavily relies on having access to large datasets of face images. These datasets need to contain numerous examples of different identities, with a wide range of images for each identity to enable the network to learn and adapt to variations within the same class. However, acquiring such datasets, especially those with diverse poses, is challenging. To address this issue, Generative Adversarial Networks (GANs) offer a potential solution by generating realistic synthetic images. Nonetheless, recent research has revealed that existing methods of separating pose from identity in GANs are inadequate. In this study, we enhance the generator of a GAN by incorporating a 3D morphable model. This integration enables the learning of a nonlinear texture model from "in-the-wild" images, allowing the generation of new synthetic identities and manipulation of pose, illumination, and expression without compromising the identity itself.We utilize the synthesized data to augment the training process of facial recognition networks and evaluate their performance using the challenging CFP and CPLFW datasets.