To address the problem of overfitting in image-to-image (I2I) translation methods using generative adversarial networks (GANs) with limited training data, we propose a data augmentation technique called ReMix. This method involves interpolating training samples at the feature level and introducing a novel content loss based on the perceptual relationships among samples. By doing so, the generator is trained to translate the intermediate samples rather than simply memorizing the training set, leading to improved generalization by the discriminator. This approach effectively reduces generation ambiguity and produces results that preserve the content of the input image. The ReMix method can be easily integrated into existing GAN models with minor modifications. Experimental results across various tasks demonstrate that GAN models equipped with the ReMix method achieve significant improvements in performance.