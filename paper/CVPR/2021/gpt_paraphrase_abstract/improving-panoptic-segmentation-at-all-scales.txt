Crop-based training methods allow the use of large panoptic segmentation networks on high-resolution images without increasing GPU memory consumption. However, these methods may result in truncated or missing large objects. To address this issue, we propose a new crop-aware bounding box regression loss (CABB loss) that encourages predictions to align with the visible parts of cropped objects while not penalizing them excessively for extending beyond the crop. Additionally, we introduce a novel data sampling and augmentation strategy that improves the model's ability to generalize across different object sizes by balancing the distribution of object sizes. By combining these contributions with a carefully designed top-down panoptic segmentation architecture, we achieve state-of-the-art results on challenging datasets including Mapillary Vistas, Indian Driving, and Cityscapes. Our approach outperforms the previous best method on Mapillary Vistas by 4.5% in PQ and 5.2% in mAP.