Deploying deep convolutional neural networks on low-power systems is challenging due to limited resources, particularly in terms of memory. The size of on-chip memory is restricted, causing a bottleneck, especially as lower layers experience significant memory explosion even in small models. Consequently, the accuracy of the system is compromised, as the input image size must be reduced to overcome this limitation. To address this issue, we propose a new approach called RaScaNet, inspired by raster-scanning in image sensors. RaScaNet utilizes a convolutional neural network to read a few rows of pixels at a time and then employs a recurrent neural network to sequentially learn the representation of the entire image. Our method operates on ultra-low power systems without reducing the input size and requires significantly smaller peak and weight memory compared to existing tiny models. Specifically, RaScaNet achieves a peak memory reduction of 15.9-24.3 times and a weight memory reduction of 5.3-12.9 times. Moreover, it fully utilizes on-chip SRAM and cache memory, with the combined peak and weight memory not exceeding 60 KB, thereby enhancing the power efficiency of the system. We conducted experiments on the Visual Wake Words and Pascal VOC datasets to demonstrate the binary classification performance of RaScaNet.