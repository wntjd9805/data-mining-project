Zero-shot learning (ZSL) is a method that aims to recognize new classes by transferring semantic knowledge from known classes. This knowledge is built on shared attributes between different classes. Strong localization of object attributes is important for visual-semantic embedding. Interestingly, when humans recognize unseen images, they automatically focus on regions with specific semantic clues. To improve attribute localization in ZSL, we introduce a novel module called goal-oriented gaze estimation (GEM). GEM predicts the actual human gaze location to determine the visual attention regions for recognizing a novel object based on attribute descriptions. The task-dependent attention is learned using GEM, while simultaneously optimizing global image features through regression of local attribute features. Our proposed method outperforms state-of-the-art ZSL methods on three benchmark datasets (CUB, SUN, and AWA2). Ablation analysis using real gaze data (CUB-VWSW) validates the accuracy and benefits of our gaze estimation module. This work highlights the potential benefits of collecting human gaze datasets and developing automatic gaze estimation algorithms for high-level computer vision tasks. The code for our method is available at https://github.com/osierboy/GEM-ZSL.