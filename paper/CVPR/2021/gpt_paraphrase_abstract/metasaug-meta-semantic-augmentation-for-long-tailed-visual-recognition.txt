The imbalance in real-world training data, where some classes have significantly more samples than others, hinders the performance of supervised learning algorithms. To address this issue, we propose augmenting minority classes using the implicit semantic data augmentation (ISDA) algorithm. However, ISDA's estimation of class-conditional statistics is ineffective for minority classes due to limited training data. To overcome this, we introduce a novel approach that learns transformed semantic directions through meta-learning. During training, the augmentation strategy is dynamically optimized to minimize loss on a small balanced validation set. Our method is empirically validated on CIFAR-LT-10/100, ImageNet-LT, and iNaturalist 2017/2018 datasets, demonstrating its effectiveness.