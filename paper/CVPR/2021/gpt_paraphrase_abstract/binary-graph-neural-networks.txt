Graph Neural Networks (GNNs) have become a popular method for learning representations on irregular data. However, they face similar implementation challenges as classical Convolutional Neural Networks (CNNs), such as large model sizes, high memory usage, and energy consumption. To address these concerns, network binarization has been proposed to significantly reduce memory requirements and leverage fast SIMD instructions for speed improvements. While binarization has been extensively studied for CNNs, its application to geometric deep learning, specifically GNNs, remains largely unexplored. In this study, we explore various strategies for binarizing GNNs and evaluate their performance on challenging benchmarks. We demonstrate that with careful model design and training process control, binary GNNs can be trained with only a moderate decrease in accuracy. Additionally, we introduce the first dynamic graph neural network in Hamming space, which utilizes efficient k-NN search on binary vectors to accelerate dynamic graph construction. We also show that the use of binary models offers significant memory savings on embedded devices. The code for our research is publicly available on Github.