Compared to detecting and describing feature points, the detection and matching of line segments present additional challenges. However, line features offer valuable advantages for multi-view tasks, as they are well-defined by the image gradient, often appear even in poorly textured areas, and provide robust structural cues. In this study, we propose the first deep network that jointly detects and describes line segments. Our method is trained in a self-supervised manner, eliminating the need for annotated line labels and allowing for generalization to any dataset. Our detector accurately and consistently localizes line segments in images, deviating from the traditional wireframe parsing approach. Additionally, our line descriptor, which takes advantage of recent advancements in descriptor learning, is highly discriminative and resistant to changes in viewpoint and occlusions. We evaluate our approach on multiple multi-view datasets, including those created with homographic warps and real-world viewpoint changes. Our complete pipeline achieves higher repeatability, localization accuracy, and matching metrics compared to previous line detection and description methods, representing an initial step towards bridging the gap with learned feature points methods. The code and trained weights for our approach are publicly available at https://github.com/cvg/SOLD2.