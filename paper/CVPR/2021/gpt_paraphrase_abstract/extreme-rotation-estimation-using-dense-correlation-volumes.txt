We introduce a technique to estimate the relative 3D rotation of RGB image pairs in situations where there is minimal or no overlap between the images. Although there is no overlap, we have discovered that there are hidden clues in the images that reveal their geometric relationship, such as the direction of the light source, vanishing points, and symmetries in the scene. To capture these implicit cues, we propose a network design that compares all pairs of points between the two input images and learns from them. This allows us to construct dense feature correlation volumes and use them to predict the relative 3D rotations. By discretizing the rotations finely, we avoid the challenges associated with directly regressing 3D rotations. We evaluate our method on a wide range of extreme RGB image pairs, including indoor and outdoor images taken under different lighting conditions and locations. The results show that our model successfully estimates relative rotations among non-overlapping images without compromising its performance on overlapping image pairs.