We introduce a method for image translation called full-resolution correspondence learning for cross-domain images. Our approach uses a hierarchical strategy, where correspondence at coarser levels guides the finer levels. We efficiently compute the correspondence at each hierarchy using PatchMatch, which iteratively leverages matchings from the neighborhood. To refine the correspondence, we employ the ConvGRU module within each PatchMatch iteration. This module considers both the matchings of larger context and the historic estimates. Our proposed approach, Co-CosNet v2, is a fully differentiable and highly efficient PatchMatch approach assisted by GRU. By training it jointly with image translation, we can establish full-resolution semantic correspondence in an unsupervised manner, which helps in exemplar-based image translation. Experimental results on various translation tasks demonstrate that CoCosNet v2 outperforms state-of-the-art literature in producing high-resolution images.