This study addresses the lack of research on the impact of light beams emitted from physical sources as adversarial attacks on deep neural networks (DNNs) in real-world scenarios. The researchers demonstrate that DNNs can be easily deceived using a laser beam. They propose a new attack method called Adversarial Laser Beam (AdvLB), which manipulates the physical parameters of the laser beam to perform the adversarial attack. The effectiveness of this approach is demonstrated through experiments conducted in both digital and physical settings. The evaluation results reveal interesting prediction errors in state-of-the-art DNNs caused by the proposed laser beam attack. The AdvLB method enriches the existing family of adversarial attacks and lays the groundwork for future studies on the robustness of light-based attacks.