This paper presents a framework for compressing deep neural network (DNN) models using tensor decomposition, specifically the tensor train (TT) and tensor ring (TR) methods. While TT/TR compression has been successful for recurrent neural networks (RNNs), it has not been effective for convolutional neural networks (CNNs) due to significant accuracy loss. To address this issue, the authors propose a systematic approach using the Alternating Direction Method of Multipliers (ADMM). The framework formulates TT decomposition as an optimization problem with constraints on tensor ranks and solves it iteratively using ADMM. Unlike previous methods, the entire DNN model is trained in its original structure and gradually acquires low tensor rank characteristics. The uncompressed model is then decomposed into TT format and fine-tuned to achieve a high-accuracy TT-format DNN model. The framework is applicable to both CNNs and RNNs and can be adapted for other tensor decomposition approaches. Experimental results on image classification and video recognition tasks demonstrate the effectiveness of the ADMM-based TT-format models, achieving high compression performance without sacrificing accuracy. Notably, on CIFAR-100, the models achieve higher top-1 accuracy than the original ResNet-20 and ResNet-32 models, with compression ratios of 2.3ˆ and 2.4ˆ, respectively. Additionally, the proposed framework achieves a 2.47ˆ reduction in FLOPs without accuracy loss when compressing ResNet-18 on ImageNet.