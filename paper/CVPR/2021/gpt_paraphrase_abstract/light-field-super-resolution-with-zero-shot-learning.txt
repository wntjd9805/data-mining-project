Deep learning has emerged as a promising approach for enhancing the resolution of light field images. However, a significant challenge arises due to the substantial differences in the conditions under which light field data is acquired. To address this issue, we propose a zero-shot learning framework that can improve the resolution of a reference view using examples solely extracted from the input low-resolution light field. Despite the limited training data available in the zero-shot setting, training an end-to-end network proves to be difficult. Therefore, we break down the task into three sub-tasks: pre-upsampling, view alignment, and multi-view aggregation. Each sub-task is tackled separately using simple yet efficient convolutional neural networks (CNNs). Additionally, our framework can be easily extended to fine-tune the pre-trained model on a source dataset, enabling better adaptation to the target input and further enhancing the performance of light field super-resolution. Experimental results demonstrate that our method not only outperforms traditional non-learning-based approaches but also exhibits superior generalization to unseen light fields compared to state-of-the-art deep-learning-based methods when faced with significant domain gaps.