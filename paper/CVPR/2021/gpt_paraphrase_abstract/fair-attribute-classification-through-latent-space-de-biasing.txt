The issue of fairness in visual recognition is gaining importance as recognition systems are widely used in real-world applications. When models are trained using data where certain labels are associated with protected attributes like gender or race, they tend to learn and exploit these correlations. To address this, we propose a method that trains accurate target classifiers while reducing biases resulting from these correlations. Our approach involves using Generative Adversarial Networks (GANs) to generate realistic images, which are then modified in the latent space to create balanced training data for each protected attribute. By augmenting the original dataset with this generated data, we show through empirical evaluation that the target classifiers trained on the augmented dataset offer several benefits, both quantitatively and qualitatively. We extensively evaluate our approach on the CelebA dataset, considering multiple target labels and protected attributes, and provide a detailed analysis and comparison with existing research in this area. The code for our method can be accessed at https://github.com/princetonvisualai/gan-debiasing.