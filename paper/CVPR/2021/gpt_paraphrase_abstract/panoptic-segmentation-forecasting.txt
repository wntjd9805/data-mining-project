Our objective is to predict the near future based on recent observations, which we believe is crucial for the success of autonomous agents. These agents must not only passively analyze observations but also react to them in real-time. The accuracy of our predictions relies on how we decompose a dynamic scene into individual objects and background elements. The background elements primarily move due to camera motion, while the individual objects move due to both camera and object motion. To achieve better predictions, we introduce panoptic segmentation forecasting, which strikes a balance between forecasting instance trajectories and predicting future image frames. To tackle this task, we develop a two-component model: one component learns the dynamics of the background elements by anticipating odometry, while the other component anticipates the dynamics of detected objects. We establish a leaderboard for this new task and validate a state-of-the-art model that outperforms existing baselines.