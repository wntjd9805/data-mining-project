Visual Question Answering (VQA) models are often criticized for relying on dataset biases and performing "educated guesses" instead of reasoning. The standard evaluation metric, which measures overall in-domain accuracy, is misleading because it favors models that exploit subtle training set statistics. Introducing artificial distribution shifts between train and test splits is not satisfactory either, as it does not reflect real-world tendencies and limits model generalization. To address these concerns, we propose the GQA-OOD benchmark. This benchmark measures accuracy for both rare and frequent question-answer pairs, with a focus on evaluating reasoning abilities. We experimentally validate this approach by training models to exploit biases to varying degrees. In a large-scale study involving 7 VQA models and 3 bias reduction techniques, we demonstrate that these models struggle with infrequent concepts. We provide recommendations for future research directions.