This paper introduces a new approach called cross-view cross-scene (CVCS) multi-view crowd counting, which addresses the limitations of current multi-view paradigms. The CVCS model trains and tests on different scenes with arbitrary camera layouts, allowing for practical application in various scenarios. To handle challenges such as view fusion, non-correspondence noise, and camera calibration errors, the CVCS model selectively combines multiple views using camera layout geometry and employs a noise view regularization method. Additionally, a synthetic multi-camera crowd counting dataset is generated, eliminating the need for collecting and annotating a large real dataset. The trained CVCS model, using unsupervised domain transfer, outperforms models trained solely on real data and shows promising results compared to fully supervised methods.