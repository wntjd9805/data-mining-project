We investigate the problem of evaluating the accuracy of computer vision models on unlabeled test data, which is a common issue in real-world scenarios. We propose a solution called Automatic model Evaluation (AutoEval) that aims to estimate the classification accuracy of a model on unlabeled test datasets. To do this, we create a meta-dataset consisting of datasets generated from the original images using various transformations. By knowing the classification accuracy of the model on each sample in the original dataset, we can use regression to solve our task. We train regression models, such as a regression neural network, using feature statistics to represent the distribution of a dataset. Through training and testing on synthetic meta-datasets and real-world datasets, respectively, we achieve a reasonable and promising prediction of the model accuracy. We also discuss the scope, limitations, and potential future directions of AutoEval.