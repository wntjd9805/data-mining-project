We introduce FFB6D, a novel Full Flow Bidirectional fusion network for 6D pose estimation using a single RGBD image. Our approach combines appearance information from the RGB image and geometry information from the depth image, recognizing their complementary nature. FFB6D integrates these two data sources by fusing them at each encoding and decoding layer, allowing the networks to leverage local and global information from one another to enhance representation learning. Additionally, we propose a simple and effective algorithm for selecting 3D keypoints based on texture and geometry information, simplifying the localization process for accurate pose estimation. Our experimental results demonstrate that FFB6D outperforms existing state-of-the-art methods on various benchmarks. The code and video for our approach are available at https://github.com/ethnhe/FFB6D.git.   To better understand the contribution of FFB6D, we compare it with the DenseFusion Network. The DenseFusion Network extracts features from different data modalities separately, without any communication, until the final layers of the encoding-decoding architecture. In contrast, our proposed FFB6D incorporates bidirectional fusion modules as bridges for information communication throughout the entire network, enabling fusion at each encoding and decoding layer. This allows for the sharing of local and global supplementary information between the appearance and geometry networks, resulting in improved representation learning for 6D pose estimation. See Figure 1 for a visual comparison of the two networks.