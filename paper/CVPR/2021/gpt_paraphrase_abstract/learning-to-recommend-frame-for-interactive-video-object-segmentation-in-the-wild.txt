This paper presents a framework for interactive video object segmentation (VOS) in real-world scenarios. The framework allows users to select frames for annotations, which are then used by a segmentation algorithm to refine the masks. Previous interactive VOS methods typically select the frame with the worst evaluation metric, but this approach requires ground truth data during testing, which is not practical. In contrast, this paper proposes a Markov Decision Process approach, where a deep reinforcement learning framework trains an agent to recommend frames based on their potential for performance improvement. This approach automates the frame selection process and makes interactive VOS more feasible in real-world settings. Experimental results demonstrate the effectiveness of the learned agent without modifying the underlying VOS algorithms. The data, code, and models associated with this work are available at the provided GitHub link.