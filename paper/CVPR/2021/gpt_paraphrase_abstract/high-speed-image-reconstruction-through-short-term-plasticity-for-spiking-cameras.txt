The fovea, located in the center of the retina, is responsible for high-acuity vision. To mimic its sampling mechanism, a retina-inspired camera called the spiking camera has been developed. This camera records external information at a sampling rate of 40,000 Hz and outputs asynchronous binary spike streams. However, the challenge lies in reconstructing the scenes captured by this camera. In this study, we propose a novel high-speed image reconstruction model that utilizes the short-term plasticity (STP) mechanism of the brain. By establishing the STP model at each pixel of the spiking camera, we can infer the scene radiance based on the firing frequency of each pixel. Additionally, we demonstrate that STP can be used to distinguish static and motion areas, further improving the reconstruction results. Our experimental results show that our methods achieve state-of-the-art performance in terms of both image quality and computing time. The working mechanisms of traditional cameras, event cameras, and spiking cameras are illustrated in Figure 1. Traditional cameras capture images at a constant frame rate, event cameras generate asynchronous events for all pixels when there is a significant change in brightness, and spiking cameras continuously capture photons and generate asynchronous spikes for all pixels when the accumulated intensity reaches a predefined threshold.