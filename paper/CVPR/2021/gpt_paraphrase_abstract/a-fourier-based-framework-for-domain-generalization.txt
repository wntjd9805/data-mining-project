This paper presents a new approach to domain generalization for deep neural networks. Domain generalization addresses the issue of performance degradation when models are tested on data that differs from the training data. The proposed method takes a Fourier-based perspective, assuming that the Fourier phase information contains important semantic details that are not easily affected by domain shifts. To ensure the model captures this phase information, a novel data augmentation strategy called amplitude mix is introduced, which interpolates between the amplitude spectrums of two images. Additionally, a consistency loss called co-teacher regularization is introduced to align the predictions from original and augmented images. Extensive experiments on three benchmarks show that the proposed method achieves state-of-the-art performance in domain generalization.