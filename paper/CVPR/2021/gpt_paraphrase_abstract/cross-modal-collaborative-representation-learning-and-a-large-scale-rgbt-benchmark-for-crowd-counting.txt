Crowd counting is a challenging task that requires comprehensive information to accurately estimate crowd density. However, previous methods have primarily relied on RGB images and struggled to identify pedestrians in diverse environments. This study demonstrates that combining optical and thermal information significantly improves pedestrian recognition. To support future research in this domain, the authors introduce a large-scale benchmark dataset called RGBT Crowd Counting (RGBT-CC), consisting of 2,030 pairs of RGB-thermal images with 138,389 annotated people. Additionally, they propose a cross-modal collaborative representation learning framework for multimodal crowd counting. This framework includes modality-specific branches, a modality-shared branch, and an Information Aggregation-Distribution Module (IADM) to fully leverage complementary information from different modalities. The IADM incorporates two collaborative information transfers to enhance both shared and specific representations through a dual information propagation mechanism. Extensive experiments on the RGBT-CC benchmark demonstrate the effectiveness of the proposed framework for RGBT crowd counting. Furthermore, the approach achieves superior performance on the ShanghaiTechRGBD dataset. The authors have released their source code and benchmark at a specified website.