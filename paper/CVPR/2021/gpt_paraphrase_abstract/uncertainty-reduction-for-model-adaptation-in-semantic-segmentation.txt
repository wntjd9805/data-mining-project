Traditional approaches to Unsupervised Domain Adaptation (UDA) for semantic segmentation typically rely on utilizing both labeled source data and unlabeled target data to identify common information between the two domains. However, in certain scenarios where data sharing is restricted due to privacy or Intellectual Property (IP) concerns, the source data may be unavailable while the classifier trained on that data is still accessible. In this paper, we explore this "model adaptation" setting.To address this challenge, we propose a method that aims to decrease the uncertainty of predictions on the target domain data. We achieve this by minimizing the entropy of the predicted posterior and maximizing the resilience of the feature representation against noise. Our method demonstrates its effectiveness in transferring segmentation from computer-generated images to real-world driving images, as well as transferring between datasets collected in different cities. Surprisingly, our approach achieves comparable performance to methods that have access to the source data.In summary, our research focuses on Unsupervised Domain Adaptation for semantic segmentation in a scenario where the source data cannot be accessed but the trained classifier can. We introduce a method that reduces prediction uncertainty by minimizing entropy and enhancing noise robustness in the feature representation. Our experiments demonstrate the efficacy of our approach in various transfer scenarios, achieving performance similar to methods with source data access.