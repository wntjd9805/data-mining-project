We propose a new method for addressing partially observable goal-driven tasks, such as goal-driven visual navigation, using a two-layer hierarchical reinforcement learning approach with a Goals Relational Graph (GRG). The GRG captures the relationships between goals in the goal space using a Dirichlet-categorical process. This enables our approach to: 1) enable the high-level network to generate sub-goals in order to achieve a final goal; 2) guide the low-level network towards an optimal policy; and 3) generalize to unseen environments and goals. We evaluate our approach on both a grid-world domain and a robotic object search task. Our experimental results demonstrate that our approach achieves better generalization performance in terms of both unseen environments and new goals.