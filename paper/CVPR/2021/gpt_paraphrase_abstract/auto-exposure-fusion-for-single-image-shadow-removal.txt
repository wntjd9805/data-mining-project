Shadow removal remains a difficult task due to the nature of shadows, which are dependent on the background and vary spatially, resulting in diverse and unknown shadow patterns. Even advanced deep neural networks struggle to completely remove shadows without leaving any traces. In this paper, we propose a novel solution to this challenge by treating it as an exposure fusion problem. Firstly, we estimate multiple over-exposure images based on the input image in order to match the color of shadow regions in these images with the shadow-free areas in the input image. We then fuse the original input with these over-exposure images to generate the final shadow-free output. However, the spatial variation of shadows requires the fusion process to be intelligent, automatically selecting appropriate over-exposure pixels from different images to ensure a natural-looking final result. To address this issue, we introduce the shadow-aware FusionNet, which takes the shadow image as input and generates fusion weight maps for all the over-exposure images. Additionally, we propose the boundary-aware RefineNet to further eliminate any remaining traces of shadows. We have conducted extensive experiments using the ISTD, ISTD+, and SRD datasets to demonstrate the effectiveness of our method. Our approach outperforms state-of-the-art methods in shadow regions and achieves comparable performance in non-shadow regions. The code for our method is available at https://github.com/tsingqguo/exposure-fusion-shadow-removal.