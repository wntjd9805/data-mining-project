Despite the recent success of deep neural networks, effectively modeling the distribution of long-tail classes in visual recognition tasks remains challenging. To address this issue, we conducted an ablative study to identify the performance bottleneck of the two-stage learning framework. Based on our findings, we propose a unified distribution alignment strategy for long-tail visual recognition.  Our approach involves developing an adaptive calibration function that allows us to adjust the classification scores for each data point. Additionally, we introduce a generalized re-weight method in the two-stage learning process to balance the class prior. This approach offers a flexible and unified solution for various scenarios in visual recognition tasks.  To validate our method, we conducted extensive experiments on four tasks: image classification, semantic segmentation, object detection, and instance segmentation. The results demonstrate that our approach achieves state-of-the-art performance in all four recognition tasks, utilizing a simple and unified framework.