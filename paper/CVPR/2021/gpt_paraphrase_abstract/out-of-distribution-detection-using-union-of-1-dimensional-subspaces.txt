The aim of out-of-distribution (OOD) detection is to handle situations where the test samples come from a different distribution than the training data. This study argues that OOD samples can be more easily detected by embedding the training data into a low-dimensional space, where the embedded training samples lie on a collection of 1-dimensional subspaces. This embedding of in-distribution (ID) samples offers two main advantages. Firstly, because of the compact representation in the feature space, OOD samples are less likely to occupy the same region as the known classes. Secondly, the first singular vector of ID samples belonging to a 1-dimensional subspace can serve as a robust representative. Motivated by these observations, a deep neural network is trained to embed the ID samples onto a union of 1-dimensional subspaces. During testing, approximate Bayesian inference sampling techniques are employed to detect input samples as OOD if they occupy the region corresponding to the ID samples with a probability of 0. The robust representatives of this region are the spectral components of the ID samples. This method does not require tuning hyperparameters using additional information and can be applied to different modalities with minimal modifications. The effectiveness of the proposed approach is demonstrated on various benchmark datasets in both image and video classification domains.