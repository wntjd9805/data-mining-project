The Feature Pyramid Network (FPN) is a well-known architecture for creating a feature pyramid that captures high-level semantic information. However, FPN has limitations in extracting and combining discriminative features, preventing it from effectively incorporating more useful features. To address this issue, we propose a new approach called Attention Aggregation based Feature Pyramid Network (A2-FPN) that improves multi-scale feature learning through attention-guided feature aggregation. In feature extraction, A2-FPN collects and distributes multi-level global context features to extract discriminative features while minimizing the loss of semantic information caused by reduced channels. In feature fusion, A2-FPN aggregates complementary information from adjacent features to create location-wise reassembly kernels for content-aware sampling. It also applies channel-wise reweighting to enhance semantic consistency before combining the features. A2-FPN consistently improves the performance of various instance segmentation frameworks. When replacing FPN with A2-FPN in Mask R-CNN, our model achieves a 2.1% and 1.6% increase in mask average precision (mask AP) when using ResNet-50 and ResNet-101 as the backbone, respectively. Additionally, integrating A2-FPN into strong baselines like Cascade Mask R-CNN and Hybrid Task Cascade leads to a 2.0% and 1.4% improvement in mask AP.