The problem of predicting human trajectories in crowds can be seen as a sequence prediction challenge that involves capturing the interactions between individuals and predicting socially-compliant distributions. While neural network-based methods have shown better performance compared to traditional methods based on distance metrics, they lack interpretability. To address this limitation, we combine the interpretability of discrete choice models with the expressive power of neural networks. By learning interpretable rule-based intents using discrete choice models and incorporating them into neural networks to model scene-specific residuals, we can explain the predictions while maintaining accuracy. Through extensive experimentation on the TrajNet++ benchmark, we demonstrate the effectiveness of our proposed architecture in providing explanations without compromising accuracy.