Learning computational models of image aesthetics can have a significant impact on the field of visual art and graphic design. While automatic image aesthetics assessment is challenging due to its subjective nature, studies have confirmed a strong correlation between image layouts and perceived image quality. Previous methods have utilized deep Convolutional Neural Networks (CNNs) to learn holistic information, but we propose using Graph Convolutional Network (GCN) architecture, which is better suited for modeling complex relations among image regions. Our approach, called Hierarchical Layout-Aware Graph Convolutional Network (HLA-GCN), aims to capture layout information. HLA-GCN is a dedicated double-subnet neural network consisting of two LA-GCN modules. The first module constructs an aesthetics-related graph in the coordinate space and performs reasoning over spatial nodes. The second module performs graph reasoning after aggregating significant regions in a latent space. The model generates a hierarchical representation with layout-aware features from both spatial and aggregated nodes for unified aesthetics assessment. Our proposed model outperforms state-of-the-art methods on the AVA and AADB datasets across three different tasks, as demonstrated by extensive evaluations. The code for our model is available at http://github.com/days1011/HLAGCN.