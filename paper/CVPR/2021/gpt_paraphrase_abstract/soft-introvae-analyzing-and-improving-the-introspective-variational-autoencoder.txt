The Introspective Variational Autoencoder (IntroVAE) has been praised for its exceptional image generation capabilities and its ability to use an image encoder for efficient inference. However, the original loss function of IntroVAE relied on a problematic hinge-loss formulation that was difficult to stabilize in practice, and its theoretical convergence analysis overlooked important components of the loss. To address these issues, we present the Soft-IntroVAE, a modified version of IntroVAE that replaces the hinge-loss terms with a smooth exponential loss on generated samples. This modification greatly improves training stability and allows for a comprehensive theoretical analysis of the algorithm. Surprisingly, we discover that IntroVAE converges to a distribution that minimizes the sum of the Kullback-Leibler distance from the data distribution and an entropy term. We discuss the implications of this finding and demonstrate that it leads to competitive image generation and reconstruction. Additionally, we showcase the application of Soft-IntroVAE in unsupervised image translation and present compelling results. More information, including code, can be found on our project website - taldatech.github.io/soft-intro-vae-web.