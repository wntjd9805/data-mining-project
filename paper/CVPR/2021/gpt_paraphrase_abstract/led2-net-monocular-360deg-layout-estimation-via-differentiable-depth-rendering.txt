Most existing methods for room layout estimation focus on minimizing loss in 2D pixel coordinates rather than utilizing the room's 3D structure. To address this limitation, we propose a new approach to reconstructing room layouts in 3D. We define the task as predicting depth along the horizon line of a panorama and introduce the DifferentiableDepth Rendering procedure to make the conversion from layout to depth prediction differentiable. This allows our model to be trained end-to-end, leveraging the 3D geometric information without requiring ground truth depth. Our method outperforms other approaches on various 360Â° layout benchmark datasets. Additionally, our formulation enables a pre-training step on the depth dataset, enhancing the generalizability of our layout estimation model.