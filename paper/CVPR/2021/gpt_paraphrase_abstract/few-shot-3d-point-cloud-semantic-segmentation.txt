Many current methods for segmenting 3D point clouds into semantic categories rely on fully supervised learning, which requires a large amount of labeled training data. However, obtaining such data is challenging and these methods are unable to segment new classes after training. In order to address these limitations, we propose a new approach called attention-aware multi-prototype transductive few-shot point cloud semantic segmentation. This method is able to segment new classes using only a few labeled examples. Each class is represented by multiple prototypes to capture the complex distribution of labeled points. We then use a transductive label propagation method to leverage the relationships between labeled multi-prototypes and unlabeled points, as well as among the unlabeled points themselves. Additionally, we introduce an attention-aware multi-level feature learning network to extract discriminative features that capture both the geometric dependencies and semantic correlations between points. Our proposed method demonstrates significant and consistent improvements compared to baseline approaches in various few-shot point cloud semantic segmentation scenarios, including 2/3-way 1/5-shot settings, on two benchmark datasets. The code for our method is available at https://github.com/Na-Z/attMPTI.