We present a new task called dense captioning in 3D scans using RGB-D sensors. Our goal is to generate bounding boxes and descriptions for objects in a 3D scene represented as a point cloud. To address the challenges of 3D object detection and description, we propose Scan2Cap, an end-to-end trained method. Scan2Cap uses an attention mechanism to generate descriptive tokens, taking into account the local context. To capture object relations, we incorporate a message passing graph module to learn object relation features. Our method outperforms 2D baseline methods on the ScanRefer dataset, achieving a significant improvement in localization and description of 3D objects (27.61% CiDEr@0.5IoU improvement).