We present two challenging datasets that significantly decrease the performance of machine learning models. These datasets are created using an adversarial filtering technique to minimize the presence of misleading cues. The examples in our datasets consistently transfer to different models, indicating shared weaknesses among computer vision models. The first dataset, IMAGENET-A, is more difficult than the ImageNet test set, posing a greater challenge for existing models. Additionally, we curate IMAGENET-O, an adversarial out-of-distribution detection dataset specifically designed for ImageNet models. On IMAGENET-A, a DenseNet-121 model achieves only 2% accuracy, a drastic drop of approximately 90%, and its out-of-distribution detection performance on IMAGENET-O is close to random chance. We observe that common data augmentation techniques have limited impact on performance improvement, and incorporating other publicly available training datasets offers minimal enhancements. However, we discover that enhancing computer vision architectures shows promise in developing robust models.