This paper addresses the challenge of effectively incorporating linguistic rules into end-to-end deep networks for scene text recognition. The authors argue that the limited capacity of language models in these networks is due to implicit language modeling, unidirectional feature representation, and language models with noise input. To overcome these limitations, the authors propose an autonomous, bidirectional, and iterative ABINet for scene text recognition.The autonomous aspect of ABINet involves blocking the gradient flow between the vision and language models to explicitly enforce language modeling. This allows for a more effective integration of linguistic knowledge into the network. To address the issue of unidirectional feature representation, the authors introduce a novel bidirectional cloze network (BCN) as the language model. This BCN utilizes bidirectional feature representation to capture a more comprehensive understanding of the text.In order to mitigate the impact of noise input, the authors propose an iterative correction method for the language model. This approach improves the accuracy of the model by iteratively refining its predictions based on the input.Additionally, the authors propose a self-training method based on the ensemble of iterative predictions. This method allows the network to learn from unlabeled images effectively, further enhancing its performance.Extensive experiments demonstrate the superiority of ABINet on low-quality images and its state-of-the-art performance on several mainstream benchmarks. Moreover, the ABINet trained with ensemble self-training shows promising improvement in achieving human-level recognition.The code for ABINet is available at https://github.com/FangShancheng/ABINet.