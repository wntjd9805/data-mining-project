We present a novel unsupervised approach to detect and track moving objects in unlabelled RGB-D videos in 3D. Our method combines traditional handcrafted techniques with deep learning algorithms. Initially, we use motion cues such as optical flow and camera motion to segment regions that appear to be moving independently from the background. These initial segments are considered as pseudo-labels. We then train an ensemble of appearance-based 2D and 3D detectors using heavy data augmentation. This ensemble helps us detect new instances of moving objects, even if they are not actually moving, which are then added as new pseudo-labels. Our method follows an expectation-maximization algorithm, where we evaluate the agreement among all modules during the expectation step and retrain the modules to improve this agreement during the maximization step. By enforcing ensemble agreement, we mitigate contamination of the generated pseudo-labels, and through data augmentation, the modules can generalize to unlabelled data. We evaluate our method against existing unsupervised object discovery and tracking techniques using challenging videos from CATER and KITTI datasets. Our results demonstrate significant improvements over the current state-of-the-art methods.