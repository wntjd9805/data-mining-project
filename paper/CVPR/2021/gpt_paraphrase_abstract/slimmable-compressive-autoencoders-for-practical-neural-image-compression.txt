Neural image compression using deep neural networks has proven to be more effective than traditional image codecs in terms of rate-distortion performance. However, these models are often heavy, computationally intensive, and optimized for a specific rate, which limits their practical use. To address this limitation, we propose a new approach called slimmable compressive autoencoders (SlimCAEs) for practical image compression. With SlimCAEs, the rate and distortion are jointly optimized for different capacities, allowing the encoders and decoders to be executed at varying capacities, resulting in different rates and complexities. We demonstrate that successful implementation of SlimCAEs requires appropriate capacity-specific tradeoffs between rate and distortion. Our experiments show that SlimCAEs are highly flexible models that offer excellent rate-distortion performance, variable rate control, and the ability to dynamically adjust memory, computational cost, and latency. As a result, SlimCAEs meet the main requirements of practical image compression.