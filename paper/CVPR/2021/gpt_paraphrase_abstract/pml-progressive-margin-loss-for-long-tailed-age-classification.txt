This paper introduces a new approach called progressive margin loss (PM-L) for unconstrained facial age classification. Traditional methods assume that each age class has enough instances to accurately represent its data distribution, but this can lead to biased predictions when there are few training samples for certain age classes. In contrast, PM-L aims to refine the age label pattern by considering the differences in intra-class variance, inter-class variance, and class center. PM-L combines the ordinal margin and the variational margin, and is integrated into a deep neural network framework. The ordinal margin captures the correlated relationship between real-world age labels, while the variational margin reduces the influence of head classes that may mislead predictions for tail samples. The optimization process also incorporates indicator curricula to improve model training. Experimental results on three face aging datasets demonstrate that PM-L outperforms state-of-the-art methods. The code for PM-L will be made publicly available.