Image compositing often results in a lack of harmony due to the mismatch between the foreground and background of two different images, which have distinct surfaces and lighting conditions. This mismatch is attributed to the differences in reflectance and illumination intrinsic images. In order to address this issue, we propose a method called intrinsic image harmonization, which aims to separate and harmonize the reflectance and illumination components of the composite image. Our approach utilizes an autoencoder to disentangle the composite image into reflectance and illumination, enabling separate harmonization. We achieve reflectance harmonization by enforcing material consistency, and illumination harmonization by learning and transferring light from the background to the foreground. Additionally, we model the patch relations between the foreground and background in a way that avoids inharmonious learning, providing adaptive guidance for intrinsic image harmonization. Extensive experiments and ablation studies demonstrate the effectiveness of our method and validate the efficacy of each component. Furthermore, we contribute a new challenging dataset for benchmarking illumination harmonization. The code and dataset for our method are available at https://github.com/zhenglab/IntrinsicHarmony.