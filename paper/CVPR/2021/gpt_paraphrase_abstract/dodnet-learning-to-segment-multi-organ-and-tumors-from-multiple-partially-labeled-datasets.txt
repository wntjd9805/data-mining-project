Most benchmark datasets for 3D medical image segmentation only have annotations for one type of organ or tumor, leading to a partially labeling issue. To address this, we propose a dynamic on-demand network called DoDNet. DoDNet consists of an encoder-decoder architecture, a task encoding module, a controller for dynamic filter generation, and a dynamic segmentation head. The current segmentation task is encoded as a task-aware prior to guide the model. Unlike existing approaches, the kernels in the dynamic head are generated adaptively by the controller based on the input image and task. This allows DoDNet to efficiently and flexibly segment multiple organs and tumors. We created a large-scale partially labeled dataset called MOTS and demonstrated the superior performance of DoDNet compared to other methods on seven organ and tumor segmentation tasks. We also transferred the weights pre-trained on MOTS to a downstream multi-organ segmentation task and achieved state-of-the-art results. Our study provides a general 3D medical image segmentation model pre-trained on a large-scale partially labeled dataset, which can be fine-tuned for downstream volumetric medical data segmentation tasks. The code and models are available at the provided link.