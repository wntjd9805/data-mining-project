This study introduces a video denoising method called "restore-from-restored," which utilizes a self-supervised approach. During the test phase, a pre-trained network is fine-tuned using a pseudo clean video obtained by applying noise to the baseline network. Unlike traditional video restoration methods, this approach does not require accurate optical flow estimation and registration steps. By employing a fully convolutional neural network (FCN) as the baseline, the method takes advantage of the FCN's translation equivariant property, allowing it to leverage similar patches across consecutive frames (patch-recurrence) to significantly enhance denoising performance. The study analyzes the restoration performance of the fine-tuned video denoising networks using the proposed self-supervision-based learning algorithm and demonstrates that the FCN can effectively utilize recurring patches without the need for precise registration among adjacent frames. Experimental results using state-of-the-art denoisers validate the effectiveness of the proposed method, showing a substantial improvement in denoising performance.