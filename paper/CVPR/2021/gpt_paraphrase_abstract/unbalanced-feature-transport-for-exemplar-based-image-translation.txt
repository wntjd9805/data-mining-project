This paper addresses the challenge of generating high-quality, realistic images with reference styles in conditional image-to-image translation. While previous methods have successfully used conditioned inputs such as semantic segmentation and edge maps, there is still a need for better feature alignment between these inputs and style exemplars. To overcome this, the authors propose a general image translation framework that incorporates optimal transport. This approach helps to establish accurate semantic correspondences between conditional inputs and exemplars by mitigating the constraint of many-to-one feature matching. Additionally, the authors introduce a novel unbalanced optimal transport method to handle the transport between features with deviational distributions, which are commonly found between conditional inputs and exemplars. Furthermore, they introduce a semantic-activation normalization scheme that successfully incorporates style features of exemplars into the image translation process. Through extensive experiments, the authors demonstrate that their method outperforms state-of-the-art techniques both qualitatively and quantitatively in various image translation tasks.