Existing methods for learning with noisy labels in large-scale datasets often result in unreliable labels that hinder neural networks from fully exploring the data. These methods typically involve noise-cleaning-based and sample-selection-based approaches. However, these approaches have limitations, as they do not fully utilize all data points and fail to represent the actual distribution of categories, especially when label annotation is corrupted. To address this issue, we propose a robust learning algorithm called DualGraph, which leverages graph neural networks to capture structural relations among labels at two levels: instance-level and distribution-level relations. The instance-level relation characterizes sample category based on instance similarity, while the distribution-level relation describes the distribution of instance similarity across all samples. By considering the robustness of the distribution-level relation to label noise, our network uses it as supervised signals to refine the instance-level similarity. By combining these two level relations, we design an end-to-end training paradigm that counteracts noisy labels and generates reliable predictions. We evaluate our method extensively on the noisy CIFAR-10, CIFAR-100, and Clothing1M datasets. The results demonstrate the superior performance of our proposed method compared to state-of-the-art baselines.