We propose a novel method to determine correspondences between pairs of images taken in challenging conditions such as varying illumination, viewpoint, context, and material. Unlike existing approaches that treat images independently, our method conditions on both images to better account for their differences. We introduce a spatial attention mechanism called CoAM, which allows the learned features to be conditioned on both images. Additionally, we use a distinctiveness score to select the best matches during testing. CoAM can be incorporated into standard architectures and trained using self-supervision or supervised data. It significantly improves performance, especially in difficult scenarios like large viewpoint changes. Our experiments show that models utilizing CoAM achieve state-of-the-art or competitive results in various tasks, including local matching, camera localization, 3D reconstruction, and image stylization.