The popular two-stream network for real-time segmentation, BiSeNet, adds an extra path to encode spatial information, which is time-consuming. Additionally, the backbones borrowed from pretrained tasks, such as image classification, may not be efficient for image segmentation due to the lack of task-specific design. To address these issues, we propose a new and efficient structure called Short-Term Dense Concatenate network (STDC network) by eliminating redundant structures. We gradually reduce the dimension of feature maps and aggregate them for image representation, forming the basic module of the STDC network. In the decoder, we introduce a Detail Aggregation module that integrates the learning of spatial information into low-level layers in a single-stream manner. Finally, we fuse the low-level features and deep features to predict the final segmentation results. Our method achieves a promising trade-off between segmentation accuracy and inference speed, as demonstrated by extensive experiments on the Cityscapes and CamVid datasets. On the Cityscapes dataset, we achieve 71.9% mIoU on the test set at a speed of 250.4 FPS on NVIDIA GTX 1080Ti, which is 45.2% faster than the latest methods. We also achieve 76.8% mIoU with 97.0 FPS when inferring on higher resolution images. The code for our method is available at https://github.com/MichaelFan01/STDC-Seg.