Camera pose estimation in known scenes has been addressed by various learning algorithms, which aim to regress precise geometric quantities from an input image. However, these approaches either fail to generalize to new viewpoints or are limited to specific scenes. In this study, we propose a different approach called PixLoc, which emphasizes the importance of learning robust and invariant visual features using deep networks, while leaving the geometric estimation to principled algorithms. PixLoc is a scene-agnostic neural network that accurately estimates the 6-DoF pose of a camera using an image and a 3D model. Our method achieves this by directly aligning multiscale deep features and treating camera localization as metric learning. By training the network end-to-end, PixLoc learns strong data priors from pixels to pose, resulting in exceptional generalization to new scenes. Additionally, our approach separates model parameters and scene geometry, enabling it to localize in large environments with coarse pose priors and improve the accuracy of sparse feature matching by refining keypoints and poses without significant overhead. The code for PixLoc will be made publicly available on GitHub at github.com/cvg/pixloc.