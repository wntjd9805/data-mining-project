The challenge of obtaining training data with 3D gaze annotations for physically unconstrained gaze estimation in real-world and outdoor settings is addressed in this study. Instead, the focus is on using videos of human interactions in unconstrained environments, which can be easily annotated with frame-level activity labels. The aim is to develop a method for weakly-supervised gaze estimation from these videos. The authors propose leveraging the strong geometric constraints associated with the activity of "looking at each other" (LAEO) to obtain viable 3D gaze supervision. They introduce a training algorithm and novel loss functions specifically designed for this task. By using weak supervision from two large-scale activity datasets, significant improvements are achieved in semi-supervised gaze estimation accuracy and cross-domain generalization on the Gaze360 gaze estimation benchmark. The code for this work is made available as open source.