The effectiveness of the autoregressive context model in improving the rate-distortion performance of learned image compression has been established. This model helps eliminate spatial redundancies among latent representations. However, the decoding process using this model is limited by a strict scan order, preventing parallelization. To address this issue, we propose a parallelizable checkerboard context model (CCM). Our two-pass checkerboard context calculation reorganizes the decoding order, thereby removing limitations on spatial locations. In our experiments, the decoding process is accelerated by more than 40 times, resulting in significantly improved computational efficiency while maintaining almost the same rate-distortion performance. This study represents the first exploration of a parallelization-friendly spatial context model for learned image compression.