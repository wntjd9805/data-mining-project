Label noise in deep neural networks often hinders training accuracy. Previous research assumes that label noise is solely determined by the true class label, but we argue that errors in human-annotated labels are more likely to be influenced by task difficulty, resulting in instance-dependent label noise. We demonstrate that this heterogeneous label noise down-weights examples with higher noise rates in a non-uniform manner, causing imbalances. Therefore, directly applying methods for class-dependent label noise may not be effective. In this study, we propose a second-order approach based on peer loss, which estimates covariance terms between instance-dependent noise rates and the Bayes optimal label. These second-order statistics effectively capture the imbalances induced by label noise. With the help of these statistics, we identify a new loss function that transforms the problem of instance-dependent label noise into one with only class-dependent label noise. This enables us to utilize existing solutions for the better-studied class-dependent label noise setting. We also present an efficient procedure to estimate these second-order statistics without access to ground truth labels or prior knowledge of noise rates. Experimental results on CIFAR10, CIFAR100, and Clothing1M datasets validate the effectiveness of our approach in handling synthetic instance-dependent label noise and real-world human label noise. The implementation of our approach is publicly available at https://github.com/UCSC-REAL/CAL.