We present a new method called POSEFu-sion, which allows for high-quality and dynamic 3D reconstruction of human figures from a single RGBD camera. Our method combines tracking-based methods and tracking-free inference to capture accurate surface details, even in regions that are not directly visible. To achieve this, we introduce a reconstruction framework that includes pose-guided keyframe selection and robust implicit surface fusion. The keyframe selection is formulated as a dynamic programming problem, ensuring smooth transitions between frames. The robust implicit surface fusion incorporates adaptive blending weights to preserve fine surface details and an automatic collision handling method to address potential self-collisions. Our method enables high-fidelity and dynamic capture of both visible and invisible regions, surpassing the performance of existing techniques. The results and experiments demonstrate the superiority of our approach in terms of reconstruction quality.