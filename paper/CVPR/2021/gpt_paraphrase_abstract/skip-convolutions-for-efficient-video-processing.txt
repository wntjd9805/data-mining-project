We propose a method called Skip-Convolutions to reduce computational costs in video streams by exploiting redundancies. Instead of processing every frame, we represent videos as changes across frames and network activations, called residuals. We modify standard convolutions to efficiently compute on residual frames by introducing binary gates that determine whether a residual is important for model predictions or can be skipped. These gates can be implemented as a network trained with convolution kernels or based on the magnitude of the residuals. Additionally, the gating functions can incorporate block-wise sparsity structures for efficient implementation on hardware platforms. By replacing all convolutions with Skip-Convolutions in two state-of-the-art architectures (EfﬁcientDet and HRNet), we consistently reduce computational costs by a factor of 3 to 4× for different tasks without sacrificing accuracy. Extensive comparisons with existing model compression and image/video efficiency methods demonstrate that Skip-Convolutions outperform other approaches by effectively leveraging temporal redundancies in videos.