Semi-supervised learning is a valuable tool for image segmentation as it can extract knowledge from unlabeled data to assist learning from labeled data. This study focuses on addressing a weakness in the popular self-learning pipeline called lazy mimicking, which refers to the model's tendency to retain its own predictions and resist updates. To overcome this issue, the authors propose the Asynchronous Teacher-Student Optimization (ATSO) algorithm. ATSO breaks up the continual learning process from teacher to student and splits the unlabeled training data into two subsets. The model is fine-tuned using one subset while updating the labels on the other subset alternately. The effectiveness of ATSO is demonstrated in medical and natural image segmentation tasks. In both scenarios, the proposed method achieves competitive performance comparable to state-of-the-art approaches, whether using partial labeled data within the same dataset or transferring the trained model to an unlabeled dataset.