This paper presents a novel approach to the problem of estimating the 3D shape and pose of a human body from a group of multiple RGB images. While previous research has focused on single images, videos, or multi-view images as inputs, our proposed method allows for estimation regardless of subject pose, camera viewpoint, or background conditions between images in the group. Our solution involves predicting distributions over SMPL body shape and pose parameters based on the input images. By combining these predicted distributions from each image, we achieve a final multi-image shape prediction. We demonstrate that utilizing the additional body shape information from multi-image input groups improves the accuracy of 3D human shape estimation compared to single-image inputs on the SSP-3D dataset and a private dataset of tape-measured humans. Moreover, our method allows for quantifying pose prediction uncertainty, which is particularly useful when dealing with challenging input images with significant occlusion. We showcase our method's ability to provide meaningful pose uncertainty on the 3DPW dataset and its competitive performance in terms of pose estimation metrics when compared to state-of-the-art approaches.