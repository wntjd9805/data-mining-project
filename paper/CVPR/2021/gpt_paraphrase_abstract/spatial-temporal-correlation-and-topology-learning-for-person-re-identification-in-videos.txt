This study introduces a novel framework called CTL for video-based person re-identification. The goal is to match pedestrians across different camera views by utilizing spatial and temporal clues from video sequences. CTL uses a CNN backbone and a key-points estimator to extract local features from the human body at different scales. It constructs multi-scale graphs by considering both global context and physical connections of the body. The framework includes a 3D graph convolution and a cross-scale graph convolution to capture spatial-temporal dependencies and structural information. By combining these convolutions, CTL effectively enhances its representational capacity by mining comprehensive clues. Experimental results on two video benchmarks demonstrate the effectiveness and state-of-the-art performance of the proposed method.