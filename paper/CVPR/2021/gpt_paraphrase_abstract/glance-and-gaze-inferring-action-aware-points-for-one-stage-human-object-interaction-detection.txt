The abstract discusses the classification of human-object interaction (HOI) detection approaches into one-stage and two-stage methods. While one-stage models are more efficient, two-stage models offer better accuracy. However, existing one-stage models lack reasoning steps and dynamic search for discriminative cues. To address this, the paper proposes a novel one-stage method called Glance and Gaze Network (GGNet) that adaptively models action-aware points using glance and gaze steps. The glance step determines interaction points, while the gaze step refines these points progressively. The refined points are then used for interaction prediction. The paper also introduces an action-aware approach to match interactions with human-object pairs and a hard negative attentive loss to optimize GGNet. The proposed method outperforms existing approaches on V-COCO and HICO-DET benchmarks. The code for GGNet is available at the provided link.