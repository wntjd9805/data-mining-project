Current methods for super-resolution (SR) using convolutional neural networks (CNNs) allocate computational resources uniformly across all image locations. However, since missing details in low-resolution (LR) images are mainly concentrated in edge and texture regions, less computational resources are needed for flat regions. This leads to redundant computation in flat regions, increasing computational costs and limiting the use of these methods on mobile devices. To address this, we propose a SparseMask SR (SMSR) network that utilizes the sparsity in image SR to improve inference efficiency. Our SMSR network learns sparse masks to identify important regions and mark redundant channels in unimportant regions. This allows for accurate localization and skipping of redundant computation while maintaining comparable performance. Experimental results show that our SMSR network achieves state-of-the-art performance, reducing FLOPs (floating point operations) by 41%, 33%, and 27% for ×2, ×3, and ×4 SR respectively. The code for our SMSR network is available at: https://github.com/LongguangWang/SMSR.