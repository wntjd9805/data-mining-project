Super-resolution techniques using deep convolutional networks are gaining popularity in academia and industry. However, the lack of proper evaluation measures hinders progress in the field by making it difficult to compare different approaches. Traditional evaluation measures like PSNR or SSIM do not accurately reflect human perception of image quality. As a result, researchers often rely on Mean-Opinion-Score (MOS) obtained from human evaluations of super-resolved images. Unfortunately, MOS values from different papers are not directly comparable due to variations in the number of raters and their subjectivity. This paper introduces a new evaluation measure called Neural Side-By-Side, which allows for automatic comparison of super-resolution models by approximating human preferences. To develop this measure, a large dataset of aligned image pairs generated by different super-resolution models was collected. Multiple raters then annotated each pair by choosing the visually more appealing image. Using this dataset and the annotations, a CNN model was trained to predict the probability of one image being more preferable than its counterpart. The study demonstrates that Neural Side-By-Side can generalize across new models and data, making it a reliable approximation of human preferences. This measure can be used to compare models and optimize hyperparameters without requiring human raters. The dataset and pretrained model are open-sourced, providing a useful tool for researchers and practitioners in the field.