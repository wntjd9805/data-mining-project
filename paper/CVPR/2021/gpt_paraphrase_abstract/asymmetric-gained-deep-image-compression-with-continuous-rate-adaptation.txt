The combination of deep learning and image compression has gained attention, with learned methods outperforming classical ones. However, continuous rate adaptation remains a challenge. Some methods use multiple networks for different rates, while others use a single model but with increased complexity and decreased performance. This paper presents a framework called Asymmetric Gained Variational Autoencoder (AG-VAE) that achieves continuous rate adjustment in a single model with minimal additional computation. The framework uses a pair of gain units for discrete rate adaptation and exponential interpolation for continuous rate adaptation without compromising performance. Additionally, an asymmetric Gaussian entropy model is proposed for accurate entropy estimation. Experimental results show that AG-VAE performs comparably to state-of-the-art learned image compression methods in quantitative measures and outperforms classical image codecs in qualitative measures. Ablation study confirms the effectiveness of gain units and the asymmetric Gaussian entropy model.