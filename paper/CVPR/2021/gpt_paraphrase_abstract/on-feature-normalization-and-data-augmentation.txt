The moments (mean and standard deviation) of latent features are often disregarded in image recognition models to reduce noise and improve efficiency. However, in image generation, these moments are important for capturing style and shape information. In this study, we propose a method called Moment Exchange, which encourages recognition models to utilize moment information by replacing the moments of one training image with those of another. We also interpolate the target labels to force the model to extract training signals from both moments and normalized features. Our approach operates efficiently in feature space and can be combined with existing augmentation methods. We demonstrate the effectiveness of Moment Exchange in improving the generalization capability of competitive baseline networks across various recognition benchmark datasets.