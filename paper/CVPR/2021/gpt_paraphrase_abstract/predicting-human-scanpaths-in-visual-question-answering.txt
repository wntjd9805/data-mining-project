This study focuses on attention mechanisms in humans and computer vision systems. While current models for predicting attention typically use static probabilistic saliency maps, real-life scenarios involve tasks of varying complexities and visual exploration is a temporal process that affects task performance. To address this gap, the researchers conducted a study to understand and predict the temporal sequences of eye fixations during general tasks and how they impact task performance. They propose a new deep reinforcement learning method that predicts scanpaths leading to different performances in visual question answering. The model learns question-specific attention patterns based on a task guidance map. To address exposure bias in scanpath prediction, the model uses self-critical sequence training and a Consistency-Divergence loss to generate distinguishable scanpaths for correct and incorrect answers. The proposed model accurately predicts the spatio-temporal patterns of human behavior in visual question answering, such as fixation position, duration, and order. It also generalizes well to free-viewing and visual search tasks, achieving human-level performance and outperforming current state-of-the-art models.