Binarizing neural network models is a promising method for deploying deep neural networks on resource-constrained devices like mobile devices. However, Binary Neural Networks (BNNs) often suffer from significant accuracy degradation compared to full-precision models. Various techniques have been proposed to enhance the accuracy of BNNs, and one approach involves balancing the distribution of binary activations to maximize the information content. In contrast to previous research, our extensive analysis suggests that an unbalanced activation distribution can actually improve the accuracy of BNNs. We also demonstrate that adjusting the threshold values of binary activation functions leads to an unbalanced activation distribution, which in turn increases the accuracy of BNN models. Our experimental results indicate that the accuracy of previous BNN models, such as XNOR-Net and Bi-Real-Net, can be improved simply by shifting the threshold values of binary activation functions, without the need for any other modifications.