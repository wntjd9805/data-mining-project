The computer vision field has recently shown interest in pre-trained models, both through supervised pre-training like ImageNet and self-supervised pre-training such as simCLR and MoCo. These pre-trained weights have been found to enhance various tasks like classification, detection, and segmentation. However, recent studies suggest that large model capacity is necessary for effective pre-training. This paper examines the concept of the lottery ticket hypothesis (LTH) in the context of supervised and self-supervised pre-trained models. LTH identifies sparse subnetworks that can be trained from scratch and still achieve the same performance as the full model. The authors investigate whether these subnetworks exist in pre-trained computer vision models and whether they maintain the same transfer performance. Extensive experiments show that matching subnetworks can be found in pre-trained weights obtained from ImageNet classification, simCLR, and MoCo, with sparsity ranging from 59.04% to 96.48%. These subnetworks consistently transfer well to multiple downstream tasks without any performance degradation compared to using the full pre-trained weights. Further analysis reveals that subnetworks from different pre-training methods have different mask structures and sensitivities to perturbations. The authors conclude that the observations of LTH remain applicable in the pre-training paradigm of computer vision, but some cases require further discussion. The codes and pre-trained models used in this study are available at the provided GitHub link.