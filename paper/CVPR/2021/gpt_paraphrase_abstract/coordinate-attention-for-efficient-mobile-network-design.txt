Recent research has shown the effectiveness of channel attention in improving model performance in mobile network design. However, these studies often overlook the importance of positional information in generating spatially selective attention maps. To address this, we propose a new attention mechanism called "coordinate attention" that incorporates positional information into channel attention. Unlike traditional channel attention, which transforms a feature tensor into a single feature vector through 2D global pooling, our approach factorizes channel attention into two 1D feature encoding processes that aggregate features along the two spatial directions. This allows us to capture long-range dependencies along one spatial direction while preserving precise positional information along the other direction. The resulting feature maps are then encoded separately into a pair of direction-aware and position-sensitive attention maps, which can be used to enhance the representations of objects of interest in the input feature map. Our coordinate attention is simple to implement and can be easily integrated into existing mobile networks without significant computational overhead. Extensive experiments demonstrate that our approach not only improves ImageNet classification performance but also performs better in downstream tasks such as object detection and semantic segmentation. The code for our coordinate attention mechanism is available at the provided GitHub link.