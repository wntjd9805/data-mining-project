Convolutional neural networks (CNNs) have long been believed to be shift-invariant due to the use of convolution and pooling layers. However, recent studies have revealed that small shifts in input can significantly alter the CNN's output, primarily due to the presence of down-sampling layers. Current solutions to this problem involve data augmentation or anti-aliasing techniques, but they have limitations and cannot achieve perfect shift invariance. Moreover, these methods do not generalize well to unseen image patterns. To overcome these challenges, we propose adaptive polyphase sampling (APS), a straightforward sub-sampling approach that enables CNNs to achieve 100% consistency in classification performance under shifts without sacrificing accuracy. APS ensures perfect shift consistency even before training, making it the first method to truly achieve shift invariance in CNNs.