Our aim is to develop a deep network that can reconstruct objects in 3D using only a small number of images, without manual annotations, and with challenging real data. Previous works have achieved similar results using synthetic data or 2D primitives, but we focus on learning from multiple views of a large collection of real object instances. To facilitate this research, we introduce a new dataset of object-centric videos for training and benchmarking. We find that existing techniques based on meshes, voxels, or implicit surfaces, which perform well for isolated objects, struggle with our challenging data. Therefore, we propose a novel neural network design called warp-conditioned ray embedding (WCR) that significantly improves reconstruction and captures detailed implicit representations of the object's surface and texture. Additionally, WCR compensates for noise in the initial structure-from-motion (SfM) reconstruction, which was used to bootstrap the learning process. Our evaluation shows that WCR outperforms several deep monocular reconstruction baselines on both existing benchmarks and our own dataset. For more information, please refer to our publication at https://henzler.github.io/publication/unsupervised_videos/.