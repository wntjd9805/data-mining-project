We present a novel convolutional method called Dynamic Region-Aware Convolution (DRConv) that assigns multiple filters to specific spatial regions automatically. This enables DRConv to capture similar representations for DR-features, surpassing the performance of standard convolution in modeling semantic variations. While standard convolutional layers can increase the number of filters to extract more visual elements, this leads to high computational costs. In contrast, DRConv transfers the increasing channel-wise filters to the spatial dimension using a learnable instructor. This approach not only enhances the representation ability of convolution but also maintains computational efficiency and translation-invariance like standard convolution. DRConv is an effective and elegant solution for managing complex and varying spatial information distribution. It can seamlessly replace standard convolution in existing networks due to its plug-and-play nature, particularly for empowering convolution layers in efficient networks. We thoroughly evaluate DRConv on various models (including MobileNet series and ShuffleNetV2) and tasks (such as classification, face recognition, detection, and segmentation). In ImageNet classification, DRConv-based ShuffleNetV2-0.5Ã— achieves state-of-the-art performance of 67.1% at the 46M multiply-adds level, demonstrating a 6.3% relative improvement.