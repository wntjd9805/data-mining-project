Anomaly detection methods have been seeking better features through deep self-supervised feature learning, but the potential of using pre-trained deep features has been largely overlooked. This paper shows that combining pre-trained features with simple anomaly detection and segmentation methods outperforms more complex state-of-the-art methods. To further improve anomaly detection, pre-trained features need to be adapted to the target distribution. While transfer learning methods are well-established in multi-class classification, they are not as explored in one-class classification (OCC). Naive adaptation methods often lead to feature deterioration and reduced performance in OCC settings. The popular OCC method, DeepSVDD, suggests using specialized architectures, but this limits adaptation performance. To combat feature collapse, this paper proposes two methods: dynamic learning of the stopping iteration using a variant of early stopping, and elastic regularization inspired by continual learning. The proposed method, PANDA, significantly outperforms state-of-the-art in OCC, outlier exposure, and anomaly segmentation settings.