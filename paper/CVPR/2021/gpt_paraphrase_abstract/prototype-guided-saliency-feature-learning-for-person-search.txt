Current methods for person search combine person detection and re-identification modules in a single system. However, the misalignment problem often encountered in person search limits the effectiveness of the re-identification module in representing distinctive features. To address this issue, we present a unique framework that utilizes prototypes in OIM loss to learn a discriminative representation. Unlike conventional approaches that use prototypes as a representation of person identity, we use them as guidance for the attention network to consistently highlight multiple instances across different poses. Additionally, we propose a new prototype update scheme with adaptive momentum to improve discriminative ability across different instances. Through extensive experiments, we demonstrate that our method significantly enhances feature discriminative power and outperforms state-of-the-art results on two person search benchmarks: CUHK-SYSU and PRW.