We propose a method for reasoning human-object interactions (HOI) in order to enhance scene understanding. We highlight the importance of object affordances for humans to discover new HOIs with unfamiliar objects. To address this, we introduce an affordance transfer learning approach that can simultaneously detect HOIs with novel objects and recognize affordances. This approach involves decoupling HOI representations into a combination of affordance and object representations, allowing for the composition of novel interactions by transferring affordance representations to new objects. Additionally, our model can infer the affordances of novel objects based on known affordance representations. Our method aims to improve the performance of HOI detection, particularly for HOIs involving unseen objects, and to infer the affordances of novel objects. Experimental results on two datasets, HICO-DET and HOI-COCO, demonstrate significant improvements compared to state-of-the-art methods for HOI detection and object affordance detection. The code for our method is available at the provided GitHub link.