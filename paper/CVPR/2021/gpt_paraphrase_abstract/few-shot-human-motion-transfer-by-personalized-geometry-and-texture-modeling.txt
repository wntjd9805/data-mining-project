We introduce a novel approach for generating realistic human images using few-shot human motion transfer. Unlike previous methods that require a large number of training images and lengthy training time, our method achieves satisfactory results with just a few source images for appearance transfer. To address the challenge of obtaining satisfactory transfer results, we utilize a geometry generator that renders a personalized surface geometry (UV map) based on shape information from the source images and pose information from 2D keypoints. Additionally, a texture generator is employed to generate a texture map conditioned on the texture of the source images, filling out invisible parts. We also propose a fine-tuning technique that improves the quality of the texture map without overfitting or introducing artifacts. Extensive experiments demonstrate that our method surpasses existing state-of-the-art methods in terms of both qualitative and quantitative performance. The code for our method is publicly available at https://github.com/HuangZhiChao95/FewShotMotionTransfer.