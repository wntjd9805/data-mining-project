Multi-pedestrian trackers excel in tracking visible targets, but struggle when heavy occlusions occur. To address this issue, the typical approach is to compare visual features of new detections with previously identified tracks. However, this method falls short in crowded scenarios where detections tend to overlap with nearby targets. In contrast, we propose a novel strategy that explicitly models the relationship between occluding and occluded tracks. This approach outperforms feature-based methods and does not rely on a separate re-identification network. Additionally, we enhance track management in a regression-based method to handle missing detections and tracks leaving the scene at the image border. Furthermore, we apply our tracker in both temporal directions and merge tracklets belonging to the same target, resulting in improved performance. Through ablative experiments, we demonstrate the effectiveness of our tracking components and surpass the state-of-the-art methods on popular pedestrian tracking benchmarks MOT16, MOT17, and MOT20.