We propose a new approach for estimating multi-view depth from a single video, which is crucial for various applications like perception, reconstruction, and robot navigation. While previous learning-based methods have shown promising results, they often estimate depth maps independently for each video frame, neglecting the strong spatial and temporal coherence between frames. Additionally, state-of-the-art models typically use computationally expensive fully 3D convolution networks for cost regularization, limiting their practical use. Our method addresses these limitations by employing an Epipolar Spatio-Temporal (EST) transformer to explicitly capture the geometric and temporal correlations across multiple depth maps. Moreover, inspired by recent Mixture-of-Experts models, we introduce a compact hybrid network that combines a 2D context-aware network and a 3D matching network to learn 2D context information and 3D disparity cues separately, thereby reducing computational costs. Extensive experiments demonstrate that our approach achieves superior accuracy in depth estimation while significantly improving speed compared to existing methods.