Despite extensive research in computer vision and graphics, current mesh saliency methods struggle to accurately predict human fixations on 3D surfaces, as indicated by recent eye-tracking experiments. These experiments suggest that mesh saliency may be linked to the saliency of 2D natural images. To address this, this study proposes a new deep neural network that learns mesh saliency using image saliency as a reference. The objectives of this approach are to determine whether mesh saliency is an independent perceptual measure or a derivative of image saliency, and to provide a weakly supervised method for improved mesh saliency prediction. Through extensive experiments, the authors demonstrate that their method outperforms existing mesh saliency methods, achieving a 116% improvement in linear correlation coefficient and a 21% improvement in area under the curve (AUC). Additionally, the study reveals that mesh saliency is inherently connected to both image saliency and object categorical information. The source code for the proposed method is available at https://github.com/rsong/MIMO-GAN.