Artificial neural networks are widely used for various tasks but their generalization capability is often hindered by biases in the training data. To address this issue, we propose a regularization strategy called EnD. This approach involves inserting an "information bottleneck" in the deep neural network, separating the bias-related information from the useful information for the training task. The advantage of EnD is that it can be applied directly to the trained model without adding complexity to the training process. Our experiments demonstrate that EnD effectively improves generalization on unbiased test sets, and it can be successfully applied to real-world scenarios such as mitigating hidden biases in COVID-19 detection using radiographic images.