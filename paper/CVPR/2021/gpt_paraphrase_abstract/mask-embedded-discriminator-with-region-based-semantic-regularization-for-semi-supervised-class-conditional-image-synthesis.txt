Semi-supervised generative learning (SSGL) is a method that utilizes unlabeled data to balance the effort of collecting and annotating data with the performance of generating new data, especially in cases where labeled data is limited. To improve the synthesis of class-specific images with limited supervision, we propose a new approach called MED-GAN, which stands for Generative Adversarial Network with a Mask-Embedded Discriminator. By incorporating a module that embeds masks, we can associate spatial information with the discriminator's features, allowing it to focus on specific regions when distinguishing between real and synthesized images. This forces the generator to synthesize instances with more precise class semantics in order to deceive the improved discriminator. Additionally, the mask embedding enables region-based semantic regularization in the discriminator's feature space, increasing the separation between real and fake classes and among object categories. This ultimately improves the matching of class-conditional distributions between real and synthesized data. Experimental results show that MED-GAN outperforms other methods, demonstrating the effectiveness of mask embedding and associated regularizers in facilitating SSGL.