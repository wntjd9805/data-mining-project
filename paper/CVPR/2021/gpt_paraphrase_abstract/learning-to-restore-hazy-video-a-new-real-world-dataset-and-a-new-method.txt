Most current deep learning-based methods for dehazing are trained and evaluated on datasets containing hazy and dehazed images. However, there is a lack of attention given to video dehazing algorithms, which can produce better results by utilizing temporal redundancy from neighboring hazy frames. This is mainly due to the absence of video dehazing datasets. To address this, we introduce the REVIDE dataset, the first dataset specifically designed for training video dehazing algorithms. We capture real-world hazy and haze-free videos using a video acquisition system that records the same scene twice. This allows us to obtain perfectly aligned paired videos. Additionally, we propose a Confidence Guided and Improved Deformable Network (CG-IDN) to tackle the challenge of exploiting temporal redundancy in hazy frames. Experimental results show that the hazy scenes in the REVIDE dataset are more realistic than synthetic datasets, and our proposed algorithm performs well compared to state-of-the-art dehazing methods.