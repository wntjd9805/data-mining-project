Depth Decomposition RGB-D salient object detection (SOD) is commonly approached as a classification or regression problem using RGB and depth modalities. Therefore, the accurate modeling of RGB-D features and the fusion of these features are crucial for successful RGB-D SOD. This paper introduces a novel approach for RGB feature modeling that is sensitive to depth information. By incorporating the depth-wise geometric prior of salient objects, the proposed depth-sensitive attention module enhances the RGB features and reduces background distractions. Additionally, to achieve effective multi-modal feature fusion, an automatic architecture search method is presented. This method efficiently identifies a feasible architecture from a specially designed multi-modal multi-scale search space. The proposed approach is evaluated on seven standard benchmarks, and extensive experiments demonstrate its effectiveness compared to state-of-the-art methods.