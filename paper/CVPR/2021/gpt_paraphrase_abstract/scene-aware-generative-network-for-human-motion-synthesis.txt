This study explores the synthesis of human motion, which is useful in various practical applications. Previous methods for this task have limitations in two aspects: they focus on poses while neglecting movement, and they do not consider the impact of the environment on human motion. To address these limitations, the authors propose a new framework that incorporates the interaction between the scene and human motion. They formulate the task as a generative task, aiming to generate realistic human motion based on both the scene and the initial position of the human. The framework separates the distribution of human motions into a distribution of movement trajectories conditioned on scenes, and a distribution of body pose dynamics conditioned on both scenes and trajectories. The authors also develop a GAN-based learning approach, which includes discriminators to ensure compatibility between human motion and the contextual scene, as well as 3D-to-2D projection constraints. The proposed method is evaluated on two challenging datasets that encompass both synthetic and real-world environments.