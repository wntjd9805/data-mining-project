The human body pose in a 3D world provides information about the surrounding objects. Humans are skilled at understanding the pose and layout of a person in an indoor scene by using their knowledge of physical laws and past experiences. However, computer vision models do not fully utilize this ability. To address this, we propose a model that can perceive a 3D scene from a single RGB image, estimate the camera pose, room layout, and reconstruct the human body and object meshes. By using comprehensive and sophisticated loss functions, our model outperforms existing methods for human body mesh and indoor scene reconstruction. This is the first model to output mesh-level predictions for both objects and humans while jointly optimizing the scene and human poses.