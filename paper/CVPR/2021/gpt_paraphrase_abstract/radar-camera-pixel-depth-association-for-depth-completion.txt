Fusing radar and video data at the pixel level is more advantageous, but also more challenging due to the sparse nature of radar data and the wide beams of automotive radar. The association between radar pixels and color pixels is poor, making existing depth completion methods inefficient for radar and video. To address this, we propose a radar-to-pixel association stage that learns a mapping from radar returns to pixels, which also helps densify radar returns. By combining this stage with a traditional depth completion method, we achieve image-guided depth completion using radar and video. Our approach outperforms using camera and radar alone on the nuScenes dataset. The source code for our method is available at https://github.com/longyunf/rc-pda.