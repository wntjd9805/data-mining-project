The role of temporal receptive fields in action segmentation is crucial. Models with large receptive fields capture long-term relationships between video clips, while models with small receptive fields capture local details. Currently, models are constructed using hand-designed receptive fields in layers. However, we aim to find better receptive field combinations by searching for them instead of using pre-designed patterns. Our approach involves a global-to-local search scheme. The global search identifies coarse combinations that are different from the human-designed patterns. Then, we use an expectation-guided iterative local search to refine the receptive field combination patterns. This search scheme can be integrated into existing action segmentation methods to achieve state-of-the-art performance. Interested individuals can access the source code at http://mmcheng.net/g2lsearch.