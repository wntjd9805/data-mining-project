We present a new approach for motion transfer, specifically transferring the motions of a source dancer to a target person. This task falls under the pose transfer problem, where the target person adjusts their pose based on the dancer's movements. Our method is able to reanimate a single image using any video sequences, even those not seen during training. To achieve this, we utilize three networks: a segmentation-mapping network, a realistic frame-rendering network, and a face refinement network. Breaking down the task into these three stages allows us to generate a sequence of realistic frames that accurately capture natural motion and appearance. Our method outperforms previous approaches in terms of visual quality and can animate individuals with diverse body types and appearances, even in challenging poses.