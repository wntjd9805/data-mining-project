This paper introduces Neural-HumanFVV, a real-time system for capturing and rendering human activities in virtual reality and augmented reality. While previous methods have made progress in reconstructing geometry and texture from sparse multi-view RGB cameras, they still struggle to achieve the same level of detail as the input images. To address this, the authors propose a hierarchical sampling strategy and a neural blending scheme for real-time implicit geometry inference, as well as a novel neural blending scheme for generating high-resolution and photo-realistic texture in novel views. Additionally, they incorporate neural normal blending to enhance geometry details and formulate their approach as a multi-task learning framework. Extensive experiments demonstrate that their system effectively achieves high-quality geometry and photo-realistic reconstruction of challenging human performances in free-viewpoint scenarios.