Quantizing deep neural networks is a useful technique to reduce memory usage and improve inference speed, especially for devices with limited resources. However, achieving high accuracy with extremely low-bit models remains challenging compared to full-precision models. To tackle this issue, we propose a novel method called learnable companding quantization (LCQ) for 2-, 3-, and 4-bit models. LCQ optimizes both model weights and learnable companding functions, allowing flexible and non-uniform control over the quantization levels of weights and activations. Additionally, we introduce a new weight normalization technique to enhance the stability of quantization training. Experimental results demonstrate that LCQ outperforms existing methods and significantly reduces the gap between quantized and full-precision models in image classification and object detection tasks. Notably, our 2-bit ResNet-50 model achieves a top-1 accuracy of 75.1% on ImageNet, reducing the gap to just 1.7%. This success showcases LCQ's potential to exploit non-uniform quantization further.