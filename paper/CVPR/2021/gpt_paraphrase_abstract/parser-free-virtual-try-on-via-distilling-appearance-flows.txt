The aim of image virtual try-on is to fit a garment image onto a person image. Previous methods relied heavily on human parsing, but even small errors in segmentation would result in unrealistic try-on images with noticeable flaws. A recent study used knowledge distillation to lessen the reliance on human parsing, where try-on images generated by a parser-based method were used to train a "student" network without segmentation. However, the image quality of the student network was limited by the parser-based model. To address this issue, we propose a new approach called "teacher-tutor-student" knowledge distillation, which can produce highly realistic images without human parsing and offers several advantages over previous methods. Firstly, our approach treats the fake images generated by the parser-based method as "tutor knowledge" that can be corrected by real "teacher knowledge" extracted from real person images in a self-supervised manner. Secondly, instead of using real images as supervisions, we use knowledge distillation to capture the appearance flows between the person image and the garment image, allowing us to find accurate dense correspondences and produce high-quality results. Extensive evaluations demonstrate the significant superiority of our method.