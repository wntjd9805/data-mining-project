The traditional approach to visual localization involves three steps: detecting and describing local features, matching the features, and rejecting outliers. However, recently proposed correspondence networks perform all three steps within a single network, but they suffer from low matching resolution due to limited memory. This study presents a new approach called Patch2Pix, which estimates correspondences in a detect-to-refine manner. It first predicts match proposals at the patch level and then refines them. Patch2Pix is a refinement network that improves match proposals by regressing pixel-level matches and rejecting outlier matches based on confidence scores. It is weakly supervised to learn correspondences consistent with the epipolar geometry of an input image pair. Experimental results demonstrate that Patch2Pix significantly enhances the performance of correspondence networks in image matching, homography estimation, and localization tasks. Furthermore, the learned refinement also generalizes to fully supervised methods without requiring re-training, achieving state-of-the-art localization performance. The code for Patch2Pix is available at https://github.com/GrumpyZhou/patch2pix.