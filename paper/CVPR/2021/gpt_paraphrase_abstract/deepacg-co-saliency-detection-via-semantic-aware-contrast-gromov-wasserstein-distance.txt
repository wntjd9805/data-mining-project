The goal of co-saliency detection is to identify and segment objects that are salient in a group of images. In order to achieve this, we propose a new deep network architecture called DeepACG, which utilizes the Gromov-Wasserstein (GW) distance to create dense correlation volumes for all pairs of pixels within the image group. These correlation volumes allow the network to accurately identify similarities between the salient objects. Additionally, we introduce a semantic-aware co-attention module (SCAM) that enhances the foreground co-saliency by incorporating predicted categorical information. SCAM identifies the semantic class of the foreground co-objects and uses this information to localize the related pixels. Moreover, we develop a contrast edge-enhanced module (EEM) to capture more contextual information and preserve fine-grained spatial details. We evaluate our model on three benchmark datasets (Cosal2015, CoCA, and CoSOD3k) and demonstrate its effectiveness through extensive experiments. Our model outperforms existing methods and achieves state-of-the-art performance.