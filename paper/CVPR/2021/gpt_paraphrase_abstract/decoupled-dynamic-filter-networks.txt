Convolution is a fundamental element in CNN architectures. However, traditional convolution has two drawbacks: it is content-agnostic and computationally intensive. Dynamic filters address the content-adaptive issue, but they increase computational overhead. Depth-wise convolution is a lighter alternative, but it often compromises CNN performance or requires more channels. To address these issues, we propose the Decoupled Dynamic Filter (DDF). Drawing inspiration from attention mechanisms, DDF separates a depth-wise dynamic filter into spatial and channel dynamic filters. This decomposition significantly reduces the number of parameters and computational costs, matching those of depth-wise convolution. Moreover, we observe a notable improvement in classification networks when replacing standard convolution with DDF, with ResNet50/101 achieving a 1.9% and 1.3% increase in top-1 accuracy, while computational costs are nearly halved. Our experiments also demonstrate that the DDF-Up variant outperforms standard convolution and specialized content-adaptive layers in detection and joint upsampling networks. The project page with code is available for reference.