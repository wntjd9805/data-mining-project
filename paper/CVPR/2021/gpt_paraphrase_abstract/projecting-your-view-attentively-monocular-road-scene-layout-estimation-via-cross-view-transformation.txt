The importance of HD map reconstruction for autonomous driving cannot be overstated. Existing LiDAR-based methods are limited due to the high cost of sensors and time-consuming computation. Camera-based methods, on the other hand, often suffer from distortion and lack of content as they require separate road segmentation and view transformation steps. To address these limitations, we propose a novel framework that can reconstruct a local map in the bird's-eye view using only a single front-view monocular image.Our framework introduces a cross-view transformation module that takes into account the constraint of cycle consistency between views. By leveraging the correlation between views, this module enhances view transformation and scene understanding. Additionally, we incorporate a context-aware discriminator that considers the relationship between vehicles and roads to further improve the results.Through experiments on public benchmarks, we demonstrate that our method achieves state-of-the-art performance in road layout estimation and vehicle occupancy estimation tasks. Notably, our model outperforms all competitors by a significant margin in the latter task. Furthermore, our model runs efficiently at 35 frames per second on a single GPU, making it suitable for real-time panorama HD map reconstruction.