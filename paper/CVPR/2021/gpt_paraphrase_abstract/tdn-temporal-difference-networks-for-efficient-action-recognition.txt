This study introduces a novel video architecture called Temporal Difference Network (TDN) to address the challenges of temporal modeling in action recognition. The main focus of TDN is to capture multi-scale temporal information efficiently. The core component of TDN is an efficient temporal module (TDM) that utilizes a temporal difference operator to assess its impact on short-term and long-term motion modeling. To capture temporal information throughout the entire video, TDN adopts a two-level difference modeling approach. For local motion modeling, temporal difference between consecutive frames is employed to provide finer motion patterns to 2D CNNs. For global motion modeling, temporal difference across segments is integrated to capture long-range structure for motion feature excitation. TDN offers a simple and principled framework for temporal modeling, with minimal additional computational cost when instantiated with existing CNNs. The performance of TDN outperforms previous methods on the Something-Something V1 & V2 datasets and achieves comparable results on the Kinetics-400 dataset. Ablation studies and visualization results of TDN are conducted to provide insightful analysis on temporal difference modeling. The code for TDN is publicly available at https://github.com/MCG-NJU/TDN.