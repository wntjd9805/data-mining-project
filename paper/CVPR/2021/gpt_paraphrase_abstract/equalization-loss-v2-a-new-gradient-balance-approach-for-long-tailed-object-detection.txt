Recently, decoupled training methods have become popular for long-tailed object detection. However, these methods require an additional fine-tuning stage and may not yield optimal results due to the separate optimization of representation and classifier. On the other hand, end-to-end training methods like equalization loss (EQL) have not performed as well as decoupled methods. This paper identifies the main issue in long-tailed object detection as the imbalanced gradients between positive and negative samples, and shows that EQL does not effectively address this problem. To overcome the issue of imbalanced gradients, a new version of equalization loss called EQL v2 is introduced. EQL v2 incorporates a novel gradient guided reweighing mechanism that balances the training process for each category independently and equally. Extensive experiments on the LVIS benchmark demonstrate that EQL v2 outperforms the original EQL by an overall average precision (AP) improvement of 4 points, with even greater improvements of 14 to 18 points on rare categories. Importantly, EQL v2 also surpasses decoupled training methods. Furthermore, without any additional tuning on the Open Images dataset, EQL v2 achieves a 7.3 points AP improvement over EQL, showcasing its strong generalization ability. The source code for EQL v2 is available at https://github.com/tztztztztz/eqlv2.