The ClassiÔ¨Åcation Transformer (C-Tran) is a novel framework for multi-label image classification that utilizes Transformers to capture the complex relationships between visual features and labels. The approach involves training a Transformer encoder to predict target labels based on masked labels and visual features from a convolutional neural network. A key aspect of the method is the use of a label mask training objective, which employs a ternary encoding scheme to represent label states as positive, negative, or unknown during training. The model achieves state-of-the-art performance on challenging datasets such as COCO and Visual Genome. Furthermore, the explicit representation of label states enables the model to produce improved results for images with partial or additional label annotations during inference. This enhanced capability is demonstrated on the COCO, Visual Genome, News-500, and CUB image datasets.