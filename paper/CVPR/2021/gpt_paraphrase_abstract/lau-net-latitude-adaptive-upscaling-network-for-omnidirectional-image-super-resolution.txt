The resolution of omnidirectional images (ODIs) is often low due to limitations in collection, storage, and transmission. Traditional two-dimensional (2D) image super-resolution methods are ineffective for spherical ODIs because pixel density is non-uniformly distributed and texture complexity varies across latitudes. To address this, we propose a novel approach called the latitude adaptive upscaling network (LAU-Net) for ODI super-resolution. LAU-Net allows pixels at different latitudes to adopt distinct upscaling factors. We employ a Laplacian multi-level separation architecture to divide the ODI into latitude bands and upscale them hierarchically using different factors. Additionally, we introduce a deep reinforcement learning scheme with a latitude adaptive reward to automatically select the optimal upscaling factors for each latitude band. LAU-Net is the first attempt to consider the latitude difference in ODI super-resolution. Extensive results demonstrate that LAU-Net significantly improves the super-resolution performance for ODIs. The codes for LAU-Net are available at https://github.com/wangh-allen/LAU-Net.