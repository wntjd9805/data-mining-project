SinGAN is a convolutional generator that is able to learn internal patch distribution despite its limited receptive field. We are interested in understanding how this translation-invariant generator is able to capture global structure using only spatially independent and identically distributed (i.i.d.) input. In this study, we investigate the role of positional encoding in achieving this capability, focusing on the use of zero padding in the generators of SinGAN and StyleGAN2.We find that positional encoding plays a crucial role in generating high-quality images and is necessary for maintaining fidelity. This phenomenon is not limited to SinGAN and StyleGAN2, as other generative architectures like DCGAN and PGGAN also exhibit the same reliance on zero padding for spatial bias. However, we observe that zero padding can result in an unbalanced spatial bias with unclear relationships between locations.To address this issue and provide a better spatial inductive bias, we explore alternative positional encodings and analyze their impact. By adopting a more flexible and explicit positional encoding, we propose a new multi-scale training strategy that significantly enhances the performance of StyleGAN2, a leading unconditional generator. Additionally, the explicit spatial inductive bias greatly improves SinGAN, making it more versatile for image manipulation.In conclusion, our study highlights the importance of positional encoding in convolutional generators and demonstrates the effectiveness of our proposed multi-scale training strategy in StyleGAN2. The explicit spatial inductive bias not only enhances the fidelity of generated images but also improves SinGAN for various image manipulation tasks.