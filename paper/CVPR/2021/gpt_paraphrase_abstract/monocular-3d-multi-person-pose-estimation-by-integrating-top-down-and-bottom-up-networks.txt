In monocular video 3D multi-person pose estimation, errors can occur due to inter-person occlusion and close interactions. Existing methods either rely on human detection or process all persons at once, leading to unreliable results. To overcome these challenges, we propose integrating top-down and bottom-up approaches. Our top-down network estimates human joints from all persons, making it robust to erroneous bounding boxes. Our bottom-up network incorporates human-detection based heatmaps, allowing it to handle scale variations. The 3D poses estimated by both networks are then fed into our integration network for final results. Additionally, we introduce a two-person pose discriminator to assess natural inter-person interactions. We also use a semi-supervised method to overcome the scarcity of 3D ground-truth data. Evaluations demonstrate the effectiveness of our proposed method, and our code is publicly available.