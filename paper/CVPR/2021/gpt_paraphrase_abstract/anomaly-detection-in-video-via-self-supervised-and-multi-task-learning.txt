Detecting anomalies in videos is a difficult task in computer vision, as there is limited data available for training. To address this challenge, we propose a novel approach for anomalous event detection in videos using self-supervised and multi-task learning at the object level. First, we utilize a pre-trained detector to detect objects in the video. Then, we train a 3D convolutional neural network to learn discriminative anomaly-specific information by simultaneously learning multiple proxy tasks. These tasks include discriminating between forward and backward moving objects, discriminating between objects in consecutive and intermittent frames, and reconstructing object-specific appearance information. Additionally, we introduce a knowledge distillation task that considers both classification and detection information, creating significant prediction differences between teacher and student models when anomalies occur. This approach, which integrates multiple self-supervised and knowledge distillation proxy tasks into a single architecture, is the first of its kind for anomalous event detection in videos. Our lightweight architecture outperforms existing methods on three benchmark datasets: Avenue, ShanghaiTech, and UCSD Ped2. Furthermore, we conduct an ablation study to demonstrate the importance of integrating self-supervised learning and normality-specific distillation in a multi-task learning setting.