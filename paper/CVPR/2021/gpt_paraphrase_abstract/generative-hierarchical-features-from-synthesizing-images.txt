Recent advancements in Generative Adversarial Networks (GANs) have greatly improved image synthesis by learning the underlying distribution of observed data. However, the potential applicability of the features learned from image generation to other vision tasks has not been extensively explored. This study aims to demonstrate that learning to synthesize images can yield hierarchical visual features that can be applied across various applications. To achieve this, we utilize the pre-trained StyleGAN generator as a learned loss function and train a new hierarchical encoder using its layer-wise representation. The resulting visual feature, known as Generative Hierarchical Feature (GH-Feat), exhibits strong transferability to both generative and discriminative tasks, such as image editing, image harmonization, image classification, face verification, landmark detection, and layout prediction. Through extensive qualitative and quantitative experiments, we provide evidence of the impressive performance of GH-Feat.