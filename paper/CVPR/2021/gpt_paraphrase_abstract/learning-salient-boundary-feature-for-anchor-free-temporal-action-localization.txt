Temporal action localization is a challenging task in video understanding, involving the identification of action categories and the localization of start and end frames for each action instance in a long video. Current models use pre-defined anchors and actionness, but this approach has limitations in terms of the number of outputs and tuning of anchor locations and sizes. In contrast, anchor-free methods are lighter and eliminate redundant hyper-parameters, but have received less attention. In this paper, we propose an efficient and effective purely anchor-free localization method. Our model consists of an end-to-end trainable basic predictor, a saliency-based refinement module that uses boundary pooling to extract valuable boundary features, and consistency constraints to ensure accurate boundary detection. Extensive experiments demonstrate that our method outperforms anchor-based and actionness-guided methods on THUMOS14, achieving state-of-the-art results, and comparable results on ActivityNet v1.3. The code for our method is available at https://github.com/TencentYoutuResearch/ActionDetection-AFSD.