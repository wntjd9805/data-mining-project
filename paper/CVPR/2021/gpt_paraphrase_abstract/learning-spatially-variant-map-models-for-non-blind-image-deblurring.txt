The classical maximum a-posteriori (MAP) framework for non-blind image deblurring requires defining appropriate data and regularization terms, which are optimized to obtain a clear image. Previous research has mainly focused on improving either the data or regularization term separately. Recognizing the importance and interaction of both terms, we propose a straightforward and efficient method to jointly learn these terms using deep neural networks within the MAP framework. Our approach not only generates suitable image-adaptive features for both terms but also predicts spatially-variant features on a per-pixel basis instead of the commonly used spatially-uniform features. This leads to better restoration of fine-scale structures and details. Quantitative and qualitative evaluations demonstrate the effectiveness of our approach, surpassing current state-of-the-art methods.