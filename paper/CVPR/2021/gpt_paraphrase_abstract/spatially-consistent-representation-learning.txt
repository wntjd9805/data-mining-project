Self-supervised learning, which involves obtaining useful representations from unlabeled images, has become popular in recent years. Contrastive learning methods, in particular, have shown impressive results in image classification tasks. However, these methods tend to focus on generating global representations that are invariant to semantic-preserving transformations, while overlooking the spatial consistency of local representations. This limitation makes them less effective for tasks such as object detection and instance segmentation. Additionally, the aggressively cropped views used in existing contrastive methods can reduce the distinction between semantically different regions within an image. To address these issues, we propose a novel algorithm called Spatially Consistent Representation Learning (SCRL). SCRL aims to produce coherent spatial representations of randomly cropped local regions by considering geometric translations and zooming operations. We evaluate the performance of SCRL on various benchmark datasets for localization tasks, and our results show significant improvements compared to image-level supervised pretraining and state-of-the-art self-supervised learning methods. In Figure 1, we present the average precision (AP) results of SCRL compared to other methods on the COCO detection task. We use a ResNet-50-FPN backbone with Faster R-CNN for this evaluation. With just 200 epochs of upstream training, SCRL outperforms the ImageNet pre-trained model and other self-supervised learning methods. Furthermore, we demonstrate that SCRL consistently outperforms random initialization, supervised pretraining, and the BYOL method across different training schedules.For more details and access to the code, please visit our GitHub repository at https://github.com/kakaobrain/scrl.