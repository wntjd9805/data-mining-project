StyleMapGAN is a novel approach for manipulating real images using generative adversarial networks (GANs). GANs are commonly used to synthesize realistic images by controlling random latent vectors. However, editing real images with GANs has drawbacks, including time-consuming optimization for projecting real images to latent vectors or inaccurate embedding through an encoder.  To address these issues, StyleMapGAN introduces a spatially variant modulation in the intermediate latent space, replacing the commonly used Adaptive Instance Normalization (AdaIN). This modification improves the accuracy of embedding real images through an encoder compared to existing optimization-based methods, while still preserving the desirable properties of GANs.  Experimental results demonstrate that StyleMapGAN outperforms state-of-the-art models in various image manipulation tasks, such as local editing and image interpolation. Additionally, conventional editing methods used on GANs can still be applied to StyleMapGAN.  The source code for StyleMapGAN is publicly available on GitHub at https://github.com/naver-ai/StyleMapGAN.