Current methods for estimating 3D human pose and shape often fail to accurately capture self-contact, such as touching the face or crossing arms and legs. To address this limitation, we present a novel approach that significantly improves human pose estimation with self-contact. First, we create a dataset called 3D Contact Poses (3DCP) which includes 3D scans of bodies fitted with SMPL-X and refined poses from AMASS to ensure good contact. Next, we leverage this dataset to create the Mimic-The-Pose (MTP) dataset, consisting of images collected through Amazon Mechanical Turk, where people mimic the poses from 3DCP with self-contact. To further enhance our approach, we develop a new optimization method called SMPLify-XMC. This method includes contact constraints and utilizes the known 3DCP body pose during fitting to generate near ground-truth poses for the images in the MTP dataset. Additionally, we label a dataset of in-the-wild images with Discrete Self-Contact (DSC) information and use another optimization method called SMPLify-DC, which takes advantage of discrete contacts during pose optimization.Finally, we incorporate our datasets into the training of a new 3D human pose regressor called TUCH (Towards Understanding Contact in Humans). Our experiments demonstrate that our method significantly improves the accuracy of 3D human pose estimation on withheld test data and existing datasets like 3DPW. Importantly, our approach not only enhances results for self-contact poses but also improves accuracy for non-contact poses.The code and data associated with our method are publicly available for research purposes at https://tuch.is.tue.mpg.de.