This study addresses the issue of novelty detection in fine-grained visual classification (FGVC). The researchers aim to integrate probabilistic and distance-based approaches to novelty detection within the framework of convolutional neural networks (CNNs). They find that softmax CNN classifiers are not suitable for novelty detection due to the unidentifiable learned class-conditional distributions and distance metrics. To address this problem, they propose a new regularization constraint called the class-conditional Gaussianity loss, which enforces Gaussian class-conditional distributions and eliminates the unidentifiability issue. This allows for the training of Novelty Detection Consistent Classifiers (NDCCs) that are optimal for both classification and novelty detection. Experimental evaluations demonstrate that NDCCs achieve significant improvements over the current state-of-the-art on small- and large-scale FGVC datasets.