Automatic unsupervised visual clustering has been a topic of significant interest in recent years. The goal is to analyze unlabeled visual images by clustering them using a parameterized appearance model. Graph Convolutional Neural Networks (GCN) have emerged as a popular clustering method, but they have several limitations. Firstly, they are sensitive to hard or noisy samples. Secondly, their computational training time makes it difficult to explore different deep network models. Lastly, it is challenging to design an end-to-end training model that integrates deep feature extraction and GCN clustering. To address these issues, this research introduces Clusformer, a new perspective based on Transformer approach for automatic visual clustering using unsupervised attention mechanism. The proposed method is robust against noisy or difficult samples and can effectively collaborate with different deep network models of varying sizes within an end-to-end framework. The evaluation on Google Landmark and MS-Celeb-1M face databases demonstrates superior performance compared to previous unsupervised clustering methods. The code for Clusformer is available at https://github.com/VinAIResearch/Clusformer.