This study introduces a novel approach called Self-supervised Mesh Reconstruction (SMR) to enhance the learning process of 3D mesh attributes in single-view 3D reconstruction methods. These methods aim to reconstruct the shape and texture of objects from a single image with only 2D image-level annotation. However, without explicit 3D attribute-level supervision, achieving accurate reconstruction remains challenging.The SMR approach is motivated by two observations. Firstly, 3D attributes should be consistent when interpolated or predicted. Secondly, the feature representation of landmarks should be consistent across all images. By utilizing only silhouette mask annotation, the SMR approach can be trained end-to-end and can generalize to reconstruct natural objects such as birds, cows, and motorbikes.Experimental results demonstrate that the SMR approach improves both supervised and unsupervised 3D mesh reconstruction on multiple datasets. Additionally, the model can be adapted to other image synthesis tasks, including novel view generation, shape transfer, and texture transfer, with promising results. The code for the SMR approach is publicly available at https://github.com/Jia-Research-Lab.