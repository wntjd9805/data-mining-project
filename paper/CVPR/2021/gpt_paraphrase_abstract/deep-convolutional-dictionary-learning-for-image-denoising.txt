Many methods have been proposed to integrate traditional image modeling techniques into deep neural networks (DNNs) for image restoration. However, these methods have limitations. First, the architectures used do not strictly follow the image representation model, losing the desired physical meaning. Second, handcrafted priors are still used instead of utilizing the learning capability of DNNs effectively. Third, a universal dictionary is learned for all images, reducing model representation flexibility. To address these issues, we propose a new framework called deep convolutional dictionary learning (DCDicL). DCDicL strictly follows the representation model, learns priors for both representation coefficients and dictionaries, and can adaptively adjust the dictionary for each input image based on its content. We validate the effectiveness of DCDicL on the image denoising problem, where it outperforms existing denoising DNNs in terms of quantitative metrics and visual quality. It can reproduce subtle image structures and textures that are difficult to recover with other methods. The code for DCDicL is available at the given GitHub link.