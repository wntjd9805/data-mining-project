We introduce MultiBodySync, an innovative framework for segmenting and aligning multiple 3D point clouds of different objects or body parts. Our framework addresses the challenges of ensuring consistency in correspondence and segmentation across multiple input point clouds, as well as achieving robust motion-based segmentation for new object categories. To overcome these challenges, we propose a method that combines spectral synchronization with an iterative deep declarative network. This allows us to simultaneously recover consistent correspondences and motion segmentation. By separating the correspondence and motion segmentation modules, we also achieve strong generalizability across different object categories. We have extensively evaluated our method on various datasets, including rigid parts in articulated objects and individually moving objects in 3D scenes, both from single-view and full point clouds. Our results demonstrate the effectiveness of our approach. The code for our method is available at https://github.com/huangjh-pub/multibody-sync.