State-of-the-art methods for detecting text in scenes typically use a bottom-up approach, modeling text instances with local pixels or components. However, these methods are sensitive to noise and rely on complex heuristic post-processing for detecting arbitrary-shaped texts. In this paper, we propose a top-down approach to address these issues. We progressively evolve initial text proposals into arbitrarily shaped text contours. The initial proposals are generated by estimating the center and size of texts in a horizontal orientation. In the first stage of evolution, we predict the corner points of oriented text proposals to reduce the regression range. In the second stage, we iteratively regress the contours of oriented text proposals to achieve arbitrarily shaped ones. In the final iteration of this stage, we rescore the confidence of the localized text by utilizing cues from multiple contour points, rather than relying solely on the single cue from the initial horizontal proposal center, which may be outside of arbitrary-shaped text regions. Additionally, to facilitate the progressive contour evolution, we design a mechanism for aggregating contour information. This mechanism enriches the feature representation on text contours by considering both circular topology and semantic context. Experimental results on CTW1500, Total-Text, ArT, and TD500 datasets demonstrate that our proposed method performs exceptionally well in detecting line-level arbitrary-shaped texts. The code for our method is available at https://github.com/dpengwen/PCR.