Video action recognition requires capturing spatial-temporal, channel-wise, and motion patterns. While 2D CNNs are computationally cheap, they struggle with temporal relationships. On the other hand, 3D CNNs perform well but are computationally expensive. To address this issue, we propose the ACTION module that can be embedded into 2D CNNs. This module consists of three paths: Spatio-Temporal Excitation (STE), Channel Excitation (CE), and Motion Excitation (ME). The STE path characterizes spatio-temporal representation using 3D convolution. The CE path recalibrates channel-wise feature responses by modeling interdependencies between channels. The ME path calculates feature-level temporal differences to excite motion-sensitive channels. By adding the ACTION module to 2D CNNs, we create ACTION-Net, a simple yet effective network with minimal extra computational cost. ACTION-Net consistently outperforms 2D CNNs on three different backbones and three datasets. Code for ACTION-Net is available at https://github.com/V-Sense/ACTION-Net.