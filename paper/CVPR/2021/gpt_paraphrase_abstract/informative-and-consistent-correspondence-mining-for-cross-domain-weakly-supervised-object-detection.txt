Cross-domain weakly supervised object detection aims to adapt object-level knowledge from a fully labeled source domain dataset to train object detectors for weakly labeled target domains. Instead of matching domain-level distributions, we propose learning pixel-wise cross-domain correspondences for more precise knowledge transfer. This is achieved through a novel cross-domain co-attention scheme trained as region competition. In this scheme, a cross-domain correspondence module identifies informative features in the target domain image that, when warped to the source domain image, can best explain its annotations. Simultaneously, a collaborative mask generator competes to mask out the relevant target image region, making the remaining features uninformative. This competitive learning helps correlate the full foreground in cross-domain image pairs, revealing the accurate object extent in the target domain. To address the ambiguity of inter-domain correspondence learning, we introduce a domain-cycle consistency regularizer that leverages more reliable intra-domain correspondence. The proposed approach consistently outperforms existing methods by a significant margin, as demonstrated through experiments on various datasets.