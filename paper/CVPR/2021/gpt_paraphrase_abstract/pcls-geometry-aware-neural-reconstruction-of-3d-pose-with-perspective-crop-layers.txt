The use of local processing is vital in convolutional neural networks (CNNs) and other neural network architectures, as it allows for effective analysis of images where relevant information is primarily found in local regions. However, the projection effects caused by the conventional camera vary depending on the global position within the image. In order to address this issue, we propose the implementation of Perspective Crop Layers (PCLs), which perform a perspective crop of the region of interest based on camera geometry. Our research demonstrates that accounting for perspective consistently enhances the accuracy of state-of-the-art 3D pose reconstruction methods. PCLs function as modular neural network layers that can be inserted into existing CNN and MLP architectures. By incorporating PCLs, the location-dependent perspective effects are eliminated while preserving end-to-end training and the number of parameters in the neural network. We showcase that PCLs lead to improved 3D human pose reconstruction accuracy in CNN architectures that employ cropping operations, such as spatial transformer networks (STN), as well as MLPs utilized for 2D-to-3D key-point lifting. These findings emphasize the importance of utilizing camera calibration information for both classical and deep-learning-based computer vision approaches. By offering a straightforward solution to enhance the accuracy of existing 3D reconstruction networks by making them geometry-aware, PCLs contribute to the advancement of computer vision research. The code for PCLs is publicly accessible at github.com/yu-frank/PerspectiveCropLayers.