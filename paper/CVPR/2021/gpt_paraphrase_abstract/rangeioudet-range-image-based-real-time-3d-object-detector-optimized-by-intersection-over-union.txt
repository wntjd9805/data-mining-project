This paper introduces RangeIoUDet, a 3D object detection framework for autonomous driving that uses range images as input. Unlike previous methods that rely on point or voxel-based convolutions, RangeIoUDet achieves high performance and efficiency by utilizing 2D convolutions on the dense representation of the range image. The model learns pointwise features from the range image and uses a region proposal network to predict 3D bounding boxes. The network is optimized using point-based IoU supervision to better learn the implicit 3D information in the range image, and a 3D Hybrid GIoU loss is introduced to generate high-quality boxes and provide accurate quality evaluation. Experimental results on the KITTI dataset demonstrate that RangeIoUDet outperforms other single-stage models while maintaining a fast inference speed of 45 FPS. Additionally, experiments on a self-built dataset validate the effectiveness of RangeIoUDet across different LIDAR sensors and object categories.