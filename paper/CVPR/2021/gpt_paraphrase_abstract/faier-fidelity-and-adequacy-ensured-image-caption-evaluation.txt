Image caption evaluation is a critical task that involves understanding and comparing the meaning of images and text. Effective evaluation metrics should be fair, thorough, and aligned with human judgment. When humans evaluate captions, they consider various aspects, such as their relevance to the image, the extent to which they convey the main idea, and the fluency and aesthetic quality of the language. These evaluation orientations can be categorized as fidelity, adequacy, and fluency. Fidelity and adequacy are determined by the image content, while fluency is related to linguistic factors and is more subjective. In this study, we propose a learning-based metric called FAIEr, inspired by human judges, to assess the fidelity and adequacy of captions. To represent both images and captions, we utilize the scene graph as a bridge between the two modalities. FAIEr primarily considers the visual scene graph as a criterion to measure fidelity. To evaluate the adequacy of the candidate caption, it emphasizes the image's main idea on the visual scene graph, guided by the reference captions. Experimental results demonstrate that FAIEr aligns closely with human judgment, exhibits high stability, low dependence on reference captions, and enables reference-free evaluation.