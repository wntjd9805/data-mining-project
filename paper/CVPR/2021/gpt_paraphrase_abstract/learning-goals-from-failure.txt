We present a framework for predicting the intentions behind human actions in videos. Drawing inspiration from developmental psychology, we utilize videos of unintentional actions to learn representations of goals without explicit guidance. Our approach involves modeling videos as contextual trajectories that capture both low-level motion and high-level action features. Through experiments and visualizations, we demonstrate that our trained model can accurately predict the underlying goals in videos of unintentional actions. Additionally, we propose a technique to automatically rectify unintentional actions by utilizing gradient signals from our model to adjust latent trajectories. Despite being trained with limited supervision, our model performs competitively or surpasses baselines trained on large supervised datasets of successful goal execution. This highlights the significance of observing unintentional actions in the process of learning about goals in videos.