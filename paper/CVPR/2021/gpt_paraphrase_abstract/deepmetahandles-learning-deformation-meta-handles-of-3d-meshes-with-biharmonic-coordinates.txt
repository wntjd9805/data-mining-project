We present DeepMetaHandles, a novel 3D generative model that utilizes mesh deformation. Our approach learns a set of meta-handles for each shape in a collection of 3D meshes, which are combinations of deformation handles. These meta-handles represent different possible deformations of the shape, with each meta-handle corresponding to an intuitive deformation. By sampling coefficients of the meta-handles within a specific range, we can generate new deformations. We use biharmonic coordinates as the deformation function, allowing smooth propagation of translations to the entire mesh. To prevent the learning of zero deformation meta-handles, we incorporate a target-fitting module that deforms the input mesh to match a random target. Additionally, we employ a soft-rasterizer-based discriminator to improve the plausibility of the deformations by projecting the meshes to a 2D space. Our experiments demonstrate the effectiveness of the generated deformations and the interpretability and consistency of the learned meta-handles. The code for our method is available at https://github.com/Colin97/DeepMetaHandles.