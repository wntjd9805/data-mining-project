This study addresses the limitations of existing weakly-supervised semantic segmentation methods that use image-level weak supervision. These limitations include sparse object coverage, inaccurate object boundaries, and the presence of pixels from non-target objects. To overcome these challenges, the authors propose a new framework called Explicit Pseudo-pixel Supervision (EPS). EPS learns from pixel-level feedback by combining two weak supervisions: the image-level label provides object identity through the localization map, and the saliency map from a saliency detection model offers accurate object boundaries. The authors employ a joint training strategy to effectively utilize the complementary relationship between these two sources of information. Their method successfully produces accurate object boundaries and eliminates co-occurring pixels, resulting in significantly improved pseudo-masks. Experimental results demonstrate that the proposed method outperforms existing methods by effectively addressing the key challenges of weakly-supervised semantic segmentation. It achieves state-of-the-art performance on the PAS-CAL VOC 2012 and MS COCO 2014 datasets. The code for the proposed method is available at the provided GitHub link. Figure 1 illustrates the effectiveness of utilizing both the saliency map and the localization map for weakly-supervised semantic segmentation, showing that the proposed EPS method correctly restores objects that the saliency map fails to capture, while also addressing the issue of the localization map overly capturing multiple objects.