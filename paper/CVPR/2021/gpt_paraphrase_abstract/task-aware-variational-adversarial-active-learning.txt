Labeling a large amount of data for deep learning techniques can be costly, which limits their application. Active learning (AL) addresses this issue by selecting the most informative samples from an unlabeled pool to be annotated. Two recent approaches in AL include a task-agnostic approach that selects data points far from the labeled pool and a task-aware approach that considers the perspective of the task model. However, the task-agnostic approach does not utilize task structures, and the task-aware approach does not effectively utilize the overall data distribution. To overcome these limitations, we propose a task-aware variational adversarial AL (TA-VAAL) method. TA-VAAL modifies the task-agnostic VAAL by incorporating the data distribution of both labeled and unlabeled pools, replacing task learning loss prediction with ranking loss prediction, and embedding normalized ranking loss information using a ranking conditional generative adversarial network. Our proposed TA-VAAL outperforms existing approaches on various benchmark datasets for classification tasks with balanced/imbalanced labels, as well as semantic segmentation. Furthermore, our in-depth analyses confirm the task-aware and task-agnostic properties of TA-VAAL.