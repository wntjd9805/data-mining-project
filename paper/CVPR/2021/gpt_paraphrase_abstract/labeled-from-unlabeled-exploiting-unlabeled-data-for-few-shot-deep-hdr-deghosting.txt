This paper presents a novel approach to High Dynamic Range (HDR) deghosting, which is a crucial tool for capturing scenes with a wide dynamic range without ghosting artifacts. Current CNN-based methods for HDR deghosting require large datasets with ground truth, which is a time-consuming process. In this study, we propose a pioneering method that utilizes zero and few-shot learning strategies to achieve data-efficient HDR deghosting. Our approach involves two stages of training. In the first stage, we train the model using a small number of labeled dynamic samples (5 or less) and a large pool of unlabeled samples with a self-supervised loss. The trained model is then used to predict HDRs for the unlabeled samples. To generate data for the second stage of training, we propose a novel method for creating corresponding dynamic inputs from the predicted HDRs of the unlabeled data. These generated artificial dynamic inputs, along with the predicted HDRs, are used as paired labeled data. In the second stage, we fine-tune the model using the original few labeled data and the artificially generated labeled data. Our few-shot approach outperforms many fully-supervised methods in two publicly available datasets, even with as few as five labeled dynamic samples.