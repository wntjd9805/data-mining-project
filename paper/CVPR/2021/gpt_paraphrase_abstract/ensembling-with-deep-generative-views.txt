Recent advancements in generative models have allowed for the creation of artificial images that closely resemble real-world variations, such as changes in color or pose, by learning from unlabeled image collections. In this study, we explore the potential benefits of applying these generated "views" to real images for tasks like image classification.   To achieve this, we utilize a pre-trained generator to determine the latent code that corresponds to a given real input image. By introducing perturbations to this code, we can generate natural variations of the image, which can then be combined at test-time. We employ StyleGAN2 as our source for generative augmentations and evaluate this approach on classification tasks involving facial attributes, cat faces, and cars.   However, we find that several key considerations must be taken into account to ensure the success of this process. The perturbation procedure, balancing the weight between the augmented images and the original image, and training the classifier on synthesized images all have an impact on the final results. Currently, we observe that while test-time ensembling with GAN-based augmentations can bring about slight improvements, the efficiency and accuracy of GAN reconstructions, along with the classifier's sensitivity to artifacts in GAN-generated images, remain as the main bottlenecks.