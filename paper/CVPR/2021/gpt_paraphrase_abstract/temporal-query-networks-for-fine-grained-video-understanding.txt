Our aim in this study is to accurately classify actions in untrimmed videos, including both temporally extended actions and actions that occur within a few frames. To achieve this, we propose a query-response mechanism where each query corresponds to a specific question and has its own set of response labels. Our first contribution is the development of a novel model called the Temporal Query Network (TQN) that enables this query-response functionality and provides a structural understanding of fine-grained actions. The TQN incorporates a temporal attention mechanism to focus on relevant segments for each query and can be trained using the labels associated with each query. Secondly, we introduce a new approach called stochastic feature bank update, which allows for training the network on videos of varying lengths with the dense sampling required for accurate responses to fine-grained queries. We compare the TQN with other architectures and text supervision methods, analyzing their advantages and disadvantages. Finally, our method is extensively evaluated on the FineGym and Diving48 benchmarks for fine-grained action classification. Remarkably, our approach achieves state-of-the-art performance using only RGB features. The project page for this work can be found at https://www.robots.ox.ac.uk/~vgg/research/tqn/. The output of our answer format is limited to the abstract.