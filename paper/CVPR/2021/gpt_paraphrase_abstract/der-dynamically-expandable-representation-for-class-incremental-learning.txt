We focus on the issue of class incremental learning, an essential step towards achieving adaptive vision intelligence. Specifically, we aim to improve the trade-off between stability and plasticity in the task of incremental learning with limited memory. To address this, we propose a new two-stage learning approach that utilizes a flexible representation to enhance the modeling of new concepts. In each incremental step, we freeze the previously learned representation and expand it with additional feature dimensions from a new learnable feature extractor. This allows us to integrate new visual concepts while retaining the knowledge we have already acquired. To adapt to the complexity of novel concepts, we dynamically expand the representation using a mask-based pruning strategy at the channel level. Additionally, we introduce an auxiliary loss to encourage the model to learn diverse and discriminative features for the new concepts. Through extensive experiments on three class incremental learning benchmarks, our method consistently outperforms other approaches by a significant margin.