Generative models that can create various types of layouts, such as documents, user interfaces, or furniture arrangements, are valuable tools for assisting design processes and generating synthetic data. In this study, we leverage the properties of self-attention layers to capture the relationships between elements in a layout. These relationships serve as the foundation for our proposed Variational Transformer Network (VTN), which is built upon the well-known Variational Autoencoder (VAE) formulation. The VTN can learn global design rules, including margins, alignments, and other aspects, without the need for explicit supervision. The layouts generated by our model closely resemble the training data while exhibiting desirable diversity. Through extensive evaluations using publicly available benchmarks for various layout types, our VTN achieves state-of-the-art diversity and perceptual quality. Furthermore, we demonstrate the effectiveness of this method in a document layout detection pipeline.