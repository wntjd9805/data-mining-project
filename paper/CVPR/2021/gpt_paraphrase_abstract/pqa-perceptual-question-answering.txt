Perceptual organization, a well-established theory on the human visual system, has experienced a decline in research interest due to the focus on deep learning models. Previous attempts to interpret complex visual scenes using perceptual organizational rules have proven to be ineffective in capturing the complexity of real-world imagery. To rejuvenate the study of perceptual organization, this paper proposes two changes: using purposefully generated synthetic data instead of real imagery, and synthesizing novel perceptually-valid patterns instead of explaining existing data. This is achieved through the introduction of the perceptual question answering (PQA) challenge, where machines generate answers from scratch based on example question-answer pairs. The paper presents the first dataset of perceptual question-answer pairs, each focusing on a specific Gestalt principle. Drawing insights from human psychology, an agent is designed to solve PQA by treating perceptual organization as a self-attention problem, generating answer patterns directly from a grid-to-grid mapping network. Experimental results show that our agent outperforms baseline models. However, a human study reveals that our agent requires significantly more data to learn compared to an average human, highlighting the need for further research. The answer format in our approach focuses on abstraction.