This abstract presents a novel method for real-time full body capture that can estimate the shape and motion of the body, hands, and a dynamic 3D face model from a single color image. The approach utilizes a new neural network architecture that takes advantage of the correlations between the body and hands, making it computationally efficient. Unlike previous methods, this approach is trained on multiple datasets that focus on the hand, body, or face individually, rather than requiring data where all parts are annotated simultaneously. This multi-dataset training allows for superior generalization ability. In comparison to previous monocular full body methods, this approach is able to capture more detailed 3D face geometry and color by estimating shape, expression, albedo, and illumination parameters of a statistical face model. The method achieves competitive accuracy on public benchmarks, while also being faster and providing more comprehensive face reconstructions.