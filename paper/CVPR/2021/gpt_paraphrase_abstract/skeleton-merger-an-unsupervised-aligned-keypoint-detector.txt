Detecting aligned 3D keypoints is crucial for various applications such as object tracking, shape retrieval, and robotics. However, creating a high-quality dataset for all object types is challenging due to the inherent ambiguity of keypoints. Additionally, existing unsupervised detectors struggle to generate aligned keypoints with sufficient coverage. In this study, we propose an unsupervised aligned keypoint detector called Skeleton Merger. This detector leverages skeletons to reconstruct objects and is based on an Autoencoder architecture. The encoder suggests keypoints and predicts the activation strengths of edges connecting these keypoints. The decoder then performs uniform sampling on the skeleton and refines it into small point clouds with pointwise offsets. Activation strengths are applied, and the sub-clouds are merged using a proposed Composite Chamfer Distance (CCD) metric. CCD measures the distance between the input point cloud and the reconstruction composed of sub-clouds masked by activation strengths. We demonstrate that Skeleton Merger is capable of detecting semantically-rich salient keypoints with good alignment. Furthermore, it achieves comparable performance to supervised methods on the KeypointNet dataset. The detector also exhibits robustness to noise and subsampling. The code for Skeleton Merger is publicly available at https://github.com/eliphatfs/SkeletonMerger.