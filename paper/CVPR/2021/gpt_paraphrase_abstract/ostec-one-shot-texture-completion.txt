Non-linear generative models have been successful in creating realistic face images. However, current approaches for 3D facial texture reconstruction and pose manipulation require large and clean datasets, which are expensive and difficult to maintain. Additionally, regression-based methods struggle with generalization and fine-tuning. To address these issues, this study proposes an unsupervised one-shot approach for 3D facial texture completion. Instead of relying on large-scale datasets, the approach utilizes knowledge from 2D face generators. It rotates an input image in 3D and fills in the unseen regions by reconstructing the rotated image using a 2D face generator. The most visible textures at different angles are then stitched together in the UV image-plane. The completed texture is projected into the generator to frontalize the target image. Experimental results demonstrate that the completed UV textures and frontalized images are high quality, maintain the original identity, and can be used to train a texture GAN model for 3DMM fitting and improve pose-invariant face recognition.