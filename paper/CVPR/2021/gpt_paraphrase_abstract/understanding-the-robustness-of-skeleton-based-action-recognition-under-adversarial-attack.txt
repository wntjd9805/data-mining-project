In this study, we investigate the robustness of current action recognition systems against adversarial attacks, which has been largely unexplored thus far. We propose a novel method to attack action recognition systems that rely on 3D skeletal motion. Our method incorporates a unique perceptual loss to ensure that the attack remains imperceptible. Through empirical studies, we demonstrate the effectiveness of our method in both white-box and black-box scenarios. We also showcase its generalizability across various action recognition systems and datasets, as well as its versatility in different attacking strategies. Extensive perceptual studies confirm the deceitfulness of our method. The results highlight the significant differences between adversarial attacks on 3D skeletal motions and traditional adversarial attack problems. The successful implementation of our method raises concerns about the robustness of action recognition systems and provides valuable insights for potential improvements.