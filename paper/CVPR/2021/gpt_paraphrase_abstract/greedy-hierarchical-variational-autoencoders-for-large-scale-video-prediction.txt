A video prediction model that can be applied to different types of scenes would allow intelligent agents like robots to perform various tasks by planning with the model. However, current video prediction models, while showing promising results on small datasets, struggle with underfitting when trained on large and diverse datasets. To overcome this underfitting issue, we recognize that the limited memory capacity of GPUs or TPUs often hinders the training of larger video prediction models. Additionally, deep hierarchical latent variable models can generate more accurate predictions by capturing the multiple levels of uncertainty in future observations, but optimizing such models end-to-end is challenging. Our main insight is that by employing a greedy and modular optimization approach to hierarchical autoencoders, we can effectively address both the memory constraints and optimization difficulties associated with large-scale video prediction. We present Greedy Hierarchical Variational Autoencoders (GHVAEs), a method that learns highly accurate video predictions by training each level of a hierarchical autoencoder in a greedy manner. Compared to state-of-the-art models, GHVAEs achieve a 17-55% improvement in prediction performance across four video datasets, a 35-40% higher success rate in real robot tasks, and performance can be further enhanced by simply adding more modules. For visualization and additional details, please refer to https://sites.google.com/view/ghvae.