The abstract discusses a new framework for learning dynamics models that have a low-dimensional latent state space. This framework is designed to enable proportional control in the latent space, making it possible to use simple PID controllers. The authors demonstrate that their learned dynamics model allows for proportional control directly from pixel inputs, simplifies and speeds up behavioral cloning of vision-based controllers, and facilitates interpretable goal discovery in imitation learning of switching controllers. Additionally, the proportional controlability enables robust path following from visual demonstrations using Dynamic Movement Primitives in the learned latent space.