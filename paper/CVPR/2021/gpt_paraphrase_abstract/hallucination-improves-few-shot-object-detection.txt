Learning to detect new objects with limited annotated examples is highly important in practice. One common yet challenging scenario arises when there are very few examples available (less than three). A key factor in enhancing few-shot detection is addressing the lack of variation in the training data. We suggest constructing a better model of variation for new classes by transferring shared variation within the same class from base classes. For this purpose, we introduce a hallucinator network that learns to generate additional useful training examples in the feature space of the region of interest (RoI), and incorporate it into a modern object detection model. Our approach significantly improves the performance of two state-of-the-art few-shot detectors that employ different proposal generation methods. Notably, we achieve a new state-of-the-art performance in the extremely few-shot scenario on the challenging COCO benchmark.