Predicting multiple possible future paths of nearby vehicles is essential for the safety of autonomous driving. Current methods for motion prediction aim to achieve this by either implicitly regularizing the features or explicitly generating multiple candidate proposals. However, this is challenging as latent features may focus on the most common mode of the data, and proposal-based methods heavily rely on prior knowledge to generate and select proposals.In this study, we introduce a new framework called mmTransformer for multimodal motion prediction. We propose a unique network architecture based on stacked transformers to capture the multimodality at the feature level using a set of fixed independent proposals. To induce the multimodality of the generated proposals, we develop a region-based training strategy.Experiments conducted on the Argoverse dataset demonstrate that our proposed model, mmTransformer, achieves state-of-the-art performance in motion prediction. It significantly enhances the diversity and accuracy of the predicted trajectories. For more information, including a demonstration video and code, please visit https://decisionforce.github.io/mmTransformer.