Point cloud semantic segmentation often requires a large amount of annotated training data, which can be a tedious task. However, recent methods have proposed training 3D networks with a small percentage of point labels. In this study, we take a more extreme approach called "One Thing One Click," where annotators only need to label one point per object. To effectively use these sparse labels in network training, we develop a novel self-training approach. This approach involves iterative training and label propagation using a graph propagation module. Additionally, we utilize a relation network to generate per-category prototypes and explicitly model the similarity between graph nodes. This allows us to generate pseudo labels that guide the iterative training process. Our experimental results on ScanNet-v2 and S3DIS datasets demonstrate that our self-training approach, with extremely sparse annotations, significantly outperforms existing weakly supervised methods for 3D semantic segmentation. Furthermore, our results are comparable to those achieved by fully supervised approaches.