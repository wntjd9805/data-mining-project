Recent advancements in self-supervised learning have resulted in the development of models capable of extracting meaningful representations from image collections without the need for explicit labeling. However, most of these approaches have been limited to training on standard benchmark datasets like ImageNet. We argue that fine-grained visual categorization problems, such as classifying plant and animal species, present a valuable opportunity for evaluating self-supervised learning methods. To facilitate progress in this area, we introduce two new datasets: iNat2021 and NeWT. iNat2021 comprises 2.7 million images from 10,000 different species contributed by users of the citizen science application iNaturalist. NeWT, developed in collaboration with domain experts, aims to benchmark representation learning algorithms on challenging natural world binary classification tasks that extend beyond standard species classification. These datasets enable us to investigate questions related to large-scale representation and transfer learning in the context of fine-grained categories. We conduct a comprehensive analysis of feature extractors trained with and without supervision on ImageNet and iNat2021, revealing the strengths and weaknesses of different learned features across a diverse range of tasks. Our findings indicate that features generated by conventional supervised methods still outperform those produced by self-supervised approaches like SimCLR. Nevertheless, ongoing advancements in self-supervised learning methods and the availability of iNat2021 and NeWT datasets serve as valuable resources for tracking progress in this field.