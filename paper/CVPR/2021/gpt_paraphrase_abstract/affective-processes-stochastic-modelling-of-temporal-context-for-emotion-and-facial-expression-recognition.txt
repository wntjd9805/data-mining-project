Temporal context is crucial for recognizing emotional expressions. Current methods that use recurrent or self-attention models to ensure temporal consistency only focus on the feature level and disregard task-specific temporal dependencies, resulting in a failure to capture context uncertainty. To address these limitations, we propose a new approach based on Neural Processes for apparent emotion recognition. Our method introduces three key components: (a) a probabilistic contextual representation with a global latent variable model, (b) temporal context modeling that incorporates task-specific predictions along with features, and (c) intelligent selection of temporal context. We evaluate our approach on four databases, including SEWA and AffWild2 for Valence and Arousal estimation, and DISFA and BP4D for Action Unit intensity estimation. Experimental results demonstrate consistent improvements compared to strong baselines and state-of-the-art methods.