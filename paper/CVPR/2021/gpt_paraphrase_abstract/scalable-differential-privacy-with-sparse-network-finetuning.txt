We present a new approach to protect the privacy of deep neural network training using public data from different domains. While differential privacy (DP) has been effective in safeguarding sensitive training data, it faces challenges when applied to complex visual recognition tasks. Traditional DP methods like DP-SGD perform well only on simple datasets and shallow networks, while recent transfer learning-based DP methods make unrealistic assumptions about the availability and distribution of public data. We propose that reducing the number of trainable parameters is crucial for improving the tradeoff between privacy and performance in DP for complex visual recognition tasks. Building upon this idea, we introduce a novel transfer learning method that fine-tunes a sparse subnetwork with DP. Through extensive experiments and ablation studies on two visual recognition tasks (CIFAR-100 to CIFAR-10 in a standard DP setting and the CD-FSL challenge with few-shot learning and multiple domain shifts), we demonstrate competitive performance.