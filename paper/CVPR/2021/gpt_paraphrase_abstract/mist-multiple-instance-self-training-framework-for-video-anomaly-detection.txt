This study focuses on weakly supervised video anomaly detection (WS-VAD) and the limitations of current approaches in generating accurate video representations. The researchers propose a multiple instance self-training framework (MIST) to improve the quality of discriminative representations using only video-level annotations. MIST consists of two components: a multiple instance pseudo label generator that employs a sparse continuous sampling strategy to generate reliable clip-level pseudo labels, and a self-guided attention boosted feature encoder that automatically highlights anomalous regions in frames and extracts task-specific representations. The researchers also employ a self-training scheme to optimize both components and obtain a task-specific feature encoder. The effectiveness of the proposed method is demonstrated through extensive experiments on two public datasets, showing comparable or better performance compared to existing supervised and weakly supervised methods. Specifically, the proposed method achieves a frame-level AUC of 94.83% on the ShanghaiTech dataset.