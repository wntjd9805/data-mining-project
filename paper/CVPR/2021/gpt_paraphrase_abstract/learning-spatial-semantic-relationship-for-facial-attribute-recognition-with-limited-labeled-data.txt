Deep learning has shown great success in Facial Attribute Recognition (FAR) but is limited by the availability of labeled data in real-world applications. To address this issue, we propose Spatial-Semantic Patch Learning (SSPL). SSPL involves two stages: First, we develop three auxiliary tasks (Patch Rotation Task, Patch Segmentation Task, and Patch Classification Task) to learn spatial-semantic relationships from unlabeled facial data, resulting in a powerful pre-trained model. Second, we transfer the knowledge learned from the auxiliary tasks to the FAR task, requiring only a limited number of labeled data for fine-tuning. Our method outperforms state-of-the-art methods in extensive experiments and studies.