This paper focuses on the task of video rescaling, which involves adjusting the spatial resolution of a video to match different viewing devices. The authors propose two joint optimization approaches for video downscaling and upscaling, using invertible neural networks with coupling layers. The first approach, LSTM-VRN, utilizes temporal information in low-resolution video to predict missing high-frequency details for upscaling. The second approach, MIMO-VRN, introduces a new strategy for simultaneously downscaling and upscaling a group of video frames. Both approaches outperform image-based models in terms of quantitative and qualitative results, and they also significantly improve upscaling quality compared to video rescaling methods that do not employ joint optimization. This work is the first attempt to jointly optimize video downscaling and upscaling. The authors compare different video rescaling frameworks, including single-input single-output (SISO) for both operations, SISO for downscaling and multi-input single-output (MISO) for upscaling, and their proposed multi-input multi-output (MIMO) approach.