This study aims to segment high-resolution images while avoiding excessive GPU memory usage and maintaining fine details in the segmentation map. To overcome memory constraints, the options are downsampling the image or dividing it into patches for separate processing. However, downsampling leads to loss of fine details, and patch-based processing lacks a global perspective. To address these challenges, the authors propose Mag-Net, a multi-scale framework that resolves local ambiguity by considering the image at multiple magnification levels. Mag-Net consists of multiple processing stages, each corresponding to a magnification level. The output of one stage feeds into the next, allowing for coarse-to-fine information propagation. By analyzing the image at progressively higher resolutions, Mag-Net recovers lost details and refines the segmentation output. Experimental results on urban, aerial, and medical image datasets demonstrate that Mag-Net consistently outperforms state-of-the-art methods. The code for Mag-Net is available at https://github.com/VinAIResearch/MagNet.