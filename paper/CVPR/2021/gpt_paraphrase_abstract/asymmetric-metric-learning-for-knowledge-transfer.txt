Recently, researchers have been exploring the transfer of knowledge from large teacher models to smaller student models in the context of metric learning, specifically for fine-grained classification. This study focuses on instance-level image retrieval and examines an asymmetric testing task, where the teacher represents the database and the student represents the queries. Building on this task, the authors propose a novel approach called asymmetric metric learning, which involves using asymmetric representations during training. This approach combines knowledge transfer with the original metric learning task. The authors conduct a systematic evaluation of different teacher and student models, as well as metric learning and knowledge transfer loss functions, on both the new asymmetric testing task and the standard symmetric testing task, where the same model represents both the database and queries. Surprisingly, the authors find that plain regression is highly effective compared to more complex knowledge transfer mechanisms, particularly in asymmetric testing. Interestingly, the asymmetric metric learning approach performs best in symmetric testing, enabling the student model to even outperform the teacher model.The authors have made their implementation publicly available, including trained student models for all loss functions and teacher-student model pairs.