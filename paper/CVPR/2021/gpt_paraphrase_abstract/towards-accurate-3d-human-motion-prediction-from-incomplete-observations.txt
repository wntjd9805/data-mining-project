Generating accurate and realistic predictions of future human poses from incomplete historical motion sequences is a crucial task in the fields of computer vision, graphics, and artificial intelligence. Despite significant progress in this area, existing methods are limited by their inability to handle missing values in the motion sequences, leading to unexpected predictions or deformities. Additionally, frequent occurrences of incomplete motion data due to occlusion and equipment imprecision hinder the practical application of current algorithms.In this study, we address this challenging problem by proposing a novel approach called the multi-task graph convolutional network (MT-GCN). Our model consists of two branches: the primary task focuses on accurately forecasting future 3D human actions, while the auxiliary task aims to repair the missing values in the incomplete observations. Both tasks are integrated into a unified framework, allowing them to share spatio-temporal representation and enhance overall performance. Through extensive experiments on three large-scale datasets with various real-world missing data scenarios, we consistently outperform state-of-the-art methods that do not explicitly analyze missing values in incomplete observations.