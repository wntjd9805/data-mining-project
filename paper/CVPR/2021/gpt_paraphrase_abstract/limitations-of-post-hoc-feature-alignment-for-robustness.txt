Feature alignment is a method used to enhance resistance to distribution shift by matching the distribution of feature activations in training and test data. One effective approach to feature alignment is aligning the batch normalization statistics in a trained neural network. This technique has gained attention for its strong performance on robustness benchmarks. However, there is limited understanding of when and why this method is successful. To gain further insights, we thoroughly investigate this approach and discover several limitations. We find that it significantly improves performance only for a specific range of distribution shifts, and in some cases, it even worsens performance. We also explain the reasons behind the effectiveness of this approach. These findings raise doubts about the practical utility of this method and Unsupervised Domain Adaptation in general for enhancing robustness.