This paper introduces a new approach to video person re-identification by presenting an efficient spatial-temporal representation. The authors propose a Bilateral Complementary Network (BiCnet) that consists of two branches: the Detail Branch and the Context Branch. The Detail Branch processes frames at their original resolution to capture detailed visual clues, while the Context Branch uses a down-sampling strategy to capture long-range contexts. Both branches incorporate multiple attention modules to identify different body parts across consecutive frames, resulting in a comprehensive representation of the target identity. Additionally, a Temporal Kernel Selection (TKS) block is introduced to capture both short-term and long-term temporal relations in an adaptive manner. This TKS block can be inserted at any depth within BiCnet, resulting in BiCnet-TKS for spatial-temporal modeling. Experimental results on multiple benchmarks demonstrate that BiCnet-TKS outperforms existing methods while requiring 50% less computations. The source code for BiCnet-TKS is available at https://github.com/blue-blue272/BiCnet-TKS.