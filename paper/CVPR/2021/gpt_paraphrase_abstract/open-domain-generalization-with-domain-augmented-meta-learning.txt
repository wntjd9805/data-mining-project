Leveraging available datasets to develop a model that can effectively generalize to unseen domains is crucial in the field of computer vision, especially when the annotated data for the unseen domains is not available. Our research focuses on a practical and novel problem called Open Domain Generalization (OpenDG), where we aim to achieve high performance on an unknown target domain by learning from different source domains, even when the distributions and label sets of each domain differ. This problem has broad applications in real-world scenarios and can be applied to diverse source domains. To address this, we propose a Domain-Augmented Meta-Learning framework that learns representations capable of open-domain generalization. We enhance the domains both at the feature-level using a new Dirichlet mixup technique and at the label-level through distilled soft-labeling, which incorporates missing classes and domain-specific knowledge. Our approach involves meta-learning over domains, where we design new meta-learning tasks and losses to preserve domain-specific knowledge while also generalizing knowledge across domains. Through experiments on various multi-domain datasets, we demonstrate that our proposed Domain-Augmented Meta-Learning (DAML) outperforms existing methods for recognizing unseen domains.