Ref-SR methods aim to enhance low-resolution (LR) input images by utilizing high-resolution (HR) reference images. However, existing methods struggle with the gaps between input and reference images, namely the transformation gap (e.g., scale and rotation) and the resolution gap (e.g., HR and LR). To address these challenges, this study proposes C2-Matching, a method that explicitly matches input and reference images by overcoming transformation and resolution gaps. To bridge the transformation gap, a contrastive correspondence network is introduced. This network learns transformation-robust correspondences using augmented views of the input image. As for the resolution gap, a teacher-student correlation distillation approach is adopted. This approach distills knowledge from easier HR-HR matching to guide more ambiguous LR-HR matching. To handle potential misalignment issues, a dynamic aggregation module is designed. To ensure realistic evaluation, the researchers contribute the Webly-Referenced SR (WR-SR) dataset, which mimics practical usage scenarios. Extensive experiments demonstrate that C2-Matching outperforms state-of-the-art methods by over 1dB on the CUFED5 benchmark. It also exhibits strong generalizability on the WR-SR dataset and robustness against large scale and rotation transformations.