Despite the impressive performance of deep models in recognizing images, they are easily affected by common corruptions like blur, noise, and low-resolution. To address this issue, data augmentation is commonly used to train robust models that can handle these corruptions. However, a simplistic data augmentation approach may lead to a model that is not specialized for specific corruptions, as it tends to learn the average distribution across all corruptions. To overcome this challenge, we propose a new training method for deep image recognition networks that can generate clean-like features from images of any quality using an invertible neural architecture. Our method consists of two stages. In the first stage, we train an invertible network exclusively on clean images, focusing on the recognition objective. In the second stage, we attach the invertible decoder, which is the inverse of the network, to a new recognition network. We then train this encoder-decoder network using both clean and corrupted images, considering both recognition and reconstruction objectives. This two-stage approach enables the network to generate clean-like and robust features from images of any quality by reconstructing their clean versions using the invertible decoder. We demonstrate the effectiveness of our method on tasks such as image classification and face recognition.