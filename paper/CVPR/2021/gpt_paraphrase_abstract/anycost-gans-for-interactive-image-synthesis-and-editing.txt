Generative adversarial networks (GANs) have revolutionized image synthesis and editing by creating photorealistic images. However, the computationally intensive nature of large-scale generators like StyleGAN2 results in a delay of several seconds to view the outcome of a single edit on edge devices, restricting interactive user experience. To overcome this limitation, we introduce Anycost GAN, inspired by quick preview features in modern rendering software, for interactive natural image editing. AnycostGAN is trained to support flexible resolutions and channels, enabling faster image generation at variable speeds. By running subsets of the full generator, we obtain visually similar outputs that serve as a reliable quick preview. Our approach incorporates sampling-based multi-resolution training, adaptive-channel training, and a generator-conditioned discriminator, resulting in improved image quality compared to separately trained models. Moreover, we introduce novel encoder training and latent code optimization techniques to ensure consistency among different sub-generators during image projection. Anycost GAN can operate within different cost budgets, achieving up to a 10× reduction in computation while accommodating a wide range of hardware and latency requirements. When deployed on desktop CPUs and edge devices, our model enables interactive image editing with perceptually similar previews at a speedup of 6-12×. We have made the code and demo publicly available.