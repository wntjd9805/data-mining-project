The increasing use of camera devices has resulted in the availability of numerous image datasets, creating opportunities for collaboration between the machine learning community and industry. However, the sensitive information contained in these datasets has deterred data owners from releasing them. Despite recent attempts to remove sensitive information from images, existing methods fail to offer a meaningful trade-off between privacy and utility, and they lack provable privacy guarantees. To address this, we propose a new privacy notion called perceptual indistinguishability (PI) specifically for images, taking into account perceptual similarity. We also introduce PI-Net, a privacy-preserving mechanism that employs image obfuscation while ensuring PI guarantee. Our study demonstrates that PI-Net achieves a significantly improved trade-off between privacy and utility using publicly available image data.