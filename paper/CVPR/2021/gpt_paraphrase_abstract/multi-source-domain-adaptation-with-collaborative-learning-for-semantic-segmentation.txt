This paper presents a new approach to multi-source unsupervised domain adaptation (MSDA) for semantic segmentation. The goal is to adapt models trained on multiple labeled source domains to an unlabeled target domain. The proposed framework includes two main components. Firstly, a simple image translation method is used to align the pixel value distribution between the source domains and the target domain. This helps reduce the gap between them to some extent. Secondly, a collaborative learning method is introduced to leverage the essential semantic information across the source domains without using any data from the target domain. This method improves the adaptation by training multiple adaptation models and constraining their outputs with pseudo labels generated by an ensembled model using the unlabeled target domain data. Extensive experiments and ablation studies are conducted on popular benchmark datasets for semantic segmentation in domain adaptation. The proposed method achieves a mean Intersection over Union (mIoU) of 59.0% on the validation set of Cityscapes when trained on the labeled Synscapes and GTA5 datasets as well as the unlabeled training set of Cityscapes. It outperforms previous state-of-the-art single-source and multi-source unsupervised domain adaptation methods.