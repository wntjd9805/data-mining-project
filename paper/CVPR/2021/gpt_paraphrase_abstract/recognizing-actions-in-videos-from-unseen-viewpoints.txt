Current methods for video recognition rely on large CNNs that are trained using labeled training data. However, these models struggle to recognize actions when presented with camera viewpoints that were not included in their training data. To overcome this limitation, we propose using 3D representations and a new geometric convolutional layer that can learn viewpoint invariant representations. Additionally, we introduce a new dataset that poses a challenge for unseen view recognition and demonstrate the effectiveness of our approaches in learning viewpoint invariant representations.