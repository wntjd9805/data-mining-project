Neural signed distance functions (SDFs) have become a popular way to represent 3D shapes. Current methods use large neural networks to approximate complex shapes with implicit surfaces, but rendering with these networks is computationally expensive and not suitable for real-time graphics. In this study, we propose a more efficient neural representation that allows for real-time rendering of high-fidelity neural SDFs without compromising on geometry reconstruction quality. Our approach involves using an octree-based feature volume to represent implicit surfaces, which allows for adaptive fitting of shapes with multiple levels of detail (LODs) and continuous LOD with SDF interpolation. We have also developed an efficient algorithm that can directly render our novel neural SDF representation in real-time by querying only the necessary LODs through sparse octree traversal. Our results show that our representation is significantly faster in terms of rendering speed compared to previous works, with a speed improvement of 2-3 orders of magnitude. Additionally, our approach achieves state-of-the-art reconstruction quality for complex shapes, as evaluated using both 3D geometric and 2D image-space metrics.