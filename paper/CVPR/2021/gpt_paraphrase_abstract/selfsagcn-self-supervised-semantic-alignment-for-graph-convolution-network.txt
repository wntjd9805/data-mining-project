Graph convolution networks (GCNs) have been successful in learning representations on graphs in various real-world applications. However, there are two main weaknesses that limit their ability to represent graph-structured data. Firstly, GCNs perform poorly when labeled data is scarce. Secondly, as more layers are stacked, the features become indistinguishable. In this paper, we introduce a solution called Self-Supervised Semantic Alignment Graph Convolution Network (SelfSAGCN) to address these weaknesses. SelfSAGCN consists of two key techniques: Identity Aggregation and Semantic Alignment. The main idea is to map node features from the same class, learned from semantic and graph structural aspects, to nearby locations. The Identity Aggregation technique extracts semantic features from labeled nodes, while Semantic Alignment aligns node features using class central similarity. This approach alleviates the over-smoothing issue and enhances the similarities between unlabeled features and labeled ones from the same class. Experimental results on five popular datasets demonstrate that SelfSAGCN outperforms existing methods in various classification tasks.