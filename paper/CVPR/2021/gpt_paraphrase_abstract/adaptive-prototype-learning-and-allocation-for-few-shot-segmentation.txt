This study introduces two new modules, superpixel-guided clustering (SGC) and guided prototype allocation (GPA), to improve the performance of few-shot segmentation. Currently, a single prototype is used to represent the global object information, which can result in ambiguities. The SGC module aggregates similar feature vectors to extract more representative prototypes, while the GPA module selects matched prototypes for more accurate guidance. By combining these modules, the Adaptive Superpixel-guided Network (ASGNet) is proposed, which is a lightweight model that can adapt to object scale and shape variations. Furthermore, the ASGNet can easily generalize to k-shot segmentation with significant improvement and no additional computational cost. Experimental results on COCO dataset show that ASGNet outperforms the state-of-the-art method by 5% in 5-shot segmentation.