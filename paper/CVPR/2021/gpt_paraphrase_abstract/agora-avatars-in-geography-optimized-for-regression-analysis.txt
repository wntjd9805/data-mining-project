Despite recent advancements in 3D human pose estimation from images, current methods still struggle in real-world scenarios. This suggests a gap between existing datasets and the complexity of common scenes involving people. Current datasets limit factors such as clothing, environmental conditions, number of subjects, and occlusion when obtaining ground-truth 3D pose. Additionally, they only evaluate sparse 3D joint locations, neglecting hand pose and face shape. To address these limitations and challenge the field, we introduce AGORA, a synthetic dataset that provides high realism and accurate ground truth. AGORA consists of 4240 high-quality human scans, including 257 scans of children, with diverse poses and natural clothing. We create 3D poses and body shapes by fitting the SMPL-X body model, accounting for clothing. We generate around 14K training and 3K test images by rendering 5 to 15 people per image using image-based lighting or rendered 3D environments, ensuring physical plausibility and photorealism. AGORA comprises 173K individual person crops. We evaluate existing state-of-the-art methods on AGORA and discover their poor performance on images of children. Consequently, we improve the SMPL-X model to better capture the shape of children and fine-tune methods on AGORA, resulting in improved performance on both AGORA and 3DPW datasets, confirming the dataset's realism. We provide the registered 3D reference training data, rendered images, and a web-based evaluation site at https://agora.is.tue.mpg.de/.