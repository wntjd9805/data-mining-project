We introduce a novel single-view 3D reconstruction network, called D2IM-Net, that is designed to recover both topological shape structures and surface features from an input image. Our approach involves training the network to learn a disentangled reconstruction with two functions: one representing the overall 3D shape and the other capturing the details. The network encodes the input image into global and local features, which are then used by two separate decoders. The base decoder reconstructs a coarse implicit field using the global features, while the detail decoder reconstructs two displacement maps based on the local features, which describe the front and back sides of the object. The final 3D reconstruction is a fusion of the base shape and the displacement maps, and is guided by three loss functions that ensure the recovery of the coarse shape, overall structure, and surface details. We also introduce a novel Laplacian term to further enhance the reconstruction quality. This is the first network of its kind that is capable of recovering detailed geometric information from a single input image.