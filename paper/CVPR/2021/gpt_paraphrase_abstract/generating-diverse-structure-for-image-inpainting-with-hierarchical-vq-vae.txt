We propose a two-stage model for diverse image inpainting, addressing the issue of multiple plausible solutions lacking quality. In the first stage, our model generates multiple coarse results with different structures using a hierarchical vector quantized variational auto-encoder (VQ-VAE). This allows for diverse and high-quality structures. In the second stage, we introduce a structural attention module within the texture generation network to capture distant correlations using structural information. We also utilize the VQ-VAE to calculate feature losses that improve structure coherence and texture realism. Experimental results on various datasets demonstrate that our method enhances both the diversity and visual quality of the inpainted images. The code and models are available at: https://github.com/USTC-JialunPeng/Diverse-Structure-Inpainting.