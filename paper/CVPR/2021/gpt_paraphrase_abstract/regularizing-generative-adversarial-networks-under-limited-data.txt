The geNet benchmark is now available on GitHub at https://github.com/google/lecam-gan. In recent years, there have been significant advancements in generative adversarial networks (GANs). However, these models heavily rely on a large amount of training data for success. This study proposes a regularization approach that can effectively train robust GAN models with limited data. The authors establish a theoretical connection between the regularized loss and a robust f-divergence called LeCam-divergence, which performs well with limited training data. Extensive experiments on various benchmark datasets show that the proposed regularization scheme has two key benefits. Firstly, it improves the generalization performance and stabilizes the learning dynamics of GAN models when data is limited. Secondly, it complements existing data augmentation methods. These properties enable the training of GAN models that achieve state-of-the-art performance even with limited training data. Note: This research was conducted during HY's internship at Google Research.