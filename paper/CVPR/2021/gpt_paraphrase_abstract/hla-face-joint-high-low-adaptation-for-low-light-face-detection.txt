Detecting faces in low light situations is difficult but important for various applications like surveillance video and night-time autonomous driving. Most current face detectors rely heavily on extensive annotations, which can be time-consuming and labor-intensive to collect. To alleviate the burden of creating new datasets for low light conditions, we utilize existing normal light data and investigate how to adapt face detectors from normal light to low light scenarios. The main challenge lies in the significant and complex gap between normal and low light conditions at both pixel and object levels. Consequently, existing low-light enhancement and adaptation methods do not yield satisfactory results. To tackle this problem, we propose a joint High-Low Adaptation (HLA) framework. By incorporating bidirectional low-level adaptation and multi-task high-level adaptation techniques, our HLA-Face model surpasses state-of-the-art methods, even without the need for dark face labels during training. Our project is publicly accessible at: https://daooshee.github.io/HLA-Face-Website/.