The focus of most existing view synthesis methods is on perspective images, which have shown promising results. However, these methods struggle when large camera movements are involved due to the limited field-of-view of pinhole cameras. This paper presents a novel approach to generating new views from a single indoor panorama, taking into account the challenges posed by large camera translations. The approach involves using Convolutional Neural Networks (CNNs) to extract deep features and estimate the depth map from the source-view image. The room layout prior, which is a strong structural constraint of the indoor scene, is then utilized to guide the generation of target views. This is achieved by estimating the room layout in the source view and transforming it into the target viewpoint. Additionally, the room layout of the generated target-view images is constrained to ensure geometric consistency. To evaluate the effectiveness of the proposed method, a large-scale photo-realistic dataset is created, which includes both small and large camera translations. Experimental results on this challenging dataset demonstrate that the method achieves state-of-the-art performance. The project page containing more information can be found at https://github.com/bluestyle97/PNVS.