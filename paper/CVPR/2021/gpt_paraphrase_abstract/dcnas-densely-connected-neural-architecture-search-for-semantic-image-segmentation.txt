We propose a novel framework called Densely Connected NAS (DCNAS) for dense image prediction tasks. Unlike existing methods, our approach allows for a wider range of network architectures and avoids the gap between realistic and proxy settings. We achieve this by directly searching for optimal network structures for multi-scale representations of visual information on a large-scale target dataset without using a proxy. The key feature of our framework is the introduction of a densely connected search space, where cells are connected to each other using learnable weights, covering a variety of mainstream network designs. Additionally, we employ both path-level and channel-level sampling strategies, incorporating a fusion module and mixture layer to reduce memory consumption and facilitate proxyless searching. Experimental results demonstrate that our proxyless searching scheme effectively bridges the gap between searching and training environments. Furthermore, our DCNAS achieves state-of-the-art performance on public semantic image segmentation benchmarks, including 84.3% on Cityscapes and 86.9% on PASCAL VOC 2012. We also maintain leading performance on the more challenging ADE20K and PASCAL-Context datasets.