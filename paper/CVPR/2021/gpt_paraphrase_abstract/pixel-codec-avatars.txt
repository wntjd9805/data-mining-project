Telecommunication using photorealistic avatars in virtual or augmented reality shows promise in achieving authentic face-to-face communication in 3D across long distances. This study introduces the Pixel Codec Avatars (PiCA), a deep generative model of 3D human faces that offers high-quality reconstruction performance while being computationally efficient and adaptable to different rendering conditions. The PiCA model incorporates two key concepts: a fully convolutional architecture for decoding spatially varying features and a rendering-adaptive per-pixel decoder. These techniques are combined through a dense surface representation that is learned in a weakly-supervised manner from low-topology mesh tracking in training images. The study demonstrates that PiCA outperforms existing techniques in reconstructing facial expressions and views for individuals of different genders and skin tones. Notably, the PiCA model is significantly smaller than the current state-of-the-art baseline model, enabling real-time rendering of multiple avatars in the same scene on a single Oculus Quest 2 mobile VR headset.