This paper introduces the Fashion IQ dataset, which supports and advances research on interactive fashion image retrieval. Unlike classical keyword-based search interfaces, conversational interfaces in the retail fashion domain are more natural, expressive, and user friendly. The Fashion IQ dataset includes human-generated captions that differentiate similar pairs of garment images, as well as real-world product descriptions and visual attribute labels for these images. The paper provides a detailed analysis of the dataset's characteristics and presents a transformer-based user simulator and interactive image retriever that can integrate visual attributes, image features, user feedback, and dialog history. This approach improves performance in dialog-based image retrieval compared to existing methods. The authors believe that the Fashion IQ dataset will inspire further development of conversational shopping assistants that are more natural and applicable in real-world scenarios.