In semi-supervised domain adaptation, the limited labeled samples in the target domain influence the features of the remaining target samples to gather around them. However, this approach fails to generate a highly discriminative feature representation for the target domain due to the dominance of labeled samples from the source domain in the training data. As a result, there is a disconnect between labeled and unlabeled target samples, as well as a misalignment between unlabeled target samples and the source domain. To tackle this problem, this study proposes a new method called Cross-domain Adaptive Clustering.To achieve both inter-domain and intra-domain adaptation, the proposed method introduces an adversarial adaptive clustering loss. This loss function groups the features of unlabeled target data into clusters and aligns them with the source domain through cluster-wise feature alignment. Additionally, pseudo labeling is applied to the unlabeled samples in the target domain, and only pseudo-labels with high confidence are retained. Pseudo labeling increases the number of "labeled" samples in each class in the target domain, resulting in a more robust and powerful cluster core for each class, which facilitates adversarial learning.Extensive experiments conducted on benchmark datasets such as DomainNet, Ofﬁce-Home, and Ofﬁce demonstrate that the proposed approach achieves state-of-the-art performance in semi-supervised domain adaptation.