This study addresses the challenges faced in tracking segmentation masks of multiple instances, specifically the need for large-scale annotations and the complexity of two-stage approaches. To overcome these challenges, the researchers propose a novel semi-supervised framework that utilizes labeled image datasets and unlabeled video sequences. By using an instance contrastive objective, they learn an embedding that can discriminate each instance from others, resulting in a robust feature representation capable of steady object tracking across frames. The tracking capability is further improved by self-supervised learning of correspondence from unlabeled videos. The proposed framework is integrated into single-stage instance segmentation and pose estimation frameworks, which significantly reduce the computational complexity compared to two-stage networks. Experimental results on the YouTube-VIS and PoseTrack datasets demonstrate that the proposed method achieves comparable or better performance than most fully-supervised methods, without the need for video annotation efforts.