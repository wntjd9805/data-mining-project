Self-attention techniques, particularly Transformers, have gained significant popularity in text processing and computer vision classification. Existing methods for visualizing image components that contribute to a specific classification rely on attention maps or heuristic propagation along the attention graph. This study proposes a new approach to compute relevancy in Transformer networks. The method utilizes the Deep Taylor Decomposition principle to assign local relevance and propagates these scores through the layers. This propagation involves attention layers and skip connections, which poses a challenge for existing methods. The proposed solution maintains total relevancy across layers through a specific formulation. The method is evaluated on recent visual Transformer networks and a text classification problem, outperforming existing explainability methods. The code for this method is accessible at https://github.com/hila-chefer/Transformer-Explainability.