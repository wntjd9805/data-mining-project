Demographic bias presents a significant challenge in face recognition systems. Current methods rely heavily on accurate demographic annotations, which are often not available in real scenarios. Additionally, these methods are typically designed for specific demographic groups and lack general applicability. To address this issue, we propose a false positive rate penalty loss that reduces face recognition bias by increasing the consistency of instance False Positive Rate (FPR). We define instance FPR as the ratio of non-target similarities above a unified threshold to the total number of non-target similarities. This threshold is estimated for a given total FPR. We introduce an additional penalty term, proportional to the ratio of instance FPR to overall FPR, into the softmax-based loss denominator. The penalty increases with larger instance FPR, promoting consistent instance FPRs. Our method does not require demographic annotations, making it effective in mitigating bias across demographic groups divided by various attributes without predefining them during training. Extensive experiments on popular benchmarks demonstrate the superiority of our approach compared to state-of-the-art competitors. The code and pre-trained models can be found at https://github.com/xkx0430/FairnessFR.