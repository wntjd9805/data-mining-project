This abstract presents a comprehensive study on learning spatiotemporal representations from videos without the need for supervision. The study examines four recent frameworks that are based on images and proposes a simple objective that can be applied to all of them in order to generalize the methods to space-time. The objective focuses on promoting persistent features within the same video, and despite its simplicity, it proves to be highly effective across various factors such as different unsupervised frameworks, pre-training datasets, downstream datasets, and backbone architectures. The study also makes interesting observations, including the discovery that encouraging long-spanned persistence can be successful even with a timespan of 60 seconds. Alongside state-of-the-art results achieved in multiple benchmarks, the study highlights several cases where unsupervised pre-training outperforms supervised approaches. The code for this study is accessible at https://github.com/facebookresearch/SlowFast.