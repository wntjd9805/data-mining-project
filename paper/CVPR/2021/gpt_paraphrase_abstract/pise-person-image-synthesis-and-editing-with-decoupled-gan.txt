We introduce PISE, a novel two-stage generative model for Person Image Synthesis and Editing. Existing methods struggle with predicting invisible regions and separating clothing shape and style, limiting their applicability in person image editing. PISE addresses these issues by generating realistic person images with desired poses, textures, and semantic layouts. For pose transfer, we first generate a human parsing map aligned with the target pose to represent clothing shape using a parsing generator. Then, an image generator produces the final image. To decouple clothing shape and style, we propose joint global and local per-region encoding and normalization to predict reasonable clothing style for invisible regions. Additionally, we introduce spatial-aware normalization to maintain spatial context relationships in the source image. Our qualitative and quantitative experiments demonstrate the superiority of our model in human pose transfer. Moreover, our model proves effective in texture transfer and region editing for person image editing. The code for our model is available for research purposes at https://github.com/Zhangjinso/PISE.