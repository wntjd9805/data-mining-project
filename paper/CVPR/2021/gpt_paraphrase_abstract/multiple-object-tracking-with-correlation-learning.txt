Recent studies have shown that convolutional networks have significantly improved the performance of multiple object tracking by simultaneously learning detection and appearance features. However, the convolutional network structure itself limits its ability to efficiently capture long-range dependencies in both the spatial and temporal dimensions. To address this issue, we propose incorporating a local correlation module that models the topological relationship between targets and their surrounding environment. This module enhances the discriminative power of our model, especially in crowded scenes. By establishing dense correspondences between spatial locations and their contexts, we can constrain the correlation volumes using self-supervised learning.In terms of capturing temporal context, existing approaches typically use multiple adjacent frames to enhance the feature representation. However, depicting dynamic motion scenes accurately using convolutional neural networks (CNNs) is inherently challenging. Instead, our paper introduces a learnable correlation operator that establishes matches between frames over convolutional feature maps in different layers. This allows us to align and propagate temporal context effectively.Through extensive experiments on the MOT datasets, our approach demonstrates the effectiveness of correlation learning, achieving superior performance compared to existing methods. Specifically, our method achieves a state-of-the-art MOTA (Multiple Object Tracking Accuracy) of 76.5% and IDF1 (Identification F1 score) of 73.6% on the MOT17 dataset.