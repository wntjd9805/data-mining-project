The importance of skeletal motion in human activity recognition has been widely recognized. However, recent studies have raised concerns about the vulnerability of skeleton-based activity recognizers to adversarial attacks. These attacks are particularly threatening when the attacker has full knowledge of the recognizer. This paper introduces a new black-box adversarial attack method called BASAR, which demonstrates that adversarial attacks can also be a threat in scenarios where the attacker does not have full knowledge of the recognizer. The authors show that on-manifold adversarial samples, which are commonly found in skeletal motions, can be used to deceive the recognizer. Through extensive evaluation and comparison, BASAR is shown to successfully attack different models, data, and attack modes. The authors also conduct perceptual studies to demonstrate that BASAR achieves effective yet imperceptible attacks. Additionally, BASAR helps identify the vulnerabilities of different activity recognizers and provides insights into which classifiers are more robust against adversarial attacks.