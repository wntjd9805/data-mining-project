We introduce a new approach to segmenting mirrors by utilizing depth estimates from ToF-based cameras. This helps to distinguish challenging cases where the contrast or relationship in RGB colors between the mirror reflection and the surrounding scene is subtle. We observe that ToF depth estimates do not provide the true depth of the mirror surface, but rather the total length of the reflected light paths, resulting in noticeable depth discontinuities at the mirror boundaries. To make use of depth information in mirror segmentation, we create a comprehensive RGB-D mirror segmentation dataset and use it to train a novel depth-aware mirror segmentation framework. Our framework initially identifies mirrors based on color and depth discontinuities and correlations. It then enhances the accuracy of the mirror boundaries by considering both color and depth information in contextual contrast. We extensively validate our depth-aware mirror segmentation method and demonstrate its superiority over state-of-the-art RGB and RGB-D methods for mirror segmentation. Experimental results highlight the effectiveness of depth as a valuable cue in mirror segmentation.