This study explores the use of two rear-facing cameras found in modern smartphones for illumination estimation. By utilizing the different spectral sensitivities of the two cameras, a small neural network is employed to predict the scene illumination. A linear 3x3 color transform specific to a given scene can be used to train the lightweight neural network, which consists of only 1460 parameters. The results show that this approach with a lightweight network yields comparable or superior results compared to more complex methods that operate on a single image. The effectiveness of the proposed method is validated through extensive experiments on radiometric data, a quasi-real two-camera dataset, and a new real image dataset captured using a smartphone with two rear-facing cameras.