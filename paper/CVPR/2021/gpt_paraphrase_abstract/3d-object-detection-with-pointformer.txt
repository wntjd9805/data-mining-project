This research paper introduces Pointformer, a Transformer-based backbone specifically designed for learning features from 3D point clouds in the context of object detection. The irregularity of 3D point cloud data poses a significant challenge in this task. To address this, the authors propose the use of a Local Transformer module that models interactions among points in a local region, enabling the learning of context-dependent region features at an object level. Additionally, a Global Transformer is employed to learn context-aware representations at the scene level. To capture the dependencies among multi-scale representations, a Local-Global Transformer is introduced to integrate local features with global features from higher resolution. Furthermore, an efficient coordinate refinement module is introduced to shift down-sampled points closer to object centroids, leading to improved object proposal generation. The authors utilize Pointformer as the backbone for object detection models and demonstrate substantial improvements over original models on both indoor and outdoor datasets.