6D pose estimation in space presents unique challenges not commonly encountered in terrestrial settings. A major difference is the absence of atmospheric scattering, which allows objects to be visible from long distances but complicates illumination conditions. Existing benchmark datasets do not adequately address this aspect and mainly focus on depicting targets in close proximity. Previous studies addressing pose estimation under large scale variations adopt a two-stage approach, first estimating scale and then estimating pose on a resized image patch. In contrast, we propose a single-stage hierarchical end-to-end trainable network that is more resilient to scale variations. Our network surpasses existing approaches in performance, not only on synthesized space-like images but also on standard benchmarks.