In recent times, numerous methods based on 2D or 3D convolutional neural networks (CNN) have emerged for the recognition of actions in videos. These approaches have achieved outstanding outcomes on various large-scale benchmark datasets. This study aims to conduct a detailed comparative analysis to gain a better understanding of the disparities among these approaches and the advancements they have made. To accomplish this, we establish a unified framework for both 2D-CNN and 3D-CNN action models. This framework allows us to eliminate unnecessary complexities and establish a fair basis for comparison. Subsequently, we undertake a comprehensive analysis involving more than 300 action recognition models. Our analysis reveals two main findings: firstly, there has been significant improvement in the efficiency of action recognition, but not in accuracy; secondly, 2D-CNN and 3D-CNN models exhibit similar abilities in terms of spatio-temporal representation and transferability. The codes used in this study can be accessed at https://github.com/IBM/action-recognition-pytorch.