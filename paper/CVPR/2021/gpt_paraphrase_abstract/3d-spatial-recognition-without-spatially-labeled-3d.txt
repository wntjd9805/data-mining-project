We present WyPR, a Weakly-supervised framework for Point cloud Recognition that only requires scene-level class tags for supervision. WyPR addresses three main tasks in 3D recognition: point-level semantic segmentation, 3D proposal generation, and 3D object detection. It achieves this by utilizing self and cross-task consistency losses to combine the predictions of these tasks. By incorporating multiple-instance learning objectives, WyPR can detect and segment objects in point cloud data without spatial labels during training. On the ScanNet and S3DIS datasets, WyPR outperforms previous state-of-the-art methods in weakly-supervised segmentation by more than 6% mIoU. Furthermore, we establish the first benchmark for weakly-supervised 3D object detection on these datasets, where WyPR surpasses standard approaches and sets strong baselines for future research.