VQA models often rely on language bias as a shortcut, which hinders their ability to effectively learn from both visual and linguistic information. Previous methods attempted to address this issue by excluding language prior during inference, but they failed to distinguish between useful language context and detrimental language bias. This paper presents a novel approach to mitigating language bias in VQA. Inspired by causal effects, the authors propose a counterfactual inference framework that captures the direct causal effect of questions on answers, allowing for the reduction of language bias by subtracting the direct language effect from the total causal effect. Experimental results demonstrate that this framework is applicable to various VQA models and fusion strategies, achieving competitive performance on the language-bias sensitive VQA-CP dataset while maintaining robustness on the balanced VQA v2 dataset without requiring additional data augmentation. The code for the proposed framework is available at https://github.com/yuleiniu/cfvqa. The answer format only provides an abstract.