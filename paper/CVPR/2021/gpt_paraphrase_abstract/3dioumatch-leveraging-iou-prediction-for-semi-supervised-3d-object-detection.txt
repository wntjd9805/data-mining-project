3D object detection is a challenging task that requires difficult-to-obtain 3D annotations. In order to address the issue of limited supervision, we propose a new semi-supervised method called 3DIoUMatch for 3D object detection in both indoor and outdoor scenes. Our approach utilizes a teacher-student mutual learning framework to transfer information from labeled to unlabeled training data in the form of pseudo-labels. However, we found that these pseudo-labels often contain significant noise and cannot be directly used. To overcome this, we introduce a confidence-based filtering mechanism inspired by FixMatch. We set confidence thresholds based on objectness and class probability predictions to filter out low-quality pseudo-labels. While this approach is effective, we also found that it does not adequately capture localization quality. To address this, we propose using the estimated 3DIoU as a metric for localization and set category-aware self-adjusted thresholds to filter poorly localized proposals. We use VoteNet as our backbone detector for indoor datasets and PV-RCNN for the KITTI autonomous driving dataset. Our method consistently outperforms state-of-the-art methods on the ScanNet and SUN-RGBD benchmarks, achieving significant improvements in mAP@0.25 and mAP@0.5 even with only 10% labeled data. Additionally, on the KITTI dataset, we demonstrate the first semi-supervised 3D object detection method and achieve superior performance compared to a fully supervised baseline across different label ratios and categories.