We have developed a technique to accurately estimate the lighting, reﬂectance, and geometry of a scene using 360◦ stereo images. By utilizing the full panoramic view, our method can capture detailed geometric information of the entire scene. We employ physical constraints to jointly estimate the properties of the scene. Initially, we reconstruct an environment light that can predict the lighting in any 3D location within the scene. Then, using a deep learning model and the stereo information, we infer the reﬂectance and surface normal of the scene. Additionally, we incorporate the relationship between lighting and geometry to improve the accuracy of the scene's reﬂectance. Through quantitative and qualitative experiments, we demonstrate that our method surpasses previous state-of-the-art techniques, thanks to the comprehensive observation provided by the 360◦ images. This advancement opens up possibilities for augmented reality applications, including mirror-object insertion.