In this study, we introduce a network called EDNet for efficient disparity estimation. Current methods for disparity estimation rely on a deep 3D convolution neural network (CNN) using a 4D concatenation volume, but this approach is inefficient due to high memory usage and slow inference speed. Our proposed EDNet addresses these issues by utilizing a combined volume that incorporates contextual information from a squeezed concatenation volume and feature similarity measurements from a correlation volume. This combined volume can be aggregated using faster and less memory-intensive 2D convolutions. Additionally, we introduce an attention-based spatial residual module that generates attention-aware residual features. This attention mechanism improves the efficiency of residual learning by providing spatial evidence of inaccurate regions through error maps at multiple scales. Experimental results on the Scene Flow and KITTI datasets demonstrate that EDNet surpasses previous 3D CNN-based methods, achieving state-of-the-art performance with significantly faster speed and lower memory consumption.