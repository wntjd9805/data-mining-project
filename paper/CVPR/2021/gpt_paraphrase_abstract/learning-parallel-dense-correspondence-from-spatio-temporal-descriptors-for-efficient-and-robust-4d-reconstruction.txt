This paper addresses the challenge of reconstructing 4D shapes from a sequence of point clouds. While deep implicit representations have shown success in extending to 4D space, there are two main challenges: designing a flexible framework for learning robust spatio-temporal shape representations from 4D point clouds and developing an efficient mechanism for capturing shape dynamics. To tackle these challenges, the authors propose a novel pipeline that learns the temporal evolution of 3D human shape through spatially continuous transformation functions among cross-frame occupancy fields. The key idea is to establish dense correspondence between predicted occupancy fields at different time steps by learning continuous displacement vector fields from robust spatio-temporal shape representations. Extensive comparisons with previous state-of-the-art methods demonstrate the superior accuracy of the proposed approach for 4D human reconstruction in the tasks of 4D shape auto-encoding and completion. Additionally, the proposed approach achieves a much faster network inference with approximately 8 times speedup, highlighting its significant efficiency. The trained models and implementation code for the proposed approach can be accessed at https://github.com/tangjiapeng/LPDC-Net.