This paper introduces a novel approach to semantic image synthesis, which involves translating semantic layouts into realistic images. While there has been progress in this field, there is still a challenge in generating diverse and efficient semantic-level multimodal results. The proposed framework addresses this challenge by utilizing class-level conditional modulation parameters as continuous probability distributions instead of discrete values. Additionally, instance-level modulation parameters are sampled using instance-adaptive stochastic sampling, ensuring consistency throughout the network. The authors also propose prior noise remapping, which involves linear perturbation parameters encoded from paired references, to facilitate supervised training and instance style control during testing. The experiments conducted on multiple datasets demonstrate that the proposed method achieves superior diversity and comparable quality compared to existing state-of-the-art methods. The code for this framework will be made available on GitHub.