This paper proposes a new approach, called Cross-Domain Triplet (CDT) loss, to improve face recognition in unseen domains. The CDT loss encourages the learning of semantically meaningful features by enforcing compact feature clusters in one domain, measured by similarity metrics from a different training domain. This is achieved by correlating explicit metrics from one domain with triplet samples from another domain in a unified loss function. The network parameters are further optimized to learn generalized features under domain shift. Unlike previous methods, our approach does not require hard-pair sample mining and filtering during training. Extensive experiments on face recognition benchmarks demonstrate the superiority of our method in handling variations compared to baseline and state-of-the-art methods.