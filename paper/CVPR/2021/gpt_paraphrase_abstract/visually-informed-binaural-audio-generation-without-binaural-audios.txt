This study focuses on the importance of stereophonic audio, particularly binaural audio, in immersive viewing environments. Previous research has explored generating visually guided stereophonic audios using multi-channel audio collections. However, the limited scale and variety of existing datasets, which require professional recording devices, hinder the generalization of supervised methods in real-world scenarios. To address this, the authors propose a pipeline called PseudoBinaural that does not rely on binaural recordings. The key idea is to create pseudo visual-stereo pairs using mono data for training. This is achieved by using spherical harmonic decomposition and head-related impulse response (HRIR) to identify the relationship between spatial locations and received binaural audios. In the visual modality, corresponding visual cues of the mono data are manually placed at sound source positions to form the pairs. The authors demonstrate that their binaural-recording-free pipeline exhibits stability in cross-dataset evaluation and achieves comparable performance in subjective preference compared to fully-supervised methods. Additionally, when combined with binaural recordings, their method further enhances the performance of binaural audio generation under supervised settings.