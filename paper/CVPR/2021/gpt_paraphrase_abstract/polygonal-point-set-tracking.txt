This paper introduces a new approach to polyg-onal point set tracking using a learning-based method. Unlike existing video object segmentation methods that focus on pixel-wise object mask propagation, our method propagates a polygonal point set over frames. This point set is a subset of points within the target contour, and our objective is to track corresponding points on the target contour. By achieving this, we can apply various visual effects such as motion tracking, part deformation, and texture mapping. To accomplish this, we propose a novel method that tracks the corresponding points between frames through global-local alignment, incorporating carefully designed losses and regularization terms. Additionally, we present a unique learning strategy that utilizes synthetic and VOS datasets, eliminating the need for a dedicated point correspondence dataset. To evaluate the effectiveness of our method, we create a new polygonal point set tracking dataset since existing datasets are not suitable for our purposes. Through extensive experiments, we demonstrate the superior performance of our method compared to baseline methods and existing contour-based VOS approaches. Furthermore, we showcase the applications of our method in visual effects, specifically in part distortion and text mapping.