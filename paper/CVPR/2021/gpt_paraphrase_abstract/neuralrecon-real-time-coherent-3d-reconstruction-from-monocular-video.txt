We introduce NeuralRecon, a new framework for real-time 3D scene reconstruction from a single video. Unlike previous approaches that estimate depth maps separately for each key-frame and then fuse them, our method directly reconstructs local surfaces as sparse TSDF volumes using a neural network. We incorporate a learning-based TSDF fusion module that utilizes gated recurrent units to guide the network in fusing features from previous video fragments. This design allows the network to capture both local smoothness and global shape information, resulting in accurate, coherent, and real-time surface reconstruction. Our system outperforms state-of-the-art methods in terms of accuracy and speed, as demonstrated on ScanNet and 7-Scenes datasets. To the best of our knowledge, this is the first learning-based system capable of real-time reconstruction of dense and coherent 3D geometry. The project page provides access to the code: https://zju3dv.github.io/neuralrecon/.