In the field of unsupervised representation learning, it is common to use labeled data to assess the quality of the learned representations. This evaluation process helps in guiding the training process, including the selection of data augmentation techniques. However, this approach is not applicable to real-world data that lacks labels, especially in privacy-sensitive domains like medical imaging. To address this limitation, this study demonstrates that evaluating the learned representations using a self-supervised image rotation task is highly correlated with standard supervised evaluations (with a rank correlation of over 0.94). This correlation is observed across various augmentation policies, training scenarios, and network architectures. Moreover, an algorithm called Self-Augment is proposed to automatically and efficiently select augmentation policies without relying on supervised evaluations. Remarkably, the learned augmentation policies perform comparably to those determined through exhaustive supervised evaluations, despite not using any labeled data.