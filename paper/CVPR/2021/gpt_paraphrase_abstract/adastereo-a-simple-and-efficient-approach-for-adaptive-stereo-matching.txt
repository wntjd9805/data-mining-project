Recent advancements in stereo matching benchmarks have been achieved by end-to-end disparity networks. However, these deep models lack the ability to adapt to different domains. To address this issue, we propose a novel domain-adaptive pipeline called AdaStereo that focuses on aligning multi-level representations for deep stereo matching networks. Compared to previous methods, AdaStereo offers a more comprehensive and effective domain adaptation pipeline. Firstly, we introduce a progressive color transfer algorithm that does not rely on adversarial techniques for input image-level alignment. Secondly, we present a parameter-free cost normalization layer that efficiently aligns internal features at the feature-level. Lastly, we introduce a related auxiliary task known as self-supervised occlusion-aware reconstruction, which helps bridge the gaps in the output space. Our AdaStereo models achieve state-of-the-art performance across multiple stereo benchmarks, including KITTI, Middlebury, ETH3D, and DrivingStereo. In fact, they even outperform disparity networks that have been fine-tuned with ground-truth data from the target domain.