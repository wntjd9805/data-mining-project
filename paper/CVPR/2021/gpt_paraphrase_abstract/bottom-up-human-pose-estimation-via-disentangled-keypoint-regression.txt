This paper explores the bottom-up approach to estimating human poses from images. The authors focus on improving the dense keypoint regression framework, which has previously been less effective than the keypoint detection and grouping framework. The authors propose a new method called disentangled keypoint regression (DEKR), which utilizes adaptive convolutions and pixel-wise spatial transformer to activate the pixels in the keypoint regions and learn representations from them. DEKR employs a multi-branch structure for separate regression, with each branch learning a representation and regressing one keypoint. This results in disentangled representations that can accurately attend to the keypoint regions, leading to spatially more accurate keypoint regression. The authors empirically demonstrate that DEKR outperforms keypoint detection and grouping methods, achieving superior bottom-up pose estimation results on two benchmark datasets, namely COCO and Crowd-Pose. The code and models for DEKR are available at the provided GitHub repository.