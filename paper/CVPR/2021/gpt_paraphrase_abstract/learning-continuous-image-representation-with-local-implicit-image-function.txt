This paper explores the challenge of representing images in a continuous manner, as machines typically store and process images in a discrete manner using 2D arrays of pixels. The authors propose a new approach called Local Implicit Image Function (LIIF) that leverages the recent advancements in 3D reconstruction with implicit neural representation. LIIF takes an image coordinate and the surrounding 2D deep features as inputs and predicts the RGB value at that coordinate as an output. This continuous representation can be generated in arbitrary resolutions and is trained using an encoder with LIIF representation through a self-supervised task involving super-resolution. The learned continuous representation is capable of extrapolating to resolutions up to 30 times higher, even without specific training tasks. The authors also demonstrate that LIIF bridges the gap between discrete and continuous representations in 2D, enabling effective learning with ground-truth images of varying sizes. Compared to methods that rely on resizing the ground-truth images, LIIF significantly outperforms in performance. The project page with the code can be found at https://yinboc.github.io/liif/.