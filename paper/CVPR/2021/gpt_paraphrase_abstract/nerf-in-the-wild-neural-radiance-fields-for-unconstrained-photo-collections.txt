A learning-based method has been developed to generate new perspectives of complex scenes using unstructured collections of real-world photographs. The method builds upon NeuralRadiance Fields (NeRF), which models scene density and color based on 3D coordinates using a multi-layer perceptron. However, NeRF is limited in its ability to handle various real-world factors like variable lighting and temporary obstructions. To overcome these limitations, several enhancements have been introduced to NeRF, resulting in accurate reconstructions from unstructured internet image collections. The improved system, called NeRF-W, has been applied to famous landmark photo collections, producing realistic and consistent renderings that outperform previous approaches.