Learning pose invariant representation is a crucial issue in shape analysis. Most existing deep learning algorithms for analyzing 3D shapes are not robust to rotations and are usually trained on synthetic datasets with pre-aligned shapes, resulting in poor generalization to unseen poses. This has led to a growing interest in rotation invariant and equivariant methods. The field of rotation equivariant deep learning has made significant progress in recent years, thanks to the well-established theory of Lie group representations and convolutions. In equivariant deep learning, a major challenge is to design activation functions that are both informative and preserve equivariance. The Tensor Field Network (TFN) framework, which has recently been introduced, offers a rotation equivariant network design for analyzing point clouds. TFN features undergo a rotation in the feature space when the input point cloud is rotated. However, TFN and similar designs only consider nonlinearities that operate on rotation invariant features, such as the norm of equivariant features, which limits their ability to capture directional information. In a recent work by Hann et al. titled "Gauge Equivariant Mesh CNNs: Anisotropic Convolutions on Geometric Graphs," 2D rotation equivariant features are interpreted as Fourier coefficients of functions on the circle. In our work, we extend this idea to 3D by interpreting TFN features as spherical harmonics coefficients of functions on the sphere. We propose a new equivariant nonlinearity and pooling method for TFN. Our experiments demonstrate improvements over the original TFN design and other equivariant nonlinearities in classification and segmentation tasks. Furthermore, our method is competitive with state-of-the-art rotation invariant methods in certain cases.