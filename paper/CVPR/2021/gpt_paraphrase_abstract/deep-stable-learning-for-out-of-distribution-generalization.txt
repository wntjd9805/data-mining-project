Deep neural networks have shown impressive performance in cases where the distribution of testing data is similar to the distribution of training data. However, when there is a significant shift in the distributions, these approaches can fail. Therefore, it is crucial to address the issue of distribution shifts between training and testing data in order to build deep models with promising performance. Existing methods make assumptions about either known heterogeneity of training data or approximately equal capacities of different domains. However, we tackle a more challenging scenario where neither of these assumptions holds. Our proposed solution involves removing the dependencies between features by learning weights for training samples. This allows deep models to eliminate spurious correlations and focus more on the true connection between discriminative features and labels. Extensive experiments on multiple distribution generalization benchmarks, such as PACS, VLCS, MNIST-M, and NICO, demonstrate the effectiveness of our method compared to state-of-the-art approaches.