Weakly supervised instance segmentation is a cost-effective method for training models, but it often results in errors such as partial segmentation and missing object predictions. To address these issues, we propose using weakly labeled videos instead of images. Videos provide additional signals like motion and temporal consistency, which can aid in segmentation. We are the first to explore the use of these video signals for weakly supervised instance segmentation. Our approach involves incorporating motion information through an adapted inter-pixel relation network (IRN) during training. Additionally, we introduce a new module called MaskConsist, which transfers stable predictions between neighboring frames to address the problem of missing object instances. Our experiments on the Youtube-VIS and Cityscapes datasets demonstrate that the combination of these approaches improves the instance segmentation metric AP50 by 5% and 3% respectively.