We introduce a probabilistic model to generate point clouds, which is essential for various 3D vision tasks like shape completion, upsampling, synthesis, and data augmentation. Our approach is inspired by the diffusion process in non-equilibrium thermodynamics, where we treat points in point clouds as particles in a thermodynamic system interacting with a heat bath. These particles diffuse from their original distribution to a noise distribution. To generate point clouds, we learn the reverse diffusion process that transforms the noise distribution into the desired shape distribution. We propose modeling this reverse diffusion process as a Markov chain conditioned on a specific shape latent. We provide a closed-form variational bound for training and offer implementations of the model. Experimental results demonstrate that our model performs competitively in point cloud generation and auto-encoding. The code for our model is available at https://github.com/luost26/diffusion-point-cloud.