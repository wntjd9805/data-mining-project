Temporal action segmentation approaches have made significant progress recently. However, annotating videos with frame-wise labels for training these models is both costly and time-consuming. While weakly supervised methods that rely on ordered action lists require less annotation effort, their performance still falls behind fully supervised approaches. In this study, we propose the use of timestamp supervision for the temporal action segmentation task. Timestamps require a similar level of annotation effort as weakly supervised methods but provide a stronger supervisory signal. To demonstrate the effectiveness of timestamp supervision, we present an approach that trains a segmentation model solely using timestamp annotations. Our approach utilizes the model's output and the annotated timestamps to generate frame-wise labels by detecting action changes. Additionally, we introduce a confidence loss that ensures predicted probabilities decrease monotonically as the distance to the timestamps increases. This guarantees that all frames, not just the most distinctive ones, are learned during training. Evaluation on four datasets reveals that models trained with timestamp annotations achieve comparable performance to fully supervised approaches.