This paper introduces a new CNN architecture called densely connected multidilated DenseNet (D3Net) for tasks that require high-resolution dense prediction. It emphasizes the importance of simultaneously modeling both local and global patterns in a large input field. Unlike existing approaches that only interchange representations in different resolutions a few times, D3Net proposes a novel multidilated convolution that incorporates different dilation factors in a single layer to model different resolutions simultaneously. By combining this multidilated convolution with the DenseNet architecture, D3Net achieves multiresolution learning with an exponentially growing receptive field in almost all layers, while avoiding the aliasing problem. Experimental results on image semantic segmentation and audio source separation tasks demonstrate that D3Net outperforms state-of-the-art methods.