Handwritten Text Recognition (HTR) is still a challenging problem due to the different writing styles. Previous works assume that there is a limited number of styles, but we propose a different approach. We assume that there will always be new styles that are drastically different, and we will have limited data for adaptation during testing. This approach is commercially viable because the model can adapt to the new style and the limited data makes it practical to implement. We use a meta-learning framework that utilizes additional new-writer data and updates the model during inference. We also find that certain characters have larger style discrepancies and propose a character-wise cross-entropy loss with instance-specific weights to address this. Our MetaHTR framework can be easily applied to state-of-the-art HTR models. Experiments show that by observing very few new style data (â‰¤ 16), we can achieve an average performance gain of 5-7%.