Active stereo cameras that use structured light to recover depth have become an important sensor for 3D scene reconstruction. These cameras project a dot pattern on object surfaces to extract disparity, regardless of object texture. However, the design of these patterns is typically done without considering the scene statistics, lighting conditions, or the reconstruction method. In this study, we propose a method that combines structured illumination and reconstruction in a single process. This method involves using a diffractive optical element and a neural network to learn the illumination and reconstruction simultaneously. We develop an image formation model that incorporates both wave and geometric optics, as well as a trinocular reconstruction network. By jointly optimizing the pattern, which we call "Polka Lines," and the reconstruction network, we are able to achieve accurate depth estimates under various imaging conditions. We validate our method through simulations and experiments with a prototype, and we also demonstrate different variants of the Polka Lines pattern tailored to specific lighting conditions.