Our goal is to create an effective model for detecting defects in images, specifically identifying unknown anomalous patterns without the need for anomalous data. To achieve this, we propose a two-stage framework that uses only normal training data to build anomaly detectors. Firstly, we train deep representations using a self-supervised approach. Then, we construct a generative one-class classifier based on these learned representations. We utilize the CutPaste technique, a simple data augmentation strategy, to classify normal data. Our experimental evaluation on the MVTec anomaly detection dataset demonstrates the versatility of our algorithm in detecting various types of real-world defects. Compared to previous methods, our approach improves the Area Under the Curve (AUC) by 3.1 when learning representations from scratch. By leveraging transfer learning with pretrained representations from ImageNet, we achieve a new state-of-the-art AUC of 96.6. Additionally, we extend our framework to learn and extract representations from patches, allowing for the localization of defective areas without the need for annotations during training.