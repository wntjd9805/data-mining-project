This study addresses the issue of mode collapse in conditional generative adversarial networks (cGANs), which aim to generate diverse images based on input conditions and latent codes. Previous approaches have focused on improving the correlation between latent codes and generated images, but have overlooked the relationships between images generated from different latent codes. The recent MSGAN attempted to enhance image diversity by considering negative relations between image pairs. In this paper, the authors propose a new framework called DivCo, which properly constrains both positive and negative relations between generated images in the latent space. They introduce a novel latent-augmented contrastive loss that encourages similarity between images generated from adjacent latent codes and dissimilarity between images generated from distinct latent codes. The proposed loss is compatible with various cGAN architectures. Extensive experiments demonstrate that DivCo can generate more diverse images compared to state-of-the-art methods without sacrificing visual quality in both unpaired and paired image generation tasks. The training code and pretrained models are available at the provided GitHub repository.