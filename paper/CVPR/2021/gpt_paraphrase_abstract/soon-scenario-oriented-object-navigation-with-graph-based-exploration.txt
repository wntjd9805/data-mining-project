The goal of intelligent robots is to navigate in a 3D environment towards a target using language instructions. However, current benchmarks focus on fixed starting points and detailed step-by-step instructions, which does not reflect real-world scenarios. In this paper, we introduce the Scenario-Oriented Object Navigation (SOON) task, where an agent must navigate from anywhere to locate a target based on a scene description. To address this task, we propose the graph-based exploration (GBE) method, which models navigation as a graph and learns knowledge from the graph to improve training. We also create a new benchmark dataset called From Anywhere to Object (FAO) that provides rich semantic scene information. Our experiments show that GBE outperforms other methods on both FAO and R2R datasets, and the ablation studies confirm the quality of the FAO dataset.