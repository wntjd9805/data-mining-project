Panoptic segmentation is the combination of instance and semantic segmentation tasks, which presents a challenge in learning both instance-specific and category-specific representations together. Current panoptic segmentation methods use complex models with separate streams for each task. In contrast, our approach, Hierarchical Lovász Embeddings, utilizes per pixel feature vectors that encode discriminative information at both instance and category levels. We employ a hierarchical Lovász hinge loss to learn a low-dimensional embedding space structured into a unified semantic and instance hierarchy, without the need for separate network branches or object proposals. Our method accurately models instances without relying on proposals and also extends to non-instance "stuff" classes where traditional instance segmentation methods are not applicable. Despite its simplicity, our model achieves state-of-the-art results compared to existing proposal-free panoptic segmentation methods on Cityscapes, COCO, and Mapillary Vistas datasets. Additionally, our model demonstrates temporal stability across video frames.