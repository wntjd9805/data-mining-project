Monocular depth predictors are often trained on large-scale datasets that have a bias towards certain camera poses. This leads to unreliable depth predictions for testing examples taken from uncommon camera angles. To address this issue, we propose two new techniques. First, we introduce a perspective-aware data augmentation method that creates new training examples with a wider range of views by perturbing existing ones in a consistent manner. Second, we suggest a conditional model that utilizes the camera pose as prior knowledge by incorporating it into the input. By combining these two methods, we demonstrate improved depth prediction for images captured from uncommon and previously unseen camera angles. We also show that our techniques enhance performance across various predictor architectures. Finally, we demonstrate that explicitly encoding the camera pose distribution enhances the generalization capability of a synthetically trained depth predictor when evaluated on real images.