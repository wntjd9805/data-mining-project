Ada3D is a computational framework that aims to reduce the computational demands of 3D convolutional networks used for video recognition. These networks operate on a sequence of frames with 3D convolutions, which can be computationally expensive. Ada3D addresses this issue by learning instance-specific 3D usage policies to determine which frames and convolution layers should be used in the network. This is achieved through a lightweight selection network that is conditioned on each input video clip. The selection network selects only the frames and convolutions that are deemed relevant, reducing the computational load of the 3D model. The selection network is optimized using policy gradient methods to maximize a reward that encourages accurate predictions with limited computation. Experimental results on three video recognition benchmarks show that Ada3D achieves similar accuracy to state-of-the-art 3D models while requiring 20% to 50% less computation across different datasets. The transferability of the learned policies and compatibility with different backbones and clip selection approaches are also demonstrated. Qualitative analysis reveals that Ada3D allocates fewer 3D convolutions and frames for static inputs, but utilizes more for motion-intensive clips.