Recognizing actions with limited labeled videos is a difficult task due to the lack of comprehensive activity labels. In this study, we tackle this problem by developing a two-pathway temporal contrastive model that utilizes unlabeled videos at different speeds. We exploit the fact that altering video speed does not alter the action being performed. Our approach involves maximizing the similarity between encoded representations of the same video at different speeds and minimizing the similarity between different videos played at different speeds. By doing so, we make use of the valuable temporal information present in unsupervised video datasets. Through manipulating video playback rates, we achieve superior performance compared to advanced semi-supervised image recognition methods on various benchmark datasets and network architectures. Notably, our approach demonstrates generalization and robustness even when applied to out-of-domain unlabeled videos. We conduct thorough ablation studies and analysis to validate the effectiveness of our proposed method. Additional information regarding our project can be found at https://cvir.github.io/TCL/.