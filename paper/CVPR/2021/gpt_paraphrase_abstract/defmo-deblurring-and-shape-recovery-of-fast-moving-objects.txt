We present a method for recovering the appearance and motion of objects captured at high speeds, which often appear blurred. This blurriness is particularly challenging to resolve when the object has a complex shape or texture. Existing methods and even human observers struggle to accurately reconstruct the object's appearance and position. To address this, we propose a generative model that takes a single image with an estimated background and generates a series of sub-frames that resemble images captured by a high-speed camera, achieving temporal super-resolution. Our model incorporates the blurred object image into a latent space representation, separates the background, and produces a sharp appearance. Drawing inspiration from the image formation model, we devise novel self-supervised loss functions that enhance performance and exhibit strong generalization capabilities. We train our method, DeFMO, on a synthetic dataset with complex scenarios but find that it also performs well on real-world data from multiple datasets. In comparison to existing approaches, DeFMO outperforms them and generates high-quality frames with temporal super-resolution.