Visual odometry is a valuable application of event sensing, particularly in situations that require high-temporal resolution. The current method of contrast maximisation is effective in recovering motion from a batch of events by enhancing the contrast of the warped event image. However, this approach has limitations such as the cost increasing with image resolution and the temporal resolution being restricted by the need for large batch sizes to generate enough structure in the contrast image. In this study, we propose spatiotemporal registration as an alternative technique for estimating rotational motion based on events. We provide theoretical justification for this approach and demonstrate its fundamental and practical advantages over contrast maximisation. Notably, spatiotemporal registration also generates feature tracks as a by-product, which directly supports an efficient visual odometry pipeline with graph-based optimization for motion averaging. The simplicity of our visual odometry pipeline enables it to process more than 1 million events per second. Additionally, we present a new event dataset for visual odometry, which includes motion sequences with significant variations in velocity acquired using a high-precision robot arm.