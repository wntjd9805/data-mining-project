Despite recent advancements in single image-based 3D human pose and shape estimation, the task of recovering smooth and temporally consistent 3D human motion from videos remains challenging. Existing video-based methods fail to address the temporal inconsistency issue present in single image-based methods, as they heavily rely on static features of the current frame. To overcome this limitation, we propose a temporally consistent mesh recovery system (TCMR) that effectively utilizes temporal information from past and future frames, without being dominated by the current static feature. Our TCMR outperforms previous video-based methods in terms of temporal consistency, achieving better per-frame 3D pose and shape accuracy. Additionally, we provide the source code for our system.