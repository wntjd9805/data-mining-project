In this paper, we present a new method for video object segmentation (VOS) that is simple, fast, and effective. The current VOS task faces challenges in differentiating object instances and aligning them across frames. Most existing VOS methods simplify the task by treating it as a binary segmentation problem and handling each instance separately. However, we propose a different approach by breaking down the VOS task into two subtasks: global embedding learning, which segments foreground objects in each frame at the pixel level, and instance feature embedding learning, which separates instances. We combine the outputs of these subtasks to quickly and accurately generate the final instance masks. By considering the relationships between instances within each frame and across frames, our network learns to distinguish multiple instances and associate them correctly in a single pass. Extensive experiments conducted on the challenging DAVIS and Youtube-VOS datasets demonstrate that our method outperforms most existing methods in both cases.