This study introduces a new approach to learning the internal distribution of patches within a single natural image without relying on external training data. Unlike previous methods that use a latent variable model, this paper proposes an energy-based generative framework to explicitly represent the statistical distribution within an image. This framework consists of a pyramid of energy functions, each parameterized by a deep neural network, to capture patch distributions at different resolutions. Additionally, a sequential training and sampling strategy is presented to efficiently train the model. The model can also learn in parallel with a self-supervised task, such as recovering the input image from a corrupted version, to enhance its descriptive power. Notably, this model does not require an auxiliary model for training and integrates internal statistics learning and image generation into a single framework. Experimental results on various image generation and manipulation tasks, such as super-resolution, image editing, harmonization, and style transfer, demonstrate the effectiveness of the proposed model for internal learning.