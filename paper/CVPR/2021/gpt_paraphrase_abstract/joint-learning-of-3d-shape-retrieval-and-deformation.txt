We present a new technique for generating high-quality 3D models that resemble a given target object image or scan. Our approach involves retrieving an existing shape from a database of 3D models and deforming its parts to match the target shape. Unlike previous methods that focus separately on shape retrieval or deformation, our method employs a joint learning procedure that trains both the neural deformation module and the embedding space used by the retrieval module simultaneously. This allows our network to learn an embedding space that is aware of deformations, resulting in retrieved models that are more suitable for matching the target after appropriate deformation. To achieve this, we utilize the embedding space to guide the shape pairs used for training the deformation module, ensuring that it learns deformations between meaningful shape pairs. Additionally, our innovative part-aware deformation module can handle inconsistent and diverse part-structures in the source shapes. We demonstrate the advantages of our joint training approach not only on our own framework but also on other state-of-the-art neural deformation modules proposed in recent years. Furthermore, we show that our jointly-trained method outperforms various non-joint baselines.