Unsupervised super-resolution (SR) techniques have gained popularity due to their practical applications and promising potential in real-world scenarios. These methods typically involve generating synthetic low-resolution (LR) images from high-resolution (HR) images in the LR domain, and then using these synthetic LR images along with the corresponding HR images for supervised training. However, the performance of these approaches is limited by the domain gap between the generated synthetic LR images and real LR images.To address this issue, we propose a novel approach called domain-distance aware super-resolution (DASR) for unsupervised real-world image SR. Our approach tackles the domain gap between the training data (e.g., synthetic LR images) and testing data (e.g., real LR images) through domain-gap aware training and domain-distance weighted supervision strategies. Domain-gap aware training allows us to leverage real data in the target domain, while domain-distance weighted supervision enables a more rational use of labeled source domain data.We validate our method on both synthetic and real datasets, and the experimental results demonstrate that DASR consistently outperforms state-of-the-art unsupervised SR approaches. The generated SR outputs exhibit more realistic and natural textures. The code for our method is available at https://github.com/ShuhangGu/DASR.