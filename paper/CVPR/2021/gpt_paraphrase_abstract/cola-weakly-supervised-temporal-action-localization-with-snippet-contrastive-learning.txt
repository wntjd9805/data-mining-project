This study focuses on weakly-supervised temporal action localization (WS-TAL), which involves localizing actions in untrimmed videos using only video-level labels. Most existing models use the "localization by classification" approach, where they identify temporal regions that contribute the most to the video-level classification. However, these models often process each snippet or frame individually, which leads to a lack of consideration for the temporal context relationship. This results in the issue of "single snippet cheating," where ambiguous snippets are difficult to classify accurately.To address this problem, the authors propose a method called Snippet Contrastive learning to Localize Actions (CoLA). They argue that learning by comparing snippets can help identify the challenging ones. The proposed approach utilizes a Snippet Contrast (SniCo) Loss to refine the representation of hard snippets in the feature space. This loss function guides the network to understand precise temporal boundaries and avoid interruptions in the temporal interval. Additionally, since frame-level annotations are not available, the authors introduce a Hard Snippet Mining algorithm to locate potential hard snippets.The effectiveness of this mining strategy in capturing hard snippets and the informativeness of the feature representation achieved through SniCo Loss are verified through extensive analyses. The experimental results demonstrate that CoLA outperforms existing methods and achieves state-of-the-art results on the THUMOS'14 and ActivityNet v1.2 datasets.