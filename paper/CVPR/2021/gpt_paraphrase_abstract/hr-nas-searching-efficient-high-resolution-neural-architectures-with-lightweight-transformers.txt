This study introduces a new method called HR-NAS that focuses on finding efficient and accurate networks for dense prediction tasks such as segmentation, detection, and pose estimation. Unlike previous Neural Architecture Search (NAS) methods that mainly target image classification, HR-NAS aims to learn high-resolution representations. This is achieved by redesigning the NAS search space and searching strategy. The study proposes a lightweight transformer that can dynamically adapt its computational complexity based on different objective functions and computation budgets to effectively encode multiscale image contexts. Additionally, HR-NAS adopts a multi-branch architecture inspired by HRNet to maintain high-resolution representations. The study also proposes an efficient fine-grained search strategy to train HR-NAS, which can explore the search space and find optimal architectures for various tasks and computation resources. Results demonstrate that HR-NAS achieves state-of-the-art trade-offs between performance and FLOPs (floating point operations) for dense prediction tasks and image classification with limited computational budgets. For instance, HR-NAS outperforms SqueezeNAS in terms of segmentation efficiency by 45.9%. The code for HR-NAS is available at https://github.com/dingmyu/HR-NAS.