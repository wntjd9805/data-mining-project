This study introduces a novel approach for remote photoplethysmography (rPPG) based physiological measurement. While existing methods focus on enhancing or extracting weak blood volume pulse (BVP) signals from face videos, they often neglect modeling the dominant noises present in these videos. As a result, their generalization ability in unseen scenarios is limited. To address this, the proposed method utilizes Dual Generative Adversarial Networks (Dual-GAN) to jointly model the BVP predictor and noise distribution. The BVP-GAN learns a noise-resistant mapping from input to ground-truth BVP, while the Noise-GAN learns the noise distribution. These two GANs enhance each other's capabilities, leading to improved disentanglement of features between BVP and noises. Additionally, a plug-and-play block called ROI alignment and fusion (ROI-AF) is introduced to overcome inconsistencies between different regions of interest (ROIs) and extract informative features from a wider receptive field. The performance of the proposed approach is compared to state-of-the-art methods in heart rate, heart rate variability, and respiration frequency estimation from face videos, demonstrating superior results.