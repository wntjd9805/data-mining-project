We introduce a novel boundary-aware loss term for semantic segmentation using an inverse-transformation network. This loss term effectively learns the extent of parametric transformations between predicted and target boundaries. By incorporating this additional loss term, we enhance the performance of segmentation backbone models without increasing their size or computational complexity. We evaluate the impact of our loss function on three segmentation benchmarks, namely Cityscapes, NYU-Depth-v2, and PASCAL, by integrating it into the training phase of various backbone networks in both single-task and multi-task settings. Through extensive experiments, we consistently outperform baseline methods and achieve state-of-the-art results on two datasets.