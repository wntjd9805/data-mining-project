Class-Incremental Learning (CIL) is a technique used to develop a classification model by gradually increasing the number of classes. However, CIL faces a challenge known as the stability-plasticity dilemma, where models with high plasticity tend to forget old classes, while models with high stability struggle to learn new classes. To address this issue, we propose a new network architecture called Adaptive Aggregation Networks (AANets). AANets consist of two types of residual blocks at each level: stable blocks and plastic blocks. The output feature maps from these blocks are aggregated and passed to the next-level blocks. We dynamically adjust the weights of the aggregation to balance stability and plasticity. We conducted experiments on three CIL benchmarks and found that existing CIL methods can be easily integrated into AANets to enhance their performance.