We address the problem of image retrieval using text feedback, where a reference image and modifier text are combined to identify the desired target image. Our focus is on developing an image-text compositor that integrates multi-modal inputs to generate a representation similar to the target image. To tackle this challenge, we propose the Content-Style Modulation (CoSMo) algorithm, which consists of two modules based on deep neural networks: the content modulator and the style modulator. The content modulator adjusts the features of the reference image locally, taking into account the normalized style of the image. We employ a disentangled multi-modal non-local block to achieve the desired content modifications. Subsequently, the style modulator reintroduces global style information to the updated feature. We provide a detailed explanation of our algorithm and the design choices made, demonstrating its exceptional performance on various image-text retrieval benchmarks. For those interested, our code is available at: https://github.com/postBG/CosMo.pytorch.