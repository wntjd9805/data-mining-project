Graph Neural Networks (GNNs) have been highly successful in learning representations of graphs. However, they typically assume that the entire attributed graph can be loaded into memory for processing. This assumption is problematic when dealing with limited memory resources and large graphs. To address this issue, we propose a Binary Graph Convolutional Network (Bi-GCN) that binarizes both the network parameters and input node features. We also modify matrix multiplications to binary operations to improve speed. Theoretical analysis shows that our Bi-GCN reduces memory consumption by an average of ∼30x for both network parameters and input data, and accelerates inference speed by an average of ∼47x on citation networks. We also develop a new gradient approximation-based back-propagation method to effectively train Bi-GCN. Extensive experiments demonstrate that Bi-GCN performs comparably to full-precision baselines. Furthermore, our binarization approach can easily be applied to other GNNs, as validated in the experiments.