Learning discriminative representation using large-scale face datasets in real-world applications is crucial but challenging. This study focuses on two main challenges: limited computing resources and imbalanced class distribution. Previous techniques using deep neural networks and well-designed losses have shown good recognition performance, but they have high computational and memory costs proportional to the number of classes in the training set, and they struggle with unbalanced classes. To address these issues, we propose a dynamic class queue (DCQ) approach. During training, we dynamically select a subset of classes for recognition and generate class weights on-the-fly, storing them in a queue. This reduces the computational requirements as only a subset of classes is used in each iteration. We empirically demonstrate that using only 10% of the classes can achieve similar performance as using all classes on large-scale datasets. Additionally, the dynamic generation of class weights suits tail classes with few instances. We show significant improvement over a strong baseline on the Megaface Challenge2 dataset, which has 672K identities, with over 88% of them having less than 10 instances. The code for our approach is available at https://github.com/bilylee/DCQ.