The development of simultaneous localization and mapping (SLAM) technology faces obstacles when applied to visual robot navigation due to factors such as rapid turns, feature-less walls, and low camera quality. To address this issue, we present the Differentiable SLAM Network (SLAM-net) and a navigation framework that enables planar robot navigation in unfamiliar indoor environments. SLAM-net incorporates a particle filter-based SLAM algorithm into a differentiable computational graph and utilizes backpropagation to learn task-specific neural network components. By optimizing all model components jointly, SLAM-net demonstrates robustness in challenging conditions. We conducted experiments using real-world RGB and RGB-D datasets in the Habitat platform, and the results show that SLAM-net outperforms the widely used ORB-SLAM in noisy conditions. Additionally, our navigation architecture with SLAM-net achieves a significant improvement in the Habitat Challenge 2020 PointNav task, with a success rate increasing from 37% to 64%. For more details, please visit our project website at http://sites.google.com/view/slamnet.