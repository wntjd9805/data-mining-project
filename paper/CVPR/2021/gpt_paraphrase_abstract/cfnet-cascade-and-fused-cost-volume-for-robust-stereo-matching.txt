The advancement in stereo matching has been greatly influenced by the availability of large annotated datasets. However, most successful models are limited to specific datasets and struggle to generalize to others. This is due to the significant differences in domains and the imbalanced distribution of disparities across various datasets, which restrict the real-world applicability of current deep stereo matching models. To address these challenges, we propose CFNet, a network based on a Cascade and Fused cost volume approach to enhance the robustness of stereo matching. Firstly, we introduce a fused cost volume representation that handles the large domain differences. By combining multiple low-resolution dense cost volumes, we can capture reliable structural representations for initial disparity estimation. Secondly, we propose a cascade cost volume representation to alleviate the issue of unbalanced disparity distribution. Specifically, we utilize uncertainty estimation based on variance to adaptively adjust the search space for the next stage of disparity estimation. This allows the network to progressively eliminate unlikely correspondences, ultimately refining the disparity estimation in a coarse-to-fine manner. To evaluate the effectiveness of CFNet, we conduct experiments on KITTI, ETH3D, and Middlebury datasets using the same training images and fixed model parameters and hyperparameters. Our proposed method achieves state-of-the-art performance and secures the first place in the stereo task of the Robust Vision Challenge 2020. The code for CFNet is available at https://github.com/gallenszl/CFNet.