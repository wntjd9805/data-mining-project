This study explores a new training scheme for Generative Adversarial Networks (GANs) that allows for more efficient training in a single stage instead of the traditional two-stage process. The authors classify GANs into two categories, Symmetric GANs and Asymmetric GANs, and introduce a gradient decomposition method to unify the two. This approach reduces the training effort required for both classes of GANs. Computational analysis demonstrates the efficiency of this method, with a significant 1.5Ã— acceleration observed across various datasets and network architectures. The researchers also demonstrate that this method can be applied to other adversarial-training scenarios, such as data-free knowledge distillation. The code for implementing this approach is available at https://github.com/zju-vipa/OSGAN.