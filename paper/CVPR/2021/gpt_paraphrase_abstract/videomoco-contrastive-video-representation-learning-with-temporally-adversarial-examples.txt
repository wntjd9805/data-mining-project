The paper introduces VideoMoCo, a method for unsupervised video representation learning inspired by the effectiveness of MoCo for image representation learning. VideoMoCo improves the temporal feature representations of MoCo by incorporating a generator and a discriminator. The generator drops out frames from the input video sequence, while the discriminator learns to encode similar feature representations regardless of frame removals. This adversarial learning process allows for the training of a temporally robust encoder. Additionally, temporal decay is used to model key attenuation in the memory queue when computing the contrastive loss. This decay helps to attend the input sample to recent keys in the queue, reflecting the degradation of key representation ability over time. By enhancing the temporal robustness of the encoder and modeling the temporal decay of the keys, VideoMoCo improves upon MoCo in the context of contrastive learning for video representation. Experimental results on benchmark datasets (UCF101 and HMDB51) demonstrate that VideoMoCo is a state-of-the-art method for video representation learning.