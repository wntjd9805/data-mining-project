We present CorrNet3D, an innovative deep learning-based framework for learning dense correspondence between 3D shapes without the need for annotated data. Our approach is motivated by the belief that aligned point clouds are easier to transform meaningfully compared to misaligned pairs. CorrNet3D consists of three modules: a deep feature embedding module, a correspondence indicator module, and a symmetric deformer module. By feeding a pair of raw point clouds into our model, we first learn the pointwise features and generate a learnable correspondence matrix using the indicator module. This matrix is then used to permute the input pair. The symmetric deformer, with an additional regularized loss, transforms the permuted point clouds to each other, facilitating the unsupervised learning of correspondence. Extensive experiments on both synthetic and real-world datasets of rigid and non-rigid 3D shapes demonstrate that CorrNet3D significantly outperforms state-of-the-art methods, including those that use meshes as input. Furthermore, our framework is flexible and can be easily adapted to supervised learning if annotated data is available. The source code and pre-trained model of CorrNet3D can be found at https://github.com/ZENGYIMING-EAMON/CorrNet3D.git.