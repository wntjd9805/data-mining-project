Siamese-based trackers have shown promising performance in visual tracking. However, the use of depth-wise cross-correlation (DW-XCorr) in these trackers has limitations. DW-XCorr is easily fooled by distractors, has fewer activated channels, and provides weak discrimination of object boundaries. Additionally, DW-XCorr is a handcrafted parameter-free module and cannot fully benefit from offline learning on large-scale data. To address these limitations, we propose a learnable module called the asymmetric convolution (ACM). ACM learns to capture semantic correlation information through offline training on large-scale data. Unlike DW-XCorr, ACM decomposes the convolution operation into two mathematically equivalent operations, allowing for the concatenation of feature maps with different sizes. ACM can also incorporate prior information, such as bounding-box size, with visual features. Furthermore, ACM can be easily integrated into existing Siamese trackers based on DW-XCorr or XCorr.We integrate ACM into three representative trackers (SiamFC, SiamRPN++, and SiamBAN) and demonstrate its generalization ability. Our experiments show that ACM outperforms existing methods on six tracking benchmarks. Specifically, on the LaSOT test set, our ACM-based tracker achieves a significant improvement of 5.8% in success (AUC) compared to the baseline.