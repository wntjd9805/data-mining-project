This paper presents a novel end-to-end trainable video text detector that utilizes semantic features for tracking texts. Unlike existing methods that rely on appearance features, which are sensitive to changes in perspective and illumination, semantic features provide more robust cues for matching text instances. The proposed approach consists of several components. Firstly, a character center segmentation branch is introduced to extract semantic features that encode the category and position of characters. Secondly, an innovative appearance-semantic-geometry descriptor is proposed to track text instances, leveraging the robustness of semantic features against appearance changes. To address the issue of limited character-level annotations, a weakly-supervised character center detection module is proposed, which generates character-level labels using only word-level annotated real images. The effectiveness of the proposed method is demonstrated through experiments on multiple video text benchmarks, including ICDAR 2013 Video, Minetto, RT-1K, CA-SIA10K, and MSRA-TD500, where it achieves state-of-the-art performance.