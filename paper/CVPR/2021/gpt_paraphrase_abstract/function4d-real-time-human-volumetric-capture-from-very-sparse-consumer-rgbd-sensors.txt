Real-time human volumetric capture of complex scenarios using light-weight setups is a challenging task in computer vision and computer graphics. This paper introduces a novel approach that combines temporal volumetric fusion and deep implicit functions for human volumetric capture. To ensure high-quality and continuous reconstruction, the proposed method incorporates dynamic sliding fusion to merge neighboring depth observations while maintaining topology consistency. Additionally, for detailed and complete surface generation, detail-preserving deep implicit functions are utilized to process RGBD input, preserving geometric details and generating more realistic texturing results. Experimental results demonstrate that our method surpasses existing techniques in terms of view sparsity, generalization capacity, reconstruction quality, and runtime efficiency.