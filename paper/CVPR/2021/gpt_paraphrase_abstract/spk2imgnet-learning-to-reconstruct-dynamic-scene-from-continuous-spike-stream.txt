The spike camera, which captures dynamic scenes, differs from conventional digital cameras by producing a continuous spike stream instead of a single snapshot. Image reconstruction is a challenging task for spike cameras. This paper presents a spike-to-image neural network (Spk2ImgNet) that reconstructs dynamic scenes from spike streams. To handle noise and high-speed motion, a hierarchical architecture is proposed. A spatially adaptive light inference subnet captures local temporal correlation, while a pyramid deformable alignment aligns intermediate features to exploit long-term temporal correlation and avoid motion blur. The network is trained using a large-scale spike dataset generated by simulating the spike camera's working mechanism. Experimental results show that the proposed network outperforms existing spike camera reconstruction methods.