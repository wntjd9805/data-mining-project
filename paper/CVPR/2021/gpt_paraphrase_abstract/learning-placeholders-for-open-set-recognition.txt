Traditional classifiers are typically used in closed-set settings, where both the training and test classes belong to the same set. However, in real-world applications, unknown categories may be encountered, and these may be mistakenly recognized as known categories by the model. To address this issue, open-set recognition has been proposed, aiming to maintain classification performance on known classes while rejecting unknown ones. In closed-set models, predictions for familiar known class instances are often overly confident, making calibration and thresholding crucial when transitioning to an open-set environment. In this study, we introduce a method called PROSER (Placeholders for Open-Set Recognition) to prepare for unknown classes by allocating placeholders for both data and classifier. Specifically, learning data placeholders enables anticipation of open-set class data, effectively transforming closed-set training into open-set training. Additionally, we reserve classifier placeholders to capture the invariant information between target and non-target classes, serving as the class-specific boundary between known and unknown. PROSER efficiently generates novel classes through manifold mixup and adaptively sets the value of the reserved open-set classifier during training. Experimental results on various datasets demonstrate the effectiveness of our proposed method.