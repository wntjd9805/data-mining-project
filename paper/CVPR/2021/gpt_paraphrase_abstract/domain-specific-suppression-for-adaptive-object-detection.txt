Object detection methods in domain adaptation often suffer from decreased performance due to the complexity of tasks requiring more transferability of the model. To address this, we propose a new perspective that considers the weights of a CNN model as a series of motion patterns. We divide the directions of weights and gradients into domain-specific and domain-invariant parts, with the goal of focusing on the domain-invariant direction and eliminating disturbance from the domain-specific one. Current methods treat these two directions as a whole during optimization, which can lead to a mismatch in the domain-invariant direction even if the output features are aligned. To overcome this, we introduce domain-specific suppression, a constraint that separates and suppresses the domain-specific direction in the original convolution gradients during backpropagation. We validate our theoretical analysis and methods on various domain adaptive object detection tasks, including weather, camera configuration, and synthetic to real-world adaptation. Our experimental results demonstrate significant improvements over state-of-the-art methods in the field, achieving a promotion of 10.2-12.2% mAP in all the domain adaptation scenarios.