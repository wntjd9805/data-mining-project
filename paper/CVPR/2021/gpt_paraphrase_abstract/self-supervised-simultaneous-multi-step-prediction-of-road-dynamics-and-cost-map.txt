Supervised learning is widely used in conventional autonomous driving systems to train perception modules. However, this approach requires a large amount of labeled data, which hinders scalability. On the other hand, end-to-end architectures do not require labeled data and have the potential for greater scalability but lack interpretability. In this study, we propose a new architecture that is trained in a fully self-supervised manner to predict space-time cost maps and road dynamics in multiple steps. Our approach replaces the manually designed cost function for motion planning with a learned high dimensional cost map that is interpretable and can incorporate diverse contextual information without the need for manual data labeling. We conducted experiments using real-world driving data and found that our solution resulted in fewer collisions and road violations compared to baseline methods, demonstrating the feasibility of fully self-supervised prediction without sacrificing scalability.