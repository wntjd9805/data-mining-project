Current methods for generating talking face videos with high visual quality and realistic animations of expression and head pose fall short in producing high-resolution videos and capturing detailed facial expressions. This is mainly due to the lack of a suitable high-resolution audio-visual dataset and the limitations of sparse facial landmarks in capturing expression details. To address these issues, we introduce a novel approach called flow-guided talking face generation, which utilizes a large-scale high-resolution audio-visual dataset collected from YouTube. This dataset comprises approximately 16 hours of 720P or 1080P videos.   Our framework leverages a facial 3D morphable model (3DMM) and divides the generation process into two cascaded modules instead of directly mapping audio to video. In the first module, we propose an animation generator that simultaneously produces movements of the mouth, eyebrows, and head pose. In the second module, we convert the animation into dense flow to capture more expression details. We also design a flow-guided video generator to synthesize videos.   Our method achieves high-definition video synthesis and outperforms existing state-of-the-art approaches in both objective and subjective evaluations.