This study addresses the vulnerability of deep neural networks to adversarial attacks in visual object tracking. While previous white-box attack methods have shown promising results, they require knowledge of the model structures of deep trackers, which is often unavailable in real-world applications. To address this limitation, the authors propose a decision-based black-box attack method called IoU attack. Unlike existing black-box attack methods that focus on static images, IoU attack generates perturbations based on predicted IoU scores from current and historical frames. By decreasing these scores, the proposed method degrades the accuracy of temporal coherent bounding boxes and object motions. Furthermore, the learned perturbations are transferred to initialize temporal motion attacks in subsequent frames. The effectiveness of the IoU attack is validated on various state-of-the-art deep trackers. Extensive experiments on benchmark datasets demonstrate the efficacy of the proposed method. The source code for the IoU attack is available at https://github.com/VISION-SJTU/IoUattack.