This study presents a novel deep learning approach to address perspective distortions in wide-angle portraits. The authors propose a cascaded network comprising a LineNet, a ShapeNet, and a transition module (TM) to correct background distortions and adapt to facial regions. The network is trained on a diverse dataset of wide-angle portraits. The authors also introduce two new metrics, line consistency and face congruence, for quantitative evaluation. Compared to previous methods, this approach does not require camera distortion parameters and outperforms existing techniques in terms of quality and accuracy.