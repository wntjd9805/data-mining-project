We propose a new approach for predicting video frames that takes into account occlusions and the consistent evolution of objects in the video. Our method involves decomposing the scene layout and motion into layers, which are then predicted and combined with their context to generate future layouts and motions. We also use predicted motion to warp the appearance of the scene from past frames in regions that are visible in the current frame, while using content-aware inpainting to synthesize regions that are occluded. This approach allows us to create a predictive model that explicitly represents objects and learns their specific motion patterns. We have evaluated our model on video prediction benchmarks.