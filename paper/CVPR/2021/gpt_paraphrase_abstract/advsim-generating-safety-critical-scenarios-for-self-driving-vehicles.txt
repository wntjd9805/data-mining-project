Advances in self-driving technology necessitate the development of simulation scenarios that can effectively test and identify potential failures in the autonomy stack. Traditionally, these scenarios are limited in scope and fail to capture all possible failure scenarios, particularly those related to perception failures caused by occlusion. In this study, we present AdvSim, an adversarial framework that generates safety-critical scenarios for LiDAR-based autonomy systems. By modifying actor trajectories in a realistic manner and updating LiDAR sensor data accordingly, AdvSim is able to simulate scenarios directly from sensor data, resulting in safety-critical scenarios that encompass the entire autonomy stack. Our experiments demonstrate the broad applicability of AdvSim, as it is capable of identifying thousands of semantically meaningful safety-critical scenarios for various modern self-driving systems. Furthermore, we show that training these systems with scenarios generated by AdvSim can enhance their robustness and safety.