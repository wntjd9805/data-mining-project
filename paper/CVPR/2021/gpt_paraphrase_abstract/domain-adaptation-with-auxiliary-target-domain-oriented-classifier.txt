Domain adaptation (DA) is a technique used to transfer knowledge from a domain with many labeled examples but different characteristics to a domain with few labeled examples. This helps reduce the need for manual labeling and has gained considerable attention. While previous methods have focused on learning feature representations that are invariant across domains, recent approaches have applied generic semi-supervised learning (SSL) techniques directly to DA tasks, achieving competitive performance. One popular SSL technique is pseudo-labeling, which assigns labels to unlabeled data using a classifier trained on labeled data. However, pseudo-labeling ignores the distribution shift in DA problems and is biased towards the source data. To address this issue, we propose a new pseudo-labeling framework called Auxiliary Target Domain-Oriented Classifier (ATDOC). ATDOC introduces an auxiliary classifier for target data only, to improve the quality of pseudo labels and alleviate classifier bias. We employ a memory mechanism and develop two types of non-parametric classifiers, namely the nearest centroid classifier and neighborhood aggregation, without introducing additional network parameters. Despite its simplicity, ATDOC with neighborhood aggregation outperforms domain alignment techniques and previous SSL techniques on various DA benchmarks and even on tasks with scarce labeled data.