Vector graphics are commonly used for representing fonts, logos, digital artworks, and graphic designs. While there are many generative algorithms available for raster images, there are only a few options for vector graphics. One approach is to convert the vector graphics into raster images and use image-based generative methods, but this eliminates the benefits of using vector representation. Another alternative is to use specialized models that require explicit supervision on the vector graphics during training. However, obtaining large-scale high-quality vector graphics datasets is challenging, and models that rely on explicit vector supervision are unnecessarily limited since the vector representation for a design is not unique. In this study, we propose a novel neural network that can generate complex vector graphics with varying topologies without explicit vector supervision. Instead, we utilize a differentiable rasterization pipeline that renders the generated vector shapes and combines them on a raster canvas. Our method is evaluated on various datasets and compared to state-of-the-art models that require explicit vector supervision. Additionally, we demonstrate the effectiveness of our approach on the MNIST dataset, where groundtruth vector representations are not available. More information, including source code, datasets, and additional results, can be found at http://geometry.cs.ucl.ac.uk/projects/2021/Im2Vec/.