The problem addressed in this study is training deep image classification models for a limited number of extremely uncommon categories. Typically, the majority of images in a dataset belong to the background category, creating an imbalanced dataset. Existing approaches for training on imbalanced datasets do not yield accurate deep models in this scenario. To overcome this, the proposed solution involves dividing the visually diverse background into multiple smaller, visually similar categories during training. This is achieved by incorporating an additional auxiliary loss into the image classification model. The auxiliary loss learns to imitate the predictions of a pre-existing classification model on the training set without requiring additional human labels. This auxiliary loss helps regularize feature learning in the shared network trunk by compelling the model to distinguish between auxiliary categories for all training examples, including those in the background. The effectiveness of the proposed method is evaluated using modified versions of the iNaturalist and Places365 datasets, where only a small subset of rare category labels are available during training. By simultaneously learning to recognize both the selected rare categories and auxiliary categories, the approach outperforms state-of-the-art imbalanced learning baselines, achieving an 8.3 mAP (mean Average Precision) improvement when background data accounts for 98.30% of the dataset. Furthermore, it surpasses fine-tuning baselines by up to 42.3 mAP points when background data constitutes 99.98% of the dataset.