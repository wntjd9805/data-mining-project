We present a solution to the complex problem of classifying whole slide images (WSIs) which have high resolutions and lack localized annotations. Our approach involves using multiple instance learning (MIL) when only slide-level labels are available. We propose a MIL-based method for WSI classification and tumor detection that eliminates the need for localized annotations. Our method consists of three main components. First, we introduce a new MIL aggregator that models the relationships between instances using a dual-stream architecture with a trainable distance measurement. Second, to overcome the challenge of large or unbalanced bags in WSIs that impede MIL model training, we utilize self-supervised contrastive learning to extract high-quality representations for MIL and address the issue of high memory usage for large bags. Third, we employ a pyramidal fusion mechanism to combine multiscale WSI features, enhancing the accuracy of classification and localization. We evaluate our model on two representative WSI datasets and find that its classification accuracy is comparable to fully-supervised methods, with an accuracy gap of less than 2% across datasets. Furthermore, our results outperform all previous MIL-based methods. Additional benchmark results on standard MIL datasets further demonstrate the superior performance of our MIL aggregator for general MIL problems.