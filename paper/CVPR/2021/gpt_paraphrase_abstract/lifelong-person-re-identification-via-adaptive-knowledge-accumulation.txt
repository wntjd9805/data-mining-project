This study focuses on the task of person re-identification (ReID), which involves identifying the same person across different camera views. Traditional ReID methods are limited because they are designed to learn from a fixed dataset, which does not allow for continuous learning in changing environments. To address this issue, the researchers propose a new task called lifelong person re-identification (LReID), which enables continuous learning across multiple domains and the ability to generalize to new and unseen domains.  To mimic the cognitive processes in the human brain, the researchers develop an Adaptive Knowledge Accumulation (AKA) framework. This framework has two key abilities: knowledge representation and knowledge operation. By incorporating these abilities, the proposed method mitigates the problem of catastrophic forgetting on previously seen domains and demonstrates the ability to generalize to unseen domains.  In addition to the proposed method, the researchers also introduce a new and large-scale benchmark dataset for LReID. Through extensive experiments, they show that their method outperforms other competitors by a margin of 5.8% in terms of mean Average Precision (mAP) in generalization evaluation.  The researchers provide their code implementation on GitHub for reproducibility purposes.