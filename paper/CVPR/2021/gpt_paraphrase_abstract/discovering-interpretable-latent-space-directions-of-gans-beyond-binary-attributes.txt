The abstract discusses the use of generative adversarial networks (GANs) to map noise latent vectors to high-quality images. It mentions that the latent space, which represents the input vectors, has semantic correlations with the output image space. Previous methods aimed to interpret the latent space and find meaningful directions for image transformations, but they relied on explicit attribute scores or binary attributes, limiting their applicability. In this paper, the authors propose a new method called AdvStyle that discovers interpretable directions without explicit scores or binary attributes. The method optimizes the discovered directions and the attribute assessor using positive and negative samples. This allows for editing of arbitrary attributes with only positive data and enables manipulation of non-binary attributes like anime styles and facial characteristics. The proposed learning strategy also reduces the entanglement between attributes, making multi-attribute manipulation easier. The authors also uncover interesting semantics with the inadvertently learned negative directions. They provide extensive experiments on anime and human attributes to demonstrate the effectiveness of their adversarial approach. The code for their method is available on GitHub.