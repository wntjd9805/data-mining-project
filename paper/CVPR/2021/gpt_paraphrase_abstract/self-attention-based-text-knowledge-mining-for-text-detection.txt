Most deep learning-based text detectors use pre-trained models, but they often overlook the differences between natural images and scene text images. Instead, they directly use ImageNet for pre-training. To address this issue, some methods first pre-train the model using synthetic data and then fine-tune it on target datasets. However, this approach is task-specific and lacks generalization capability. This paper proposes a solution called STKM (Self-attention based Text Knowledge Mining) that aims to provide general pre-trained models for text detectors. STKM consists of a CNN Encoder and a Self-attention Decoder. It uses SynthText to learn prior knowledge for text detection. The Self-attention Decoder decodes features from the CNN Encoder to texts without the need for detection, guiding the CNN backbone to learn discriminative semantic representations that were ignored by previous methods. The knowledge learned by the backbone can then be transferred to different text detectors, significantly improving their detection performance. For example, the EAST model achieves a 5.89% higher F-measure on the ICDAR15 dataset. This improvement is achieved without any additional complexities. The pre-trained model can be accessed at https://github.com/CVI-SZU/STKM.