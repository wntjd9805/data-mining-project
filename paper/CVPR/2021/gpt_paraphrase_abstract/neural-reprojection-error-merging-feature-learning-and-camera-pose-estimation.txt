The conventional approach to absolute camera pose estimation involves solving two separate problems: feature matching and Perspective-n-Point. However, this method results in a loss of information and potential errors in the pose estimation. To address this, we propose the use of Neural Reprojection Error (NRE) as a substitute for the traditional Reprojection Error (RE). NRE combines the camera pose estimation and feature learning problems, leading to richer information and eliminating the need for choosing a robust loss and its hyperparameters. We also introduce a coarse-to-fine optimization method that efficiently minimizes the sum of NRE terms with respect to the camera pose. Experimental results demonstrate that NRE significantly enhances the robustness and accuracy of camera pose estimation while being computationally and memory efficient. This approach of merging deep learning and 3D geometry has potential applications in other computer vision tasks. The source code and model weights are available at hugogermain.com/nre.