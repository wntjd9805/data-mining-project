This paper proposes a novel approach called EfﬁScene for solving the challenging unsupervised scene ﬂow estimation problem. The approach addresses this problem by jointly learning four low-level vision sub-tasks: optical ﬂow, stereo-depth, camera pose, and motion segmentation. The key insight is that the rigidity of the scene shares the same geometric structure with object movements and scene depth. Therefore, the rigidity from motion segmentation can be inferred by coupling optical ﬂow, stereo-depth, and camera pose to improve the estimation accuracy.   The EfﬁScene framework first estimates optical ﬂow and depth at a coarse level and then computes camera pose using the Perspective-n-Points method. To learn local rigidity, a novel Rigidity From Motion (RfM) layer is designed with three principal components: correlation extraction, boundary learning, and outlier exclusion. The final outputs are fused based on the rigid map from RfM at finer levels.   To train EfﬁScene efficiently, two new losses, Lbnd and Lunc, are introduced to prevent trivial solutions and regularize the flow boundary discontinuity. Experimental evaluations on the KITTI scene ﬂow benchmark demonstrate that the proposed method outperforms state-of-the-art approaches in all sub-tasks, including optical ﬂow, depth estimation, visual odometry, and motion segmentation. The results show significant improvements in accuracy for each sub-task.