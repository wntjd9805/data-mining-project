This paper proposes a new approach for representing, detecting, and tracking 3D objects using points instead of 3D boxes. The current method of using 3D boxes to represent objects in a point-cloud comes with challenges, such as difficulties in handling object orientation and fitting bounding boxes to rotated objects. The proposed framework, called CenterPoint, detects object centers using a keypoint detector and then regresses to other attributes like 3D size, orientation, and velocity. In the second stage, additional point features on the object are used to refine these estimates. The tracking process simplifies to a greedy closest-point matching. CenterPoint achieves state-of-the-art performance on the nuScenes benchmark for both 3D detection and tracking, with 65.5 NDS and 63.8 AMOTA for a single model. It also outperforms all previous single model methods by a large margin and ranks first among all Lidar-only submissions on the Waymo Open Dataset. The code and pretrained models for CenterPoint are available at https://github.com/tianweiy/CenterPoint.