This paper presents a new framework called Learning to Aggregate and Personalize (LAP) for robust 3D face modeling without shape assumptions. The existing non-parametric face modeling approaches suffer from over-reliance on local color appearance and unclear noise. LAP addresses this problem by implicitly separating the identity-consistent and scene-specific faces from an unconstrained photo set. To achieve an ID-consistent face, LAP uses a curriculum learning approach with relaxed consistency loss to adaptively aggregate intrinsic face factors. To personalize the face for a specific scene, LAP introduces an attribute-refining network to modify the ID-consistent face with target attributes and details. The proposed method allows for more meaningful facial structure and higher resolutions in unsupervised 3D face modeling. Extensive experiments on benchmarks demonstrate that LAP outperforms state-of-the-art methods, both with and without prior knowledge or supervision, in terms of face shape and texture recovery.