We present a new deep neural network that can accurately estimate the depth map of a single monocular indoor panorama. Unlike existing methods, our network directly operates on the equirectangular projection of the image, taking advantage of the unique properties of indoor 360-degree images. Recognizing the significance of gravity in indoor scenes, we propose a concise representation of the scene by dividing it into vertical slices on the sphere. By analyzing the relationships between these slices, both short-term and long-term, we are able to reconstruct the equirectangular depth map. Our approach enables us to preserve high-resolution details in the extracted features, even with a deep network architecture. Through extensive experiments, we demonstrate that our method surpasses current state-of-the-art solutions in terms of prediction accuracy, particularly when applied to real-world data.