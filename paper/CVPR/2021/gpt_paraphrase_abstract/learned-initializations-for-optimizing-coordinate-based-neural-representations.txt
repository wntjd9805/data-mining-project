Coordinate-based neural representations have shown promise as an alternative to discrete, array-based representations for complex low dimensional signals. However, initializing the weights randomly for each new signal is inefficient. To address this, we propose using standard meta-learning algorithms to learn the initial weight parameters for fully-connected networks based on the class of signals being represented (e.g., faces or 3D models of chairs). By using these learned initial weights, convergence during optimization is faster and the model can better generalize when only partial observations of a given signal are available. We demonstrate the benefits of this approach in various tasks, such as representing 2D images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D image observations.