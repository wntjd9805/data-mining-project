This paper addresses the issue of unsupervised person re-identification (re-ID), which involves learning discriminative models using unlabeled data. One common approach is to generate pseudo-labels through clustering and use them to optimize the model. However, this method is hindered by two challenges: 1) noisy labels produced by clustering and 2) variations in features caused by changes in camera angles. Noisy labels can lead to incorrect optimization, reducing model accuracy. Feature variations can result in assigning samples from the same person but captured by different cameras to different pseudo-labels, making the model sensitive to camera variations. To solve these problems, we propose a unified framework that addresses both challenges. Specifically, we introduce a Dynamic and Symmetric Cross-Entropy loss (DSCE) to handle noisy samples and a camera-aware meta-learning algorithm (MetaCam) to adapt to camera shifts. DSCE mitigates the negative effects of noisy samples and can accommodate changes in clusters after each clustering step. MetaCam simulates cross-camera constraints by dividing the training data into meta-train and meta-test sets based on camera IDs. By incorporating gradients from both meta-train and meta-test, the model is enforced to learn features that are invariant to camera variations. Extensive experiments on three re-ID benchmarks demonstrate the effectiveness and complementary nature of DSCE and MetaCam. Our method outperforms state-of-the-art approaches in both fully unsupervised re-ID and unsupervised domain adaptive re-ID scenarios.