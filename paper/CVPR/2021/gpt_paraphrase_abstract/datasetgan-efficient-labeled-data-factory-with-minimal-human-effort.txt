We present DatasetGAN, a method for automatically generating large datasets of high-quality semantically segmented images with minimal human involvement. Deep neural networks require extensive training on large datasets, which can be time-consuming to annotate. Our approach utilizes the capabilities of recent Generative Adversarial Networks (GANs) to generate realistic images. By decoding the latent code of the GAN, we can produce semantic segmentations of the images. The decoder is trained with a few labeled examples, enabling it to generalize to the entire latent space and create an infinite annotated dataset generator. These generated datasets can be used to train computer vision models, just like real datasets. With only a small number of manually segmented images required, our method allows for detailed annotation and the generation of datasets with rich object and part segmentations. We demonstrate the effectiveness of our approach by generating datasets for seven image segmentation tasks, including pixel-level labels for 34 human face parts and 32 car parts. Our method outperforms semi-supervised baselines significantly and achieves comparable performance to fully supervised methods, which often require 100 times more annotated data than our approach.