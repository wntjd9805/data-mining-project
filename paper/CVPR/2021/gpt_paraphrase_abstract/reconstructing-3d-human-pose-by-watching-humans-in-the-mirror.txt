This paper introduces a novel task of reconstructing 3D human pose from a single image captured through a mirror. Unlike typical scenarios of 3D pose estimation from a single view, the mirror reflection offers an additional perspective to resolve depth ambiguity. The authors propose an optimization-based approach that leverages mirror symmetry constraints to accurately reconstruct the 3D pose. They also present a method to estimate the mirror's surface normal using vanishing points in the single image. To evaluate their approach, a large-scale dataset called Mirrored-Human is collected, encompassing diverse human subjects, poses, and backgrounds. Experimental results demonstrate that training existing single-view 3D pose estimators on Mirrored-Human with the reconstructed 3D poses as pseudo ground-truth significantly improves accuracy and generalizability. The code and dataset can be accessed at https://zju3dv.github.io/Mirrored-Human/.