We propose PVGNet, a one-stage and voting-based 3D object detector for LiDAR points. Unlike images, LiDAR points are distributed along object boundaries, making boundary features crucial for detection. However, quantization introduces ambiguity during training and inference. PVGNet addresses this by extracting point, voxel, and grid-level features in a unified backbone architecture and producing point-wise fusion features. It segments LiDAR points into foreground and background, predicts 3D bounding boxes for each foreground point, and performs group voting for final results. We also address instance-level point imbalance caused by occlusion and observation distance with a novel instance-aware focal loss. Experiments on KITTI and Waymo datasets show that PVGNet outperforms previous methods and ranks highly on KITTI 3D/BEV detection leaderboards.