Previous methods for identifying interpretable dimensions in the latent space of Generative Adversarial Networks (GANs) require manual annotations and a clear definition of the target attribute, limiting their practical applications. In this study, we propose an unsupervised approach to uncover the underlying factors of variation in GANs' internal representation. By examining the generation mechanism of GANs and decomposing pre-trained weights, we introduce a closed-form factorization algorithm for latent semantic discovery. Our approach is not only fast but also capable of finding semantically meaningful dimensions comparable to state-of-the-art supervised methods. Additionally, it yields versatile concepts across multiple GAN models trained on various datasets.